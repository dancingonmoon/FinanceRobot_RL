
Search: Running Trial #1

default configuration

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4314.000000   4315.000000
mean      0.000441    20062.255222  ...   20122.295285  20118.633889
std       0.027818    16039.874230  ...   16077.162832  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7691.585083   7690.540039
50%       0.000642    11554.824463  ...   11724.320312  11715.610352
75%       0.011655    29873.081836  ...   29925.802734  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-27 22:02:58.706439: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-27 22:02:59.106973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:03:26.895577: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201
2023-07-27 22:03:28.265608: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-02207023-07-27-2273-  22:200273:-27 22:03:28.292140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
03:28.292138: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-27 22:03:28.292697: I tensorflow/core/platform/cpu_feature_guard.cc:142] This Tenso2:023-072rFl-2o7 w22: bina0r3y is :282o02pt3-0i7-27 22:03:288..292780: I te2mized92138: I tensorflo.w/co with on292eA7nPrI e/3D6: I tepnesep Neural Network Library (oneDNN) to use the foll2o023-07-27 22:03:28.292936: I tenssorflow/coreolatform/cpu/orwfpla_ing Ctfrform/cpuflPlow/o_wfeUatureeac/ctuore_goua _re/instrugctpirrd.cc:142] uoanTrd.ccls :i1hain42]e sTt f2hor/i mplatTes0 npsforFo2lTo/w binar3erm/cpu_featensorFlow binary is optimy- 0ucprii7z-eudfrorm 27 22s o_:03:28feature_guard.cc:1waep_tgn.ith 294co32] uTard.imized with oneAPI Deep Neural Net205:ew In echc-otrkAPI D is: Tee1Librarycensornsorfl (ow/core/plaeo4Flow 2p Neuritbfinary iormr] This Tsn optimized with onetical operations:  AVX AVX2
To API Deepal  NNeetwork eeDNN) to use tL/ucrapl Nhe fenable them in otnesuitoollowing CPU instructions in perforr_bfFlmraerature_guardwoyance-co.rckherr io (pweoneDt icrNal operatioLibrn s:baaNi)nrac t:r y t1y iiosnAVX o A  opt(ou4V2X]nsee DNth2
TNe) fi  Ttosmhiis TensorFlow bized,  nwao eirth oneAPI Deep Neural Network Library (oneDNu rebuilsoNe lnable thed )ym  in other operatiiTes  opntoinlowtmizedihnstg oroFl ou weiths followCP oneAPew  iws,I nigthe following CPDth th e appropriate compUre U iinsbinu itlstreerructionCuep Nes inP ural Network Library (oneDNN) to use the followi fplags.
cltid ng CPU ionestTnensorrucUs instFtlo rriinwucon tions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuil spe fin odrmrpfoe rformanaTcnceree-cma-ncrncsorFlow with the appropriate compilrwith etrheit f-ical operaticriltaons:  AVX AVX2ie aticalppg osp.

ropical oeTrriate compiler flaoagps eretn.a
ablitions:o  AVX AVnsX2
To enable t: eh  eAm tVhiXe AmVX2
Tn ot o enable theher m in other operations, rebuild TensorFlow with the appropriate compiler flags.
operations, rebuild TensorFlow with the appropriate compiler flags.
in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-27 22:03:29.662850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:03:29.844133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:03:29.896026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:03:29.928975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:03:29.942243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:03:29.944766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:03:29.950980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:03:29.982311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:03:30.697163: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
update:  5/2000, 耗时:0.00分/0.15分 | step:    40 | performance: 1.0 | accuracy: 0.20 | loss: 13.94
update: 10/2000, 耗时:0.00分/0.16分 | step:    80 | performance: 1.4 | accuracy: 0.50 | loss: 4.49
update: 15/2000, 耗时:0.00分/0.16分 | step:   120 | performance: 1.3 | accuracy: 0.47 | loss: 0.48
update: 20/2000, 耗时:0.00分/0.17分 | step:   160 | performance: 1.2 | accuracy: 0.40 | loss: 1.57
update: 25/2000, 耗时:0.00分/0.18分 | step:   200 | performance: 1.0 | accuracy: 0.36 | loss: 0.38
update: 30/2000, 耗时:0.00分/0.19分 | step:   240 | performance: 1.0 | accuracy: 0.40 | loss: 0.36
update: 35/2000, 耗时:0.00分/0.19分 | step:   280 | performance: 0.9 | accuracy: 0.37 | loss: 0.63
update: 40/2000, 耗时:0.00分/0.20分 | step:   320 | performance: 1.0 | accuracy: 0.38 | loss: 0.43
update: 45/2000, 耗时:0.00分/0.21分 | step:   360 | performance: 0.9 | accuracy: 0.36 | loss: 0.37
update: 50/2000, 耗时:0.00分/0.22分 | step:   400 | performance: 1.0 | accuracy: 0.38 | loss: 0.55
update: 55/2000, 耗时:0.00分/0.22分 | step:   440 | performance: 0.9 | accuracy: 0.38 | loss: 0.25
update: 60/2000, 耗时:0.00分/0.23分 | step:   480 | performance: 1.0 | accuracy: 0.40 | loss: 1.92
update: 65/2000, 耗时:0.00分/0.24分 | step:   520 | performance: 0.9 | accuracy: 0.38 | loss: 1.00
update: 70/2000, 耗时:0.00分/0.25分 | step:   560 | performance: 0.8 | accuracy: 0.37 | loss: 0.79
update: 75/2000, 耗时:0.00分/0.25分 | step:   600 | performance: 0.7 | accuracy: 0.36 | loss: 0.76
update: 80/2000, 耗时:0.00分/0.26分 | step:   640 | performance: 0.7 | accuracy: 0.35 | loss: 0.43
update: 85/2000, 耗时:0.00分/0.27分 | step:   680 | performance: 0.6 | accuracy: 0.34 | loss: 0.32
update: 90/2000, 耗时:0.00分/0.28分 | step:   720 | performance: 0.5 | accuracy: 0.32 | loss: 0.82
update: 95/2000, 耗时:0.00分/0.28分 | step:   760 | performance: 0.5 | accuracy: 0.31 | loss: 0.49
update:100/2000, 耗时:0.00分/0.29分 | step:   800 | performance: 0.6 | accuracy: 0.31 | loss: 0.50
update:105/2000, 耗时:0.00分/0.30分 | step:   840 | performance: 0.5 | accuracy: 0.30 | loss: 0.41
update:110/2000, 耗时:0.00分/0.31分 | step:   880 | performance: 0.5 | accuracy: 0.29 | loss: 0.27
update:115/2000, 耗时:0.00分/0.31分 | step:   920 | performance: 0.5 | accuracy: 0.30 | loss: 0.23
update:120/2000, 耗时:0.00分/0.32分 | step:   960 | performance: 0.5 | accuracy: 0.32 | loss: 0.58
update:125/2000, 耗时:0.00分/0.33分 | step:  1000 | performance: 0.5 | accuracy: 0.33 | loss: 0.12
update:130/2000, 耗时:0.00分/0.33分 | step:  1040 | performance: 0.5 | accuracy: 0.34 | loss: 0.45
update:135/2000, 耗时:0.00分/0.34分 | step:  1080 | performance: 0.6 | accuracy: 0.35 | loss: 0.27
update:140/2000, 耗时:0.00分/0.35分 | step:  1120 | performance: 0.6 | accuracy: 0.34 | loss: 0.51
update:145/2000, 耗时:0.00分/0.36分 | step:  1160 | performance: 0.6 | accuracy: 0.34 | loss: 0.47
update:150/2000, 耗时:0.00分/0.36分 | step:  1200 | performance: 0.6 | accuracy: 0.35 | loss: 0.33
update:155/2000, 耗时:0.00分/0.37分 | step:  1240 | performance: 0.6 | accuracy: 0.34 | loss: 0.40
update:160/2000, 耗时:0.00分/0.38分 | step:  1280 | performance: 0.6 | accuracy: 0.34 | loss: 0.22
update:165/2000, 耗时:0.00分/0.38分 | step:  1320 | performance: 0.6 | accuracy: 0.33 | loss: 0.50
update:170/2000, 耗时:0.00分/0.39分 | step:  1360 | performance: 0.6 | accuracy: 0.34 | loss: 0.28
update:175/2000, 耗时:0.00分/0.40分 | step:  1400 | performance: 0.6 | accuracy: 0.34 | loss: 0.42
update:180/2000, 耗时:0.00分/0.41分 | step:  1440 | performance: 0.7 | accuracy: 0.34 | loss: 0.70
update:185/2000, 耗时:0.00分/0.41分 | step:  1480 | performance: 0.8 | accuracy: 0.35 | loss: 0.56
update:190/2000, 耗时:0.00分/0.42分 | step:  1520 | performance: 0.8 | accuracy: 0.35 | loss: 0.64
update:195/2000, 耗时:0.00分/0.43分 | step:  1560 | performance: 0.8 | accuracy: 0.35 | loss: 0.66
update:200/2000, 耗时:0.00分/0.44分 | step:  1600 | performance: 0.8 | accuracy: 0.35 | loss: 0.42
update:205/2000, 耗时:0.00分/0.44分 | step:  1640 | performance: 0.9 | accuracy: 0.36 | loss: 0.94
update:210/2000, 耗时:0.00分/0.45分 | step:  1680 | performance: 1.0 | accuracy: 0.37 | loss: 0.43
update:215/2000, 耗时:0.00分/0.46分 | step:  1720 | performance: 1.1 | accuracy: 0.38 | loss: 0.36
update:220/2000, 耗时:0.00分/0.47分 | step:  1760 | performance: 1.1 | accuracy: 0.37 | loss: 0.39
update:225/2000, 耗时:0.00分/0.47分 | step:  1800 | performance: 1.0 | accuracy: 0.37 | loss: 0.57
update:230/2000, 耗时:0.00分/0.48分 | step:  1840 | performance: 0.9 | accuracy: 0.37 | loss: 0.63
update:235/2000, 耗时:0.00分/0.49分 | step:  1880 | performance: 0.9 | accuracy: 0.37 | loss: 0.43
update:240/2000, 耗时:0.00分/0.49分 | step:  1920 | performance: 0.9 | accuracy: 0.38 | loss: 0.44
update:245/2000, 耗时:0.00分/0.50分 | step:  1960 | performance: 1.0 | accuracy: 0.38 | loss: 0.47
update:250/2000, 耗时:0.00分/0.51分 | step:  2000 | performance: 1.0 | accuracy: 0.38 | loss: 0.50
update:255/2000, 耗时:0.00分/0.52分 | step:  2040 | performance: 1.0 | accuracy: 0.38 | loss: 0.50
update:260/2000, 耗时:0.00分/0.52分 | step:  2080 | performance: 1.0 | accuracy: 0.38 | loss: 0.37
update:265/2000, 耗时:0.00分/0.53分 | step:  2120 | performance: 1.0 | accuracy: 0.38 | loss: 0.35
update:270/2000, 耗时:0.00分/0.54分 | step:  2160 | performance: 1.0 | accuracy: 0.38 | loss: 0.35
update:275/2000, 耗时:0.00分/0.55分 | step:  2200 | performance: 1.0 | accuracy: 0.39 | loss: 0.38
update:280/2000, 耗时:0.00分/0.55分 | step:  2240 | performance: 1.1 | accuracy: 0.38 | loss: 0.29
update:285/2000, 耗时:0.00分/0.56分 | step:  2280 | performance: 1.1 | accuracy: 0.38 | loss: 0.22
update:290/2000, 耗时:0.00分/0.57分 | step:  2320 | performance: 1.0 | accuracy: 0.37 | loss: 0.30
update:295/2000, 耗时:0.00分/0.58分 | step:  2360 | performance: 1.0 | accuracy: 0.37 | loss: 0.25
update:300/2000, 耗时:0.00分/0.58分 | step:  2400 | performance: 0.9 | accuracy: 0.36 | loss: 0.15
update:305/2000, 耗时:0.00分/0.59分 | step:  2440 | performance: 0.9 | accuracy: 0.36 | loss: 0.27
update:310/2000, 耗时:0.00分/0.60分 | step:  2480 | performance: 1.0 | accuracy: 0.36 | loss: 0.42
update:315/2000, 耗时:0.00分/0.60分 | step:  2520 | performance: 0.9 | accuracy: 0.36 | loss: 0.49
update:320/2000, 耗时:0.00分/0.61分 | step:  2560 | performance: 0.9 | accuracy: 0.36 | loss: 0.08
update:325/2000, 耗时:0.00分/0.62分 | step:  2600 | performance: 1.0 | accuracy: 0.36 | loss: 0.29
update:330/2000, 耗时:0.00分/0.63分 | step:  2640 | performance: 0.9 | accuracy: 0.35 | loss: 0.27
update:335/2000, 耗时:0.00分/0.63分 | step:  2680 | performance: 1.0 | accuracy: 0.35 | loss: 0.38
update:340/2000, 耗时:0.00分/0.64分 | step:  2720 | performance: 1.0 | accuracy: 0.36 | loss: 0.33
update:345/2000, 耗时:0.00分/0.65分 | step:  2760 | performance: 1.0 | accuracy: 0.35 | loss: 0.11
update:350/2000, 耗时:0.00分/0.65分 | step:  2800 | performance: 1.0 | accuracy: 0.35 | loss: 0.33
update:355/2000, 耗时:0.00分/0.66分 | step:  2840 | performance: 1.0 | accuracy: 0.35 | loss: 0.70
update:360/2000, 耗时:0.00分/0.67分 | step:  2880 | performance: 1.0 | accuracy: 0.35 | loss: 0.36
update:365/2000, 耗时:0.00分/0.68分 | step:  2920 | performance: 1.0 | accuracy: 0.36 | loss: 0.33
update:370/2000, 耗时:0.00分/0.68分 | step:  2960 | performance: 1.0 | accuracy: 0.36 | loss: 0.20
update:375/2000, 耗时:0.00分/0.69分 | step:  3000 | performance: 1.0 | accuracy: 0.36 | loss: 0.51
update:380/2000, 耗时:0.00分/0.70分 | step:  3040 | performance: 0.9 | accuracy: 0.36 | loss: 0.09
update:385/2000, 耗时:0.00分/0.71分 | step:  3080 | performance: 0.9 | accuracy: 0.36 | loss: 0.35
update:390/2000, 耗时:0.00分/0.71分 | step:  3120 | performance: 1.0 | accuracy: 0.36 | loss: 0.42
update:395/2000, 耗时:0.00分/0.72分 | step:  3160 | performance: 1.0 | accuracy: 0.35 | loss: 0.04
update:400/2000, 耗时:0.00分/0.73分 | step:  3200 | performance: 1.0 | accuracy: 0.35 | loss: 0.46
update:405/2000, 耗时:0.00分/0.74分 | step:  3240 | performance: 1.0 | accuracy: 0.36 | loss: 0.20
update:410/2000, 耗时:0.00分/0.75分 | step:  3280 | performance: 1.0 | accuracy: 0.35 | loss: 0.05
update:415/2000, 耗时:0.00分/0.75分 | step:  3320 | performance: 1.0 | accuracy: 0.35 | loss: 0.13
update:420/2000, 耗时:0.00分/0.76分 | step:  3360 | performance: 1.0 | accuracy: 0.35 | loss: -0.01
update:425/2000, 耗时:0.00分/0.77分 | step:  3400 | performance: 1.1 | accuracy: 0.35 | loss: 0.00
update:430/2000, 耗时:0.00分/0.78分 | step:  3440 | performance: 1.1 | accuracy: 0.36 | loss: 0.41
update:435/2000, 耗时:0.00分/0.78分 | step:  3480 | performance: 1.0 | accuracy: 0.35 | loss: 0.86
update:440/2000, 耗时:0.00分/0.79分 | step:  3520 | performance: 1.0 | accuracy: 0.36 | loss: 0.76
update:445/2000, 耗时:0.00分/0.80分 | step:  3560 | performance: 1.0 | accuracy: 0.36 | loss: 0.29
update:450/2000, 耗时:0.00分/0.81分 | step:  3600 | performance: 1.0 | accuracy: 0.36 | loss: 0.60
update:455/2000, 耗时:0.00分/0.81分 | step:  3640 | performance: 1.1 | accuracy: 0.36 | loss: 0.43
update:460/2000, 耗时:0.00分/0.82分 | step:  3680 | performance: 1.1 | accuracy: 0.36 | loss: 0.14
update:465/2000, 耗时:0.00分/0.83分 | step:  3720 | performance: 1.2 | accuracy: 0.36 | loss: 0.32
update:470/2000, 耗时:0.00分/0.84分 | step:  3760 | performance: 1.2 | accuracy: 0.36 | loss: 0.42
update:475/2000, 耗时:0.00分/0.84分 | step:  3800 | performance: 1.2 | accuracy: 0.36 | loss: 0.21
update:480/2000, 耗时:0.00分/0.85分 | step:  3840 | performance: 1.3 | accuracy: 0.36 | loss: 0.45
update:485/2000, 耗时:0.00分/0.86分 | step:  3880 | performance: 1.2 | accuracy: 0.36 | loss: 0.29
update:490/2000, 耗时:0.00分/0.87分 | step:  3920 | performance: 1.2 | accuracy: 0.36 | loss: 0.48
update:495/2000, 耗时:0.00分/0.87分 | step:  3960 | performance: 1.2 | accuracy: 0.36 | loss: 0.38
update:500/2000, 耗时:0.00分/0.88分 | step:  4000 | performance: 1.2 | accuracy: 0.36 | loss: 0.25
update:505/2000, 耗时:0.00分/0.89分 | step:  4040 | performance: 1.3 | accuracy: 0.36 | loss: 0.23
update:510/2000, 耗时:0.00分/0.89分 | step:  4080 | performance: 1.3 | accuracy: 0.37 | loss: 0.42
update:515/2000, 耗时:0.00分/0.90分 | step:  4120 | performance: 1.3 | accuracy: 0.37 | loss: 0.15
update:520/2000, 耗时:0.00分/0.91分 | step:  4160 | performance: 1.3 | accuracy: 0.36 | loss: 0.13
update:525/2000, 耗时:0.00分/0.92分 | step:  4200 | performance: 1.3 | accuracy: 0.36 | loss: 0.56
update:530/2000, 耗时:0.00分/0.92分 | step:  4240 | performance: 1.2 | accuracy: 0.36 | loss: 0.57
update:535/2000, 耗时:0.00分/0.94分 | step:  4280 | performance: 1.2 | accuracy: 0.36 | loss: 0.54
update:540/2000, 耗时:0.00分/0.94分 | step:  4320 | performance: 1.3 | accuracy: 0.36 | loss: 0.31
update:545/2000, 耗时:0.00分/0.95分 | step:  4360 | performance: 1.3 | accuracy: 0.37 | loss: 0.04
update:550/2000, 耗时:0.00分/0.96分 | step:  4400 | performance: 1.3 | accuracy: 0.36 | loss: 0.18
update:555/2000, 耗时:0.00分/0.97分 | step:  4440 | performance: 1.3 | accuracy: 0.36 | loss: 0.27
update:560/2000, 耗时:0.00分/0.97分 | step:  4480 | performance: 1.3 | accuracy: 0.36 | loss: -0.07
update:565/2000, 耗时:0.00分/0.98分 | step:  4520 | performance: 1.2 | accuracy: 0.36 | loss: 0.38
update:570/2000, 耗时:0.00分/0.99分 | step:  4560 | performance: 1.2 | accuracy: 0.36 | loss: 0.29
update:575/2000, 耗时:0.00分/1.00分 | step:  4600 | performance: 1.2 | accuracy: 0.35 | loss: 0.23
update:580/2000, 耗时:0.00分/1.00分 | step:  4640 | performance: 1.2 | accuracy: 0.36 | loss: 0.16
update:585/2000, 耗时:0.00分/1.01分 | step:  4680 | performance: 1.2 | accuracy: 0.36 | loss: 0.05
update:590/2000, 耗时:0.00分/1.02分 | step:  4720 | performance: 1.2 | accuracy: 0.36 | loss: 0.16
update:595/2000, 耗时:0.00分/1.03分 | step:  4760 | performance: 1.2 | accuracy: 0.36 | loss: 0.30
update:600/2000, 耗时:0.00分/1.03分 | step:  4800 | performance: 1.2 | accuracy: 0.36 | loss: 0.27
update:605/2000, 耗时:0.00分/1.04分 | step:  4840 | performance: 1.2 | accuracy: 0.35 | loss: 0.36
update:610/2000, 耗时:0.00分/1.05分 | step:  4880 | performance: 1.2 | accuracy: 0.36 | loss: 0.43
update:615/2000, 耗时:0.00分/1.06分 | step:  4920 | performance: 1.2 | accuracy: 0.36 | loss: 0.09
update:620/2000, 耗时:0.00分/1.06分 | step:  4960 | performance: 1.2 | accuracy: 0.35 | loss: 0.42
update:625/2000, 耗时:0.00分/1.07分 | step:  5000 | performance: 1.2 | accuracy: 0.36 | loss: 0.28
update:630/2000, 耗时:0.00分/1.08分 | step:  5040 | performance: 1.2 | accuracy: 0.36 | loss: 0.19
update:635/2000, 耗时:0.00分/1.08分 | step:  5080 | performance: 1.2 | accuracy: 0.35 | loss: 0.10
update:640/2000, 耗时:0.00分/1.09分 | step:  5120 | performance: 1.2 | accuracy: 0.35 | loss: 0.17
update:645/2000, 耗时:0.00分/1.10分 | step:  5160 | performance: 1.2 | accuracy: 0.35 | loss: 0.36
update:650/2000, 耗时:0.00分/1.11分 | step:  5200 | performance: 1.2 | accuracy: 0.35 | loss: 0.11
update:655/2000, 耗时:0.00分/1.11分 | step:  5240 | performance: 1.2 | accuracy: 0.35 | loss: 0.33
update:660/2000, 耗时:0.00分/1.12分 | step:  5280 | performance: 1.2 | accuracy: 0.35 | loss: 0.36
update:665/2000, 耗时:0.00分/1.13分 | step:  5320 | performance: 1.2 | accuracy: 0.35 | loss: 0.55
update:670/2000, 耗时:0.00分/1.14分 | step:  5360 | performance: 1.2 | accuracy: 0.35 | loss: 0.27
update:675/2000, 耗时:0.00分/1.14分 | step:  5400 | performance: 1.1 | accuracy: 0.35 | loss: 0.55
update:680/2000, 耗时:0.00分/1.15分 | step:  5440 | performance: 1.1 | accuracy: 0.35 | loss: 0.25
update:685/2000, 耗时:0.00分/1.16分 | step:  5480 | performance: 1.0 | accuracy: 0.35 | loss: 0.38
update:690/2000, 耗时:0.00分/1.17分 | step:  5520 | performance: 1.0 | accuracy: 0.34 | loss: 0.40
update:695/2000, 耗时:0.00分/1.17分 | step:  5560 | performance: 1.0 | accuracy: 0.35 | loss: 0.45
update:700/2000, 耗时:0.00分/1.18分 | step:  5600 | performance: 1.0 | accuracy: 0.35 | loss: 0.46
update:705/2000, 耗时:0.00分/1.19分 | step:  5640 | performance: 1.0 | accuracy: 0.35 | loss: 0.60
update:710/2000, 耗时:0.00分/1.19分 | step:  5680 | performance: 1.0 | accuracy: 0.35 | loss: 0.01
update:715/2000, 耗时:0.00分/1.20分 | step:  5720 | performance: 1.1 | accuracy: 0.35 | loss: 0.39
update:720/2000, 耗时:0.00分/1.21分 | step:  5760 | performance: 1.1 | accuracy: 0.35 | loss: 0.46
update:725/2000, 耗时:0.00分/1.22分 | step:  5800 | performance: 1.1 | accuracy: 0.35 | loss: 0.33
update:730/2000, 耗时:0.00分/1.22分 | step:  5840 | performance: 1.0 | accuracy: 0.35 | loss: 0.47
update:735/2000, 耗时:0.00分/1.23分 | step:  5880 | performance: 0.9 | accuracy: 0.35 | loss: 0.53
update:740/2000, 耗时:0.00分/1.24分 | step:  5920 | performance: 1.0 | accuracy: 0.35 | loss: 0.48
update:745/2000, 耗时:0.00分/1.25分 | step:  5960 | performance: 1.0 | accuracy: 0.35 | loss: 0.50
update:750/2000, 耗时:0.00分/1.25分 | step:  6000 | performance: 1.1 | accuracy: 0.35 | loss: 0.65
update:755/2000, 耗时:0.00分/1.26分 | step:  6040 | performance: 1.1 | accuracy: 0.35 | loss: 0.60
update:760/2000, 耗时:0.00分/1.27分 | step:  6080 | performance: 1.0 | accuracy: 0.36 | loss: 0.49
update:765/2000, 耗时:0.00分/1.28分 | step:  6120 | performance: 1.0 | accuracy: 0.35 | loss: 0.27
update:770/2000, 耗时:0.00分/1.28分 | step:  6160 | performance: 1.1 | accuracy: 0.35 | loss: 0.06
update:775/2000, 耗时:0.00分/1.29分 | step:  6200 | performance: 1.2 | accuracy: 0.35 | loss: 0.70
update:780/2000, 耗时:0.00分/1.30分 | step:  6240 | performance: 1.1 | accuracy: 0.36 | loss: 0.19
update:785/2000, 耗时:0.00分/1.31分 | step:  6280 | performance: 1.2 | accuracy: 0.36 | loss: 0.20
update:790/2000, 耗时:0.00分/1.31分 | step:  6320 | performance: 1.2 | accuracy: 0.35 | loss: 0.20
update:795/2000, 耗时:0.00分/1.32分 | step:  6360 | performance: 1.2 | accuracy: 0.36 | loss: 0.42
update:800/2000, 耗时:0.00分/1.33分 | step:  6400 | performance: 1.2 | accuracy: 0.35 | loss: 0.25
update:805/2000, 耗时:0.00分/1.34分 | step:  6440 | performance: 1.2 | accuracy: 0.35 | loss: 0.12
update:810/2000, 耗时:0.00分/1.34分 | step:  6480 | performance: 1.2 | accuracy: 0.35 | loss: 0.38
update:815/2000, 耗时:0.00分/1.35分 | step:  6520 | performance: 1.3 | accuracy: 0.35 | loss: 0.20
update:820/2000, 耗时:0.00分/1.36分 | step:  6560 | performance: 1.3 | accuracy: 0.35 | loss: 0.29
update:825/2000, 耗时:0.00分/1.37分 | step:  6600 | performance: 1.3 | accuracy: 0.35 | loss: 0.11
update:830/2000, 耗时:0.00分/1.37分 | step:  6640 | performance: 1.3 | accuracy: 0.35 | loss: 0.17
update:835/2000, 耗时:0.00分/1.38分 | step:  6680 | performance: 1.2 | accuracy: 0.35 | loss: 0.34
update:840/2000, 耗时:0.00分/1.39分 | step:  6720 | performance: 1.2 | accuracy: 0.35 | loss: 0.15
update:845/2000, 耗时:0.00分/1.40分 | step:  6760 | performance: 1.2 | accuracy: 0.35 | loss: -0.01
update:850/2000, 耗时:0.00分/1.40分 | step:  6800 | performance: 1.2 | accuracy: 0.35 | loss: 0.24
update:855/2000, 耗时:0.00分/1.41分 | step:  6840 | performance: 1.1 | accuracy: 0.35 | loss: 0.17
update:860/2000, 耗时:0.00分/1.42分 | step:  6880 | performance: 1.2 | accuracy: 0.35 | loss: 0.21
update:865/2000, 耗时:0.00分/1.43分 | step:  6920 | performance: 1.2 | accuracy: 0.35 | loss: 0.25
update:870/2000, 耗时:0.00分/1.43分 | step:  6960 | performance: 1.2 | accuracy: 0.35 | loss: 0.26
update:875/2000, 耗时:0.00分/1.44分 | step:  7000 | performance: 1.2 | accuracy: 0.35 | loss: 0.39
update:880/2000, 耗时:0.00分/1.45分 | step:  7040 | performance: 1.2 | accuracy: 0.35 | loss: 0.43
update:885/2000, 耗时:0.00分/1.46分 | step:  7080 | performance: 1.2 | accuracy: 0.35 | loss: 0.35
update:890/2000, 耗时:0.00分/1.47分 | step:  7120 | performance: 1.2 | accuracy: 0.35 | loss: 0.28
update:895/2000, 耗时:0.00分/1.48分 | step:  7160 | performance: 1.2 | accuracy: 0.35 | loss: 0.20
update:900/2000, 耗时:0.00分/1.49分 | step:  7200 | performance: 1.2 | accuracy: 0.35 | loss: 0.28
update:905/2000, 耗时:0.00分/1.49分 | step:  7240 | performance: 1.2 | accuracy: 0.35 | loss: 0.35
update:910/2000, 耗时:0.00分/1.50分 | step:  7280 | performance: 1.2 | accuracy: 0.35 | loss: 0.16
update:915/2000, 耗时:0.00分/1.51分 | step:  7320 | performance: 1.2 | accuracy: 0.35 | loss: 0.30
update:920/2000, 耗时:0.00分/1.52分 | step:  7360 | performance: 1.2 | accuracy: 0.35 | loss: 0.20
update:925/2000, 耗时:0.00分/1.52分 | step:  7400 | performance: 1.2 | accuracy: 0.35 | loss: 0.18
update:930/2000, 耗时:0.00分/1.53分 | step:  7440 | performance: 1.2 | accuracy: 0.35 | loss: 0.12
update:935/2000, 耗时:0.00分/1.54分 | step:  7480 | performance: 1.2 | accuracy: 0.35 | loss: 0.42
update:940/2000, 耗时:0.00分/1.55分 | step:  7520 | performance: 1.0 | accuracy: 0.35 | loss: 0.40
update:945/2000, 耗时:0.00分/1.55分 | step:  7560 | performance: 1.0 | accuracy: 0.35 | loss: 0.29
update:950/2000, 耗时:0.00分/1.56分 | step:  7600 | performance: 1.0 | accuracy: 0.35 | loss: 0.02
update:955/2000, 耗时:0.00分/1.57分 | step:  7640 | performance: 1.0 | accuracy: 0.34 | loss: -0.00
update:960/2000, 耗时:0.00分/1.58分 | step:  7680 | performance: 1.0 | accuracy: 0.34 | loss: 0.12
update:965/2000, 耗时:0.00分/1.58分 | step:  7720 | performance: 1.0 | accuracy: 0.34 | loss: 0.03
update:970/2000, 耗时:0.00分/1.59分 | step:  7760 | performance: 1.0 | accuracy: 0.34 | loss: 0.28
update:975/2000, 耗时:0.00分/1.60分 | step:  7800 | performance: 1.0 | accuracy: 0.34 | loss: 0.10
update:980/2000, 耗时:0.00分/1.60分 | step:  7840 | performance: 1.0 | accuracy: 0.34 | loss: 0.13
update:985/2000, 耗时:0.00分/1.61分 | step:  7880 | performance: 1.0 | accuracy: 0.34 | loss: 0.21
update:990/2000, 耗时:0.00分/1.62分 | step:  7920 | performance: 1.0 | accuracy: 0.34 | loss: 0.20
update:995/2000, 耗时:0.00分/1.63分 | step:  7960 | performance: 1.0 | accuracy: 0.34 | loss: 0.36
update:1000/2000, 耗时:0.00分/1.63分 | step:  8000 | performance: 1.0 | accuracy: 0.34 | loss: 0.05
update:1005/2000, 耗时:0.00分/1.64分 | step:  8040 | performance: 0.9 | accuracy: 0.33 | loss: 0.18
update:1010/2000, 耗时:0.00分/1.65分 | step:  8080 | performance: 0.9 | accuracy: 0.33 | loss: 0.22
update:1015/2000, 耗时:0.00分/1.65分 | step:  8120 | performance: 0.9 | accuracy: 0.33 | loss: -0.01
update:1020/2000, 耗时:0.00分/1.66分 | step:  8160 | performance: 0.9 | accuracy: 0.33 | loss: 0.01
update:1025/2000, 耗时:0.00分/1.67分 | step:  8200 | performance: 0.9 | accuracy: 0.33 | loss: 0.28
update:1030/2000, 耗时:0.00分/1.67分 | step:  8240 | performance: 1.0 | accuracy: 0.33 | loss: 0.57
update:1035/2000, 耗时:0.00分/1.68分 | step:  8280 | performance: 0.9 | accuracy: 0.33 | loss: 0.52
update:1040/2000, 耗时:0.00分/1.69分 | step:  8320 | performance: 0.9 | accuracy: 0.33 | loss: 0.04
update:1045/2000, 耗时:0.00分/1.70分 | step:  8360 | performance: 0.9 | accuracy: 0.33 | loss: 0.20
update:1050/2000, 耗时:0.00分/1.70分 | step:  8400 | performance: 0.9 | accuracy: 0.33 | loss: 0.49
update:1055/2000, 耗时:0.00分/1.71分 | step:  8440 | performance: 0.9 | accuracy: 0.33 | loss: 0.05
update:1060/2000, 耗时:0.00分/1.72分 | step:  8480 | performance: 0.9 | accuracy: 0.33 | loss: 0.17
update:1065/2000, 耗时:0.00分/1.72分 | step:  8520 | performance: 0.9 | accuracy: 0.33 | loss: 0.15
update:1070/2000, 耗时:0.00分/1.73分 | step:  8560 | performance: 0.9 | accuracy: 0.33 | loss: 0.15
update:1075/2000, 耗时:0.00分/1.74分 | step:  8600 | performance: 0.9 | accuracy: 0.32 | loss: 0.14
update:1080/2000, 耗时:0.00分/1.75分 | step:  8640 | performance: 0.9 | accuracy: 0.32 | loss: 0.11
update:1085/2000, 耗时:0.00分/1.75分 | step:  8680 | performance: 0.9 | accuracy: 0.32 | loss: 0.32
update:1090/2000, 耗时:0.00分/1.76分 | step:  8720 | performance: 0.9 | accuracy: 0.32 | loss: 0.41
update:1095/2000, 耗时:0.00分/1.77分 | step:  8760 | performance: 0.9 | accuracy: 0.32 | loss: 0.41
update:1100/2000, 耗时:0.00分/1.77分 | step:  8800 | performance: 0.9 | accuracy: 0.32 | loss: 0.16
update:1105/2000, 耗时:0.00分/1.78分 | step:  8840 | performance: 0.9 | accuracy: 0.32 | loss: 0.15
update:1110/2000, 耗时:0.00分/1.79分 | step:  8880 | performance: 0.9 | accuracy: 0.32 | loss: 0.38
update:1115/2000, 耗时:0.00分/1.79分 | step:  8920 | performance: 0.9 | accuracy: 0.32 | loss: 0.36
update:1120/2000, 耗时:0.00分/1.80分 | step:  8960 | performance: 0.8 | accuracy: 0.32 | loss: 0.97
update:1125/2000, 耗时:0.00分/1.81分 | step:  9000 | performance: 0.8 | accuracy: 0.32 | loss: 0.50
update:1130/2000, 耗时:0.00分/1.82分 | step:  9040 | performance: 0.8 | accuracy: 0.32 | loss: 0.40
update:1135/2000, 耗时:0.00分/1.82分 | step:  9080 | performance: 0.8 | accuracy: 0.32 | loss: 0.20
update:1140/2000, 耗时:0.00分/1.83分 | step:  9120 | performance: 0.8 | accuracy: 0.32 | loss: 0.63
update:1145/2000, 耗时:0.00分/1.84分 | step:  9160 | performance: 0.8 | accuracy: 0.32 | loss: 0.94
update:1150/2000, 耗时:0.00分/1.84分 | step:  9200 | performance: 0.7 | accuracy: 0.33 | loss: 0.71
update:1155/2000, 耗时:0.00分/1.85分 | step:  9240 | performance: 0.7 | accuracy: 0.32 | loss: 0.28
update:1160/2000, 耗时:0.00分/1.86分 | step:  9280 | performance: 0.7 | accuracy: 0.32 | loss: 0.32
update:1165/2000, 耗时:0.00分/1.87分 | step:  9320 | performance: 0.7 | accuracy: 0.32 | loss: 0.09
update:1170/2000, 耗时:0.00分/1.87分 | step:  9360 | performance: 0.7 | accuracy: 0.32 | loss: 0.29
update:1175/2000, 耗时:0.00分/1.88分 | step:  9400 | performance: 0.7 | accuracy: 0.32 | loss: 0.27
update:1180/2000, 耗时:0.00分/1.89分 | step:  9440 | performance: 0.7 | accuracy: 0.32 | loss: 0.36
update:1185/2000, 耗时:0.00分/1.89分 | step:  9480 | performance: 0.7 | accuracy: 0.32 | loss: 0.32
update:1190/2000, 耗时:0.00分/1.90分 | step:  9520 | performance: 0.7 | accuracy: 0.33 | loss: 0.29
update:1195/2000, 耗时:0.00分/1.91分 | step:  9560 | performance: 0.7 | accuracy: 0.33 | loss: 0.34
update:1200/2000, 耗时:0.00分/1.91分 | step:  9600 | performance: 0.7 | accuracy: 0.33 | loss: 0.27
update:1205/2000, 耗时:0.00分/1.92分 | step:  9640 | performance: 0.7 | accuracy: 0.33 | loss: 0.63
update:1210/2000, 耗时:0.00分/1.93分 | step:  9680 | performance: 0.6 | accuracy: 0.33 | loss: 0.36
update:1215/2000, 耗时:0.00分/1.94分 | step:  9720 | performance: 0.6 | accuracy: 0.33 | loss: 0.16
update:1220/2000, 耗时:0.00分/1.94分 | step:  9760 | performance: 0.6 | accuracy: 0.33 | loss: 0.36
update:1225/2000, 耗时:0.00分/1.95分 | step:  9800 | performance: 0.6 | accuracy: 0.33 | loss: 0.36
update:1230/2000, 耗时:0.00分/1.96分 | step:  9840 | performance: 0.6 | accuracy: 0.33 | loss: 0.17
update:1235/2000, 耗时:0.00分/1.96分 | step:  9880 | performance: 0.6 | accuracy: 0.33 | loss: 0.50
update:1240/2000, 耗时:0.00分/1.97分 | step:  9920 | performance: 0.6 | accuracy: 0.33 | loss: 0.25
update:1245/2000, 耗时:0.00分/1.98分 | step:  9960 | performance: 0.6 | accuracy: 0.32 | loss: 0.37
update:1250/2000, 耗时:0.00分/1.99分 | step: 10000 | performance: 0.6 | accuracy: 0.33 | loss: 0.26
update:1255/2000, 耗时:0.00分/1.99分 | step: 10040 | performance: 0.6 | accuracy: 0.33 | loss: 0.10
update:1260/2000, 耗时:0.00分/2.00分 | step: 10080 | performance: 0.6 | accuracy: 0.33 | loss: 0.41
update:1265/2000, 耗时:0.00分/2.01分 | step: 10120 | performance: 0.6 | accuracy: 0.33 | loss: 0.40
update:1270/2000, 耗时:0.00分/2.02分 | step: 10160 | performance: 0.6 | accuracy: 0.33 | loss: 0.35
update:1275/2000, 耗时:0.00分/2.02分 | step: 10200 | performance: 0.6 | accuracy: 0.33 | loss: 0.08
update:1280/2000, 耗时:0.00分/2.03分 | step: 10240 | performance: 0.6 | accuracy: 0.33 | loss: 0.50
update:1285/2000, 耗时:0.00分/2.04分 | step: 10280 | performance: 0.6 | accuracy: 0.32 | loss: 0.24
update:1290/2000, 耗时:0.00分/2.04分 | step: 10320 | performance: 0.5 | accuracy: 0.32 | loss: 0.92
update:1295/2000, 耗时:0.00分/2.05分 | step: 10360 | performance: 0.5 | accuracy: 0.32 | loss: 0.13
update:1300/2000, 耗时:0.00分/2.06分 | step: 10400 | performance: 0.6 | accuracy: 0.32 | loss: 0.19
update:1305/2000, 耗时:0.00分/2.07分 | step: 10440 | performance: 0.5 | accuracy: 0.32 | loss: 0.38
update:1310/2000, 耗时:0.00分/2.07分 | step: 10480 | performance: 0.5 | accuracy: 0.32 | loss: 0.11
update:1315/2000, 耗时:0.00分/2.08分 | step: 10520 | performance: 0.5 | accuracy: 0.32 | loss: 0.19
update:1320/2000, 耗时:0.00分/2.09分 | step: 10560 | performance: 0.5 | accuracy: 0.32 | loss: 0.52
update:1325/2000, 耗时:0.00分/2.10分 | step: 10600 | performance: 0.5 | accuracy: 0.32 | loss: 0.46
update:1330/2000, 耗时:0.00分/2.10分 | step: 10640 | performance: 0.5 | accuracy: 0.32 | loss: 0.29
update:1335/2000, 耗时:0.00分/2.11分 | step: 10680 | performance: 0.5 | accuracy: 0.32 | loss: 0.55
update:1340/2000, 耗时:0.00分/2.12分 | step: 10720 | performance: 0.5 | accuracy: 0.32 | loss: 0.07
update:1345/2000, 耗时:0.00分/2.13分 | step: 10760 | performance: 0.5 | accuracy: 0.32 | loss: 0.17
update:1350/2000, 耗时:0.00分/2.13分 | step: 10800 | performance: 0.5 | accuracy: 0.32 | loss: 0.13
update:1355/2000, 耗时:0.00分/2.14分 | step: 10840 | performance: 0.4 | accuracy: 0.32 | loss: 0.34
update:1360/2000, 耗时:0.00分/2.15分 | step: 10880 | performance: 0.4 | accuracy: 0.32 | loss: 0.50
update:1365/2000, 耗时:0.00分/2.16分 | step: 10920 | performance: 0.5 | accuracy: 0.32 | loss: 0.35
update:1370/2000, 耗时:0.00分/2.16分 | step: 10960 | performance: 0.5 | accuracy: 0.32 | loss: 0.22
update:1375/2000, 耗时:0.00分/2.17分 | step: 11000 | performance: 0.5 | accuracy: 0.33 | loss: 0.13
update:1380/2000, 耗时:0.00分/2.18分 | step: 11040 | performance: 0.5 | accuracy: 0.32 | loss: -0.01
update:1385/2000, 耗时:0.00分/2.18分 | step: 11080 | performance: 0.5 | accuracy: 0.32 | loss: 0.28
update:1390/2000, 耗时:0.00分/2.19分 | step: 11120 | performance: 0.5 | accuracy: 0.33 | loss: 0.43
update:1395/2000, 耗时:0.00分/2.20分 | step: 11160 | performance: 0.5 | accuracy: 0.32 | loss: 0.27
update:1400/2000, 耗时:0.00分/2.20分 | step: 11200 | performance: 0.5 | accuracy: 0.32 | loss: 0.05
update:1405/2000, 耗时:0.00分/2.21分 | step: 11240 | performance: 0.5 | accuracy: 0.32 | loss: 0.15
update:1410/2000, 耗时:0.00分/2.22分 | step: 11280 | performance: 0.5 | accuracy: 0.32 | loss: 0.26
update:1415/2000, 耗时:0.00分/2.23分 | step: 11320 | performance: 0.5 | accuracy: 0.32 | loss: 0.17
update:1420/2000, 耗时:0.00分/2.23分 | step: 11360 | performance: 0.5 | accuracy: 0.32 | loss: 0.35
update:1425/2000, 耗时:0.00分/2.24分 | step: 11400 | performance: 0.4 | accuracy: 0.32 | loss: 0.35
update:1430/2000, 耗时:0.00分/2.25分 | step: 11440 | performance: 0.5 | accuracy: 0.32 | loss: 0.25
update:1435/2000, 耗时:0.00分/2.25分 | step: 11480 | performance: 0.5 | accuracy: 0.32 | loss: 0.15
update:1440/2000, 耗时:0.00分/2.26分 | step: 11520 | performance: 0.5 | accuracy: 0.32 | loss: 0.24
update:1445/2000, 耗时:0.00分/2.27分 | step: 11560 | performance: 0.5 | accuracy: 0.32 | loss: 0.14
update:1450/2000, 耗时:0.00分/2.28分 | step: 11600 | performance: 0.5 | accuracy: 0.32 | loss: 0.04
update:1455/2000, 耗时:0.00分/2.28分 | step: 11640 | performance: 0.5 | accuracy: 0.32 | loss: 0.39
update:1460/2000, 耗时:0.00分/2.29分 | step: 11680 | performance: 0.5 | accuracy: 0.32 | loss: 0.91
update:1465/2000, 耗时:0.00分/2.30分 | step: 11720 | performance: 0.5 | accuracy: 0.32 | loss: 0.31
update:1470/2000, 耗时:0.00分/2.30分 | step: 11760 | performance: 0.5 | accuracy: 0.32 | loss: 0.03
update:1475/2000, 耗时:0.00分/2.31分 | step: 11800 | performance: 0.5 | accuracy: 0.32 | loss: 0.39
update:1480/2000, 耗时:0.00分/2.32分 | step: 11840 | performance: 0.5 | accuracy: 0.32 | loss: 0.16
update:1485/2000, 耗时:0.00分/2.33分 | step: 11880 | performance: 0.5 | accuracy: 0.32 | loss: 0.11
update:1490/2000, 耗时:0.00分/2.33分 | step: 11920 | performance: 0.5 | accuracy: 0.32 | loss: 0.21
update:1495/2000, 耗时:0.00分/2.34分 | step: 11960 | performance: 0.5 | accuracy: 0.32 | loss: 0.13
update:1500/2000, 耗时:0.00分/2.35分 | step: 12000 | performance: 0.5 | accuracy: 0.32 | loss: 0.19
update:1505/2000, 耗时:0.00分/2.35分 | step: 12040 | performance: 0.5 | accuracy: 0.32 | loss: 0.14
update:1510/2000, 耗时:0.00分/2.36分 | step: 12080 | performance: 0.5 | accuracy: 0.32 | loss: 0.23
update:1515/2000, 耗时:0.00分/2.37分 | step: 12120 | performance: 0.5 | accuracy: 0.32 | loss: 0.03
update:1520/2000, 耗时:0.00分/2.38分 | step: 12160 | performance: 0.5 | accuracy: 0.32 | loss: 0.25
update:1525/2000, 耗时:0.00分/2.38分 | step: 12200 | performance: 0.5 | accuracy: 0.32 | loss: 0.44
update:1530/2000, 耗时:0.00分/2.39分 | step: 12240 | performance: 0.5 | accuracy: 0.32 | loss: 0.34
update:1535/2000, 耗时:0.00分/2.40分 | step: 12280 | performance: 0.5 | accuracy: 0.32 | loss: 0.26
update:1540/2000, 耗时:0.00分/2.40分 | step: 12320 | performance: 0.5 | accuracy: 0.32 | loss: 0.30
update:1545/2000, 耗时:0.00分/2.41分 | step: 12360 | performance: 0.5 | accuracy: 0.32 | loss: 0.20
update:1550/2000, 耗时:0.00分/2.42分 | step: 12400 | performance: 0.5 | accuracy: 0.32 | loss: 0.35
update:1555/2000, 耗时:0.00分/2.43分 | step: 12440 | performance: 0.5 | accuracy: 0.32 | loss: 0.26
update:1560/2000, 耗时:0.00分/2.43分 | step: 12480 | performance: 0.5 | accuracy: 0.32 | loss: 0.33
update:1565/2000, 耗时:0.00分/2.44分 | step: 12520 | performance: 0.5 | accuracy: 0.32 | loss: 0.18
update:1570/2000, 耗时:0.00分/2.45分 | step: 12560 | performance: 0.5 | accuracy: 0.32 | loss: 0.28
update:1575/2000, 耗时:0.00分/2.45分 | step: 12600 | performance: 0.5 | accuracy: 0.32 | loss: 0.15
update:1580/2000, 耗时:0.00分/2.46分 | step: 12640 | performance: 0.5 | accuracy: 0.32 | loss: 0.10
update:1585/2000, 耗时:0.00分/2.47分 | step: 12680 | performance: 0.5 | accuracy: 0.32 | loss: 0.03
update:1590/2000, 耗时:0.00分/2.47分 | step: 12720 | performance: 0.5 | accuracy: 0.32 | loss: 0.30
update:1595/2000, 耗时:0.00分/2.48分 | step: 12760 | performance: 0.5 | accuracy: 0.32 | loss: 0.29
update:1600/2000, 耗时:0.00分/2.49分 | step: 12800 | performance: 0.5 | accuracy: 0.32 | loss: 0.30
update:1605/2000, 耗时:0.00分/2.50分 | step: 12840 | performance: 0.5 | accuracy: 0.32 | loss: 0.13
update:1610/2000, 耗时:0.00分/2.50分 | step: 12880 | performance: 0.5 | accuracy: 0.32 | loss: 0.21
update:1615/2000, 耗时:0.00分/2.51分 | step: 12920 | performance: 0.5 | accuracy: 0.32 | loss: 0.12
update:1620/2000, 耗时:0.00分/2.52分 | step: 12960 | performance: 0.6 | accuracy: 0.32 | loss: 0.33
update:1625/2000, 耗时:0.00分/2.53分 | step: 13000 | performance: 0.5 | accuracy: 0.32 | loss: 0.27
update:1630/2000, 耗时:0.00分/2.53分 | step: 13040 | performance: 0.7 | accuracy: 0.32 | loss: 0.68
update:1635/2000, 耗时:0.00分/2.54分 | step: 13080 | performance: 0.7 | accuracy: 0.32 | loss: 1.03
update:1640/2000, 耗时:0.00分/2.55分 | step: 13120 | performance: 0.7 | accuracy: 0.32 | loss: 0.52
update:1645/2000, 耗时:0.00分/2.56分 | step: 13160 | performance: 0.6 | accuracy: 0.32 | loss: 0.71
update:1650/2000, 耗时:0.00分/2.56分 | step: 13200 | performance: 0.7 | accuracy: 0.32 | loss: 0.24
update:1655/2000, 耗时:0.00分/2.57分 | step: 13240 | performance: 0.7 | accuracy: 0.32 | loss: 0.53
update:1660/2000, 耗时:0.00分/2.58分 | step: 13280 | performance: 0.7 | accuracy: 0.32 | loss: 0.71
update:1665/2000, 耗时:0.00分/2.58分 | step: 13320 | performance: 0.7 | accuracy: 0.32 | loss: 0.31
update:1670/2000, 耗时:0.00分/2.59分 | step: 13360 | performance: 0.7 | accuracy: 0.32 | loss: 0.37
update:1675/2000, 耗时:0.00分/2.60分 | step: 13400 | performance: 0.7 | accuracy: 0.32 | loss: 0.15
update:1680/2000, 耗时:0.00分/2.61分 | step: 13440 | performance: 0.7 | accuracy: 0.32 | loss: 0.27
update:1685/2000, 耗时:0.00分/2.61分 | step: 13480 | performance: 0.7 | accuracy: 0.32 | loss: 0.31
update:1690/2000, 耗时:0.00分/2.62分 | step: 13520 | performance: 0.7 | accuracy: 0.32 | loss: 0.39
update:1695/2000, 耗时:0.00分/2.63分 | step: 13560 | performance: 0.7 | accuracy: 0.32 | loss: 0.22
update:1700/2000, 耗时:0.00分/2.63分 | step: 13600 | performance: 0.7 | accuracy: 0.32 | loss: 0.12
update:1705/2000, 耗时:0.00分/2.64分 | step: 13640 | performance: 0.7 | accuracy: 0.32 | loss: 0.47
update:1710/2000, 耗时:0.00分/2.65分 | step: 13680 | performance: 0.7 | accuracy: 0.32 | loss: 0.42
update:1715/2000, 耗时:0.00分/2.65分 | step: 13720 | performance: 0.6 | accuracy: 0.32 | loss: 0.12
update:1720/2000, 耗时:0.00分/2.66分 | step: 13760 | performance: 0.6 | accuracy: 0.32 | loss: 0.21
update:1725/2000, 耗时:0.00分/2.67分 | step: 13800 | performance: 0.6 | accuracy: 0.32 | loss: 0.53
update:1730/2000, 耗时:0.00分/2.67分 | step: 13840 | performance: 0.7 | accuracy: 0.32 | loss: 0.57
update:1735/2000, 耗时:0.00分/2.68分 | step: 13880 | performance: 0.7 | accuracy: 0.32 | loss: 0.62
update:1740/2000, 耗时:0.00分/2.69分 | step: 13920 | performance: 0.7 | accuracy: 0.32 | loss: 0.29
update:1745/2000, 耗时:0.00分/2.69分 | step: 13960 | performance: 0.7 | accuracy: 0.32 | loss: 0.53
update:1750/2000, 耗时:0.00分/2.70分 | step: 14000 | performance: 0.6 | accuracy: 0.32 | loss: 0.32
update:1755/2000, 耗时:0.00分/2.71分 | step: 14040 | performance: 0.6 | accuracy: 0.32 | loss: 0.22
update:1760/2000, 耗时:0.00分/2.72分 | step: 14080 | performance: 0.6 | accuracy: 0.32 | loss: 0.11
update:1765/2000, 耗时:0.00分/2.72分 | step: 14120 | performance: 0.6 | accuracy: 0.32 | loss: 0.09
update:1770/2000, 耗时:0.00分/2.73分 | step: 14160 | performance: 0.6 | accuracy: 0.32 | loss: 0.16
update:1775/2000, 耗时:0.00分/2.74分 | step: 14200 | performance: 0.6 | accuracy: 0.32 | loss: 0.13
update:1780/2000, 耗时:0.00分/2.74分 | step: 14240 | performance: 0.7 | accuracy: 0.32 | loss: 0.19
update:1785/2000, 耗时:0.00分/2.75分 | step: 14280 | performance: 0.7 | accuracy: 0.32 | loss: 0.07
update:1790/2000, 耗时:0.00分/2.76分 | step: 14320 | performance: 0.6 | accuracy: 0.32 | loss: 0.06
update:1795/2000, 耗时:0.00分/2.77分 | step: 14360 | performance: 0.7 | accuracy: 0.32 | loss: 0.29
update:1800/2000, 耗时:0.00分/2.77分 | step: 14400 | performance: 0.7 | accuracy: 0.32 | loss: 0.09
update:1805/2000, 耗时:0.00分/2.78分 | step: 14440 | performance: 0.7 | accuracy: 0.32 | loss: 0.30
update:1810/2000, 耗时:0.00分/2.79分 | step: 14480 | performance: 0.7 | accuracy: 0.32 | loss: 0.14
update:1815/2000, 耗时:0.00分/2.79分 | step: 14520 | performance: 0.7 | accuracy: 0.32 | loss: 0.19
update:1820/2000, 耗时:0.00分/2.80分 | step: 14560 | performance: 0.7 | accuracy: 0.31 | loss: 0.13
update:1825/2000, 耗时:0.00分/2.81分 | step: 14600 | performance: 0.7 | accuracy: 0.31 | loss: 0.13
update:1830/2000, 耗时:0.00分/2.81分 | step: 14640 | performance: 0.7 | accuracy: 0.31 | loss: 0.27
update:1835/2000, 耗时:0.00分/2.82分 | step: 14680 | performance: 0.7 | accuracy: 0.31 | loss: 0.13
update:1840/2000, 耗时:0.00分/2.83分 | step: 14720 | performance: 0.7 | accuracy: 0.31 | loss: 0.23
update:1845/2000, 耗时:0.00分/2.84分 | step: 14760 | performance: 0.7 | accuracy: 0.31 | loss: 0.13
update:1850/2000, 耗时:0.00分/2.84分 | step: 14800 | performance: 0.7 | accuracy: 0.31 | loss: 0.19
update:1855/2000, 耗时:0.00分/2.85分 | step: 14840 | performance: 0.7 | accuracy: 0.31 | loss: 0.07
update:1860/2000, 耗时:0.00分/2.86分 | step: 14880 | performance: 0.7 | accuracy: 0.31 | loss: 0.31
update:1865/2000, 耗时:0.00分/2.86分 | step: 14920 | performance: 0.7 | accuracy: 0.31 | loss: 0.31
update:1870/2000, 耗时:0.00分/2.87分 | step: 14960 | performance: 0.7 | accuracy: 0.31 | loss: 0.36
update:1875/2000, 耗时:0.00分/2.88分 | step: 15000 | performance: 0.7 | accuracy: 0.31 | loss: 0.16
update:1880/2000, 耗时:0.00分/2.89分 | step: 15040 | performance: 0.7 | accuracy: 0.31 | loss: 0.05
update:1885/2000, 耗时:0.00分/2.89分 | step: 15080 | performance: 0.7 | accuracy: 0.31 | loss: 0.27
update:1890/2000, 耗时:0.00分/2.90分 | step: 15120 | performance: 0.7 | accuracy: 0.31 | loss: -0.01
update:1895/2000, 耗时:0.00分/2.91分 | step: 15160 | performance: 0.7 | accuracy: 0.31 | loss: 0.06
update:1900/2000, 耗时:0.00分/2.91分 | step: 15200 | performance: 0.7 | accuracy: 0.31 | loss: 0.18
update:1905/2000, 耗时:0.00分/2.92分 | step: 15240 | performance: 0.7 | accuracy: 0.31 | loss: 0.10
update:1910/2000, 耗时:0.00分/2.93分 | step: 15280 | performance: 0.7 | accuracy: 0.31 | loss: 0.17
update:1915/2000, 耗时:0.00分/2.94分 | step: 15320 | performance: 0.7 | accuracy: 0.31 | loss: 0.32
update:1920/2000, 耗时:0.00分/2.94分 | step: 15360 | performance: 0.7 | accuracy: 0.31 | loss: 0.07
update:1925/2000, 耗时:0.00分/2.95分 | step: 15400 | performance: 0.7 | accuracy: 0.31 | loss: 0.16
update:1930/2000, 耗时:0.00分/2.95分 | step: 15440 | performance: 0.7 | accuracy: 0.31 | loss: 0.34
update:1935/2000, 耗时:0.00分/2.96分 | step: 15480 | performance: 0.7 | accuracy: 0.31 | loss: 0.11
update:1940/2000, 耗时:0.00分/2.97分 | step: 15520 | performance: 0.7 | accuracy: 0.31 | loss: 0.15
update:1945/2000, 耗时:0.00分/2.97分 | step: 15560 | performance: 0.7 | accuracy: 0.31 | loss: 0.22
update:1950/2000, 耗时:0.00分/2.98分 | step: 15600 | performance: 0.7 | accuracy: 0.31 | loss: -0.01
update:1955/2000, 耗时:0.00分/2.99分 | step: 15640 | performance: 0.7 | accuracy: 0.31 | loss: 0.33
update:1960/2000, 耗时:0.00分/2.99分 | step: 15680 | performance: 0.7 | accuracy: 0.31 | loss: 0.09
update:1965/2000, 耗时:0.00分/3.00分 | step: 15720 | performance: 0.7 | accuracy: 0.31 | loss: 0.16
update:1970/2000, 耗时:0.00分/3.01分 | step: 15760 | performance: 0.7 | accuracy: 0.31 | loss: 0.43
update:1975/2000, 耗时:0.00分/3.01分 | step: 15800 | performance: 0.7 | accuracy: 0.31 | loss: 0.38
update:1980/2000, 耗时:0.00分/3.02分 | step: 15840 | performance: 0.8 | accuracy: 0.31 | loss: 0.51
update:1985/2000, 耗时:0.00分/3.03分 | step: 15880 | performance: 0.8 | accuracy: 0.31 | loss: 0.46
update:1990/2000, 耗时:0.00分/3.03分 | step: 15920 | performance: 0.8 | accuracy: 0.31 | loss: 0.64
update:1995/2000, 耗时:0.00分/3.04分 | step: 15960 | performance: 0.8 | accuracy: 0.31 | loss: 0.32
update:2000/2000, 耗时:0.00分/3.05分 | step: 16000 | performance: 0.8 | accuracy: 0.31 | loss: 0.21
----------------------------------------finished----------------------------------------
  0%|          | 0/408 [00:00<?, ?it/s]==================================================
100%|| 408/408 [00:00<00:00, 40797.12it/s]
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1085.87
2023-07-24T12:00:00 | net performance [%] = 8.5870
2023-07-24T12:00:00 | number of trades [#] = 152
==================================================
Trial 1 Complete [00h 03m 32s]
net_wealth: 1086.9573977817645

Best net_wealth So Far: 1086.9573977817645
Total elapsed time: 00h 03m 32s

Search: Running Trial #2

Value             |Best Value So Far |Hyperparameter
6                 |1                 |horizon
365               |225               |lookback
False             |False             |MarketFactor
8                 |3                 |lags
0.8               |0.5               |gamma
16                |16                |batch_size
5                 |1                 |n_step
0.96              |0.8               |gae_lambda
1                 |0.1               |gradient_clip_norm
3                 |3                 |epochs
0.001             |0.001             |actor_lr
0.0005            |0.001             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4309.000000   4315.000000
mean      0.000441    20062.255222  ...   20140.547965  20118.633889
std       0.027818    16039.874230  ...   16077.550480  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7699.189941   7690.540039
50%       0.000642    11554.824463  ...   11743.940430  11715.610352
75%       0.011655    29873.081836  ...   29950.949219  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
202023-23-07-27 22:06:22505.023-02686296:0223-7 3--072-07 2272I7- 20222:3: 06:5506.:55-t2076 .e6ns82o268r6296:f low2960/c:7: I 7--te2n7s206: Ioor272 e/p5r ftensolr:52f2.:6o0l8a6t303l1o:wfw6/c:o5r5 .mo//6cpu6cr_efe/pl:8565a30Ior .e56:8 /ptlI6u3r62a:tfeo_ t rgmeI/tenatcnusafro stepdoonrsfr.rofml/occr:u_cfpf14lu_l2w]/efao corwTeatuet/uhor/erewpli_sgc_a/tfcouoroerm/arguraec/ppdr.dccu/.lca_ fT:tfec142] n:p1lT2h4atisorm2f]os ea oThrFTlen/2rm/c0isp u_c0stfe23-T2urpeu_oernso3rgF-aFo0u_7fl-wtu2lreo ab7oew wbi 0a 2n2a_bgry: uini7a-iatrrrdd2.n0c7urecy.6a ry ic:25_:g12s: 0ocpti u64::1is5a25m54iz2ed] w.] .Thissr6i th   8opt oTpto6neAdh.i8is6miPci 6ITc Te7enszendsormFolD72o:w1 4i2 eep7r7F4lbo:wzw i thI]eb: on Idi na itne e ANTe uryh iiwsiaPsI otr reatDhny sln Neioeep tw ss oo oneptpitNieAuPmIrTfenrlaiozolwserf lDmoorFliowz e rbNedd/k ewi  tLwientw/cpa richo oNreerywiorboe tihrkune a/ pL/orsa oAipbllpPtniaetAfPr alI aDterey oI(rN etwmrfDormyomrk/cipzue_df e ep Np/ cpuoenwiLeNaeururi b(roaatrhneeDy lon NNaNtleAet)w otDoNN rP IuuNre tDees eewo)rk  Lt(h et _foon_egfDop ilblko wi rNaLnNgN CPiue)s eurUt oaeybtuurra rare(_y ounieDNn sae tthh N(e) srtf otognuarldlooewer du.iDnN cftuiNono.ccc:s) l l1gi nCo4wtion gc2:]sue 142 l]  tThCP  perfsPU iee  tfohhUeormT h ifinsstr aNnlcelTioln-screuecttwoliitotwriuoinosnnrccs sg CatliTw kP Ueion L iing  iorpFeCoPnnplrU sisenasti noswtrtrboorFlrifnn pse:u cur ow tbiofbincanrrmatr yAoiro y annis(rViosn soaromneX  aDnNcye -cin  ApcreNien rii-tcpfepotrimcVrX2sa noipraclfot)
 Toe -ocrpiitt itmeerncoiaitirz aublmmesd ew tiecizain athle oeodntscpaerha toineAPoIn sDhel:e ep:-cr iAV XN   meuratiwcia  lAotpleh  eiornVe Xn a A  ANVeXtowotAPVI troip2efrkaXoD
eTtnis:heepor   AoVnso  Ne oX:enuab Lli rlae l ow2A
btrahelVTrAim  yo enpeirnnVXX2 
Aa a( oogNbetntV XTCoPeUt2wlh iinosntrs,ee 
uT oDrt he  ecoepmorrNkNentnion  ainble rL so tihne )e attoi oriabbunptrhase eerm b so,p erreabtuitlfnuilod  royh Tee eirimont (ltsnshoranc,eonFefedr T lDoNe-hcel ropmorwliotwinge ri Ni)n  ewbiutCh itlhdectnos orFP au laUptTenoso s ainlsirown sterucwi, ot hoep t Fterreabthielrofnost:u i lidoh olplr AoVwo  TXen AwotshVpirtheX 2inwsianpg C P
paropUe iTpo reinaatber c taet ocniloetsntruocmtiioon ptilreFl hnehm osr, ei pan msf p perlfagsrieiwo tw.ilbthnoprrmo pehaenrc p
ue-eilrroi fcopthrei tiaerattirrmance-crons,icead  cotpproTicala lpen m flpsi oarilate rFlogpesrroepe.obuierwa twc frlai
ioonagss.
mlpth the:d  ilt apiTensoeprorons rFApriate compiler fVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
 flags.
:  AVX AVX2
Tlow with the appropriate compiler flags.
o elags.
nable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-27 22:06:56.369890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:06:56.381635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:06:56.410407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:06:56.414337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:06:56.415713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:06:56.427534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:06:56.442650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:06:56.453332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
Saving PPO weights in both H5 format and checkpoint @ update:4 
update:  5/2000, 耗时:0.00分/0.03分 | step:   200 | performance: 0.6 | accuracy: 0.32 | loss: 2.01
update: 10/2000, 耗时:0.00分/0.04分 | step:   400 | performance: 0.8 | accuracy: 0.38 | loss: 1.05
update: 15/2000, 耗时:0.00分/0.05分 | step:   600 | performance: 1.0 | accuracy: 0.40 | loss: 2.20
update: 20/2000, 耗时:0.00分/0.06分 | step:   800 | performance: 0.3 | accuracy: 0.35 | loss: 3.33
update: 25/2000, 耗时:0.00分/0.07分 | step:  1000 | performance: 0.3 | accuracy: 0.34 | loss: 0.77
update: 30/2000, 耗时:0.00分/0.08分 | step:  1200 | performance: 0.3 | accuracy: 0.34 | loss: 1.65
update: 35/2000, 耗时:0.00分/0.09分 | step:  1400 | performance: 0.5 | accuracy: 0.38 | loss: 1.16
update: 40/2000, 耗时:0.00分/0.10分 | step:  1600 | performance: 0.6 | accuracy: 0.38 | loss: 3.86
update: 45/2000, 耗时:0.00分/0.11分 | step:  1800 | performance: 1.3 | accuracy: 0.41 | loss: 4.65
update: 50/2000, 耗时:0.00分/0.11分 | step:  2000 | performance: 1.0 | accuracy: 0.40 | loss: 0.47
update: 55/2000, 耗时:0.00分/0.12分 | step:  2200 | performance: 0.7 | accuracy: 0.40 | loss: 5.32
update: 60/2000, 耗时:0.00分/0.13分 | step:  2400 | performance: 0.3 | accuracy: 0.38 | loss: 0.79
update: 65/2000, 耗时:0.00分/0.14分 | step:  2600 | performance: 0.7 | accuracy: 0.40 | loss: 0.59
update: 70/2000, 耗时:0.00分/0.15分 | step:  2800 | performance: 0.7 | accuracy: 0.40 | loss: 3.18
update: 75/2000, 耗时:0.00分/0.16分 | step:  3000 | performance: 0.6 | accuracy: 0.39 | loss: 6.61
update: 80/2000, 耗时:0.00分/0.17分 | step:  3200 | performance: 0.9 | accuracy: 0.41 | loss: 3.65
update: 85/2000, 耗时:0.00分/0.18分 | step:  3400 | performance: 0.7 | accuracy: 0.41 | loss: 2.31
update: 90/2000, 耗时:0.00分/0.19分 | step:  3600 | performance: 0.9 | accuracy: 0.41 | loss: 1.04
update: 95/2000, 耗时:0.00分/0.20分 | step:  3800 | performance: 0.6 | accuracy: 0.41 | loss: 0.91
update:100/2000, 耗时:0.00分/0.21分 | step:  4000 | performance: 0.7 | accuracy: 0.41 | loss: 3.04
update:105/2000, 耗时:0.00分/0.22分 | step:  4200 | performance: 3.7 | accuracy: 0.43 | loss: 9.15
update:110/2000, 耗时:0.00分/0.23分 | step:  4400 | performance: 11.3 | accuracy: 0.44 | loss: 1.13
update:115/2000, 耗时:0.00分/0.24分 | step:  4600 | performance: 46.6 | accuracy: 0.46 | loss: 1.67
update:120/2000, 耗时:0.00分/0.25分 | step:  4800 | performance: 21.7 | accuracy: 0.46 | loss: 2.63
update:125/2000, 耗时:0.00分/0.26分 | step:  5000 | performance: 15.5 | accuracy: 0.45 | loss: 1.11
update:130/2000, 耗时:0.00分/0.28分 | step:  5200 | performance: 29.5 | accuracy: 0.46 | loss: 3.77
update:135/2000, 耗时:0.00分/0.29分 | step:  5400 | performance: 34.9 | accuracy: 0.46 | loss: 1.30
update:140/2000, 耗时:0.00分/0.30分 | step:  5600 | performance: 28.3 | accuracy: 0.46 | loss: 0.87
update:145/2000, 耗时:0.00分/0.31分 | step:  5800 | performance: 20.4 | accuracy: 0.46 | loss: 0.87
update:150/2000, 耗时:0.00分/0.32分 | step:  6000 | performance: 19.2 | accuracy: 0.45 | loss: 2.81
update:155/2000, 耗时:0.00分/0.33分 | step:  6200 | performance: 16.9 | accuracy: 0.45 | loss: 1.23
update:160/2000, 耗时:0.00分/0.34分 | step:  6400 | performance: 4.1 | accuracy: 0.44 | loss: 1.81
update:165/2000, 耗时:0.00分/0.35分 | step:  6600 | performance: 3.1 | accuracy: 0.43 | loss: 1.84
update:170/2000, 耗时:0.00分/0.36分 | step:  6800 | performance: 3.2 | accuracy: 0.43 | loss: 0.61
update:175/2000, 耗时:0.00分/0.37分 | step:  7000 | performance: 18.5 | accuracy: 0.44 | loss: 4.69
update:180/2000, 耗时:0.00分/0.38分 | step:  7200 | performance: 29.9 | accuracy: 0.44 | loss: 2.55
update:185/2000, 耗时:0.00分/0.39分 | step:  7400 | performance: 21.2 | accuracy: 0.44 | loss: 0.93
update:190/2000, 耗时:0.00分/0.40分 | step:  7600 | performance: 63.1 | accuracy: 0.45 | loss: 0.74
update:195/2000, 耗时:0.00分/0.41分 | step:  7800 | performance: 148.7 | accuracy: 0.46 | loss: 3.98
update:200/2000, 耗时:0.00分/0.42分 | step:  8000 | performance: 99.1 | accuracy: 0.46 | loss: 11.21
update:205/2000, 耗时:0.00分/0.43分 | step:  8200 | performance: 60.4 | accuracy: 0.45 | loss: 4.53
update:210/2000, 耗时:0.00分/0.44分 | step:  8400 | performance: 196.0 | accuracy: 0.46 | loss: 2.07
update:215/2000, 耗时:0.00分/0.45分 | step:  8600 | performance: 85.0 | accuracy: 0.45 | loss: 7.48
update:220/2000, 耗时:0.00分/0.46分 | step:  8800 | performance: 90.6 | accuracy: 0.46 | loss: 3.12
update:225/2000, 耗时:0.00分/0.47分 | step:  9000 | performance: 84.5 | accuracy: 0.45 | loss: 2.54
update:230/2000, 耗时:0.00分/0.48分 | step:  9200 | performance: 73.3 | accuracy: 0.45 | loss: 1.90
update:235/2000, 耗时:0.00分/0.49分 | step:  9400 | performance: 53.4 | accuracy: 0.45 | loss: 2.88
update:240/2000, 耗时:0.00分/0.50分 | step:  9600 | performance: 89.8 | accuracy: 0.45 | loss: 2.41
update:245/2000, 耗时:0.00分/0.52分 | step:  9800 | performance: 33.5 | accuracy: 0.45 | loss: 1.70
update:250/2000, 耗时:0.00分/0.53分 | step: 10000 | performance: 50.3 | accuracy: 0.46 | loss: 3.23
update:255/2000, 耗时:0.00分/0.54分 | step: 10200 | performance: 102.1 | accuracy: 0.46 | loss: 2.64
update:260/2000, 耗时:0.00分/0.55分 | step: 10400 | performance: 134.9 | accuracy: 0.47 | loss: 1.90
update:265/2000, 耗时:0.00分/0.56分 | step: 10600 | performance: 133.7 | accuracy: 0.47 | loss: 1.52
update:270/2000, 耗时:0.00分/0.57分 | step: 10800 | performance: 97.6 | accuracy: 0.47 | loss: 4.32
update:275/2000, 耗时:0.00分/0.58分 | step: 11000 | performance: 44.7 | accuracy: 0.46 | loss: 1.93
update:280/2000, 耗时:0.00分/0.59分 | step: 11200 | performance: 31.0 | accuracy: 0.46 | loss: 1.44
update:285/2000, 耗时:0.00分/0.60分 | step: 11400 | performance: 18.5 | accuracy: 0.46 | loss: 3.43
update:290/2000, 耗时:0.00分/0.61分 | step: 11600 | performance: 33.7 | accuracy: 0.46 | loss: 2.51
update:295/2000, 耗时:0.00分/0.62分 | step: 11800 | performance: 75.9 | accuracy: 0.46 | loss: 6.87
update:300/2000, 耗时:0.00分/0.63分 | step: 12000 | performance: 433.9 | accuracy: 0.46 | loss: 6.57
update:305/2000, 耗时:0.00分/0.64分 | step: 12200 | performance: 261.2 | accuracy: 0.46 | loss: 2.86
update:310/2000, 耗时:0.00分/0.65分 | step: 12400 | performance: 243.1 | accuracy: 0.46 | loss: 1.45
update:315/2000, 耗时:0.00分/0.66分 | step: 12600 | performance: 116.6 | accuracy: 0.46 | loss: 2.15
update:320/2000, 耗时:0.00分/0.67分 | step: 12800 | performance: 50.1 | accuracy: 0.46 | loss: 6.77
update:325/2000, 耗时:0.00分/0.68分 | step: 13000 | performance: 47.0 | accuracy: 0.46 | loss: 4.29
update:330/2000, 耗时:0.00分/0.69分 | step: 13200 | performance: 34.5 | accuracy: 0.45 | loss: 0.63
update:335/2000, 耗时:0.00分/0.70分 | step: 13400 | performance: 40.0 | accuracy: 0.45 | loss: 3.72
update:340/2000, 耗时:0.00分/0.71分 | step: 13600 | performance: 51.3 | accuracy: 0.46 | loss: 0.48
update:345/2000, 耗时:0.00分/0.72分 | step: 13800 | performance: 48.1 | accuracy: 0.46 | loss: 1.13
update:350/2000, 耗时:0.00分/0.73分 | step: 14000 | performance: 40.4 | accuracy: 0.46 | loss: 3.24
update:355/2000, 耗时:0.00分/0.74分 | step: 14200 | performance: 13.1 | accuracy: 0.45 | loss: 3.42
update:360/2000, 耗时:0.00分/0.75分 | step: 14400 | performance: 11.0 | accuracy: 0.45 | loss: 1.06
update:365/2000, 耗时:0.00分/0.76分 | step: 14600 | performance: 13.1 | accuracy: 0.45 | loss: 3.06
update:370/2000, 耗时:0.00分/0.77分 | step: 14800 | performance: 27.5 | accuracy: 0.45 | loss: 2.60
update:375/2000, 耗时:0.00分/0.78分 | step: 15000 | performance: 24.9 | accuracy: 0.45 | loss: 1.55
update:380/2000, 耗时:0.00分/0.79分 | step: 15200 | performance: 23.9 | accuracy: 0.45 | loss: 0.39
update:385/2000, 耗时:0.00分/0.80分 | step: 15400 | performance: 13.6 | accuracy: 0.45 | loss: 2.07
update:390/2000, 耗时:0.00分/0.81分 | step: 15600 | performance: 5.7 | accuracy: 0.44 | loss: 0.54
update:395/2000, 耗时:0.00分/0.82分 | step: 15800 | performance: 2.3 | accuracy: 0.44 | loss: 1.61
update:400/2000, 耗时:0.00分/0.83分 | step: 16000 | performance: 3.9 | accuracy: 0.44 | loss: 5.18
update:405/2000, 耗时:0.00分/0.84分 | step: 16200 | performance: 5.1 | accuracy: 0.44 | loss: 5.08
update:410/2000, 耗时:0.00分/0.85分 | step: 16400 | performance: 19.2 | accuracy: 0.45 | loss: 0.80
update:415/2000, 耗时:0.00分/0.86分 | step: 16600 | performance: 117.3 | accuracy: 0.45 | loss: 1.88
update:420/2000, 耗时:0.00分/0.87分 | step: 16800 | performance: 333.0 | accuracy: 0.46 | loss: 1.04
update:425/2000, 耗时:0.00分/0.88分 | step: 17000 | performance: 133.5 | accuracy: 0.45 | loss: 2.91
update:430/2000, 耗时:0.00分/0.89分 | step: 17200 | performance: 913.3 | accuracy: 0.46 | loss: 4.18
update:435/2000, 耗时:0.00分/0.90分 | step: 17400 | performance: 2725.3 | accuracy: 0.46 | loss: 4.28
update:440/2000, 耗时:0.00分/0.91分 | step: 17600 | performance: 1490.0 | accuracy: 0.46 | loss: 2.33
update:445/2000, 耗时:0.00分/0.92分 | step: 17800 | performance: 4378.4 | accuracy: 0.47 | loss: 1.53
update:450/2000, 耗时:0.00分/0.93分 | step: 18000 | performance: 4360.1 | accuracy: 0.47 | loss: 1.48
update:455/2000, 耗时:0.00分/0.95分 | step: 18200 | performance: 6048.8 | accuracy: 0.47 | loss: 2.31
update:460/2000, 耗时:0.00分/0.96分 | step: 18400 | performance: 1823.2 | accuracy: 0.47 | loss: 2.13
update:465/2000, 耗时:0.00分/0.97分 | step: 18600 | performance: 3750.2 | accuracy: 0.47 | loss: 1.48
update:470/2000, 耗时:0.00分/0.98分 | step: 18800 | performance: 335.7 | accuracy: 0.46 | loss: 2.62
update:475/2000, 耗时:0.00分/0.99分 | step: 19000 | performance: 423.2 | accuracy: 0.46 | loss: 2.23
update:480/2000, 耗时:0.00分/1.00分 | step: 19200 | performance: 330.8 | accuracy: 0.46 | loss: 4.28
update:485/2000, 耗时:0.00分/1.01分 | step: 19400 | performance: 947.0 | accuracy: 0.47 | loss: 1.91
update:490/2000, 耗时:0.00分/1.02分 | step: 19600 | performance: 917.8 | accuracy: 0.47 | loss: 4.19
update:495/2000, 耗时:0.00分/1.03分 | step: 19800 | performance: 1263.5 | accuracy: 0.47 | loss: 2.86
update:500/2000, 耗时:0.00分/1.04分 | step: 20000 | performance: 376.8 | accuracy: 0.47 | loss: 6.22
update:505/2000, 耗时:0.00分/1.05分 | step: 20200 | performance: 128.4 | accuracy: 0.47 | loss: 1.20
update:510/2000, 耗时:0.00分/1.07分 | step: 20400 | performance: 104.9 | accuracy: 0.47 | loss: 0.74
update:515/2000, 耗时:0.00分/1.08分 | step: 20600 | performance: 149.6 | accuracy: 0.47 | loss: 6.43
update:520/2000, 耗时:0.00分/1.09分 | step: 20800 | performance: 227.9 | accuracy: 0.47 | loss: 3.36
update:525/2000, 耗时:0.00分/1.10分 | step: 21000 | performance: 99.0 | accuracy: 0.47 | loss: 3.31
update:530/2000, 耗时:0.00分/1.11分 | step: 21200 | performance: 38.2 | accuracy: 0.46 | loss: 0.96
update:535/2000, 耗时:0.00分/1.12分 | step: 21400 | performance: 37.2 | accuracy: 0.46 | loss: 1.58
update:540/2000, 耗时:0.00分/1.13分 | step: 21600 | performance: 51.1 | accuracy: 0.46 | loss: 2.80
update:545/2000, 耗时:0.00分/1.14分 | step: 21800 | performance: 24.3 | accuracy: 0.46 | loss: 0.89
update:550/2000, 耗时:0.00分/1.16分 | step: 22000 | performance: 11.3 | accuracy: 0.46 | loss: 1.18
update:555/2000, 耗时:0.00分/1.17分 | step: 22200 | performance: 14.4 | accuracy: 0.46 | loss: 3.12
update:560/2000, 耗时:0.00分/1.18分 | step: 22400 | performance: 13.7 | accuracy: 0.46 | loss: 2.78
update:565/2000, 耗时:0.00分/1.19分 | step: 22600 | performance: 24.8 | accuracy: 0.46 | loss: 2.98
update:570/2000, 耗时:0.00分/1.20分 | step: 22800 | performance: 68.7 | accuracy: 0.46 | loss: 3.26
update:575/2000, 耗时:0.00分/1.21分 | step: 23000 | performance: 27.3 | accuracy: 0.46 | loss: 4.05
update:580/2000, 耗时:0.00分/1.22分 | step: 23200 | performance: 44.6 | accuracy: 0.46 | loss: 7.45
update:585/2000, 耗时:0.00分/1.23分 | step: 23400 | performance: 33.4 | accuracy: 0.46 | loss: 4.38
update:590/2000, 耗时:0.00分/1.25分 | step: 23600 | performance: 42.0 | accuracy: 0.46 | loss: 3.01
update:595/2000, 耗时:0.00分/1.26分 | step: 23800 | performance: 16.2 | accuracy: 0.46 | loss: 2.85
update:600/2000, 耗时:0.00分/1.27分 | step: 24000 | performance: 33.7 | accuracy: 0.46 | loss: 4.52
update:605/2000, 耗时:0.00分/1.28分 | step: 24200 | performance: 45.4 | accuracy: 0.46 | loss: 4.21
update:610/2000, 耗时:0.00分/1.29分 | step: 24400 | performance: 65.2 | accuracy: 0.46 | loss: 1.69
update:615/2000, 耗时:0.00分/1.30分 | step: 24600 | performance: 276.8 | accuracy: 0.46 | loss: 2.11
update:620/2000, 耗时:0.00分/1.31分 | step: 24800 | performance: 233.6 | accuracy: 0.46 | loss: 7.03
update:625/2000, 耗时:0.00分/1.32分 | step: 25000 | performance: 493.2 | accuracy: 0.47 | loss: 3.93
update:630/2000, 耗时:0.00分/1.33分 | step: 25200 | performance: 2319.7 | accuracy: 0.47 | loss: 6.76
update:635/2000, 耗时:0.00分/1.34分 | step: 25400 | performance: 2676.6 | accuracy: 0.47 | loss: 8.43
update:640/2000, 耗时:0.00分/1.35分 | step: 25600 | performance: 1556.9 | accuracy: 0.47 | loss: 7.33
update:645/2000, 耗时:0.00分/1.36分 | step: 25800 | performance: 1385.0 | accuracy: 0.47 | loss: 1.76
update:650/2000, 耗时:0.00分/1.37分 | step: 26000 | performance: 1117.3 | accuracy: 0.46 | loss: 2.34
update:655/2000, 耗时:0.00分/1.38分 | step: 26200 | performance: 2723.2 | accuracy: 0.47 | loss: 1.41
update:660/2000, 耗时:0.00分/1.40分 | step: 26400 | performance: 4799.9 | accuracy: 0.47 | loss: 1.87
update:665/2000, 耗时:0.00分/1.41分 | step: 26600 | performance: 5042.3 | accuracy: 0.47 | loss: 3.24
update:670/2000, 耗时:0.00分/1.42分 | step: 26800 | performance: 4944.3 | accuracy: 0.47 | loss: 0.64
update:675/2000, 耗时:0.00分/1.43分 | step: 27000 | performance: 5127.2 | accuracy: 0.47 | loss: 2.41
update:680/2000, 耗时:0.00分/1.44分 | step: 27200 | performance: 3597.5 | accuracy: 0.47 | loss: 4.73
update:685/2000, 耗时:0.00分/1.45分 | step: 27400 | performance: 7850.5 | accuracy: 0.47 | loss: 9.14
update:690/2000, 耗时:0.00分/1.46分 | step: 27600 | performance: 16155.6 | accuracy: 0.47 | loss: 2.35
update:695/2000, 耗时:0.00分/1.47分 | step: 27800 | performance: 11774.9 | accuracy: 0.47 | loss: 0.98
update:700/2000, 耗时:0.00分/1.48分 | step: 28000 | performance: 12136.1 | accuracy: 0.47 | loss: 2.53
update:705/2000, 耗时:0.00分/1.49分 | step: 28200 | performance: 14469.0 | accuracy: 0.47 | loss: 2.31
Saving PPO weights in both H5 format and checkpoint @ update:707 
update:710/2000, 耗时:0.00分/1.50分 | step: 28400 | performance: 2.7 | accuracy: 0.62 | loss: 2.81
Saving PPO weights in both H5 format and checkpoint @ update:711 
update:715/2000, 耗时:0.00分/1.52分 | step: 28600 | performance: 3.7 | accuracy: 0.59 | loss: 1.17
update:720/2000, 耗时:0.00分/1.53分 | step: 28800 | performance: 14.0 | accuracy: 0.67 | loss: 1.17
update:725/2000, 耗时:0.00分/1.54分 | step: 29000 | performance: 6.1 | accuracy: 0.58 | loss: 1.43
update:730/2000, 耗时:0.00分/1.55分 | step: 29200 | performance: 2.7 | accuracy: 0.49 | loss: 1.99
update:735/2000, 耗时:0.00分/1.56分 | step: 29400 | performance: 4.5 | accuracy: 0.53 | loss: 4.41
update:740/2000, 耗时:0.00分/1.57分 | step: 29600 | performance: 10.1 | accuracy: 0.55 | loss: 4.18
update:745/2000, 耗时:0.00分/1.58分 | step: 29800 | performance: 9.9 | accuracy: 0.55 | loss: 0.95
update:750/2000, 耗时:0.00分/1.59分 | step: 30000 | performance: 23.7 | accuracy: 0.56 | loss: 2.30
update:755/2000, 耗时:0.00分/1.60分 | step: 30200 | performance: 30.5 | accuracy: 0.55 | loss: 5.42
update:760/2000, 耗时:0.00分/1.61分 | step: 30400 | performance: 35.0 | accuracy: 0.55 | loss: 2.94
update:765/2000, 耗时:0.00分/1.62分 | step: 30600 | performance: 7.2 | accuracy: 0.51 | loss: 2.28
update:770/2000, 耗时:0.00分/1.63分 | step: 30800 | performance: 22.8 | accuracy: 0.53 | loss: 3.78
update:775/2000, 耗时:0.00分/1.64分 | step: 31000 | performance: 31.9 | accuracy: 0.54 | loss: 1.21
update:780/2000, 耗时:0.00分/1.65分 | step: 31200 | performance: 17.2 | accuracy: 0.51 | loss: 1.11
update:785/2000, 耗时:0.00分/1.66分 | step: 31400 | performance: 31.9 | accuracy: 0.52 | loss: 3.28
update:790/2000, 耗时:0.00分/1.67分 | step: 31600 | performance: 31.4 | accuracy: 0.52 | loss: 2.18
update:795/2000, 耗时:0.00分/1.68分 | step: 31800 | performance: 28.5 | accuracy: 0.51 | loss: 2.41
update:800/2000, 耗时:0.00分/1.69分 | step: 32000 | performance: 30.3 | accuracy: 0.51 | loss: 1.06
update:805/2000, 耗时:0.00分/1.70分 | step: 32200 | performance: 37.1 | accuracy: 0.52 | loss: 2.94
update:810/2000, 耗时:0.00分/1.71分 | step: 32400 | performance: 67.4 | accuracy: 0.52 | loss: 6.80
update:815/2000, 耗时:0.00分/1.72分 | step: 32600 | performance: 627.3 | accuracy: 0.54 | loss: 3.22
update:820/2000, 耗时:0.00分/1.73分 | step: 32800 | performance: 1644.6 | accuracy: 0.54 | loss: 1.24
update:825/2000, 耗时:0.00分/1.74分 | step: 33000 | performance: 749.7 | accuracy: 0.54 | loss: 2.22
update:830/2000, 耗时:0.00分/1.75分 | step: 33200 | performance: 994.7 | accuracy: 0.54 | loss: 1.01
update:835/2000, 耗时:0.00分/1.76分 | step: 33400 | performance: 1399.3 | accuracy: 0.54 | loss: 0.84
update:840/2000, 耗时:0.00分/1.77分 | step: 33600 | performance: 1899.9 | accuracy: 0.54 | loss: 2.95
update:845/2000, 耗时:0.00分/1.78分 | step: 33800 | performance: 1345.3 | accuracy: 0.53 | loss: 1.55
update:850/2000, 耗时:0.00分/1.79分 | step: 34000 | performance: 811.5 | accuracy: 0.53 | loss: 0.50
update:855/2000, 耗时:0.00分/1.80分 | step: 34200 | performance: 964.6 | accuracy: 0.52 | loss: 2.90
update:860/2000, 耗时:0.00分/1.81分 | step: 34400 | performance: 804.7 | accuracy: 0.52 | loss: 1.14
update:865/2000, 耗时:0.00分/1.82分 | step: 34600 | performance: 435.1 | accuracy: 0.51 | loss: 5.32
update:870/2000, 耗时:0.00分/1.83分 | step: 34800 | performance: 210.2 | accuracy: 0.50 | loss: 0.97
update:875/2000, 耗时:0.00分/1.84分 | step: 35000 | performance: 164.2 | accuracy: 0.49 | loss: 4.53
update:880/2000, 耗时:0.00分/1.85分 | step: 35200 | performance: 68.7 | accuracy: 0.48 | loss: 1.95
update:885/2000, 耗时:0.00分/1.86分 | step: 35400 | performance: 23.6 | accuracy: 0.48 | loss: 1.20
update:890/2000, 耗时:0.00分/1.87分 | step: 35600 | performance: 26.8 | accuracy: 0.47 | loss: 1.63
update:895/2000, 耗时:0.00分/1.88分 | step: 35800 | performance: 33.3 | accuracy: 0.46 | loss: 1.45
update:900/2000, 耗时:0.00分/1.89分 | step: 36000 | performance: 171.3 | accuracy: 0.47 | loss: 1.38
update:905/2000, 耗时:0.00分/1.90分 | step: 36200 | performance: 173.4 | accuracy: 0.47 | loss: 3.89
update:910/2000, 耗时:0.00分/1.91分 | step: 36400 | performance: 57.3 | accuracy: 0.47 | loss: 7.34
update:915/2000, 耗时:0.00分/1.92分 | step: 36600 | performance: 86.4 | accuracy: 0.47 | loss: 4.16
update:920/2000, 耗时:0.00分/1.93分 | step: 36800 | performance: 47.6 | accuracy: 0.46 | loss: 1.07
update:925/2000, 耗时:0.00分/1.94分 | step: 37000 | performance: 30.0 | accuracy: 0.46 | loss: 5.08
update:930/2000, 耗时:0.00分/1.95分 | step: 37200 | performance: 39.5 | accuracy: 0.46 | loss: 1.83
update:935/2000, 耗时:0.00分/1.96分 | step: 37400 | performance: 23.4 | accuracy: 0.46 | loss: 1.34
update:940/2000, 耗时:0.00分/1.97分 | step: 37600 | performance: 39.7 | accuracy: 0.46 | loss: 2.48
update:945/2000, 耗时:0.00分/1.98分 | step: 37800 | performance: 42.8 | accuracy: 0.46 | loss: 3.98
update:950/2000, 耗时:0.00分/1.99分 | step: 38000 | performance: 19.0 | accuracy: 0.46 | loss: 4.31
update:955/2000, 耗时:0.00分/2.00分 | step: 38200 | performance: 25.6 | accuracy: 0.46 | loss: 2.06
update:960/2000, 耗时:0.00分/2.01分 | step: 38400 | performance: 94.2 | accuracy: 0.47 | loss: 2.04
update:965/2000, 耗时:0.00分/2.02分 | step: 38600 | performance: 67.4 | accuracy: 0.47 | loss: 3.38
update:970/2000, 耗时:0.00分/2.03分 | step: 38800 | performance: 92.3 | accuracy: 0.48 | loss: 2.68
update:975/2000, 耗时:0.00分/2.04分 | step: 39000 | performance: 93.1 | accuracy: 0.48 | loss: 1.54
update:980/2000, 耗时:0.00分/2.05分 | step: 39200 | performance: 34.3 | accuracy: 0.47 | loss: 2.86
update:985/2000, 耗时:0.00分/2.06分 | step: 39400 | performance: 30.9 | accuracy: 0.47 | loss: 3.30
update:990/2000, 耗时:0.00分/2.07分 | step: 39600 | performance: 14.2 | accuracy: 0.47 | loss: 2.84
update:995/2000, 耗时:0.00分/2.08分 | step: 39800 | performance: 14.5 | accuracy: 0.46 | loss: 1.57
update:1000/2000, 耗时:0.00分/2.09分 | step: 40000 | performance: 24.4 | accuracy: 0.46 | loss: 3.32
update:1005/2000, 耗时:0.00分/2.10分 | step: 40200 | performance: 690.6 | accuracy: 0.47 | loss: 2.16
update:1010/2000, 耗时:0.00分/2.11分 | step: 40400 | performance: 219.5 | accuracy: 0.47 | loss: 4.38
update:1015/2000, 耗时:0.00分/2.12分 | step: 40600 | performance: 115.0 | accuracy: 0.46 | loss: 6.03
update:1020/2000, 耗时:0.00分/2.13分 | step: 40800 | performance: 88.4 | accuracy: 0.46 | loss: 3.24
update:1025/2000, 耗时:0.00分/2.14分 | step: 41000 | performance: 24.1 | accuracy: 0.46 | loss: 1.88
update:1030/2000, 耗时:0.00分/2.15分 | step: 41200 | performance: 17.4 | accuracy: 0.46 | loss: 1.71
update:1035/2000, 耗时:0.00分/2.16分 | step: 41400 | performance: 19.6 | accuracy: 0.46 | loss: 0.87
update:1040/2000, 耗时:0.00分/2.17分 | step: 41600 | performance: 19.1 | accuracy: 0.45 | loss: 0.23
update:1045/2000, 耗时:0.00分/2.18分 | step: 41800 | performance: 19.5 | accuracy: 0.45 | loss: 0.53
update:1050/2000, 耗时:0.00分/2.19分 | step: 42000 | performance: 18.4 | accuracy: 0.45 | loss: 3.32
update:1055/2000, 耗时:0.00分/2.20分 | step: 42200 | performance: 20.3 | accuracy: 0.45 | loss: 1.07
update:1060/2000, 耗时:0.00分/2.21分 | step: 42400 | performance: 7.0 | accuracy: 0.44 | loss: 0.68
update:1065/2000, 耗时:0.00分/2.22分 | step: 42600 | performance: 7.4 | accuracy: 0.44 | loss: 0.34
update:1070/2000, 耗时:0.00分/2.23分 | step: 42800 | performance: 6.8 | accuracy: 0.43 | loss: 0.78
update:1075/2000, 耗时:0.00分/2.24分 | step: 43000 | performance: 6.8 | accuracy: 0.43 | loss: 0.07
update:1080/2000, 耗时:0.00分/2.25分 | step: 43200 | performance: 7.1 | accuracy: 0.42 | loss: 0.32
update:1085/2000, 耗时:0.00分/2.26分 | step: 43400 | performance: 7.5 | accuracy: 0.42 | loss: 0.17
update:1090/2000, 耗时:0.00分/2.27分 | step: 43600 | performance: 8.3 | accuracy: 0.42 | loss: 0.33
update:1095/2000, 耗时:0.00分/2.28分 | step: 43800 | performance: 12.4 | accuracy: 0.42 | loss: 1.00
update:1100/2000, 耗时:0.00分/2.29分 | step: 44000 | performance: 29.1 | accuracy: 0.42 | loss: 2.11
update:1105/2000, 耗时:0.00分/2.30分 | step: 44200 | performance: 84.5 | accuracy: 0.43 | loss: 0.18
update:1110/2000, 耗时:0.00分/2.31分 | step: 44400 | performance: 100.4 | accuracy: 0.43 | loss: 10.81
update:1115/2000, 耗时:0.00分/2.32分 | step: 44600 | performance: 197.5 | accuracy: 0.43 | loss: 3.39
update:1120/2000, 耗时:0.00分/2.33分 | step: 44800 | performance: 854.7 | accuracy: 0.44 | loss: 0.93
update:1125/2000, 耗时:0.00分/2.34分 | step: 45000 | performance: 4984.9 | accuracy: 0.44 | loss: 19.08
update:1130/2000, 耗时:0.00分/2.35分 | step: 45200 | performance: 2123.7 | accuracy: 0.44 | loss: 4.63
update:1135/2000, 耗时:0.00分/2.36分 | step: 45400 | performance: 5604.0 | accuracy: 0.44 | loss: 2.71
update:1140/2000, 耗时:0.00分/2.37分 | step: 45600 | performance: 30951.1 | accuracy: 0.45 | loss: 0.66
update:1145/2000, 耗时:0.00分/2.38分 | step: 45800 | performance: 23162.1 | accuracy: 0.45 | loss: 0.34
update:1150/2000, 耗时:0.00分/2.39分 | step: 46000 | performance: 70426.8 | accuracy: 0.45 | loss: 2.68
update:1155/2000, 耗时:0.00分/2.40分 | step: 46200 | performance: 42581.7 | accuracy: 0.45 | loss: 0.69
update:1160/2000, 耗时:0.00分/2.41分 | step: 46400 | performance: 57878.7 | accuracy: 0.45 | loss: 2.27
update:1165/2000, 耗时:0.00分/2.42分 | step: 46600 | performance: 50413.5 | accuracy: 0.45 | loss: 3.15
update:1170/2000, 耗时:0.00分/2.43分 | step: 46800 | performance: 44558.0 | accuracy: 0.45 | loss: 2.74
update:1175/2000, 耗时:0.00分/2.44分 | step: 47000 | performance: 18919.1 | accuracy: 0.45 | loss: 4.13
update:1180/2000, 耗时:0.00分/2.45分 | step: 47200 | performance: 7001.5 | accuracy: 0.45 | loss: 1.69
update:1185/2000, 耗时:0.00分/2.46分 | step: 47400 | performance: 6500.6 | accuracy: 0.45 | loss: 1.87
update:1190/2000, 耗时:0.00分/2.47分 | step: 47600 | performance: 12658.2 | accuracy: 0.45 | loss: 2.90
update:1195/2000, 耗时:0.00分/2.48分 | step: 47800 | performance: 9295.6 | accuracy: 0.45 | loss: 1.07
update:1200/2000, 耗时:0.00分/2.49分 | step: 48000 | performance: 16269.9 | accuracy: 0.45 | loss: 3.29
update:1205/2000, 耗时:0.00分/2.50分 | step: 48200 | performance: 3761.6 | accuracy: 0.45 | loss: 3.26
update:1210/2000, 耗时:0.00分/2.51分 | step: 48400 | performance: 1939.9 | accuracy: 0.45 | loss: 1.36
update:1215/2000, 耗时:0.00分/2.52分 | step: 48600 | performance: 1399.7 | accuracy: 0.45 | loss: 1.23
update:1220/2000, 耗时:0.00分/2.53分 | step: 48800 | performance: 1398.6 | accuracy: 0.45 | loss: 0.48
update:1225/2000, 耗时:0.00分/2.54分 | step: 49000 | performance: 793.9 | accuracy: 0.44 | loss: 0.79
update:1230/2000, 耗时:0.00分/2.55分 | step: 49200 | performance: 549.3 | accuracy: 0.44 | loss: 1.72
update:1235/2000, 耗时:0.00分/2.56分 | step: 49400 | performance: 404.2 | accuracy: 0.44 | loss: 3.42
update:1240/2000, 耗时:0.00分/2.57分 | step: 49600 | performance: 632.6 | accuracy: 0.44 | loss: 1.05
update:1245/2000, 耗时:0.00分/2.58分 | step: 49800 | performance: 656.2 | accuracy: 0.44 | loss: 1.08
update:1250/2000, 耗时:0.00分/2.59分 | step: 50000 | performance: 432.4 | accuracy: 0.44 | loss: 4.02
update:1255/2000, 耗时:0.00分/2.60分 | step: 50200 | performance: 381.3 | accuracy: 0.44 | loss: 0.05
update:1260/2000, 耗时:0.00分/2.61分 | step: 50400 | performance: 270.6 | accuracy: 0.43 | loss: 0.00
update:1265/2000, 耗时:0.00分/2.62分 | step: 50600 | performance: 247.6 | accuracy: 0.43 | loss: 0.53
update:1270/2000, 耗时:0.00分/2.63分 | step: 50800 | performance: 296.3 | accuracy: 0.43 | loss: 1.01
update:1275/2000, 耗时:0.00分/2.64分 | step: 51000 | performance: 446.5 | accuracy: 0.43 | loss: 5.77
update:1280/2000, 耗时:0.00分/2.65分 | step: 51200 | performance: 566.3 | accuracy: 0.43 | loss: 1.68
update:1285/2000, 耗时:0.00分/2.66分 | step: 51400 | performance: 236.9 | accuracy: 0.43 | loss: 2.85
update:1290/2000, 耗时:0.00分/2.67分 | step: 51600 | performance: 305.4 | accuracy: 0.43 | loss: 1.53
update:1295/2000, 耗时:0.00分/2.68分 | step: 51800 | performance: 307.5 | accuracy: 0.43 | loss: 1.15
update:1300/2000, 耗时:0.00分/2.69分 | step: 52000 | performance: 167.5 | accuracy: 0.43 | loss: 3.62
update:1305/2000, 耗时:0.00分/2.70分 | step: 52200 | performance: 138.0 | accuracy: 0.43 | loss: 2.41
update:1310/2000, 耗时:0.00分/2.71分 | step: 52400 | performance: 275.0 | accuracy: 0.43 | loss: 1.22
update:1315/2000, 耗时:0.00分/2.72分 | step: 52600 | performance: 386.0 | accuracy: 0.43 | loss: 3.54
update:1320/2000, 耗时:0.00分/2.73分 | step: 52800 | performance: 1923.8 | accuracy: 0.44 | loss: 1.52
update:1325/2000, 耗时:0.00分/2.74分 | step: 53000 | performance: 2030.9 | accuracy: 0.44 | loss: 1.08
update:1330/2000, 耗时:0.00分/2.75分 | step: 53200 | performance: 1579.5 | accuracy: 0.44 | loss: 2.78
update:1335/2000, 耗时:0.00分/2.76分 | step: 53400 | performance: 19580.0 | accuracy: 0.44 | loss: 1.93
update:1340/2000, 耗时:0.00分/2.77分 | step: 53600 | performance: 27465.4 | accuracy: 0.44 | loss: 1.56
update:1345/2000, 耗时:0.00分/2.78分 | step: 53800 | performance: 19352.2 | accuracy: 0.44 | loss: 4.87
update:1350/2000, 耗时:0.00分/2.79分 | step: 54000 | performance: 12101.2 | accuracy: 0.44 | loss: 2.96
update:1355/2000, 耗时:0.00分/2.80分 | step: 54200 | performance: 8979.3 | accuracy: 0.44 | loss: 3.34
update:1360/2000, 耗时:0.00分/2.81分 | step: 54400 | performance: 16183.7 | accuracy: 0.44 | loss: 2.04
update:1365/2000, 耗时:0.00分/2.82分 | step: 54600 | performance: 24948.8 | accuracy: 0.44 | loss: 1.07
update:1370/2000, 耗时:0.00分/2.83分 | step: 54800 | performance: 25183.6 | accuracy: 0.44 | loss: 4.20
update:1375/2000, 耗时:0.00分/2.84分 | step: 55000 | performance: 31047.1 | accuracy: 0.44 | loss: 2.46
update:1380/2000, 耗时:0.00分/2.85分 | step: 55200 | performance: 33113.4 | accuracy: 0.44 | loss: 2.06
update:1385/2000, 耗时:0.00分/2.86分 | step: 55400 | performance: 33761.2 | accuracy: 0.44 | loss: 1.21
update:1390/2000, 耗时:0.00分/2.87分 | step: 55600 | performance: 22050.6 | accuracy: 0.44 | loss: 2.95
update:1395/2000, 耗时:0.00分/2.88分 | step: 55800 | performance: 83627.3 | accuracy: 0.44 | loss: 1.42
update:1400/2000, 耗时:0.00分/2.89分 | step: 56000 | performance: 90622.5 | accuracy: 0.45 | loss: 1.42
update:1405/2000, 耗时:0.00分/2.90分 | step: 56200 | performance: 74900.2 | accuracy: 0.44 | loss: 0.59
update:1410/2000, 耗时:0.00分/2.91分 | step: 56400 | performance: 86822.5 | accuracy: 0.44 | loss: 0.53
Saving PPO weights in both H5 format and checkpoint @ update:1414 
update:1415/2000, 耗时:0.00分/2.92分 | step: 56600 | performance: 1.0 | accuracy: 0.00 | loss: 1.05
step: 56676 | worker_3@n_step_4: average total_reward after train data exhaustion : 71.0 | max total_reward: 203.0
step: 56677 | worker_4@n_step_4: average total_reward after train data exhaustion : 84.3 | max total_reward: 310.6
step: 56680 | worker_7@n_step_4: average total_reward after train data exhaustion : 79.7 | max total_reward: 310.6
Saving PPO weights in both H5 format and checkpoint @ update:1417 
update:1420/2000, 耗时:0.00分/2.93分 | step: 56800 | performance: 2.1 | accuracy: 0.40 | loss: 1.39
update:1425/2000, 耗时:0.00分/2.94分 | step: 57000 | performance: 2.9 | accuracy: 0.38 | loss: 3.61
update:1430/2000, 耗时:0.00分/2.95分 | step: 57200 | performance: 8.3 | accuracy: 0.51 | loss: 5.81
update:1435/2000, 耗时:0.00分/2.96分 | step: 57400 | performance: 3.6 | accuracy: 0.47 | loss: 1.42
update:1440/2000, 耗时:0.00分/2.97分 | step: 57600 | performance: 2.3 | accuracy: 0.43 | loss: 2.59
update:1445/2000, 耗时:0.00分/2.98分 | step: 57800 | performance: 3.7 | accuracy: 0.48 | loss: 3.10
update:1450/2000, 耗时:0.00分/2.99分 | step: 58000 | performance: 8.5 | accuracy: 0.51 | loss: 3.43
update:1455/2000, 耗时:0.00分/3.00分 | step: 58200 | performance: 9.2 | accuracy: 0.52 | loss: 3.01
update:1460/2000, 耗时:0.00分/3.01分 | step: 58400 | performance: 22.2 | accuracy: 0.53 | loss: 1.21
update:1465/2000, 耗时:0.00分/3.02分 | step: 58600 | performance: 29.7 | accuracy: 0.53 | loss: 2.74
update:1470/2000, 耗时:0.00分/3.03分 | step: 58800 | performance: 30.9 | accuracy: 0.52 | loss: 1.70
update:1475/2000, 耗时:0.00分/3.04分 | step: 59000 | performance: 23.4 | accuracy: 0.51 | loss: 2.63
update:1480/2000, 耗时:0.00分/3.05分 | step: 59200 | performance: 28.8 | accuracy: 0.51 | loss: 1.22
update:1485/2000, 耗时:0.00分/3.06分 | step: 59400 | performance: 41.7 | accuracy: 0.51 | loss: 2.52
update:1490/2000, 耗时:0.00分/3.07分 | step: 59600 | performance: 25.0 | accuracy: 0.50 | loss: 2.50
update:1495/2000, 耗时:0.00分/3.08分 | step: 59800 | performance: 46.5 | accuracy: 0.50 | loss: 4.57
update:1500/2000, 耗时:0.00分/3.09分 | step: 60000 | performance: 44.4 | accuracy: 0.50 | loss: 1.67
update:1505/2000, 耗时:0.00分/3.10分 | step: 60200 | performance: 39.9 | accuracy: 0.50 | loss: 2.70
update:1510/2000, 耗时:0.00分/3.11分 | step: 60400 | performance: 41.2 | accuracy: 0.50 | loss: 1.84
update:1515/2000, 耗时:0.00分/3.12分 | step: 60600 | performance: 48.7 | accuracy: 0.50 | loss: 2.05
update:1520/2000, 耗时:0.00分/3.13分 | step: 60800 | performance: 77.0 | accuracy: 0.50 | loss: 4.53
update:1525/2000, 耗时:0.00分/3.14分 | step: 61000 | performance: 885.5 | accuracy: 0.52 | loss: 3.02
update:1530/2000, 耗时:0.00分/3.15分 | step: 61200 | performance: 2128.3 | accuracy: 0.52 | loss: 8.40
update:1535/2000, 耗时:0.00分/3.16分 | step: 61400 | performance: 1006.1 | accuracy: 0.52 | loss: 1.82
update:1540/2000, 耗时:0.00分/3.17分 | step: 61600 | performance: 1269.3 | accuracy: 0.52 | loss: 3.16
update:1545/2000, 耗时:0.00分/3.18分 | step: 61800 | performance: 1820.9 | accuracy: 0.52 | loss: 1.12
update:1550/2000, 耗时:0.00分/3.19分 | step: 62000 | performance: 2208.9 | accuracy: 0.52 | loss: 2.15
update:1555/2000, 耗时:0.00分/3.20分 | step: 62200 | performance: 1583.7 | accuracy: 0.52 | loss: 4.85
update:1560/2000, 耗时:0.00分/3.21分 | step: 62400 | performance: 921.1 | accuracy: 0.51 | loss: 1.40
update:1565/2000, 耗时:0.00分/3.22分 | step: 62600 | performance: 1022.8 | accuracy: 0.50 | loss: 2.40
update:1570/2000, 耗时:0.00分/3.23分 | step: 62800 | performance: 903.8 | accuracy: 0.50 | loss: 0.40
update:1575/2000, 耗时:0.00分/3.24分 | step: 63000 | performance: 1016.2 | accuracy: 0.50 | loss: 1.86
update:1580/2000, 耗时:0.00分/3.25分 | step: 63200 | performance: 1945.2 | accuracy: 0.50 | loss: 1.29
update:1585/2000, 耗时:0.00分/3.26分 | step: 63400 | performance: 2302.1 | accuracy: 0.50 | loss: 2.73
update:1590/2000, 耗时:0.00分/3.27分 | step: 63600 | performance: 4507.5 | accuracy: 0.51 | loss: 5.57
update:1595/2000, 耗时:0.00分/3.28分 | step: 63800 | performance: 20414.0 | accuracy: 0.52 | loss: 1.44
update:1600/2000, 耗时:0.00分/3.29分 | step: 64000 | performance: 30929.0 | accuracy: 0.52 | loss: 1.22
update:1605/2000, 耗时:0.00分/3.30分 | step: 64200 | performance: 37376.4 | accuracy: 0.52 | loss: 3.95
update:1610/2000, 耗时:0.00分/3.31分 | step: 64400 | performance: 273029.5 | accuracy: 0.53 | loss: 0.89
update:1615/2000, 耗时:0.00分/3.32分 | step: 64600 | performance: 256046.5 | accuracy: 0.53 | loss: 2.09
update:1620/2000, 耗时:0.00分/3.33分 | step: 64800 | performance: 91794.4 | accuracy: 0.52 | loss: 1.36
update:1625/2000, 耗时:0.00分/3.34分 | step: 65000 | performance: 263460.4 | accuracy: 0.53 | loss: 4.16
update:1630/2000, 耗时:0.00分/3.35分 | step: 65200 | performance: 161114.6 | accuracy: 0.52 | loss: 0.68
update:1635/2000, 耗时:0.00分/3.36分 | step: 65400 | performance: 147059.9 | accuracy: 0.51 | loss: 1.88
update:1640/2000, 耗时:0.00分/3.37分 | step: 65600 | performance: 130633.0 | accuracy: 0.51 | loss: 0.52
update:1645/2000, 耗时:0.00分/3.38分 | step: 65800 | performance: 134293.8 | accuracy: 0.50 | loss: 1.97
update:1650/2000, 耗时:0.00分/3.39分 | step: 66000 | performance: 87070.0 | accuracy: 0.50 | loss: 1.50
update:1655/2000, 耗时:0.00分/3.40分 | step: 66200 | performance: 94808.6 | accuracy: 0.50 | loss: 8.54
update:1660/2000, 耗时:0.00分/3.41分 | step: 66400 | performance: 42793.7 | accuracy: 0.50 | loss: 2.43
update:1665/2000, 耗时:0.00分/3.42分 | step: 66600 | performance: 66866.1 | accuracy: 0.50 | loss: 3.39
update:1670/2000, 耗时:0.00分/3.43分 | step: 66800 | performance: 243883.9 | accuracy: 0.51 | loss: 2.21
update:1675/2000, 耗时:0.00分/3.44分 | step: 67000 | performance: 181302.3 | accuracy: 0.51 | loss: 3.46
update:1680/2000, 耗时:0.00分/3.45分 | step: 67200 | performance: 239238.4 | accuracy: 0.51 | loss: 4.22
update:1685/2000, 耗时:0.00分/3.46分 | step: 67400 | performance: 249510.3 | accuracy: 0.51 | loss: 1.51
update:1690/2000, 耗时:0.00分/3.47分 | step: 67600 | performance: 97668.2 | accuracy: 0.51 | loss: 2.96
update:1695/2000, 耗时:0.00分/3.48分 | step: 67800 | performance: 89280.5 | accuracy: 0.51 | loss: 2.25
update:1700/2000, 耗时:0.00分/3.49分 | step: 68000 | performance: 60213.0 | accuracy: 0.51 | loss: 1.04
update:1705/2000, 耗时:0.00分/3.50分 | step: 68200 | performance: 55526.5 | accuracy: 0.50 | loss: 0.25
update:1710/2000, 耗时:0.00分/3.51分 | step: 68400 | performance: 55307.3 | accuracy: 0.49 | loss: 4.47
update:1715/2000, 耗时:0.00分/3.52分 | step: 68600 | performance: 910820.2 | accuracy: 0.50 | loss: 4.89
update:1720/2000, 耗时:0.00分/3.53分 | step: 68800 | performance: 307508.3 | accuracy: 0.49 | loss: 3.78
update:1725/2000, 耗时:0.00分/3.54分 | step: 69000 | performance: 152705.1 | accuracy: 0.49 | loss: 2.70
update:1730/2000, 耗时:0.00分/3.55分 | step: 69200 | performance: 134048.5 | accuracy: 0.49 | loss: 4.03
update:1735/2000, 耗时:0.00分/3.56分 | step: 69400 | performance: 90748.0 | accuracy: 0.48 | loss: 1.25
update:1740/2000, 耗时:0.00分/3.57分 | step: 69600 | performance: 111364.0 | accuracy: 0.49 | loss: 0.83
update:1745/2000, 耗时:0.00分/3.57分 | step: 69800 | performance: 93669.4 | accuracy: 0.48 | loss: 0.94
update:1750/2000, 耗时:0.00分/3.58分 | step: 70000 | performance: 85357.3 | accuracy: 0.48 | loss: 2.17
update:1755/2000, 耗时:0.00分/3.59分 | step: 70200 | performance: 72057.8 | accuracy: 0.48 | loss: 0.98
update:1760/2000, 耗时:0.00分/3.60分 | step: 70400 | performance: 66661.6 | accuracy: 0.48 | loss: 0.60
update:1765/2000, 耗时:0.00分/3.61分 | step: 70600 | performance: 67394.3 | accuracy: 0.47 | loss: 1.98
update:1770/2000, 耗时:0.00分/3.62分 | step: 70800 | performance: 162530.8 | accuracy: 0.48 | loss: 1.39
update:1775/2000, 耗时:0.00分/3.63分 | step: 71000 | performance: 183319.3 | accuracy: 0.48 | loss: 2.98
update:1780/2000, 耗时:0.00分/3.64分 | step: 71200 | performance: 163250.7 | accuracy: 0.48 | loss: 5.60
update:1785/2000, 耗时:0.00分/3.65分 | step: 71400 | performance: 77944.4 | accuracy: 0.47 | loss: 1.47
update:1790/2000, 耗时:0.00分/3.66分 | step: 71600 | performance: 109905.1 | accuracy: 0.48 | loss: 1.11
update:1795/2000, 耗时:0.00分/3.67分 | step: 71800 | performance: 95224.8 | accuracy: 0.48 | loss: 3.22
update:1800/2000, 耗时:0.00分/3.68分 | step: 72000 | performance: 140205.2 | accuracy: 0.48 | loss: 2.81
update:1805/2000, 耗时:0.00分/3.69分 | step: 72200 | performance: 346966.6 | accuracy: 0.48 | loss: 2.65
update:1810/2000, 耗时:0.00分/3.70分 | step: 72400 | performance: 784303.4 | accuracy: 0.49 | loss: 2.23
update:1815/2000, 耗时:0.00分/3.71分 | step: 72600 | performance: 2313436.1 | accuracy: 0.49 | loss: 1.33
update:1820/2000, 耗时:0.00分/3.72分 | step: 72800 | performance: 2802888.4 | accuracy: 0.49 | loss: 2.36
update:1825/2000, 耗时:0.00分/3.73分 | step: 73000 | performance: 4634664.1 | accuracy: 0.49 | loss: 2.55
update:1830/2000, 耗时:0.00分/3.74分 | step: 73200 | performance: 21655090.0 | accuracy: 0.50 | loss: 1.65
update:1835/2000, 耗时:0.00分/3.75分 | step: 73400 | performance: 158999018.4 | accuracy: 0.50 | loss: 10.24
update:1840/2000, 耗时:0.00分/3.76分 | step: 73600 | performance: 56534639.9 | accuracy: 0.50 | loss: 4.51
update:1845/2000, 耗时:0.00分/3.77分 | step: 73800 | performance: 138299282.7 | accuracy: 0.50 | loss: 1.23
update:1850/2000, 耗时:0.00分/3.78分 | step: 74000 | performance: 793403033.8 | accuracy: 0.51 | loss: 6.60
update:1855/2000, 耗时:0.00分/3.79分 | step: 74200 | performance: 559928158.5 | accuracy: 0.51 | loss: 1.44
update:1860/2000, 耗时:0.00分/3.80分 | step: 74400 | performance: 1999212100.6 | accuracy: 0.51 | loss: 6.52
update:1865/2000, 耗时:0.00分/3.81分 | step: 74600 | performance: 1098217615.6 | accuracy: 0.51 | loss: 3.89
update:1870/2000, 耗时:0.00分/3.82分 | step: 74800 | performance: 1592385393.9 | accuracy: 0.51 | loss: 5.62
update:1875/2000, 耗时:0.00分/3.83分 | step: 75000 | performance: 1311472977.5 | accuracy: 0.51 | loss: 1.93
update:1880/2000, 耗时:0.00分/3.84分 | step: 75200 | performance: 1364009135.5 | accuracy: 0.51 | loss: 4.50
update:1885/2000, 耗时:0.00分/3.85分 | step: 75400 | performance: 548821044.0 | accuracy: 0.51 | loss: 3.12
update:1890/2000, 耗时:0.00分/3.86分 | step: 75600 | performance: 1688960413.3 | accuracy: 0.51 | loss: 3.14
update:1895/2000, 耗时:0.00分/3.87分 | step: 75800 | performance: 2312975577.3 | accuracy: 0.51 | loss: 2.17
update:1900/2000, 耗时:0.00分/3.87分 | step: 76000 | performance: 2562645304.8 | accuracy: 0.51 | loss: 1.73
update:1905/2000, 耗时:0.00分/3.88分 | step: 76200 | performance: 1958294288.4 | accuracy: 0.51 | loss: 1.65
update:1910/2000, 耗时:0.00分/3.89分 | step: 76400 | performance: 3470931784.7 | accuracy: 0.51 | loss: 5.81
update:1915/2000, 耗时:0.00分/3.90分 | step: 76600 | performance: 882170172.1 | accuracy: 0.51 | loss: 3.17
update:1920/2000, 耗时:0.00分/3.91分 | step: 76800 | performance: 707137824.8 | accuracy: 0.50 | loss: 0.42
update:1925/2000, 耗时:0.00分/3.92分 | step: 77000 | performance: 865021402.2 | accuracy: 0.50 | loss: 0.78
update:1930/2000, 耗时:0.00分/3.93分 | step: 77200 | performance: 1010654742.2 | accuracy: 0.50 | loss: 1.52
update:1935/2000, 耗时:0.00分/3.94分 | step: 77400 | performance: 685766338.0 | accuracy: 0.50 | loss: 0.94
update:1940/2000, 耗时:0.00分/3.95分 | step: 77600 | performance: 552812031.0 | accuracy: 0.50 | loss: 1.33
update:1945/2000, 耗时:0.00分/3.96分 | step: 77800 | performance: 569890518.6 | accuracy: 0.50 | loss: 3.20
update:1950/2000, 耗时:0.00分/3.97分 | step: 78000 | performance: 943480818.1 | accuracy: 0.50 | loss: 1.43
update:1955/2000, 耗时:0.00分/3.98分 | step: 78200 | performance: 893626697.6 | accuracy: 0.50 | loss: 0.97
update:1960/2000, 耗时:0.00分/3.99分 | step: 78400 | performance: 633450490.9 | accuracy: 0.50 | loss: 3.91
update:1965/2000, 耗时:0.00分/4.00分 | step: 78600 | performance: 396483839.3 | accuracy: 0.50 | loss: 2.74
update:1970/2000, 耗时:0.00分/4.01分 | step: 78800 | performance: 1096879246.7 | accuracy: 0.50 | loss: 1.86
update:1975/2000, 耗时:0.00分/4.02分 | step: 79000 | performance: 1124621937.8 | accuracy: 0.50 | loss: 0.47
update:1980/2000, 耗时:0.00分/4.03分 | step: 79200 | performance: 1212927411.2 | accuracy: 0.50 | loss: 1.18
update:1985/2000, 耗时:0.00分/4.04分 | step: 79400 | performance: 1586559833.2 | accuracy: 0.50 | loss: 1.23
update:1990/2000, 耗时:0.00分/4.05分 | step: 79600 | performance: 2042334355.3 | accuracy: 0.49 | loss: 0.32
update:1995/2000, 耗时:0.00分/4.06分 | step: 79800 | performance: 1639102319.3 | accuracy: 0.49 | loss: 0.07
  0%|          | 0/403 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/4.07分 | step: 80000 | performance: 1337459577.8 | accuracy: 0.49 | loss: 0.03
----------------------------------------finished----------------------------------------
100%|| 403/403 [00:00<00:00, 134247.04it/s]
==================================================
2023-01-04T12:00:00 | *** START BACKTEST ***
2023-01-04T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1204.09
2023-07-24T12:00:00 | net performance [%] = 20.4091
2023-07-24T12:00:00 | number of trades [#] = 100
==================================================
Trial 2 Complete [00h 04m 31s]
net_wealth: 1205.2963195772593

Best net_wealth So Far: 1205.2963195772593
Total elapsed time: 00h 08m 03s

Search: Running Trial #3

Value             |Best Value So Far |Hyperparameter
1                 |6                 |horizon
225               |365               |lookback
False             |False             |MarketFactor
8                 |8                 |lags
0.9               |0.8               |gamma
32                |16                |batch_size
10                |5                 |n_step
0.92              |0.96              |gae_lambda
2                 |1                 |gradient_clip_norm
3                 |3                 |epochs
5e-05             |0.001             |actor_lr
1e-05             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4314.000000   4315.000000
mean      0.000441    20062.255222  ...   20122.295285  20118.633889
std       0.027818    16039.874230  ...   16077.162832  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7691.585083   7690.540039
50%       0.000642    11554.824463  ...   11724.320312  11715.610352
75%       0.011655    29873.081836  ...   29925.802734  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-27 22:11:25.693769: I tensorflow/core/plat2023-07-272023-07-2f27 22:o0r23-01m/71:2c-27 p5u_.fea62tur22093:e8231_gu-ar01:25.7-276938 d2.c18:2 I 102:c: 14:1ten12s2o2] T:hi:rflow/core/1 p0223-Ila1:t2form5 t50..7-276 2/26:11es99cp3 8T3798:u_2nsor5f.f:e a6e93tI tenurelow/c_snogorflosruwoea/r6core/p/Frd.c4l: I otle884:anso crf:l142]oIw ten /cstfooThis rrme/pl/orcpafllapu_tfoewtfw/ biTefncaororments/o/aucplrrpry Feai2s u0t2_o_2f0eopt3im-2aftorumr3izre-el_gud0/7o-20 m/7w- bga7c 2inrucard.pccp:u7au d.2__fefeacact:u1r4e124] 2rty2T:_ughuair ]i 1rs 1TTwitd.e2s2:1eh_ihs: T2 ogpet5n1uis.orFln6om:asw  o9iobina24z2n9e5rcFr9.ecl6ow :y14 b:rd .ii9A4d cwicntIh2:1847aPIry  D eoenpi  s2eA2Nst oe]pnePuI ral:  t i]DNTshIios  e  etenTshpoe rNmftieTupratlw olrNko oimiwL/icorreenzfilbresowarsy  e(d wTiet/hoznt wore/csponloorFrleodr aDtowe /pfFobniNNk)lnowwr  Ltal mry/ ibeioA PuiaincspIu D_astfefryeaebt oo t hiurempp tth s/ criNeoenopt_e fpgu_fueurmaiailmrzd .rceAPaIr iceoa:Dyz teuNeedld(  w1l4o2twrewoniwio]ep eTD_rgk NhithntgL   uNaeCPih onUe sN ibrradrT) onyu reteoA.ial Nnc(conPI sntrse u:DuNosADee1NretPp)4e2 Fcltio ]wIt bo Twohr  iusokN eDenita eLhuerrnys iibps   ifr Tee thae nfonaNseoroylurrFl ol ll sNw b(eitnaa pwelooorwkirwroyforl  isN eng  CoPiLng ptComtaPnUcwipmni e-eitzoirebUrDaNrdy ncir  swtrmki iuncitiioLtibtNs) t(onhrniocea s in Dl ot zeNonrusaepdereyA (onPp etrfo rwIhr aeiDtmhD eeeuatcitpnoNne) icoeANPNn-s t IN oDio)e utron e n eufass coriutppel the  fllsowioe rNe:ilcfloorN a twnewlA oVpXe AVmXareuo2n
T agr Ccoetthier akPoU n e-ncsrf:oi nsLtial i nglil b rAbtlicNaorwyaeVtXier uc(C lA opw orthtPioke eoUne imVX2r
aDtLniTnisntbo  isognNNnr o eCn)trhearu ctiiny ra bloens:o s(  ipPUpe r Ane rpfeort att oV Xnhfeom eAViroi nisnt Xu2s
eToDrNnmNo ot rtuhsceti)meanna ,t oohre acne-cce bolp-erfor euasle thntsrcrietm iie  thlobnseion w,i rni poic efaollebnugi lltowicCPtUhdri opeerr uTielanl  iosfoorrmnadtnst g  TCenoFalncirsucePoUpoo-rcp inw nes:resrr iaFawtiitth titoioniclalo ns, nos o retpherAsb:u iwter  aAVuX AlaVtiX dAV VoXn2s:Tpei
cti pXrnsoons ni r wo prin2F
iATV opTetrh taot X henepfeolromwna ea coambpliebalepprropfonler  tAVec itarer-cmaX hweimte2h riint t
T ifcnceooa le ch naebleo mth -lmotpehrecre ioapa rtheptngiterialerm it ia fcla lo thopnpriona so,tphsei ornesb:gerarte r  iopeo proposA.
reu.nisati
atriVl:d Teonations, Xn  r sAsVeebXo rcFulowAVoXmp ,  iAlVXwiter flagi2reh2
To
b thld Tese Tuild o. en
nT enablseoaaep them inrsble thpFrnelm inow oop other operations, rebuild TensorFlow with the appropriate compiler flags.
 with theriate appropriate compiler flagother operations, rebuild TensorFlow with the appropriate compiler flags.
rFlow with the appropriate compiler flags.
 compiler flags.
s.
2023-07-27 22:11:26.339349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:11:26.342162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:11:26.356135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:11:26.362177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.2023-07-27 202:11:26.36884, 5: I tensocomrputfe caplability: 8ow/core/comm.6
on_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:11:26.371566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:11:26.386462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:11:26.395805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 1.4 | accuracy: 0.40 | loss: 0.73
update: 10/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 1.0 | accuracy: 0.32 | loss: 1.26
update: 15/2000, 耗时:0.00分/0.06分 | step:  1200 | performance: 1.0 | accuracy: 0.31 | loss: 1.39
update: 20/2000, 耗时:0.00分/0.07分 | step:  1600 | performance: 0.8 | accuracy: 0.30 | loss: 2.29
update: 25/2000, 耗时:0.00分/0.08分 | step:  2000 | performance: 1.0 | accuracy: 0.34 | loss: 1.62
update: 30/2000, 耗时:0.00分/0.09分 | step:  2400 | performance: 1.0 | accuracy: 0.36 | loss: 1.27
update: 35/2000, 耗时:0.00分/0.10分 | step:  2800 | performance: 0.8 | accuracy: 0.36 | loss: 1.18
update: 40/2000, 耗时:0.00分/0.12分 | step:  3200 | performance: 0.8 | accuracy: 0.36 | loss: 0.69
update: 45/2000, 耗时:0.00分/0.13分 | step:  3600 | performance: 0.9 | accuracy: 0.36 | loss: 1.56
update: 50/2000, 耗时:0.00分/0.14分 | step:  4000 | performance: 1.1 | accuracy: 0.36 | loss: 2.87
update: 55/2000, 耗时:0.00分/0.15分 | step:  4400 | performance: 1.5 | accuracy: 0.38 | loss: 3.53
update: 60/2000, 耗时:0.00分/0.17分 | step:  4800 | performance: 1.5 | accuracy: 0.38 | loss: 1.11
update: 65/2000, 耗时:0.00分/0.18分 | step:  5200 | performance: 1.5 | accuracy: 0.38 | loss: 1.11
update: 70/2000, 耗时:0.00分/0.19分 | step:  5600 | performance: 1.3 | accuracy: 0.37 | loss: 0.77
update: 75/2000, 耗时:0.00分/0.21分 | step:  6000 | performance: 1.4 | accuracy: 0.37 | loss: 0.92
update: 80/2000, 耗时:0.00分/0.22分 | step:  6400 | performance: 1.3 | accuracy: 0.37 | loss: 1.11
update: 85/2000, 耗时:0.00分/0.23分 | step:  6800 | performance: 1.2 | accuracy: 0.37 | loss: 1.08
update: 90/2000, 耗时:0.00分/0.25分 | step:  7200 | performance: 1.0 | accuracy: 0.37 | loss: 1.61
update: 95/2000, 耗时:0.00分/0.26分 | step:  7600 | performance: 0.9 | accuracy: 0.37 | loss: 1.69
update:100/2000, 耗时:0.00分/0.27分 | step:  8000 | performance: 0.9 | accuracy: 0.37 | loss: 3.70
update:105/2000, 耗时:0.00分/0.29分 | step:  8400 | performance: 0.6 | accuracy: 0.36 | loss: 0.90
update:110/2000, 耗时:0.00分/0.30分 | step:  8800 | performance: 0.5 | accuracy: 0.36 | loss: 2.37
update:115/2000, 耗时:0.00分/0.31分 | step:  9200 | performance: 0.5 | accuracy: 0.36 | loss: 1.00
update:120/2000, 耗时:0.00分/0.33分 | step:  9600 | performance: 0.6 | accuracy: 0.36 | loss: 0.81
update:125/2000, 耗时:0.00分/0.34分 | step: 10000 | performance: 0.7 | accuracy: 0.36 | loss: 1.28
update:130/2000, 耗时:0.00分/0.35分 | step: 10400 | performance: 0.8 | accuracy: 0.36 | loss: 0.54
update:135/2000, 耗时:0.00分/0.37分 | step: 10800 | performance: 0.9 | accuracy: 0.35 | loss: 1.89
update:140/2000, 耗时:0.00分/0.38分 | step: 11200 | performance: 0.8 | accuracy: 0.35 | loss: 1.11
update:145/2000, 耗时:0.00分/0.39分 | step: 11600 | performance: 0.6 | accuracy: 0.35 | loss: 1.08
update:150/2000, 耗时:0.00分/0.41分 | step: 12000 | performance: 0.6 | accuracy: 0.35 | loss: 2.01
update:155/2000, 耗时:0.00分/0.42分 | step: 12400 | performance: 0.6 | accuracy: 0.35 | loss: 1.06
update:160/2000, 耗时:0.00分/0.43分 | step: 12800 | performance: 0.7 | accuracy: 0.35 | loss: 1.12
update:165/2000, 耗时:0.00分/0.45分 | step: 13200 | performance: 0.5 | accuracy: 0.34 | loss: 0.84
update:170/2000, 耗时:0.00分/0.46分 | step: 13600 | performance: 0.5 | accuracy: 0.34 | loss: 0.91
update:175/2000, 耗时:0.00分/0.47分 | step: 14000 | performance: 0.4 | accuracy: 0.34 | loss: 2.42
update:180/2000, 耗时:0.00分/0.49分 | step: 14400 | performance: 0.5 | accuracy: 0.35 | loss: 0.56
update:185/2000, 耗时:0.00分/0.50分 | step: 14800 | performance: 0.4 | accuracy: 0.35 | loss: 0.63
update:190/2000, 耗时:0.00分/0.51分 | step: 15200 | performance: 0.4 | accuracy: 0.35 | loss: 0.91
update:195/2000, 耗时:0.00分/0.53分 | step: 15600 | performance: 0.4 | accuracy: 0.35 | loss: 0.83
update:200/2000, 耗时:0.00分/0.54分 | step: 16000 | performance: 0.5 | accuracy: 0.35 | loss: 0.56
update:205/2000, 耗时:0.00分/0.56分 | step: 16400 | performance: 0.5 | accuracy: 0.35 | loss: 1.00
update:210/2000, 耗时:0.00分/0.57分 | step: 16800 | performance: 0.5 | accuracy: 0.35 | loss: 0.96
update:215/2000, 耗时:0.00分/0.58分 | step: 17200 | performance: 0.4 | accuracy: 0.35 | loss: 4.57
update:220/2000, 耗时:0.00分/0.60分 | step: 17600 | performance: 0.3 | accuracy: 0.34 | loss: 1.64
update:225/2000, 耗时:0.00分/0.61分 | step: 18000 | performance: 0.2 | accuracy: 0.34 | loss: 0.92
update:230/2000, 耗时:0.00分/0.62分 | step: 18400 | performance: 0.2 | accuracy: 0.34 | loss: 1.27
update:235/2000, 耗时:0.00分/0.64分 | step: 18800 | performance: 0.3 | accuracy: 0.34 | loss: 0.66
update:240/2000, 耗时:0.00分/0.65分 | step: 19200 | performance: 0.3 | accuracy: 0.34 | loss: 1.12
update:245/2000, 耗时:0.00分/0.66分 | step: 19600 | performance: 0.3 | accuracy: 0.34 | loss: 0.39
update:250/2000, 耗时:0.00分/0.68分 | step: 20000 | performance: 0.3 | accuracy: 0.34 | loss: 0.47
update:255/2000, 耗时:0.00分/0.69分 | step: 20400 | performance: 0.2 | accuracy: 0.34 | loss: 1.18
update:260/2000, 耗时:0.00分/0.70分 | step: 20800 | performance: 0.2 | accuracy: 0.34 | loss: 1.42
update:265/2000, 耗时:0.00分/0.72分 | step: 21200 | performance: 0.2 | accuracy: 0.34 | loss: 1.72
update:270/2000, 耗时:0.00分/0.73分 | step: 21600 | performance: 0.2 | accuracy: 0.34 | loss: 1.07
update:275/2000, 耗时:0.00分/0.75分 | step: 22000 | performance: 0.2 | accuracy: 0.34 | loss: 1.18
update:280/2000, 耗时:0.00分/0.76分 | step: 22400 | performance: 0.1 | accuracy: 0.33 | loss: 1.58
update:285/2000, 耗时:0.00分/0.77分 | step: 22800 | performance: 0.1 | accuracy: 0.33 | loss: 1.29
update:290/2000, 耗时:0.00分/0.79分 | step: 23200 | performance: 0.1 | accuracy: 0.33 | loss: 0.69
update:295/2000, 耗时:0.00分/0.80分 | step: 23600 | performance: 0.1 | accuracy: 0.33 | loss: 1.04
update:300/2000, 耗时:0.00分/0.81分 | step: 24000 | performance: 0.1 | accuracy: 0.33 | loss: 0.78
update:305/2000, 耗时:0.00分/0.83分 | step: 24400 | performance: 0.1 | accuracy: 0.33 | loss: 0.93
update:310/2000, 耗时:0.00分/0.84分 | step: 24800 | performance: 0.1 | accuracy: 0.33 | loss: 0.97
update:315/2000, 耗时:0.00分/0.85分 | step: 25200 | performance: 0.1 | accuracy: 0.33 | loss: 0.69
update:320/2000, 耗时:0.00分/0.87分 | step: 25600 | performance: 0.1 | accuracy: 0.33 | loss: 0.96
update:325/2000, 耗时:0.00分/0.88分 | step: 26000 | performance: 0.1 | accuracy: 0.33 | loss: 1.49
update:330/2000, 耗时:0.00分/0.90分 | step: 26400 | performance: 0.1 | accuracy: 0.33 | loss: 1.91
update:335/2000, 耗时:0.00分/0.91分 | step: 26800 | performance: 0.1 | accuracy: 0.33 | loss: 1.37
update:340/2000, 耗时:0.00分/0.92分 | step: 27200 | performance: 0.1 | accuracy: 0.33 | loss: 0.93
update:345/2000, 耗时:0.00分/0.94分 | step: 27600 | performance: 0.1 | accuracy: 0.33 | loss: 1.37
update:350/2000, 耗时:0.00分/0.95分 | step: 28000 | performance: 0.1 | accuracy: 0.33 | loss: 1.06
update:355/2000, 耗时:0.00分/0.96分 | step: 28400 | performance: 0.1 | accuracy: 0.33 | loss: 0.97
update:360/2000, 耗时:0.00分/0.98分 | step: 28800 | performance: 0.1 | accuracy: 0.33 | loss: 1.02
update:365/2000, 耗时:0.00分/0.99分 | step: 29200 | performance: 0.1 | accuracy: 0.33 | loss: 1.27
Saving PPO weights in both H5 format and checkpoint @ update:368 
update:370/2000, 耗时:0.00分/1.01分 | step: 29600 | performance: 0.8 | accuracy: 0.15 | loss: 0.75
Saving PPO weights in both H5 format and checkpoint @ update:371 
update:375/2000, 耗时:0.00分/1.03分 | step: 30000 | performance: 0.7 | accuracy: 0.22 | loss: 1.03
update:380/2000, 耗时:0.00分/1.04分 | step: 30400 | performance: 0.5 | accuracy: 0.19 | loss: 1.64
update:385/2000, 耗时:0.00分/1.05分 | step: 30800 | performance: 0.5 | accuracy: 0.21 | loss: 1.14
update:390/2000, 耗时:0.00分/1.06分 | step: 31200 | performance: 0.4 | accuracy: 0.22 | loss: 2.29
update:395/2000, 耗时:0.00分/1.08分 | step: 31600 | performance: 0.5 | accuracy: 0.27 | loss: 1.39
update:400/2000, 耗时:0.00分/1.09分 | step: 32000 | performance: 0.5 | accuracy: 0.29 | loss: 1.02
update:405/2000, 耗时:0.00分/1.10分 | step: 32400 | performance: 0.6 | accuracy: 0.30 | loss: 1.15
update:410/2000, 耗时:0.00分/1.12分 | step: 32800 | performance: 0.6 | accuracy: 0.29 | loss: 1.13
update:415/2000, 耗时:0.00分/1.13分 | step: 33200 | performance: 0.8 | accuracy: 0.28 | loss: 0.70
update:420/2000, 耗时:0.00分/1.14分 | step: 33600 | performance: 0.6 | accuracy: 0.27 | loss: 1.74
update:425/2000, 耗时:0.00分/1.16分 | step: 34000 | performance: 0.6 | accuracy: 0.28 | loss: 1.10
update:430/2000, 耗时:0.00分/1.17分 | step: 34400 | performance: 0.7 | accuracy: 0.29 | loss: 0.94
update:435/2000, 耗时:0.00分/1.18分 | step: 34800 | performance: 0.7 | accuracy: 0.29 | loss: 0.31
update:440/2000, 耗时:0.00分/1.20分 | step: 35200 | performance: 0.7 | accuracy: 0.29 | loss: 1.42
update:445/2000, 耗时:0.00分/1.21分 | step: 35600 | performance: 0.6 | accuracy: 0.29 | loss: 1.29
update:450/2000, 耗时:0.00分/1.23分 | step: 36000 | performance: 0.6 | accuracy: 0.30 | loss: 0.48
update:455/2000, 耗时:0.00分/1.24分 | step: 36400 | performance: 0.7 | accuracy: 0.30 | loss: 0.61
update:460/2000, 耗时:0.00分/1.25分 | step: 36800 | performance: 0.6 | accuracy: 0.30 | loss: 0.76
update:465/2000, 耗时:0.00分/1.27分 | step: 37200 | performance: 0.5 | accuracy: 0.30 | loss: 2.04
update:470/2000, 耗时:0.00分/1.28分 | step: 37600 | performance: 0.4 | accuracy: 0.30 | loss: 1.38
update:475/2000, 耗时:0.00分/1.29分 | step: 38000 | performance: 0.4 | accuracy: 0.30 | loss: 0.76
update:480/2000, 耗时:0.00分/1.31分 | step: 38400 | performance: 0.4 | accuracy: 0.29 | loss: 0.63
update:485/2000, 耗时:0.00分/1.32分 | step: 38800 | performance: 0.4 | accuracy: 0.29 | loss: 0.95
update:490/2000, 耗时:0.00分/1.33分 | step: 39200 | performance: 0.4 | accuracy: 0.29 | loss: 0.89
update:495/2000, 耗时:0.00分/1.35分 | step: 39600 | performance: 0.4 | accuracy: 0.28 | loss: 1.46
update:500/2000, 耗时:0.00分/1.36分 | step: 40000 | performance: 0.4 | accuracy: 0.28 | loss: 0.73
update:505/2000, 耗时:0.00分/1.38分 | step: 40400 | performance: 0.5 | accuracy: 0.29 | loss: 1.25
update:510/2000, 耗时:0.00分/1.39分 | step: 40800 | performance: 0.4 | accuracy: 0.28 | loss: 0.82
update:515/2000, 耗时:0.00分/1.40分 | step: 41200 | performance: 0.4 | accuracy: 0.29 | loss: 0.68
update:520/2000, 耗时:0.00分/1.42分 | step: 41600 | performance: 0.5 | accuracy: 0.29 | loss: 1.49
update:525/2000, 耗时:0.00分/1.43分 | step: 42000 | performance: 0.4 | accuracy: 0.29 | loss: 1.24
update:530/2000, 耗时:0.00分/1.44分 | step: 42400 | performance: 0.4 | accuracy: 0.28 | loss: 1.37
update:535/2000, 耗时:0.00分/1.45分 | step: 42800 | performance: 0.5 | accuracy: 0.28 | loss: 1.75
update:540/2000, 耗时:0.00分/1.47分 | step: 43200 | performance: 0.5 | accuracy: 0.28 | loss: 0.60
update:545/2000, 耗时:0.00分/1.48分 | step: 43600 | performance: 0.6 | accuracy: 0.28 | loss: 0.54
update:550/2000, 耗时:0.00分/1.50分 | step: 44000 | performance: 0.6 | accuracy: 0.29 | loss: 0.70
update:555/2000, 耗时:0.00分/1.51分 | step: 44400 | performance: 0.6 | accuracy: 0.29 | loss: 0.45
update:560/2000, 耗时:0.00分/1.52分 | step: 44800 | performance: 0.5 | accuracy: 0.29 | loss: 0.55
update:565/2000, 耗时:0.00分/1.54分 | step: 45200 | performance: 0.5 | accuracy: 0.29 | loss: 0.75
update:570/2000, 耗时:0.00分/1.55分 | step: 45600 | performance: 0.6 | accuracy: 0.29 | loss: 0.87
update:575/2000, 耗时:0.00分/1.56分 | step: 46000 | performance: 0.6 | accuracy: 0.29 | loss: 1.48
update:580/2000, 耗时:0.00分/1.58分 | step: 46400 | performance: 0.5 | accuracy: 0.28 | loss: 0.99
update:585/2000, 耗时:0.00分/1.59分 | step: 46800 | performance: 0.6 | accuracy: 0.28 | loss: 0.54
update:590/2000, 耗时:0.00分/1.61分 | step: 47200 | performance: 0.6 | accuracy: 0.28 | loss: 0.70
update:595/2000, 耗时:0.00分/1.62分 | step: 47600 | performance: 0.7 | accuracy: 0.28 | loss: 0.52
update:600/2000, 耗时:0.00分/1.63分 | step: 48000 | performance: 0.7 | accuracy: 0.27 | loss: 0.74
update:605/2000, 耗时:0.00分/1.65分 | step: 48400 | performance: 0.7 | accuracy: 0.27 | loss: 0.77
update:610/2000, 耗时:0.00分/1.66分 | step: 48800 | performance: 0.7 | accuracy: 0.27 | loss: 0.43
update:615/2000, 耗时:0.00分/1.68分 | step: 49200 | performance: 0.7 | accuracy: 0.27 | loss: 0.60
update:620/2000, 耗时:0.00分/1.69分 | step: 49600 | performance: 0.8 | accuracy: 0.27 | loss: 2.24
update:625/2000, 耗时:0.00分/1.70分 | step: 50000 | performance: 0.8 | accuracy: 0.27 | loss: 1.01
update:630/2000, 耗时:0.00分/1.72分 | step: 50400 | performance: 0.7 | accuracy: 0.28 | loss: 1.42
update:635/2000, 耗时:0.00分/1.73分 | step: 50800 | performance: 0.8 | accuracy: 0.28 | loss: 1.72
update:640/2000, 耗时:0.00分/1.75分 | step: 51200 | performance: 0.9 | accuracy: 0.28 | loss: 0.42
update:645/2000, 耗时:0.00分/1.76分 | step: 51600 | performance: 0.9 | accuracy: 0.27 | loss: 0.51
update:650/2000, 耗时:0.00分/1.77分 | step: 52000 | performance: 0.9 | accuracy: 0.27 | loss: 0.37
update:655/2000, 耗时:0.00分/1.79分 | step: 52400 | performance: 0.8 | accuracy: 0.27 | loss: 0.33
update:660/2000, 耗时:0.00分/1.80分 | step: 52800 | performance: 0.7 | accuracy: 0.27 | loss: 0.77
update:665/2000, 耗时:0.00分/1.82分 | step: 53200 | performance: 0.6 | accuracy: 0.27 | loss: 0.70
update:670/2000, 耗时:0.00分/1.83分 | step: 53600 | performance: 0.5 | accuracy: 0.27 | loss: 0.83
update:675/2000, 耗时:0.00分/1.84分 | step: 54000 | performance: 0.5 | accuracy: 0.27 | loss: 0.74
update:680/2000, 耗时:0.00分/1.86分 | step: 54400 | performance: 0.7 | accuracy: 0.27 | loss: 0.86
update:685/2000, 耗时:0.00分/1.87分 | step: 54800 | performance: 0.6 | accuracy: 0.27 | loss: 0.96
update:690/2000, 耗时:0.00分/1.89分 | step: 55200 | performance: 0.7 | accuracy: 0.27 | loss: 0.74
update:695/2000, 耗时:0.00分/1.90分 | step: 55600 | performance: 0.7 | accuracy: 0.27 | loss: 1.21
update:700/2000, 耗时:0.00分/1.91分 | step: 56000 | performance: 0.8 | accuracy: 0.27 | loss: 0.79
update:705/2000, 耗时:0.00分/1.93分 | step: 56400 | performance: 0.8 | accuracy: 0.27 | loss: 1.64
update:710/2000, 耗时:0.00分/1.94分 | step: 56800 | performance: 0.7 | accuracy: 0.27 | loss: 0.79
update:715/2000, 耗时:0.00分/1.96分 | step: 57200 | performance: 0.7 | accuracy: 0.27 | loss: 0.40
update:720/2000, 耗时:0.00分/1.97分 | step: 57600 | performance: 0.7 | accuracy: 0.27 | loss: 0.72
update:725/2000, 耗时:0.00分/1.98分 | step: 58000 | performance: 0.6 | accuracy: 0.27 | loss: 1.14
update:730/2000, 耗时:0.00分/2.00分 | step: 58400 | performance: 0.6 | accuracy: 0.27 | loss: 0.64
update:735/2000, 耗时:0.00分/2.01分 | step: 58800 | performance: 0.9 | accuracy: 0.00 | loss: 0.82
Saving PPO weights in both H5 format and checkpoint @ update:735 
step: 59195 | worker_2@n_step_9: average total_reward after train data exhaustion : 19.6 | max total_reward: 138.4
update:740/2000, 耗时:0.00分/2.03分 | step: 59200 | performance: 0.7 | accuracy: 0.16 | loss: 0.80
update:745/2000, 耗时:0.00分/2.04分 | step: 59600 | performance: 0.9 | accuracy: 0.20 | loss: 0.75
update:750/2000, 耗时:0.00分/2.06分 | step: 60000 | performance: 1.7 | accuracy: 0.25 | loss: 0.71
update:755/2000, 耗时:0.00分/2.07分 | step: 60400 | performance: 1.5 | accuracy: 0.26 | loss: 0.89
update:760/2000, 耗时:0.00分/2.09分 | step: 60800 | performance: 1.5 | accuracy: 0.25 | loss: 0.68
update:765/2000, 耗时:0.00分/2.10分 | step: 61200 | performance: 1.3 | accuracy: 0.24 | loss: 0.65
update:770/2000, 耗时:0.00分/2.12分 | step: 61600 | performance: 1.1 | accuracy: 0.24 | loss: 0.60
update:775/2000, 耗时:0.00分/2.13分 | step: 62000 | performance: 1.0 | accuracy: 0.24 | loss: 0.40
update:780/2000, 耗时:0.00分/2.14分 | step: 62400 | performance: 1.1 | accuracy: 0.24 | loss: 0.49
update:785/2000, 耗时:0.00分/2.16分 | step: 62800 | performance: 1.1 | accuracy: 0.23 | loss: 0.45
update:790/2000, 耗时:0.00分/2.17分 | step: 63200 | performance: 1.0 | accuracy: 0.23 | loss: 0.47
update:795/2000, 耗时:0.00分/2.19分 | step: 63600 | performance: 1.1 | accuracy: 0.23 | loss: 0.53
update:800/2000, 耗时:0.00分/2.20分 | step: 64000 | performance: 1.0 | accuracy: 0.23 | loss: 0.66
update:805/2000, 耗时:0.00分/2.22分 | step: 64400 | performance: 0.9 | accuracy: 0.22 | loss: 1.21
update:810/2000, 耗时:0.00分/2.23分 | step: 64800 | performance: 0.8 | accuracy: 0.21 | loss: 0.70
update:815/2000, 耗时:0.00分/2.25分 | step: 65200 | performance: 0.7 | accuracy: 0.20 | loss: 0.25
update:820/2000, 耗时:0.00分/2.26分 | step: 65600 | performance: 0.7 | accuracy: 0.20 | loss: 0.52
update:825/2000, 耗时:0.00分/2.27分 | step: 66000 | performance: 0.8 | accuracy: 0.20 | loss: 0.42
update:830/2000, 耗时:0.00分/2.29分 | step: 66400 | performance: 0.8 | accuracy: 0.20 | loss: 0.50
update:835/2000, 耗时:0.00分/2.30分 | step: 66800 | performance: 0.9 | accuracy: 0.20 | loss: 0.56
update:840/2000, 耗时:0.00分/2.32分 | step: 67200 | performance: 0.8 | accuracy: 0.20 | loss: 0.37
update:845/2000, 耗时:0.00分/2.33分 | step: 67600 | performance: 0.8 | accuracy: 0.19 | loss: 0.28
update:850/2000, 耗时:0.00分/2.35分 | step: 68000 | performance: 0.9 | accuracy: 0.19 | loss: 0.33
update:855/2000, 耗时:0.00分/2.36分 | step: 68400 | performance: 0.8 | accuracy: 0.19 | loss: 0.37
update:860/2000, 耗时:0.00分/2.38分 | step: 68800 | performance: 0.8 | accuracy: 0.19 | loss: 0.39
update:865/2000, 耗时:0.00分/2.39分 | step: 69200 | performance: 0.8 | accuracy: 0.19 | loss: 0.35
update:870/2000, 耗时:0.00分/2.40分 | step: 69600 | performance: 0.9 | accuracy: 0.19 | loss: 0.27
update:875/2000, 耗时:0.00分/2.42分 | step: 70000 | performance: 0.9 | accuracy: 0.19 | loss: 0.52
update:880/2000, 耗时:0.00分/2.43分 | step: 70400 | performance: 0.9 | accuracy: 0.19 | loss: 0.29
update:885/2000, 耗时:0.00分/2.44分 | step: 70800 | performance: 0.9 | accuracy: 0.19 | loss: 0.29
update:890/2000, 耗时:0.00分/2.45分 | step: 71200 | performance: 1.0 | accuracy: 0.19 | loss: 0.22
update:895/2000, 耗时:0.00分/2.47分 | step: 71600 | performance: 1.1 | accuracy: 0.19 | loss: 0.48
update:900/2000, 耗时:0.00分/2.48分 | step: 72000 | performance: 0.9 | accuracy: 0.19 | loss: 0.51
update:905/2000, 耗时:0.00分/2.49分 | step: 72400 | performance: 0.9 | accuracy: 0.18 | loss: 0.40
update:910/2000, 耗时:0.00分/2.51分 | step: 72800 | performance: 0.9 | accuracy: 0.18 | loss: 0.11
update:915/2000, 耗时:0.00分/2.52分 | step: 73200 | performance: 0.9 | accuracy: 0.18 | loss: 0.17
update:920/2000, 耗时:0.00分/2.53分 | step: 73600 | performance: 0.9 | accuracy: 0.17 | loss: 0.26
update:925/2000, 耗时:0.00分/2.54分 | step: 74000 | performance: 0.8 | accuracy: 0.17 | loss: 0.21
update:930/2000, 耗时:0.00分/2.56分 | step: 74400 | performance: 0.9 | accuracy: 0.17 | loss: 0.11
update:935/2000, 耗时:0.00分/2.57分 | step: 74800 | performance: 0.9 | accuracy: 0.17 | loss: 0.24
update:940/2000, 耗时:0.00分/2.58分 | step: 75200 | performance: 0.9 | accuracy: 0.17 | loss: 0.20
update:945/2000, 耗时:0.00分/2.60分 | step: 75600 | performance: 0.9 | accuracy: 0.17 | loss: 0.24
update:950/2000, 耗时:0.00分/2.61分 | step: 76000 | performance: 0.8 | accuracy: 0.16 | loss: 0.19
update:955/2000, 耗时:0.00分/2.63分 | step: 76400 | performance: 0.8 | accuracy: 0.16 | loss: 0.20
update:960/2000, 耗时:0.00分/2.64分 | step: 76800 | performance: 1.0 | accuracy: 0.16 | loss: 0.31
update:965/2000, 耗时:0.00分/2.65分 | step: 77200 | performance: 1.0 | accuracy: 0.16 | loss: 0.39
update:970/2000, 耗时:0.00分/2.67分 | step: 77600 | performance: 1.0 | accuracy: 0.16 | loss: 0.39
update:975/2000, 耗时:0.00分/2.68分 | step: 78000 | performance: 1.1 | accuracy: 0.16 | loss: 0.17
update:980/2000, 耗时:0.00分/2.69分 | step: 78400 | performance: 1.1 | accuracy: 0.15 | loss: 0.21
update:985/2000, 耗时:0.00分/2.71分 | step: 78800 | performance: 1.0 | accuracy: 0.15 | loss: 0.12
update:990/2000, 耗时:0.00分/2.72分 | step: 79200 | performance: 1.0 | accuracy: 0.15 | loss: 0.28
update:995/2000, 耗时:0.00分/2.73分 | step: 79600 | performance: 1.0 | accuracy: 0.15 | loss: 0.11
update:1000/2000, 耗时:0.00分/2.75分 | step: 80000 | performance: 1.0 | accuracy: 0.15 | loss: 0.15
update:1005/2000, 耗时:0.00分/2.76分 | step: 80400 | performance: 1.0 | accuracy: 0.15 | loss: 0.12
update:1010/2000, 耗时:0.00分/2.77分 | step: 80800 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
update:1015/2000, 耗时:0.00分/2.79分 | step: 81200 | performance: 1.1 | accuracy: 0.14 | loss: 0.20
update:1020/2000, 耗时:0.00分/2.80分 | step: 81600 | performance: 1.1 | accuracy: 0.14 | loss: 0.17
update:1025/2000, 耗时:0.00分/2.82分 | step: 82000 | performance: 1.1 | accuracy: 0.14 | loss: 0.21
update:1030/2000, 耗时:0.00分/2.83分 | step: 82400 | performance: 1.1 | accuracy: 0.14 | loss: 0.11
update:1035/2000, 耗时:0.00分/2.85分 | step: 82800 | performance: 1.1 | accuracy: 0.14 | loss: 0.09
update:1040/2000, 耗时:0.00分/2.86分 | step: 83200 | performance: 1.0 | accuracy: 0.14 | loss: 0.23
update:1045/2000, 耗时:0.00分/2.88分 | step: 83600 | performance: 1.0 | accuracy: 0.13 | loss: 0.25
update:1050/2000, 耗时:0.00分/2.89分 | step: 84000 | performance: 1.0 | accuracy: 0.13 | loss: 0.06
update:1055/2000, 耗时:0.00分/2.91分 | step: 84400 | performance: 1.0 | accuracy: 0.13 | loss: 0.18
update:1060/2000, 耗时:0.00分/2.92分 | step: 84800 | performance: 1.0 | accuracy: 0.13 | loss: 0.26
update:1065/2000, 耗时:0.00分/2.94分 | step: 85200 | performance: 0.9 | accuracy: 0.13 | loss: 0.15
update:1070/2000, 耗时:0.00分/2.95分 | step: 85600 | performance: 1.0 | accuracy: 0.13 | loss: 0.12
update:1075/2000, 耗时:0.00分/2.97分 | step: 86000 | performance: 1.0 | accuracy: 0.13 | loss: 0.10
update:1080/2000, 耗时:0.00分/2.98分 | step: 86400 | performance: 1.0 | accuracy: 0.13 | loss: 0.15
update:1085/2000, 耗时:0.00分/3.00分 | step: 86800 | performance: 1.0 | accuracy: 0.13 | loss: 0.15
update:1090/2000, 耗时:0.00分/3.01分 | step: 87200 | performance: 1.0 | accuracy: 0.13 | loss: 0.10
update:1095/2000, 耗时:0.00分/3.03分 | step: 87600 | performance: 1.0 | accuracy: 0.12 | loss: 0.24
update:1100/2000, 耗时:0.00分/3.04分 | step: 88000 | performance: 1.0 | accuracy: 0.12 | loss: 0.08
Saving PPO weights in both H5 format and checkpoint @ update:1103 
Saving PPO weights in both H5 format and checkpoint @ update:1104 
update:1105/2000, 耗时:0.00分/3.06分 | step: 88400 | performance: 1.1 | accuracy: 0.14 | loss: 0.22
Saving PPO weights in both H5 format and checkpoint @ update:1105 
step: 88474 | worker_1@n_step_9: average total_reward after train data exhaustion : 47.2 | max total_reward: 211.9
step: 88480 | worker_7@n_step_9: average total_reward after train data exhaustion : 46.0 | max total_reward: 211.9
update:1110/2000, 耗时:0.00分/3.08分 | step: 88800 | performance: 1.0 | accuracy: 0.17 | loss: 0.07
step: 89195 | worker_2@n_step_9: average total_reward after train data exhaustion : 14.7 | max total_reward: 211.9
update:1115/2000, 耗时:0.00分/3.10分 | step: 89200 | performance: 1.0 | accuracy: 1.00 | loss: 0.09
step: 89596 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.6 | max total_reward: 211.9
step: 89599 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.6 | max total_reward: 211.9
step: 89600 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.6 | max total_reward: 211.9
update:1120/2000, 耗时:0.00分/3.11分 | step: 89600 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 89834 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 89838 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 211.9
update:1125/2000, 耗时:0.00分/3.12分 | step: 90000 | performance: 1.0 | accuracy: 0.12 | loss: 0.08
update:1130/2000, 耗时:0.00分/3.14分 | step: 90400 | performance: 1.0 | accuracy: 0.14 | loss: 0.14
step: 90480 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 90553 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 90555 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 90716 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 90717 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 90799 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
update:1135/2000, 耗时:0.00分/3.15分 | step: 90800 | performance: 1.0 | accuracy: 0.17 | loss: 0.07
step: 90954 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 91198 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 211.9
update:1140/2000, 耗时:0.00分/3.17分 | step: 91200 | performance: 1.0 | accuracy: 1.00 | loss: 0.05
step: 91600 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1145/2000, 耗时:0.00分/3.18分 | step: 91600 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 91836 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 91915 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 91919 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1150/2000, 耗时:0.00分/3.20分 | step: 92000 | performance: 1.0 | accuracy: 0.06 | loss: 0.08
step: 92077 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 92078 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 92233 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1155/2000, 耗时:0.00分/3.21分 | step: 92400 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
update:1160/2000, 耗时:0.00分/3.22分 | step: 92800 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 92957 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 93196 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1165/2000, 耗时:0.00分/3.24分 | step: 93200 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 93275 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 93279 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 93434 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 93438 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 93593 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1170/2000, 耗时:0.00分/3.25分 | step: 93600 | performance: 1.0 | accuracy: 0.25 | loss: 0.03
step: 93840 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1175/2000, 耗时:0.00分/3.27分 | step: 94000 | performance: 1.0 | accuracy: 0.33 | loss: 0.07
step: 94077 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1180/2000, 耗时:0.00分/3.28分 | step: 94400 | performance: 1.0 | accuracy: 0.50 | loss: 0.04
step: 94556 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 94635 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 94639 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 94794 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 94798 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1185/2000, 耗时:0.00分/3.29分 | step: 94800 | performance: 1.0 | accuracy: 1.00 | loss: 0.03
step: 94953 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 95200 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
update:1190/2000, 耗时:0.00分/3.31分 | step: 95200 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 95437 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
update:1195/2000, 耗时:0.00分/3.32分 | step: 95600 | performance: 1.0 | accuracy: 0.06 | loss: 0.02
step: 95916 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 95995 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 95999 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1200/2000, 耗时:0.00分/3.34分 | step: 96000 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
step: 96154 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 96158 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 96313 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1205/2000, 耗时:0.00分/3.35分 | step: 96400 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
step: 96560 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 96797 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1210/2000, 耗时:0.00分/3.36分 | step: 96800 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
update:1215/2000, 耗时:0.00分/3.38分 | step: 97200 | performance: 1.0 | accuracy: 0.08 | loss: 0.01
step: 97276 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 97355 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 97359 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 97514 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 97518 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1220/2000, 耗时:0.00分/3.39分 | step: 97600 | performance: 1.0 | accuracy: 0.09 | loss: 0.02
step: 97673 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 97920 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1225/2000, 耗时:0.00分/3.41分 | step: 98000 | performance: 1.0 | accuracy: 0.10 | loss: 0.03
step: 98157 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1230/2000, 耗时:0.00分/3.42分 | step: 98400 | performance: 1.0 | accuracy: 0.11 | loss: 0.04
step: 98479 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 98636 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 98715 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1235/2000, 耗时:0.00分/3.43分 | step: 98800 | performance: 1.0 | accuracy: 0.12 | loss: 0.04
step: 98878 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 99033 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1240/2000, 耗时:0.00分/3.45分 | step: 99200 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
update:1245/2000, 耗时:0.00分/3.46分 | step: 99600 | performance: 1.0 | accuracy: 0.50 | loss: 0.05
step: 99839 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 99996 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1250/2000, 耗时:0.00分/3.48分 | step: 100000 | performance: 1.0 | accuracy: 1.00 | loss: 0.04
step: 100153 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 100238 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 100400 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1255/2000, 耗时:0.00分/3.49分 | step: 100400 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 100637 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1260/2000, 耗时:0.00分/3.50分 | step: 100800 | performance: 1.0 | accuracy: 0.06 | loss: 0.02
step: 100955 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 101114 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 101199 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1265/2000, 耗时:0.00分/3.52分 | step: 101200 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
step: 101273 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 101356 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 101358 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1270/2000, 耗时:0.00分/3.53分 | step: 101600 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
step: 101760 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 101997 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1275/2000, 耗时:0.00分/3.55分 | step: 102000 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 102234 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 102315 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1280/2000, 耗时:0.00分/3.56分 | step: 102400 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 102476 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 102559 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 102633 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 102718 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1285/2000, 耗时:0.00分/3.57分 | step: 102800 | performance: 1.0 | accuracy: 0.09 | loss: 0.03
step: 103120 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1290/2000, 耗时:0.00分/3.59分 | step: 103200 | performance: 1.0 | accuracy: 0.10 | loss: 0.04
step: 103357 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 103435 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1295/2000, 耗时:0.00分/3.60分 | step: 103600 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 103836 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 103919 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1300/2000, 耗时:0.00分/3.62分 | step: 104000 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 104078 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1305/2000, 耗时:0.00分/3.63分 | step: 104400 | performance: 1.0 | accuracy: 0.14 | loss: 0.03
step: 104480 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 104714 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 104717 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 104795 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1310/2000, 耗时:0.00分/3.64分 | step: 104800 | performance: 1.0 | accuracy: 0.50 | loss: 0.04
step: 105113 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 105196 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1315/2000, 耗时:0.00分/3.66分 | step: 105200 | performance: 1.0 | accuracy: 1.00 | loss: 0.04
step: 105279 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 105600 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1320/2000, 耗时:0.00分/3.67分 | step: 105600 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 105915 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1325/2000, 耗时:0.00分/3.68分 | step: 106000 | performance: 1.0 | accuracy: 0.06 | loss: 0.03
step: 106077 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 106399 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1330/2000, 耗时:0.00分/3.70分 | step: 106400 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
step: 106556 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 106558 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1335/2000, 耗时:0.00分/3.71分 | step: 106800 | performance: 1.0 | accuracy: 0.07 | loss: 0.03
step: 106960 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 107194 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1340/2000, 耗时:0.00分/3.72分 | step: 107200 | performance: 1.0 | accuracy: 0.08 | loss: 0.03
step: 107275 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 107437 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 107519 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1345/2000, 耗时:0.00分/3.74分 | step: 107600 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 107678 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 107916 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1350/2000, 耗时:0.00分/3.75分 | step: 108000 | performance: 0.9 | accuracy: 0.09 | loss: 0.07
step: 108320 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1355/2000, 耗时:0.00分/3.77分 | step: 108400 | performance: 1.0 | accuracy: 0.10 | loss: 0.03
step: 108554 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 108557 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 108635 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 108713 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1360/2000, 耗时:0.00分/3.78分 | step: 108800 | performance: 1.0 | accuracy: 0.11 | loss: 0.04
step: 109038 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1365/2000, 耗时:0.00分/3.79分 | step: 109200 | performance: 1.0 | accuracy: 0.12 | loss: 0.03
update:1370/2000, 耗时:0.00分/3.81分 | step: 109600 | performance: 1.0 | accuracy: 0.14 | loss: 0.11
step: 109680 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 109755 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 109759 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 109833 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 109914 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 109917 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1375/2000, 耗时:0.00分/3.82分 | step: 110000 | performance: 1.0 | accuracy: 0.17 | loss: 0.07
step: 110396 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 110398 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1380/2000, 耗时:0.00分/3.83分 | step: 110400 | performance: 1.0 | accuracy: 0.20 | loss: 0.03
update:1385/2000, 耗时:0.00分/3.85分 | step: 110800 | performance: 1.0 | accuracy: 0.25 | loss: 0.07
step: 110875 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 110953 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 111040 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 111114 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 111119 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1390/2000, 耗时:0.00分/3.86分 | step: 111200 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 111277 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 111516 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1395/2000, 耗时:0.00分/3.87分 | step: 111600 | performance: 1.0 | accuracy: 0.50 | loss: 0.04
step: 111758 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 111995 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1400/2000, 耗时:0.00分/3.89分 | step: 112000 | performance: 0.9 | accuracy: 0.07 | loss: 0.07
step: 112160 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 112234 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 112239 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 112313 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 112397 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1405/2000, 耗时:0.00分/3.90分 | step: 112400 | performance: 1.0 | accuracy: 0.08 | loss: 0.03
step: 112636 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1410/2000, 耗时:0.00分/3.92分 | step: 112800 | performance: 1.0 | accuracy: 0.08 | loss: 0.03
step: 113118 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1415/2000, 耗时:0.00分/3.93分 | step: 113200 | performance: 1.1 | accuracy: 0.11 | loss: 0.06
step: 113355 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 113360 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 113513 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 113594 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1420/2000, 耗时:0.00分/3.94分 | step: 113600 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 113757 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 113996 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1425/2000, 耗时:0.00分/3.96分 | step: 114000 | performance: 1.0 | accuracy: 0.08 | loss: 0.01
step: 114238 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1430/2000, 耗时:0.00分/3.97分 | step: 114400 | performance: 1.0 | accuracy: 0.09 | loss: 0.02
step: 114480 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 114715 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 114719 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1435/2000, 耗时:0.00分/3.98分 | step: 114800 | performance: 1.0 | accuracy: 0.17 | loss: 0.12
step: 114873 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 114877 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1440/2000, 耗时:0.00分/4.00分 | step: 115200 | performance: 1.1 | accuracy: 0.11 | loss: 0.05
step: 115276 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 115358 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 115360 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1445/2000, 耗时:0.00分/4.01分 | step: 115600 | performance: 1.0 | accuracy: 0.08 | loss: 0.11
step: 115835 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 115993 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 115994 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 115997 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1450/2000, 耗时:0.00分/4.02分 | step: 116000 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 116238 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 116396 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1455/2000, 耗时:0.00分/4.04分 | step: 116400 | performance: 1.0 | accuracy: 0.09 | loss: 0.01
step: 116715 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 116719 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 116720 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1460/2000, 耗时:0.00分/4.05分 | step: 116800 | performance: 1.0 | accuracy: 0.10 | loss: 0.07
step: 117113 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 117117 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1465/2000, 耗时:0.00分/4.06分 | step: 117200 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
step: 117516 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 117598 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1470/2000, 耗时:0.00分/4.08分 | step: 117600 | performance: 1.0 | accuracy: 0.25 | loss: 0.08
step: 117679 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 117840 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1475/2000, 耗时:0.00分/4.09分 | step: 118000 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 118075 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 118154 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 118233 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 118237 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1480/2000, 耗时:0.00分/4.11分 | step: 118400 | performance: 1.0 | accuracy: 0.50 | loss: 0.06
step: 118559 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1485/2000, 耗时:0.00分/4.12分 | step: 118800 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
step: 118958 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 118960 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 119034 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 119195 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1490/2000, 耗时:0.00分/4.13分 | step: 119200 | performance: 0.9 | accuracy: 0.08 | loss: 0.15
step: 119353 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 119437 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 119439 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1495/2000, 耗时:0.00分/4.15分 | step: 119600 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 119836 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 119914 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1500/2000, 耗时:0.00分/4.16分 | step: 120000 | performance: 1.0 | accuracy: 0.09 | loss: 0.04
step: 120315 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 120319 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1505/2000, 耗时:0.00分/4.17分 | step: 120400 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
step: 120713 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 120716 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1510/2000, 耗时:0.00分/4.19分 | step: 120800 | performance: 1.0 | accuracy: 0.40 | loss: 0.18
step: 120958 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 121034 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 121200 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1515/2000, 耗时:0.00分/4.20分 | step: 121200 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 121435 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1520/2000, 耗时:0.00分/4.21分 | step: 121600 | performance: 1.1 | accuracy: 0.17 | loss: 0.11
step: 121833 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 121840 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 121914 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 121919 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1525/2000, 耗时:0.00分/4.23分 | step: 122000 | performance: 1.0 | accuracy: 0.10 | loss: 0.22
step: 122078 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 122395 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1530/2000, 耗时:0.00分/4.24分 | step: 122400 | performance: 1.1 | accuracy: 0.14 | loss: 0.12
step: 122476 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 122557 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 122633 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 122720 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1535/2000, 耗时:0.00分/4.25分 | step: 122800 | performance: 1.0 | accuracy: 0.10 | loss: 0.20
step: 122879 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1540/2000, 耗时:0.00分/4.27分 | step: 123200 | performance: 1.0 | accuracy: 1.00 | loss: 0.13
step: 123277 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 211.9
step: 123515 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 123516 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1545/2000, 耗时:0.00分/4.28分 | step: 123600 | performance: 1.2 | accuracy: 0.15 | loss: 0.17
step: 123838 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1550/2000, 耗时:0.00分/4.29分 | step: 124000 | performance: 1.0 | accuracy: 0.12 | loss: 0.12
step: 124313 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1555/2000, 耗时:0.00分/4.31分 | step: 124400 | performance: 1.0 | accuracy: 0.12 | loss: 0.29
step: 124556 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 124798 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1560/2000, 耗时:0.00分/4.32分 | step: 124800 | performance: 1.0 | accuracy: 0.50 | loss: 0.07
update:1565/2000, 耗时:0.00分/4.33分 | step: 125200 | performance: 1.1 | accuracy: 0.12 | loss: 0.06
step: 125355 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1570/2000, 耗时:0.00分/4.35分 | step: 125600 | performance: 1.8 | accuracy: 0.14 | loss: 0.21
update:1575/2000, 耗时:0.00分/4.36分 | step: 126000 | performance: 1.8 | accuracy: 0.13 | loss: 0.24
step: 126075 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1580/2000, 耗时:0.00分/4.37分 | step: 126400 | performance: 1.7 | accuracy: 0.11 | loss: 0.34
step: 126478 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 126559 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1585/2000, 耗时:0.00分/4.39分 | step: 126800 | performance: 1.7 | accuracy: 0.11 | loss: 0.16
update:1590/2000, 耗时:0.00分/4.40分 | step: 127200 | performance: 0.9 | accuracy: 0.18 | loss: 0.13
step: 127280 | worker_7@n_step_9: average total_reward after train data exhaustion : 2.2 | max total_reward: 211.9
step: 127353 | worker_0@n_step_9: average total_reward after train data exhaustion : 2.2 | max total_reward: 211.9
step: 127596 | worker_3@n_step_9: average total_reward after train data exhaustion : 2.2 | max total_reward: 211.9
update:1595/2000, 耗时:0.00分/4.42分 | step: 127600 | performance: 1.0 | accuracy: 0.50 | loss: 0.30
update:1600/2000, 耗时:0.00分/4.43分 | step: 128000 | performance: 1.0 | accuracy: 0.09 | loss: 0.16
step: 128394 | worker_1@n_step_9: average total_reward after train data exhaustion : 2.3 | max total_reward: 211.9
update:1605/2000, 耗时:0.00分/4.44分 | step: 128400 | performance: 1.7 | accuracy: 0.23 | loss: 0.11
step: 128638 | worker_5@n_step_9: average total_reward after train data exhaustion : 2.2 | max total_reward: 211.9
update:1610/2000, 耗时:0.00分/4.46分 | step: 128800 | performance: 1.6 | accuracy: 0.13 | loss: 0.22
step: 128876 | worker_3@n_step_9: average total_reward after train data exhaustion : 2.0 | max total_reward: 211.9
step: 129117 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1615/2000, 耗时:0.00分/4.47分 | step: 129200 | performance: 1.5 | accuracy: 0.10 | loss: 0.23
step: 129515 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 211.9
update:1620/2000, 耗时:0.00分/4.48分 | step: 129600 | performance: 1.0 | accuracy: 0.33 | loss: 0.20
step: 129673 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 211.9
update:1625/2000, 耗时:0.00分/4.50分 | step: 130000 | performance: 1.0 | accuracy: 0.09 | loss: 0.17
update:1630/2000, 耗时:0.00分/4.51分 | step: 130400 | performance: 0.9 | accuracy: 0.13 | loss: 0.21
step: 130476 | worker_3@n_step_9: average total_reward after train data exhaustion : 2.0 | max total_reward: 211.9
step: 130717 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 211.9
update:1635/2000, 耗时:0.00分/4.53分 | step: 130800 | performance: 1.0 | accuracy: 1.00 | loss: 0.26
step: 131120 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 211.9
update:1640/2000, 耗时:0.00分/4.54分 | step: 131200 | performance: 1.1 | accuracy: 0.20 | loss: 0.23
step: 131594 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 211.9
update:1645/2000, 耗时:0.00分/4.55分 | step: 131600 | performance: 1.1 | accuracy: 0.12 | loss: 0.53
step: 131759 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
update:1650/2000, 耗时:0.00分/4.57分 | step: 132000 | performance: 1.0 | accuracy: 0.17 | loss: 0.25
step: 132398 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1655/2000, 耗时:0.00分/4.58分 | step: 132400 | performance: 1.1 | accuracy: 0.29 | loss: 0.24
step: 132474 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 211.9
step: 132559 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 211.9
update:1660/2000, 耗时:0.00分/4.59分 | step: 132800 | performance: 1.2 | accuracy: 0.15 | loss: 0.29
update:1665/2000, 耗时:0.00分/4.61分 | step: 133200 | performance: 1.4 | accuracy: 0.12 | loss: 0.25
step: 133594 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
update:1670/2000, 耗时:0.00分/4.62分 | step: 133600 | performance: 1.3 | accuracy: 0.10 | loss: 0.29
step: 133833 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 211.9
step: 133999 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 211.9
update:1675/2000, 耗时:0.00分/4.63分 | step: 134000 | performance: 1.2 | accuracy: 0.15 | loss: 0.19
update:1680/2000, 耗时:0.00分/4.65分 | step: 134400 | performance: 0.9 | accuracy: 0.07 | loss: 0.35
step: 134473 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 134639 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 211.9
step: 134797 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 211.9
update:1685/2000, 耗时:0.00分/4.66分 | step: 134800 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
step: 134874 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 211.9
update:1690/2000, 耗时:0.00分/4.67分 | step: 135200 | performance: 1.0 | accuracy: 1.00 | loss: 0.21
step: 135353 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 135360 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 135435 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 135599 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 211.9
update:1695/2000, 耗时:0.00分/4.69分 | step: 135600 | performance: 1.0 | accuracy: 0.08 | loss: 0.12
step: 135917 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 135918 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 136000 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1700/2000, 耗时:0.00分/4.70分 | step: 136000 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
update:1705/2000, 耗时:0.00分/4.72分 | step: 136400 | performance: 1.1 | accuracy: 0.16 | loss: 0.18
step: 136718 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
update:1710/2000, 耗时:0.00分/4.73分 | step: 136800 | performance: 1.4 | accuracy: 0.14 | loss: 0.24
step: 136953 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 137195 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1715/2000, 耗时:0.00分/4.74分 | step: 137200 | performance: 1.4 | accuracy: 0.12 | loss: 0.17
update:1720/2000, 耗时:0.00分/4.76分 | step: 137600 | performance: 1.2 | accuracy: 0.12 | loss: 0.23
step: 137917 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1725/2000, 耗时:0.00分/4.77分 | step: 138000 | performance: 1.3 | accuracy: 0.11 | loss: 0.25
step: 138159 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1730/2000, 耗时:0.00分/4.78分 | step: 138400 | performance: 1.0 | accuracy: 1.00 | loss: 0.13
step: 138560 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 211.9
update:1735/2000, 耗时:0.00分/4.80分 | step: 138800 | performance: 0.9 | accuracy: 0.11 | loss: 0.28
update:1740/2000, 耗时:0.00分/4.81分 | step: 139200 | performance: 1.0 | accuracy: 0.25 | loss: 0.21
update:1745/2000, 耗时:0.00分/4.83分 | step: 139600 | performance: 0.9 | accuracy: 0.23 | loss: 0.40
step: 139755 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 211.9
update:1750/2000, 耗时:0.00分/4.84分 | step: 140000 | performance: 1.0 | accuracy: 0.00 | loss: 0.27
step: 140316 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 140400 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1755/2000, 耗时:0.00分/4.85分 | step: 140400 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
step: 140795 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1760/2000, 耗时:0.00分/4.87分 | step: 140800 | performance: 1.0 | accuracy: 0.14 | loss: 0.16
step: 141113 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1765/2000, 耗时:0.00分/4.88分 | step: 141200 | performance: 1.0 | accuracy: 0.50 | loss: 0.16
step: 141276 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 141435 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1770/2000, 耗时:0.00分/4.89分 | step: 141600 | performance: 1.0 | accuracy: 0.07 | loss: 0.12
update:1775/2000, 耗时:0.00分/4.91分 | step: 142000 | performance: 1.0 | accuracy: 0.15 | loss: 0.23
update:1780/2000, 耗时:0.00分/4.92分 | step: 142400 | performance: 1.2 | accuracy: 0.11 | loss: 0.13
step: 142555 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 211.9
step: 142556 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 211.9
update:1785/2000, 耗时:0.00分/4.93分 | step: 142800 | performance: 1.1 | accuracy: 0.25 | loss: 0.17
step: 142953 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 211.9
update:1790/2000, 耗时:0.00分/4.95分 | step: 143200 | performance: 1.0 | accuracy: 0.07 | loss: 0.18
step: 143360 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 143516 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 143519 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1795/2000, 耗时:0.00分/4.96分 | step: 143600 | performance: 1.0 | accuracy: 0.11 | loss: 0.04
step: 143833 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1800/2000, 耗时:0.00分/4.97分 | step: 144000 | performance: 1.0 | accuracy: 0.25 | loss: 0.14
step: 144394 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
update:1805/2000, 耗时:0.00分/4.99分 | step: 144400 | performance: 1.0 | accuracy: 0.12 | loss: 0.08
step: 144473 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 144637 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
update:1810/2000, 耗时:0.00分/5.00分 | step: 144800 | performance: 1.0 | accuracy: 0.12 | loss: 0.29
step: 145035 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 145120 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1815/2000, 耗时:0.00分/5.02分 | step: 145200 | performance: 1.0 | accuracy: 0.10 | loss: 0.17
step: 145517 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 145593 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
update:1820/2000, 耗时:0.00分/5.03分 | step: 145600 | performance: 1.0 | accuracy: 0.08 | loss: 0.06
step: 145918 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1825/2000, 耗时:0.00分/5.04分 | step: 146000 | performance: 1.0 | accuracy: 0.18 | loss: 0.13
step: 146154 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 146159 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 146160 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1830/2000, 耗时:0.00分/5.06分 | step: 146400 | performance: 1.1 | accuracy: 0.13 | loss: 0.21
step: 146798 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1835/2000, 耗时:0.00分/5.07分 | step: 146800 | performance: 1.0 | accuracy: 0.11 | loss: 0.06
step: 147034 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 147200 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
update:1840/2000, 耗时:0.00分/5.08分 | step: 147200 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 147437 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1845/2000, 耗时:0.00分/5.10分 | step: 147600 | performance: 0.9 | accuracy: 0.17 | loss: 0.19
step: 147675 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 147756 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1850/2000, 耗时:0.00分/5.11分 | step: 148000 | performance: 0.9 | accuracy: 0.07 | loss: 0.15
step: 148154 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
update:1855/2000, 耗时:0.00分/5.12分 | step: 148400 | performance: 1.2 | accuracy: 0.12 | loss: 0.17
step: 148473 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 148558 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 148716 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1860/2000, 耗时:0.00分/5.14分 | step: 148800 | performance: 1.0 | accuracy: 0.14 | loss: 0.09
step: 148880 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
update:1865/2000, 耗时:0.00分/5.15分 | step: 149200 | performance: 1.0 | accuracy: 0.50 | loss: 0.06
step: 149274 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 149357 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 149438 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 149593 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 211.9
update:1870/2000, 耗时:0.00分/5.17分 | step: 149600 | performance: 1.0 | accuracy: 1.00 | loss: 0.13
step: 149675 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 211.9
update:1875/2000, 耗时:0.00分/5.18分 | step: 150000 | performance: 1.1 | accuracy: 0.12 | loss: 0.08
step: 150159 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 150237 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 150318 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1880/2000, 耗时:0.00分/5.19分 | step: 150400 | performance: 1.1 | accuracy: 0.25 | loss: 0.27
step: 150473 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 150476 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 150640 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
update:1885/2000, 耗时:0.00分/5.21分 | step: 150800 | performance: 1.0 | accuracy: 0.33 | loss: 0.07
step: 151113 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
update:1890/2000, 耗时:0.00分/5.22分 | step: 151200 | performance: 1.0 | accuracy: 0.11 | loss: 0.13
step: 151438 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 151515 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 151597 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 151600 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1895/2000, 耗时:0.00分/5.23分 | step: 151600 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 151914 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1900/2000, 耗时:0.00分/5.25分 | step: 152000 | performance: 1.1 | accuracy: 0.10 | loss: 0.15
step: 152076 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 152398 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 211.9
update:1905/2000, 耗时:0.00分/5.26分 | step: 152400 | performance: 1.0 | accuracy: 0.07 | loss: 0.07
step: 152475 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 211.9
step: 152477 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 211.9
step: 152719 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
update:1910/2000, 耗时:0.00分/5.28分 | step: 152800 | performance: 1.2 | accuracy: 0.15 | loss: 0.17
step: 152874 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 153036 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 211.9
update:1915/2000, 耗时:0.00分/5.29分 | step: 153200 | performance: 1.0 | accuracy: 0.11 | loss: 0.22
step: 153515 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 153518 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 153520 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 153594 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 153597 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1920/2000, 耗时:0.00分/5.30分 | step: 153600 | performance: 1.0 | accuracy: 0.20 | loss: 0.16
step: 153673 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 153679 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1925/2000, 耗时:0.00分/5.32分 | step: 154000 | performance: 1.1 | accuracy: 0.11 | loss: 0.12
step: 154234 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1930/2000, 耗时:0.00分/5.33分 | step: 154400 | performance: 1.0 | accuracy: 0.11 | loss: 0.09
step: 154475 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 154559 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
step: 154793 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
update:1935/2000, 耗时:0.00分/5.34分 | step: 154800 | performance: 1.2 | accuracy: 0.50 | loss: 0.17
step: 154877 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 154956 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 211.9
step: 155194 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1940/2000, 耗时:0.00分/5.36分 | step: 155200 | performance: 1.0 | accuracy: 0.08 | loss: 0.08
step: 155517 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
step: 155518 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 155520 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 155595 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
update:1945/2000, 耗时:0.00分/5.37分 | step: 155600 | performance: 1.0 | accuracy: 0.10 | loss: 0.15
step: 155759 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1950/2000, 耗时:0.00分/5.38分 | step: 156000 | performance: 1.1 | accuracy: 0.12 | loss: 0.16
step: 156237 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
update:1955/2000, 耗时:0.00分/5.40分 | step: 156400 | performance: 1.0 | accuracy: 0.08 | loss: 0.08
step: 156640 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 211.9
step: 156716 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 211.9
update:1960/2000, 耗时:0.00分/5.41分 | step: 156800 | performance: 1.1 | accuracy: 0.15 | loss: 0.23
step: 157118 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 211.9
update:1965/2000, 耗时:0.00分/5.42分 | step: 157200 | performance: 1.0 | accuracy: 0.16 | loss: 0.33
step: 157355 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 211.9
update:1970/2000, 耗时:0.00分/5.44分 | step: 157600 | performance: 0.9 | accuracy: 0.12 | loss: 0.13
step: 157758 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 211.9
update:1975/2000, 耗时:0.00分/5.45分 | step: 158000 | performance: 1.2 | accuracy: 0.10 | loss: 0.14
step: 158320 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 211.9
step: 158399 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 211.9
update:1980/2000, 耗时:0.00分/5.46分 | step: 158400 | performance: 1.0 | accuracy: 0.10 | loss: 0.15
step: 158475 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 158633 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 158638 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
update:1985/2000, 耗时:0.00分/5.48分 | step: 158800 | performance: 1.0 | accuracy: 0.20 | loss: 0.26
step: 159037 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.6 | max total_reward: 211.9
update:1990/2000, 耗时:0.00分/5.49分 | step: 159200 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
step: 159278 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 211.9
step: 159359 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 211.9
update:1995/2000, 耗时:0.00分/5.50分 | step: 159600 | performance: 1.0 | accuracy: 0.06 | loss: 0.15
step: 159917 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 211.9
step: 159999 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 211.9
  0%|          | 0/403 [00:00<?, ?it/s]100%|| 403/403 [00:00<00:00, 134311.05it/s]
update:2000/2000, 耗时:0.00分/5.52分 | step: 160000 | performance: 0.9 | accuracy: 0.09 | loss: 0.19
----------------------------------------finished----------------------------------------
==================================================
2023-01-04T12:00:00 | *** START BACKTEST ***
2023-01-04T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1380.20
2023-07-24T12:00:00 | net performance [%] = 38.0202
2023-07-24T12:00:00 | number of trades [#] = 8
==================================================
Trial 3 Complete [00h 05m 57s]
net_wealth: 1380.2023481050508

Best net_wealth So Far: 1380.2023481050508
Total elapsed time: 00h 14m 00s

Search: Running Trial #4

Value             |Best Value So Far |Hyperparameter
4                 |1                 |horizon
365               |225               |lookback
False             |False             |MarketFactor
3                 |8                 |lags
0.85              |0.9               |gamma
16                |32                |batch_size
7                 |10                |n_step
0.96              |0.92              |gae_lambda
10                |2                 |gradient_clip_norm
5                 |3                 |epochs
0.001             |5e-05             |actor_lr
0.001             |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4311.000000   4315.000000
mean      0.000441    20062.255222  ...   20133.281642  20118.633889
std       0.027818    16039.874230  ...   16077.358923  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7695.614990   7690.540039
50%       0.000642    11554.824463  ...   11741.480469  11715.610352
75%       0.011655    29873.081836  ...   29939.474609  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
22023-07-27 22:17:22.202374155: I tensorflow/core/platform/cpu_feature_guard.cc:142] Thi2023-07-27 22:103-02s023-07-2273 7 T--e0n2sorFlow bi27-272n: 22:17:17 22:17:22.374175: 7:I222.2.374203 7tens6422o: I2rflow/co 7:22:. I te374150: I tensorflow/core/platform/cnary srie/sp u_platform/cpu_feature_guardfoptie.ccamt:1uizer42]ed t Thwiiths oenensA TPorIoflorf Deeenlow/wc/cosr_e/opolrFartlfgeoopw ubinar ard.cc:14y/plNeu2a 2] Thisi2 0Tens023r2m-0s7 /oraol rcFl-p2Ntfor37-tmiomize0e7tw-27/cdo r  2wk Lipiutbh_2featurr eon_e22::1gauA1PI72 D0eep a2rr:Neyura72:3222.- 0l7.(d 3N7eot-2n43p6687 .2u: 7we_owI 2rk 46c1L Dfeat:ct1e:17N: NIn ut742) s]t r:oorfe2_Th 2biesgi .unuslowasTreonnsaoi37b/dcry. cic4osr :rrFrlow1o4e2e tfal]/  pblh8oTwhpteim ifo02:ni zI/llar credy with  ooowiy rengniesA t (CPoepPo/nplIntea Deeps aUttfoioNriDNN)  mitnfsrlotirzufsw /cceoromemt/ucr/al cpNTetepwuoinoun_rs_orrefse fi/ekaF Lnpdl ow iatiholtatwp eurbfion  obnarremae_nutrryA igusauPrI fese _oguD etepheptr iNmeizyaoarrmu edf oldw.r/lcoit crpduwic:h(._fn1 42]oeneocc ga tCeca:l1nuPrUe D 4e2-N_NN)cTrhiinetis ttow gu]iocrkst TreauA PuTclt Io peDreaesp iet itohLi nhNiesu oTnasronrsF es bfroailne pa nlro:ry  (Nledr.ccwf osre tbliomraF:n1awnoc4er2A]VoX -ownyeDcArrikn gTi  iLibr NNlVatiryChPiXc2a
lTo wsU  si nsToo )( op tebreeoniuncanrsyr ttaine oipbaltis Doe  uooNrttsehonsFi mtihzeN l) p oftoe d eiwonlslmu s:toew i iinb iotn  mpht hAeViez erdf  wXi nfotrmha AVXo2o
oTonlelAanrwtheric yn eAPeIo woneaPbiipse roIl n-g  DCPateDeepUpi crtihen tg  eiocCPeNpem iU uNeuinsnt  inrsranostall raulctioo nNsh tir,eet imNuetntipw rp eorpfeoorczedti w kw irtmhrLoibrkr aaroenati obnnceLribres-yceuaiornarrlyd (oneD ( oTneeDNN Aist,iinns p)NPt erronosiecbuIN :   tAiVD)eepflal  oXdroFpletroaw owt i onAiV r NueTurtmha naclsoe sueensorFXs-tch:loe e  2a
pTpo rrt twh e enawi iftolbohteh l le Ntheifeotwwiontcoallg loopwmi nihrriga te ACVPXUne ap pirn pkAVesr   ot Xoapttihoe2n
LCriurPrcsT:o b rictoea ryaiUo mi n(sonnpttse nea c oiroDANVmlupcNe)X b lAeratre Vtii Xtp2otfo la
Tniulernhse mig siofl . no sppiea
gee n  ernost.h
nsaerf,o rremaforrbntmanblcui loe thce-he-crite epm edf ollraiTcoticawinoenritsolig i coanrsF,npCPlUowl w r ebinuiitlde Te hsr nasor Ftttloroihuctions in performanpw wother icoentop-e eh s: critical o eratahppAVX AVXrropatperea tii2ons: trioi AVX 
oaAVX2ap
pTnnTtoos:  r se nA, rea cenaoble them piebVoX uibn othled TAVensr olX2
Tomr oenipilateerper aFlow witttih the ons,appropriate compehr flags.
able them in iler flotehm  in oeragsr.ther  ebuilcoped o Trationsm
,popenieratioler flag sns,roerb usiFlow wrle.b
uild TensorFlow with the appropriate compiler flags.
d TensorFlow with the appropriate compiler flags.
ith the appropriate compiler flags.
2023-07-27 22:17:23.027274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22023-07-27 22:17:23.029602:17:235: I tenso.029605r: I tensorflow/flow/core/common_runtime/gpu/gpu_dcore/common_runtevice.cc:i1510] Createmd device/eg /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> depu/gvice: 0, npau_devimec:e.cc:1 NVID51IA0] GeForce RT CrXe 3070, pci bus id: 0000:01ated:00.0, compute capability: 8.6 devic
e /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:17:23.031160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:17:23.053916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:17:23.067516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:17:23.068261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:17:23.078937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   280 | performance: 0.5 | accuracy: 0.34 | loss: 1.55
update: 10/2000, 耗时:0.00分/0.05分 | step:   560 | performance: 0.6 | accuracy: 0.36 | loss: 1.81
update: 15/2000, 耗时:0.00分/0.06分 | step:   840 | performance: 0.5 | accuracy: 0.34 | loss: 4.15
update: 20/2000, 耗时:0.00分/0.08分 | step:  1120 | performance: 0.3 | accuracy: 0.34 | loss: 1.63
update: 25/2000, 耗时:0.00分/0.09分 | step:  1400 | performance: 0.6 | accuracy: 0.36 | loss: 2.64
update: 30/2000, 耗时:0.00分/0.10分 | step:  1680 | performance: 0.9 | accuracy: 0.38 | loss: 5.86
update: 35/2000, 耗时:0.00分/0.12分 | step:  1960 | performance: 1.2 | accuracy: 0.40 | loss: 1.65
update: 40/2000, 耗时:0.00分/0.13分 | step:  2240 | performance: 0.8 | accuracy: 0.40 | loss: 7.22
update: 45/2000, 耗时:0.00分/0.15分 | step:  2520 | performance: 0.6 | accuracy: 0.40 | loss: 3.07
update: 50/2000, 耗时:0.00分/0.16分 | step:  2800 | performance: 0.9 | accuracy: 0.41 | loss: 1.32
update: 55/2000, 耗时:0.00分/0.18分 | step:  3080 | performance: 1.0 | accuracy: 0.41 | loss: 5.41
update: 60/2000, 耗时:0.00分/0.19分 | step:  3360 | performance: 0.9 | accuracy: 0.41 | loss: 5.68
update: 65/2000, 耗时:0.00分/0.21分 | step:  3640 | performance: 1.1 | accuracy: 0.41 | loss: 2.36
update: 70/2000, 耗时:0.00分/0.22分 | step:  3920 | performance: 1.1 | accuracy: 0.43 | loss: 5.90
update: 75/2000, 耗时:0.00分/0.24分 | step:  4200 | performance: 1.8 | accuracy: 0.43 | loss: 4.76
update: 80/2000, 耗时:0.00分/0.26分 | step:  4480 | performance: 7.8 | accuracy: 0.45 | loss: 1.77
update: 85/2000, 耗时:0.00分/0.27分 | step:  4760 | performance: 8.3 | accuracy: 0.46 | loss: 4.61
update: 90/2000, 耗时:0.00分/0.29分 | step:  5040 | performance: 8.0 | accuracy: 0.46 | loss: 4.72
update: 95/2000, 耗时:0.00分/0.30分 | step:  5320 | performance: 12.9 | accuracy: 0.46 | loss: 0.58
update:100/2000, 耗时:0.00分/0.32分 | step:  5600 | performance: 12.6 | accuracy: 0.46 | loss: 2.71
update:105/2000, 耗时:0.00分/0.34分 | step:  5880 | performance: 10.5 | accuracy: 0.45 | loss: 0.82
update:110/2000, 耗时:0.00分/0.35分 | step:  6160 | performance: 9.0 | accuracy: 0.45 | loss: 0.63
update:115/2000, 耗时:0.00分/0.37分 | step:  6440 | performance: 3.9 | accuracy: 0.44 | loss: 4.26
update:120/2000, 耗时:0.00分/0.38分 | step:  6720 | performance: 3.6 | accuracy: 0.44 | loss: 1.03
update:125/2000, 耗时:0.00分/0.40分 | step:  7000 | performance: 6.1 | accuracy: 0.43 | loss: 3.97
update:130/2000, 耗时:0.00分/0.42分 | step:  7280 | performance: 17.5 | accuracy: 0.44 | loss: 1.36
update:135/2000, 耗时:0.00分/0.43分 | step:  7560 | performance: 16.0 | accuracy: 0.44 | loss: 4.31
update:140/2000, 耗时:0.00分/0.45分 | step:  7840 | performance: 36.6 | accuracy: 0.45 | loss: 9.94
update:145/2000, 耗时:0.00分/0.46分 | step:  8120 | performance: 33.7 | accuracy: 0.45 | loss: 2.69
update:150/2000, 耗时:0.01分/0.48分 | step:  8400 | performance: 49.6 | accuracy: 0.46 | loss: 3.02
update:155/2000, 耗时:0.00分/0.51分 | step:  8680 | performance: 25.3 | accuracy: 0.45 | loss: 1.77
update:160/2000, 耗时:0.01分/0.53分 | step:  8960 | performance: 24.2 | accuracy: 0.45 | loss: 2.11
update:165/2000, 耗时:0.00分/0.55分 | step:  9240 | performance: 24.3 | accuracy: 0.45 | loss: 1.11
update:170/2000, 耗时:0.00分/0.58分 | step:  9520 | performance: 23.8 | accuracy: 0.45 | loss: 1.44
update:175/2000, 耗时:0.00分/0.60分 | step:  9800 | performance: 18.6 | accuracy: 0.45 | loss: 1.14
update:180/2000, 耗时:0.00分/0.62分 | step: 10080 | performance: 31.0 | accuracy: 0.46 | loss: 3.35
update:185/2000, 耗时:0.00分/0.64分 | step: 10360 | performance: 44.9 | accuracy: 0.46 | loss: 3.94
update:190/2000, 耗时:0.00分/0.65分 | step: 10640 | performance: 51.2 | accuracy: 0.46 | loss: 2.11
update:195/2000, 耗时:0.00分/0.67分 | step: 10920 | performance: 36.1 | accuracy: 0.46 | loss: 1.08
update:200/2000, 耗时:0.00分/0.69分 | step: 11200 | performance: 20.4 | accuracy: 0.46 | loss: 6.83
update:205/2000, 耗时:0.00分/0.71分 | step: 11480 | performance: 17.6 | accuracy: 0.45 | loss: 0.50
update:210/2000, 耗时:0.00分/0.72分 | step: 11760 | performance: 9.7 | accuracy: 0.45 | loss: 0.89
update:215/2000, 耗时:0.00分/0.74分 | step: 12040 | performance: 9.5 | accuracy: 0.45 | loss: 7.72
update:220/2000, 耗时:0.00分/0.76分 | step: 12320 | performance: 4.8 | accuracy: 0.44 | loss: 4.47
update:225/2000, 耗时:0.00分/0.78分 | step: 12600 | performance: 4.8 | accuracy: 0.44 | loss: 5.11
update:230/2000, 耗时:0.00分/0.79分 | step: 12880 | performance: 2.5 | accuracy: 0.44 | loss: 1.93
update:235/2000, 耗时:0.00分/0.82分 | step: 13160 | performance: 2.4 | accuracy: 0.44 | loss: 2.82
update:240/2000, 耗时:0.01分/0.84分 | step: 13440 | performance: 2.2 | accuracy: 0.44 | loss: 1.30
update:245/2000, 耗时:0.00分/0.87分 | step: 13720 | performance: 1.9 | accuracy: 0.43 | loss: 0.98
update:250/2000, 耗时:0.00分/0.89分 | step: 14000 | performance: 1.9 | accuracy: 0.43 | loss: 0.86
update:255/2000, 耗时:0.01分/0.92分 | step: 14280 | performance: 4.5 | accuracy: 0.44 | loss: 1.34
update:260/2000, 耗时:0.01分/0.94分 | step: 14560 | performance: 4.1 | accuracy: 0.44 | loss: 0.83
update:265/2000, 耗时:0.01分/0.97分 | step: 14840 | performance: 2.6 | accuracy: 0.44 | loss: 3.02
update:270/2000, 耗时:0.01分/1.00分 | step: 15120 | performance: 2.9 | accuracy: 0.44 | loss: 0.54
update:275/2000, 耗时:0.01分/1.02分 | step: 15400 | performance: 3.5 | accuracy: 0.45 | loss: 0.73
update:280/2000, 耗时:0.01分/1.05分 | step: 15680 | performance: 7.1 | accuracy: 0.45 | loss: 2.00
update:285/2000, 耗时:0.01分/1.08分 | step: 15960 | performance: 23.0 | accuracy: 0.46 | loss: 0.27
update:290/2000, 耗时:0.01分/1.10分 | step: 16240 | performance: 22.6 | accuracy: 0.46 | loss: 2.40
update:295/2000, 耗时:0.01分/1.13分 | step: 16520 | performance: 72.5 | accuracy: 0.46 | loss: 1.86
update:300/2000, 耗时:0.01分/1.16分 | step: 16800 | performance: 257.6 | accuracy: 0.47 | loss: 18.90
update:305/2000, 耗时:0.01分/1.18分 | step: 17080 | performance: 247.9 | accuracy: 0.47 | loss: 3.22
update:310/2000, 耗时:0.01分/1.21分 | step: 17360 | performance: 967.3 | accuracy: 0.47 | loss: 0.40
update:315/2000, 耗时:0.01分/1.23分 | step: 17640 | performance: 862.1 | accuracy: 0.47 | loss: 4.56
update:320/2000, 耗时:0.00分/1.26分 | step: 17920 | performance: 1377.5 | accuracy: 0.48 | loss: 13.62
update:325/2000, 耗时:0.00分/1.28分 | step: 18200 | performance: 1818.3 | accuracy: 0.48 | loss: 1.45
update:330/2000, 耗时:0.00分/1.31分 | step: 18480 | performance: 1309.9 | accuracy: 0.48 | loss: 3.20
update:335/2000, 耗时:0.00分/1.33分 | step: 18760 | performance: 869.2 | accuracy: 0.48 | loss: 5.25
update:340/2000, 耗时:0.00分/1.36分 | step: 19040 | performance: 515.9 | accuracy: 0.47 | loss: 2.33
update:345/2000, 耗时:0.01分/1.38分 | step: 19320 | performance: 681.5 | accuracy: 0.47 | loss: 3.14
update:350/2000, 耗时:0.01分/1.41分 | step: 19600 | performance: 907.9 | accuracy: 0.47 | loss: 1.50
update:355/2000, 耗时:0.00分/1.43分 | step: 19880 | performance: 947.0 | accuracy: 0.47 | loss: 6.66
update:360/2000, 耗时:0.00分/1.45分 | step: 20160 | performance: 280.5 | accuracy: 0.47 | loss: 1.17
update:365/2000, 耗时:0.00分/1.46分 | step: 20440 | performance: 455.9 | accuracy: 0.47 | loss: 1.01
update:370/2000, 耗时:0.00分/1.48分 | step: 20720 | performance: 310.9 | accuracy: 0.47 | loss: 0.65
update:375/2000, 耗时:0.00分/1.49分 | step: 21000 | performance: 171.8 | accuracy: 0.47 | loss: 2.23
update:380/2000, 耗时:0.00分/1.51分 | step: 21280 | performance: 403.1 | accuracy: 0.47 | loss: 1.32
update:385/2000, 耗时:0.00分/1.53分 | step: 21560 | performance: 341.0 | accuracy: 0.47 | loss: 3.58
update:390/2000, 耗时:0.00分/1.54分 | step: 21840 | performance: 244.6 | accuracy: 0.47 | loss: 3.64
update:395/2000, 耗时:0.00分/1.56分 | step: 22120 | performance: 97.7 | accuracy: 0.47 | loss: 0.70
update:400/2000, 耗时:0.00分/1.57分 | step: 22400 | performance: 73.6 | accuracy: 0.46 | loss: 1.29
update:405/2000, 耗时:0.00分/1.59分 | step: 22680 | performance: 43.8 | accuracy: 0.46 | loss: 0.54
update:410/2000, 耗时:0.00分/1.61分 | step: 22960 | performance: 55.4 | accuracy: 0.46 | loss: 0.03
update:415/2000, 耗时:0.00分/1.62分 | step: 23240 | performance: 58.4 | accuracy: 0.45 | loss: 0.09
update:420/2000, 耗时:0.00分/1.64分 | step: 23520 | performance: 54.6 | accuracy: 0.45 | loss: 0.11
update:425/2000, 耗时:0.00分/1.66分 | step: 23800 | performance: 44.1 | accuracy: 0.44 | loss: 0.37
update:430/2000, 耗时:0.00分/1.67分 | step: 24080 | performance: 44.8 | accuracy: 0.44 | loss: 0.21
update:435/2000, 耗时:0.00分/1.69分 | step: 24360 | performance: 45.5 | accuracy: 0.43 | loss: 0.01
update:440/2000, 耗时:0.00分/1.71分 | step: 24640 | performance: 44.8 | accuracy: 0.43 | loss: 0.03
update:445/2000, 耗时:0.00分/1.73分 | step: 24920 | performance: 46.4 | accuracy: 0.43 | loss: 0.03
update:450/2000, 耗时:0.00分/1.74分 | step: 25200 | performance: 46.4 | accuracy: 0.42 | loss: -0.00
update:455/2000, 耗时:0.00分/1.76分 | step: 25480 | performance: 42.5 | accuracy: 0.42 | loss: 0.24
update:460/2000, 耗时:0.00分/1.78分 | step: 25760 | performance: 39.4 | accuracy: 0.41 | loss: 0.24
update:465/2000, 耗时:0.00分/1.80分 | step: 26040 | performance: 41.5 | accuracy: 0.41 | loss: 0.39
update:470/2000, 耗时:0.00分/1.81分 | step: 26320 | performance: 53.7 | accuracy: 0.41 | loss: 0.36
update:475/2000, 耗时:0.00分/1.83分 | step: 26600 | performance: 45.6 | accuracy: 0.40 | loss: 0.46
update:480/2000, 耗时:0.00分/1.85分 | step: 26880 | performance: 49.4 | accuracy: 0.40 | loss: 0.74
update:485/2000, 耗时:0.00分/1.87分 | step: 27160 | performance: 58.7 | accuracy: 0.40 | loss: 0.63
update:490/2000, 耗时:0.00分/1.88分 | step: 27440 | performance: 65.8 | accuracy: 0.40 | loss: 1.57
update:495/2000, 耗时:0.00分/1.90分 | step: 27720 | performance: 68.4 | accuracy: 0.39 | loss: 0.66
update:500/2000, 耗时:0.00分/1.92分 | step: 28000 | performance: 58.9 | accuracy: 0.39 | loss: 0.74
update:505/2000, 耗时:0.00分/1.94分 | step: 28280 | performance: 58.8 | accuracy: 0.39 | loss: 0.39
Saving PPO weights in both H5 format and checkpoint @ update:506 
update:510/2000, 耗时:0.00分/1.96分 | step: 28560 | performance: 1.1 | accuracy: 0.26 | loss: 0.89
update:515/2000, 耗时:0.00分/1.97分 | step: 28840 | performance: 1.3 | accuracy: 0.23 | loss: 1.50
update:520/2000, 耗时:0.00分/1.99分 | step: 29120 | performance: 0.8 | accuracy: 0.19 | loss: 0.54
update:525/2000, 耗时:0.00分/2.01分 | step: 29400 | performance: 0.7 | accuracy: 0.18 | loss: 0.48
update:530/2000, 耗时:0.00分/2.03分 | step: 29680 | performance: 1.4 | accuracy: 0.23 | loss: 2.59
update:535/2000, 耗时:0.00分/2.05分 | step: 29960 | performance: 1.6 | accuracy: 0.23 | loss: 2.27
update:540/2000, 耗时:0.00分/2.07分 | step: 30240 | performance: 2.1 | accuracy: 0.24 | loss: 1.34
update:545/2000, 耗时:0.00分/2.08分 | step: 30520 | performance: 1.7 | accuracy: 0.26 | loss: 0.91
update:550/2000, 耗时:0.00分/2.10分 | step: 30800 | performance: 1.2 | accuracy: 0.26 | loss: 1.29
update:555/2000, 耗时:0.00分/2.11分 | step: 31080 | performance: 1.9 | accuracy: 0.27 | loss: 0.97
update:560/2000, 耗时:0.00分/2.13分 | step: 31360 | performance: 1.9 | accuracy: 0.27 | loss: 1.11
update:565/2000, 耗时:0.00分/2.14分 | step: 31640 | performance: 2.2 | accuracy: 0.27 | loss: 0.77
update:570/2000, 耗时:0.00分/2.16分 | step: 31920 | performance: 2.5 | accuracy: 0.28 | loss: 1.28
update:575/2000, 耗时:0.00分/2.17分 | step: 32200 | performance: 2.3 | accuracy: 0.28 | loss: 2.13
update:580/2000, 耗时:0.00分/2.19分 | step: 32480 | performance: 2.7 | accuracy: 0.28 | loss: 1.59
update:585/2000, 耗时:0.00分/2.20分 | step: 32760 | performance: 3.3 | accuracy: 0.27 | loss: 0.31
update:590/2000, 耗时:0.00分/2.22分 | step: 33040 | performance: 2.5 | accuracy: 0.26 | loss: 2.57
update:595/2000, 耗时:0.00分/2.24分 | step: 33320 | performance: 2.1 | accuracy: 0.26 | loss: 0.98
update:600/2000, 耗时:0.00分/2.25分 | step: 33600 | performance: 2.0 | accuracy: 0.25 | loss: 0.38
update:605/2000, 耗时:0.00分/2.28分 | step: 33880 | performance: 1.8 | accuracy: 0.24 | loss: 0.74
update:610/2000, 耗时:0.00分/2.30分 | step: 34160 | performance: 1.6 | accuracy: 0.23 | loss: 0.23
update:615/2000, 耗时:0.01分/2.33分 | step: 34440 | performance: 1.5 | accuracy: 0.23 | loss: 0.17
update:620/2000, 耗时:0.00分/2.35分 | step: 34720 | performance: 1.2 | accuracy: 0.22 | loss: 0.41
update:625/2000, 耗时:0.00分/2.38分 | step: 35000 | performance: 1.0 | accuracy: 0.21 | loss: 0.54
update:630/2000, 耗时:0.01分/2.41分 | step: 35280 | performance: 1.3 | accuracy: 0.22 | loss: 2.51
update:635/2000, 耗时:0.00分/2.43分 | step: 35560 | performance: 4.5 | accuracy: 0.24 | loss: 2.33
update:640/2000, 耗时:0.00分/2.46分 | step: 35840 | performance: 3.9 | accuracy: 0.24 | loss: 3.35
update:645/2000, 耗时:0.00分/2.48分 | step: 36120 | performance: 14.5 | accuracy: 0.26 | loss: 7.33
update:650/2000, 耗时:0.01分/2.51分 | step: 36400 | performance: 7.8 | accuracy: 0.27 | loss: 4.41
update:655/2000, 耗时:0.01分/2.54分 | step: 36680 | performance: 10.9 | accuracy: 0.28 | loss: 3.96
update:660/2000, 耗时:0.01分/2.56分 | step: 36960 | performance: 7.4 | accuracy: 0.28 | loss: 3.11
update:665/2000, 耗时:0.01分/2.59分 | step: 37240 | performance: 7.9 | accuracy: 0.29 | loss: 1.18
update:670/2000, 耗时:0.00分/2.62分 | step: 37520 | performance: 9.2 | accuracy: 0.29 | loss: 1.04
update:675/2000, 耗时:0.01分/2.64分 | step: 37800 | performance: 8.3 | accuracy: 0.28 | loss: 0.01
update:680/2000, 耗时:0.00分/2.66分 | step: 38080 | performance: 7.2 | accuracy: 0.28 | loss: 0.00
update:685/2000, 耗时:0.00分/2.68分 | step: 38360 | performance: 7.7 | accuracy: 0.27 | loss: 0.23
update:690/2000, 耗时:0.00分/2.69分 | step: 38640 | performance: 9.6 | accuracy: 0.27 | loss: 0.10
update:695/2000, 耗时:0.00分/2.71分 | step: 38920 | performance: 8.7 | accuracy: 0.26 | loss: 0.12
update:700/2000, 耗时:0.00分/2.73分 | step: 39200 | performance: 8.5 | accuracy: 0.25 | loss: 0.07
update:705/2000, 耗时:0.00分/2.74分 | step: 39480 | performance: 8.3 | accuracy: 0.25 | loss: 0.61
update:710/2000, 耗时:0.00分/2.76分 | step: 39760 | performance: 7.1 | accuracy: 0.25 | loss: 1.51
update:715/2000, 耗时:0.00分/2.78分 | step: 40040 | performance: 3.8 | accuracy: 0.26 | loss: 1.14
update:720/2000, 耗时:0.00分/2.80分 | step: 40320 | performance: 9.1 | accuracy: 0.26 | loss: 0.39
update:725/2000, 耗时:0.00分/2.81分 | step: 40600 | performance: 8.3 | accuracy: 0.25 | loss: 0.13
update:730/2000, 耗时:0.00分/2.83分 | step: 40880 | performance: 8.1 | accuracy: 0.25 | loss: 0.25
update:735/2000, 耗时:0.00分/2.85分 | step: 41160 | performance: 6.0 | accuracy: 0.24 | loss: 3.47
update:740/2000, 耗时:0.00分/2.86分 | step: 41440 | performance: 7.3 | accuracy: 0.25 | loss: 1.27
update:745/2000, 耗时:0.00分/2.88分 | step: 41720 | performance: 6.9 | accuracy: 0.25 | loss: 2.03
update:750/2000, 耗时:0.00分/2.90分 | step: 42000 | performance: 6.4 | accuracy: 0.25 | loss: 0.59
update:755/2000, 耗时:0.00分/2.92分 | step: 42280 | performance: 5.9 | accuracy: 0.25 | loss: 0.73
update:760/2000, 耗时:0.00分/2.93分 | step: 42560 | performance: 10.2 | accuracy: 0.25 | loss: 3.83
update:765/2000, 耗时:0.00分/2.95分 | step: 42840 | performance: 9.8 | accuracy: 0.26 | loss: 1.82
update:770/2000, 耗时:0.00分/2.97分 | step: 43120 | performance: 5.8 | accuracy: 0.26 | loss: 0.75
update:775/2000, 耗时:0.00分/2.99分 | step: 43400 | performance: 5.6 | accuracy: 0.27 | loss: 2.04
update:780/2000, 耗时:0.00分/3.00分 | step: 43680 | performance: 5.6 | accuracy: 0.27 | loss: 0.88
update:785/2000, 耗时:0.00分/3.02分 | step: 43960 | performance: 11.2 | accuracy: 0.28 | loss: 2.05
update:790/2000, 耗时:0.00分/3.04分 | step: 44240 | performance: 31.9 | accuracy: 0.29 | loss: 4.39
update:795/2000, 耗时:0.00分/3.06分 | step: 44520 | performance: 40.6 | accuracy: 0.29 | loss: 1.84
update:800/2000, 耗时:0.00分/3.07分 | step: 44800 | performance: 85.6 | accuracy: 0.30 | loss: 0.66
update:805/2000, 耗时:0.00分/3.09分 | step: 45080 | performance: 574.7 | accuracy: 0.31 | loss: 6.92
update:810/2000, 耗时:0.00分/3.11分 | step: 45360 | performance: 264.0 | accuracy: 0.31 | loss: 2.66
update:815/2000, 耗时:0.00分/3.12分 | step: 45640 | performance: 1405.5 | accuracy: 0.32 | loss: 0.51
update:820/2000, 耗时:0.00分/3.14分 | step: 45920 | performance: 1568.3 | accuracy: 0.32 | loss: 1.44
update:825/2000, 耗时:0.00分/3.16分 | step: 46200 | performance: 2641.5 | accuracy: 0.33 | loss: 3.49
update:830/2000, 耗时:0.00分/3.17分 | step: 46480 | performance: 2433.8 | accuracy: 0.33 | loss: 2.88
update:835/2000, 耗时:0.00分/3.19分 | step: 46760 | performance: 1483.5 | accuracy: 0.33 | loss: 4.74
update:840/2000, 耗时:0.00分/3.21分 | step: 47040 | performance: 1062.5 | accuracy: 0.33 | loss: 10.33
update:845/2000, 耗时:0.00分/3.22分 | step: 47320 | performance: 462.1 | accuracy: 0.33 | loss: 0.34
update:850/2000, 耗时:0.00分/3.24分 | step: 47600 | performance: 471.8 | accuracy: 0.32 | loss: 0.01
update:855/2000, 耗时:0.00分/3.26分 | step: 47880 | performance: 456.3 | accuracy: 0.32 | loss: 0.01
update:860/2000, 耗时:0.00分/3.27分 | step: 48160 | performance: 456.3 | accuracy: 0.31 | loss: 0.00
update:865/2000, 耗时:0.00分/3.29分 | step: 48440 | performance: 410.6 | accuracy: 0.31 | loss: 0.09
update:870/2000, 耗时:0.00分/3.31分 | step: 48720 | performance: 457.1 | accuracy: 0.31 | loss: 1.22
update:875/2000, 耗时:0.00分/3.33分 | step: 49000 | performance: 421.5 | accuracy: 0.31 | loss: 1.68
update:880/2000, 耗时:0.00分/3.34分 | step: 49280 | performance: 489.1 | accuracy: 0.31 | loss: 0.05
update:885/2000, 耗时:0.00分/3.36分 | step: 49560 | performance: 813.0 | accuracy: 0.31 | loss: 2.14
update:890/2000, 耗时:0.00分/3.38分 | step: 49840 | performance: 845.2 | accuracy: 0.31 | loss: 1.06
update:895/2000, 耗时:0.00分/3.39分 | step: 50120 | performance: 640.0 | accuracy: 0.31 | loss: 0.87
update:900/2000, 耗时:0.00分/3.41分 | step: 50400 | performance: 271.5 | accuracy: 0.31 | loss: 0.48
update:905/2000, 耗时:0.00分/3.43分 | step: 50680 | performance: 244.6 | accuracy: 0.31 | loss: 0.26
update:910/2000, 耗时:0.00分/3.44分 | step: 50960 | performance: 244.6 | accuracy: 0.31 | loss: 0.02
update:915/2000, 耗时:0.00分/3.46分 | step: 51240 | performance: 244.6 | accuracy: 0.30 | loss: 0.00
update:920/2000, 耗时:0.00分/3.48分 | step: 51520 | performance: 244.6 | accuracy: 0.30 | loss: 0.00
update:925/2000, 耗时:0.00分/3.50分 | step: 51800 | performance: 266.0 | accuracy: 0.30 | loss: 0.03
update:930/2000, 耗时:0.00分/3.51分 | step: 52080 | performance: 266.0 | accuracy: 0.29 | loss: 0.15
update:935/2000, 耗时:0.00分/3.53分 | step: 52360 | performance: 266.0 | accuracy: 0.29 | loss: 0.02
update:940/2000, 耗时:0.00分/3.54分 | step: 52640 | performance: 266.0 | accuracy: 0.29 | loss: 0.00
update:945/2000, 耗时:0.00分/3.56分 | step: 52920 | performance: 266.0 | accuracy: 0.28 | loss: 0.00
update:950/2000, 耗时:0.00分/3.58分 | step: 53200 | performance: 266.0 | accuracy: 0.28 | loss: 0.00
update:955/2000, 耗时:0.00分/3.59分 | step: 53480 | performance: 266.0 | accuracy: 0.28 | loss: 0.00
update:960/2000, 耗时:0.00分/3.61分 | step: 53760 | performance: 266.0 | accuracy: 0.27 | loss: 0.00
update:965/2000, 耗时:0.00分/3.63分 | step: 54040 | performance: 266.0 | accuracy: 0.27 | loss: 0.00
update:970/2000, 耗时:0.00分/3.64分 | step: 54320 | performance: 266.0 | accuracy: 0.27 | loss: 0.00
update:975/2000, 耗时:0.00分/3.66分 | step: 54600 | performance: 266.0 | accuracy: 0.27 | loss: 0.01
update:980/2000, 耗时:0.00分/3.67分 | step: 54880 | performance: 266.0 | accuracy: 0.26 | loss: 0.00
update:985/2000, 耗时:0.00分/3.69分 | step: 55160 | performance: 266.0 | accuracy: 0.26 | loss: 0.08
update:990/2000, 耗时:0.00分/3.70分 | step: 55440 | performance: 266.0 | accuracy: 0.26 | loss: 0.00
update:995/2000, 耗时:0.00分/3.72分 | step: 55720 | performance: 266.0 | accuracy: 0.26 | loss: 0.00
update:1000/2000, 耗时:0.00分/3.73分 | step: 56000 | performance: 266.0 | accuracy: 0.25 | loss: 0.01
update:1005/2000, 耗时:0.00分/3.75分 | step: 56280 | performance: 266.0 | accuracy: 0.25 | loss: 0.02
update:1010/2000, 耗时:0.00分/3.77分 | step: 56560 | performance: 266.0 | accuracy: 0.25 | loss: 0.07
Saving PPO weights in both H5 format and checkpoint @ update:1012 
update:1015/2000, 耗时:0.00分/3.79分 | step: 56840 | performance: 1.0 | accuracy: 0.17 | loss: 0.07
update:1020/2000, 耗时:0.00分/3.80分 | step: 57120 | performance: 1.0 | accuracy: 0.10 | loss: 0.01
update:1025/2000, 耗时:0.00分/3.82分 | step: 57400 | performance: 1.0 | accuracy: 0.15 | loss: 0.10
update:1030/2000, 耗时:0.00分/3.83分 | step: 57680 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1035/2000, 耗时:0.00分/3.85分 | step: 57960 | performance: 1.0 | accuracy: 0.10 | loss: 0.03
update:1040/2000, 耗时:0.00分/3.87分 | step: 58240 | performance: 1.0 | accuracy: 0.15 | loss: 0.09
update:1045/2000, 耗时:0.00分/3.88分 | step: 58520 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1050/2000, 耗时:0.00分/3.90分 | step: 58800 | performance: 1.0 | accuracy: 0.10 | loss: 0.03
update:1055/2000, 耗时:0.00分/3.91分 | step: 59080 | performance: 1.0 | accuracy: 0.15 | loss: 0.08
update:1060/2000, 耗时:0.00分/3.93分 | step: 59360 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1065/2000, 耗时:0.00分/3.94分 | step: 59640 | performance: 1.0 | accuracy: 0.10 | loss: 0.03
update:1070/2000, 耗时:0.00分/3.96分 | step: 59920 | performance: 1.0 | accuracy: 0.15 | loss: 0.08
update:1075/2000, 耗时:0.00分/3.97分 | step: 60200 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1080/2000, 耗时:0.00分/3.99分 | step: 60480 | performance: 1.0 | accuracy: 0.10 | loss: 0.03
update:1085/2000, 耗时:0.00分/4.00分 | step: 60760 | performance: 1.0 | accuracy: 0.15 | loss: 0.08
update:1090/2000, 耗时:0.00分/4.01分 | step: 61040 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1095/2000, 耗时:0.00分/4.03分 | step: 61320 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1100/2000, 耗时:0.00分/4.04分 | step: 61600 | performance: 1.0 | accuracy: 0.15 | loss: 0.08
update:1105/2000, 耗时:0.00分/4.06分 | step: 61880 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1110/2000, 耗时:0.00分/4.08分 | step: 62160 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1115/2000, 耗时:0.00分/4.09分 | step: 62440 | performance: 1.0 | accuracy: 0.15 | loss: 0.08
update:1120/2000, 耗时:0.00分/4.11分 | step: 62720 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1125/2000, 耗时:0.00分/4.12分 | step: 63000 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1130/2000, 耗时:0.00分/4.14分 | step: 63280 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1135/2000, 耗时:0.00分/4.15分 | step: 63560 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1140/2000, 耗时:0.00分/4.17分 | step: 63840 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1145/2000, 耗时:0.00分/4.18分 | step: 64120 | performance: 1.0 | accuracy: 0.15 | loss: 0.08
update:1150/2000, 耗时:0.00分/4.20分 | step: 64400 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1155/2000, 耗时:0.00分/4.21分 | step: 64680 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1160/2000, 耗时:0.00分/4.23分 | step: 64960 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1165/2000, 耗时:0.00分/4.24分 | step: 65240 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1170/2000, 耗时:0.00分/4.26分 | step: 65520 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1175/2000, 耗时:0.00分/4.28分 | step: 65800 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1180/2000, 耗时:0.00分/4.29分 | step: 66080 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1185/2000, 耗时:0.00分/4.31分 | step: 66360 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1190/2000, 耗时:0.00分/4.32分 | step: 66640 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1195/2000, 耗时:0.00分/4.34分 | step: 66920 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1200/2000, 耗时:0.00分/4.35分 | step: 67200 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1205/2000, 耗时:0.00分/4.37分 | step: 67480 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1210/2000, 耗时:0.00分/4.38分 | step: 67760 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1215/2000, 耗时:0.00分/4.40分 | step: 68040 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1220/2000, 耗时:0.00分/4.41分 | step: 68320 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1225/2000, 耗时:0.00分/4.43分 | step: 68600 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1230/2000, 耗时:0.00分/4.45分 | step: 68880 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1235/2000, 耗时:0.00分/4.46分 | step: 69160 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1240/2000, 耗时:0.00分/4.48分 | step: 69440 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1245/2000, 耗时:0.00分/4.49分 | step: 69720 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1250/2000, 耗时:0.00分/4.51分 | step: 70000 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1255/2000, 耗时:0.00分/4.52分 | step: 70280 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1260/2000, 耗时:0.00分/4.54分 | step: 70560 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1265/2000, 耗时:0.00分/4.55分 | step: 70840 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1270/2000, 耗时:0.00分/4.57分 | step: 71120 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1275/2000, 耗时:0.00分/4.59分 | step: 71400 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1280/2000, 耗时:0.00分/4.60分 | step: 71680 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1285/2000, 耗时:0.00分/4.62分 | step: 71960 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1290/2000, 耗时:0.00分/4.63分 | step: 72240 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1295/2000, 耗时:0.00分/4.65分 | step: 72520 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1300/2000, 耗时:0.00分/4.67分 | step: 72800 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1305/2000, 耗时:0.00分/4.68分 | step: 73080 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1310/2000, 耗时:0.00分/4.70分 | step: 73360 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1315/2000, 耗时:0.00分/4.71分 | step: 73640 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1320/2000, 耗时:0.00分/4.73分 | step: 73920 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1325/2000, 耗时:0.00分/4.74分 | step: 74200 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1330/2000, 耗时:0.00分/4.76分 | step: 74480 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1335/2000, 耗时:0.00分/4.77分 | step: 74760 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1340/2000, 耗时:0.00分/4.79分 | step: 75040 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1345/2000, 耗时:0.00分/4.80分 | step: 75320 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1350/2000, 耗时:0.00分/4.82分 | step: 75600 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1355/2000, 耗时:0.00分/4.84分 | step: 75880 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1360/2000, 耗时:0.00分/4.85分 | step: 76160 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1365/2000, 耗时:0.00分/4.87分 | step: 76440 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1370/2000, 耗时:0.00分/4.88分 | step: 76720 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1375/2000, 耗时:0.00分/4.90分 | step: 77000 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1380/2000, 耗时:0.00分/4.91分 | step: 77280 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1385/2000, 耗时:0.00分/4.93分 | step: 77560 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1390/2000, 耗时:0.00分/4.94分 | step: 77840 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1395/2000, 耗时:0.00分/4.96分 | step: 78120 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1400/2000, 耗时:0.00分/4.97分 | step: 78400 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1405/2000, 耗时:0.00分/4.99分 | step: 78680 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1410/2000, 耗时:0.00分/5.01分 | step: 78960 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1415/2000, 耗时:0.00分/5.02分 | step: 79240 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1420/2000, 耗时:0.00分/5.04分 | step: 79520 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1425/2000, 耗时:0.00分/5.05分 | step: 79800 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1430/2000, 耗时:0.00分/5.07分 | step: 80080 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1435/2000, 耗时:0.00分/5.09分 | step: 80360 | performance: 1.0 | accuracy: 0.17 | loss: 0.07
update:1440/2000, 耗时:0.00分/5.10分 | step: 80640 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1445/2000, 耗时:0.00分/5.12分 | step: 80920 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1450/2000, 耗时:0.00分/5.13分 | step: 81200 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1455/2000, 耗时:0.00分/5.15分 | step: 81480 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1460/2000, 耗时:0.00分/5.16分 | step: 81760 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1465/2000, 耗时:0.00分/5.18分 | step: 82040 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1470/2000, 耗时:0.00分/5.20分 | step: 82320 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1475/2000, 耗时:0.00分/5.21分 | step: 82600 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1480/2000, 耗时:0.00分/5.23分 | step: 82880 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1485/2000, 耗时:0.00分/5.24分 | step: 83160 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1490/2000, 耗时:0.00分/5.26分 | step: 83440 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1495/2000, 耗时:0.00分/5.27分 | step: 83720 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1500/2000, 耗时:0.00分/5.29分 | step: 84000 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1505/2000, 耗时:0.00分/5.31分 | step: 84280 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1510/2000, 耗时:0.00分/5.32分 | step: 84560 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1515/2000, 耗时:0.00分/5.34分 | step: 84840 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1520/2000, 耗时:0.00分/5.35分 | step: 85120 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1525/2000, 耗时:0.00分/5.37分 | step: 85400 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1530/2000, 耗时:0.00分/5.38分 | step: 85680 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1535/2000, 耗时:0.00分/5.40分 | step: 85960 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1540/2000, 耗时:0.00分/5.41分 | step: 86240 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1545/2000, 耗时:0.00分/5.43分 | step: 86520 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1550/2000, 耗时:0.00分/5.45分 | step: 86800 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1555/2000, 耗时:0.00分/5.46分 | step: 87080 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1560/2000, 耗时:0.00分/5.48分 | step: 87360 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1565/2000, 耗时:0.00分/5.49分 | step: 87640 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1570/2000, 耗时:0.00分/5.51分 | step: 87920 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1575/2000, 耗时:0.00分/5.52分 | step: 88200 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1580/2000, 耗时:0.00分/5.54分 | step: 88480 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1585/2000, 耗时:0.00分/5.55分 | step: 88760 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1590/2000, 耗时:0.00分/5.57分 | step: 89040 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1595/2000, 耗时:0.00分/5.59分 | step: 89320 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1600/2000, 耗时:0.00分/5.60分 | step: 89600 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
update:1605/2000, 耗时:0.00分/5.62分 | step: 89880 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1610/2000, 耗时:0.00分/5.63分 | step: 90160 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1615/2000, 耗时:0.00分/5.65分 | step: 90440 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1620/2000, 耗时:0.00分/5.66分 | step: 90720 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1625/2000, 耗时:0.00分/5.68分 | step: 91000 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1630/2000, 耗时:0.00分/5.70分 | step: 91280 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1635/2000, 耗时:0.00分/5.71分 | step: 91560 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1640/2000, 耗时:0.00分/5.73分 | step: 91840 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1645/2000, 耗时:0.00分/5.74分 | step: 92120 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1650/2000, 耗时:0.00分/5.76分 | step: 92400 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1655/2000, 耗时:0.00分/5.77分 | step: 92680 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1660/2000, 耗时:0.00分/5.79分 | step: 92960 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1665/2000, 耗时:0.00分/5.80分 | step: 93240 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1670/2000, 耗时:0.00分/5.82分 | step: 93520 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1675/2000, 耗时:0.00分/5.84分 | step: 93800 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1680/2000, 耗时:0.00分/5.85分 | step: 94080 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1685/2000, 耗时:0.00分/5.87分 | step: 94360 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1690/2000, 耗时:0.00分/5.88分 | step: 94640 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1695/2000, 耗时:0.00分/5.90分 | step: 94920 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1700/2000, 耗时:0.00分/5.91分 | step: 95200 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1705/2000, 耗时:0.00分/5.93分 | step: 95480 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1710/2000, 耗时:0.00分/5.94分 | step: 95760 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1715/2000, 耗时:0.00分/5.96分 | step: 96040 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1720/2000, 耗时:0.00分/5.97分 | step: 96320 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1725/2000, 耗时:0.00分/5.99分 | step: 96600 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1730/2000, 耗时:0.00分/6.00分 | step: 96880 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1735/2000, 耗时:0.00分/6.02分 | step: 97160 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1740/2000, 耗时:0.00分/6.03分 | step: 97440 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1745/2000, 耗时:0.00分/6.05分 | step: 97720 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1750/2000, 耗时:0.00分/6.06分 | step: 98000 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1755/2000, 耗时:0.00分/6.08分 | step: 98280 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1760/2000, 耗时:0.00分/6.09分 | step: 98560 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1765/2000, 耗时:0.00分/6.11分 | step: 98840 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1770/2000, 耗时:0.00分/6.12分 | step: 99120 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1775/2000, 耗时:0.00分/6.14分 | step: 99400 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1780/2000, 耗时:0.00分/6.15分 | step: 99680 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1785/2000, 耗时:0.00分/6.17分 | step: 99960 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1790/2000, 耗时:0.00分/6.18分 | step: 100240 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1795/2000, 耗时:0.00分/6.20分 | step: 100520 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1800/2000, 耗时:0.00分/6.21分 | step: 100800 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1805/2000, 耗时:0.00分/6.23分 | step: 101080 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1810/2000, 耗时:0.00分/6.24分 | step: 101360 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
update:1815/2000, 耗时:0.00分/6.26分 | step: 101640 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1820/2000, 耗时:0.00分/6.27分 | step: 101920 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1825/2000, 耗时:0.00分/6.29分 | step: 102200 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1830/2000, 耗时:0.00分/6.30分 | step: 102480 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1835/2000, 耗时:0.00分/6.32分 | step: 102760 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1840/2000, 耗时:0.00分/6.33分 | step: 103040 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1845/2000, 耗时:0.00分/6.35分 | step: 103320 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1850/2000, 耗时:0.00分/6.37分 | step: 103600 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1855/2000, 耗时:0.00分/6.38分 | step: 103880 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1860/2000, 耗时:0.00分/6.40分 | step: 104160 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1865/2000, 耗时:0.00分/6.41分 | step: 104440 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1870/2000, 耗时:0.00分/6.43分 | step: 104720 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1875/2000, 耗时:0.00分/6.44分 | step: 105000 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1880/2000, 耗时:0.00分/6.46分 | step: 105280 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1885/2000, 耗时:0.00分/6.47分 | step: 105560 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1890/2000, 耗时:0.00分/6.49分 | step: 105840 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1895/2000, 耗时:0.00分/6.50分 | step: 106120 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1900/2000, 耗时:0.00分/6.52分 | step: 106400 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1905/2000, 耗时:0.00分/6.53分 | step: 106680 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1910/2000, 耗时:0.00分/6.55分 | step: 106960 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1915/2000, 耗时:0.00分/6.56分 | step: 107240 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1920/2000, 耗时:0.00分/6.58分 | step: 107520 | performance: 1.0 | accuracy: 0.10 | loss: 0.02
update:1925/2000, 耗时:0.00分/6.59分 | step: 107800 | performance: 1.0 | accuracy: 0.15 | loss: 0.07
update:1930/2000, 耗时:0.00分/6.61分 | step: 108080 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
update:1935/2000, 耗时:0.00分/6.63分 | step: 108360 | performance: 0.7 | accuracy: 0.10 | loss: 0.88
update:1940/2000, 耗时:0.00分/6.64分 | step: 108640 | performance: 1.0 | accuracy: 0.15 | loss: 0.09
update:1945/2000, 耗时:0.00分/6.66分 | step: 108920 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 109197 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.4 | max total_reward: 222.1
update:1950/2000, 耗时:0.00分/6.67分 | step: 109200 | performance: 0.9 | accuracy: 0.13 | loss: -0.00
step: 109365 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.4 | max total_reward: 222.1
update:1955/2000, 耗时:0.00分/6.69分 | step: 109480 | performance: 1.0 | accuracy: 0.25 | loss: 0.06
step: 109533 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.4 | max total_reward: 222.1
step: 109701 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.6 | max total_reward: 222.1
update:1960/2000, 耗时:0.00分/6.70分 | step: 109760 | performance: 1.0 | accuracy: 0.11 | loss: 0.06
step: 109869 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.6 | max total_reward: 222.1
step: 110037 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.6 | max total_reward: 222.1
update:1965/2000, 耗时:0.00分/6.72分 | step: 110040 | performance: 1.0 | accuracy: 0.18 | loss: 0.05
step: 110205 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.8 | max total_reward: 222.1
update:1970/2000, 耗时:0.00分/6.73分 | step: 110320 | performance: 1.0 | accuracy: 0.25 | loss: 0.07
step: 110373 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.9 | max total_reward: 222.1
step: 110541 | worker_4@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 222.1
update:1975/2000, 耗时:0.00分/6.75分 | step: 110600 | performance: 1.0 | accuracy: 0.11 | loss: 0.06
step: 110709 | worker_4@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 222.1
step: 110877 | worker_4@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 222.1
update:1980/2000, 耗时:0.00分/6.76分 | step: 110880 | performance: 1.0 | accuracy: 0.18 | loss: 0.05
step: 111045 | worker_4@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 222.1
update:1985/2000, 耗时:0.00分/6.78分 | step: 111160 | performance: 1.0 | accuracy: 0.25 | loss: 0.07
step: 111213 | worker_4@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 222.1
step: 111381 | worker_4@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 222.1
update:1990/2000, 耗时:0.00分/6.80分 | step: 111440 | performance: 1.0 | accuracy: 0.11 | loss: 0.07
step: 111549 | worker_4@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 222.1
step: 111717 | worker_4@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 222.1
update:1995/2000, 耗时:0.00分/6.81分 | step: 111720 | performance: 1.0 | accuracy: 0.18 | loss: 0.05
step: 111885 | worker_4@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 222.1
  0%|          | 0/408 [00:00<?, ?it/s]100%|| 408/408 [00:00<00:00, 102159.63it/s]
update:2000/2000, 耗时:0.00分/6.83分 | step: 112000 | performance: 1.0 | accuracy: 0.25 | loss: 0.07
----------------------------------------finished----------------------------------------
==================================================
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1070.80
2023-07-24T12:00:00 | net performance [%] = 7.0798
2023-07-24T12:00:00 | number of trades [#] = 2
==================================================
Trial 4 Complete [00h 07m 15s]
net_wealth: 1071.8698221793009

Best net_wealth So Far: 1380.2023481050508
Total elapsed time: 00h 21m 15s

Search: Running Trial #5

Value             |Best Value So Far |Hyperparameter
4                 |1                 |horizon
365               |225               |lookback
False             |False             |MarketFactor
3                 |8                 |lags
0.85              |0.9               |gamma
32                |32                |batch_size
3                 |10                |n_step
0.99              |0.92              |gae_lambda
0.1               |2                 |gradient_clip_norm
3                 |3                 |epochs
1e-05             |5e-05             |actor_lr
5e-05             |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4311.000000   4315.000000
mean      0.000441    20062.255222  ...   20133.281642  20118.633889
std       0.027818    16039.874230  ...   16077.358923  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7695.614990   7690.540039
50%       0.000642    11554.824463  ...   11741.480469  11715.610352
75%       0.011655    29873.081836  ...   29939.474609  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-27 22:24:38.129373: I tensorflow/c2023-07-27 22:24:38.129408: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized 2023-07-27 22:24:38.2wit2023-07-27 22h1: 24:29463o38n.eAP1293I:73  : IID  tteneensorfloesporw f/low/cocNre/platoefreural Networkoormr /eL//pla0platform/c2i3b-0tfr7oa-rrc27 22:24:38.129376: I tensorflow/core/platform/cpu_2fpm02eu3pa_fu/cpt-e07-_atuurerfeat2eure_g7_ 2gua2_guua2aruy (_0r2d.cod302r.fcenad-3teDNc.:cc:10147u-re_guard.cc:01422:24:]472c2] -: T27 22This Tensohis TNrF) elnowt-] bi2n7so3o8 .:124:342u 22:]s2  ThisThis  4:38T.Te1erFlon8n.2as1ry i29o906: I trs9s8e4F nsorfo1lpt:ow/core iI te/emized p1wi2w b9th ln iothe nn932ofeoallA:sroFlow arPI Deoe wIpi Neurf ngl Ctoawl/cbPiU  inoaernyrlost nNw etwrsuoribinorsfarlck oewt y f//cpoiotrmrrlsaLi/yc i siooppu_ bnratopoetriyfea/tf (ppulamoirzetso tmrd nienD NpNe)ii/ewmtifc ptuo_ fuzoed erfiwtasermt_uirteo hrh/ otmg hceauapu fnr_nfeeAPdo.molloiwincacne_e-gcu:a1rcdgzA4P2r]  CTetPuiI Deetd.chispi cwi  TrenaUNc:1l4 eutr o2]i halesITpehi _gsuD rat nsariTetru d.ceNetwocnpenctio:onosne 1s42s API:]r ionr DFeNeuF l oAVXrolweTal o wpe ph N Nrefories rbAVXTtku2reiwn
anoaT oLsor irbkrylra Ne  Lis  bimteoFlrbyr aiwnaa(nocnew- ororkcrpatbnyiticlirmeiDzead wy eibN s opi i(onntLhibrteimNal i)DNN)oar t nzeedAPI  ot oo Dwe epperayt iiou nNssse tu:s  oetuhehreae  the rl Neymf  t oiAn fo (potwlolrokimVwn lLiizXedlbr  iAenarwitDgy  ChN oVX2PUio(oneNw)in
TDoN  noNt)hteo tg  tAeih erCPnIa o PuU Deep snesti obr nouperluNen etecsttiaAtP sueoioIhne s i nrr ntst,h eafreb uDhumcpieoel loweltiinledp rgo nfTole Csf i n sNPoirNn eumraleltwoorF UN rlno piotnhser otwiek oLwingr Cuc wePtUtitiobr hancrwfpi enso rinet-amnshcrr atncoyra (oen arreittppprDiik LeeuoNoca-cNn)irfctsionsblo, prrairrym t at (oonoanr  uesDerciepeeienN   rb-N)cpeatic torofutiol dmotun Ts: phie rrmileenssaen ct Acfaolllhoerer-oi tifV coriFwXin A cg CtPlVlXpifcaoawgeo2l
lToslraa til wU  oo.owoinisp
ptngh  CPi een:aeb l en thUstrurAeV Xa AV ctrtXi2n
saaiothpprTtoi oenorputniaerbcotmilons ne ts ishie:ns :ina i n   tAm pperfoArVee mVXn othin er Xo ot herp eraoarAtcperations,f AVX2
VTX2ioons, rebuild TensorFlow with the appropriate compiler flags.
nce-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with  rompiler ro enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
the appropriate compiler flags.

To enable them in other operations, rebuild TensorFlow with theebuild TensorFlow with the appropriate cflags.
 appomrmaopripiler flags.
nce-critical operations:  AVX AVate compiler flags.
X2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-27 22:24:38.759038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:24:38.786146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:24:38.791164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:24:38.792851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:24:38.812933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-227 023-07-27 22:22:24:38.822649: I tensorflow/core/common_runtime/gpu/gpu_d24:38ev.822649: iIc e.cct:1510] Created device ensor/fjob:localow/corle/common_runtime/gpu/host/greplicpu_devia:0/tace.cc:1510sk:0/device:GPU:]0 Created device  /job:locwith 545a4 lhost/MB memory:  -repl> device: 0,ica:0 na/mtase:k:0/devic e:GPU:0NVIDIA  witGeForceh  5R454 MB mTeXmory:  -> device: 0, name: NVIDIA GeForce RTX 307 3070, pci bus id: 00000:01:00, pci b.0, compute capabilituy:s 8.6
 id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:24:38.829819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   120 | performance: 0.8 | accuracy: 0.27 | loss: 1.83
Saving PPO weights in both H5 format and checkpoint @ update:6 
update: 10/2000, 耗时:0.00分/0.04分 | step:   240 | performance: 0.4 | accuracy: 0.17 | loss: 0.89
update: 15/2000, 耗时:0.00分/0.05分 | step:   360 | performance: 0.5 | accuracy: 0.18 | loss: 0.98
update: 20/2000, 耗时:0.00分/0.06分 | step:   480 | performance: 0.5 | accuracy: 0.22 | loss: 1.97
update: 25/2000, 耗时:0.00分/0.06分 | step:   600 | performance: 0.4 | accuracy: 0.20 | loss: 1.01
update: 30/2000, 耗时:0.00分/0.07分 | step:   720 | performance: 0.5 | accuracy: 0.22 | loss: 1.61
update: 35/2000, 耗时:0.00分/0.08分 | step:   840 | performance: 0.4 | accuracy: 0.24 | loss: 1.74
update: 40/2000, 耗时:0.00分/0.08分 | step:   960 | performance: 0.3 | accuracy: 0.24 | loss: 0.91
update: 45/2000, 耗时:0.00分/0.09分 | step:  1080 | performance: 0.3 | accuracy: 0.27 | loss: 1.28
update: 50/2000, 耗时:0.00分/0.10分 | step:  1200 | performance: 0.3 | accuracy: 0.28 | loss: 0.84
update: 55/2000, 耗时:0.00分/0.11分 | step:  1320 | performance: 0.3 | accuracy: 0.29 | loss: 0.99
update: 60/2000, 耗时:0.00分/0.11分 | step:  1440 | performance: 0.2 | accuracy: 0.29 | loss: 1.36
update: 65/2000, 耗时:0.00分/0.12分 | step:  1560 | performance: 0.2 | accuracy: 0.31 | loss: 1.25
update: 70/2000, 耗时:0.00分/0.13分 | step:  1680 | performance: 0.2 | accuracy: 0.32 | loss: 0.68
update: 75/2000, 耗时:0.00分/0.14分 | step:  1800 | performance: 0.2 | accuracy: 0.33 | loss: 1.27
update: 80/2000, 耗时:0.00分/0.14分 | step:  1920 | performance: 0.2 | accuracy: 0.34 | loss: 1.45
update: 85/2000, 耗时:0.00分/0.15分 | step:  2040 | performance: 0.2 | accuracy: 0.34 | loss: 0.81
update: 90/2000, 耗时:0.00分/0.16分 | step:  2160 | performance: 0.2 | accuracy: 0.34 | loss: 1.38
update: 95/2000, 耗时:0.00分/0.17分 | step:  2280 | performance: 0.1 | accuracy: 0.33 | loss: 0.91
update:100/2000, 耗时:0.00分/0.18分 | step:  2400 | performance: 0.1 | accuracy: 0.34 | loss: 0.63
update:105/2000, 耗时:0.00分/0.18分 | step:  2520 | performance: 0.1 | accuracy: 0.34 | loss: 1.34
update:110/2000, 耗时:0.00分/0.19分 | step:  2640 | performance: 0.1 | accuracy: 0.34 | loss: 1.22
update:115/2000, 耗时:0.00分/0.20分 | step:  2760 | performance: 0.1 | accuracy: 0.34 | loss: 0.88
update:120/2000, 耗时:0.00分/0.21分 | step:  2880 | performance: 0.1 | accuracy: 0.34 | loss: 1.88
update:125/2000, 耗时:0.00分/0.22分 | step:  3000 | performance: 0.0 | accuracy: 0.34 | loss: 1.21
update:130/2000, 耗时:0.00分/0.22分 | step:  3120 | performance: 0.0 | accuracy: 0.34 | loss: 0.86
update:135/2000, 耗时:0.00分/0.23分 | step:  3240 | performance: 0.0 | accuracy: 0.36 | loss: 0.83
update:140/2000, 耗时:0.00分/0.24分 | step:  3360 | performance: 0.0 | accuracy: 0.36 | loss: 1.10
update:145/2000, 耗时:0.00分/0.25分 | step:  3480 | performance: 0.0 | accuracy: 0.36 | loss: 1.00
update:150/2000, 耗时:0.00分/0.26分 | step:  3600 | performance: 0.0 | accuracy: 0.37 | loss: 1.54
update:155/2000, 耗时:0.00分/0.27分 | step:  3720 | performance: 0.0 | accuracy: 0.37 | loss: 1.94
update:160/2000, 耗时:0.00分/0.27分 | step:  3840 | performance: 0.0 | accuracy: 0.38 | loss: 0.83
update:165/2000, 耗时:0.00分/0.28分 | step:  3960 | performance: 0.0 | accuracy: 0.38 | loss: 1.75
update:170/2000, 耗时:0.00分/0.29分 | step:  4080 | performance: 0.0 | accuracy: 0.39 | loss: 1.04
update:175/2000, 耗时:0.00分/0.30分 | step:  4200 | performance: 0.0 | accuracy: 0.39 | loss: 0.78
update:180/2000, 耗时:0.00分/0.31分 | step:  4320 | performance: 0.0 | accuracy: 0.39 | loss: 1.23
update:185/2000, 耗时:0.00分/0.32分 | step:  4440 | performance: 0.0 | accuracy: 0.39 | loss: 1.84
update:190/2000, 耗时:0.00分/0.33分 | step:  4560 | performance: 0.1 | accuracy: 0.40 | loss: 3.35
update:195/2000, 耗时:0.00分/0.34分 | step:  4680 | performance: 0.1 | accuracy: 0.41 | loss: 2.55
update:200/2000, 耗时:0.00分/0.35分 | step:  4800 | performance: 0.0 | accuracy: 0.40 | loss: 0.60
update:205/2000, 耗时:0.00分/0.36分 | step:  4920 | performance: 0.1 | accuracy: 0.41 | loss: 0.87
update:210/2000, 耗时:0.00分/0.37分 | step:  5040 | performance: 0.0 | accuracy: 0.40 | loss: 0.54
update:215/2000, 耗时:0.00分/0.37分 | step:  5160 | performance: 0.1 | accuracy: 0.41 | loss: 1.24
update:220/2000, 耗时:0.00分/0.38分 | step:  5280 | performance: 0.1 | accuracy: 0.42 | loss: 1.19
update:225/2000, 耗时:0.00分/0.39分 | step:  5400 | performance: 0.1 | accuracy: 0.42 | loss: 1.16
update:230/2000, 耗时:0.00分/0.40分 | step:  5520 | performance: 0.1 | accuracy: 0.42 | loss: 0.82
update:235/2000, 耗时:0.00分/0.41分 | step:  5640 | performance: 0.1 | accuracy: 0.43 | loss: 1.41
update:240/2000, 耗时:0.00分/0.42分 | step:  5760 | performance: 0.1 | accuracy: 0.42 | loss: 0.57
update:245/2000, 耗时:0.00分/0.43分 | step:  5880 | performance: 0.1 | accuracy: 0.42 | loss: 0.38
update:250/2000, 耗时:0.00分/0.44分 | step:  6000 | performance: 0.1 | accuracy: 0.42 | loss: 1.04
update:255/2000, 耗时:0.00分/0.45分 | step:  6120 | performance: 0.1 | accuracy: 0.42 | loss: 0.77
update:260/2000, 耗时:0.00分/0.45分 | step:  6240 | performance: 0.1 | accuracy: 0.43 | loss: 0.93
update:265/2000, 耗时:0.00分/0.46分 | step:  6360 | performance: 0.1 | accuracy: 0.43 | loss: 0.82
update:270/2000, 耗时:0.00分/0.47分 | step:  6480 | performance: 0.0 | accuracy: 0.42 | loss: 1.71
update:275/2000, 耗时:0.00分/0.48分 | step:  6600 | performance: 0.0 | accuracy: 0.42 | loss: 0.82
update:280/2000, 耗时:0.00分/0.49分 | step:  6720 | performance: 0.0 | accuracy: 0.42 | loss: 0.62
update:285/2000, 耗时:0.00分/0.50分 | step:  6840 | performance: 0.0 | accuracy: 0.41 | loss: 0.36
update:290/2000, 耗时:0.00分/0.51分 | step:  6960 | performance: 0.0 | accuracy: 0.41 | loss: 0.48
update:295/2000, 耗时:0.00分/0.52分 | step:  7080 | performance: 0.1 | accuracy: 0.40 | loss: 0.36
update:300/2000, 耗时:0.00分/0.53分 | step:  7200 | performance: 0.1 | accuracy: 0.40 | loss: 0.02
update:305/2000, 耗时:0.00分/0.54分 | step:  7320 | performance: 0.1 | accuracy: 0.39 | loss: 0.00
update:310/2000, 耗时:0.00分/0.54分 | step:  7440 | performance: 0.1 | accuracy: 0.39 | loss: 0.04
update:315/2000, 耗时:0.00分/0.55分 | step:  7560 | performance: 0.1 | accuracy: 0.38 | loss: 0.06
update:320/2000, 耗时:0.00分/0.56分 | step:  7680 | performance: 0.1 | accuracy: 0.38 | loss: -0.05
update:325/2000, 耗时:0.00分/0.57分 | step:  7800 | performance: 0.1 | accuracy: 0.37 | loss: 0.14
update:330/2000, 耗时:0.00分/0.58分 | step:  7920 | performance: 0.1 | accuracy: 0.36 | loss: 0.11
update:335/2000, 耗时:0.00分/0.59分 | step:  8040 | performance: 0.1 | accuracy: 0.36 | loss: 0.02
update:340/2000, 耗时:0.00分/0.60分 | step:  8160 | performance: 0.1 | accuracy: 0.35 | loss: 0.18
update:345/2000, 耗时:0.00分/0.61分 | step:  8280 | performance: 0.1 | accuracy: 0.35 | loss: 0.08
update:350/2000, 耗时:0.00分/0.62分 | step:  8400 | performance: 0.1 | accuracy: 0.35 | loss: 0.33
update:355/2000, 耗时:0.00分/0.63分 | step:  8520 | performance: 0.1 | accuracy: 0.34 | loss: 0.23
update:360/2000, 耗时:0.00分/0.63分 | step:  8640 | performance: 0.1 | accuracy: 0.34 | loss: 0.21
update:365/2000, 耗时:0.00分/0.64分 | step:  8760 | performance: 0.1 | accuracy: 0.34 | loss: 0.12
update:370/2000, 耗时:0.00分/0.65分 | step:  8880 | performance: 0.1 | accuracy: 0.33 | loss: 0.08
update:375/2000, 耗时:0.00分/0.66分 | step:  9000 | performance: 0.1 | accuracy: 0.33 | loss: 0.36
update:380/2000, 耗时:0.00分/0.67分 | step:  9120 | performance: 0.1 | accuracy: 0.33 | loss: 1.17
update:385/2000, 耗时:0.00分/0.68分 | step:  9240 | performance: 0.1 | accuracy: 0.32 | loss: 0.15
update:390/2000, 耗时:0.00分/0.69分 | step:  9360 | performance: 0.1 | accuracy: 0.32 | loss: 0.31
update:395/2000, 耗时:0.00分/0.70分 | step:  9480 | performance: 0.1 | accuracy: 0.32 | loss: 0.98
update:400/2000, 耗时:0.00分/0.71分 | step:  9600 | performance: 0.1 | accuracy: 0.32 | loss: 0.40
update:405/2000, 耗时:0.00分/0.72分 | step:  9720 | performance: 0.0 | accuracy: 0.32 | loss: 1.35
update:410/2000, 耗时:0.00分/0.73分 | step:  9840 | performance: 0.0 | accuracy: 0.32 | loss: 1.96
update:415/2000, 耗时:0.00分/0.73分 | step:  9960 | performance: 0.0 | accuracy: 0.32 | loss: 1.19
update:420/2000, 耗时:0.00分/0.74分 | step: 10080 | performance: 0.0 | accuracy: 0.32 | loss: 1.13
update:425/2000, 耗时:0.00分/0.75分 | step: 10200 | performance: 0.0 | accuracy: 0.32 | loss: 1.06
update:430/2000, 耗时:0.00分/0.76分 | step: 10320 | performance: 0.0 | accuracy: 0.32 | loss: 0.63
update:435/2000, 耗时:0.00分/0.77分 | step: 10440 | performance: 0.0 | accuracy: 0.32 | loss: 1.59
update:440/2000, 耗时:0.00分/0.78分 | step: 10560 | performance: 0.0 | accuracy: 0.33 | loss: 1.15
update:445/2000, 耗时:0.00分/0.79分 | step: 10680 | performance: 0.0 | accuracy: 0.33 | loss: 0.46
update:450/2000, 耗时:0.00分/0.80分 | step: 10800 | performance: 0.0 | accuracy: 0.33 | loss: 1.59
update:455/2000, 耗时:0.00分/0.80分 | step: 10920 | performance: 0.0 | accuracy: 0.33 | loss: 1.49
update:460/2000, 耗时:0.00分/0.81分 | step: 11040 | performance: 0.0 | accuracy: 0.33 | loss: 0.44
update:465/2000, 耗时:0.00分/0.82分 | step: 11160 | performance: 0.0 | accuracy: 0.33 | loss: 0.99
update:470/2000, 耗时:0.00分/0.83分 | step: 11280 | performance: 0.0 | accuracy: 0.33 | loss: 0.46
update:475/2000, 耗时:0.00分/0.84分 | step: 11400 | performance: 0.0 | accuracy: 0.33 | loss: 0.51
update:480/2000, 耗时:0.00分/0.85分 | step: 11520 | performance: 0.0 | accuracy: 0.33 | loss: 0.30
update:485/2000, 耗时:0.00分/0.86分 | step: 11640 | performance: 0.0 | accuracy: 0.33 | loss: 0.33
update:490/2000, 耗时:0.00分/0.87分 | step: 11760 | performance: 0.0 | accuracy: 0.33 | loss: 0.23
update:495/2000, 耗时:0.00分/0.87分 | step: 11880 | performance: 0.0 | accuracy: 0.33 | loss: 1.23
update:500/2000, 耗时:0.00分/0.88分 | step: 12000 | performance: 0.0 | accuracy: 0.32 | loss: 0.80
update:505/2000, 耗时:0.00分/0.89分 | step: 12120 | performance: 0.0 | accuracy: 0.32 | loss: 0.88
update:510/2000, 耗时:0.00分/0.90分 | step: 12240 | performance: 0.0 | accuracy: 0.32 | loss: 3.60
update:515/2000, 耗时:0.00分/0.91分 | step: 12360 | performance: 0.0 | accuracy: 0.32 | loss: 1.10
update:520/2000, 耗时:0.00分/0.92分 | step: 12480 | performance: 0.0 | accuracy: 0.33 | loss: 1.10
update:525/2000, 耗时:0.00分/0.93分 | step: 12600 | performance: 0.0 | accuracy: 0.33 | loss: 1.50
update:530/2000, 耗时:0.00分/0.93分 | step: 12720 | performance: 0.0 | accuracy: 0.32 | loss: 0.59
update:535/2000, 耗时:0.00分/0.94分 | step: 12840 | performance: 0.0 | accuracy: 0.32 | loss: 2.35
update:540/2000, 耗时:0.00分/0.95分 | step: 12960 | performance: 0.0 | accuracy: 0.32 | loss: 0.47
update:545/2000, 耗时:0.00分/0.96分 | step: 13080 | performance: 0.0 | accuracy: 0.32 | loss: 0.29
update:550/2000, 耗时:0.00分/0.97分 | step: 13200 | performance: 0.0 | accuracy: 0.32 | loss: 0.14
update:555/2000, 耗时:0.00分/0.98分 | step: 13320 | performance: 0.0 | accuracy: 0.32 | loss: 0.16
update:560/2000, 耗时:0.00分/0.99分 | step: 13440 | performance: 0.0 | accuracy: 0.32 | loss: 0.30
update:565/2000, 耗时:0.00分/0.99分 | step: 13560 | performance: 0.0 | accuracy: 0.31 | loss: 0.24
update:570/2000, 耗时:0.00分/1.00分 | step: 13680 | performance: 0.0 | accuracy: 0.31 | loss: 0.75
update:575/2000, 耗时:0.00分/1.01分 | step: 13800 | performance: 0.0 | accuracy: 0.31 | loss: 0.24
update:580/2000, 耗时:0.00分/1.02分 | step: 13920 | performance: 0.0 | accuracy: 0.31 | loss: 0.35
update:585/2000, 耗时:0.00分/1.03分 | step: 14040 | performance: 0.0 | accuracy: 0.31 | loss: 0.52
update:590/2000, 耗时:0.00分/1.04分 | step: 14160 | performance: 0.0 | accuracy: 0.31 | loss: 0.46
update:595/2000, 耗时:0.00分/1.05分 | step: 14280 | performance: 0.0 | accuracy: 0.31 | loss: 0.45
update:600/2000, 耗时:0.00分/1.05分 | step: 14400 | performance: 0.0 | accuracy: 0.31 | loss: 0.36
update:605/2000, 耗时:0.00分/1.06分 | step: 14520 | performance: 0.0 | accuracy: 0.31 | loss: 0.09
update:610/2000, 耗时:0.00分/1.07分 | step: 14640 | performance: 0.0 | accuracy: 0.31 | loss: 0.04
update:615/2000, 耗时:0.00分/1.08分 | step: 14760 | performance: 0.0 | accuracy: 0.30 | loss: -0.01
update:620/2000, 耗时:0.00分/1.09分 | step: 14880 | performance: 0.0 | accuracy: 0.30 | loss: 0.08
update:625/2000, 耗时:0.00分/1.10分 | step: 15000 | performance: 0.0 | accuracy: 0.30 | loss: 0.31
update:630/2000, 耗时:0.00分/1.11分 | step: 15120 | performance: 0.0 | accuracy: 0.30 | loss: 0.54
update:635/2000, 耗时:0.00分/1.11分 | step: 15240 | performance: 0.0 | accuracy: 0.30 | loss: 0.49
update:640/2000, 耗时:0.00分/1.12分 | step: 15360 | performance: 0.0 | accuracy: 0.30 | loss: 0.41
update:645/2000, 耗时:0.00分/1.13分 | step: 15480 | performance: 0.0 | accuracy: 0.30 | loss: 0.69
update:650/2000, 耗时:0.00分/1.14分 | step: 15600 | performance: 0.0 | accuracy: 0.30 | loss: 0.48
update:655/2000, 耗时:0.00分/1.15分 | step: 15720 | performance: 0.0 | accuracy: 0.30 | loss: 0.10
update:660/2000, 耗时:0.00分/1.16分 | step: 15840 | performance: 0.0 | accuracy: 0.30 | loss: 0.13
update:665/2000, 耗时:0.00分/1.17分 | step: 15960 | performance: 0.0 | accuracy: 0.30 | loss: 0.16
update:670/2000, 耗时:0.00分/1.17分 | step: 16080 | performance: 0.0 | accuracy: 0.29 | loss: 0.05
update:675/2000, 耗时:0.00分/1.18分 | step: 16200 | performance: 0.0 | accuracy: 0.29 | loss: 0.06
update:680/2000, 耗时:0.00分/1.19分 | step: 16320 | performance: 0.0 | accuracy: 0.29 | loss: 0.01
update:685/2000, 耗时:0.00分/1.20分 | step: 16440 | performance: 0.0 | accuracy: 0.29 | loss: 0.09
update:690/2000, 耗时:0.00分/1.21分 | step: 16560 | performance: 0.0 | accuracy: 0.29 | loss: 0.12
update:695/2000, 耗时:0.00分/1.22分 | step: 16680 | performance: 0.0 | accuracy: 0.28 | loss: 0.03
update:700/2000, 耗时:0.00分/1.23分 | step: 16800 | performance: 0.0 | accuracy: 0.28 | loss: 0.01
update:705/2000, 耗时:0.00分/1.23分 | step: 16920 | performance: 0.0 | accuracy: 0.28 | loss: -0.00
update:710/2000, 耗时:0.00分/1.24分 | step: 17040 | performance: 0.0 | accuracy: 0.28 | loss: 0.06
update:715/2000, 耗时:0.00分/1.25分 | step: 17160 | performance: 0.0 | accuracy: 0.28 | loss: -0.01
update:720/2000, 耗时:0.00分/1.26分 | step: 17280 | performance: 0.0 | accuracy: 0.28 | loss: 0.29
update:725/2000, 耗时:0.00分/1.27分 | step: 17400 | performance: 0.0 | accuracy: 0.27 | loss: 0.05
update:730/2000, 耗时:0.00分/1.28分 | step: 17520 | performance: 0.0 | accuracy: 0.27 | loss: 0.08
update:735/2000, 耗时:0.00分/1.29分 | step: 17640 | performance: 0.0 | accuracy: 0.27 | loss: 0.00
update:740/2000, 耗时:0.00分/1.29分 | step: 17760 | performance: 0.0 | accuracy: 0.27 | loss: 0.19
update:745/2000, 耗时:0.00分/1.30分 | step: 17880 | performance: 0.0 | accuracy: 0.27 | loss: -0.02
update:750/2000, 耗时:0.00分/1.31分 | step: 18000 | performance: 0.0 | accuracy: 0.27 | loss: 0.11
update:755/2000, 耗时:0.00分/1.32分 | step: 18120 | performance: 0.0 | accuracy: 0.27 | loss: 0.17
update:760/2000, 耗时:0.00分/1.33分 | step: 18240 | performance: 0.0 | accuracy: 0.26 | loss: 0.33
update:765/2000, 耗时:0.00分/1.34分 | step: 18360 | performance: 0.0 | accuracy: 0.26 | loss: 0.35
update:770/2000, 耗时:0.00分/1.35分 | step: 18480 | performance: 0.0 | accuracy: 0.26 | loss: 0.06
update:775/2000, 耗时:0.00分/1.35分 | step: 18600 | performance: 0.0 | accuracy: 0.26 | loss: 0.29
update:780/2000, 耗时:0.00分/1.36分 | step: 18720 | performance: 0.0 | accuracy: 0.26 | loss: 0.33
update:785/2000, 耗时:0.00分/1.37分 | step: 18840 | performance: 0.0 | accuracy: 0.26 | loss: 0.27
update:790/2000, 耗时:0.00分/1.38分 | step: 18960 | performance: 0.0 | accuracy: 0.26 | loss: 0.76
update:795/2000, 耗时:0.00分/1.39分 | step: 19080 | performance: 0.0 | accuracy: 0.26 | loss: 0.71
update:800/2000, 耗时:0.00分/1.40分 | step: 19200 | performance: 0.0 | accuracy: 0.26 | loss: 1.30
update:805/2000, 耗时:0.00分/1.41分 | step: 19320 | performance: 0.0 | accuracy: 0.26 | loss: 2.27
update:810/2000, 耗时:0.00分/1.42分 | step: 19440 | performance: 0.0 | accuracy: 0.26 | loss: 1.38
update:815/2000, 耗时:0.00分/1.43分 | step: 19560 | performance: 0.0 | accuracy: 0.26 | loss: 1.19
update:820/2000, 耗时:0.00分/1.44分 | step: 19680 | performance: 0.0 | accuracy: 0.26 | loss: 0.88
update:825/2000, 耗时:0.00分/1.45分 | step: 19800 | performance: 0.0 | accuracy: 0.26 | loss: 0.80
update:830/2000, 耗时:0.00分/1.45分 | step: 19920 | performance: 0.0 | accuracy: 0.27 | loss: 2.23
update:835/2000, 耗时:0.00分/1.46分 | step: 20040 | performance: 0.0 | accuracy: 0.27 | loss: 2.40
update:840/2000, 耗时:0.00分/1.47分 | step: 20160 | performance: 0.0 | accuracy: 0.27 | loss: 0.80
update:845/2000, 耗时:0.00分/1.48分 | step: 20280 | performance: 0.0 | accuracy: 0.27 | loss: 1.42
update:850/2000, 耗时:0.00分/1.49分 | step: 20400 | performance: 0.0 | accuracy: 0.27 | loss: 1.02
update:855/2000, 耗时:0.00分/1.50分 | step: 20520 | performance: 0.0 | accuracy: 0.27 | loss: 0.64
update:860/2000, 耗时:0.00分/1.51分 | step: 20640 | performance: 0.0 | accuracy: 0.27 | loss: 1.10
update:865/2000, 耗时:0.00分/1.52分 | step: 20760 | performance: 0.0 | accuracy: 0.27 | loss: 0.44
update:870/2000, 耗时:0.00分/1.53分 | step: 20880 | performance: 0.0 | accuracy: 0.27 | loss: 0.49
update:875/2000, 耗时:0.00分/1.53分 | step: 21000 | performance: 0.0 | accuracy: 0.27 | loss: 1.08
update:880/2000, 耗时:0.00分/1.54分 | step: 21120 | performance: 0.0 | accuracy: 0.27 | loss: 0.78
update:885/2000, 耗时:0.00分/1.55分 | step: 21240 | performance: 0.0 | accuracy: 0.27 | loss: 0.71
update:890/2000, 耗时:0.00分/1.56分 | step: 21360 | performance: 0.0 | accuracy: 0.27 | loss: 0.38
update:895/2000, 耗时:0.00分/1.57分 | step: 21480 | performance: 0.0 | accuracy: 0.27 | loss: 0.07
update:900/2000, 耗时:0.00分/1.58分 | step: 21600 | performance: 0.0 | accuracy: 0.27 | loss: 0.19
update:905/2000, 耗时:0.00分/1.59分 | step: 21720 | performance: 0.0 | accuracy: 0.26 | loss: 0.27
update:910/2000, 耗时:0.00分/1.60分 | step: 21840 | performance: 0.0 | accuracy: 0.26 | loss: 0.26
update:915/2000, 耗时:0.00分/1.61分 | step: 21960 | performance: 0.0 | accuracy: 0.26 | loss: 0.25
update:920/2000, 耗时:0.00分/1.62分 | step: 22080 | performance: 0.0 | accuracy: 0.26 | loss: 0.25
update:925/2000, 耗时:0.00分/1.63分 | step: 22200 | performance: 0.0 | accuracy: 0.26 | loss: 0.67
update:930/2000, 耗时:0.00分/1.64分 | step: 22320 | performance: 0.0 | accuracy: 0.26 | loss: 0.50
update:935/2000, 耗时:0.00分/1.64分 | step: 22440 | performance: 0.0 | accuracy: 0.26 | loss: 0.54
update:940/2000, 耗时:0.00分/1.65分 | step: 22560 | performance: 0.0 | accuracy: 0.26 | loss: 1.18
update:945/2000, 耗时:0.00分/1.66分 | step: 22680 | performance: 0.0 | accuracy: 0.26 | loss: 0.33
update:950/2000, 耗时:0.00分/1.67分 | step: 22800 | performance: 0.0 | accuracy: 0.26 | loss: 2.09
update:955/2000, 耗时:0.00分/1.68分 | step: 22920 | performance: 0.0 | accuracy: 0.26 | loss: 1.37
update:960/2000, 耗时:0.00分/1.69分 | step: 23040 | performance: 0.0 | accuracy: 0.27 | loss: 1.69
update:965/2000, 耗时:0.00分/1.70分 | step: 23160 | performance: 0.0 | accuracy: 0.27 | loss: 0.96
update:970/2000, 耗时:0.00分/1.70分 | step: 23280 | performance: 0.0 | accuracy: 0.27 | loss: 1.63
update:975/2000, 耗时:0.00分/1.71分 | step: 23400 | performance: 0.0 | accuracy: 0.27 | loss: 3.16
update:980/2000, 耗时:0.00分/1.72分 | step: 23520 | performance: 0.0 | accuracy: 0.27 | loss: 2.20
update:985/2000, 耗时:0.00分/1.73分 | step: 23640 | performance: 0.0 | accuracy: 0.27 | loss: 1.24
update:990/2000, 耗时:0.00分/1.74分 | step: 23760 | performance: 0.0 | accuracy: 0.27 | loss: 0.61
update:995/2000, 耗时:0.00分/1.75分 | step: 23880 | performance: 0.0 | accuracy: 0.27 | loss: 1.50
update:1000/2000, 耗时:0.00分/1.76分 | step: 24000 | performance: 0.0 | accuracy: 0.27 | loss: 0.94
update:1005/2000, 耗时:0.00分/1.77分 | step: 24120 | performance: 0.0 | accuracy: 0.27 | loss: 1.01
update:1010/2000, 耗时:0.00分/1.78分 | step: 24240 | performance: 0.0 | accuracy: 0.27 | loss: 0.95
update:1015/2000, 耗时:0.00分/1.78分 | step: 24360 | performance: 0.0 | accuracy: 0.27 | loss: 1.60
update:1020/2000, 耗时:0.00分/1.79分 | step: 24480 | performance: 0.0 | accuracy: 0.28 | loss: 1.79
update:1025/2000, 耗时:0.00分/1.80分 | step: 24600 | performance: 0.0 | accuracy: 0.28 | loss: 0.48
update:1030/2000, 耗时:0.00分/1.81分 | step: 24720 | performance: 0.0 | accuracy: 0.28 | loss: 1.02
update:1035/2000, 耗时:0.00分/1.82分 | step: 24840 | performance: 0.0 | accuracy: 0.28 | loss: 2.86
update:1040/2000, 耗时:0.00分/1.83分 | step: 24960 | performance: 0.0 | accuracy: 0.28 | loss: 0.57
update:1045/2000, 耗时:0.00分/1.84分 | step: 25080 | performance: 0.0 | accuracy: 0.28 | loss: 6.18
update:1050/2000, 耗时:0.00分/1.85分 | step: 25200 | performance: 0.0 | accuracy: 0.28 | loss: 1.54
update:1055/2000, 耗时:0.00分/1.86分 | step: 25320 | performance: 0.0 | accuracy: 0.29 | loss: 2.32
update:1060/2000, 耗时:0.00分/1.87分 | step: 25440 | performance: 0.0 | accuracy: 0.29 | loss: 2.22
update:1065/2000, 耗时:0.00分/1.87分 | step: 25560 | performance: 0.0 | accuracy: 0.29 | loss: 0.53
update:1070/2000, 耗时:0.00分/1.88分 | step: 25680 | performance: 0.0 | accuracy: 0.29 | loss: 1.09
update:1075/2000, 耗时:0.00分/1.89分 | step: 25800 | performance: 0.0 | accuracy: 0.29 | loss: 2.91
update:1080/2000, 耗时:0.00分/1.90分 | step: 25920 | performance: 0.0 | accuracy: 0.29 | loss: 1.12
update:1085/2000, 耗时:0.00分/1.91分 | step: 26040 | performance: 0.0 | accuracy: 0.29 | loss: 1.39
update:1090/2000, 耗时:0.00分/1.92分 | step: 26160 | performance: 0.0 | accuracy: 0.29 | loss: 2.10
update:1095/2000, 耗时:0.00分/1.93分 | step: 26280 | performance: 0.0 | accuracy: 0.29 | loss: 1.00
update:1100/2000, 耗时:0.00分/1.94分 | step: 26400 | performance: 0.0 | accuracy: 0.29 | loss: 0.68
update:1105/2000, 耗时:0.00分/1.94分 | step: 26520 | performance: 0.0 | accuracy: 0.29 | loss: 1.73
update:1110/2000, 耗时:0.00分/1.95分 | step: 26640 | performance: 0.0 | accuracy: 0.30 | loss: 2.29
update:1115/2000, 耗时:0.00分/1.96分 | step: 26760 | performance: 0.0 | accuracy: 0.30 | loss: 1.07
update:1120/2000, 耗时:0.00分/1.97分 | step: 26880 | performance: 0.0 | accuracy: 0.30 | loss: 1.78
update:1125/2000, 耗时:0.00分/1.98分 | step: 27000 | performance: 0.0 | accuracy: 0.30 | loss: 0.88
update:1130/2000, 耗时:0.00分/1.99分 | step: 27120 | performance: 0.0 | accuracy: 0.30 | loss: 1.06
update:1135/2000, 耗时:0.00分/2.00分 | step: 27240 | performance: 0.0 | accuracy: 0.30 | loss: 1.20
update:1140/2000, 耗时:0.00分/2.00分 | step: 27360 | performance: 0.0 | accuracy: 0.30 | loss: 1.12
update:1145/2000, 耗时:0.00分/2.01分 | step: 27480 | performance: 0.0 | accuracy: 0.30 | loss: 0.90
update:1150/2000, 耗时:0.00分/2.02分 | step: 27600 | performance: 0.0 | accuracy: 0.30 | loss: 0.88
update:1155/2000, 耗时:0.00分/2.03分 | step: 27720 | performance: 0.0 | accuracy: 0.30 | loss: 0.66
update:1160/2000, 耗时:0.00分/2.04分 | step: 27840 | performance: 0.0 | accuracy: 0.30 | loss: 0.96
update:1165/2000, 耗时:0.00分/2.05分 | step: 27960 | performance: 0.0 | accuracy: 0.30 | loss: 0.82
update:1170/2000, 耗时:0.00分/2.06分 | step: 28080 | performance: 0.0 | accuracy: 0.30 | loss: 0.75
update:1175/2000, 耗时:0.00分/2.07分 | step: 28200 | performance: 0.0 | accuracy: 0.30 | loss: 0.92
update:1180/2000, 耗时:0.00分/2.07分 | step: 28320 | performance: 1.0 | accuracy: 0.00 | loss: 0.37
Saving PPO weights in both H5 format and checkpoint @ update:1180 
update:1185/2000, 耗时:0.00分/2.09分 | step: 28440 | performance: 0.9 | accuracy: 0.19 | loss: 1.72
Saving PPO weights in both H5 format and checkpoint @ update:1186 
update:1190/2000, 耗时:0.00分/2.10分 | step: 28560 | performance: 0.8 | accuracy: 0.13 | loss: 0.76
update:1195/2000, 耗时:0.00分/2.11分 | step: 28680 | performance: 1.0 | accuracy: 0.40 | loss: 0.86
update:1200/2000, 耗时:0.00分/2.11分 | step: 28800 | performance: 0.8 | accuracy: 0.40 | loss: 2.31
update:1205/2000, 耗时:0.00分/2.12分 | step: 28920 | performance: 0.7 | accuracy: 0.31 | loss: 0.60
update:1210/2000, 耗时:0.00分/2.13分 | step: 29040 | performance: 0.7 | accuracy: 0.30 | loss: 1.45
update:1215/2000, 耗时:0.00分/2.14分 | step: 29160 | performance: 0.6 | accuracy: 0.29 | loss: 1.23
update:1220/2000, 耗时:0.00分/2.15分 | step: 29280 | performance: 0.9 | accuracy: 0.34 | loss: 1.30
update:1225/2000, 耗时:0.00分/2.16分 | step: 29400 | performance: 0.9 | accuracy: 0.35 | loss: 1.24
update:1230/2000, 耗时:0.00分/2.16分 | step: 29520 | performance: 0.7 | accuracy: 0.35 | loss: 1.35
update:1235/2000, 耗时:0.00分/2.17分 | step: 29640 | performance: 0.7 | accuracy: 0.37 | loss: 1.21
update:1240/2000, 耗时:0.00分/2.18分 | step: 29760 | performance: 0.5 | accuracy: 0.36 | loss: 0.88
update:1245/2000, 耗时:0.00分/2.19分 | step: 29880 | performance: 0.5 | accuracy: 0.35 | loss: 1.33
update:1250/2000, 耗时:0.00分/2.20分 | step: 30000 | performance: 0.5 | accuracy: 0.35 | loss: 1.09
update:1255/2000, 耗时:0.00分/2.21分 | step: 30120 | performance: 0.5 | accuracy: 0.37 | loss: 0.97
update:1260/2000, 耗时:0.00分/2.22分 | step: 30240 | performance: 0.5 | accuracy: 0.38 | loss: 1.64
update:1265/2000, 耗时:0.00分/2.22分 | step: 30360 | performance: 0.4 | accuracy: 0.38 | loss: 0.81
update:1270/2000, 耗时:0.00分/2.23分 | step: 30480 | performance: 0.5 | accuracy: 0.39 | loss: 0.54
update:1275/2000, 耗时:0.00分/2.24分 | step: 30600 | performance: 0.5 | accuracy: 0.39 | loss: 1.34
update:1280/2000, 耗时:0.00分/2.25分 | step: 30720 | performance: 0.5 | accuracy: 0.39 | loss: 1.04
update:1285/2000, 耗时:0.00分/2.26分 | step: 30840 | performance: 0.5 | accuracy: 0.40 | loss: 1.54
update:1290/2000, 耗时:0.00分/2.27分 | step: 30960 | performance: 0.4 | accuracy: 0.40 | loss: 0.48
update:1295/2000, 耗时:0.00分/2.28分 | step: 31080 | performance: 0.3 | accuracy: 0.40 | loss: 1.10
update:1300/2000, 耗时:0.00分/2.28分 | step: 31200 | performance: 0.2 | accuracy: 0.39 | loss: 0.80
update:1305/2000, 耗时:0.00分/2.29分 | step: 31320 | performance: 0.2 | accuracy: 0.38 | loss: 1.27
update:1310/2000, 耗时:0.00分/2.30分 | step: 31440 | performance: 0.2 | accuracy: 0.37 | loss: 0.60
update:1315/2000, 耗时:0.00分/2.31分 | step: 31560 | performance: 0.1 | accuracy: 0.38 | loss: 1.34
update:1320/2000, 耗时:0.00分/2.32分 | step: 31680 | performance: 0.1 | accuracy: 0.38 | loss: 1.13
update:1325/2000, 耗时:0.00分/2.33分 | step: 31800 | performance: 0.1 | accuracy: 0.38 | loss: 0.61
update:1330/2000, 耗时:0.00分/2.34分 | step: 31920 | performance: 0.1 | accuracy: 0.38 | loss: 1.32
update:1335/2000, 耗时:0.00分/2.34分 | step: 32040 | performance: 0.1 | accuracy: 0.38 | loss: 1.70
update:1340/2000, 耗时:0.00分/2.35分 | step: 32160 | performance: 0.1 | accuracy: 0.38 | loss: 1.53
update:1345/2000, 耗时:0.00分/2.36分 | step: 32280 | performance: 0.1 | accuracy: 0.38 | loss: 1.36
update:1350/2000, 耗时:0.00分/2.37分 | step: 32400 | performance: 0.1 | accuracy: 0.39 | loss: 1.43
update:1355/2000, 耗时:0.00分/2.38分 | step: 32520 | performance: 0.1 | accuracy: 0.39 | loss: 0.86
update:1360/2000, 耗时:0.00分/2.39分 | step: 32640 | performance: 0.1 | accuracy: 0.39 | loss: 1.86
update:1365/2000, 耗时:0.00分/2.39分 | step: 32760 | performance: 0.1 | accuracy: 0.40 | loss: 0.74
update:1370/2000, 耗时:0.00分/2.40分 | step: 32880 | performance: 0.1 | accuracy: 0.41 | loss: 2.41
update:1375/2000, 耗时:0.00分/2.41分 | step: 33000 | performance: 0.1 | accuracy: 0.41 | loss: 2.63
update:1380/2000, 耗时:0.00分/2.42分 | step: 33120 | performance: 0.1 | accuracy: 0.41 | loss: 1.55
update:1385/2000, 耗时:0.00分/2.43分 | step: 33240 | performance: 0.1 | accuracy: 0.42 | loss: 0.68
update:1390/2000, 耗时:0.00分/2.44分 | step: 33360 | performance: 0.1 | accuracy: 0.42 | loss: 0.77
update:1395/2000, 耗时:0.00分/2.44分 | step: 33480 | performance: 0.1 | accuracy: 0.42 | loss: 0.97
update:1400/2000, 耗时:0.00分/2.45分 | step: 33600 | performance: 0.1 | accuracy: 0.42 | loss: 0.62
update:1405/2000, 耗时:0.00分/2.46分 | step: 33720 | performance: 0.1 | accuracy: 0.43 | loss: 1.43
update:1410/2000, 耗时:0.00分/2.47分 | step: 33840 | performance: 0.1 | accuracy: 0.43 | loss: 0.91
update:1415/2000, 耗时:0.00分/2.48分 | step: 33960 | performance: 0.1 | accuracy: 0.43 | loss: 0.83
update:1420/2000, 耗时:0.00分/2.49分 | step: 34080 | performance: 0.1 | accuracy: 0.42 | loss: 1.36
update:1425/2000, 耗时:0.00分/2.49分 | step: 34200 | performance: 0.1 | accuracy: 0.42 | loss: 0.76
update:1430/2000, 耗时:0.00分/2.50分 | step: 34320 | performance: 0.1 | accuracy: 0.43 | loss: 0.72
update:1435/2000, 耗时:0.00分/2.51分 | step: 34440 | performance: 0.1 | accuracy: 0.43 | loss: 0.64
update:1440/2000, 耗时:0.00分/2.52分 | step: 34560 | performance: 0.1 | accuracy: 0.43 | loss: 0.73
update:1445/2000, 耗时:0.00分/2.53分 | step: 34680 | performance: 0.1 | accuracy: 0.43 | loss: 1.59
update:1450/2000, 耗时:0.00分/2.54分 | step: 34800 | performance: 0.1 | accuracy: 0.42 | loss: 0.73
update:1455/2000, 耗时:0.00分/2.55分 | step: 34920 | performance: 0.1 | accuracy: 0.42 | loss: 0.82
update:1460/2000, 耗时:0.00分/2.55分 | step: 35040 | performance: 0.1 | accuracy: 0.42 | loss: 0.72
update:1465/2000, 耗时:0.00分/2.56分 | step: 35160 | performance: 0.1 | accuracy: 0.42 | loss: 0.65
update:1470/2000, 耗时:0.00分/2.57分 | step: 35280 | performance: 0.1 | accuracy: 0.41 | loss: 0.34
update:1475/2000, 耗时:0.00分/2.58分 | step: 35400 | performance: 0.1 | accuracy: 0.41 | loss: 0.60
update:1480/2000, 耗时:0.00分/2.59分 | step: 35520 | performance: 0.1 | accuracy: 0.41 | loss: -0.01
update:1485/2000, 耗时:0.00分/2.60分 | step: 35640 | performance: 0.1 | accuracy: 0.41 | loss: -0.02
update:1490/2000, 耗时:0.00分/2.61分 | step: 35760 | performance: 0.1 | accuracy: 0.40 | loss: 0.01
update:1495/2000, 耗时:0.00分/2.62分 | step: 35880 | performance: 0.1 | accuracy: 0.40 | loss: 0.12
update:1500/2000, 耗时:0.00分/2.62分 | step: 36000 | performance: 0.1 | accuracy: 0.39 | loss: 0.51
update:1505/2000, 耗时:0.00分/2.63分 | step: 36120 | performance: 0.1 | accuracy: 0.38 | loss: 0.47
update:1510/2000, 耗时:0.00分/2.64分 | step: 36240 | performance: 0.1 | accuracy: 0.38 | loss: 0.12
update:1515/2000, 耗时:0.00分/2.65分 | step: 36360 | performance: 0.1 | accuracy: 0.38 | loss: 0.44
update:1520/2000, 耗时:0.00分/2.66分 | step: 36480 | performance: 0.1 | accuracy: 0.37 | loss: -0.00
update:1525/2000, 耗时:0.00分/2.67分 | step: 36600 | performance: 0.1 | accuracy: 0.36 | loss: 0.20
update:1530/2000, 耗时:0.00分/2.68分 | step: 36720 | performance: 0.1 | accuracy: 0.36 | loss: 0.12
update:1535/2000, 耗时:0.00分/2.68分 | step: 36840 | performance: 0.1 | accuracy: 0.36 | loss: 0.05
update:1540/2000, 耗时:0.00分/2.69分 | step: 36960 | performance: 0.1 | accuracy: 0.35 | loss: 0.09
update:1545/2000, 耗时:0.00分/2.70分 | step: 37080 | performance: 0.1 | accuracy: 0.35 | loss: 0.20
update:1550/2000, 耗时:0.00分/2.71分 | step: 37200 | performance: 0.1 | accuracy: 0.34 | loss: 0.31
update:1555/2000, 耗时:0.00分/2.72分 | step: 37320 | performance: 0.1 | accuracy: 0.34 | loss: 0.50
update:1560/2000, 耗时:0.00分/2.73分 | step: 37440 | performance: 0.1 | accuracy: 0.34 | loss: 0.26
update:1565/2000, 耗时:0.00分/2.74分 | step: 37560 | performance: 0.1 | accuracy: 0.34 | loss: 0.14
update:1570/2000, 耗时:0.00分/2.74分 | step: 37680 | performance: 0.1 | accuracy: 0.33 | loss: 0.31
update:1575/2000, 耗时:0.00分/2.75分 | step: 37800 | performance: 0.1 | accuracy: 0.33 | loss: 0.55
update:1580/2000, 耗时:0.00分/2.76分 | step: 37920 | performance: 0.1 | accuracy: 0.33 | loss: 0.65
update:1585/2000, 耗时:0.00分/2.77分 | step: 38040 | performance: 0.1 | accuracy: 0.33 | loss: 0.81
update:1590/2000, 耗时:0.00分/2.78分 | step: 38160 | performance: 0.1 | accuracy: 0.33 | loss: 1.07
update:1595/2000, 耗时:0.00分/2.79分 | step: 38280 | performance: 0.1 | accuracy: 0.33 | loss: 1.13
update:1600/2000, 耗时:0.00分/2.80分 | step: 38400 | performance: 0.2 | accuracy: 0.33 | loss: 0.87
update:1605/2000, 耗时:0.00分/2.80分 | step: 38520 | performance: 0.2 | accuracy: 0.33 | loss: 0.68
update:1610/2000, 耗时:0.00分/2.81分 | step: 38640 | performance: 0.2 | accuracy: 0.33 | loss: 1.05
update:1615/2000, 耗时:0.00分/2.82分 | step: 38760 | performance: 0.2 | accuracy: 0.33 | loss: 0.68
update:1620/2000, 耗时:0.00分/2.83分 | step: 38880 | performance: 0.2 | accuracy: 0.33 | loss: 1.52
update:1625/2000, 耗时:0.00分/2.84分 | step: 39000 | performance: 0.2 | accuracy: 0.34 | loss: 0.75
update:1630/2000, 耗时:0.00分/2.85分 | step: 39120 | performance: 0.2 | accuracy: 0.34 | loss: 1.87
update:1635/2000, 耗时:0.00分/2.86分 | step: 39240 | performance: 0.2 | accuracy: 0.34 | loss: 1.74
update:1640/2000, 耗时:0.00分/2.86分 | step: 39360 | performance: 0.2 | accuracy: 0.34 | loss: 1.13
update:1645/2000, 耗时:0.00分/2.87分 | step: 39480 | performance: 0.2 | accuracy: 0.35 | loss: 0.59
update:1650/2000, 耗时:0.00分/2.88分 | step: 39600 | performance: 0.2 | accuracy: 0.35 | loss: 0.64
update:1655/2000, 耗时:0.00分/2.89分 | step: 39720 | performance: 0.2 | accuracy: 0.35 | loss: 0.64
update:1660/2000, 耗时:0.00分/2.90分 | step: 39840 | performance: 0.2 | accuracy: 0.35 | loss: 0.75
update:1665/2000, 耗时:0.00分/2.91分 | step: 39960 | performance: 0.2 | accuracy: 0.35 | loss: 0.65
update:1670/2000, 耗时:0.00分/2.91分 | step: 40080 | performance: 0.1 | accuracy: 0.35 | loss: 0.57
update:1675/2000, 耗时:0.00分/2.92分 | step: 40200 | performance: 0.1 | accuracy: 0.35 | loss: 0.72
update:1680/2000, 耗时:0.00分/2.93分 | step: 40320 | performance: 0.1 | accuracy: 0.34 | loss: 0.17
update:1685/2000, 耗时:0.00分/2.94分 | step: 40440 | performance: 0.1 | accuracy: 0.34 | loss: 0.54
update:1690/2000, 耗时:0.00分/2.95分 | step: 40560 | performance: 0.1 | accuracy: 0.34 | loss: 1.75
update:1695/2000, 耗时:0.00分/2.96分 | step: 40680 | performance: 0.1 | accuracy: 0.34 | loss: 2.58
update:1700/2000, 耗时:0.00分/2.96分 | step: 40800 | performance: 0.1 | accuracy: 0.34 | loss: 1.42
update:1705/2000, 耗时:0.00分/2.97分 | step: 40920 | performance: 0.0 | accuracy: 0.34 | loss: 0.50
update:1710/2000, 耗时:0.00分/2.98分 | step: 41040 | performance: 0.0 | accuracy: 0.34 | loss: 1.16
update:1715/2000, 耗时:0.00分/2.99分 | step: 41160 | performance: 0.0 | accuracy: 0.34 | loss: 0.73
update:1720/2000, 耗时:0.00分/3.00分 | step: 41280 | performance: 0.0 | accuracy: 0.34 | loss: 1.15
update:1725/2000, 耗时:0.00分/3.01分 | step: 41400 | performance: 0.0 | accuracy: 0.34 | loss: 0.33
update:1730/2000, 耗时:0.00分/3.02分 | step: 41520 | performance: 0.0 | accuracy: 0.34 | loss: 0.37
update:1735/2000, 耗时:0.00分/3.02分 | step: 41640 | performance: 0.0 | accuracy: 0.34 | loss: 0.11
update:1740/2000, 耗时:0.00分/3.03分 | step: 41760 | performance: 0.0 | accuracy: 0.34 | loss: 0.25
update:1745/2000, 耗时:0.00分/3.04分 | step: 41880 | performance: 0.0 | accuracy: 0.34 | loss: 0.48
update:1750/2000, 耗时:0.00分/3.05分 | step: 42000 | performance: 0.0 | accuracy: 0.34 | loss: 0.31
update:1755/2000, 耗时:0.00分/3.06分 | step: 42120 | performance: 0.0 | accuracy: 0.33 | loss: 0.35
update:1760/2000, 耗时:0.00分/3.07分 | step: 42240 | performance: 0.0 | accuracy: 0.33 | loss: 0.70
update:1765/2000, 耗时:0.00分/3.08分 | step: 42360 | performance: 0.0 | accuracy: 0.33 | loss: 0.68
update:1770/2000, 耗时:0.00分/3.08分 | step: 42480 | performance: 0.0 | accuracy: 0.33 | loss: 0.76
update:1775/2000, 耗时:0.00分/3.09分 | step: 42600 | performance: 0.0 | accuracy: 0.33 | loss: 0.58
update:1780/2000, 耗时:0.00分/3.10分 | step: 42720 | performance: 0.0 | accuracy: 0.33 | loss: 0.49
update:1785/2000, 耗时:0.00分/3.11分 | step: 42840 | performance: 0.0 | accuracy: 0.33 | loss: 0.19
update:1790/2000, 耗时:0.00分/3.12分 | step: 42960 | performance: 0.0 | accuracy: 0.33 | loss: 0.34
update:1795/2000, 耗时:0.00分/3.13分 | step: 43080 | performance: 0.0 | accuracy: 0.33 | loss: 0.21
update:1800/2000, 耗时:0.00分/3.14分 | step: 43200 | performance: 0.0 | accuracy: 0.33 | loss: 0.06
update:1805/2000, 耗时:0.00分/3.15分 | step: 43320 | performance: 0.0 | accuracy: 0.33 | loss: 0.50
update:1810/2000, 耗时:0.00分/3.15分 | step: 43440 | performance: 0.0 | accuracy: 0.33 | loss: 0.34
update:1815/2000, 耗时:0.00分/3.16分 | step: 43560 | performance: 0.0 | accuracy: 0.32 | loss: 0.38
update:1820/2000, 耗时:0.00分/3.17分 | step: 43680 | performance: 0.0 | accuracy: 0.32 | loss: 0.64
update:1825/2000, 耗时:0.00分/3.18分 | step: 43800 | performance: 0.0 | accuracy: 0.32 | loss: 0.38
update:1830/2000, 耗时:0.00分/3.19分 | step: 43920 | performance: 0.0 | accuracy: 0.32 | loss: 0.24
update:1835/2000, 耗时:0.00分/3.20分 | step: 44040 | performance: 0.0 | accuracy: 0.32 | loss: 0.43
update:1840/2000, 耗时:0.00分/3.21分 | step: 44160 | performance: 0.1 | accuracy: 0.32 | loss: -0.00
update:1845/2000, 耗时:0.00分/3.21分 | step: 44280 | performance: 0.1 | accuracy: 0.32 | loss: 0.13
update:1850/2000, 耗时:0.00分/3.22分 | step: 44400 | performance: 0.1 | accuracy: 0.32 | loss: 0.02
update:1855/2000, 耗时:0.00分/3.23分 | step: 44520 | performance: 0.1 | accuracy: 0.32 | loss: 0.19
update:1860/2000, 耗时:0.00分/3.24分 | step: 44640 | performance: 0.1 | accuracy: 0.32 | loss: 0.01
update:1865/2000, 耗时:0.00分/3.25分 | step: 44760 | performance: 0.1 | accuracy: 0.31 | loss: 0.02
update:1870/2000, 耗时:0.00分/3.26分 | step: 44880 | performance: 0.1 | accuracy: 0.31 | loss: 0.07
update:1875/2000, 耗时:0.00分/3.27分 | step: 45000 | performance: 0.1 | accuracy: 0.31 | loss: 0.12
update:1880/2000, 耗时:0.00分/3.27分 | step: 45120 | performance: 0.1 | accuracy: 0.31 | loss: 0.01
update:1885/2000, 耗时:0.00分/3.28分 | step: 45240 | performance: 0.1 | accuracy: 0.30 | loss: 0.00
update:1890/2000, 耗时:0.00分/3.29分 | step: 45360 | performance: 0.1 | accuracy: 0.30 | loss: -0.00
update:1895/2000, 耗时:0.00分/3.30分 | step: 45480 | performance: 0.1 | accuracy: 0.30 | loss: 0.18
update:1900/2000, 耗时:0.00分/3.31分 | step: 45600 | performance: 0.1 | accuracy: 0.30 | loss: 0.21
update:1905/2000, 耗时:0.00分/3.32分 | step: 45720 | performance: 0.1 | accuracy: 0.30 | loss: 0.13
update:1910/2000, 耗时:0.00分/3.33分 | step: 45840 | performance: 0.1 | accuracy: 0.30 | loss: -0.01
update:1915/2000, 耗时:0.00分/3.33分 | step: 45960 | performance: 0.1 | accuracy: 0.29 | loss: 0.04
update:1920/2000, 耗时:0.00分/3.34分 | step: 46080 | performance: 0.1 | accuracy: 0.29 | loss: 0.30
update:1925/2000, 耗时:0.00分/3.35分 | step: 46200 | performance: 0.1 | accuracy: 0.29 | loss: 0.01
update:1930/2000, 耗时:0.00分/3.36分 | step: 46320 | performance: 0.1 | accuracy: 0.29 | loss: 0.12
update:1935/2000, 耗时:0.00分/3.37分 | step: 46440 | performance: 0.1 | accuracy: 0.29 | loss: 0.24
update:1940/2000, 耗时:0.00分/3.38分 | step: 46560 | performance: 0.1 | accuracy: 0.29 | loss: 0.55
update:1945/2000, 耗时:0.00分/3.39分 | step: 46680 | performance: 0.1 | accuracy: 0.28 | loss: 0.07
update:1950/2000, 耗时:0.00分/3.39分 | step: 46800 | performance: 0.1 | accuracy: 0.28 | loss: 0.05
update:1955/2000, 耗时:0.00分/3.40分 | step: 46920 | performance: 0.1 | accuracy: 0.28 | loss: 0.21
update:1960/2000, 耗时:0.00分/3.41分 | step: 47040 | performance: 0.1 | accuracy: 0.28 | loss: 0.60
update:1965/2000, 耗时:0.00分/3.42分 | step: 47160 | performance: 0.1 | accuracy: 0.28 | loss: 0.13
update:1970/2000, 耗时:0.00分/3.43分 | step: 47280 | performance: 0.1 | accuracy: 0.28 | loss: 0.80
update:1975/2000, 耗时:0.00分/3.44分 | step: 47400 | performance: 0.1 | accuracy: 0.28 | loss: 1.06
update:1980/2000, 耗时:0.00分/3.45分 | step: 47520 | performance: 0.1 | accuracy: 0.28 | loss: 0.82
update:1985/2000, 耗时:0.00分/3.45分 | step: 47640 | performance: 0.1 | accuracy: 0.28 | loss: 2.34
update:1990/2000, 耗时:0.00分/3.46分 | step: 47760 | performance: 0.1 | accuracy: 0.28 | loss: 1.28
update:1995/2000, 耗时:0.00分/3.47分 | step: 47880 | performance: 0.1 | accuracy: 0.28 | loss: 0.90
  0%|          | 0/408 [00:00<?, ?it/s]100%|| 408/408 [00:00<00:00, 102196.24it/s]
update:2000/2000, 耗时:0.00分/3.48分 | step: 48000 | performance: 0.1 | accuracy: 0.28 | loss: 0.84
----------------------------------------finished----------------------------------------
==================================================
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1042.98
2023-07-24T12:00:00 | net performance [%] = 4.2981
2023-07-24T12:00:00 | number of trades [#] = 42
==================================================
Trial 5 Complete [00h 03m 55s]
net_wealth: 1044.0254539231912

Best net_wealth So Far: 1380.2023481050508
Total elapsed time: 00h 25m 10s

Search: Running Trial #6

Value             |Best Value So Far |Hyperparameter
3                 |1                 |horizon
365               |225               |lookback
False             |False             |MarketFactor
20                |8                 |lags
0.95              |0.9               |gamma
32                |32                |batch_size
10                |10                |n_step
0.94              |0.92              |gae_lambda
0.5               |2                 |gradient_clip_norm
3                 |3                 |epochs
0.001             |5e-05             |actor_lr
0.0001            |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4312.000000   4315.000000
mean      0.000441    20062.255222  ...   20129.629835  20118.633889
std       0.027818    16039.874230  ...   16077.282571  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7694.525024   7690.540039
50%       0.000642    11554.824463  ...   11737.255371  11715.610352
75%       0.011655    29873.081836  ...   29933.737305  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-27 22:28:32.915784: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binar2023-07-27 22:28:32.915833: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is 2023-07-27 22:28:32.915889: I tensorflow/core/platform/cpu_feature_guard.cc:142] This Ten2y is optimized with oosorFptilnmoeiwAz Pe20b23-07-27ina I Deep Nr2ey i2ural :s2Netw 8:3o2op.rk L9ti1brary (oneDNN5imized)9 70: t wIo used with ith o 0t2enn3-07-2seAo7 22:28:3P2I.r f9lDee1p5ow/ 9Nc 3or1:eone/ur IpeAPI Dateehp el Neural Network Librarya tfl  Neenstwtorflofoork ol(oLirw/corml/nce/pbueorwiaplatform/crDNN) nyg (oneDNN) topCu _Pfuse the feU aollowing CPU insituntructrstei_ructoion2ns in ps in guar_featpure_g to 2de20u20.2ce3-u07r-frsfaoorrcrm0d.cc:amn:e 1422tance-h1cce-]342c]- Thi07rs 3 This T-ei0ticen2 f7- 72-227osal oroirF2 T2e2:pt27leor:ali82:83 t2nws obi:o3n2s:clri2. . AV99F1l614naalr 02oXw y 0:: 2I8 6Aoopwii:s33b9V Xonie2ra.7n9g CpP:1ttions UIi26 aryt:e i m
iTn nistsor tseonzse r3ed optf5orfl An1:oiwmVla bwu/iXz lIc AVcX2 etorito etnhte
/we/d iho newistonTcohs mpelao  oArPtorniiffeeAPnIn or Il Dot/epnlaeep abml/  owhecpperDfeoe eth/Np Nutfeerem in rocomuu_rfe/roaraarnmeatulrc eNee_t-cgw /lruiatricpoudt_feahcr kNe.tcw oLtc:p14aruoeirl rpberak2el_grr  aLuatyopirf ]( atdoooTnebi.opeerDaNtrimh/rarcNc)nys,p  ircretbou il s(uaotnisu_odo Tne sT::14nsee ns  AVfnesao,tX o2r]F lr trTehbiuoFehDeNNAlo wfolsi lb) lwV Xw2itoi td nTurh  Taernoey_ gestor
FnlsoowrusheeTw uwairtdF ih ntg C. ohieclt a pahoswppcp:r ree obptiomp ofnpro1irziatle coea4PUl owbim2l]e pThis Tinieledrn gi waitshtr u tn oftCePcUt hsenleAPiomr Fin Io  loiansciotnhse r owgioDm tsr.uncpeeepnb ipneilraryrp
er flformat a aatiois Neuraoryptln Niemtc ngss.ei wio
-isin pcr ork Librnzieticald with oneAPI Deep Neural Ns operate,ary (iooneterfonrs:  AVX AVX2
DwNomancrN)Tko L een-ciobrary (r ipatttbo ilicale mized wiuth eoperations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriattm in osne the following CPU inheDNN roes tructions)e ob tihe tco use thnrui neAPI Deep  epeNoemolpprdurai f erations,T ofllrrebensuooe Network LimilanrdlFcre -crbfrar lolitaTeniglow sorFlowcwawiith nls ywith the approp .o
p tr(hego iaer tnCPU instructions in peaeDNN) to use the following CPU instruce ppropriate comrtionsapciolfto mieirno nfrpmanill performancsc: aer flags.
ee-cr-gcritical operations:  A itsV.iXca AV
l operations: AV X AVX2
To enable tAX2hem in other operations, rebuild TensorFlow witVX AVX2
To enable h the appropriate compiler flags.
them in other operations, rebuild TensorFlow with the appropriate compiler flags.

To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-27 22:28:33.558106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:28:33.569249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:28:33.569658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:28:33.573572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:28:33.583089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:28:33.583510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:28:33.606310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device 2023/j-o0b:loc7alhost/replica:0-27 22:28:33.606310: I tensorflow/task:/0c/odevice:GPU:0re/common_ runtwith 54i5me/gpu/gpu_de4 MB mvice.cemory:  ->c:151 device: 0, name: NVIDIA G0eF] orce CreatRTX 3070, pcied de vbus ice /jobid: 000:localh0ost/replica:0/tas:01:00.0k:0/devic, computee:GPU:0 w capaibility: 8.6t
h 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
Saving PPO weights in both H5 format and checkpoint @ update:2 
update:  5/2000, 耗时:0.00分/0.04分 | step:   400 | performance: 0.9 | accuracy: 0.32 | loss: 2.56
update: 10/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 1.0 | accuracy: 0.33 | loss: 1.31
update: 15/2000, 耗时:0.00分/0.06分 | step:  1200 | performance: 0.7 | accuracy: 0.31 | loss: 0.94
update: 20/2000, 耗时:0.00分/0.07分 | step:  1600 | performance: 0.5 | accuracy: 0.25 | loss: 0.55
update: 25/2000, 耗时:0.00分/0.08分 | step:  2000 | performance: 0.6 | accuracy: 0.22 | loss: 0.48
update: 30/2000, 耗时:0.00分/0.10分 | step:  2400 | performance: 0.7 | accuracy: 0.21 | loss: 1.94
update: 35/2000, 耗时:0.00分/0.11分 | step:  2800 | performance: 0.6 | accuracy: 0.22 | loss: 1.69
update: 40/2000, 耗时:0.00分/0.12分 | step:  3200 | performance: 0.6 | accuracy: 0.21 | loss: 0.58
update: 45/2000, 耗时:0.00分/0.13分 | step:  3600 | performance: 0.5 | accuracy: 0.20 | loss: 1.04
update: 50/2000, 耗时:0.00分/0.15分 | step:  4000 | performance: 0.6 | accuracy: 0.20 | loss: 1.95
update: 55/2000, 耗时:0.00分/0.16分 | step:  4400 | performance: 3.3 | accuracy: 0.25 | loss: 9.16
update: 60/2000, 耗时:0.00分/0.17分 | step:  4800 | performance: 2.5 | accuracy: 0.26 | loss: 1.32
update: 65/2000, 耗时:0.00分/0.19分 | step:  5200 | performance: 2.9 | accuracy: 0.27 | loss: 0.90
update: 70/2000, 耗时:0.00分/0.20分 | step:  5600 | performance: 2.6 | accuracy: 0.27 | loss: 6.39
update: 75/2000, 耗时:0.00分/0.22分 | step:  6000 | performance: 2.6 | accuracy: 0.27 | loss: 0.79
update: 80/2000, 耗时:0.00分/0.23分 | step:  6400 | performance: 1.9 | accuracy: 0.26 | loss: 1.11
update: 85/2000, 耗时:0.00分/0.24分 | step:  6800 | performance: 2.4 | accuracy: 0.27 | loss: 1.33
update: 90/2000, 耗时:0.00分/0.26分 | step:  7200 | performance: 6.3 | accuracy: 0.29 | loss: 1.97
update: 95/2000, 耗时:0.00分/0.27分 | step:  7600 | performance: 16.9 | accuracy: 0.31 | loss: 12.98
update:100/2000, 耗时:0.00分/0.29分 | step:  8000 | performance: 11.2 | accuracy: 0.32 | loss: 3.22
update:105/2000, 耗时:0.00分/0.30分 | step:  8400 | performance: 8.4 | accuracy: 0.33 | loss: 6.89
update:110/2000, 耗时:0.00分/0.31分 | step:  8800 | performance: 8.5 | accuracy: 0.34 | loss: 2.01
update:115/2000, 耗时:0.00分/0.33分 | step:  9200 | performance: 6.8 | accuracy: 0.33 | loss: 1.69
update:120/2000, 耗时:0.00分/0.34分 | step:  9600 | performance: 8.7 | accuracy: 0.34 | loss: 1.35
update:125/2000, 耗时:0.00分/0.36分 | step: 10000 | performance: 13.7 | accuracy: 0.34 | loss: 2.92
update:130/2000, 耗时:0.00分/0.37分 | step: 10400 | performance: 16.1 | accuracy: 0.34 | loss: 4.83
update:135/2000, 耗时:0.00分/0.39分 | step: 10800 | performance: 8.4 | accuracy: 0.34 | loss: 1.09
update:140/2000, 耗时:0.00分/0.40分 | step: 11200 | performance: 7.8 | accuracy: 0.34 | loss: 2.14
update:145/2000, 耗时:0.00分/0.41分 | step: 11600 | performance: 8.9 | accuracy: 0.35 | loss: 2.07
update:150/2000, 耗时:0.00分/0.43分 | step: 12000 | performance: 18.6 | accuracy: 0.35 | loss: 1.69
update:155/2000, 耗时:0.00分/0.44分 | step: 12400 | performance: 10.6 | accuracy: 0.34 | loss: 1.26
update:160/2000, 耗时:0.00分/0.46分 | step: 12800 | performance: 10.8 | accuracy: 0.34 | loss: 1.45
update:165/2000, 耗时:0.00分/0.47分 | step: 13200 | performance: 9.2 | accuracy: 0.34 | loss: 1.09
update:170/2000, 耗时:0.00分/0.49分 | step: 13600 | performance: 9.1 | accuracy: 0.34 | loss: 1.32
update:175/2000, 耗时:0.00分/0.50分 | step: 14000 | performance: 7.5 | accuracy: 0.33 | loss: 2.20
update:180/2000, 耗时:0.00分/0.51分 | step: 14400 | performance: 5.3 | accuracy: 0.33 | loss: 1.01
update:185/2000, 耗时:0.00分/0.53分 | step: 14800 | performance: 7.0 | accuracy: 0.33 | loss: 0.93
update:190/2000, 耗时:0.00分/0.54分 | step: 15200 | performance: 10.4 | accuracy: 0.34 | loss: 2.22
update:195/2000, 耗时:0.00分/0.56分 | step: 15600 | performance: 24.3 | accuracy: 0.35 | loss: 5.18
update:200/2000, 耗时:0.00分/0.57分 | step: 16000 | performance: 42.8 | accuracy: 0.35 | loss: 4.62
update:205/2000, 耗时:0.00分/0.59分 | step: 16400 | performance: 109.2 | accuracy: 0.36 | loss: 8.47
update:210/2000, 耗时:0.00分/0.60分 | step: 16800 | performance: 224.7 | accuracy: 0.37 | loss: 6.73
update:215/2000, 耗时:0.00分/0.61分 | step: 17200 | performance: 619.7 | accuracy: 0.37 | loss: 2.78
update:220/2000, 耗时:0.00分/0.63分 | step: 17600 | performance: 950.1 | accuracy: 0.38 | loss: 9.98
update:225/2000, 耗时:0.00分/0.64分 | step: 18000 | performance: 984.5 | accuracy: 0.38 | loss: 1.45
update:230/2000, 耗时:0.00分/0.66分 | step: 18400 | performance: 847.2 | accuracy: 0.38 | loss: 2.20
update:235/2000, 耗时:0.00分/0.67分 | step: 18800 | performance: 226.9 | accuracy: 0.38 | loss: 3.29
update:240/2000, 耗时:0.00分/0.69分 | step: 19200 | performance: 173.9 | accuracy: 0.38 | loss: 2.10
update:245/2000, 耗时:0.00分/0.70分 | step: 19600 | performance: 248.3 | accuracy: 0.38 | loss: 3.33
update:250/2000, 耗时:0.00分/0.72分 | step: 20000 | performance: 124.8 | accuracy: 0.38 | loss: 4.50
update:255/2000, 耗时:0.00分/0.73分 | step: 20400 | performance: 106.1 | accuracy: 0.38 | loss: 1.40
update:260/2000, 耗时:0.00分/0.74分 | step: 20800 | performance: 120.1 | accuracy: 0.38 | loss: 1.50
update:265/2000, 耗时:0.00分/0.76分 | step: 21200 | performance: 133.2 | accuracy: 0.38 | loss: 1.50
update:270/2000, 耗时:0.00分/0.77分 | step: 21600 | performance: 126.4 | accuracy: 0.37 | loss: 0.58
update:275/2000, 耗时:0.00分/0.79分 | step: 22000 | performance: 116.6 | accuracy: 0.37 | loss: 1.00
update:280/2000, 耗时:0.00分/0.80分 | step: 22400 | performance: 97.3 | accuracy: 0.37 | loss: 0.70
update:285/2000, 耗时:0.00分/0.82分 | step: 22800 | performance: 129.4 | accuracy: 0.37 | loss: 1.71
update:290/2000, 耗时:0.00分/0.83分 | step: 23200 | performance: 215.6 | accuracy: 0.37 | loss: 0.50
update:295/2000, 耗时:0.00分/0.84分 | step: 23600 | performance: 164.7 | accuracy: 0.36 | loss: 0.31
update:300/2000, 耗时:0.00分/0.86分 | step: 24000 | performance: 211.3 | accuracy: 0.36 | loss: 0.85
update:305/2000, 耗时:0.00分/0.87分 | step: 24400 | performance: 210.8 | accuracy: 0.36 | loss: 0.89
update:310/2000, 耗时:0.00分/0.89分 | step: 24800 | performance: 192.3 | accuracy: 0.36 | loss: 0.92
update:315/2000, 耗时:0.00分/0.90分 | step: 25200 | performance: 312.1 | accuracy: 0.36 | loss: 2.30
update:320/2000, 耗时:0.00分/0.92分 | step: 25600 | performance: 324.2 | accuracy: 0.35 | loss: 1.36
update:325/2000, 耗时:0.00分/0.93分 | step: 26000 | performance: 328.2 | accuracy: 0.35 | loss: 1.21
update:330/2000, 耗时:0.00分/0.94分 | step: 26400 | performance: 389.1 | accuracy: 0.35 | loss: 7.54
update:335/2000, 耗时:0.00分/0.96分 | step: 26800 | performance: 391.0 | accuracy: 0.35 | loss: 1.19
update:340/2000, 耗时:0.00分/0.97分 | step: 27200 | performance: 377.4 | accuracy: 0.35 | loss: 2.52
update:345/2000, 耗时:0.00分/0.99分 | step: 27600 | performance: 520.1 | accuracy: 0.36 | loss: 1.36
update:350/2000, 耗时:0.00分/1.00分 | step: 28000 | performance: 561.2 | accuracy: 0.36 | loss: 1.02
Saving PPO weights in both H5 format and checkpoint @ update:353 
Saving PPO weights in both H5 format and checkpoint @ update:354 
update:355/2000, 耗时:0.00分/1.02分 | step: 28400 | performance: 1.0 | accuracy: 0.25 | loss: 1.78
update:360/2000, 耗时:0.00分/1.04分 | step: 28800 | performance: 0.9 | accuracy: 0.33 | loss: 6.31
update:365/2000, 耗时:0.00分/1.05分 | step: 29200 | performance: 1.1 | accuracy: 0.30 | loss: 0.70
update:370/2000, 耗时:0.00分/1.06分 | step: 29600 | performance: 1.5 | accuracy: 0.32 | loss: 1.58
update:375/2000, 耗时:0.00分/1.08分 | step: 30000 | performance: 2.6 | accuracy: 0.32 | loss: 0.88
update:380/2000, 耗时:0.00分/1.09分 | step: 30400 | performance: 1.6 | accuracy: 0.31 | loss: 4.57
update:385/2000, 耗时:0.00分/1.11分 | step: 30800 | performance: 3.2 | accuracy: 0.33 | loss: 1.12
update:390/2000, 耗时:0.00分/1.12分 | step: 31200 | performance: 3.3 | accuracy: 0.34 | loss: 1.09
update:395/2000, 耗时:0.00分/1.13分 | step: 31600 | performance: 3.1 | accuracy: 0.35 | loss: 1.30
update:400/2000, 耗时:0.00分/1.15分 | step: 32000 | performance: 3.2 | accuracy: 0.36 | loss: 2.01
update:405/2000, 耗时:0.00分/1.16分 | step: 32400 | performance: 15.2 | accuracy: 0.39 | loss: 5.05
update:410/2000, 耗时:0.00分/1.17分 | step: 32800 | performance: 15.9 | accuracy: 0.40 | loss: 7.48
update:415/2000, 耗时:0.00分/1.19分 | step: 33200 | performance: 22.5 | accuracy: 0.40 | loss: 2.39
update:420/2000, 耗时:0.00分/1.20分 | step: 33600 | performance: 22.7 | accuracy: 0.40 | loss: 1.79
update:425/2000, 耗时:0.00分/1.21分 | step: 34000 | performance: 19.2 | accuracy: 0.40 | loss: 2.05
update:430/2000, 耗时:0.00分/1.23分 | step: 34400 | performance: 18.6 | accuracy: 0.40 | loss: 2.58
update:435/2000, 耗时:0.00分/1.24分 | step: 34800 | performance: 12.5 | accuracy: 0.40 | loss: 1.56
update:440/2000, 耗时:0.00分/1.25分 | step: 35200 | performance: 39.1 | accuracy: 0.41 | loss: 3.44
update:445/2000, 耗时:0.00分/1.27分 | step: 35600 | performance: 47.0 | accuracy: 0.42 | loss: 4.84
update:450/2000, 耗时:0.00分/1.28分 | step: 36000 | performance: 144.7 | accuracy: 0.44 | loss: 9.86
update:455/2000, 耗时:0.00分/1.29分 | step: 36400 | performance: 85.5 | accuracy: 0.44 | loss: 10.10
update:460/2000, 耗时:0.00分/1.31分 | step: 36800 | performance: 51.4 | accuracy: 0.44 | loss: 3.52
update:465/2000, 耗时:0.00分/1.32分 | step: 37200 | performance: 50.2 | accuracy: 0.44 | loss: 1.63
update:470/2000, 耗时:0.00分/1.34分 | step: 37600 | performance: 84.8 | accuracy: 0.44 | loss: 1.38
update:475/2000, 耗时:0.00分/1.35分 | step: 38000 | performance: 90.0 | accuracy: 0.44 | loss: 1.01
update:480/2000, 耗时:0.00分/1.36分 | step: 38400 | performance: 125.0 | accuracy: 0.43 | loss: 2.07
update:485/2000, 耗时:0.00分/1.38分 | step: 38800 | performance: 134.1 | accuracy: 0.43 | loss: 1.32
update:490/2000, 耗时:0.00分/1.39分 | step: 39200 | performance: 115.0 | accuracy: 0.42 | loss: 0.74
update:495/2000, 耗时:0.00分/1.40分 | step: 39600 | performance: 97.6 | accuracy: 0.41 | loss: 1.78
update:500/2000, 耗时:0.00分/1.42分 | step: 40000 | performance: 163.3 | accuracy: 0.41 | loss: 6.80
update:505/2000, 耗时:0.00分/1.43分 | step: 40400 | performance: 162.3 | accuracy: 0.41 | loss: 0.39
update:510/2000, 耗时:0.00分/1.44分 | step: 40800 | performance: 192.6 | accuracy: 0.40 | loss: 0.76
update:515/2000, 耗时:0.00分/1.46分 | step: 41200 | performance: 165.8 | accuracy: 0.40 | loss: 3.31
update:520/2000, 耗时:0.00分/1.47分 | step: 41600 | performance: 182.6 | accuracy: 0.40 | loss: 0.85
update:525/2000, 耗时:0.00分/1.49分 | step: 42000 | performance: 191.3 | accuracy: 0.40 | loss: 1.75
update:530/2000, 耗时:0.00分/1.50分 | step: 42400 | performance: 132.9 | accuracy: 0.39 | loss: 1.20
update:535/2000, 耗时:0.00分/1.51分 | step: 42800 | performance: 104.3 | accuracy: 0.39 | loss: 2.55
update:540/2000, 耗时:0.00分/1.53分 | step: 43200 | performance: 78.7 | accuracy: 0.39 | loss: 0.74
update:545/2000, 耗时:0.00分/1.54分 | step: 43600 | performance: 102.3 | accuracy: 0.39 | loss: 5.62
update:550/2000, 耗时:0.00分/1.55分 | step: 44000 | performance: 269.8 | accuracy: 0.40 | loss: 6.75
update:555/2000, 耗时:0.00分/1.57分 | step: 44400 | performance: 300.7 | accuracy: 0.40 | loss: 4.71
update:560/2000, 耗时:0.00分/1.58分 | step: 44800 | performance: 2551.6 | accuracy: 0.41 | loss: 6.95
update:565/2000, 耗时:0.00分/1.59分 | step: 45200 | performance: 1885.2 | accuracy: 0.41 | loss: 1.94
update:570/2000, 耗时:0.00分/1.61分 | step: 45600 | performance: 2310.3 | accuracy: 0.41 | loss: 4.24
update:575/2000, 耗时:0.00分/1.62分 | step: 46000 | performance: 2812.0 | accuracy: 0.41 | loss: 4.86
update:580/2000, 耗时:0.00分/1.63分 | step: 46400 | performance: 3325.3 | accuracy: 0.42 | loss: 7.15
update:585/2000, 耗时:0.00分/1.65分 | step: 46800 | performance: 2588.5 | accuracy: 0.42 | loss: 2.90
update:590/2000, 耗时:0.00分/1.66分 | step: 47200 | performance: 972.8 | accuracy: 0.41 | loss: 1.66
update:595/2000, 耗时:0.00分/1.67分 | step: 47600 | performance: 724.1 | accuracy: 0.41 | loss: 1.82
update:600/2000, 耗时:0.00分/1.69分 | step: 48000 | performance: 488.7 | accuracy: 0.41 | loss: 10.15
update:605/2000, 耗时:0.00分/1.70分 | step: 48400 | performance: 402.9 | accuracy: 0.41 | loss: 1.38
update:610/2000, 耗时:0.00分/1.71分 | step: 48800 | performance: 343.9 | accuracy: 0.40 | loss: 0.57
update:615/2000, 耗时:0.00分/1.73分 | step: 49200 | performance: 267.4 | accuracy: 0.40 | loss: 0.10
update:620/2000, 耗时:0.00分/1.74分 | step: 49600 | performance: 281.9 | accuracy: 0.39 | loss: 0.96
update:625/2000, 耗时:0.00分/1.75分 | step: 50000 | performance: 350.8 | accuracy: 0.39 | loss: 0.91
update:630/2000, 耗时:0.00分/1.77分 | step: 50400 | performance: 326.0 | accuracy: 0.38 | loss: 0.86
update:635/2000, 耗时:0.00分/1.78分 | step: 50800 | performance: 372.4 | accuracy: 0.38 | loss: 2.05
update:640/2000, 耗时:0.00分/1.79分 | step: 51200 | performance: 350.9 | accuracy: 0.38 | loss: 0.95
update:645/2000, 耗时:0.00分/1.81分 | step: 51600 | performance: 335.0 | accuracy: 0.38 | loss: 0.82
update:650/2000, 耗时:0.00分/1.82分 | step: 52000 | performance: 238.1 | accuracy: 0.37 | loss: 0.39
update:655/2000, 耗时:0.00分/1.83分 | step: 52400 | performance: 266.9 | accuracy: 0.37 | loss: 0.61
update:660/2000, 耗时:0.00分/1.85分 | step: 52800 | performance: 729.6 | accuracy: 0.37 | loss: 0.58
update:665/2000, 耗时:0.00分/1.86分 | step: 53200 | performance: 1332.2 | accuracy: 0.37 | loss: 4.75
update:670/2000, 耗时:0.00分/1.87分 | step: 53600 | performance: 1390.7 | accuracy: 0.37 | loss: 4.32
update:675/2000, 耗时:0.00分/1.89分 | step: 54000 | performance: 884.9 | accuracy: 0.37 | loss: 1.04
update:680/2000, 耗时:0.00分/1.90分 | step: 54400 | performance: 1401.5 | accuracy: 0.37 | loss: 0.86
update:685/2000, 耗时:0.00分/1.91分 | step: 54800 | performance: 1675.2 | accuracy: 0.37 | loss: 1.08
update:690/2000, 耗时:0.00分/1.93分 | step: 55200 | performance: 1868.2 | accuracy: 0.38 | loss: 2.84
update:695/2000, 耗时:0.00分/1.94分 | step: 55600 | performance: 1620.3 | accuracy: 0.38 | loss: 1.14
update:700/2000, 耗时:0.00分/1.95分 | step: 56000 | performance: 1461.2 | accuracy: 0.38 | loss: 1.00
update:705/2000, 耗时:0.00分/1.97分 | step: 56400 | performance: 1.1 | accuracy: 0.17 | loss: 0.76
Saving PPO weights in both H5 format and checkpoint @ update:705 
Saving PPO weights in both H5 format and checkpoint @ update:707 
update:710/2000, 耗时:0.00分/1.99分 | step: 56800 | performance: 1.8 | accuracy: 0.36 | loss: 1.82
update:715/2000, 耗时:0.00分/2.00分 | step: 57200 | performance: 1.0 | accuracy: 0.28 | loss: 0.99
update:720/2000, 耗时:0.00分/2.02分 | step: 57600 | performance: 1.3 | accuracy: 0.27 | loss: 1.71
update:725/2000, 耗时:0.00分/2.03分 | step: 58000 | performance: 1.8 | accuracy: 0.28 | loss: 0.49
update:730/2000, 耗时:0.00分/2.04分 | step: 58400 | performance: 1.9 | accuracy: 0.27 | loss: 0.70
update:735/2000, 耗时:0.00分/2.06分 | step: 58800 | performance: 2.1 | accuracy: 0.26 | loss: 1.90
update:740/2000, 耗时:0.00分/2.07分 | step: 59200 | performance: 1.9 | accuracy: 0.25 | loss: 0.93
update:745/2000, 耗时:0.00分/2.09分 | step: 59600 | performance: 2.4 | accuracy: 0.25 | loss: 1.81
update:750/2000, 耗时:0.00分/2.10分 | step: 60000 | performance: 2.7 | accuracy: 0.27 | loss: 1.76
update:755/2000, 耗时:0.00分/2.11分 | step: 60400 | performance: 4.1 | accuracy: 0.29 | loss: 3.58
update:760/2000, 耗时:0.00分/2.13分 | step: 60800 | performance: 12.1 | accuracy: 0.31 | loss: 1.62
update:765/2000, 耗时:0.00分/2.14分 | step: 61200 | performance: 9.6 | accuracy: 0.32 | loss: 1.39
update:770/2000, 耗时:0.00分/2.15分 | step: 61600 | performance: 13.2 | accuracy: 0.34 | loss: 4.63
update:775/2000, 耗时:0.00分/2.17分 | step: 62000 | performance: 8.3 | accuracy: 0.33 | loss: 3.81
update:780/2000, 耗时:0.00分/2.18分 | step: 62400 | performance: 7.6 | accuracy: 0.32 | loss: 2.69
update:785/2000, 耗时:0.00分/2.19分 | step: 62800 | performance: 5.2 | accuracy: 0.32 | loss: 1.50
update:790/2000, 耗时:0.00分/2.21分 | step: 63200 | performance: 5.2 | accuracy: 0.31 | loss: 1.73
update:795/2000, 耗时:0.00分/2.22分 | step: 63600 | performance: 10.4 | accuracy: 0.32 | loss: 2.52
update:800/2000, 耗时:0.00分/2.23分 | step: 64000 | performance: 32.7 | accuracy: 0.35 | loss: 3.31
update:805/2000, 耗时:0.00分/2.25分 | step: 64400 | performance: 16.5 | accuracy: 0.35 | loss: 6.67
update:810/2000, 耗时:0.00分/2.26分 | step: 64800 | performance: 17.9 | accuracy: 0.36 | loss: 2.79
update:815/2000, 耗时:0.00分/2.27分 | step: 65200 | performance: 14.6 | accuracy: 0.36 | loss: 3.79
update:820/2000, 耗时:0.00分/2.29分 | step: 65600 | performance: 17.0 | accuracy: 0.36 | loss: 4.61
update:825/2000, 耗时:0.00分/2.30分 | step: 66000 | performance: 12.4 | accuracy: 0.36 | loss: 1.54
update:830/2000, 耗时:0.00分/2.31分 | step: 66400 | performance: 17.4 | accuracy: 0.36 | loss: 1.32
update:835/2000, 耗时:0.00分/2.33分 | step: 66800 | performance: 17.3 | accuracy: 0.36 | loss: 1.40
update:840/2000, 耗时:0.00分/2.34分 | step: 67200 | performance: 12.6 | accuracy: 0.35 | loss: 1.69
update:845/2000, 耗时:0.00分/2.35分 | step: 67600 | performance: 10.1 | accuracy: 0.35 | loss: 2.08
update:850/2000, 耗时:0.00分/2.37分 | step: 68000 | performance: 14.6 | accuracy: 0.35 | loss: 0.80
update:855/2000, 耗时:0.00分/2.38分 | step: 68400 | performance: 49.6 | accuracy: 0.35 | loss: 1.35
update:860/2000, 耗时:0.00分/2.39分 | step: 68800 | performance: 40.8 | accuracy: 0.34 | loss: 1.90
update:865/2000, 耗时:0.00分/2.41分 | step: 69200 | performance: 34.0 | accuracy: 0.34 | loss: 2.04
update:870/2000, 耗时:0.00分/2.42分 | step: 69600 | performance: 34.4 | accuracy: 0.33 | loss: 0.79
update:875/2000, 耗时:0.00分/2.43分 | step: 70000 | performance: 40.0 | accuracy: 0.33 | loss: 2.75
update:880/2000, 耗时:0.00分/2.45分 | step: 70400 | performance: 33.1 | accuracy: 0.33 | loss: 2.09
update:885/2000, 耗时:0.00分/2.46分 | step: 70800 | performance: 33.8 | accuracy: 0.34 | loss: 2.72
update:890/2000, 耗时:0.00分/2.48分 | step: 71200 | performance: 22.4 | accuracy: 0.34 | loss: 0.84
update:895/2000, 耗时:0.00分/2.49分 | step: 71600 | performance: 26.4 | accuracy: 0.35 | loss: 1.28
update:900/2000, 耗时:0.00分/2.50分 | step: 72000 | performance: 63.6 | accuracy: 0.35 | loss: 1.40
update:905/2000, 耗时:0.00分/2.52分 | step: 72400 | performance: 109.3 | accuracy: 0.36 | loss: 2.20
update:910/2000, 耗时:0.00分/2.53分 | step: 72800 | performance: 319.3 | accuracy: 0.37 | loss: 5.83
update:915/2000, 耗时:0.00分/2.55分 | step: 73200 | performance: 494.2 | accuracy: 0.37 | loss: 5.50
update:920/2000, 耗时:0.00分/2.56分 | step: 73600 | performance: 1939.0 | accuracy: 0.38 | loss: 5.43
update:925/2000, 耗时:0.00分/2.57分 | step: 74000 | performance: 2683.4 | accuracy: 0.39 | loss: 3.26
update:930/2000, 耗时:0.00分/2.59分 | step: 74400 | performance: 2451.2 | accuracy: 0.39 | loss: 1.50
update:935/2000, 耗时:0.00分/2.60分 | step: 74800 | performance: 2256.1 | accuracy: 0.39 | loss: 2.05
update:940/2000, 耗时:0.00分/2.62分 | step: 75200 | performance: 1376.1 | accuracy: 0.39 | loss: 0.52
update:945/2000, 耗时:0.00分/2.63分 | step: 75600 | performance: 2164.2 | accuracy: 0.39 | loss: 2.17
update:950/2000, 耗时:0.00分/2.65分 | step: 76000 | performance: 1826.2 | accuracy: 0.39 | loss: 3.62
update:955/2000, 耗时:0.00分/2.66分 | step: 76400 | performance: 857.0 | accuracy: 0.38 | loss: 1.18
update:960/2000, 耗时:0.00分/2.67分 | step: 76800 | performance: 861.3 | accuracy: 0.38 | loss: 1.12
update:965/2000, 耗时:0.00分/2.69分 | step: 77200 | performance: 527.7 | accuracy: 0.38 | loss: 0.86
update:970/2000, 耗时:0.00分/2.70分 | step: 77600 | performance: 386.0 | accuracy: 0.37 | loss: 0.04
update:975/2000, 耗时:0.00分/2.72分 | step: 78000 | performance: 386.0 | accuracy: 0.37 | loss: 0.01
update:980/2000, 耗时:0.00分/2.73分 | step: 78400 | performance: 461.2 | accuracy: 0.36 | loss: 0.82
update:985/2000, 耗时:0.00分/2.75分 | step: 78800 | performance: 468.5 | accuracy: 0.36 | loss: 1.85
update:990/2000, 耗时:0.00分/2.76分 | step: 79200 | performance: 541.0 | accuracy: 0.36 | loss: 1.38
update:995/2000, 耗时:0.00分/2.77分 | step: 79600 | performance: 562.2 | accuracy: 0.36 | loss: 1.70
update:1000/2000, 耗时:0.00分/2.79分 | step: 80000 | performance: 495.6 | accuracy: 0.36 | loss: 1.35
update:1005/2000, 耗时:0.00分/2.80分 | step: 80400 | performance: 581.9 | accuracy: 0.35 | loss: 0.44
update:1010/2000, 耗时:0.00分/2.82分 | step: 80800 | performance: 1050.2 | accuracy: 0.35 | loss: 1.94
update:1015/2000, 耗时:0.00分/2.83分 | step: 81200 | performance: 1026.0 | accuracy: 0.36 | loss: 1.54
update:1020/2000, 耗时:0.00分/2.84分 | step: 81600 | performance: 4260.4 | accuracy: 0.36 | loss: 2.48
update:1025/2000, 耗时:0.00分/2.86分 | step: 82000 | performance: 2667.5 | accuracy: 0.36 | loss: 3.67
update:1030/2000, 耗时:0.00分/2.87分 | step: 82400 | performance: 2982.1 | accuracy: 0.36 | loss: 3.35
update:1035/2000, 耗时:0.00分/2.89分 | step: 82800 | performance: 3833.9 | accuracy: 0.37 | loss: 4.85
update:1040/2000, 耗时:0.00分/2.90分 | step: 83200 | performance: 4746.3 | accuracy: 0.37 | loss: 6.15
update:1045/2000, 耗时:0.00分/2.91分 | step: 83600 | performance: 3805.8 | accuracy: 0.37 | loss: 2.52
update:1050/2000, 耗时:0.00分/2.93分 | step: 84000 | performance: 7400.0 | accuracy: 0.37 | loss: 1.19
update:1055/2000, 耗时:0.00分/2.94分 | step: 84400 | performance: 7431.2 | accuracy: 0.37 | loss: 0.77
Saving PPO weights in both H5 format and checkpoint @ update:1057 
Saving PPO weights in both H5 format and checkpoint @ update:1059 
update:1060/2000, 耗时:0.00分/2.96分 | step: 84800 | performance: 1.2 | accuracy: 0.24 | loss: 0.48
update:1065/2000, 耗时:0.00分/2.98分 | step: 85200 | performance: 1.0 | accuracy: 0.27 | loss: 1.11
update:1070/2000, 耗时:0.00分/2.99分 | step: 85600 | performance: 0.8 | accuracy: 0.22 | loss: 0.96
update:1075/2000, 耗时:0.00分/3.01分 | step: 86000 | performance: 1.0 | accuracy: 0.24 | loss: 1.18
update:1080/2000, 耗时:0.00分/3.02分 | step: 86400 | performance: 1.3 | accuracy: 0.28 | loss: 2.38
update:1085/2000, 耗时:0.00分/3.03分 | step: 86800 | performance: 1.0 | accuracy: 0.28 | loss: 1.02
update:1090/2000, 耗时:0.00分/3.05分 | step: 87200 | performance: 1.4 | accuracy: 0.29 | loss: 0.93
update:1095/2000, 耗时:0.00分/3.06分 | step: 87600 | performance: 1.5 | accuracy: 0.29 | loss: 2.26
update:1100/2000, 耗时:0.00分/3.07分 | step: 88000 | performance: 1.5 | accuracy: 0.29 | loss: 0.65
update:1105/2000, 耗时:0.00分/3.09分 | step: 88400 | performance: 1.5 | accuracy: 0.30 | loss: 1.29
update:1110/2000, 耗时:0.00分/3.10分 | step: 88800 | performance: 3.2 | accuracy: 0.30 | loss: 2.63
update:1115/2000, 耗时:0.00分/3.12分 | step: 89200 | performance: 4.4 | accuracy: 0.32 | loss: 1.25
update:1120/2000, 耗时:0.00分/3.13分 | step: 89600 | performance: 5.3 | accuracy: 0.32 | loss: 3.41
update:1125/2000, 耗时:0.00分/3.14分 | step: 90000 | performance: 5.5 | accuracy: 0.32 | loss: 0.43
update:1130/2000, 耗时:0.00分/3.16分 | step: 90400 | performance: 4.6 | accuracy: 0.31 | loss: 1.44
update:1135/2000, 耗时:0.00分/3.17分 | step: 90800 | performance: 4.4 | accuracy: 0.30 | loss: 0.29
update:1140/2000, 耗时:0.00分/3.19分 | step: 91200 | performance: 4.4 | accuracy: 0.28 | loss: 0.33
update:1145/2000, 耗时:0.00分/3.20分 | step: 91600 | performance: 3.5 | accuracy: 0.27 | loss: 0.02
update:1150/2000, 耗时:0.00分/3.21分 | step: 92000 | performance: 3.4 | accuracy: 0.26 | loss: 0.49
update:1155/2000, 耗时:0.00分/3.23分 | step: 92400 | performance: 3.4 | accuracy: 0.25 | loss: 0.03
update:1160/2000, 耗时:0.00分/3.24分 | step: 92800 | performance: 3.5 | accuracy: 0.24 | loss: 0.18
update:1165/2000, 耗时:0.00分/3.25分 | step: 93200 | performance: 3.5 | accuracy: 0.23 | loss: 0.01
update:1170/2000, 耗时:0.00分/3.27分 | step: 93600 | performance: 3.5 | accuracy: 0.22 | loss: 0.02
update:1175/2000, 耗时:0.00分/3.28分 | step: 94000 | performance: 3.5 | accuracy: 0.22 | loss: 0.47
update:1180/2000, 耗时:0.00分/3.29分 | step: 94400 | performance: 3.2 | accuracy: 0.21 | loss: -0.00
update:1185/2000, 耗时:0.00分/3.31分 | step: 94800 | performance: 3.3 | accuracy: 0.21 | loss: 1.90
update:1190/2000, 耗时:0.00分/3.32分 | step: 95200 | performance: 3.4 | accuracy: 0.22 | loss: 1.89
update:1195/2000, 耗时:0.00分/3.34分 | step: 95600 | performance: 2.8 | accuracy: 0.22 | loss: 2.07
update:1200/2000, 耗时:0.00分/3.35分 | step: 96000 | performance: 2.8 | accuracy: 0.21 | loss: 0.11
update:1205/2000, 耗时:0.00分/3.37分 | step: 96400 | performance: 2.3 | accuracy: 0.21 | loss: 1.30
update:1210/2000, 耗时:0.00分/3.38分 | step: 96800 | performance: 2.0 | accuracy: 0.20 | loss: 0.43
update:1215/2000, 耗时:0.00分/3.39分 | step: 97200 | performance: 1.7 | accuracy: 0.20 | loss: -0.00
update:1220/2000, 耗时:0.00分/3.41分 | step: 97600 | performance: 1.8 | accuracy: 0.20 | loss: 0.39
update:1225/2000, 耗时:0.00分/3.42分 | step: 98000 | performance: 1.7 | accuracy: 0.20 | loss: 0.60
update:1230/2000, 耗时:0.00分/3.44分 | step: 98400 | performance: 1.7 | accuracy: 0.19 | loss: 0.11
update:1235/2000, 耗时:0.00分/3.45分 | step: 98800 | performance: 1.7 | accuracy: 0.19 | loss: 0.13
update:1240/2000, 耗时:0.00分/3.47分 | step: 99200 | performance: 1.7 | accuracy: 0.19 | loss: 0.05
update:1245/2000, 耗时:0.00分/3.49分 | step: 99600 | performance: 1.7 | accuracy: 0.18 | loss: 0.06
update:1250/2000, 耗时:0.00分/3.50分 | step: 100000 | performance: 2.4 | accuracy: 0.19 | loss: 1.47
update:1255/2000, 耗时:0.00分/3.52分 | step: 100400 | performance: 6.4 | accuracy: 0.20 | loss: 0.96
update:1260/2000, 耗时:0.00分/3.53分 | step: 100800 | performance: 11.3 | accuracy: 0.21 | loss: 11.08
update:1265/2000, 耗时:0.00分/3.55分 | step: 101200 | performance: 36.9 | accuracy: 0.22 | loss: 16.69
update:1270/2000, 耗时:0.00分/3.56分 | step: 101600 | performance: 51.1 | accuracy: 0.23 | loss: 9.59
update:1275/2000, 耗时:0.00分/3.58分 | step: 102000 | performance: 98.6 | accuracy: 0.24 | loss: 4.91
update:1280/2000, 耗时:0.00分/3.59分 | step: 102400 | performance: 131.7 | accuracy: 0.24 | loss: 4.21
update:1285/2000, 耗时:0.00分/3.61分 | step: 102800 | performance: 98.8 | accuracy: 0.25 | loss: 8.85
update:1290/2000, 耗时:0.00分/3.62分 | step: 103200 | performance: 59.7 | accuracy: 0.25 | loss: 9.32
update:1295/2000, 耗时:0.00分/3.64分 | step: 103600 | performance: 39.1 | accuracy: 0.25 | loss: 0.75
update:1300/2000, 耗时:0.00分/3.65分 | step: 104000 | performance: 44.4 | accuracy: 0.25 | loss: 0.30
update:1305/2000, 耗时:0.00分/3.67分 | step: 104400 | performance: 44.4 | accuracy: 0.25 | loss: 0.02
update:1310/2000, 耗时:0.00分/3.69分 | step: 104800 | performance: 45.1 | accuracy: 0.24 | loss: 0.10
update:1315/2000, 耗时:0.00分/3.70分 | step: 105200 | performance: 40.2 | accuracy: 0.24 | loss: 0.22
update:1320/2000, 耗时:0.00分/3.72分 | step: 105600 | performance: 44.2 | accuracy: 0.24 | loss: 0.31
update:1325/2000, 耗时:0.00分/3.73分 | step: 106000 | performance: 47.6 | accuracy: 0.24 | loss: 1.83
update:1330/2000, 耗时:0.00分/3.75分 | step: 106400 | performance: 39.8 | accuracy: 0.24 | loss: 0.72
update:1335/2000, 耗时:0.00分/3.76分 | step: 106800 | performance: 32.0 | accuracy: 0.23 | loss: 0.14
update:1340/2000, 耗时:0.00分/3.78分 | step: 107200 | performance: 31.6 | accuracy: 0.23 | loss: 0.35
update:1345/2000, 耗时:0.00分/3.79分 | step: 107600 | performance: 25.0 | accuracy: 0.23 | loss: 0.30
update:1350/2000, 耗时:0.00分/3.81分 | step: 108000 | performance: 24.4 | accuracy: 0.22 | loss: 0.47
update:1355/2000, 耗时:0.00分/3.82分 | step: 108400 | performance: 27.1 | accuracy: 0.22 | loss: 0.18
update:1360/2000, 耗时:0.00分/3.84分 | step: 108800 | performance: 33.8 | accuracy: 0.22 | loss: 0.11
update:1365/2000, 耗时:0.00分/3.86分 | step: 109200 | performance: 47.4 | accuracy: 0.22 | loss: 0.59
update:1370/2000, 耗时:0.00分/3.87分 | step: 109600 | performance: 45.1 | accuracy: 0.22 | loss: 1.32
update:1375/2000, 耗时:0.00分/3.89分 | step: 110000 | performance: 42.0 | accuracy: 0.22 | loss: 3.39
update:1380/2000, 耗时:0.00分/3.90分 | step: 110400 | performance: 32.1 | accuracy: 0.22 | loss: 0.29
update:1385/2000, 耗时:0.00分/3.92分 | step: 110800 | performance: 35.2 | accuracy: 0.22 | loss: 0.53
update:1390/2000, 耗时:0.00分/3.93分 | step: 111200 | performance: 34.7 | accuracy: 0.22 | loss: 0.79
update:1395/2000, 耗时:0.00分/3.95分 | step: 111600 | performance: 35.0 | accuracy: 0.21 | loss: 0.88
update:1400/2000, 耗时:0.00分/3.96分 | step: 112000 | performance: 39.7 | accuracy: 0.21 | loss: 0.74
update:1405/2000, 耗时:0.00分/3.97分 | step: 112400 | performance: 36.5 | accuracy: 0.22 | loss: 0.84
update:1410/2000, 耗时:0.00分/3.99分 | step: 112800 | performance: 0.9 | accuracy: 0.00 | loss: 0.91
update:1415/2000, 耗时:0.00分/4.00分 | step: 113200 | performance: 1.1 | accuracy: 0.24 | loss: 1.45
update:1420/2000, 耗时:0.00分/4.01分 | step: 113600 | performance: 0.9 | accuracy: 0.22 | loss: 3.46
update:1425/2000, 耗时:0.00分/4.03分 | step: 114000 | performance: 1.0 | accuracy: 0.21 | loss: 1.00
update:1430/2000, 耗时:0.00分/4.04分 | step: 114400 | performance: 1.4 | accuracy: 0.25 | loss: 3.18
update:1435/2000, 耗时:0.00分/4.06分 | step: 114800 | performance: 1.5 | accuracy: 0.27 | loss: 0.56
update:1440/2000, 耗时:0.00分/4.07分 | step: 115200 | performance: 1.1 | accuracy: 0.25 | loss: 0.93
update:1445/2000, 耗时:0.00分/4.08分 | step: 115600 | performance: 1.2 | accuracy: 0.24 | loss: 0.55
update:1450/2000, 耗时:0.00分/4.10分 | step: 116000 | performance: 1.2 | accuracy: 0.22 | loss: 0.16
update:1455/2000, 耗时:0.00分/4.11分 | step: 116400 | performance: 1.2 | accuracy: 0.20 | loss: 0.15
update:1460/2000, 耗时:0.00分/4.13分 | step: 116800 | performance: 1.2 | accuracy: 0.19 | loss: 1.43
update:1465/2000, 耗时:0.00分/4.14分 | step: 117200 | performance: 2.7 | accuracy: 0.22 | loss: 2.01
update:1470/2000, 耗时:0.00分/4.16分 | step: 117600 | performance: 4.0 | accuracy: 0.24 | loss: 1.97
update:1475/2000, 耗时:0.00分/4.17分 | step: 118000 | performance: 4.3 | accuracy: 0.25 | loss: 1.44
update:1480/2000, 耗时:0.00分/4.19分 | step: 118400 | performance: 4.2 | accuracy: 0.26 | loss: 4.15
update:1485/2000, 耗时:0.00分/4.20分 | step: 118800 | performance: 3.4 | accuracy: 0.26 | loss: 0.74
update:1490/2000, 耗时:0.00分/4.22分 | step: 119200 | performance: 3.3 | accuracy: 0.24 | loss: 0.56
update:1495/2000, 耗时:0.00分/4.23分 | step: 119600 | performance: 3.2 | accuracy: 0.25 | loss: 3.47
update:1500/2000, 耗时:0.00分/4.24分 | step: 120000 | performance: 12.3 | accuracy: 0.27 | loss: 3.05
update:1505/2000, 耗时:0.00分/4.26分 | step: 120400 | performance: 17.0 | accuracy: 0.29 | loss: 10.10
update:1510/2000, 耗时:0.00分/4.27分 | step: 120800 | performance: 18.6 | accuracy: 0.30 | loss: 3.80
update:1515/2000, 耗时:0.00分/4.29分 | step: 121200 | performance: 18.6 | accuracy: 0.31 | loss: 0.92
update:1520/2000, 耗时:0.00分/4.30分 | step: 121600 | performance: 16.5 | accuracy: 0.32 | loss: 1.78
update:1525/2000, 耗时:0.00分/4.32分 | step: 122000 | performance: 17.0 | accuracy: 0.31 | loss: 0.46
update:1530/2000, 耗时:0.00分/4.33分 | step: 122400 | performance: 19.6 | accuracy: 0.31 | loss: 2.47
update:1535/2000, 耗时:0.00分/4.34分 | step: 122800 | performance: 13.6 | accuracy: 0.30 | loss: 0.96
update:1540/2000, 耗时:0.00分/4.36分 | step: 123200 | performance: 14.7 | accuracy: 0.30 | loss: 1.37
update:1545/2000, 耗时:0.00分/4.37分 | step: 123600 | performance: 12.3 | accuracy: 0.31 | loss: 5.14
update:1550/2000, 耗时:0.00分/4.39分 | step: 124000 | performance: 10.6 | accuracy: 0.31 | loss: 0.73
update:1555/2000, 耗时:0.00分/4.40分 | step: 124400 | performance: 10.6 | accuracy: 0.30 | loss: 0.89
update:1560/2000, 耗时:0.00分/4.41分 | step: 124800 | performance: 7.8 | accuracy: 0.30 | loss: 1.41
update:1565/2000, 耗时:0.00分/4.43分 | step: 125200 | performance: 6.0 | accuracy: 0.30 | loss: 0.61
update:1570/2000, 耗时:0.00分/4.44分 | step: 125600 | performance: 6.7 | accuracy: 0.30 | loss: 0.43
update:1575/2000, 耗时:0.00分/4.45分 | step: 126000 | performance: 6.1 | accuracy: 0.29 | loss: 0.19
update:1580/2000, 耗时:0.00分/4.47分 | step: 126400 | performance: 5.8 | accuracy: 0.29 | loss: 0.61
update:1585/2000, 耗时:0.00分/4.48分 | step: 126800 | performance: 5.7 | accuracy: 0.28 | loss: 0.80
update:1590/2000, 耗时:0.00分/4.49分 | step: 127200 | performance: 5.7 | accuracy: 0.27 | loss: 0.15
update:1595/2000, 耗时:0.00分/4.51分 | step: 127600 | performance: 5.7 | accuracy: 0.27 | loss: 0.31
update:1600/2000, 耗时:0.00分/4.52分 | step: 128000 | performance: 5.7 | accuracy: 0.26 | loss: 0.17
update:1605/2000, 耗时:0.00分/4.54分 | step: 128400 | performance: 5.7 | accuracy: 0.26 | loss: 0.02
update:1610/2000, 耗时:0.00分/4.55分 | step: 128800 | performance: 5.7 | accuracy: 0.25 | loss: 0.10
update:1615/2000, 耗时:0.00分/4.56分 | step: 129200 | performance: 5.7 | accuracy: 0.25 | loss: 0.01
update:1620/2000, 耗时:0.00分/4.58分 | step: 129600 | performance: 5.7 | accuracy: 0.24 | loss: 0.01
update:1625/2000, 耗时:0.00分/4.59分 | step: 130000 | performance: 5.7 | accuracy: 0.23 | loss: 0.00
update:1630/2000, 耗时:0.00分/4.60分 | step: 130400 | performance: 5.7 | accuracy: 0.23 | loss: 0.00
update:1635/2000, 耗时:0.00分/4.62分 | step: 130800 | performance: 5.7 | accuracy: 0.22 | loss: 0.00
update:1640/2000, 耗时:0.00分/4.63分 | step: 131200 | performance: 5.7 | accuracy: 0.22 | loss: 0.33
update:1645/2000, 耗时:0.00分/4.64分 | step: 131600 | performance: 5.7 | accuracy: 0.22 | loss: 0.00
update:1650/2000, 耗时:0.00分/4.66分 | step: 132000 | performance: 5.3 | accuracy: 0.21 | loss: 0.27
update:1655/2000, 耗时:0.00分/4.67分 | step: 132400 | performance: 6.0 | accuracy: 0.21 | loss: 0.79
update:1660/2000, 耗时:0.00分/4.68分 | step: 132800 | performance: 6.4 | accuracy: 0.21 | loss: 0.22
update:1665/2000, 耗时:0.00分/4.70分 | step: 133200 | performance: 5.9 | accuracy: 0.21 | loss: 0.00
update:1670/2000, 耗时:0.00分/4.71分 | step: 133600 | performance: 5.9 | accuracy: 0.20 | loss: 0.19
update:1675/2000, 耗时:0.00分/4.72分 | step: 134000 | performance: 5.9 | accuracy: 0.20 | loss: 0.16
update:1680/2000, 耗时:0.00分/4.74分 | step: 134400 | performance: 5.9 | accuracy: 0.20 | loss: 0.05
update:1685/2000, 耗时:0.00分/4.75分 | step: 134800 | performance: 5.9 | accuracy: 0.19 | loss: 0.00
update:1690/2000, 耗时:0.00分/4.77分 | step: 135200 | performance: 5.9 | accuracy: 0.19 | loss: 0.07
update:1695/2000, 耗时:0.00分/4.78分 | step: 135600 | performance: 5.9 | accuracy: 0.19 | loss: 0.02
update:1700/2000, 耗时:0.00分/4.79分 | step: 136000 | performance: 5.9 | accuracy: 0.18 | loss: 0.00
update:1705/2000, 耗时:0.00分/4.81分 | step: 136400 | performance: 5.9 | accuracy: 0.18 | loss: 0.01
update:1710/2000, 耗时:0.00分/4.82分 | step: 136800 | performance: 5.9 | accuracy: 0.18 | loss: 0.00
update:1715/2000, 耗时:0.00分/4.83分 | step: 137200 | performance: 5.9 | accuracy: 0.17 | loss: 0.00
update:1720/2000, 耗时:0.00分/4.85分 | step: 137600 | performance: 5.9 | accuracy: 0.17 | loss: 0.04
update:1725/2000, 耗时:0.00分/4.86分 | step: 138000 | performance: 5.9 | accuracy: 0.17 | loss: 0.00
update:1730/2000, 耗时:0.00分/4.88分 | step: 138400 | performance: 5.9 | accuracy: 0.17 | loss: 0.00
update:1735/2000, 耗时:0.00分/4.89分 | step: 138800 | performance: 5.9 | accuracy: 0.17 | loss: 0.00
update:1740/2000, 耗时:0.00分/4.90分 | step: 139200 | performance: 5.9 | accuracy: 0.16 | loss: 0.01
update:1745/2000, 耗时:0.00分/4.92分 | step: 139600 | performance: 5.9 | accuracy: 0.16 | loss: 0.09
update:1750/2000, 耗时:0.00分/4.93分 | step: 140000 | performance: 6.0 | accuracy: 0.16 | loss: 0.27
update:1755/2000, 耗时:0.00分/4.94分 | step: 140400 | performance: 9.6 | accuracy: 0.16 | loss: 1.53
update:1760/2000, 耗时:0.00分/4.96分 | step: 140800 | performance: 9.6 | accuracy: 0.16 | loss: 0.55
step: 140877 | worker_4@n_step_9: average total_reward after train data exhaustion : 175.7 | max total_reward: 404.9
update:1765/2000, 耗时:0.00分/4.97分 | step: 141200 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:1770/2000, 耗时:0.00分/4.98分 | step: 141600 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
update:1775/2000, 耗时:0.00分/4.99分 | step: 142000 | performance: 1.7 | accuracy: 0.24 | loss: 0.83
update:1780/2000, 耗时:0.00分/5.01分 | step: 142400 | performance: 1.4 | accuracy: 0.22 | loss: 1.06
update:1785/2000, 耗时:0.00分/5.02分 | step: 142800 | performance: 1.5 | accuracy: 0.15 | loss: 0.09
step: 143036 | worker_3@n_step_9: average total_reward after train data exhaustion : 14.8 | max total_reward: 404.9
update:1790/2000, 耗时:0.00分/5.03分 | step: 143200 | performance: 1.3 | accuracy: 0.13 | loss: 0.37
update:1795/2000, 耗时:0.00分/5.05分 | step: 143600 | performance: 1.1 | accuracy: 0.14 | loss: 0.32
update:1800/2000, 耗时:0.00分/5.06分 | step: 144000 | performance: 1.1 | accuracy: 0.13 | loss: 0.21
update:1805/2000, 耗时:0.00分/5.07分 | step: 144400 | performance: 1.1 | accuracy: 0.14 | loss: 0.71
update:1810/2000, 耗时:0.00分/5.09分 | step: 144800 | performance: 0.8 | accuracy: 0.15 | loss: 3.86
update:1815/2000, 耗时:0.00分/5.10分 | step: 145200 | performance: 0.9 | accuracy: 0.19 | loss: 2.36
update:1820/2000, 耗时:0.00分/5.12分 | step: 145600 | performance: 0.9 | accuracy: 0.21 | loss: 1.08
update:1825/2000, 耗时:0.00分/5.13分 | step: 146000 | performance: 3.8 | accuracy: 0.25 | loss: 5.84
update:1830/2000, 耗时:0.00分/5.14分 | step: 146400 | performance: 2.9 | accuracy: 0.26 | loss: 2.27
update:1835/2000, 耗时:0.00分/5.16分 | step: 146800 | performance: 3.8 | accuracy: 0.28 | loss: 3.08
update:1840/2000, 耗时:0.00分/5.17分 | step: 147200 | performance: 2.9 | accuracy: 0.29 | loss: 3.51
update:1845/2000, 耗时:0.00分/5.18分 | step: 147600 | performance: 2.9 | accuracy: 0.29 | loss: 1.73
update:1850/2000, 耗时:0.00分/5.20分 | step: 148000 | performance: 1.4 | accuracy: 0.29 | loss: 4.34
update:1855/2000, 耗时:0.00分/5.21分 | step: 148400 | performance: 1.2 | accuracy: 0.28 | loss: 0.65
update:1860/2000, 耗时:0.00分/5.22分 | step: 148800 | performance: 0.9 | accuracy: 0.28 | loss: 0.82
update:1865/2000, 耗时:0.00分/5.24分 | step: 149200 | performance: 1.0 | accuracy: 0.28 | loss: 2.25
update:1870/2000, 耗时:0.00分/5.25分 | step: 149600 | performance: 1.0 | accuracy: 0.28 | loss: 2.23
update:1875/2000, 耗时:0.00分/5.26分 | step: 150000 | performance: 1.4 | accuracy: 0.28 | loss: 1.14
update:1880/2000, 耗时:0.00分/5.28分 | step: 150400 | performance: 1.5 | accuracy: 0.29 | loss: 1.09
update:1885/2000, 耗时:0.00分/5.29分 | step: 150800 | performance: 1.1 | accuracy: 0.28 | loss: 1.46
update:1890/2000, 耗时:0.00分/5.30分 | step: 151200 | performance: 0.7 | accuracy: 0.28 | loss: 1.62
update:1895/2000, 耗时:0.00分/5.32分 | step: 151600 | performance: 0.8 | accuracy: 0.28 | loss: 1.24
update:1900/2000, 耗时:0.00分/5.33分 | step: 152000 | performance: 0.7 | accuracy: 0.28 | loss: 1.18
update:1905/2000, 耗时:0.00分/5.34分 | step: 152400 | performance: 0.6 | accuracy: 0.28 | loss: 2.15
update:1910/2000, 耗时:0.00分/5.36分 | step: 152800 | performance: 0.5 | accuracy: 0.28 | loss: 0.77
update:1915/2000, 耗时:0.00分/5.37分 | step: 153200 | performance: 0.6 | accuracy: 0.27 | loss: 0.25
update:1920/2000, 耗时:0.00分/5.38分 | step: 153600 | performance: 0.3 | accuracy: 0.27 | loss: 2.85
update:1925/2000, 耗时:0.00分/5.40分 | step: 154000 | performance: 0.3 | accuracy: 0.27 | loss: 1.22
update:1930/2000, 耗时:0.00分/5.41分 | step: 154400 | performance: 0.3 | accuracy: 0.27 | loss: 0.79
update:1935/2000, 耗时:0.00分/5.42分 | step: 154800 | performance: 0.3 | accuracy: 0.26 | loss: 0.78
update:1940/2000, 耗时:0.00分/5.44分 | step: 155200 | performance: 0.3 | accuracy: 0.26 | loss: 0.43
update:1945/2000, 耗时:0.00分/5.45分 | step: 155600 | performance: 0.3 | accuracy: 0.26 | loss: 0.74
update:1950/2000, 耗时:0.00分/5.47分 | step: 156000 | performance: 0.2 | accuracy: 0.26 | loss: 1.53
update:1955/2000, 耗时:0.00分/5.48分 | step: 156400 | performance: 0.2 | accuracy: 0.26 | loss: 1.40
update:1960/2000, 耗时:0.00分/5.49分 | step: 156800 | performance: 0.2 | accuracy: 0.26 | loss: 1.08
update:1965/2000, 耗时:0.00分/5.51分 | step: 157200 | performance: 0.4 | accuracy: 0.26 | loss: 4.43
update:1970/2000, 耗时:0.00分/5.52分 | step: 157600 | performance: 0.7 | accuracy: 0.27 | loss: 1.99
update:1975/2000, 耗时:0.00分/5.53分 | step: 158000 | performance: 1.9 | accuracy: 0.28 | loss: 6.35
update:1980/2000, 耗时:0.00分/5.55分 | step: 158400 | performance: 3.0 | accuracy: 0.29 | loss: 6.34
update:1985/2000, 耗时:0.00分/5.56分 | step: 158800 | performance: 9.1 | accuracy: 0.30 | loss: 4.16
update:1990/2000, 耗时:0.00分/5.57分 | step: 159200 | performance: 14.6 | accuracy: 0.31 | loss: 5.41
update:1995/2000, 耗时:0.00分/5.58分 | step: 159600 | performance: 14.9 | accuracy: 0.31 | loss: 4.76
  0%|          | 0/391 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/5.60分 | step: 160000 | performance: 13.7 | accuracy: 0.31 | loss: 7.85
----------------------------------------finished----------------------------------------
100%|| 391/391 [00:00<00:00, 48865.43it/s]
==================================================
2023-01-10T12:00:00 | *** START BACKTEST ***
2023-01-10T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1287.33
2023-07-24T12:00:00 | net performance [%] = 28.7330
2023-07-24T12:00:00 | number of trades [#] = 18
==================================================
Trial 6 Complete [00h 06m 02s]
net_wealth: 1288.618456514952

Best net_wealth So Far: 1380.2023481050508
Total elapsed time: 00h 31m 12s

Search: Running Trial #7

Value             |Best Value So Far |Hyperparameter
7                 |1                 |horizon
225               |225               |lookback
True              |False             |MarketFactor
14                |8                 |lags
0.92              |0.9               |gamma
32                |32                |batch_size
1                 |10                |n_step
0.94              |0.92              |gae_lambda
2                 |2                 |gradient_clip_norm
5                 |3                 |epochs
0.001             |5e-05             |actor_lr
1e-05             |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4294.000000   4301.000000
mean      0.000435    20113.607657  ...   20195.171043  20169.373185
std       0.027833    16040.642334  ...   16078.971923  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7758.522461   7730.930176
50%       0.000642    11571.842969  ...   11758.879883  11751.469727
75%       0.011590    29894.706152  ...   30019.495605  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-27 22:34:34.587254: I tensorflow/core/platform/cpu_feature_g2023-07-27 22:34:34.587300: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network2200 L22u03ai-23-07-27 22:34:34.587394: I brrary (otens0n7-eDNo2Nr7)f  tol2220322o3-w/core/pla- 0:tfouse d3t.rm7h-27/cc:14e 22 f4c:pu_ollow:3i3nfea0ture_gu74:-234.a587254.587369: 37 2:I 2I  :34:3tten42.]ensorflow/cs587o ore/platform/cpu_feature475: I tensorflowr_2rg02fl3/-ocw/coo grduarre/p.cce:C142/platforml/PT] aUTht hiis iTesfnn osstoTrerrnFslouwctiorm/ocpun_fs ceat iF2n l0ourpupwerfeor_b_guainmf0ar7ane-aturercde.cc: b-ciriti1247c 22:34:a23l4. _583-70n67ary is-27 do ptimg9i5:y2 z e2I. itecnd:s34:us 3o4o.rcp:afrltodw.c1c425 8:o1]4 p7/82Thicomre1/i2i0ze:d Ie]ws T ]p lT T rhaitswaihthi soinite tThe nosnonreFformA/ cTpePsonosu_IrFlofe lnas: oww  biD onbeteup iArVreN_eanrtFXl oAVX2
egnwsey isuur ToaoaArPyIop t lrfen Ni aardlimsi zoeobDw.celeee tdcpt hw/cNoeeputri orrek m: 1 awl miL/bNiez4ipilattnbraefi2t]  royrmdT hwinho th (awrot/ociornheAPnse TpyI  iDsk eou Donpe_fNsN )reeoartFulone t iLmept NiriAwoebuez bipoe r_Pal NeI eugtDdee pw swuarrea rtoheNreayitirnu o(nthral Ns,d .foekt wrar lebcy  ouco:14niirLl2ow] ekisb roaiThinsl pAtPriy dL TibrIa eDneToenne D(ognesoNesDorFmlizprro Ne dN eNFwl Nb)uyCow PiUn awiitr nswiotrytrucal  (t  ithonsh t iNe twoounse onheDNNr)s inop )t e kaettoimperformai AhPznLe Iu sDpepdribrary f w to usio eetol(e the folhploe l riate po wNeocioncutnng ral NetowmpeAPI ihwlDeee fCer flaolloepgse.D Ni-NoN
Pnwc)rkU in irges it Linuitcralg rotpeCubrarca aPrU itiCPU instyntons inr s l( oturpucioNnneteDteiocNsN)n stro:  t fin iwuoo osrrmaApnce-crns ieero  kuthsenV e LiX AVX2
To enable them in other operations, rebuild TensorFlow with the appfropriate compileritical operations:  AVX AVX2
  performance-critib the folfolTormance-critilloo ocal rwaing CorPwiecUn ifal operations:  Anpealabgl y reCVPX AVX2nUasgt rtuchs
tTe.(ion imo
ns:  eDNntsi nA iotrucNoon sV) X  tAeVihetXo2rn tpi
oenrs i formnu spner Topeferatoioaran  ethblcnameeebl e th- critiectmhfeolma in other ope in otllo hance-ewcirngi rC ooonppsrtPaUete, r rireons, rebubatiiild TensorFlownstiruuons, rebuic with ctatlild Tensh iooe raonps ppropFleoriate coratimw wilpiler tioh n ptnhereations:  AVX AVX2
To enable them in other opd Tefn sso:or r AVfFllags.
approprmoXiate com aAwnc eraVwXi2e-p
itthTleor i flagsonc.
enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
ritical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler fls, rebuild TensorFlow with the appropriate compiler flags.
ags.
 the appropriate compiler flags.
2023-07-27 22:34:35.218378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:34:35.218970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:34:35.227786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:34:35.239589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:34:35.244776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:34:35.252759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:34:35.280701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:34:35.289233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:    40 | performance: 1.3 | accuracy: 0.60 | loss: 0.19
update: 10/2000, 耗时:0.00分/0.04分 | step:    80 | performance: 2.7 | accuracy: 0.80 | loss: 0.02
update: 15/2000, 耗时:0.00分/0.05分 | step:   120 | performance: 2.2 | accuracy: 0.60 | loss: 1.40
update: 20/2000, 耗时:0.00分/0.06分 | step:   160 | performance: 2.2 | accuracy: 0.45 | loss: 0.14
update: 25/2000, 耗时:0.00分/0.07分 | step:   200 | performance: 2.0 | accuracy: 0.40 | loss: 0.26
update: 30/2000, 耗时:0.00分/0.08分 | step:   240 | performance: 0.7 | accuracy: 0.33 | loss: 1.62
update: 35/2000, 耗时:0.00分/0.09分 | step:   280 | performance: 0.7 | accuracy: 0.29 | loss: 0.02
update: 40/2000, 耗时:0.00分/0.10分 | step:   320 | performance: 0.7 | accuracy: 0.25 | loss: 1.78
update: 45/2000, 耗时:0.00分/0.11分 | step:   360 | performance: 0.7 | accuracy: 0.22 | loss: 1.36
update: 50/2000, 耗时:0.00分/0.12分 | step:   400 | performance: 0.7 | accuracy: 0.20 | loss: 0.95
update: 55/2000, 耗时:0.00分/0.13分 | step:   440 | performance: 0.7 | accuracy: 0.22 | loss: 0.56
update: 60/2000, 耗时:0.00分/0.14分 | step:   480 | performance: 0.8 | accuracy: 0.22 | loss: 2.52
update: 65/2000, 耗时:0.00分/0.15分 | step:   520 | performance: 2.1 | accuracy: 0.28 | loss: 2.12
update: 70/2000, 耗时:0.00分/0.16分 | step:   560 | performance: 5.8 | accuracy: 0.33 | loss: 2.52
update: 75/2000, 耗时:0.00分/0.17分 | step:   600 | performance: 6.3 | accuracy: 0.35 | loss: 2.88
update: 80/2000, 耗时:0.00分/0.18分 | step:   640 | performance: 5.1 | accuracy: 0.36 | loss: 2.72
update: 85/2000, 耗时:0.00分/0.19分 | step:   680 | performance: 4.7 | accuracy: 0.35 | loss: 5.54
update: 90/2000, 耗时:0.00分/0.20分 | step:   720 | performance: 2.1 | accuracy: 0.33 | loss: 2.81
update: 95/2000, 耗时:0.00分/0.21分 | step:   760 | performance: 1.6 | accuracy: 0.33 | loss: 1.08
update:100/2000, 耗时:0.00分/0.22分 | step:   800 | performance: 1.9 | accuracy: 0.33 | loss: 0.02
update:105/2000, 耗时:0.00分/0.23分 | step:   840 | performance: 2.1 | accuracy: 0.32 | loss: 1.02
update:110/2000, 耗时:0.00分/0.24分 | step:   880 | performance: 2.6 | accuracy: 0.35 | loss: 0.58
update:115/2000, 耗时:0.00分/0.25分 | step:   920 | performance: 3.6 | accuracy: 0.37 | loss: 0.77
update:120/2000, 耗时:0.00分/0.26分 | step:   960 | performance: 3.6 | accuracy: 0.38 | loss: 0.21
update:125/2000, 耗时:0.00分/0.27分 | step:  1000 | performance: 3.8 | accuracy: 0.37 | loss: 0.14
update:130/2000, 耗时:0.00分/0.28分 | step:  1040 | performance: 8.6 | accuracy: 0.39 | loss: 1.79
update:135/2000, 耗时:0.00分/0.29分 | step:  1080 | performance: 16.3 | accuracy: 0.41 | loss: 0.81
update:140/2000, 耗时:0.00分/0.31分 | step:  1120 | performance: 16.7 | accuracy: 0.41 | loss: 1.40
update:145/2000, 耗时:0.00分/0.32分 | step:  1160 | performance: 10.9 | accuracy: 0.40 | loss: 0.35
update:150/2000, 耗时:0.00分/0.33分 | step:  1200 | performance: 11.5 | accuracy: 0.40 | loss: 0.60
update:155/2000, 耗时:0.00分/0.34分 | step:  1240 | performance: 17.9 | accuracy: 0.42 | loss: 0.00
update:160/2000, 耗时:0.00分/0.35分 | step:  1280 | performance: 18.9 | accuracy: 0.42 | loss: 0.50
update:165/2000, 耗时:0.00分/0.36分 | step:  1320 | performance: 24.5 | accuracy: 0.44 | loss: 0.85
update:170/2000, 耗时:0.00分/0.37分 | step:  1360 | performance: 39.4 | accuracy: 0.45 | loss: 0.82
update:175/2000, 耗时:0.00分/0.38分 | step:  1400 | performance: 59.6 | accuracy: 0.46 | loss: 3.56
update:180/2000, 耗时:0.00分/0.39分 | step:  1440 | performance: 73.2 | accuracy: 0.47 | loss: 1.09
update:185/2000, 耗时:0.00分/0.40分 | step:  1480 | performance: 64.6 | accuracy: 0.45 | loss: 0.02
update:190/2000, 耗时:0.00分/0.41分 | step:  1520 | performance: 70.9 | accuracy: 0.46 | loss: 0.13
update:195/2000, 耗时:0.00分/0.42分 | step:  1560 | performance: 66.1 | accuracy: 0.46 | loss: 0.91
update:200/2000, 耗时:0.00分/0.43分 | step:  1600 | performance: 44.4 | accuracy: 0.46 | loss: 0.47
update:205/2000, 耗时:0.00分/0.45分 | step:  1640 | performance: 21.6 | accuracy: 0.44 | loss: 0.08
update:210/2000, 耗时:0.00分/0.46分 | step:  1680 | performance: 20.6 | accuracy: 0.44 | loss: 0.02
update:215/2000, 耗时:0.00分/0.47分 | step:  1720 | performance: 18.2 | accuracy: 0.44 | loss: 0.47
update:220/2000, 耗时:0.00分/0.48分 | step:  1760 | performance: 12.0 | accuracy: 0.43 | loss: 0.72
update:225/2000, 耗时:0.00分/0.49分 | step:  1800 | performance: 9.7 | accuracy: 0.43 | loss: 1.17
update:230/2000, 耗时:0.00分/0.50分 | step:  1840 | performance: 9.7 | accuracy: 0.43 | loss: 0.80
update:235/2000, 耗时:0.00分/0.51分 | step:  1880 | performance: 8.6 | accuracy: 0.42 | loss: 1.17
update:240/2000, 耗时:0.00分/0.52分 | step:  1920 | performance: 9.2 | accuracy: 0.43 | loss: 0.43
update:245/2000, 耗时:0.00分/0.53分 | step:  1960 | performance: 6.5 | accuracy: 0.42 | loss: 1.25
update:250/2000, 耗时:0.00分/0.54分 | step:  2000 | performance: 7.0 | accuracy: 0.42 | loss: 0.00
update:255/2000, 耗时:0.00分/0.55分 | step:  2040 | performance: 8.8 | accuracy: 0.44 | loss: 0.21
update:260/2000, 耗时:0.00分/0.56分 | step:  2080 | performance: 13.6 | accuracy: 0.45 | loss: 0.81
update:265/2000, 耗时:0.00分/0.57分 | step:  2120 | performance: 12.9 | accuracy: 0.44 | loss: 0.21
update:270/2000, 耗时:0.00分/0.58分 | step:  2160 | performance: 15.4 | accuracy: 0.45 | loss: 1.61
update:275/2000, 耗时:0.00分/0.60分 | step:  2200 | performance: 16.4 | accuracy: 0.45 | loss: 0.01
update:280/2000, 耗时:0.00分/0.61分 | step:  2240 | performance: 16.8 | accuracy: 0.45 | loss: 0.36
update:285/2000, 耗时:0.00分/0.62分 | step:  2280 | performance: 30.0 | accuracy: 0.46 | loss: 0.80
update:290/2000, 耗时:0.00分/0.63分 | step:  2320 | performance: 36.9 | accuracy: 0.47 | loss: 0.33
update:295/2000, 耗时:0.00分/0.64分 | step:  2360 | performance: 38.4 | accuracy: 0.47 | loss: 1.11
update:300/2000, 耗时:0.00分/0.65分 | step:  2400 | performance: 33.5 | accuracy: 0.47 | loss: 1.50
update:305/2000, 耗时:0.00分/0.66分 | step:  2440 | performance: 30.3 | accuracy: 0.46 | loss: 1.27
update:310/2000, 耗时:0.00分/0.67分 | step:  2480 | performance: 31.3 | accuracy: 0.47 | loss: 0.00
update:315/2000, 耗时:0.00分/0.68分 | step:  2520 | performance: 30.2 | accuracy: 0.46 | loss: 1.11
update:320/2000, 耗时:0.00分/0.69分 | step:  2560 | performance: 50.8 | accuracy: 0.47 | loss: 1.95
update:325/2000, 耗时:0.00分/0.70分 | step:  2600 | performance: 84.4 | accuracy: 0.48 | loss: 0.58
update:330/2000, 耗时:0.00分/0.71分 | step:  2640 | performance: 96.1 | accuracy: 0.48 | loss: 0.12
update:335/2000, 耗时:0.00分/0.72分 | step:  2680 | performance: 88.1 | accuracy: 0.48 | loss: 1.02
update:340/2000, 耗时:0.00分/0.74分 | step:  2720 | performance: 80.7 | accuracy: 0.47 | loss: 0.87
update:345/2000, 耗时:0.00分/0.75分 | step:  2760 | performance: 134.5 | accuracy: 0.48 | loss: 7.07
update:350/2000, 耗时:0.00分/0.76分 | step:  2800 | performance: 144.8 | accuracy: 0.48 | loss: 0.00
update:355/2000, 耗时:0.00分/0.77分 | step:  2840 | performance: 150.4 | accuracy: 0.48 | loss: 0.02
update:360/2000, 耗时:0.00分/0.78分 | step:  2880 | performance: 121.0 | accuracy: 0.48 | loss: 2.25
update:365/2000, 耗时:0.00分/0.79分 | step:  2920 | performance: 99.8 | accuracy: 0.47 | loss: -0.00
update:370/2000, 耗时:0.00分/0.80分 | step:  2960 | performance: 95.1 | accuracy: 0.46 | loss: 1.27
update:375/2000, 耗时:0.00分/0.81分 | step:  3000 | performance: 97.0 | accuracy: 0.46 | loss: 0.26
update:380/2000, 耗时:0.00分/0.82分 | step:  3040 | performance: 93.3 | accuracy: 0.46 | loss: 0.10
update:385/2000, 耗时:0.00分/0.83分 | step:  3080 | performance: 93.3 | accuracy: 0.45 | loss: 0.01
update:390/2000, 耗时:0.00分/0.84分 | step:  3120 | performance: 93.3 | accuracy: 0.44 | loss: 0.28
update:395/2000, 耗时:0.00分/0.85分 | step:  3160 | performance: 93.3 | accuracy: 0.44 | loss: 0.00
update:400/2000, 耗时:0.00分/0.87分 | step:  3200 | performance: 93.3 | accuracy: 0.43 | loss: 0.12
update:405/2000, 耗时:0.00分/0.88分 | step:  3240 | performance: 93.3 | accuracy: 0.43 | loss: 0.02
update:410/2000, 耗时:0.00分/0.89分 | step:  3280 | performance: 120.5 | accuracy: 0.43 | loss: 0.13
update:415/2000, 耗时:0.00分/0.90分 | step:  3320 | performance: 120.5 | accuracy: 0.43 | loss: 0.00
update:420/2000, 耗时:0.00分/0.91分 | step:  3360 | performance: 135.3 | accuracy: 0.43 | loss: 0.20
update:425/2000, 耗时:0.00分/0.92分 | step:  3400 | performance: 205.4 | accuracy: 0.44 | loss: 0.01
update:430/2000, 耗时:0.00分/0.93分 | step:  3440 | performance: 292.6 | accuracy: 0.44 | loss: 1.90
update:435/2000, 耗时:0.00分/0.94分 | step:  3480 | performance: 351.0 | accuracy: 0.45 | loss: 0.81
update:440/2000, 耗时:0.00分/0.95分 | step:  3520 | performance: 584.4 | accuracy: 0.45 | loss: 0.09
update:445/2000, 耗时:0.00分/0.96分 | step:  3560 | performance: 604.9 | accuracy: 0.45 | loss: 0.09
update:450/2000, 耗时:0.00分/0.97分 | step:  3600 | performance: 593.9 | accuracy: 0.45 | loss: 0.14
update:455/2000, 耗时:0.00分/0.99分 | step:  3640 | performance: 593.9 | accuracy: 0.44 | loss: 0.70
update:460/2000, 耗时:0.00分/1.00分 | step:  3680 | performance: 593.9 | accuracy: 0.44 | loss: 0.33
update:465/2000, 耗时:0.00分/1.01分 | step:  3720 | performance: 593.9 | accuracy: 0.43 | loss: 0.40
update:470/2000, 耗时:0.00分/1.02分 | step:  3760 | performance: 548.5 | accuracy: 0.43 | loss: 0.42
update:475/2000, 耗时:0.00分/1.03分 | step:  3800 | performance: 548.5 | accuracy: 0.42 | loss: 0.37
update:480/2000, 耗时:0.00分/1.04分 | step:  3840 | performance: 544.4 | accuracy: 0.42 | loss: 0.40
update:485/2000, 耗时:0.00分/1.05分 | step:  3880 | performance: 544.4 | accuracy: 0.41 | loss: 0.55
update:490/2000, 耗时:0.00分/1.06分 | step:  3920 | performance: 544.4 | accuracy: 0.41 | loss: 0.33
update:495/2000, 耗时:0.00分/1.07分 | step:  3960 | performance: 978.3 | accuracy: 0.42 | loss: 1.93
update:500/2000, 耗时:0.00分/1.08分 | step:  4000 | performance: 1414.9 | accuracy: 0.42 | loss: 0.01
update:505/2000, 耗时:0.00分/1.10分 | step:  4040 | performance: 1486.2 | accuracy: 0.43 | loss: 0.23
update:510/2000, 耗时:0.00分/1.11分 | step:  4080 | performance: 1437.7 | accuracy: 0.42 | loss: 0.51
update:515/2000, 耗时:0.00分/1.12分 | step:  4120 | performance: 1487.7 | accuracy: 0.42 | loss: 1.36
update:520/2000, 耗时:0.00分/1.13分 | step:  4160 | performance: 1691.1 | accuracy: 0.42 | loss: 0.93
update:525/2000, 耗时:0.00分/1.14分 | step:  4200 | performance: 1298.7 | accuracy: 0.42 | loss: 1.32
update:530/2000, 耗时:0.00分/1.15分 | step:  4240 | performance: 1263.7 | accuracy: 0.42 | loss: 1.40
update:535/2000, 耗时:0.00分/1.16分 | step:  4280 | performance: 1434.5 | accuracy: 0.42 | loss: 1.02
update:540/2000, 耗时:0.00分/1.17分 | step:  4320 | performance: 1301.0 | accuracy: 0.42 | loss: 2.60
update:545/2000, 耗时:0.00分/1.18分 | step:  4360 | performance: 1332.3 | accuracy: 0.42 | loss: 0.67
update:550/2000, 耗时:0.00分/1.19分 | step:  4400 | performance: 1401.0 | accuracy: 0.43 | loss: 0.03
update:555/2000, 耗时:0.00分/1.20分 | step:  4440 | performance: 1342.2 | accuracy: 0.42 | loss: 0.08
update:560/2000, 耗时:0.00分/1.21分 | step:  4480 | performance: 1306.7 | accuracy: 0.42 | loss: 0.28
update:565/2000, 耗时:0.00分/1.22分 | step:  4520 | performance: 1621.9 | accuracy: 0.42 | loss: 0.21
update:570/2000, 耗时:0.00分/1.24分 | step:  4560 | performance: 1651.2 | accuracy: 0.42 | loss: 4.58
update:575/2000, 耗时:0.00分/1.25分 | step:  4600 | performance: 1194.4 | accuracy: 0.42 | loss: 0.89
update:580/2000, 耗时:0.00分/1.26分 | step:  4640 | performance: 1307.3 | accuracy: 0.42 | loss: 0.56
update:585/2000, 耗时:0.00分/1.27分 | step:  4680 | performance: 1398.7 | accuracy: 0.43 | loss: 0.33
update:590/2000, 耗时:0.00分/1.28分 | step:  4720 | performance: 1430.8 | accuracy: 0.43 | loss: 0.11
update:595/2000, 耗时:0.00分/1.29分 | step:  4760 | performance: 1483.9 | accuracy: 0.43 | loss: 0.92
update:600/2000, 耗时:0.00分/1.30分 | step:  4800 | performance: 1641.3 | accuracy: 0.44 | loss: 1.32
update:605/2000, 耗时:0.00分/1.31分 | step:  4840 | performance: 1823.0 | accuracy: 0.44 | loss: 0.19
update:610/2000, 耗时:0.00分/1.32分 | step:  4880 | performance: 1755.1 | accuracy: 0.44 | loss: 0.26
update:615/2000, 耗时:0.00分/1.33分 | step:  4920 | performance: 1657.8 | accuracy: 0.43 | loss: 0.01
update:620/2000, 耗时:0.00分/1.34分 | step:  4960 | performance: 1568.3 | accuracy: 0.43 | loss: 0.55
update:625/2000, 耗时:0.00分/1.36分 | step:  5000 | performance: 1704.8 | accuracy: 0.44 | loss: 0.18
update:630/2000, 耗时:0.00分/1.37分 | step:  5040 | performance: 1723.2 | accuracy: 0.44 | loss: 0.00
update:635/2000, 耗时:0.00分/1.38分 | step:  5080 | performance: 3140.3 | accuracy: 0.44 | loss: 0.76
update:640/2000, 耗时:0.00分/1.39分 | step:  5120 | performance: 4615.1 | accuracy: 0.44 | loss: 1.16
update:645/2000, 耗时:0.00分/1.40分 | step:  5160 | performance: 12166.2 | accuracy: 0.45 | loss: 1.66
update:650/2000, 耗时:0.00分/1.41分 | step:  5200 | performance: 21953.1 | accuracy: 0.45 | loss: 0.00
update:655/2000, 耗时:0.00分/1.42分 | step:  5240 | performance: 42337.9 | accuracy: 0.46 | loss: 3.98
update:660/2000, 耗时:0.00分/1.43分 | step:  5280 | performance: 46558.5 | accuracy: 0.46 | loss: 0.65
update:665/2000, 耗时:0.00分/1.44分 | step:  5320 | performance: 44021.2 | accuracy: 0.45 | loss: 0.76
update:670/2000, 耗时:0.00分/1.45分 | step:  5360 | performance: 44021.2 | accuracy: 0.45 | loss: 0.38
update:675/2000, 耗时:0.00分/1.46分 | step:  5400 | performance: 44021.2 | accuracy: 0.45 | loss: 0.02
update:680/2000, 耗时:0.00分/1.48分 | step:  5440 | performance: 44021.2 | accuracy: 0.44 | loss: 0.23
update:685/2000, 耗时:0.00分/1.49分 | step:  5480 | performance: 44021.2 | accuracy: 0.44 | loss: 0.28
update:690/2000, 耗时:0.00分/1.50分 | step:  5520 | performance: 44021.2 | accuracy: 0.44 | loss: 0.00
update:695/2000, 耗时:0.00分/1.51分 | step:  5560 | performance: 44021.2 | accuracy: 0.43 | loss: 0.23
update:700/2000, 耗时:0.00分/1.52分 | step:  5600 | performance: 44021.2 | accuracy: 0.43 | loss: 0.06
update:705/2000, 耗时:0.00分/1.53分 | step:  5640 | performance: 44021.2 | accuracy: 0.43 | loss: 0.05
update:710/2000, 耗时:0.00分/1.54分 | step:  5680 | performance: 43460.0 | accuracy: 0.43 | loss: -0.01
update:715/2000, 耗时:0.00分/1.55分 | step:  5720 | performance: 43460.0 | accuracy: 0.42 | loss: 0.09
update:720/2000, 耗时:0.00分/1.56分 | step:  5760 | performance: 43460.0 | accuracy: 0.42 | loss: 0.21
update:725/2000, 耗时:0.00分/1.57分 | step:  5800 | performance: 43460.0 | accuracy: 0.42 | loss: 0.92
update:730/2000, 耗时:0.00分/1.58分 | step:  5840 | performance: 43460.0 | accuracy: 0.42 | loss: 1.06
update:735/2000, 耗时:0.00分/1.60分 | step:  5880 | performance: 43460.0 | accuracy: 0.41 | loss: 0.21
update:740/2000, 耗时:0.00分/1.61分 | step:  5920 | performance: 43460.0 | accuracy: 0.41 | loss: 0.01
update:745/2000, 耗时:0.00分/1.62分 | step:  5960 | performance: 43460.0 | accuracy: 0.41 | loss: 0.07
update:750/2000, 耗时:0.00分/1.63分 | step:  6000 | performance: 43460.0 | accuracy: 0.40 | loss: 0.01
update:755/2000, 耗时:0.00分/1.64分 | step:  6040 | performance: 43725.4 | accuracy: 0.40 | loss: 0.31
update:760/2000, 耗时:0.00分/1.65分 | step:  6080 | performance: 41384.2 | accuracy: 0.40 | loss: 0.98
update:765/2000, 耗时:0.00分/1.66分 | step:  6120 | performance: 39426.2 | accuracy: 0.40 | loss: 0.20
update:770/2000, 耗时:0.00分/1.67分 | step:  6160 | performance: 44470.9 | accuracy: 0.41 | loss: 0.21
update:775/2000, 耗时:0.00分/1.68分 | step:  6200 | performance: 43861.4 | accuracy: 0.40 | loss: 1.49
update:780/2000, 耗时:0.00分/1.69分 | step:  6240 | performance: 46067.0 | accuracy: 0.41 | loss: 0.43
update:785/2000, 耗时:0.00分/1.70分 | step:  6280 | performance: 56447.1 | accuracy: 0.41 | loss: 0.45
update:790/2000, 耗时:0.00分/1.71分 | step:  6320 | performance: 55847.5 | accuracy: 0.41 | loss: 0.99
update:795/2000, 耗时:0.00分/1.72分 | step:  6360 | performance: 54254.3 | accuracy: 0.41 | loss: 0.42
update:800/2000, 耗时:0.00分/1.74分 | step:  6400 | performance: 57986.1 | accuracy: 0.41 | loss: 0.27
update:805/2000, 耗时:0.00分/1.75分 | step:  6440 | performance: 49604.2 | accuracy: 0.41 | loss: 1.08
update:810/2000, 耗时:0.00分/1.76分 | step:  6480 | performance: 38754.9 | accuracy: 0.41 | loss: 1.90
update:815/2000, 耗时:0.00分/1.77分 | step:  6520 | performance: 41631.9 | accuracy: 0.41 | loss: 3.69
update:820/2000, 耗时:0.00分/1.78分 | step:  6560 | performance: 42050.4 | accuracy: 0.41 | loss: 0.94
update:825/2000, 耗时:0.00分/1.79分 | step:  6600 | performance: 31412.9 | accuracy: 0.41 | loss: 0.75
update:830/2000, 耗时:0.00分/1.80分 | step:  6640 | performance: 23006.8 | accuracy: 0.41 | loss: 0.22
update:835/2000, 耗时:0.00分/1.81分 | step:  6680 | performance: 21742.9 | accuracy: 0.41 | loss: 1.33
update:840/2000, 耗时:0.00分/1.82分 | step:  6720 | performance: 27287.9 | accuracy: 0.41 | loss: 0.68
update:845/2000, 耗时:0.00分/1.83分 | step:  6760 | performance: 28789.9 | accuracy: 0.41 | loss: 0.71
update:850/2000, 耗时:0.00分/1.84分 | step:  6800 | performance: 29930.8 | accuracy: 0.41 | loss: 0.54
update:855/2000, 耗时:0.00分/1.85分 | step:  6840 | performance: 30681.6 | accuracy: 0.41 | loss: 0.58
update:860/2000, 耗时:0.00分/1.86分 | step:  6880 | performance: 26468.5 | accuracy: 0.41 | loss: 0.71
update:865/2000, 耗时:0.00分/1.87分 | step:  6920 | performance: 25565.5 | accuracy: 0.41 | loss: 0.97
update:870/2000, 耗时:0.00分/1.88分 | step:  6960 | performance: 27003.4 | accuracy: 0.41 | loss: 0.44
update:875/2000, 耗时:0.00分/1.89分 | step:  7000 | performance: 24711.2 | accuracy: 0.41 | loss: 0.66
update:880/2000, 耗时:0.00分/1.90分 | step:  7040 | performance: 22017.0 | accuracy: 0.40 | loss: 0.78
update:885/2000, 耗时:0.00分/1.91分 | step:  7080 | performance: 21388.1 | accuracy: 0.40 | loss: 0.72
update:890/2000, 耗时:0.00分/1.93分 | step:  7120 | performance: 21871.6 | accuracy: 0.40 | loss: 0.16
update:895/2000, 耗时:0.00分/1.94分 | step:  7160 | performance: 23248.0 | accuracy: 0.40 | loss: 0.00
update:900/2000, 耗时:0.00分/1.95分 | step:  7200 | performance: 21541.3 | accuracy: 0.40 | loss: 1.29
update:905/2000, 耗时:0.00分/1.96分 | step:  7240 | performance: 18822.6 | accuracy: 0.40 | loss: 0.20
update:910/2000, 耗时:0.00分/1.97分 | step:  7280 | performance: 11216.7 | accuracy: 0.40 | loss: 1.35
update:915/2000, 耗时:0.00分/1.98分 | step:  7320 | performance: 5123.7 | accuracy: 0.40 | loss: 0.27
update:920/2000, 耗时:0.00分/1.99分 | step:  7360 | performance: 4411.7 | accuracy: 0.39 | loss: 0.90
update:925/2000, 耗时:0.00分/2.00分 | step:  7400 | performance: 3705.0 | accuracy: 0.39 | loss: 2.03
update:930/2000, 耗时:0.00分/2.01分 | step:  7440 | performance: 4212.8 | accuracy: 0.39 | loss: 0.08
update:935/2000, 耗时:0.00分/2.02分 | step:  7480 | performance: 4411.9 | accuracy: 0.40 | loss: 1.29
update:940/2000, 耗时:0.00分/2.03分 | step:  7520 | performance: 3960.5 | accuracy: 0.39 | loss: 0.32
update:945/2000, 耗时:0.00分/2.04分 | step:  7560 | performance: 3440.8 | accuracy: 0.39 | loss: 0.74
update:950/2000, 耗时:0.00分/2.05分 | step:  7600 | performance: 3179.4 | accuracy: 0.39 | loss: 0.31
update:955/2000, 耗时:0.00分/2.06分 | step:  7640 | performance: 2840.9 | accuracy: 0.39 | loss: 0.50
update:960/2000, 耗时:0.00分/2.07分 | step:  7680 | performance: 3197.9 | accuracy: 0.39 | loss: 2.37
update:965/2000, 耗时:0.00分/2.08分 | step:  7720 | performance: 3307.7 | accuracy: 0.39 | loss: 2.19
update:970/2000, 耗时:0.00分/2.10分 | step:  7760 | performance: 2775.1 | accuracy: 0.39 | loss: 2.82
update:975/2000, 耗时:0.00分/2.11分 | step:  7800 | performance: 1899.4 | accuracy: 0.39 | loss: 1.66
update:980/2000, 耗时:0.00分/2.12分 | step:  7840 | performance: 1736.7 | accuracy: 0.39 | loss: 0.01
update:985/2000, 耗时:0.00分/2.13分 | step:  7880 | performance: 1245.4 | accuracy: 0.38 | loss: 0.00
update:990/2000, 耗时:0.00分/2.14分 | step:  7920 | performance: 569.4 | accuracy: 0.38 | loss: 0.71
update:995/2000, 耗时:0.00分/2.15分 | step:  7960 | performance: 243.1 | accuracy: 0.38 | loss: 0.24
update:1000/2000, 耗时:0.00分/2.16分 | step:  8000 | performance: 258.1 | accuracy: 0.38 | loss: 0.93
update:1005/2000, 耗时:0.00分/2.17分 | step:  8040 | performance: 254.5 | accuracy: 0.38 | loss: 3.09
update:1010/2000, 耗时:0.00分/2.18分 | step:  8080 | performance: 230.9 | accuracy: 0.38 | loss: 4.33
update:1015/2000, 耗时:0.00分/2.19分 | step:  8120 | performance: 216.9 | accuracy: 0.38 | loss: 0.19
update:1020/2000, 耗时:0.00分/2.20分 | step:  8160 | performance: 139.1 | accuracy: 0.38 | loss: 1.30
update:1025/2000, 耗时:0.00分/2.21分 | step:  8200 | performance: 113.9 | accuracy: 0.38 | loss: 2.94
update:1030/2000, 耗时:0.00分/2.23分 | step:  8240 | performance: 125.7 | accuracy: 0.38 | loss: 0.99
update:1035/2000, 耗时:0.00分/2.24分 | step:  8280 | performance: 150.5 | accuracy: 0.38 | loss: 0.01
update:1040/2000, 耗时:0.00分/2.25分 | step:  8320 | performance: 232.9 | accuracy: 0.38 | loss: 0.04
update:1045/2000, 耗时:0.00分/2.26分 | step:  8360 | performance: 225.2 | accuracy: 0.38 | loss: 1.31
update:1050/2000, 耗时:0.00分/2.27分 | step:  8400 | performance: 227.1 | accuracy: 0.38 | loss: 0.76
update:1055/2000, 耗时:0.00分/2.28分 | step:  8440 | performance: 173.7 | accuracy: 0.38 | loss: 1.82
update:1060/2000, 耗时:0.00分/2.29分 | step:  8480 | performance: 103.5 | accuracy: 0.38 | loss: 3.50
update:1065/2000, 耗时:0.00分/2.30分 | step:  8520 | performance: 78.2 | accuracy: 0.38 | loss: 0.06
update:1070/2000, 耗时:0.00分/2.31分 | step:  8560 | performance: 52.9 | accuracy: 0.38 | loss: 0.47
update:1075/2000, 耗时:0.00分/2.32分 | step:  8600 | performance: 25.7 | accuracy: 0.37 | loss: 0.77
update:1080/2000, 耗时:0.00分/2.33分 | step:  8640 | performance: 12.9 | accuracy: 0.37 | loss: 0.24
update:1085/2000, 耗时:0.00分/2.34分 | step:  8680 | performance: 11.0 | accuracy: 0.37 | loss: 0.00
update:1090/2000, 耗时:0.00分/2.36分 | step:  8720 | performance: 20.6 | accuracy: 0.38 | loss: 4.20
update:1095/2000, 耗时:0.00分/2.37分 | step:  8760 | performance: 21.9 | accuracy: 0.38 | loss: 0.56
update:1100/2000, 耗时:0.00分/2.38分 | step:  8800 | performance: 19.0 | accuracy: 0.37 | loss: 0.91
update:1105/2000, 耗时:0.00分/2.39分 | step:  8840 | performance: 13.6 | accuracy: 0.37 | loss: 0.78
update:1110/2000, 耗时:0.00分/2.40分 | step:  8880 | performance: 12.0 | accuracy: 0.37 | loss: 1.23
update:1115/2000, 耗时:0.00分/2.41分 | step:  8920 | performance: 18.0 | accuracy: 0.38 | loss: 0.05
update:1120/2000, 耗时:0.00分/2.42分 | step:  8960 | performance: 20.6 | accuracy: 0.38 | loss: 3.32
update:1125/2000, 耗时:0.00分/2.43分 | step:  9000 | performance: 24.8 | accuracy: 0.38 | loss: 0.28
update:1130/2000, 耗时:0.00分/2.45分 | step:  9040 | performance: 16.0 | accuracy: 0.38 | loss: 0.00
update:1135/2000, 耗时:0.00分/2.46分 | step:  9080 | performance: 21.5 | accuracy: 0.38 | loss: 0.44
update:1140/2000, 耗时:0.00分/2.47分 | step:  9120 | performance: 27.2 | accuracy: 0.38 | loss: 1.05
update:1145/2000, 耗时:0.00分/2.48分 | step:  9160 | performance: 32.5 | accuracy: 0.38 | loss: 0.04
update:1150/2000, 耗时:0.00分/2.49分 | step:  9200 | performance: 29.5 | accuracy: 0.38 | loss: 1.48
update:1155/2000, 耗时:0.00分/2.51分 | step:  9240 | performance: 17.9 | accuracy: 0.38 | loss: 1.68
update:1160/2000, 耗时:0.00分/2.52分 | step:  9280 | performance: 10.8 | accuracy: 0.38 | loss: 2.47
update:1165/2000, 耗时:0.00分/2.53分 | step:  9320 | performance: 7.5 | accuracy: 0.38 | loss: 0.01
update:1170/2000, 耗时:0.00分/2.54分 | step:  9360 | performance: 8.3 | accuracy: 0.38 | loss: 1.70
update:1175/2000, 耗时:0.00分/2.55分 | step:  9400 | performance: 9.1 | accuracy: 0.38 | loss: 2.25
update:1180/2000, 耗时:0.00分/2.57分 | step:  9440 | performance: 15.7 | accuracy: 0.38 | loss: 0.64
update:1185/2000, 耗时:0.00分/2.58分 | step:  9480 | performance: 17.9 | accuracy: 0.39 | loss: 0.00
update:1190/2000, 耗时:0.00分/2.59分 | step:  9520 | performance: 15.0 | accuracy: 0.38 | loss: 0.12
update:1195/2000, 耗时:0.00分/2.60分 | step:  9560 | performance: 18.8 | accuracy: 0.39 | loss: 0.36
update:1200/2000, 耗时:0.00分/2.61分 | step:  9600 | performance: 19.5 | accuracy: 0.39 | loss: 1.01
update:1205/2000, 耗时:0.00分/2.63分 | step:  9640 | performance: 20.1 | accuracy: 0.39 | loss: 0.78
update:1210/2000, 耗时:0.00分/2.64分 | step:  9680 | performance: 28.8 | accuracy: 0.39 | loss: 0.80
update:1215/2000, 耗时:0.00分/2.65分 | step:  9720 | performance: 27.2 | accuracy: 0.39 | loss: 0.85
update:1220/2000, 耗时:0.00分/2.66分 | step:  9760 | performance: 17.1 | accuracy: 0.39 | loss: 1.37
update:1225/2000, 耗时:0.00分/2.67分 | step:  9800 | performance: 15.9 | accuracy: 0.39 | loss: 0.36
update:1230/2000, 耗时:0.00分/2.69分 | step:  9840 | performance: 17.1 | accuracy: 0.39 | loss: 0.72
update:1235/2000, 耗时:0.00分/2.70分 | step:  9880 | performance: 19.2 | accuracy: 0.39 | loss: 0.10
update:1240/2000, 耗时:0.00分/2.71分 | step:  9920 | performance: 18.0 | accuracy: 0.39 | loss: 0.31
update:1245/2000, 耗时:0.00分/2.72分 | step:  9960 | performance: 18.7 | accuracy: 0.39 | loss: 0.61
update:1250/2000, 耗时:0.00分/2.73分 | step: 10000 | performance: 20.5 | accuracy: 0.40 | loss: 0.18
update:1255/2000, 耗时:0.00分/2.75分 | step: 10040 | performance: 21.2 | accuracy: 0.40 | loss: 1.23
update:1260/2000, 耗时:0.00分/2.76分 | step: 10080 | performance: 34.3 | accuracy: 0.40 | loss: 1.71
update:1265/2000, 耗时:0.00分/2.77分 | step: 10120 | performance: 86.9 | accuracy: 0.40 | loss: 0.82
update:1270/2000, 耗时:0.00分/2.78分 | step: 10160 | performance: 101.2 | accuracy: 0.40 | loss: 0.37
update:1275/2000, 耗时:0.00分/2.79分 | step: 10200 | performance: 90.1 | accuracy: 0.40 | loss: 0.00
update:1280/2000, 耗时:0.00分/2.80分 | step: 10240 | performance: 92.8 | accuracy: 0.40 | loss: 0.10
update:1285/2000, 耗时:0.00分/2.81分 | step: 10280 | performance: 100.8 | accuracy: 0.40 | loss: 0.79
update:1290/2000, 耗时:0.00分/2.83分 | step: 10320 | performance: 84.6 | accuracy: 0.40 | loss: 1.94
update:1295/2000, 耗时:0.00分/2.84分 | step: 10360 | performance: 75.0 | accuracy: 0.40 | loss: 1.31
update:1300/2000, 耗时:0.00分/2.85分 | step: 10400 | performance: 81.5 | accuracy: 0.40 | loss: 0.53
update:1305/2000, 耗时:0.00分/2.86分 | step: 10440 | performance: 94.6 | accuracy: 0.40 | loss: 0.24
update:1310/2000, 耗时:0.00分/2.87分 | step: 10480 | performance: 109.6 | accuracy: 0.41 | loss: 0.09
update:1315/2000, 耗时:0.00分/2.89分 | step: 10520 | performance: 97.3 | accuracy: 0.40 | loss: 0.67
update:1320/2000, 耗时:0.00分/2.90分 | step: 10560 | performance: 138.3 | accuracy: 0.41 | loss: 0.36
update:1325/2000, 耗时:0.00分/2.91分 | step: 10600 | performance: 62.4 | accuracy: 0.40 | loss: 2.19
update:1330/2000, 耗时:0.00分/2.92分 | step: 10640 | performance: 37.2 | accuracy: 0.40 | loss: 1.17
update:1335/2000, 耗时:0.00分/2.93分 | step: 10680 | performance: 41.8 | accuracy: 0.41 | loss: 0.54
update:1340/2000, 耗时:0.00分/2.94分 | step: 10720 | performance: 41.0 | accuracy: 0.41 | loss: 1.41
update:1345/2000, 耗时:0.00分/2.95分 | step: 10760 | performance: 38.5 | accuracy: 0.40 | loss: 0.32
update:1350/2000, 耗时:0.00分/2.96分 | step: 10800 | performance: 45.2 | accuracy: 0.41 | loss: 1.42
update:1355/2000, 耗时:0.00分/2.98分 | step: 10840 | performance: 56.8 | accuracy: 0.41 | loss: 0.83
update:1360/2000, 耗时:0.00分/2.99分 | step: 10880 | performance: 60.5 | accuracy: 0.41 | loss: 1.51
update:1365/2000, 耗时:0.00分/3.00分 | step: 10920 | performance: 69.0 | accuracy: 0.41 | loss: 1.07
update:1370/2000, 耗时:0.00分/3.01分 | step: 10960 | performance: 82.1 | accuracy: 0.41 | loss: 0.37
update:1375/2000, 耗时:0.00分/3.02分 | step: 11000 | performance: 113.7 | accuracy: 0.42 | loss: 0.70
update:1380/2000, 耗时:0.00分/3.03分 | step: 11040 | performance: 206.4 | accuracy: 0.42 | loss: 0.48
update:1385/2000, 耗时:0.00分/3.04分 | step: 11080 | performance: 266.4 | accuracy: 0.42 | loss: 0.48
update:1390/2000, 耗时:0.00分/3.05分 | step: 11120 | performance: 212.7 | accuracy: 0.42 | loss: 0.16
update:1395/2000, 耗时:0.00分/3.07分 | step: 11160 | performance: 182.2 | accuracy: 0.42 | loss: 3.83
update:1400/2000, 耗时:0.00分/3.08分 | step: 11200 | performance: 224.7 | accuracy: 0.42 | loss: 0.00
update:1405/2000, 耗时:0.00分/3.09分 | step: 11240 | performance: 218.2 | accuracy: 0.42 | loss: 0.48
update:1410/2000, 耗时:0.00分/3.10分 | step: 11280 | performance: 189.7 | accuracy: 0.42 | loss: 0.12
update:1415/2000, 耗时:0.00分/3.11分 | step: 11320 | performance: 220.0 | accuracy: 0.42 | loss: 0.91
update:1420/2000, 耗时:0.00分/3.12分 | step: 11360 | performance: 247.7 | accuracy: 0.42 | loss: 0.48
update:1425/2000, 耗时:0.00分/3.13分 | step: 11400 | performance: 277.6 | accuracy: 0.42 | loss: 0.11
update:1430/2000, 耗时:0.00分/3.15分 | step: 11440 | performance: 329.1 | accuracy: 0.42 | loss: 0.62
update:1435/2000, 耗时:0.00分/3.16分 | step: 11480 | performance: 262.2 | accuracy: 0.42 | loss: 6.25
update:1440/2000, 耗时:0.00分/3.17分 | step: 11520 | performance: 230.0 | accuracy: 0.42 | loss: 2.01
update:1445/2000, 耗时:0.00分/3.18分 | step: 11560 | performance: 244.9 | accuracy: 0.42 | loss: 2.12
update:1450/2000, 耗时:0.00分/3.19分 | step: 11600 | performance: 246.3 | accuracy: 0.42 | loss: 0.27
update:1455/2000, 耗时:0.00分/3.20分 | step: 11640 | performance: 237.6 | accuracy: 0.42 | loss: 1.36
update:1460/2000, 耗时:0.00分/3.22分 | step: 11680 | performance: 265.7 | accuracy: 0.42 | loss: 0.66
update:1465/2000, 耗时:0.00分/3.23分 | step: 11720 | performance: 237.9 | accuracy: 0.42 | loss: 1.23
update:1470/2000, 耗时:0.00分/3.24分 | step: 11760 | performance: 154.4 | accuracy: 0.42 | loss: 1.31
update:1475/2000, 耗时:0.00分/3.25分 | step: 11800 | performance: 122.8 | accuracy: 0.42 | loss: 1.96
update:1480/2000, 耗时:0.00分/3.26分 | step: 11840 | performance: 120.1 | accuracy: 0.42 | loss: 0.88
update:1485/2000, 耗时:0.00分/3.27分 | step: 11880 | performance: 86.5 | accuracy: 0.42 | loss: 0.16
update:1490/2000, 耗时:0.00分/3.28分 | step: 11920 | performance: 65.3 | accuracy: 0.42 | loss: 0.42
update:1495/2000, 耗时:0.00分/3.29分 | step: 11960 | performance: 68.3 | accuracy: 0.42 | loss: 1.74
update:1500/2000, 耗时:0.00分/3.30分 | step: 12000 | performance: 76.4 | accuracy: 0.42 | loss: 0.06
update:1505/2000, 耗时:0.00分/3.32分 | step: 12040 | performance: 90.5 | accuracy: 0.42 | loss: 0.58
update:1510/2000, 耗时:0.00分/3.33分 | step: 12080 | performance: 76.8 | accuracy: 0.42 | loss: 0.63
update:1515/2000, 耗时:0.00分/3.34分 | step: 12120 | performance: 47.4 | accuracy: 0.42 | loss: 0.70
update:1520/2000, 耗时:0.00分/3.35分 | step: 12160 | performance: 43.3 | accuracy: 0.42 | loss: 1.20
update:1525/2000, 耗时:0.00分/3.36分 | step: 12200 | performance: 46.0 | accuracy: 0.42 | loss: 0.29
update:1530/2000, 耗时:0.00分/3.37分 | step: 12240 | performance: 39.5 | accuracy: 0.42 | loss: 0.44
update:1535/2000, 耗时:0.00分/3.38分 | step: 12280 | performance: 30.1 | accuracy: 0.42 | loss: 0.39
update:1540/2000, 耗时:0.00分/3.39分 | step: 12320 | performance: 27.5 | accuracy: 0.42 | loss: 1.47
update:1545/2000, 耗时:0.00分/3.41分 | step: 12360 | performance: 23.6 | accuracy: 0.41 | loss: 1.40
update:1550/2000, 耗时:0.00分/3.42分 | step: 12400 | performance: 28.1 | accuracy: 0.42 | loss: 1.41
update:1555/2000, 耗时:0.00分/3.43分 | step: 12440 | performance: 32.4 | accuracy: 0.42 | loss: 2.85
update:1560/2000, 耗时:0.00分/3.44分 | step: 12480 | performance: 35.8 | accuracy: 0.42 | loss: 1.06
update:1565/2000, 耗时:0.00分/3.45分 | step: 12520 | performance: 34.9 | accuracy: 0.42 | loss: 0.60
update:1570/2000, 耗时:0.00分/3.46分 | step: 12560 | performance: 48.5 | accuracy: 0.42 | loss: 1.58
update:1575/2000, 耗时:0.00分/3.48分 | step: 12600 | performance: 77.8 | accuracy: 0.42 | loss: 0.45
update:1580/2000, 耗时:0.00分/3.49分 | step: 12640 | performance: 78.0 | accuracy: 0.42 | loss: 0.00
update:1585/2000, 耗时:0.00分/3.50分 | step: 12680 | performance: 68.2 | accuracy: 0.42 | loss: 0.36
update:1590/2000, 耗时:0.00分/3.51分 | step: 12720 | performance: 61.4 | accuracy: 0.42 | loss: 0.00
update:1595/2000, 耗时:0.00分/3.52分 | step: 12760 | performance: 121.9 | accuracy: 0.42 | loss: 0.06
update:1600/2000, 耗时:0.00分/3.53分 | step: 12800 | performance: 485.2 | accuracy: 0.42 | loss: 4.24
update:1605/2000, 耗时:0.00分/3.55分 | step: 12840 | performance: 2559.5 | accuracy: 0.43 | loss: 0.22
update:1610/2000, 耗时:0.00分/3.56分 | step: 12880 | performance: 3176.1 | accuracy: 0.43 | loss: 1.14
update:1615/2000, 耗时:0.00分/3.57分 | step: 12920 | performance: 1453.8 | accuracy: 0.43 | loss: 2.36
update:1620/2000, 耗时:0.00分/3.58分 | step: 12960 | performance: 941.3 | accuracy: 0.43 | loss: 0.00
update:1625/2000, 耗时:0.00分/3.59分 | step: 13000 | performance: 750.3 | accuracy: 0.43 | loss: 0.00
update:1630/2000, 耗时:0.00分/3.60分 | step: 13040 | performance: 644.0 | accuracy: 0.43 | loss: 0.00
update:1635/2000, 耗时:0.00分/3.62分 | step: 13080 | performance: 907.6 | accuracy: 0.43 | loss: 0.05
update:1640/2000, 耗时:0.00分/3.63分 | step: 13120 | performance: 710.6 | accuracy: 0.43 | loss: 3.00
update:1645/2000, 耗时:0.00分/3.64分 | step: 13160 | performance: 508.3 | accuracy: 0.42 | loss: 1.45
update:1650/2000, 耗时:0.00分/3.65分 | step: 13200 | performance: 412.7 | accuracy: 0.42 | loss: 1.37
update:1655/2000, 耗时:0.00分/3.66分 | step: 13240 | performance: 306.9 | accuracy: 0.42 | loss: 0.49
update:1660/2000, 耗时:0.00分/3.68分 | step: 13280 | performance: 420.9 | accuracy: 0.42 | loss: 1.51
update:1665/2000, 耗时:0.00分/3.69分 | step: 13320 | performance: 480.5 | accuracy: 0.43 | loss: 1.01
update:1670/2000, 耗时:0.00分/3.70分 | step: 13360 | performance: 458.6 | accuracy: 0.43 | loss: 0.74
update:1675/2000, 耗时:0.00分/3.71分 | step: 13400 | performance: 369.3 | accuracy: 0.42 | loss: 0.05
update:1680/2000, 耗时:0.00分/3.72分 | step: 13440 | performance: 439.0 | accuracy: 0.43 | loss: 1.57
update:1685/2000, 耗时:0.00分/3.73分 | step: 13480 | performance: 339.9 | accuracy: 0.43 | loss: 0.22
update:1690/2000, 耗时:0.00分/3.75分 | step: 13520 | performance: 239.2 | accuracy: 0.42 | loss: 0.37
update:1695/2000, 耗时:0.00分/3.76分 | step: 13560 | performance: 177.3 | accuracy: 0.42 | loss: 0.21
update:1700/2000, 耗时:0.00分/3.77分 | step: 13600 | performance: 92.0 | accuracy: 0.42 | loss: 2.91
update:1705/2000, 耗时:0.00分/3.78分 | step: 13640 | performance: 81.4 | accuracy: 0.42 | loss: 2.45
update:1710/2000, 耗时:0.00分/3.79分 | step: 13680 | performance: 73.0 | accuracy: 0.42 | loss: 0.81
update:1715/2000, 耗时:0.00分/3.80分 | step: 13720 | performance: 47.1 | accuracy: 0.42 | loss: 0.34
update:1720/2000, 耗时:0.00分/3.82分 | step: 13760 | performance: 75.9 | accuracy: 0.42 | loss: 0.46
update:1725/2000, 耗时:0.00分/3.83分 | step: 13800 | performance: 67.9 | accuracy: 0.42 | loss: 1.44
update:1730/2000, 耗时:0.00分/3.84分 | step: 13840 | performance: 50.7 | accuracy: 0.42 | loss: 1.32
update:1735/2000, 耗时:0.00分/3.85分 | step: 13880 | performance: 47.0 | accuracy: 0.42 | loss: 0.06
update:1740/2000, 耗时:0.00分/3.86分 | step: 13920 | performance: 53.0 | accuracy: 0.42 | loss: 0.43
update:1745/2000, 耗时:0.00分/3.87分 | step: 13960 | performance: 71.9 | accuracy: 0.42 | loss: 1.17
update:1750/2000, 耗时:0.00分/3.89分 | step: 14000 | performance: 82.9 | accuracy: 0.42 | loss: 0.64
update:1755/2000, 耗时:0.00分/3.90分 | step: 14040 | performance: 63.2 | accuracy: 0.42 | loss: 0.73
update:1760/2000, 耗时:0.00分/3.91分 | step: 14080 | performance: 52.6 | accuracy: 0.42 | loss: 0.21
update:1765/2000, 耗时:0.00分/3.92分 | step: 14120 | performance: 45.6 | accuracy: 0.42 | loss: 0.80
update:1770/2000, 耗时:0.00分/3.93分 | step: 14160 | performance: 47.5 | accuracy: 0.42 | loss: 1.15
update:1775/2000, 耗时:0.00分/3.94分 | step: 14200 | performance: 47.1 | accuracy: 0.42 | loss: 1.16
update:1780/2000, 耗时:0.00分/3.96分 | step: 14240 | performance: 44.5 | accuracy: 0.42 | loss: 0.24
update:1785/2000, 耗时:0.00分/3.97分 | step: 14280 | performance: 53.1 | accuracy: 0.42 | loss: 0.31
update:1790/2000, 耗时:0.00分/3.98分 | step: 14320 | performance: 59.8 | accuracy: 0.42 | loss: 0.29
update:1795/2000, 耗时:0.00分/3.99分 | step: 14360 | performance: 56.8 | accuracy: 0.42 | loss: 0.84
update:1800/2000, 耗时:0.00分/4.00分 | step: 14400 | performance: 61.3 | accuracy: 0.42 | loss: 0.52
update:1805/2000, 耗时:0.00分/4.01分 | step: 14440 | performance: 56.3 | accuracy: 0.42 | loss: 0.63
update:1810/2000, 耗时:0.00分/4.03分 | step: 14480 | performance: 61.9 | accuracy: 0.42 | loss: 1.13
update:1815/2000, 耗时:0.00分/4.04分 | step: 14520 | performance: 74.2 | accuracy: 0.43 | loss: 1.18
update:1820/2000, 耗时:0.00分/4.05分 | step: 14560 | performance: 74.8 | accuracy: 0.43 | loss: 0.69
update:1825/2000, 耗时:0.00分/4.06分 | step: 14600 | performance: 74.7 | accuracy: 0.43 | loss: 0.61
update:1830/2000, 耗时:0.00分/4.07分 | step: 14640 | performance: 77.5 | accuracy: 0.43 | loss: 0.76
update:1835/2000, 耗时:0.00分/4.08分 | step: 14680 | performance: 68.1 | accuracy: 0.43 | loss: 0.81
update:1840/2000, 耗时:0.00分/4.10分 | step: 14720 | performance: 67.6 | accuracy: 0.43 | loss: 0.27
update:1845/2000, 耗时:0.00分/4.11分 | step: 14760 | performance: 69.4 | accuracy: 0.43 | loss: 0.35
update:1850/2000, 耗时:0.00分/4.12分 | step: 14800 | performance: 72.0 | accuracy: 0.43 | loss: 0.22
update:1855/2000, 耗时:0.00分/4.13分 | step: 14840 | performance: 76.4 | accuracy: 0.43 | loss: 0.31
update:1860/2000, 耗时:0.00分/4.14分 | step: 14880 | performance: 74.5 | accuracy: 0.43 | loss: 1.04
update:1865/2000, 耗时:0.00分/4.15分 | step: 14920 | performance: 63.3 | accuracy: 0.43 | loss: 0.76
update:1870/2000, 耗时:0.00分/4.16分 | step: 14960 | performance: 54.1 | accuracy: 0.43 | loss: 0.69
update:1875/2000, 耗时:0.00分/4.17分 | step: 15000 | performance: 32.1 | accuracy: 0.43 | loss: 0.94
update:1880/2000, 耗时:0.00分/4.19分 | step: 15040 | performance: 20.9 | accuracy: 0.42 | loss: 0.04
update:1885/2000, 耗时:0.00分/4.20分 | step: 15080 | performance: 17.6 | accuracy: 0.42 | loss: 0.06
update:1890/2000, 耗时:0.00分/4.21分 | step: 15120 | performance: 19.2 | accuracy: 0.42 | loss: 1.58
update:1895/2000, 耗时:0.00分/4.22分 | step: 15160 | performance: 15.1 | accuracy: 0.42 | loss: 1.72
update:1900/2000, 耗时:0.00分/4.23分 | step: 15200 | performance: 14.1 | accuracy: 0.42 | loss: 0.11
update:1905/2000, 耗时:0.00分/4.25分 | step: 15240 | performance: 14.9 | accuracy: 0.42 | loss: 0.67
update:1910/2000, 耗时:0.00分/4.26分 | step: 15280 | performance: 14.6 | accuracy: 0.42 | loss: 1.45
update:1915/2000, 耗时:0.00分/4.27分 | step: 15320 | performance: 12.8 | accuracy: 0.42 | loss: 0.54
update:1920/2000, 耗时:0.00分/4.28分 | step: 15360 | performance: 12.5 | accuracy: 0.42 | loss: 0.53
update:1925/2000, 耗时:0.00分/4.29分 | step: 15400 | performance: 14.6 | accuracy: 0.42 | loss: 0.80
update:1930/2000, 耗时:0.00分/4.31分 | step: 15440 | performance: 15.1 | accuracy: 0.42 | loss: 0.02
update:1935/2000, 耗时:0.00分/4.32分 | step: 15480 | performance: 17.2 | accuracy: 0.42 | loss: 1.20
update:1940/2000, 耗时:0.00分/4.33分 | step: 15520 | performance: 17.2 | accuracy: 0.42 | loss: 0.29
update:1945/2000, 耗时:0.00分/4.34分 | step: 15560 | performance: 14.9 | accuracy: 0.42 | loss: 1.22
update:1950/2000, 耗时:0.00分/4.35分 | step: 15600 | performance: 20.7 | accuracy: 0.42 | loss: 0.14
update:1955/2000, 耗时:0.00分/4.36分 | step: 15640 | performance: 37.4 | accuracy: 0.43 | loss: 0.37
update:1960/2000, 耗时:0.00分/4.38分 | step: 15680 | performance: 40.2 | accuracy: 0.43 | loss: 0.82
update:1965/2000, 耗时:0.00分/4.39分 | step: 15720 | performance: 38.1 | accuracy: 0.43 | loss: 1.12
update:1970/2000, 耗时:0.00分/4.40分 | step: 15760 | performance: 35.7 | accuracy: 0.43 | loss: 0.59
update:1975/2000, 耗时:0.00分/4.41分 | step: 15800 | performance: 28.7 | accuracy: 0.42 | loss: 0.07
update:1980/2000, 耗时:0.00分/4.42分 | step: 15840 | performance: 24.4 | accuracy: 0.42 | loss: 1.32
update:1985/2000, 耗时:0.00分/4.43分 | step: 15880 | performance: 26.0 | accuracy: 0.42 | loss: 1.37
update:1990/2000, 耗时:0.00分/4.44分 | step: 15920 | performance: 34.4 | accuracy: 0.43 | loss: 0.53
update:1995/2000, 耗时:0.00分/4.45分 | step: 15960 | performance: 31.5 | accuracy: 0.42 | loss: 1.27
update:2000/2000, 耗时:0.00分/4.46分 | step: 16000 | performance: 28.7 | accuracy: 0.42 | loss: 0.60
----------------------------------------finished----------------------------------------
  0%|          | 0/397 [00:00<?, ?it/s]100%|| 397/397 [00:00<00:00, 132290.35it/s]
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1000.00
2023-07-24T12:00:00 | net performance [%] = 0.0000
2023-07-24T12:00:00 | number of trades [#] = 0
==================================================
Trial 7 Complete [00h 04m 53s]
net_wealth: 1000.0

Best net_wealth So Far: 1380.2023481050508
Total elapsed time: 00h 36m 05s

Search: Running Trial #8

Value             |Best Value So Far |Hyperparameter
6                 |1                 |horizon
225               |225               |lookback
True              |False             |MarketFactor
14                |8                 |lags
0.85              |0.9               |gamma
32                |32                |batch_size
64                |10                |n_step
0.8               |0.92              |gae_lambda
2                 |2                 |gradient_clip_norm
3                 |3                 |epochs
0.001             |5e-05             |actor_lr
1e-05             |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4295.000000   4301.000000
mean      0.000435    20113.607657  ...   20191.527960  20169.373185
std       0.027833    16040.642334  ...   16078.872271  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7755.915039   7730.930176
50%       0.000642    11571.842969  ...   11757.219727  11751.469727
75%       0.011590    29894.706152  ...   30018.430664  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-27 22:39:220202023233-07-27 --072-027-27 72 :39:222282:39::329.:28.29925479895.692:: 9I9  I tt5e4nes7onsrofrflol:o I ww//cor28.2t2023-07-27 22:3e9nse/porfllo95watf/co4roec27:0ore/plat23f-/ Ip tl0rm/cpu_7feature_guard.-cc:142] This 2TensorFlow bina79 ensorflo2owrm/c/crpy2or::39:28.2 8.is2 oept/imized996pul7a t_fowitrfeamh o/turcnepe_uAPI_gf 22002Duard.c3e2eep9972-5307--0727c  22N5-:::e39:218 a.t2979991f:u IIatrure_guard.cc:2o7r 2a l m :IN1ett/w otrk 4L22:c] een39p:u2iTbshinsr8_oas o trf.rTr4y2f2lloowe9 9w]//ncs oc(orTe/opnelroart9hDei/Flowples Ten8nsN5: No rI btinaflsoerowrn)/Fclory is etof/plateao fooprtmi/wctpm ibsuourrfel _zf_edu aow/ctofgesae ouiawrtthuithrdfnary oe fol is opr.ocnrelowie_tirAmg/e/PmInmuard .Dceeipzep lcc/apc:d1 cg: 142CtPU ]f ouT_hinsitsw4p Tu_en2iftrrs]eNeatumhuorc / catruorpTifoenu_fheaenatl_sFguirsue _Nguaetltoa rwd .eTAePnIsbocr Flwo Dionr kiencawepp:r1 eyrfLoirm4a b  bNi2n]reaurrya l  n(aroy ineceN-ceiDNtsTs ohuritwiriptoimrkds ri eLz.NcTaeni_ oepltbg opeua)i tomrsda roizedwridc.rccc::1ayt (4 t iuosoe2 h nosn:]nwti1hr F 42e]TDtNNheei  fos llow loAwhinTgb)i P CeTh is T narynesPooArI DFUnt Vo eeiAnuleposPsIX nDw  AVXs2o ite  
sr uNtrheFTooeleow ef opl uenable cthbetioinrbns in pertimnaalp Nei rifmn  Noetoy isurrimzeaa rohdllaopw yenctet-wi rc roiptiith omwoicsi noerk nLiprit Netibmwzaailzoerrk AePed witd wI tioDietha ronegAeyp (ho nCPU i n PoneAPI nNsDeIe , reseutrer DoepepbDpuiu NNe lNal urLibctioN) taolnd Ten eraNetwork LsorNu eibrary urs in(oneDNNe)t to uaFlow tiwonrsworysee thsk  (Loinebr r:D NpeN)r fiote attlh  rom  uNfeotlwhetlaowncsa foheo-rckreeiln appliotical wi ry ropritaA VLhoXn ApVeXg i(brrte com CPUaoptineD2a
Tiler for enabley l themae  fgin oNollN )iogs(oneDNN. theCoPw)i t nntnorg CP use tos: Us Uhe f
oti insto usperurlarloune cthetcwtis triuoncti osntnfsoii oAnVX  AgVs iin, nl oX 2l
 preoTpoe eerfwornable them iiformance-critical ng CPoCbuildPU n other operations, rebuild TensorFlow with the appropriate compilUp  nsiienst Tr nerationss:t r uArin perforuefcVX AVX2
Ttmnasncieolacgs-nts ciorFrlmnarioo.wt w  
ical opieionsp ein npnrerationacee-s:rtfh o tf bAVrmhcritlore manXet i cceal -ahcrem inaAVXonictippre2 otcha
pTel- coooreripr operriate compiler fla patgenationabts.ils
ieornec ta:  AVX AVX2
Tola tein hse:m  io nAVopeX AanrsV, X2ble the ro
To enable tetbuild Temher operat in other operathnseomrFlow with the appropriati oaiotine compilerns, rebuild TensorFlow with the appropriate compiler flags.
 flags.
 other operations, rebuild TensorFlow with the appropriate compiler flagns, rebuild TensorFlow with the appropriate compiler flags.
ions:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
s.
2023-07-27 22:39:28.888072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:39:28.920991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:39:28.928808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:39:28.929947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:39:28.941291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:39:28.942332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:39:28.947583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:39:28.962384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.06分 | step:  2560 | performance: 0.0 | accuracy: 0.25 | loss: 1.84
update: 10/2000, 耗时:0.01分/0.11分 | step:  5120 | performance: 0.0 | accuracy: 0.27 | loss: 3.10
update: 15/2000, 耗时:0.01分/0.16分 | step:  7680 | performance: 0.0 | accuracy: 0.27 | loss: 3.22
update: 20/2000, 耗时:0.01分/0.21分 | step: 10240 | performance: 0.1 | accuracy: 0.27 | loss: 2.09
update: 25/2000, 耗时:0.01分/0.26分 | step: 12800 | performance: 0.0 | accuracy: 0.27 | loss: 3.31
update: 30/2000, 耗时:0.01分/0.30分 | step: 15360 | performance: 0.0 | accuracy: 0.28 | loss: 2.32
update: 35/2000, 耗时:0.01分/0.35分 | step: 17920 | performance: 1.0 | accuracy: 0.30 | loss: 7.57
update: 40/2000, 耗时:0.01分/0.40分 | step: 20480 | performance: 0.4 | accuracy: 0.31 | loss: 1.84
update: 45/2000, 耗时:0.01分/0.45分 | step: 23040 | performance: 0.9 | accuracy: 0.30 | loss: 3.66
update: 50/2000, 耗时:0.01分/0.50分 | step: 25600 | performance: 0.1 | accuracy: 0.29 | loss: 1.99
update: 55/2000, 耗时:0.01分/0.55分 | step: 28160 | performance: 0.0 | accuracy: 0.29 | loss: 1.35
Saving PPO weights in both H5 format and checkpoint @ update:58 
update: 60/2000, 耗时:0.01分/0.60分 | step: 30720 | performance: 0.2 | accuracy: 0.24 | loss: 2.13
update: 65/2000, 耗时:0.01分/0.65分 | step: 33280 | performance: 0.0 | accuracy: 0.27 | loss: 1.84
update: 70/2000, 耗时:0.01分/0.70分 | step: 35840 | performance: 0.0 | accuracy: 0.27 | loss: 1.11
update: 75/2000, 耗时:0.01分/0.75分 | step: 38400 | performance: 0.0 | accuracy: 0.28 | loss: 2.84
update: 80/2000, 耗时:0.01分/0.79分 | step: 40960 | performance: 0.0 | accuracy: 0.29 | loss: 1.62
update: 85/2000, 耗时:0.01分/0.84分 | step: 43520 | performance: 0.0 | accuracy: 0.29 | loss: 1.40
update: 90/2000, 耗时:0.01分/0.88分 | step: 46080 | performance: 0.1 | accuracy: 0.30 | loss: 2.09
update: 95/2000, 耗时:0.01分/0.93分 | step: 48640 | performance: 6.7 | accuracy: 0.32 | loss: 3.81
update:100/2000, 耗时:0.01分/0.97分 | step: 51200 | performance: 3.1 | accuracy: 0.31 | loss: 2.10
update:105/2000, 耗时:0.01分/1.02分 | step: 53760 | performance: 1.2 | accuracy: 0.30 | loss: 1.47
update:110/2000, 耗时:0.01分/1.07分 | step: 56320 | performance: 0.3 | accuracy: 0.29 | loss: 1.48
update:115/2000, 耗时:0.01分/1.11分 | step: 58880 | performance: 0.4 | accuracy: 0.17 | loss: 2.21
update:120/2000, 耗时:0.01分/1.16分 | step: 61440 | performance: 0.1 | accuracy: 0.17 | loss: 0.74
update:125/2000, 耗时:0.01分/1.20分 | step: 64000 | performance: 0.0 | accuracy: 0.15 | loss: 3.60
update:130/2000, 耗时:0.01分/1.25分 | step: 66560 | performance: 0.1 | accuracy: 0.20 | loss: 2.31
update:135/2000, 耗时:0.01分/1.30分 | step: 69120 | performance: 0.2 | accuracy: 0.22 | loss: 1.17
update:140/2000, 耗时:0.01分/1.34分 | step: 71680 | performance: 0.1 | accuracy: 0.22 | loss: 3.58
update:145/2000, 耗时:0.01分/1.39分 | step: 74240 | performance: 0.1 | accuracy: 0.23 | loss: 1.33
update:150/2000, 耗时:0.01分/1.43分 | step: 76800 | performance: 32.1 | accuracy: 0.25 | loss: 3.74
update:155/2000, 耗时:0.01分/1.48分 | step: 79360 | performance: 4.6 | accuracy: 0.25 | loss: 1.81
update:160/2000, 耗时:0.01分/1.52分 | step: 81920 | performance: 4.6 | accuracy: 0.24 | loss: 1.24
update:165/2000, 耗时:0.01分/1.57分 | step: 84480 | performance: 2.2 | accuracy: 0.24 | loss: 0.85
update:170/2000, 耗时:0.01分/1.62分 | step: 87040 | performance: 2.6 | accuracy: 0.23 | loss: 0.71
update:175/2000, 耗时:0.01分/1.66分 | step: 89600 | performance: 0.2 | accuracy: 0.21 | loss: 1.30
update:180/2000, 耗时:0.01分/1.71分 | step: 92160 | performance: 0.0 | accuracy: 0.21 | loss: 0.76
update:185/2000, 耗时:0.01分/1.75分 | step: 94720 | performance: 0.0 | accuracy: 0.21 | loss: 0.63
update:190/2000, 耗时:0.01分/1.80分 | step: 97280 | performance: 0.3 | accuracy: 0.24 | loss: 1.96
update:195/2000, 耗时:0.01分/1.84分 | step: 99840 | performance: 0.3 | accuracy: 0.23 | loss: 0.67
update:200/2000, 耗时:0.01分/1.89分 | step: 102400 | performance: 0.1 | accuracy: 0.23 | loss: 0.79
update:205/2000, 耗时:0.01分/1.94分 | step: 104960 | performance: 0.6 | accuracy: 0.24 | loss: 1.69
update:210/2000, 耗时:0.01分/1.98分 | step: 107520 | performance: 7.3 | accuracy: 0.26 | loss: 2.46
update:215/2000, 耗时:0.01分/2.03分 | step: 110080 | performance: 27.2 | accuracy: 0.25 | loss: 1.52
update:220/2000, 耗时:0.01分/2.07分 | step: 112640 | performance: 13.9 | accuracy: 0.25 | loss: 1.17
update:225/2000, 耗时:0.01分/2.12分 | step: 115200 | performance: 1.3 | accuracy: 0.24 | loss: 0.85
Saving PPO weights in both H5 format and checkpoint @ update:229 
update:230/2000, 耗时:0.01分/2.17分 | step: 117760 | performance: 0.4 | accuracy: 0.13 | loss: 1.28
update:235/2000, 耗时:0.01分/2.22分 | step: 120320 | performance: 0.6 | accuracy: 0.17 | loss: 0.69
update:240/2000, 耗时:0.01分/2.26分 | step: 122880 | performance: 0.1 | accuracy: 0.16 | loss: 1.29
update:245/2000, 耗时:0.01分/2.31分 | step: 125440 | performance: 0.4 | accuracy: 0.18 | loss: 1.24
update:250/2000, 耗时:0.01分/2.35分 | step: 128000 | performance: 0.2 | accuracy: 0.18 | loss: 0.78
update:255/2000, 耗时:0.01分/2.40分 | step: 130560 | performance: 0.0 | accuracy: 0.18 | loss: 0.99
update:260/2000, 耗时:0.01分/2.45分 | step: 133120 | performance: 0.0 | accuracy: 0.19 | loss: 0.87
update:265/2000, 耗时:0.01分/2.49分 | step: 135680 | performance: 5.1 | accuracy: 0.22 | loss: 1.84
update:270/2000, 耗时:0.01分/2.54分 | step: 138240 | performance: 3.5 | accuracy: 0.22 | loss: 1.14
update:275/2000, 耗时:0.01分/2.58分 | step: 140800 | performance: 2.9 | accuracy: 0.22 | loss: 0.98
update:280/2000, 耗时:0.01分/2.63分 | step: 143360 | performance: 0.8 | accuracy: 0.22 | loss: 1.35
update:285/2000, 耗时:0.01分/2.68分 | step: 145920 | performance: 0.6 | accuracy: 0.22 | loss: 0.61
Saving PPO weights in both H5 format and checkpoint @ update:286 
update:290/2000, 耗时:0.01分/2.73分 | step: 148480 | performance: 0.5 | accuracy: 0.19 | loss: 0.59
update:295/2000, 耗时:0.01分/2.77分 | step: 151040 | performance: 0.5 | accuracy: 0.18 | loss: 0.63
update:300/2000, 耗时:0.01分/2.82分 | step: 153600 | performance: 0.2 | accuracy: 0.20 | loss: 0.61
update:305/2000, 耗时:0.01分/2.86分 | step: 156160 | performance: 0.8 | accuracy: 0.20 | loss: 0.76
update:310/2000, 耗时:0.01分/2.91分 | step: 158720 | performance: 0.6 | accuracy: 0.20 | loss: 0.72
update:315/2000, 耗时:0.01分/2.95分 | step: 161280 | performance: 0.5 | accuracy: 0.20 | loss: 0.53
update:320/2000, 耗时:0.01分/3.00分 | step: 163840 | performance: 11.2 | accuracy: 0.22 | loss: 2.07
update:325/2000, 耗时:0.01分/3.04分 | step: 166400 | performance: 4.1 | accuracy: 0.23 | loss: 1.49
update:330/2000, 耗时:0.01分/3.09分 | step: 168960 | performance: 6.4 | accuracy: 0.23 | loss: 1.28
update:335/2000, 耗时:0.01分/3.14分 | step: 171520 | performance: 1.0 | accuracy: 0.23 | loss: 1.04
update:340/2000, 耗时:0.01分/3.18分 | step: 174080 | performance: 0.2 | accuracy: 0.22 | loss: 0.59
update:345/2000, 耗时:0.01分/3.23分 | step: 176640 | performance: 1.5 | accuracy: 0.18 | loss: 0.71
update:350/2000, 耗时:0.01分/3.27分 | step: 179200 | performance: 0.7 | accuracy: 0.14 | loss: 0.47
update:355/2000, 耗时:0.01分/3.32分 | step: 181760 | performance: 0.5 | accuracy: 0.13 | loss: 0.52
update:360/2000, 耗时:0.01分/3.36分 | step: 184320 | performance: 0.8 | accuracy: 0.15 | loss: 0.96
update:365/2000, 耗时:0.01分/3.41分 | step: 186880 | performance: 1.2 | accuracy: 0.15 | loss: 0.43
update:370/2000, 耗时:0.01分/3.45分 | step: 189440 | performance: 2.3 | accuracy: 0.15 | loss: 0.35
update:375/2000, 耗时:0.01分/3.50分 | step: 192000 | performance: 2.6 | accuracy: 0.14 | loss: 0.39
update:380/2000, 耗时:0.01分/3.55分 | step: 194560 | performance: 10.9 | accuracy: 0.14 | loss: 0.64
update:385/2000, 耗时:0.01分/3.59分 | step: 197120 | performance: 10.8 | accuracy: 0.14 | loss: 0.40
update:390/2000, 耗时:0.01分/3.64分 | step: 199680 | performance: 12.6 | accuracy: 0.13 | loss: 0.37
update:395/2000, 耗时:0.01分/3.69分 | step: 202240 | performance: 5.6 | accuracy: 0.13 | loss: 0.26
update:400/2000, 耗时:0.01分/3.73分 | step: 204800 | performance: 4.5 | accuracy: 0.12 | loss: 0.20
step: 205312 | worker_7@n_step_63: average total_reward after train data exhaustion : 52.0 | max total_reward: 203.9
step: 206844 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 206847 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:405/2000, 耗时:0.01分/3.78分 | step: 207360 | performance: 1.1 | accuracy: 0.11 | loss: 0.16
step: 208377 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:410/2000, 耗时:0.01分/3.83分 | step: 209920 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
update:415/2000, 耗时:0.01分/3.88分 | step: 212480 | performance: 1.0 | accuracy: 0.00 | loss: 0.36
step: 212986 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 203.9
step: 212987 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 203.9
update:420/2000, 耗时:0.01分/3.92分 | step: 215040 | performance: 1.1 | accuracy: 0.07 | loss: 0.36
step: 216569 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 217083 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:425/2000, 耗时:0.01分/3.97分 | step: 217600 | performance: 1.2 | accuracy: 0.07 | loss: 0.37
step: 220155 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:430/2000, 耗时:0.01分/4.02分 | step: 220160 | performance: 1.1 | accuracy: 0.11 | loss: 0.35
update:435/2000, 耗时:0.01分/4.06分 | step: 222720 | performance: 1.3 | accuracy: 0.20 | loss: 0.37
step: 224255 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 224256 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:440/2000, 耗时:0.01分/4.11分 | step: 225280 | performance: 1.0 | accuracy: 0.07 | loss: 0.36
step: 226811 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 227833 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:445/2000, 耗时:0.01分/4.16分 | step: 227840 | performance: 1.1 | accuracy: 0.33 | loss: 0.38
step: 228351 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 230394 | worker_1@n_step_63: average total_reward after train data exhaustion : -0.7 | max total_reward: 203.9
step: 230396 | worker_3@n_step_63: average total_reward after train data exhaustion : -0.6 | max total_reward: 203.9
update:450/2000, 耗时:0.01分/4.21分 | step: 230400 | performance: 0.9 | accuracy: 0.00 | loss: 0.42
step: 232445 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 232448 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:455/2000, 耗时:0.01分/4.25分 | step: 232960 | performance: 1.1 | accuracy: 0.20 | loss: 0.26
step: 235004 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
update:460/2000, 耗时:0.01分/4.30分 | step: 235520 | performance: 1.2 | accuracy: 0.25 | loss: 0.33
step: 236031 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
update:465/2000, 耗时:0.01分/4.35分 | step: 238080 | performance: 1.2 | accuracy: 0.14 | loss: 0.36
step: 238585 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
step: 240127 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 240635 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
update:470/2000, 耗时:0.01分/4.39分 | step: 240640 | performance: 2.2 | accuracy: 0.13 | loss: 0.46
step: 241657 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 241659 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:475/2000, 耗时:0.01分/4.44分 | step: 243200 | performance: 1.4 | accuracy: 0.25 | loss: 0.34
update:480/2000, 耗时:0.01分/4.49分 | step: 245760 | performance: 2.1 | accuracy: 0.13 | loss: 0.44
update:485/2000, 耗时:0.01分/4.53分 | step: 248320 | performance: 1.0 | accuracy: 0.00 | loss: 0.37
step: 248829 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 249339 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 249850 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 203.9
update:490/2000, 耗时:0.01分/4.58分 | step: 250880 | performance: 1.0 | accuracy: 0.00 | loss: 0.34
step: 251392 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
update:495/2000, 耗时:0.01分/4.64分 | step: 253440 | performance: 1.2 | accuracy: 0.25 | loss: 0.46
step: 255482 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 203.9
step: 255488 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 203.9
update:500/2000, 耗时:0.01分/4.68分 | step: 256000 | performance: 1.0 | accuracy: 0.00 | loss: 0.29
step: 258553 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 258558 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:505/2000, 耗时:0.01分/4.73分 | step: 258560 | performance: 1.2 | accuracy: 0.09 | loss: 0.18
step: 260604 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 260606 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 261115 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:510/2000, 耗时:0.01分/4.78分 | step: 261120 | performance: 1.4 | accuracy: 0.12 | loss: 0.23
step: 262649 | worker_0@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
step: 263168 | worker_7@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
step: 263674 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:515/2000, 耗时:0.01分/4.83分 | step: 263680 | performance: 1.3 | accuracy: 0.13 | loss: 0.30
step: 265214 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 265722 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:520/2000, 耗时:0.01分/4.88分 | step: 266240 | performance: 1.1 | accuracy: 0.07 | loss: 0.31
step: 267259 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 267264 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 267769 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
update:525/2000, 耗时:0.01分/4.93分 | step: 268800 | performance: 1.1 | accuracy: 0.06 | loss: 0.38
step: 269820 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 269822 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 271353 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 203.9
update:530/2000, 耗时:0.01分/4.98分 | step: 271360 | performance: 1.0 | accuracy: 0.00 | loss: 0.48
step: 271866 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
step: 272889 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
step: 273914 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:535/2000, 耗时:0.01分/5.02分 | step: 273920 | performance: 1.2 | accuracy: 1.00 | loss: 0.35
step: 276474 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:540/2000, 耗时:0.01分/5.07分 | step: 276480 | performance: 1.3 | accuracy: 0.15 | loss: 0.30
step: 278522 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:545/2000, 耗时:0.01分/5.12分 | step: 279040 | performance: 1.5 | accuracy: 0.14 | loss: 0.35
step: 279552 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 203.9
step: 280058 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:550/2000, 耗时:0.01分/5.16分 | step: 281600 | performance: 1.0 | accuracy: 0.10 | loss: 0.32
step: 283131 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:555/2000, 耗时:0.01分/5.21分 | step: 284160 | performance: 1.1 | accuracy: 0.10 | loss: 0.44
step: 285183 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 285692 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 286201 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:560/2000, 耗时:0.01分/5.26分 | step: 286720 | performance: 1.0 | accuracy: 0.00 | loss: 0.34
step: 287228 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 287232 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
update:565/2000, 耗时:0.01分/5.30分 | step: 289280 | performance: 0.6 | accuracy: 0.11 | loss: 0.64
step: 290300 | worker_3@n_step_63: average total_reward after train data exhaustion : -0.3 | max total_reward: 203.9
step: 291837 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
update:570/2000, 耗时:0.01分/5.35分 | step: 291840 | performance: 1.0 | accuracy: 0.00 | loss: 0.35
step: 292348 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 203.9
step: 293883 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:575/2000, 耗时:0.01分/5.39分 | step: 294400 | performance: 1.2 | accuracy: 0.50 | loss: 0.44
update:580/2000, 耗时:0.01分/5.44分 | step: 296960 | performance: 1.0 | accuracy: 0.07 | loss: 0.43
update:585/2000, 耗时:0.01分/5.48分 | step: 299520 | performance: 1.4 | accuracy: 0.15 | loss: 0.50
step: 302073 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:590/2000, 耗时:0.01分/5.53分 | step: 302080 | performance: 1.5 | accuracy: 0.12 | loss: 0.30
step: 302589 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
step: 304634 | worker_1@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 203.9
update:595/2000, 耗时:0.01分/5.58分 | step: 304640 | performance: 1.6 | accuracy: 0.10 | loss: 0.48
step: 305660 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
step: 306688 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:600/2000, 耗时:0.01分/5.62分 | step: 307200 | performance: 1.0 | accuracy: 0.00 | loss: 0.39
update:605/2000, 耗时:0.01分/5.67分 | step: 309760 | performance: 1.2 | accuracy: 0.13 | loss: 0.64
step: 311802 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:610/2000, 耗时:0.01分/5.71分 | step: 312320 | performance: 1.0 | accuracy: 0.00 | loss: 0.27
step: 312827 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
step: 312828 | worker_3@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
step: 314875 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 203.9
update:615/2000, 耗时:0.01分/5.76分 | step: 314880 | performance: 0.9 | accuracy: 0.00 | loss: 0.27
step: 316414 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 203.9
update:620/2000, 耗时:0.01分/5.81分 | step: 317440 | performance: 1.3 | accuracy: 0.14 | loss: 0.21
step: 319482 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 319485 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 319487 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 319996 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:625/2000, 耗时:0.01分/5.85分 | step: 320000 | performance: 1.2 | accuracy: 0.14 | loss: 0.16
step: 320510 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
update:630/2000, 耗时:0.01分/5.90分 | step: 322560 | performance: 1.0 | accuracy: 0.00 | loss: 0.42
step: 325115 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
update:635/2000, 耗时:0.01分/5.94分 | step: 325120 | performance: 1.0 | accuracy: 0.00 | loss: 0.44
step: 326138 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:640/2000, 耗时:0.01分/5.99分 | step: 327680 | performance: 1.2 | accuracy: 0.15 | loss: 0.33
update:645/2000, 耗时:0.01分/6.04分 | step: 330240 | performance: 1.5 | accuracy: 0.23 | loss: 0.73
update:650/2000, 耗时:0.01分/6.08分 | step: 332800 | performance: 1.2 | accuracy: 0.08 | loss: 0.41
step: 333824 | worker_7@n_step_63: average total_reward after train data exhaustion : -0.4 | max total_reward: 203.9
update:655/2000, 耗时:0.01分/6.13分 | step: 335360 | performance: 1.0 | accuracy: 0.00 | loss: 0.37
update:660/2000, 耗时:0.01分/6.17分 | step: 337920 | performance: 0.2 | accuracy: 0.12 | loss: 0.68
update:665/2000, 耗时:0.01分/6.22分 | step: 340480 | performance: 1.7 | accuracy: 0.17 | loss: 0.32
update:670/2000, 耗时:0.01分/6.26分 | step: 343040 | performance: 0.9 | accuracy: 0.12 | loss: 0.43
update:675/2000, 耗时:0.01分/6.31分 | step: 345600 | performance: 0.1 | accuracy: 0.10 | loss: 0.68
update:680/2000, 耗时:0.01分/6.35分 | step: 348160 | performance: 0.4 | accuracy: 0.12 | loss: 0.80
update:685/2000, 耗时:0.01分/6.40分 | step: 350720 | performance: 2.9 | accuracy: 0.13 | loss: 0.56
update:690/2000, 耗时:0.01分/6.45分 | step: 353280 | performance: 3.9 | accuracy: 0.14 | loss: 0.56
update:695/2000, 耗时:0.01分/6.49分 | step: 355840 | performance: 5.4 | accuracy: 0.14 | loss: 0.51
step: 358393 | worker_0@n_step_63: average total_reward after train data exhaustion : 6.1 | max total_reward: 203.9
update:700/2000, 耗时:0.01分/6.54分 | step: 358400 | performance: 24.3 | accuracy: 0.14 | loss: 0.55
update:705/2000, 耗时:0.01分/6.58分 | step: 360960 | performance: 11.2 | accuracy: 0.14 | loss: 0.34
step: 363001 | worker_0@n_step_63: average total_reward after train data exhaustion : 5.8 | max total_reward: 203.9
step: 363519 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 203.9
update:710/2000, 耗时:0.01分/6.63分 | step: 363520 | performance: 18.3 | accuracy: 0.13 | loss: 0.31
step: 364030 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 365051 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 365567 | worker_6@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 203.9
step: 366078 | worker_5@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
update:715/2000, 耗时:0.01分/6.68分 | step: 366080 | performance: 12.3 | accuracy: 0.13 | loss: 0.25
step: 366587 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.3 | max total_reward: 203.9
step: 367614 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
step: 368127 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.5 | max total_reward: 203.9
update:720/2000, 耗时:0.01分/6.72分 | step: 368640 | performance: 9.4 | accuracy: 0.12 | loss: 0.25
step: 369659 | worker_2@n_step_63: average total_reward after train data exhaustion : 3.0 | max total_reward: 203.9
update:725/2000, 耗时:0.01分/6.77分 | step: 371200 | performance: 0.8 | accuracy: 0.11 | loss: 0.44
update:730/2000, 耗时:0.01分/6.82分 | step: 373760 | performance: 1.0 | accuracy: 0.00 | loss: 0.31
step: 375290 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 376315 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
update:735/2000, 耗时:0.01分/6.87分 | step: 376320 | performance: 1.1 | accuracy: 0.50 | loss: 0.31
update:740/2000, 耗时:0.01分/6.92分 | step: 378880 | performance: 1.3 | accuracy: 0.13 | loss: 0.65
update:745/2000, 耗时:0.01分/6.96分 | step: 381440 | performance: 0.7 | accuracy: 0.12 | loss: 0.29
update:750/2000, 耗时:0.01分/7.01分 | step: 384000 | performance: 1.0 | accuracy: 0.00 | loss: 0.41
step: 385019 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
update:755/2000, 耗时:0.01分/7.05分 | step: 386560 | performance: 1.2 | accuracy: 0.22 | loss: 0.41
step: 389119 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:760/2000, 耗时:0.01分/7.10分 | step: 389120 | performance: 1.1 | accuracy: 0.07 | loss: 0.30
update:765/2000, 耗时:0.01分/7.15分 | step: 391680 | performance: 2.1 | accuracy: 0.11 | loss: 0.41
step: 393212 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 393215 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:770/2000, 耗时:0.01分/7.19分 | step: 394240 | performance: 1.7 | accuracy: 0.10 | loss: 0.37
step: 395773 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 395776 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
update:775/2000, 耗时:0.01分/7.24分 | step: 396800 | performance: 1.1 | accuracy: 0.07 | loss: 0.44
update:780/2000, 耗时:0.01分/7.29分 | step: 399360 | performance: 0.9 | accuracy: 0.12 | loss: 0.60
step: 400383 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 401914 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:785/2000, 耗时:0.01分/7.33分 | step: 401920 | performance: 1.6 | accuracy: 0.12 | loss: 0.42
step: 403962 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 203.9
update:790/2000, 耗时:0.01分/7.38分 | step: 404480 | performance: 1.1 | accuracy: 0.10 | loss: 0.31
step: 405498 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 406522 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
step: 406523 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 407038 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
update:795/2000, 耗时:0.01分/7.43分 | step: 407040 | performance: 1.7 | accuracy: 0.36 | loss: 0.47
step: 408064 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:800/2000, 耗时:0.01分/7.47分 | step: 409600 | performance: 1.0 | accuracy: 0.00 | loss: 0.40
step: 411646 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:805/2000, 耗时:0.01分/7.52分 | step: 412160 | performance: 1.2 | accuracy: 0.14 | loss: 0.30
step: 412668 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 413177 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
step: 413692 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:810/2000, 耗时:0.01分/7.56分 | step: 414720 | performance: 0.9 | accuracy: 0.12 | loss: 0.40
step: 416250 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:815/2000, 耗时:0.01分/7.61分 | step: 417280 | performance: 0.6 | accuracy: 0.11 | loss: 0.24
update:820/2000, 耗时:0.01分/7.66分 | step: 419840 | performance: 1.5 | accuracy: 0.33 | loss: 0.47
step: 422395 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:825/2000, 耗时:0.01分/7.70分 | step: 422400 | performance: 1.5 | accuracy: 0.27 | loss: 0.39
update:830/2000, 耗时:0.01分/7.75分 | step: 424960 | performance: 1.1 | accuracy: 0.20 | loss: 0.44
step: 425466 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
update:835/2000, 耗时:0.01分/7.79分 | step: 427520 | performance: 1.4 | accuracy: 0.25 | loss: 0.38
step: 429051 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.2 | max total_reward: 203.9
update:840/2000, 耗时:0.01分/7.84分 | step: 430080 | performance: 1.8 | accuracy: 0.11 | loss: 0.31
update:845/2000, 耗时:0.01分/7.88分 | step: 432640 | performance: 1.1 | accuracy: 0.07 | loss: 0.33
update:850/2000, 耗时:0.01分/7.93分 | step: 435200 | performance: 1.4 | accuracy: 0.17 | loss: 0.42
update:855/2000, 耗时:0.01分/7.98分 | step: 437760 | performance: 1.3 | accuracy: 0.40 | loss: 0.30
step: 438779 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 439295 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:860/2000, 耗时:0.01分/8.02分 | step: 440320 | performance: 1.0 | accuracy: 0.00 | loss: 0.30
step: 441850 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 203.9
update:865/2000, 耗时:0.01分/8.07分 | step: 442880 | performance: 1.8 | accuracy: 0.12 | loss: 0.63
step: 445433 | worker_0@n_step_63: average total_reward after train data exhaustion : -0.3 | max total_reward: 203.9
update:870/2000, 耗时:0.01分/8.11分 | step: 445440 | performance: 2.5 | accuracy: 0.14 | loss: 0.40
step: 446460 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 203.9
update:875/2000, 耗时:0.01分/8.16分 | step: 448000 | performance: 2.7 | accuracy: 0.10 | loss: 0.33
step: 448508 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:880/2000, 耗时:0.01分/8.21分 | step: 450560 | performance: 1.2 | accuracy: 0.10 | loss: 0.53
update:885/2000, 耗时:0.01分/8.25分 | step: 453120 | performance: 1.4 | accuracy: 0.15 | loss: 0.50
update:890/2000, 耗时:0.01分/8.30分 | step: 455680 | performance: 1.4 | accuracy: 0.15 | loss: 0.30
update:895/2000, 耗时:0.01分/8.34分 | step: 458240 | performance: 0.8 | accuracy: 0.15 | loss: 0.46
update:900/2000, 耗时:0.01分/8.39分 | step: 460800 | performance: 2.7 | accuracy: 0.15 | loss: 0.37
update:905/2000, 耗时:0.01分/8.43分 | step: 463360 | performance: 2.3 | accuracy: 0.14 | loss: 0.42
update:910/2000, 耗时:0.01分/8.48分 | step: 465920 | performance: 2.2 | accuracy: 0.13 | loss: 0.31
update:915/2000, 耗时:0.01分/8.52分 | step: 468480 | performance: 5.9 | accuracy: 0.15 | loss: 0.73
update:920/2000, 耗时:0.01分/8.57分 | step: 471040 | performance: 8.5 | accuracy: 0.15 | loss: 1.10
update:925/2000, 耗时:0.01分/8.62分 | step: 473600 | performance: 76.1 | accuracy: 0.17 | loss: 1.02
update:930/2000, 耗时:0.01分/8.66分 | step: 476160 | performance: 43.4 | accuracy: 0.17 | loss: 0.51
update:935/2000, 耗时:0.01分/8.71分 | step: 478720 | performance: 19.5 | accuracy: 0.16 | loss: 0.42
update:940/2000, 耗时:0.01分/8.75分 | step: 481280 | performance: 1.2 | accuracy: 1.00 | loss: 0.38
step: 481792 | worker_7@n_step_63: average total_reward after train data exhaustion : 3.2 | max total_reward: 203.9
step: 482810 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 482815 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 483838 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:945/2000, 耗时:0.01分/8.80分 | step: 483840 | performance: 1.1 | accuracy: 0.07 | loss: 0.33
step: 485369 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:950/2000, 耗时:0.01分/8.84分 | step: 486400 | performance: 0.6 | accuracy: 0.15 | loss: 0.54
step: 486910 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 203.9
update:955/2000, 耗时:0.01分/8.89分 | step: 488960 | performance: 1.1 | accuracy: 0.12 | loss: 0.35
step: 489470 | worker_5@n_step_63: average total_reward after train data exhaustion : -0.5 | max total_reward: 203.9
step: 491003 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.4 | max total_reward: 203.9
update:960/2000, 耗时:0.01分/8.94分 | step: 491520 | performance: 1.0 | accuracy: 0.00 | loss: 0.26
step: 492032 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
step: 493568 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:965/2000, 耗时:0.01分/8.98分 | step: 494080 | performance: 0.8 | accuracy: 0.11 | loss: 0.46
update:970/2000, 耗时:0.01分/9.03分 | step: 496640 | performance: 1.0 | accuracy: 0.00 | loss: 0.25
update:975/2000, 耗时:0.01分/9.07分 | step: 499200 | performance: 1.1 | accuracy: 0.08 | loss: 0.45
step: 500222 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 203.9
update:980/2000, 耗时:0.01分/9.12分 | step: 501760 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
step: 502271 | worker_6@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 203.9
update:985/2000, 耗时:0.01分/9.16分 | step: 504320 | performance: 1.1 | accuracy: 0.12 | loss: 0.42
step: 504832 | worker_7@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
update:990/2000, 耗时:0.01分/9.21分 | step: 506880 | performance: 0.8 | accuracy: 0.12 | loss: 0.28
step: 508411 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 508412 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
update:995/2000, 耗时:0.01分/9.26分 | step: 509440 | performance: 1.0 | accuracy: 0.00 | loss: 0.32
step: 509949 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 203.9
step: 511484 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:1000/2000, 耗时:0.01分/9.30分 | step: 512000 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
step: 513022 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:1005/2000, 耗时:0.01分/9.35分 | step: 514560 | performance: 1.1 | accuracy: 0.12 | loss: 0.15
step: 515070 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 515072 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 517116 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:1010/2000, 耗时:0.01分/9.39分 | step: 517120 | performance: 1.0 | accuracy: 0.00 | loss: 0.28
step: 517626 | worker_1@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
step: 517627 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.2 | max total_reward: 203.9
step: 519166 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:1015/2000, 耗时:0.01分/9.44分 | step: 519680 | performance: 1.6 | accuracy: 0.21 | loss: 0.44
step: 521213 | worker_4@n_step_63: average total_reward after train data exhaustion : -0.4 | max total_reward: 203.9
update:1020/2000, 耗时:0.01分/9.49分 | step: 522240 | performance: 1.3 | accuracy: 0.25 | loss: 0.47
step: 524286 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:1025/2000, 耗时:0.01分/9.53分 | step: 524800 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
update:1030/2000, 耗时:0.01分/9.58分 | step: 527360 | performance: 1.0 | accuracy: 0.00 | loss: 0.57
step: 528384 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:1035/2000, 耗时:0.01分/9.63分 | step: 529920 | performance: 1.0 | accuracy: 0.00 | loss: 0.33
step: 531965 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
update:1040/2000, 耗时:0.01分/9.67分 | step: 532480 | performance: 0.9 | accuracy: 0.15 | loss: 0.57
update:1045/2000, 耗时:0.01分/9.72分 | step: 535040 | performance: 0.7 | accuracy: 0.12 | loss: 0.52
step: 535550 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
step: 536060 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:1050/2000, 耗时:0.01分/9.77分 | step: 537600 | performance: 0.3 | accuracy: 0.11 | loss: 0.21
update:1055/2000, 耗时:0.01分/9.82分 | step: 540160 | performance: 0.4 | accuracy: 0.10 | loss: 0.28
step: 540668 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:1060/2000, 耗时:0.01分/9.86分 | step: 542720 | performance: 1.3 | accuracy: 0.12 | loss: 0.37
step: 543741 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 203.9
step: 543744 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 544255 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 545275 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:1065/2000, 耗时:0.01分/9.91分 | step: 545280 | performance: 1.2 | accuracy: 0.33 | loss: 0.55
step: 546298 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:1070/2000, 耗时:0.01分/9.95分 | step: 547840 | performance: 0.9 | accuracy: 0.13 | loss: 0.62
update:1075/2000, 耗时:0.01分/10.00分 | step: 550400 | performance: 1.0 | accuracy: 0.00 | loss: 0.31
step: 551930 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 552443 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 203.9
update:1080/2000, 耗时:0.01分/10.05分 | step: 552960 | performance: 1.3 | accuracy: 0.23 | loss: 0.29
step: 553466 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 553467 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 553981 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 553982 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
update:1085/2000, 耗时:0.01分/10.10分 | step: 555520 | performance: 1.1 | accuracy: 0.10 | loss: 0.43
step: 557050 | worker_1@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
update:1090/2000, 耗时:0.01分/10.14分 | step: 558080 | performance: 1.0 | accuracy: 0.00 | loss: 0.28
step: 559103 | worker_6@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 203.9
step: 559612 | worker_3@n_step_63: average total_reward after train data exhaustion : -0.4 | max total_reward: 203.9
step: 560125 | worker_4@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 203.9
step: 560636 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:1095/2000, 耗时:0.01分/10.19分 | step: 560640 | performance: 1.2 | accuracy: 0.11 | loss: 0.28
step: 562171 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.6 | max total_reward: 203.9
step: 563195 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.5 | max total_reward: 203.9
update:1100/2000, 耗时:0.01分/10.23分 | step: 563200 | performance: 1.3 | accuracy: 0.13 | loss: 0.49
update:1105/2000, 耗时:0.01分/10.28分 | step: 565760 | performance: 0.6 | accuracy: 0.11 | loss: 0.33
update:1110/2000, 耗时:0.01分/10.33分 | step: 568320 | performance: 0.7 | accuracy: 0.12 | loss: 0.36
step: 570361 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
update:1115/2000, 耗时:0.01分/10.37分 | step: 570880 | performance: 1.0 | accuracy: 0.00 | loss: 0.34
step: 571903 | worker_6@n_step_63: average total_reward after train data exhaustion : -0.5 | max total_reward: 203.9
update:1120/2000, 耗时:0.01分/10.42分 | step: 573440 | performance: 1.7 | accuracy: 0.28 | loss: 0.29
update:1125/2000, 耗时:0.01分/10.47分 | step: 576000 | performance: 1.4 | accuracy: 0.10 | loss: 0.41
step: 578555 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.8 | max total_reward: 203.9
update:1130/2000, 耗时:0.01分/10.51分 | step: 578560 | performance: 1.0 | accuracy: 0.00 | loss: 0.48
step: 581118 | worker_5@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
update:1135/2000, 耗时:0.01分/10.56分 | step: 581120 | performance: 1.1 | accuracy: 0.08 | loss: 0.34
update:1140/2000, 耗时:0.01分/10.61分 | step: 583680 | performance: 1.0 | accuracy: 0.00 | loss: 0.32
step: 584701 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:1145/2000, 耗时:0.01分/10.66分 | step: 586240 | performance: 1.1 | accuracy: 0.20 | loss: 0.21
update:1150/2000, 耗时:0.01分/10.71分 | step: 588800 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
step: 590335 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:1155/2000, 耗时:0.01分/10.75分 | step: 591360 | performance: 1.5 | accuracy: 0.18 | loss: 0.26
step: 591870 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 593913 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:1160/2000, 耗时:0.01分/10.80分 | step: 593920 | performance: 1.3 | accuracy: 0.21 | loss: 0.50
step: 594938 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 595966 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
step: 595968 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:1165/2000, 耗时:0.01分/10.85分 | step: 596480 | performance: 1.1 | accuracy: 0.20 | loss: 0.46
update:1170/2000, 耗时:0.01分/10.90分 | step: 599040 | performance: 1.3 | accuracy: 0.14 | loss: 0.46
step: 600059 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 600063 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:1175/2000, 耗时:0.01分/10.95分 | step: 601600 | performance: 0.9 | accuracy: 0.00 | loss: 0.47
step: 603644 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:1180/2000, 耗时:0.01分/11.00分 | step: 604160 | performance: 2.5 | accuracy: 0.15 | loss: 0.37
step: 605689 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:1185/2000, 耗时:0.01分/11.05分 | step: 606720 | performance: 2.3 | accuracy: 0.10 | loss: 0.34
step: 607737 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 608256 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 608764 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:1190/2000, 耗时:0.01分/11.10分 | step: 609280 | performance: 1.3 | accuracy: 0.17 | loss: 0.23
step: 610816 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
step: 611837 | worker_4@n_step_63: average total_reward after train data exhaustion : -0.2 | max total_reward: 203.9
update:1195/2000, 耗时:0.01分/11.15分 | step: 611840 | performance: 1.3 | accuracy: 0.40 | loss: 0.53
step: 613888 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:1200/2000, 耗时:0.01分/11.19分 | step: 614400 | performance: 1.2 | accuracy: 0.22 | loss: 0.41
update:1205/2000, 耗时:0.01分/11.24分 | step: 616960 | performance: 1.4 | accuracy: 0.10 | loss: 0.42
update:1210/2000, 耗时:0.01分/11.28分 | step: 619520 | performance: 1.3 | accuracy: 0.17 | loss: 0.32
update:1215/2000, 耗时:0.01分/11.33分 | step: 622080 | performance: 3.1 | accuracy: 0.11 | loss: 0.27
update:1220/2000, 耗时:0.01分/11.38分 | step: 624640 | performance: 1.3 | accuracy: 0.12 | loss: 0.34
step: 625659 | worker_2@n_step_63: average total_reward after train data exhaustion : 3.5 | max total_reward: 203.9
step: 627199 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
step: 627200 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
update:1225/2000, 耗时:0.01分/11.42分 | step: 627200 | performance: 1.0 | accuracy: 0.00 | loss: 0.34
step: 627710 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 628219 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 628729 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 629242 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
step: 629755 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
update:1230/2000, 耗时:0.01分/11.47分 | step: 629760 | performance: 1.7 | accuracy: 0.40 | loss: 0.45
update:1235/2000, 耗时:0.01分/11.52分 | step: 632320 | performance: 1.1 | accuracy: 0.13 | loss: 0.23
step: 632827 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 203.9
step: 634361 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
update:1240/2000, 耗时:0.01分/11.56分 | step: 634880 | performance: 1.4 | accuracy: 0.23 | loss: 0.35
update:1245/2000, 耗时:0.01分/11.61分 | step: 637440 | performance: 1.0 | accuracy: 0.00 | loss: 0.34
update:1250/2000, 耗时:0.01分/11.66分 | step: 640000 | performance: 1.0 | accuracy: 0.00 | loss: 0.46
step: 640507 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
step: 642043 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 203.9
step: 642047 | worker_6@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 203.9
update:1255/2000, 耗时:0.01分/11.70分 | step: 642560 | performance: 1.0 | accuracy: 0.00 | loss: 0.47
step: 644092 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
update:1260/2000, 耗时:0.01分/11.75分 | step: 645120 | performance: 1.2 | accuracy: 0.11 | loss: 0.40
step: 645632 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 646651 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:1265/2000, 耗时:0.01分/11.79分 | step: 647680 | performance: 1.1 | accuracy: 0.14 | loss: 0.44
step: 648698 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 649212 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 649728 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:1270/2000, 耗时:0.01分/11.84分 | step: 650240 | performance: 1.1 | accuracy: 0.06 | loss: 0.21
step: 651264 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
step: 652285 | worker_4@n_step_63: average total_reward after train data exhaustion : -0.2 | max total_reward: 203.9
update:1275/2000, 耗时:0.01分/11.89分 | step: 652800 | performance: 1.0 | accuracy: 0.11 | loss: 0.55
step: 654329 | worker_0@n_step_63: average total_reward after train data exhaustion : -0.5 | max total_reward: 203.9
step: 654336 | worker_7@n_step_63: average total_reward after train data exhaustion : -0.4 | max total_reward: 203.9
update:1280/2000, 耗时:0.01分/11.93分 | step: 655360 | performance: 1.4 | accuracy: 0.17 | loss: 0.53
step: 657406 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 203.9
update:1285/2000, 耗时:0.01分/11.98分 | step: 657920 | performance: 1.2 | accuracy: 0.10 | loss: 0.25
step: 658429 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 658937 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 658942 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
update:1290/2000, 耗时:0.01分/12.02分 | step: 660480 | performance: 1.1 | accuracy: 0.12 | loss: 0.46
step: 660989 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 661503 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 662522 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
update:1295/2000, 耗时:0.01分/12.07分 | step: 663040 | performance: 1.2 | accuracy: 1.00 | loss: 0.50
step: 664574 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 665082 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 665088 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
update:1300/2000, 耗时:0.01分/12.12分 | step: 665600 | performance: 1.0 | accuracy: 0.00 | loss: 0.49
update:1305/2000, 耗时:0.01分/12.16分 | step: 668160 | performance: 0.5 | accuracy: 0.12 | loss: 0.32
step: 670718 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:1310/2000, 耗时:0.01分/12.21分 | step: 670720 | performance: 0.4 | accuracy: 0.10 | loss: 0.50
step: 671226 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 203.9
step: 672764 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 203.9
step: 673279 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 203.9
update:1315/2000, 耗时:0.01分/12.26分 | step: 673280 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
step: 674301 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 675838 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:1320/2000, 耗时:0.01分/12.30分 | step: 675840 | performance: 1.3 | accuracy: 0.15 | loss: 0.39
step: 677371 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 677882 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 203.9
update:1325/2000, 耗时:0.01分/12.35分 | step: 678400 | performance: 1.2 | accuracy: 0.17 | loss: 0.42
step: 679936 | worker_7@n_step_63: average total_reward after train data exhaustion : -0.3 | max total_reward: 203.9
step: 680441 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 203.9
update:1330/2000, 耗时:0.01分/12.39分 | step: 680960 | performance: 0.7 | accuracy: 0.11 | loss: 0.45
step: 683001 | worker_0@n_step_63: average total_reward after train data exhaustion : -0.9 | max total_reward: 203.9
update:1335/2000, 耗时:0.01分/12.44分 | step: 683520 | performance: 2.4 | accuracy: 0.12 | loss: 0.33
step: 684542 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 685053 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 203.9
step: 685055 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 203.9
step: 685568 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 203.9
update:1340/2000, 耗时:0.01分/12.49分 | step: 686080 | performance: 1.1 | accuracy: 0.06 | loss: 0.37
step: 686585 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 203.9
step: 688635 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
update:1345/2000, 耗时:0.01分/12.53分 | step: 688640 | performance: 0.7 | accuracy: 0.11 | loss: 0.37
update:1350/2000, 耗时:0.01分/12.58分 | step: 691200 | performance: 1.1 | accuracy: 0.10 | loss: 0.28
step: 693246 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 203.9
update:1355/2000, 耗时:0.01分/12.62分 | step: 693760 | performance: 1.0 | accuracy: 0.00 | loss: 0.42
step: 694266 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 203.9
step: 694268 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 203.9
step: 695290 | worker_1@n_step_63: average total_reward after train data exhaustion : -0.8 | max total_reward: 203.9
step: 695806 | worker_5@n_step_63: average total_reward after train data exhaustion : -1.0 | max total_reward: 203.9
update:1360/2000, 耗时:0.01分/12.67分 | step: 696320 | performance: 1.8 | accuracy: 0.13 | loss: 0.34
update:1365/2000, 耗时:0.01分/12.72分 | step: 698880 | performance: 0.7 | accuracy: 0.11 | loss: 0.38
update:1370/2000, 耗时:0.01分/12.76分 | step: 701440 | performance: 0.4 | accuracy: 0.12 | loss: 0.39
update:1375/2000, 耗时:0.01分/12.81分 | step: 704000 | performance: 0.8 | accuracy: 0.14 | loss: 0.45
update:1380/2000, 耗时:0.01分/12.85分 | step: 706560 | performance: 1.1 | accuracy: 0.14 | loss: 0.91
update:1385/2000, 耗时:0.01分/12.90分 | step: 709120 | performance: 0.5 | accuracy: 0.15 | loss: 0.78
update:1390/2000, 耗时:0.01分/12.95分 | step: 711680 | performance: 9.7 | accuracy: 0.17 | loss: 1.20
update:1395/2000, 耗时:0.01分/12.99分 | step: 714240 | performance: 9.9 | accuracy: 0.18 | loss: 1.51
update:1400/2000, 耗时:0.01分/13.04分 | step: 716800 | performance: 72.7 | accuracy: 0.19 | loss: 1.74
update:1405/2000, 耗时:0.01分/13.08分 | step: 719360 | performance: 24.5 | accuracy: 0.21 | loss: 1.79
update:1410/2000, 耗时:0.01分/13.13分 | step: 721920 | performance: 0.7 | accuracy: 0.22 | loss: 2.05
update:1415/2000, 耗时:0.01分/13.17分 | step: 724480 | performance: 0.2 | accuracy: 0.34 | loss: 2.34
update:1420/2000, 耗时:0.01分/13.22分 | step: 727040 | performance: 0.1 | accuracy: 0.32 | loss: 2.16
update:1425/2000, 耗时:0.01分/13.27分 | step: 729600 | performance: 0.1 | accuracy: 0.31 | loss: 1.57
update:1430/2000, 耗时:0.01分/13.31分 | step: 732160 | performance: 13.3 | accuracy: 0.37 | loss: 2.65
update:1435/2000, 耗时:0.01分/13.36分 | step: 734720 | performance: 2.3 | accuracy: 0.35 | loss: 2.49
update:1440/2000, 耗时:0.01分/13.40分 | step: 737280 | performance: 1.4 | accuracy: 0.36 | loss: 1.31
update:1445/2000, 耗时:0.01分/13.45分 | step: 739840 | performance: 3.7 | accuracy: 0.37 | loss: 2.96
update:1450/2000, 耗时:0.01分/13.49分 | step: 742400 | performance: 1629.8 | accuracy: 0.38 | loss: 2.34
update:1455/2000, 耗时:0.01分/13.54分 | step: 744960 | performance: 547.7 | accuracy: 0.38 | loss: 3.40
update:1460/2000, 耗时:0.01分/13.58分 | step: 747520 | performance: 137.1 | accuracy: 0.38 | loss: 2.90
update:1465/2000, 耗时:0.01分/13.63分 | step: 750080 | performance: 8.6 | accuracy: 0.39 | loss: 3.15
update:1470/2000, 耗时:0.01分/13.68分 | step: 752640 | performance: 3.2 | accuracy: 1.00 | loss: 4.11
update:1475/2000, 耗时:0.01分/13.72分 | step: 755200 | performance: 0.0 | accuracy: 0.36 | loss: 2.36
update:1480/2000, 耗时:0.01分/13.77分 | step: 757760 | performance: 0.0 | accuracy: 0.39 | loss: 2.27
update:1485/2000, 耗时:0.01分/13.81分 | step: 760320 | performance: 0.0 | accuracy: 0.38 | loss: 1.51
update:1490/2000, 耗时:0.01分/13.86分 | step: 762880 | performance: 0.1 | accuracy: 0.38 | loss: 1.71
update:1495/2000, 耗时:0.01分/13.90分 | step: 765440 | performance: 0.0 | accuracy: 0.36 | loss: 2.77
update:1500/2000, 耗时:0.01分/13.95分 | step: 768000 | performance: 0.0 | accuracy: 0.36 | loss: 2.17
update:1505/2000, 耗时:0.01分/13.99分 | step: 770560 | performance: 4.7 | accuracy: 0.38 | loss: 3.02
update:1510/2000, 耗时:0.01分/14.04分 | step: 773120 | performance: 4.8 | accuracy: 0.39 | loss: 3.67
update:1515/2000, 耗时:0.01分/14.09分 | step: 775680 | performance: 25.8 | accuracy: 0.40 | loss: 3.53
update:1520/2000, 耗时:0.01分/14.13分 | step: 778240 | performance: 1.4 | accuracy: 0.40 | loss: 3.90
update:1525/2000, 耗时:0.01分/14.18分 | step: 780800 | performance: 0.1 | accuracy: 0.41 | loss: 3.14
update:1530/2000, 耗时:0.01分/14.22分 | step: 783360 | performance: 0.0 | accuracy: 0.42 | loss: 3.45
update:1535/2000, 耗时:0.01分/14.27分 | step: 785920 | performance: 0.0 | accuracy: 0.42 | loss: 3.38
update:1540/2000, 耗时:0.01分/14.31分 | step: 788480 | performance: 0.0 | accuracy: 0.40 | loss: 2.29
update:1545/2000, 耗时:0.01分/14.36分 | step: 791040 | performance: 0.0 | accuracy: 0.43 | loss: 3.10
update:1550/2000, 耗时:0.01分/14.40分 | step: 793600 | performance: 0.0 | accuracy: 0.42 | loss: 4.18
update:1555/2000, 耗时:0.01分/14.45分 | step: 796160 | performance: 0.0 | accuracy: 0.44 | loss: 2.96
update:1560/2000, 耗时:0.01分/14.49分 | step: 798720 | performance: 0.2 | accuracy: 0.45 | loss: 3.46
update:1565/2000, 耗时:0.01分/14.54分 | step: 801280 | performance: 144.2 | accuracy: 0.47 | loss: 3.02
update:1570/2000, 耗时:0.01分/14.59分 | step: 803840 | performance: 155.2 | accuracy: 0.47 | loss: 4.05
update:1575/2000, 耗时:0.01分/14.63分 | step: 806400 | performance: 15.4 | accuracy: 0.47 | loss: 3.42
update:1580/2000, 耗时:0.01分/14.68分 | step: 808960 | performance: 0.3 | accuracy: 0.46 | loss: 2.84
update:1585/2000, 耗时:0.01分/14.72分 | step: 811520 | performance: 0.2 | accuracy: 0.43 | loss: 4.12
update:1590/2000, 耗时:0.01分/14.77分 | step: 814080 | performance: 0.0 | accuracy: 0.40 | loss: 2.62
update:1595/2000, 耗时:0.01分/14.81分 | step: 816640 | performance: 0.0 | accuracy: 0.37 | loss: 2.24
update:1600/2000, 耗时:0.01分/14.86分 | step: 819200 | performance: 0.0 | accuracy: 0.38 | loss: 2.23
update:1605/2000, 耗时:0.01分/14.90分 | step: 821760 | performance: 0.0 | accuracy: 0.38 | loss: 1.71
update:1610/2000, 耗时:0.01分/14.95分 | step: 824320 | performance: 0.0 | accuracy: 0.38 | loss: 3.21
update:1615/2000, 耗时:0.01分/14.99分 | step: 826880 | performance: 0.0 | accuracy: 0.40 | loss: 2.80
update:1620/2000, 耗时:0.01分/15.04分 | step: 829440 | performance: 8.7 | accuracy: 0.42 | loss: 3.23
update:1625/2000, 耗时:0.01分/15.09分 | step: 832000 | performance: 2.9 | accuracy: 0.42 | loss: 4.27
update:1630/2000, 耗时:0.01分/15.13分 | step: 834560 | performance: 3.1 | accuracy: 0.43 | loss: 3.53
update:1635/2000, 耗时:0.01分/15.18分 | step: 837120 | performance: 0.0 | accuracy: 0.43 | loss: 3.45
update:1640/2000, 耗时:0.01分/15.22分 | step: 839680 | performance: 0.0 | accuracy: 0.43 | loss: 3.17
Saving PPO weights in both H5 format and checkpoint @ update:1640 
Saving PPO weights in both H5 format and checkpoint @ update:1642 
update:1645/2000, 耗时:0.01分/15.28分 | step: 842240 | performance: 0.1 | accuracy: 0.47 | loss: 2.96
Saving PPO weights in both H5 format and checkpoint @ update:1647 
Saving PPO weights in both H5 format and checkpoint @ update:1648 
Saving PPO weights in both H5 format and checkpoint @ update:1649 
update:1650/2000, 耗时:0.01分/15.34分 | step: 844800 | performance: 0.0 | accuracy: 0.43 | loss: 2.93
update:1655/2000, 耗时:0.01分/15.39分 | step: 847360 | performance: 0.0 | accuracy: 0.42 | loss: 2.59
Saving PPO weights in both H5 format and checkpoint @ update:1657 
update:1660/2000, 耗时:0.01分/15.44分 | step: 849920 | performance: 0.1 | accuracy: 0.46 | loss: 3.36
Saving PPO weights in both H5 format and checkpoint @ update:1663 
update:1665/2000, 耗时:0.01分/15.49分 | step: 852480 | performance: 0.0 | accuracy: 0.45 | loss: 3.94
update:1670/2000, 耗时:0.01分/15.53分 | step: 855040 | performance: 0.1 | accuracy: 0.46 | loss: 2.87
update:1675/2000, 耗时:0.01分/15.58分 | step: 857600 | performance: 11.7 | accuracy: 0.49 | loss: 3.77
update:1680/2000, 耗时:0.01分/15.63分 | step: 860160 | performance: 76.9 | accuracy: 0.49 | loss: 3.68
Saving PPO weights in both H5 format and checkpoint @ update:1683 
update:1685/2000, 耗时:0.01分/15.68分 | step: 862720 | performance: 1419.6 | accuracy: 0.50 | loss: 4.10
update:1690/2000, 耗时:0.01分/15.73分 | step: 865280 | performance: 80.4 | accuracy: 0.50 | loss: 3.79
update:1695/2000, 耗时:0.01分/15.78分 | step: 867840 | performance: 0.7 | accuracy: 0.49 | loss: 3.62
Saving PPO weights in both H5 format and checkpoint @ update:1697 
Saving PPO weights in both H5 format and checkpoint @ update:1699 
update:1700/2000, 耗时:0.01分/15.83分 | step: 870400 | performance: 0.2 | accuracy: 0.49 | loss: 4.62
Saving PPO weights in both H5 format and checkpoint @ update:1704 
update:1705/2000, 耗时:0.01分/15.88分 | step: 872960 | performance: 0.0 | accuracy: 0.46 | loss: 4.05
Saving PPO weights in both H5 format and checkpoint @ update:1705 
Saving PPO weights in both H5 format and checkpoint @ update:1706 
update:1710/2000, 耗时:0.01分/15.94分 | step: 875520 | performance: 0.0 | accuracy: 0.44 | loss: 3.52
Saving PPO weights in both H5 format and checkpoint @ update:1714 
update:1715/2000, 耗时:0.01分/16.00分 | step: 878080 | performance: 0.1 | accuracy: 0.50 | loss: 4.60
update:1720/2000, 耗时:0.01分/16.04分 | step: 880640 | performance: 0.0 | accuracy: 0.48 | loss: 4.29
Saving PPO weights in both H5 format and checkpoint @ update:1720 
update:1725/2000, 耗时:0.01分/16.09分 | step: 883200 | performance: 0.0 | accuracy: 0.49 | loss: 3.68
update:1730/2000, 耗时:0.01分/16.14分 | step: 885760 | performance: 0.0 | accuracy: 0.50 | loss: 4.35
update:1735/2000, 耗时:0.01分/16.19分 | step: 888320 | performance: 446.2 | accuracy: 0.53 | loss: 3.71
update:1740/2000, 耗时:0.01分/16.23分 | step: 890880 | performance: 146.7 | accuracy: 0.52 | loss: 4.93
Saving PPO weights in both H5 format and checkpoint @ update:1740 
update:1745/2000, 耗时:0.01分/16.28分 | step: 893440 | performance: 44.7 | accuracy: 0.52 | loss: 4.35
update:1750/2000, 耗时:0.01分/16.33分 | step: 896000 | performance: 0.5 | accuracy: 0.51 | loss: 4.23
update:1755/2000, 耗时:0.01分/16.37分 | step: 898560 | performance: 0.1 | accuracy: 0.51 | loss: 4.18
Saving PPO weights in both H5 format and checkpoint @ update:1755 
Saving PPO weights in both H5 format and checkpoint @ update:1756 
update:1760/2000, 耗时:0.01分/16.43分 | step: 901120 | performance: 0.0 | accuracy: 0.45 | loss: 3.24
Saving PPO weights in both H5 format and checkpoint @ update:1763 
update:1765/2000, 耗时:0.01分/16.48分 | step: 903680 | performance: 0.0 | accuracy: 0.47 | loss: 4.90
update:1770/2000, 耗时:0.01分/16.53分 | step: 906240 | performance: 0.0 | accuracy: 0.47 | loss: 3.41
Saving PPO weights in both H5 format and checkpoint @ update:1771 
update:1775/2000, 耗时:0.01分/16.59分 | step: 908800 | performance: 0.0 | accuracy: 0.49 | loss: 3.41
Saving PPO weights in both H5 format and checkpoint @ update:1777 
update:1780/2000, 耗时:0.01分/16.64分 | step: 911360 | performance: 0.0 | accuracy: 0.49 | loss: 4.54
update:1785/2000, 耗时:0.01分/16.69分 | step: 913920 | performance: 0.1 | accuracy: 0.50 | loss: 3.41
update:1790/2000, 耗时:0.01分/16.74分 | step: 916480 | performance: 35.1 | accuracy: 0.52 | loss: 3.71
update:1795/2000, 耗时:0.01分/16.78分 | step: 919040 | performance: 12.5 | accuracy: 0.52 | loss: 4.34
update:1800/2000, 耗时:0.01分/16.84分 | step: 921600 | performance: 229.2 | accuracy: 0.52 | loss: 3.94
update:1805/2000, 耗时:0.01分/16.88分 | step: 924160 | performance: 5.0 | accuracy: 0.51 | loss: 3.95
update:1810/2000, 耗时:0.01分/16.94分 | step: 926720 | performance: 0.2 | accuracy: 0.51 | loss: 3.42
update:1815/2000, 耗时:0.01分/17.00分 | step: 929280 | performance: 0.1 | accuracy: 0.47 | loss: 4.13
update:1820/2000, 耗时:0.01分/17.06分 | step: 931840 | performance: 0.0 | accuracy: 0.47 | loss: 4.42
update:1825/2000, 耗时:0.01分/17.12分 | step: 934400 | performance: 0.0 | accuracy: 0.45 | loss: 3.24
update:1830/2000, 耗时:0.01分/17.18分 | step: 936960 | performance: 0.1 | accuracy: 0.50 | loss: 4.58
update:1835/2000, 耗时:0.01分/17.23分 | step: 939520 | performance: 0.0 | accuracy: 0.48 | loss: 4.52
update:1840/2000, 耗时:0.01分/17.29分 | step: 942080 | performance: 0.0 | accuracy: 0.50 | loss: 3.79
update:1845/2000, 耗时:0.01分/17.35分 | step: 944640 | performance: 0.3 | accuracy: 0.51 | loss: 4.81
update:1850/2000, 耗时:0.01分/17.40分 | step: 947200 | performance: 499.3 | accuracy: 0.53 | loss: 3.61
update:1855/2000, 耗时:0.01分/17.46分 | step: 949760 | performance: 72.6 | accuracy: 0.52 | loss: 4.58
update:1860/2000, 耗时:0.01分/17.51分 | step: 952320 | performance: 40.9 | accuracy: 0.52 | loss: 3.84
update:1865/2000, 耗时:0.01分/17.56分 | step: 954880 | performance: 1.0 | accuracy: 0.51 | loss: 3.79
update:1870/2000, 耗时:0.01分/17.62分 | step: 957440 | performance: 0.5 | accuracy: 0.42 | loss: 4.70
update:1875/2000, 耗时:0.01分/17.67分 | step: 960000 | performance: 0.0 | accuracy: 0.45 | loss: 3.75
Saving PPO weights in both H5 format and checkpoint @ update:1875 
Saving PPO weights in both H5 format and checkpoint @ update:1876 
update:1880/2000, 耗时:0.01分/17.72分 | step: 962560 | performance: 0.0 | accuracy: 0.46 | loss: 4.18
update:1885/2000, 耗时:0.01分/17.77分 | step: 965120 | performance: 0.0 | accuracy: 0.49 | loss: 3.91
update:1890/2000, 耗时:0.01分/17.81分 | step: 967680 | performance: 0.0 | accuracy: 0.49 | loss: 3.87
update:1895/2000, 耗时:0.01分/17.86分 | step: 970240 | performance: 0.0 | accuracy: 0.49 | loss: 4.94
update:1900/2000, 耗时:0.01分/17.91分 | step: 972800 | performance: 0.0 | accuracy: 0.50 | loss: 3.71
update:1905/2000, 耗时:0.01分/17.96分 | step: 975360 | performance: 187.5 | accuracy: 0.53 | loss: 4.04
update:1910/2000, 耗时:0.01分/18.00分 | step: 977920 | performance: 12.1 | accuracy: 0.52 | loss: 4.39
update:1915/2000, 耗时:0.01分/18.05分 | step: 980480 | performance: 165.8 | accuracy: 0.52 | loss: 3.76
update:1920/2000, 耗时:0.01分/18.09分 | step: 983040 | performance: 6.0 | accuracy: 0.51 | loss: 3.77
update:1925/2000, 耗时:0.01分/18.14分 | step: 985600 | performance: 0.2 | accuracy: 0.51 | loss: 3.70
update:1930/2000, 耗时:0.01分/18.19分 | step: 988160 | performance: 0.0 | accuracy: 0.47 | loss: 3.57
update:1935/2000, 耗时:0.01分/18.23分 | step: 990720 | performance: 0.0 | accuracy: 0.45 | loss: 3.88
update:1940/2000, 耗时:0.01分/18.28分 | step: 993280 | performance: 0.0 | accuracy: 0.44 | loss: 2.96
Saving PPO weights in both H5 format and checkpoint @ update:1942 
update:1945/2000, 耗时:0.01分/18.33分 | step: 995840 | performance: 0.1 | accuracy: 0.47 | loss: 3.15
update:1950/2000, 耗时:0.01分/18.37分 | step: 998400 | performance: 0.0 | accuracy: 0.46 | loss: 4.02
update:1955/2000, 耗时:0.01分/18.42分 | step: 1000960 | performance: 0.0 | accuracy: 0.46 | loss: 2.52
update:1960/2000, 耗时:0.01分/18.46分 | step: 1003520 | performance: 0.3 | accuracy: 0.47 | loss: 3.04
update:1965/2000, 耗时:0.01分/18.51分 | step: 1006080 | performance: 61.1 | accuracy: 0.49 | loss: 3.44
update:1970/2000, 耗时:0.01分/18.56分 | step: 1008640 | performance: 207.9 | accuracy: 0.49 | loss: 3.87
update:1975/2000, 耗时:0.01分/18.60分 | step: 1011200 | performance: 20.3 | accuracy: 0.49 | loss: 3.71
update:1980/2000, 耗时:0.01分/18.65分 | step: 1013760 | performance: 0.1 | accuracy: 0.47 | loss: 3.15
update:1985/2000, 耗时:0.01分/18.69分 | step: 1016320 | performance: 0.1 | accuracy: 0.39 | loss: 4.06
update:1990/2000, 耗时:0.01分/18.74分 | step: 1018880 | performance: 0.0 | accuracy: 0.41 | loss: 3.10
update:1995/2000, 耗时:0.01分/18.78分 | step: 1021440 | performance: 0.0 | accuracy: 0.39 | loss: 2.56
update:2000/2000, 耗时:0.01分/18.83分 | step: 1024000 | performance: 0.0 | accuracy: 0.42 | loss: 3.61
----------------------------------------finished----------------------------------------
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/397 [00:00<?, ?it/s]100%|| 397/397 [00:00<00:00, 132059.54it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1712.77
2023-07-24T12:00:00 | net performance [%] = 71.2771
2023-07-24T12:00:00 | number of trades [#] = 4
==================================================
Trial 8 Complete [00h 19m 16s]
net_wealth: 1714.485333603393

Best net_wealth So Far: 1714.485333603393
Total elapsed time: 00h 55m 21s

Search: Running Trial #9

Value             |Best Value So Far |Hyperparameter
3                 |6                 |horizon
365               |225               |lookback
True              |True              |MarketFactor
10                |14                |lags
0.98              |0.85              |gamma
16                |32                |batch_size
32                |64                |n_step
0.9               |0.8               |gae_lambda
5                 |2                 |gradient_clip_norm
3                 |3                 |epochs
0.0005            |0.001             |actor_lr
0.001             |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4298.000000   4301.000000
mean      0.000435    20113.607657  ...   20180.392273  20169.373185
std       0.027833    16040.642334  ...   16078.781641  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7741.750122   7730.930176
50%       0.000642    11571.842969  ...   11754.949707  11751.469727
75%       0.011590    29894.706152  ...   30015.383301  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-27 22:58:44.149321: I tensorflow/core/platfor22023-07-2027m3 2-2:58:44.149357: I tensorflow/core/platform/cpu_feature_guard.cc:142] This2/cp007-2u3-02_7 7-2722: f22:58:44ea5.ture14_guard98:44416.cc:: 2I 0 Tet.ensorflow/core/platformn/142]2sorFlo14wc3-07p -ub2i7 2nary 2_is :fo5eptimize8ad:t 4ur4w.e_guard.cc:i1144t29h]490: I  tensThi9or s  321Thiso2f02nlo: IeA2P0I T2 3-0ew7/D-227e c0Tee2nsno s23o-0t2reFnlow oprFrlsb oNw7-2inae/r7y e2p2u :ir5la8tfs ora:mop4t/4c.pu_l14feiatmiur9e9_g2uz8 Netard.c3:wcork-:e142] Thi  I 0Ltesn orb:fib7ilo58ran-w2 rTarye/syod  wi t(o7n eDNN)2n2:5is op stco8h ore /pltioonra:euAFPIm i:zlo4esew t heD efe44d rtpw N.foirt4e.mh1fulra 1ow/c/4o4n9o8eAPI7or6 cDl:9lp l e8IobwinaN9eutiry iwnsege oCrP  k pt NULoepne itsiu5n: brraalsrIimtryu  _f(oic troztef/lpennseelioraDoNaNo)tutfnlsrdwf/ocrom oew/N in ertew/_ gtuwapcpoor duup_ie.slrftecrforahk  eco t/nmt:LcfoeaAncPIo D1eirbm4-2crirr]ee/a/ tircy ecppluTh_fpa l oiea(tNfoneeos uheDNN)aa tufolre_gulowitTensor nural NrFe_guard.cc:a1rdge.t C4Pwork Lp2to]cre  This Trc:1at42ioens:] i unsorFloTlhoUww  A  imb/cpuisnssetruc Tbi_tfionVX Aee bVins inaaXnsroaatrutrrFy ins perfoh2
Tor rorylow bim ee_ gfuarpty  andnaryis. cci coep-critiotimiicalleonwing(:ons aoz142] peeDNmbizt iNlThis T opee)mizedCd toldr  w use athi wiwetiottPnsore theUFlnim inhhoth st on se oneew  rAuAo:nbfollc  AViPtioPXI n einarInsAP yA Di iVne  pDeerIoeepX Dee f2o
ToN epw Nrp Nienmeunabuoral sl roetugaaplN reh them iet iCPU atlNeir ope n minzceerNnateotherd ewsitorwo-rc nostiwtorh ,upietriacta krcownorletbeik opuoinld teirrsk API , rebu Doans iLeib ilTetLrarLnsoribriiboryda Tensorerpn (Folow n npy awsFelo(oneDNN)r:itehrwy w i Dto ufoNt NeusrN (tohera)e nteoD NuN)l   amp  steh e ah thpNenttwotrcoe- uApre  sfeolicaVhX tlpopwiateropeor  cAoVmXp2i
Tro lenrr enig Cfhliatticags.
ePa ab lfollowieU  k Lifobrarcoy nmpiler fl oiglags.el(onnse
 peD them in other operations, rebuild TensorFlow with the appropriate compiler flags.
rations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
NCPUN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
lowing CPU in instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
structions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
tructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-27 22:58:44.808779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:58:44.815522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 202MB memory:  ->3-07-27 22 de:v58:44.815599: I tensoicerflow/core/common_runti:me/gpu/gpu_dev 0ice.cc:1510], nam Create: NVIDIA GeForce Red device TX 30/job:localhost70/, pci replica:0bus id: 00/task:0/devi00:01:0ce:GPU:0 with 054.054 MB memory:  -> device, compute capability: 8.6
: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 2023-07-27 22:588.6
:44.816017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:58:44.816917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:58:44.835107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:58:44.840635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 22:58:44.849973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.05分 | step:  1280 | performance: 0.5 | accuracy: 0.29 | loss: 1.49
update: 10/2000, 耗时:0.00分/0.07分 | step:  2560 | performance: 0.7 | accuracy: 0.27 | loss: 2.60
update: 15/2000, 耗时:0.01分/0.10分 | step:  3840 | performance: 0.4 | accuracy: 0.24 | loss: 1.50
update: 20/2000, 耗时:0.01分/0.12分 | step:  5120 | performance: 0.5 | accuracy: 0.24 | loss: 0.80
update: 25/2000, 耗时:0.01分/0.15分 | step:  6400 | performance: 0.3 | accuracy: 0.23 | loss: 1.79
update: 30/2000, 耗时:0.01分/0.18分 | step:  7680 | performance: 0.4 | accuracy: 0.26 | loss: 3.27
update: 35/2000, 耗时:0.01分/0.21分 | step:  8960 | performance: 0.2 | accuracy: 0.28 | loss: 2.29
update: 40/2000, 耗时:0.01分/0.24分 | step: 10240 | performance: 0.5 | accuracy: 0.28 | loss: 1.30
update: 45/2000, 耗时:0.01分/0.27分 | step: 11520 | performance: 0.3 | accuracy: 0.28 | loss: 1.28
update: 50/2000, 耗时:0.01分/0.30分 | step: 12800 | performance: 0.2 | accuracy: 0.27 | loss: 2.57
update: 55/2000, 耗时:0.01分/0.33分 | step: 14080 | performance: 0.1 | accuracy: 0.27 | loss: 2.73
update: 60/2000, 耗时:0.01分/0.35分 | step: 15360 | performance: 0.1 | accuracy: 0.27 | loss: 1.06
update: 65/2000, 耗时:0.01分/0.38分 | step: 16640 | performance: 0.2 | accuracy: 0.29 | loss: 5.75
update: 70/2000, 耗时:0.01分/0.41分 | step: 17920 | performance: 0.3 | accuracy: 0.29 | loss: 3.67
update: 75/2000, 耗时:0.01分/0.44分 | step: 19200 | performance: 0.1 | accuracy: 0.29 | loss: 1.55
update: 80/2000, 耗时:0.01分/0.47分 | step: 20480 | performance: 0.0 | accuracy: 0.29 | loss: 1.02
update: 85/2000, 耗时:0.01分/0.50分 | step: 21760 | performance: 0.0 | accuracy: 0.29 | loss: 1.74
update: 90/2000, 耗时:0.01分/0.53分 | step: 23040 | performance: 0.0 | accuracy: 0.29 | loss: 1.21
update: 95/2000, 耗时:0.01分/0.56分 | step: 24320 | performance: 0.0 | accuracy: 0.29 | loss: 1.16
update:100/2000, 耗时:0.01分/0.59分 | step: 25600 | performance: 0.0 | accuracy: 0.28 | loss: 1.14
update:105/2000, 耗时:0.01分/0.62分 | step: 26880 | performance: 0.1 | accuracy: 0.28 | loss: 1.69
update:110/2000, 耗时:0.01分/0.65分 | step: 28160 | performance: 1.0 | accuracy: 0.00 | loss: 1.18
Saving PPO weights in both H5 format and checkpoint @ update:110 
update:115/2000, 耗时:0.01分/0.68分 | step: 29440 | performance: 0.9 | accuracy: 0.27 | loss: 1.54
update:120/2000, 耗时:0.01分/0.71分 | step: 30720 | performance: 1.0 | accuracy: 0.27 | loss: 2.46
update:125/2000, 耗时:0.01分/0.73分 | step: 32000 | performance: 1.1 | accuracy: 0.26 | loss: 0.72
update:130/2000, 耗时:0.01分/0.76分 | step: 33280 | performance: 1.7 | accuracy: 0.25 | loss: 1.08
update:135/2000, 耗时:0.01分/0.79分 | step: 34560 | performance: 1.4 | accuracy: 0.24 | loss: 1.29
update:140/2000, 耗时:0.01分/0.82分 | step: 35840 | performance: 1.3 | accuracy: 0.25 | loss: 2.92
update:145/2000, 耗时:0.01分/0.85分 | step: 37120 | performance: 1.1 | accuracy: 0.25 | loss: 0.80
update:150/2000, 耗时:0.01分/0.87分 | step: 38400 | performance: 1.2 | accuracy: 0.24 | loss: 1.27
update:155/2000, 耗时:0.01分/0.90分 | step: 39680 | performance: 1.1 | accuracy: 0.23 | loss: 1.60
update:160/2000, 耗时:0.01分/0.93分 | step: 40960 | performance: 1.3 | accuracy: 0.23 | loss: 0.75
update:165/2000, 耗时:0.01分/0.96分 | step: 42240 | performance: 1.5 | accuracy: 0.22 | loss: 0.70
update:170/2000, 耗时:0.01分/0.99分 | step: 43520 | performance: 1.3 | accuracy: 0.21 | loss: 0.30
update:175/2000, 耗时:0.01分/1.02分 | step: 44800 | performance: 1.3 | accuracy: 0.20 | loss: 0.81
update:180/2000, 耗时:0.01分/1.05分 | step: 46080 | performance: 1.6 | accuracy: 0.19 | loss: 0.19
update:185/2000, 耗时:0.01分/1.07分 | step: 47360 | performance: 1.5 | accuracy: 0.18 | loss: 0.47
update:190/2000, 耗时:0.01分/1.10分 | step: 48640 | performance: 1.3 | accuracy: 0.17 | loss: 0.29
update:195/2000, 耗时:0.01分/1.13分 | step: 49920 | performance: 1.2 | accuracy: 0.17 | loss: 0.21
update:200/2000, 耗时:0.01分/1.16分 | step: 51200 | performance: 1.0 | accuracy: 0.17 | loss: 0.41
update:205/2000, 耗时:0.01分/1.19分 | step: 52480 | performance: 1.3 | accuracy: 0.16 | loss: 0.38
update:210/2000, 耗时:0.01分/1.21分 | step: 53760 | performance: 1.7 | accuracy: 0.16 | loss: 0.37
update:215/2000, 耗时:0.01分/1.24分 | step: 55040 | performance: 1.6 | accuracy: 0.15 | loss: 0.67
update:220/2000, 耗时:0.01分/1.27分 | step: 56320 | performance: 0.9 | accuracy: 0.25 | loss: 0.89
Saving PPO weights in both H5 format and checkpoint @ update:220 
update:225/2000, 耗时:0.01分/1.31分 | step: 57600 | performance: 1.7 | accuracy: 0.19 | loss: 0.66
update:230/2000, 耗时:0.01分/1.33分 | step: 58880 | performance: 2.7 | accuracy: 0.17 | loss: 0.96
update:235/2000, 耗时:0.01分/1.36分 | step: 60160 | performance: 2.6 | accuracy: 0.16 | loss: 0.52
update:240/2000, 耗时:0.01分/1.39分 | step: 61440 | performance: 4.2 | accuracy: 0.15 | loss: 0.45
update:245/2000, 耗时:0.01分/1.42分 | step: 62720 | performance: 2.8 | accuracy: 0.15 | loss: 0.48
update:250/2000, 耗时:0.01分/1.45分 | step: 64000 | performance: 2.8 | accuracy: 0.13 | loss: 0.01
update:255/2000, 耗时:0.01分/1.47分 | step: 65280 | performance: 3.0 | accuracy: 0.12 | loss: 0.13
update:260/2000, 耗时:0.01分/1.50分 | step: 66560 | performance: 2.9 | accuracy: 0.11 | loss: 0.24
update:265/2000, 耗时:0.01分/1.53分 | step: 67840 | performance: 3.3 | accuracy: 0.10 | loss: 0.14
step: 68345 | worker_0@n_step_31: average total_reward after train data exhaustion : 28.4 | max total_reward: 131.5
update:270/2000, 耗时:0.01分/1.56分 | step: 69120 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 69627 | worker_2@n_step_31: average total_reward after train data exhaustion : 2.3 | max total_reward: 131.5
step: 69882 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:275/2000, 耗时:0.01分/1.59分 | step: 70400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 70654 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 70908 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 71165 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 71424 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:280/2000, 耗时:0.01分/1.62分 | step: 71680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 72447 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 72697 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:285/2000, 耗时:0.01分/1.65分 | step: 72960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 73979 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 74234 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:290/2000, 耗时:0.01分/1.67分 | step: 74240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 75006 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 75260 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 75517 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:295/2000, 耗时:0.01分/1.70分 | step: 75520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 75776 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 76799 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:300/2000, 耗时:0.01分/1.73分 | step: 76800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 77049 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:305/2000, 耗时:0.01分/1.76分 | step: 78080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 78331 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 78586 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 79358 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:310/2000, 耗时:0.01分/1.79分 | step: 79360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 79612 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 79869 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 80128 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:315/2000, 耗时:0.01分/1.82分 | step: 80640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 81151 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 81401 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:320/2000, 耗时:0.01分/1.84分 | step: 81920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 82683 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 82938 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:325/2000, 耗时:0.01分/1.87分 | step: 83200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 83710 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 131.5
step: 83964 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 83968 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 84221 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
update:330/2000, 耗时:0.01分/1.90分 | step: 84480 | performance: 1.0 | accuracy: 0.08 | loss: 0.11
step: 84991 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 131.5
update:335/2000, 耗时:0.01分/1.93分 | step: 85760 | performance: 1.1 | accuracy: 0.06 | loss: 0.19
step: 86268 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 131.5
update:340/2000, 耗时:0.01分/1.96分 | step: 87040 | performance: 1.2 | accuracy: 0.15 | loss: 0.37
step: 88057 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 131.5
update:345/2000, 耗时:0.01分/1.99分 | step: 88320 | performance: 1.1 | accuracy: 0.12 | loss: 0.35
step: 89598 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 131.5
step: 89599 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 131.5
update:350/2000, 耗时:0.01分/2.02分 | step: 89600 | performance: 1.2 | accuracy: 0.11 | loss: 0.32
update:355/2000, 耗时:0.01分/2.05分 | step: 90880 | performance: 1.1 | accuracy: 0.25 | loss: 1.42
step: 92157 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 131.5
update:360/2000, 耗时:0.01分/2.08分 | step: 92160 | performance: 1.5 | accuracy: 0.15 | loss: 0.51
update:365/2000, 耗时:0.01分/2.11分 | step: 93440 | performance: 1.0 | accuracy: 0.50 | loss: 0.24
step: 93696 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 131.5
update:370/2000, 耗时:0.01分/2.14分 | step: 94720 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 94973 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 131.5
step: 95228 | worker_3@n_step_31: average total_reward after train data exhaustion : 2.0 | max total_reward: 131.5
step: 95230 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.1 | max total_reward: 131.5
update:375/2000, 耗时:0.01分/2.17分 | step: 96000 | performance: 1.3 | accuracy: 0.16 | loss: 0.63
update:380/2000, 耗时:0.01分/2.20分 | step: 97280 | performance: 1.2 | accuracy: 0.13 | loss: 0.30
update:385/2000, 耗时:0.01分/2.23分 | step: 98560 | performance: 1.1 | accuracy: 0.15 | loss: 0.90
update:390/2000, 耗时:0.01分/2.26分 | step: 99840 | performance: 1.3 | accuracy: 0.16 | loss: 1.26
update:395/2000, 耗时:0.01分/2.29分 | step: 101120 | performance: 1.5 | accuracy: 0.17 | loss: 0.95
update:400/2000, 耗时:0.01分/2.32分 | step: 102400 | performance: 1.4 | accuracy: 0.16 | loss: 1.29
update:405/2000, 耗时:0.01分/2.35分 | step: 103680 | performance: 1.8 | accuracy: 0.16 | loss: 0.60
update:410/2000, 耗时:0.01分/2.37分 | step: 104960 | performance: 1.1 | accuracy: 0.15 | loss: 0.30
update:415/2000, 耗时:0.01分/2.40分 | step: 106240 | performance: 1.1 | accuracy: 0.13 | loss: 0.09
update:420/2000, 耗时:0.01分/2.43分 | step: 107520 | performance: 1.1 | accuracy: 0.12 | loss: 0.47
update:425/2000, 耗时:0.01分/2.46分 | step: 108800 | performance: 1.1 | accuracy: 0.12 | loss: 0.65
update:430/2000, 耗时:0.01分/2.49分 | step: 110080 | performance: 0.9 | accuracy: 0.11 | loss: 0.30
update:435/2000, 耗时:0.01分/2.52分 | step: 111360 | performance: 0.6 | accuracy: 0.10 | loss: 0.14
step: 112379 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.4 | max total_reward: 131.5
update:440/2000, 耗时:0.01分/2.55分 | step: 112640 | performance: 0.6 | accuracy: 0.10 | loss: 0.26
update:445/2000, 耗时:0.01分/2.58分 | step: 113920 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 114170 | worker_1@n_step_31: average total_reward after train data exhaustion : 5.5 | max total_reward: 131.5
step: 114174 | worker_5@n_step_31: average total_reward after train data exhaustion : 7.7 | max total_reward: 131.5
step: 114937 | worker_0@n_step_31: average total_reward after train data exhaustion : 5.7 | max total_reward: 131.5
update:450/2000, 耗时:0.01分/2.61分 | step: 115200 | performance: 1.1 | accuracy: 0.10 | loss: 0.46
update:455/2000, 耗时:0.01分/2.64分 | step: 116480 | performance: 1.0 | accuracy: 0.13 | loss: 0.76
step: 116991 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 131.5
update:460/2000, 耗时:0.01分/2.67分 | step: 117760 | performance: 1.0 | accuracy: 0.00 | loss: 0.76
update:465/2000, 耗时:0.01分/2.70分 | step: 119040 | performance: 1.4 | accuracy: 0.15 | loss: 0.49
update:470/2000, 耗时:0.01分/2.73分 | step: 120320 | performance: 1.3 | accuracy: 0.14 | loss: 0.74
update:475/2000, 耗时:0.01分/2.76分 | step: 121600 | performance: 1.5 | accuracy: 0.13 | loss: 0.43
update:480/2000, 耗时:0.01分/2.79分 | step: 122880 | performance: 1.7 | accuracy: 0.12 | loss: 0.39
update:485/2000, 耗时:0.01分/2.81分 | step: 124160 | performance: 1.5 | accuracy: 0.11 | loss: 0.06
update:490/2000, 耗时:0.01分/2.84分 | step: 125440 | performance: 1.5 | accuracy: 0.10 | loss: 0.10
step: 125951 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.6 | max total_reward: 131.5
update:495/2000, 耗时:0.01分/2.87分 | step: 126720 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 126970 | worker_1@n_step_31: average total_reward after train data exhaustion : 2.6 | max total_reward: 131.5
update:500/2000, 耗时:0.01分/2.90分 | step: 128000 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 129280 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
update:505/2000, 耗时:0.01分/2.93分 | step: 129280 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 129534 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 131.5
step: 129789 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 131.5
step: 129791 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 131.5
update:510/2000, 耗时:0.01分/2.96分 | step: 130560 | performance: 1.1 | accuracy: 0.10 | loss: 0.33
step: 131583 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 131.5
update:515/2000, 耗时:0.01分/2.99分 | step: 131840 | performance: 1.1 | accuracy: 0.15 | loss: 0.69
step: 132093 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 131.5
update:520/2000, 耗时:0.01分/3.02分 | step: 133120 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
step: 133371 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 131.5
update:525/2000, 耗时:0.01分/3.05分 | step: 134400 | performance: 0.9 | accuracy: 0.11 | loss: 0.24
update:530/2000, 耗时:0.01分/3.08分 | step: 135680 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
update:535/2000, 耗时:0.01分/3.11分 | step: 136960 | performance: 1.3 | accuracy: 0.11 | loss: 0.57
update:540/2000, 耗时:0.01分/3.14分 | step: 138240 | performance: 1.1 | accuracy: 0.14 | loss: 0.85
update:545/2000, 耗时:0.01分/3.17分 | step: 139520 | performance: 1.3 | accuracy: 0.13 | loss: 0.51
update:550/2000, 耗时:0.01分/3.20分 | step: 140800 | performance: 1.1 | accuracy: 0.13 | loss: 0.46
update:555/2000, 耗时:0.01分/3.23分 | step: 142080 | performance: 1.7 | accuracy: 0.13 | loss: 0.41
update:560/2000, 耗时:0.01分/3.26分 | step: 143360 | performance: 1.8 | accuracy: 0.13 | loss: 0.63
update:565/2000, 耗时:0.01分/3.29分 | step: 144640 | performance: 1.8 | accuracy: 0.12 | loss: 0.09
step: 145149 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 131.5
step: 145658 | worker_1@n_step_31: average total_reward after train data exhaustion : 3.8 | max total_reward: 131.5
step: 145660 | worker_3@n_step_31: average total_reward after train data exhaustion : 3.8 | max total_reward: 131.5
step: 145913 | worker_0@n_step_31: average total_reward after train data exhaustion : 4.4 | max total_reward: 131.5
step: 145919 | worker_6@n_step_31: average total_reward after train data exhaustion : 4.4 | max total_reward: 131.5
update:570/2000, 耗时:0.01分/3.32分 | step: 145920 | performance: 1.8 | accuracy: 0.10 | loss: 0.07
update:575/2000, 耗时:0.01分/3.35分 | step: 147200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:580/2000, 耗时:0.01分/3.38分 | step: 148480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 148987 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 148990 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 149501 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:585/2000, 耗时:0.01分/3.41分 | step: 149760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 150010 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 150012 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 150016 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 150265 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 150271 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:590/2000, 耗时:0.01分/3.44分 | step: 151040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:595/2000, 耗时:0.01分/3.47分 | step: 152320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 153339 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 153342 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:600/2000, 耗时:0.01分/3.51分 | step: 153600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 153853 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 154362 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 154364 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 154368 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 154617 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 154623 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:605/2000, 耗时:0.01分/3.54分 | step: 154880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:610/2000, 耗时:0.01分/3.57分 | step: 156160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:615/2000, 耗时:0.01分/3.60分 | step: 157440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 157691 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 157694 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 158205 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 158714 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 158716 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 158720 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:620/2000, 耗时:0.01分/3.63分 | step: 158720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 158969 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 158975 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:625/2000, 耗时:0.01分/3.66分 | step: 160000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:630/2000, 耗时:0.01分/3.69分 | step: 161280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 162043 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 162046 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 162557 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:635/2000, 耗时:0.01分/3.72分 | step: 162560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 163066 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 163068 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 163072 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 163321 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 163327 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:640/2000, 耗时:0.01分/3.76分 | step: 163840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:645/2000, 耗时:0.01分/3.79分 | step: 165120 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 166395 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 166398 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:650/2000, 耗时:0.01分/3.82分 | step: 166400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 166909 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 167418 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 167420 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 167424 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 167673 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 167679 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:655/2000, 耗时:0.01分/3.85分 | step: 167680 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:660/2000, 耗时:0.01分/3.87分 | step: 168960 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:665/2000, 耗时:0.01分/3.90分 | step: 170240 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 170747 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 170750 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 171261 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:670/2000, 耗时:0.01分/3.93分 | step: 171520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 171770 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 171772 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 171776 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 172025 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 172031 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:675/2000, 耗时:0.01分/3.96分 | step: 172800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:680/2000, 耗时:0.01分/3.99分 | step: 174080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 175099 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 175102 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:685/2000, 耗时:0.01分/4.02分 | step: 175360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 175613 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 176122 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 176124 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 176128 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 176377 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 176383 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:690/2000, 耗时:0.01分/4.05分 | step: 176640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:695/2000, 耗时:0.01分/4.08分 | step: 177920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:700/2000, 耗时:0.01分/4.11分 | step: 179200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 179451 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 179454 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 179965 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 180474 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 180476 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 180480 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:705/2000, 耗时:0.01分/4.14分 | step: 180480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 180729 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 180735 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:710/2000, 耗时:0.01分/4.17分 | step: 181760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:715/2000, 耗时:0.01分/4.20分 | step: 183040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 183803 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 183806 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 184317 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:720/2000, 耗时:0.01分/4.23分 | step: 184320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 184826 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 184828 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 184832 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 185081 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 185087 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:725/2000, 耗时:0.01分/4.26分 | step: 185600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:730/2000, 耗时:0.01分/4.29分 | step: 186880 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 188155 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 188158 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:735/2000, 耗时:0.01分/4.32分 | step: 188160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 188669 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 189178 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 189180 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 189184 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 189433 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 189439 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:740/2000, 耗时:0.01分/4.35分 | step: 189440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:745/2000, 耗时:0.01分/4.38分 | step: 190720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:750/2000, 耗时:0.01分/4.41分 | step: 192000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 192507 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 192510 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 193021 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:755/2000, 耗时:0.01分/4.44分 | step: 193280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 193530 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 193532 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 193536 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 193785 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 193791 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:760/2000, 耗时:0.01分/4.47分 | step: 194560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:765/2000, 耗时:0.01分/4.50分 | step: 195840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 196859 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 196862 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:770/2000, 耗时:0.01分/4.53分 | step: 197120 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 197373 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 197882 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 197884 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 197888 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 198137 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 198143 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:775/2000, 耗时:0.01分/4.56分 | step: 198400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:780/2000, 耗时:0.01分/4.59分 | step: 199680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:785/2000, 耗时:0.01分/4.62分 | step: 200960 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 201211 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 201214 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 201725 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 202234 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 202236 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 202240 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:790/2000, 耗时:0.01分/4.65分 | step: 202240 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 202489 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 202495 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:795/2000, 耗时:0.01分/4.67分 | step: 203520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:800/2000, 耗时:0.01分/4.70分 | step: 204800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 205563 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 205566 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 206077 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:805/2000, 耗时:0.01分/4.73分 | step: 206080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 206586 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 206588 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 206592 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 206841 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 206847 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:810/2000, 耗时:0.01分/4.76分 | step: 207360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:815/2000, 耗时:0.01分/4.79分 | step: 208640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 209915 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 209918 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:820/2000, 耗时:0.01分/4.82分 | step: 209920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 210429 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 210938 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 210940 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 210944 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 211193 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 211199 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:825/2000, 耗时:0.01分/4.85分 | step: 211200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:830/2000, 耗时:0.01分/4.88分 | step: 212480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:835/2000, 耗时:0.01分/4.91分 | step: 213760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 214267 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 214270 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 214781 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:840/2000, 耗时:0.01分/4.94分 | step: 215040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 215290 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 215292 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 215296 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 215545 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 215551 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:845/2000, 耗时:0.01分/4.97分 | step: 216320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:850/2000, 耗时:0.01分/5.00分 | step: 217600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 218619 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 218622 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:855/2000, 耗时:0.01分/5.03分 | step: 218880 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 219133 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 219642 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 219644 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 219648 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 219897 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 219903 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:860/2000, 耗时:0.01分/5.06分 | step: 220160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:865/2000, 耗时:0.01分/5.09分 | step: 221440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:870/2000, 耗时:0.01分/5.12分 | step: 222720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 222971 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 222974 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 223485 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 223994 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 223996 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 224000 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:875/2000, 耗时:0.01分/5.15分 | step: 224000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 224249 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 224255 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:880/2000, 耗时:0.01分/5.17分 | step: 225280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:885/2000, 耗时:0.01分/5.20分 | step: 226560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 227323 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 227326 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 227837 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:890/2000, 耗时:0.01分/5.23分 | step: 227840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 228346 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 228348 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 228352 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 228601 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 228607 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:895/2000, 耗时:0.01分/5.26分 | step: 229120 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:900/2000, 耗时:0.01分/5.29分 | step: 230400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 231675 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 231678 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:905/2000, 耗时:0.01分/5.32分 | step: 231680 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 232189 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 232698 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 232700 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 232704 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 232953 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 232959 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:910/2000, 耗时:0.01分/5.35分 | step: 232960 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:915/2000, 耗时:0.01分/5.38分 | step: 234240 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:920/2000, 耗时:0.01分/5.41分 | step: 235520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 236027 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 236030 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 236541 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:925/2000, 耗时:0.01分/5.44分 | step: 236800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 237050 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 237052 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 237056 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 237305 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 237311 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:930/2000, 耗时:0.01分/5.47分 | step: 238080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:935/2000, 耗时:0.01分/5.50分 | step: 239360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 240379 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 240382 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:940/2000, 耗时:0.01分/5.53分 | step: 240640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 240893 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 241402 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 241404 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 241408 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 241657 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 241663 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:945/2000, 耗时:0.01分/5.56分 | step: 241920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:950/2000, 耗时:0.01分/5.59分 | step: 243200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:955/2000, 耗时:0.01分/5.62分 | step: 244480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 244731 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 244734 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 245245 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 245754 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 245756 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 245760 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:960/2000, 耗时:0.01分/5.65分 | step: 245760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 246009 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 246015 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:965/2000, 耗时:0.01分/5.68分 | step: 247040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:970/2000, 耗时:0.01分/5.70分 | step: 248320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 249083 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 249086 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 249597 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:975/2000, 耗时:0.01分/5.73分 | step: 249600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 250106 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 250108 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 250112 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 250361 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 250367 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:980/2000, 耗时:0.01分/5.76分 | step: 250880 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:985/2000, 耗时:0.01分/5.79分 | step: 252160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 253435 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 253438 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:990/2000, 耗时:0.01分/5.82分 | step: 253440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 253949 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 254458 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 254460 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 254464 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 254713 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 254719 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:995/2000, 耗时:0.01分/5.85分 | step: 254720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1000/2000, 耗时:0.01分/5.88分 | step: 256000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1005/2000, 耗时:0.01分/5.91分 | step: 257280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 257787 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 257790 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 258301 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:1010/2000, 耗时:0.01分/5.94分 | step: 258560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 258810 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 258812 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 258816 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 259065 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 259071 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:1015/2000, 耗时:0.01分/5.97分 | step: 259840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1020/2000, 耗时:0.01分/6.00分 | step: 261120 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 262139 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 262142 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:1025/2000, 耗时:0.01分/6.02分 | step: 262400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 262653 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 263162 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 263164 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 263168 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 263417 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 263423 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
update:1030/2000, 耗时:0.01分/6.05分 | step: 263680 | performance: 1.0 | accuracy: 0.00 | loss: 0.28
update:1035/2000, 耗时:0.01分/6.08分 | step: 264960 | performance: 1.1 | accuracy: 0.14 | loss: 0.60
update:1040/2000, 耗时:0.01分/6.11分 | step: 266240 | performance: 1.1 | accuracy: 0.14 | loss: 0.47
update:1045/2000, 耗时:0.01分/6.14分 | step: 267520 | performance: 2.0 | accuracy: 0.16 | loss: 0.46
update:1050/2000, 耗时:0.01分/6.16分 | step: 268800 | performance: 1.8 | accuracy: 0.16 | loss: 0.85
update:1055/2000, 耗时:0.01分/6.19分 | step: 270080 | performance: 1.6 | accuracy: 0.14 | loss: 0.57
update:1060/2000, 耗时:0.01分/6.22分 | step: 271360 | performance: 2.1 | accuracy: 0.13 | loss: 0.18
update:1065/2000, 耗时:0.01分/6.25分 | step: 272640 | performance: 2.0 | accuracy: 0.13 | loss: 0.43
update:1070/2000, 耗时:0.01分/6.27分 | step: 273920 | performance: 1.3 | accuracy: 0.11 | loss: 0.11
update:1075/2000, 耗时:0.01分/6.30分 | step: 275200 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 275966 | worker_5@n_step_31: average total_reward after train data exhaustion : 4.8 | max total_reward: 131.5
step: 276223 | worker_6@n_step_31: average total_reward after train data exhaustion : 4.7 | max total_reward: 131.5
update:1080/2000, 耗时:0.01分/6.33分 | step: 276480 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 277243 | worker_2@n_step_31: average total_reward after train data exhaustion : 2.3 | max total_reward: 131.5
update:1085/2000, 耗时:0.01分/6.36分 | step: 277760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 278266 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 131.5
step: 278521 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 131.5
step: 278528 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 131.5
step: 278781 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 131.5
update:1090/2000, 耗时:0.01分/6.39分 | step: 279040 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 279292 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 131.5
step: 280318 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 131.5
update:1095/2000, 耗时:0.01分/6.42分 | step: 280320 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 280575 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 131.5
step: 281595 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
update:1100/2000, 耗时:0.01分/6.45分 | step: 281600 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:1105/2000, 耗时:0.01分/6.48分 | step: 282880 | performance: 1.2 | accuracy: 0.15 | loss: 0.66
step: 283899 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 131.5
update:1110/2000, 耗时:0.01分/6.51分 | step: 284160 | performance: 0.9 | accuracy: 0.06 | loss: 0.48
step: 284921 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 131.5
step: 284925 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 131.5
step: 285184 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 131.5
step: 285436 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 131.5
update:1115/2000, 耗时:0.01分/6.54分 | step: 285440 | performance: 1.0 | accuracy: 0.00 | loss: 0.34
step: 285691 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 131.5
step: 285693 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 131.5
update:1120/2000, 耗时:0.01分/6.56分 | step: 286720 | performance: 1.7 | accuracy: 0.17 | loss: 1.22
update:1125/2000, 耗时:0.01分/6.59分 | step: 288000 | performance: 2.2 | accuracy: 0.14 | loss: 0.60
update:1130/2000, 耗时:0.01分/6.62分 | step: 289280 | performance: 1.9 | accuracy: 0.13 | loss: 0.57
update:1135/2000, 耗时:0.01分/6.65分 | step: 290560 | performance: 2.3 | accuracy: 0.14 | loss: 0.72
update:1140/2000, 耗时:0.01分/6.68分 | step: 291840 | performance: 1.7 | accuracy: 0.15 | loss: 0.91
update:1145/2000, 耗时:0.01分/6.70分 | step: 293120 | performance: 1.7 | accuracy: 0.14 | loss: 0.43
update:1150/2000, 耗时:0.01分/6.73分 | step: 294400 | performance: 1.6 | accuracy: 0.12 | loss: 0.13
update:1155/2000, 耗时:0.01分/6.76分 | step: 295680 | performance: 1.6 | accuracy: 0.12 | loss: 0.18
update:1160/2000, 耗时:0.01分/6.79分 | step: 296960 | performance: 1.7 | accuracy: 0.11 | loss: 0.13
step: 297981 | worker_4@n_step_31: average total_reward after train data exhaustion : 3.7 | max total_reward: 131.5
step: 298238 | worker_5@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 131.5
step: 298239 | worker_6@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 131.5
update:1165/2000, 耗时:0.01分/6.82分 | step: 298240 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
update:1170/2000, 耗时:0.01分/6.85分 | step: 299520 | performance: 0.9 | accuracy: 0.00 | loss: 0.19
update:1175/2000, 耗时:0.01分/6.87分 | step: 300800 | performance: 1.1 | accuracy: 0.11 | loss: 0.29
step: 301054 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 131.5
step: 301305 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 131.5
update:1180/2000, 耗时:0.01分/6.90分 | step: 302080 | performance: 1.4 | accuracy: 0.18 | loss: 0.63
update:1185/2000, 耗时:0.01分/6.93分 | step: 303360 | performance: 1.7 | accuracy: 0.15 | loss: 0.48
update:1190/2000, 耗时:0.01分/6.96分 | step: 304640 | performance: 1.8 | accuracy: 0.14 | loss: 0.56
update:1195/2000, 耗时:0.01分/6.99分 | step: 305920 | performance: 3.1 | accuracy: 0.15 | loss: 0.99
update:1200/2000, 耗时:0.01分/7.02分 | step: 307200 | performance: 2.4 | accuracy: 0.14 | loss: 0.51
update:1205/2000, 耗时:0.01分/7.05分 | step: 308480 | performance: 2.3 | accuracy: 0.13 | loss: 0.26
update:1210/2000, 耗时:0.01分/7.08分 | step: 309760 | performance: 2.4 | accuracy: 0.11 | loss: 0.18
update:1215/2000, 耗时:0.01分/7.11分 | step: 311040 | performance: 2.9 | accuracy: 0.11 | loss: 0.37
update:1220/2000, 耗时:0.01分/7.14分 | step: 312320 | performance: 2.8 | accuracy: 0.11 | loss: 0.18
update:1225/2000, 耗时:0.01分/7.16分 | step: 313600 | performance: 1.0 | accuracy: 0.09 | loss: 0.36
update:1230/2000, 耗时:0.01分/7.19分 | step: 314880 | performance: 1.1 | accuracy: 0.07 | loss: 0.57
step: 315641 | worker_0@n_step_31: average total_reward after train data exhaustion : 3.9 | max total_reward: 131.5
step: 315903 | worker_6@n_step_31: average total_reward after train data exhaustion : 3.9 | max total_reward: 131.5
update:1235/2000, 耗时:0.01分/7.22分 | step: 316160 | performance: 1.0 | accuracy: 0.11 | loss: 0.29
update:1240/2000, 耗时:0.01分/7.25分 | step: 317440 | performance: 1.7 | accuracy: 0.16 | loss: 0.66
step: 318715 | worker_2@n_step_31: average total_reward after train data exhaustion : 2.7 | max total_reward: 131.5
update:1245/2000, 耗时:0.01分/7.28分 | step: 318720 | performance: 1.5 | accuracy: 0.11 | loss: 0.34
step: 318976 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.9 | max total_reward: 131.5
update:1250/2000, 耗时:0.01分/7.31分 | step: 320000 | performance: 1.0 | accuracy: 0.50 | loss: 0.37
step: 320256 | worker_7@n_step_31: average total_reward after train data exhaustion : 3.8 | max total_reward: 131.5
step: 320766 | worker_5@n_step_31: average total_reward after train data exhaustion : 5.4 | max total_reward: 131.5
update:1255/2000, 耗时:0.01分/7.33分 | step: 321280 | performance: 1.0 | accuracy: 0.11 | loss: 0.19
step: 321531 | worker_2@n_step_31: average total_reward after train data exhaustion : 2.2 | max total_reward: 131.5
step: 322554 | worker_1@n_step_31: average total_reward after train data exhaustion : 2.6 | max total_reward: 131.5
update:1260/2000, 耗时:0.01分/7.36分 | step: 322560 | performance: 1.3 | accuracy: 0.20 | loss: 0.65
update:1265/2000, 耗时:0.01分/7.39分 | step: 323840 | performance: 1.1 | accuracy: 0.14 | loss: 0.32
update:1270/2000, 耗时:0.01分/7.42分 | step: 325120 | performance: 1.6 | accuracy: 0.21 | loss: 1.24
update:1275/2000, 耗时:0.01分/7.45分 | step: 326400 | performance: 3.1 | accuracy: 0.27 | loss: 1.83
update:1280/2000, 耗时:0.01分/7.48分 | step: 327680 | performance: 4.4 | accuracy: 0.29 | loss: 1.79
update:1285/2000, 耗时:0.01分/7.51分 | step: 328960 | performance: 8.9 | accuracy: 0.27 | loss: 0.75
update:1290/2000, 耗时:0.01分/7.54分 | step: 330240 | performance: 6.5 | accuracy: 0.25 | loss: 0.63
update:1295/2000, 耗时:0.01分/7.57分 | step: 331520 | performance: 5.1 | accuracy: 0.22 | loss: 0.47
update:1300/2000, 耗时:0.00分/7.60分 | step: 332800 | performance: 3.7 | accuracy: 0.19 | loss: 0.08
update:1305/2000, 耗时:0.00分/7.62分 | step: 334080 | performance: 4.7 | accuracy: 0.18 | loss: 0.28
update:1310/2000, 耗时:0.01分/7.65分 | step: 335360 | performance: 4.8 | accuracy: 0.16 | loss: 0.35
update:1315/2000, 耗时:0.01分/7.68分 | step: 336640 | performance: 4.0 | accuracy: 0.15 | loss: 0.17
update:1320/2000, 耗时:0.01分/7.71分 | step: 337920 | performance: 3.8 | accuracy: 0.14 | loss: 0.08
update:1325/2000, 耗时:0.01分/7.73分 | step: 339200 | performance: 3.8 | accuracy: 0.14 | loss: 0.09
update:1330/2000, 耗时:0.01分/7.76分 | step: 340480 | performance: 3.8 | accuracy: 0.13 | loss: 0.07
step: 341503 | worker_6@n_step_31: average total_reward after train data exhaustion : 2.5 | max total_reward: 131.5
step: 341753 | worker_0@n_step_31: average total_reward after train data exhaustion : 2.4 | max total_reward: 131.5
update:1335/2000, 耗时:0.01分/7.79分 | step: 341760 | performance: 2.9 | accuracy: 0.12 | loss: 0.03
update:1340/2000, 耗时:0.01分/7.82分 | step: 343040 | performance: 2.9 | accuracy: 0.11 | loss: 0.10
step: 344059 | worker_2@n_step_31: average total_reward after train data exhaustion : 5.2 | max total_reward: 131.5
update:1345/2000, 耗时:0.01分/7.85分 | step: 344320 | performance: 2.9 | accuracy: 0.11 | loss: 0.09
step: 344828 | worker_3@n_step_31: average total_reward after train data exhaustion : 2.1 | max total_reward: 131.5
step: 345085 | worker_4@n_step_31: average total_reward after train data exhaustion : 2.2 | max total_reward: 131.5
update:1350/2000, 耗时:0.01分/7.88分 | step: 345600 | performance: 2.7 | accuracy: 0.10 | loss: 0.13
step: 345855 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 131.5
step: 346362 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 131.5
update:1355/2000, 耗时:0.01分/7.90分 | step: 346880 | performance: 2.8 | accuracy: 0.10 | loss: 0.44
step: 347390 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 131.5
step: 348155 | worker_2@n_step_31: average total_reward after train data exhaustion : 3.1 | max total_reward: 131.5
step: 348156 | worker_3@n_step_31: average total_reward after train data exhaustion : 3.0 | max total_reward: 131.5
update:1360/2000, 耗时:0.01分/7.93分 | step: 348160 | performance: 1.0 | accuracy: 0.00 | loss: 0.39
step: 348415 | worker_6@n_step_31: average total_reward after train data exhaustion : 2.9 | max total_reward: 131.5
step: 348669 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 131.5
update:1365/2000, 耗时:0.01分/7.96分 | step: 349440 | performance: 1.0 | accuracy: 0.11 | loss: 0.43
update:1370/2000, 耗时:0.01分/7.99分 | step: 350720 | performance: 1.1 | accuracy: 0.10 | loss: 0.61
update:1375/2000, 耗时:0.01分/8.02分 | step: 352000 | performance: 1.3 | accuracy: 0.17 | loss: 0.70
update:1380/2000, 耗时:0.01分/8.05分 | step: 353280 | performance: 1.5 | accuracy: 0.12 | loss: 0.73
update:1385/2000, 耗时:0.01分/8.08分 | step: 354560 | performance: 1.0 | accuracy: 0.00 | loss: 0.44
update:1390/2000, 耗时:0.01分/8.10分 | step: 355840 | performance: 1.5 | accuracy: 0.18 | loss: 1.01
update:1395/2000, 耗时:0.01分/8.13分 | step: 357120 | performance: 1.9 | accuracy: 0.15 | loss: 0.56
update:1400/2000, 耗时:0.01分/8.16分 | step: 358400 | performance: 1.8 | accuracy: 0.11 | loss: 0.55
update:1405/2000, 耗时:0.01分/8.19分 | step: 359680 | performance: 1.8 | accuracy: 0.12 | loss: 0.85
update:1410/2000, 耗时:0.01分/8.22分 | step: 360960 | performance: 1.7 | accuracy: 0.12 | loss: 0.47
update:1415/2000, 耗时:0.01分/8.25分 | step: 362240 | performance: 1.7 | accuracy: 0.12 | loss: 0.57
update:1420/2000, 耗时:0.01分/8.28分 | step: 363520 | performance: 1.5 | accuracy: 0.11 | loss: 0.52
update:1425/2000, 耗时:0.01分/8.30分 | step: 364800 | performance: 1.5 | accuracy: 0.11 | loss: 0.85
update:1430/2000, 耗时:0.01分/8.34分 | step: 366080 | performance: 1.7 | accuracy: 0.11 | loss: 0.48
update:1435/2000, 耗时:0.01分/8.36分 | step: 367360 | performance: 1.8 | accuracy: 0.11 | loss: 2.14
update:1440/2000, 耗时:0.01分/8.39分 | step: 368640 | performance: 1.5 | accuracy: 0.11 | loss: 0.37
update:1445/2000, 耗时:0.01分/8.42分 | step: 369920 | performance: 1.4 | accuracy: 0.11 | loss: 0.55
update:1450/2000, 耗时:0.01分/8.45分 | step: 371200 | performance: 1.2 | accuracy: 0.11 | loss: 0.14
step: 372478 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.5 | max total_reward: 131.5
update:1455/2000, 耗时:0.01分/8.48分 | step: 372480 | performance: 1.1 | accuracy: 0.10 | loss: 0.15
step: 373248 | worker_7@n_step_31: average total_reward after train data exhaustion : 4.8 | max total_reward: 131.5
update:1460/2000, 耗时:0.01分/8.51分 | step: 373760 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 374015 | worker_6@n_step_31: average total_reward after train data exhaustion : 7.1 | max total_reward: 131.5
update:1465/2000, 耗时:0.01分/8.54分 | step: 375040 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 375803 | worker_2@n_step_31: average total_reward after train data exhaustion : 3.9 | max total_reward: 131.5
step: 376060 | worker_3@n_step_31: average total_reward after train data exhaustion : 3.9 | max total_reward: 131.5
step: 376318 | worker_5@n_step_31: average total_reward after train data exhaustion : 3.9 | max total_reward: 131.5
update:1470/2000, 耗时:0.01分/8.57分 | step: 376320 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 377338 | worker_1@n_step_31: average total_reward after train data exhaustion : 2.3 | max total_reward: 131.5
step: 377600 | worker_7@n_step_31: average total_reward after train data exhaustion : 2.4 | max total_reward: 131.5
update:1475/2000, 耗时:0.01分/8.60分 | step: 377600 | performance: 1.0 | accuracy: 0.00 | loss: 0.35
update:1480/2000, 耗时:0.01分/8.63分 | step: 378880 | performance: 0.9 | accuracy: 0.11 | loss: 0.29
step: 379392 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 131.5
step: 379644 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 131.5
update:1485/2000, 耗时:0.01分/8.66分 | step: 380160 | performance: 1.1 | accuracy: 0.15 | loss: 0.44
update:1490/2000, 耗时:0.01分/8.69分 | step: 381440 | performance: 1.0 | accuracy: 0.00 | loss: 0.56
step: 381951 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 131.5
update:1495/2000, 耗时:0.01分/8.72分 | step: 382720 | performance: 0.8 | accuracy: 0.12 | loss: 1.03
update:1500/2000, 耗时:0.01分/8.75分 | step: 384000 | performance: 1.0 | accuracy: 0.12 | loss: 0.55
update:1505/2000, 耗时:0.01分/8.78分 | step: 385280 | performance: 1.0 | accuracy: 0.12 | loss: 0.29
update:1510/2000, 耗时:0.01分/8.80分 | step: 386560 | performance: 1.0 | accuracy: 0.12 | loss: 0.50
update:1515/2000, 耗时:0.01分/8.83分 | step: 387840 | performance: 1.1 | accuracy: 0.11 | loss: 0.31
step: 389115 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 131.5
update:1520/2000, 耗时:0.01分/8.86分 | step: 389120 | performance: 1.0 | accuracy: 0.10 | loss: 0.21
step: 390140 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 131.5
step: 390141 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.6 | max total_reward: 131.5
step: 390398 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.5 | max total_reward: 131.5
update:1525/2000, 耗时:0.01分/8.89分 | step: 390400 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 391673 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 391679 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 391680 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
update:1530/2000, 耗时:0.01分/8.92分 | step: 391680 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 392954 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 131.5
step: 392955 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 131.5
update:1535/2000, 耗时:0.01分/8.95分 | step: 392960 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 393469 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 131.5
update:1540/2000, 耗时:0.01分/8.98分 | step: 394240 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
update:1545/2000, 耗时:0.01分/9.00分 | step: 395520 | performance: 1.1 | accuracy: 0.20 | loss: 0.84
update:1550/2000, 耗时:0.01分/9.03分 | step: 396800 | performance: 1.5 | accuracy: 0.12 | loss: 0.49
update:1555/2000, 耗时:0.01分/9.06分 | step: 398080 | performance: 2.1 | accuracy: 0.11 | loss: 0.34
update:1560/2000, 耗时:0.01分/9.09分 | step: 399360 | performance: 2.5 | accuracy: 0.12 | loss: 1.05
update:1565/2000, 耗时:0.01分/9.12分 | step: 400640 | performance: 4.9 | accuracy: 0.14 | loss: 0.79
update:1570/2000, 耗时:0.01分/9.15分 | step: 401920 | performance: 3.5 | accuracy: 0.14 | loss: 0.43
update:1575/2000, 耗时:0.01分/9.18分 | step: 403200 | performance: 3.0 | accuracy: 0.12 | loss: 0.13
update:1580/2000, 耗时:0.01分/9.20分 | step: 404480 | performance: 3.8 | accuracy: 0.11 | loss: 0.10
update:1585/2000, 耗时:0.01分/9.23分 | step: 405760 | performance: 4.0 | accuracy: 0.10 | loss: 0.25
step: 406013 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 131.5
update:1590/2000, 耗时:0.01分/9.26分 | step: 407040 | performance: 1.0 | accuracy: 0.00 | loss: 0.32
step: 407291 | worker_2@n_step_31: average total_reward after train data exhaustion : 5.8 | max total_reward: 131.5
update:1595/2000, 耗时:0.01分/9.29分 | step: 408320 | performance: 1.2 | accuracy: 0.11 | loss: 0.68
step: 408572 | worker_3@n_step_31: average total_reward after train data exhaustion : 3.6 | max total_reward: 131.5
update:1600/2000, 耗时:0.01分/9.32分 | step: 409600 | performance: 1.0 | accuracy: 0.13 | loss: 0.67
step: 410624 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.6 | max total_reward: 131.5
update:1605/2000, 耗时:0.01分/9.35分 | step: 410880 | performance: 0.8 | accuracy: 0.00 | loss: 0.50
update:1610/2000, 耗时:0.01分/9.38分 | step: 412160 | performance: 1.3 | accuracy: 0.14 | loss: 0.61
step: 413184 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 131.5
update:1615/2000, 耗时:0.01分/9.41分 | step: 413440 | performance: 1.0 | accuracy: 0.16 | loss: 0.91
update:1620/2000, 耗时:0.01分/9.44分 | step: 414720 | performance: 1.0 | accuracy: 0.00 | loss: 0.35
step: 414976 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 131.5
step: 415486 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.3 | max total_reward: 131.5
update:1625/2000, 耗时:0.01分/9.47分 | step: 416000 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
step: 416511 | worker_6@n_step_31: average total_reward after train data exhaustion : 3.0 | max total_reward: 131.5
update:1630/2000, 耗时:0.01分/9.51分 | step: 417280 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
update:1635/2000, 耗时:0.01分/9.54分 | step: 418560 | performance: 1.0 | accuracy: 0.00 | loss: 0.32
step: 418810 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 131.5
update:1640/2000, 耗时:0.01分/9.57分 | step: 419840 | performance: 1.2 | accuracy: 0.15 | loss: 0.78
update:1645/2000, 耗时:0.01分/9.60分 | step: 421120 | performance: 1.6 | accuracy: 0.13 | loss: 0.93
update:1650/2000, 耗时:0.01分/9.63分 | step: 422400 | performance: 1.6 | accuracy: 0.13 | loss: 0.72
update:1655/2000, 耗时:0.01分/9.66分 | step: 423680 | performance: 3.3 | accuracy: 0.15 | loss: 1.00
update:1660/2000, 耗时:0.01分/9.68分 | step: 424960 | performance: 2.6 | accuracy: 0.15 | loss: 1.01
update:1665/2000, 耗时:0.01分/9.72分 | step: 426240 | performance: 1.5 | accuracy: 0.14 | loss: 0.34
update:1670/2000, 耗时:0.01分/9.74分 | step: 427520 | performance: 1.8 | accuracy: 0.13 | loss: 0.30
update:1675/2000, 耗时:0.01分/9.77分 | step: 428800 | performance: 3.1 | accuracy: 0.14 | loss: 0.67
update:1680/2000, 耗时:0.01分/9.80分 | step: 430080 | performance: 3.6 | accuracy: 0.14 | loss: 0.56
update:1685/2000, 耗时:0.01分/9.83分 | step: 431360 | performance: 4.1 | accuracy: 0.13 | loss: 0.36
update:1690/2000, 耗时:0.01分/9.86分 | step: 432640 | performance: 3.7 | accuracy: 0.13 | loss: 0.39
update:1695/2000, 耗时:0.01分/9.89分 | step: 433920 | performance: 3.6 | accuracy: 0.12 | loss: 0.26
step: 434427 | worker_2@n_step_31: average total_reward after train data exhaustion : 2.7 | max total_reward: 131.5
update:1700/2000, 耗时:0.01分/9.91分 | step: 435200 | performance: 3.3 | accuracy: 0.12 | loss: 0.08
update:1705/2000, 耗时:0.01分/9.94分 | step: 436480 | performance: 3.3 | accuracy: 0.11 | loss: 0.15
step: 437502 | worker_5@n_step_31: average total_reward after train data exhaustion : 3.3 | max total_reward: 131.5
update:1710/2000, 耗时:0.01分/9.97分 | step: 437760 | performance: 3.2 | accuracy: 0.10 | loss: 0.16
step: 438527 | worker_6@n_step_31: average total_reward after train data exhaustion : 3.7 | max total_reward: 131.5
step: 438779 | worker_2@n_step_31: average total_reward after train data exhaustion : 3.7 | max total_reward: 131.5
update:1715/2000, 耗时:0.01分/10.00分 | step: 439040 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 439549 | worker_4@n_step_31: average total_reward after train data exhaustion : 5.1 | max total_reward: 131.5
step: 439552 | worker_7@n_step_31: average total_reward after train data exhaustion : 5.2 | max total_reward: 131.5
step: 440058 | worker_1@n_step_31: average total_reward after train data exhaustion : 3.8 | max total_reward: 131.5
update:1720/2000, 耗时:0.01分/10.03分 | step: 440320 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 441342 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 131.5
update:1725/2000, 耗时:0.01分/10.06分 | step: 441600 | performance: 1.0 | accuracy: 0.00 | loss: 0.30
step: 441855 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.8 | max total_reward: 131.5
step: 442622 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 131.5
step: 442874 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 131.5
update:1730/2000, 耗时:0.01分/10.09分 | step: 442880 | performance: 1.0 | accuracy: 0.14 | loss: 0.30
update:1735/2000, 耗时:0.01分/10.11分 | step: 444160 | performance: 1.3 | accuracy: 0.14 | loss: 0.32
update:1740/2000, 耗时:0.01分/10.14分 | step: 445440 | performance: 1.6 | accuracy: 0.13 | loss: 0.37
update:1745/2000, 耗时:0.01分/10.17分 | step: 446720 | performance: 1.0 | accuracy: 0.00 | loss: 0.97
update:1750/2000, 耗时:0.01分/10.20分 | step: 448000 | performance: 1.3 | accuracy: 0.21 | loss: 0.67
update:1755/2000, 耗时:0.01分/10.23分 | step: 449280 | performance: 2.0 | accuracy: 0.19 | loss: 1.43
update:1760/2000, 耗时:0.01分/10.25分 | step: 450560 | performance: 1.3 | accuracy: 0.16 | loss: 0.90
update:1765/2000, 耗时:0.01分/10.28分 | step: 451840 | performance: 1.5 | accuracy: 0.16 | loss: 0.68
update:1770/2000, 耗时:0.01分/10.31分 | step: 453120 | performance: 1.4 | accuracy: 0.14 | loss: 0.37
update:1775/2000, 耗时:0.01分/10.34分 | step: 454400 | performance: 1.5 | accuracy: 0.14 | loss: 0.30
update:1780/2000, 耗时:0.01分/10.37分 | step: 455680 | performance: 1.4 | accuracy: 0.12 | loss: 0.14
update:1785/2000, 耗时:0.01分/10.40分 | step: 456960 | performance: 1.7 | accuracy: 0.11 | loss: 0.23
update:1790/2000, 耗时:0.01分/10.42分 | step: 458240 | performance: 1.1 | accuracy: 0.11 | loss: 0.05
step: 458492 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.6 | max total_reward: 131.5
update:1795/2000, 耗时:0.01分/10.45分 | step: 459520 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
update:1800/2000, 耗时:0.01分/10.48分 | step: 460800 | performance: 1.1 | accuracy: 0.08 | loss: 0.06
step: 461821 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 462073 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 131.5
update:1805/2000, 耗时:0.01分/10.51分 | step: 462080 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 462330 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 462331 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 462332 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 462335 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
step: 462336 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 131.5
update:1810/2000, 耗时:0.01分/10.54分 | step: 463360 | performance: 1.3 | accuracy: 0.15 | loss: 0.45
update:1815/2000, 耗时:0.01分/10.57分 | step: 464640 | performance: 1.1 | accuracy: 0.08 | loss: 0.31
step: 464890 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.5 | max total_reward: 131.5
step: 464894 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.4 | max total_reward: 131.5
step: 465152 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 131.5
update:1820/2000, 耗时:0.01分/10.59分 | step: 465920 | performance: 1.2 | accuracy: 0.20 | loss: 0.73
step: 466429 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 131.5
step: 466940 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 131.5
update:1825/2000, 耗时:0.01分/10.62分 | step: 467200 | performance: 1.1 | accuracy: 0.12 | loss: 0.36
update:1830/2000, 耗时:0.01分/10.65分 | step: 468480 | performance: 1.0 | accuracy: 0.00 | loss: 1.04
update:1835/2000, 耗时:0.01分/10.68分 | step: 469760 | performance: 1.1 | accuracy: 0.17 | loss: 0.54
update:1840/2000, 耗时:0.01分/10.71分 | step: 471040 | performance: 1.2 | accuracy: 0.16 | loss: 0.65
update:1845/2000, 耗时:0.01分/10.73分 | step: 472320 | performance: 1.2 | accuracy: 0.14 | loss: 1.02
update:1850/2000, 耗时:0.01分/10.76分 | step: 473600 | performance: 1.6 | accuracy: 0.13 | loss: 0.44
update:1855/2000, 耗时:0.01分/10.79分 | step: 474880 | performance: 1.7 | accuracy: 0.12 | loss: 0.15
update:1860/2000, 耗时:0.01分/10.82分 | step: 476160 | performance: 1.7 | accuracy: 0.11 | loss: 0.04
step: 476415 | worker_6@n_step_31: average total_reward after train data exhaustion : 2.6 | max total_reward: 131.5
update:1865/2000, 耗时:0.01分/10.85分 | step: 477440 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
step: 477691 | worker_2@n_step_31: average total_reward after train data exhaustion : 3.0 | max total_reward: 131.5
step: 478461 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 131.5
update:1870/2000, 耗时:0.01分/10.87分 | step: 478720 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
step: 478976 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 131.5
update:1875/2000, 耗时:0.01分/10.90分 | step: 480000 | performance: 1.1 | accuracy: 0.14 | loss: 0.40
update:1880/2000, 耗时:0.01分/10.93分 | step: 481280 | performance: 1.0 | accuracy: 0.00 | loss: 0.36
step: 482042 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 131.5
update:1885/2000, 耗时:0.01分/10.96分 | step: 482560 | performance: 1.0 | accuracy: 0.17 | loss: 0.65
step: 483070 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 131.5
update:1890/2000, 耗时:0.01分/10.98分 | step: 483840 | performance: 1.4 | accuracy: 0.11 | loss: 0.46
update:1895/2000, 耗时:0.01分/11.01分 | step: 485120 | performance: 1.0 | accuracy: 0.00 | loss: 0.55
update:1900/2000, 耗时:0.01分/11.04分 | step: 486400 | performance: 1.4 | accuracy: 0.15 | loss: 1.01
update:1905/2000, 耗时:0.01分/11.07分 | step: 487680 | performance: 1.2 | accuracy: 0.15 | loss: 0.44
update:1910/2000, 耗时:0.01分/11.10分 | step: 488960 | performance: 1.1 | accuracy: 0.14 | loss: 0.50
update:1915/2000, 耗时:0.01分/11.12分 | step: 490240 | performance: 1.1 | accuracy: 0.12 | loss: 0.32
update:1920/2000, 耗时:0.01分/11.15分 | step: 491520 | performance: 1.0 | accuracy: 0.11 | loss: 0.35
update:1925/2000, 耗时:0.01分/11.18分 | step: 492800 | performance: 1.0 | accuracy: 0.00 | loss: 0.53
update:1930/2000, 耗时:0.01分/11.21分 | step: 494080 | performance: 1.2 | accuracy: 0.18 | loss: 0.50
update:1935/2000, 耗时:0.01分/11.23分 | step: 495360 | performance: 1.2 | accuracy: 0.15 | loss: 0.80
update:1940/2000, 耗时:0.01分/11.26分 | step: 496640 | performance: 1.4 | accuracy: 0.12 | loss: 0.44
step: 497657 | worker_0@n_step_31: average total_reward after train data exhaustion : 4.1 | max total_reward: 150.6
update:1945/2000, 耗时:0.01分/11.29分 | step: 497920 | performance: 1.8 | accuracy: 0.13 | loss: 0.39
update:1950/2000, 耗时:0.01分/11.32分 | step: 499200 | performance: 2.8 | accuracy: 0.13 | loss: 0.44
update:1955/2000, 耗时:0.01分/11.35分 | step: 500480 | performance: 2.8 | accuracy: 0.13 | loss: 0.40
update:1960/2000, 耗时:0.01分/11.38分 | step: 501760 | performance: 2.3 | accuracy: 0.13 | loss: 0.48
update:1965/2000, 耗时:0.01分/11.41分 | step: 503040 | performance: 1.3 | accuracy: 0.11 | loss: 0.24
update:1970/2000, 耗时:0.01分/11.43分 | step: 504320 | performance: 1.2 | accuracy: 0.11 | loss: 0.50
step: 505081 | worker_0@n_step_31: average total_reward after train data exhaustion : 3.2 | max total_reward: 150.6
update:1975/2000, 耗时:0.01分/11.46分 | step: 505600 | performance: 1.4 | accuracy: 0.11 | loss: 0.39
update:1980/2000, 耗时:0.01分/11.49分 | step: 506880 | performance: 2.8 | accuracy: 0.11 | loss: 1.04
update:1985/2000, 耗时:0.01分/11.52分 | step: 508160 | performance: 2.5 | accuracy: 0.12 | loss: 0.77
update:1990/2000, 耗时:0.01分/11.55分 | step: 509440 | performance: 1.6 | accuracy: 0.11 | loss: 0.40
update:1995/2000, 耗时:0.01分/11.57分 | step: 510720 | performance: 1.0 | accuracy: 0.11 | loss: 0.47
step: 510971 | worker_2@n_step_31: average total_reward after train data exhaustion : 5.8 | max total_reward: 150.6
update:2000/2000, 耗时:0.01分/11.60分 | step: 512000 | performance: 0.8 | accuracy: 0.10 | loss: 0.33
----------------------------------------finished----------------------------------------
==================================================
2023-01-05T12:00:00 | *** START BACKTEST ***
2023-01-05T12:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/401 [00:00<?, ?it/s]100%|| 401/401 [00:00<00:00, 133602.03it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1011.45
2023-07-24T12:00:00 | net performance [%] = 1.1454
2023-07-24T12:00:00 | number of trades [#] = 2
==================================================
Trial 9 Complete [00h 12m 02s]
net_wealth: 1011.45446308841

Best net_wealth So Far: 1714.485333603393
Total elapsed time: 01h 07m 23s

Search: Running Trial #10

Value             |Best Value So Far |Hyperparameter
5                 |6                 |horizon
730               |225               |lookback
False             |True              |MarketFactor
20                |14                |lags
0.92              |0.85              |gamma
16                |32                |batch_size
20                |64                |n_step
0.99              |0.8               |gae_lambda
10                |2                 |gradient_clip_norm
5                 |3                 |epochs
0.0005            |0.001             |actor_lr
0.0005            |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4310.000000   4315.000000
mean      0.000441    20062.255222  ...   20136.939364  20118.633889
std       0.027818    16039.874230  ...   16077.430342  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7696.969971   7690.540039
50%       0.000642    11554.824463  ...   11742.710449  11715.610352
75%       0.011655    29873.081836  ...   29945.211914  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
22023-07-023-07-27 23:10:46.169468: I tensorflow/core/plat22023-07-27 23:102fo32-rm/cpu_7202f3-07-27eat 07-272 23:10:46.169473: I tensorflow 23:10:46.169507: I t/3:10ecor:n4e/pla6sorflow/c.t0:46.169467: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneuore/platDformfNN) /orctm16/9532:o cpu_Ip fteatue use nrsu_feature_guetha_grdue.c acfr:d14.o2clrec:low14_ig2] This TensorFlow binary is optimized with oneAPouard.ccr]f:l This ongwT/ ceoCPU inre/psorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU 1I Del4aneptfs tor2r]m/cpuNuce T_tions uhirfal sin e NpeatuTe2re_gu0t2i23wr0n2s3tru-f0ct-07-o7rk Li-i2b27oao rd.cc:142n2s3:0]1 0T h:2in 3is -p4T0enserfo76e.r-m1or7002na56r27rnarFlms :2oa orIFnw locwe37 b- criiti:nten sbi1aor2ca3rf0ny:lla 1 0ro(o:p4:y eraonye i64t6ionis .w/c.D1Ns:17N)0o7 0 AVX 0rAVXe 4to u/sep2
 olTatof otrh51semp/:c pt  imfIoo pt1lltuize0ice-emidowi n:ze dg wiennas_fewti hC crittah PIootiuU nteonrecrse_gnaleAuafAP i opePlrblII Ddn.sc oDeorerefloaece :tt1r4pwtpio2 /u cwn]N eTht/s:h em iiociso nsr eNc TieAVeore//urn pplanuspellralaatX  ANVettnfXf2o
rTom /Ncrwform /ocrokpo peunabl rue_fe_ fmtewaotrtkeaatnuch eumrre_eteheLL i_grorFl-nu opergiuiac abtirrridothot.acrde.riocwca rbib yn s(,raorn:o1n4eaDacyc :(1o4n22]Npe ]  TThhiirNry issebl esD NNo Tpe rTa) teo)t irnteoons,punstatiloi  soirmFuroerFol odbulsue izeow sTee nd  wn sb:bwiild Tienasitnhaer  othe rnt hAyVX roy ifFollf oAsno rlso ViXsF 2oeplotwlinoAwP Iglpiwmi  Deeitzh Ctthi
Topw meodPeU  iozwe Neadi nws twiw iriucutiopthng CtphroenPr iothnsa ia loUb np nle i ntehANnrsieAPIt Da etwork teeepeP It preuLcib rafpopNhoemmp iDcetelieor rrornsfpap rm eury ilniriana Neaua(  lr tgopoertaNnnheDls.c
e-cr NeNNereif t)t itewo ccalrorot oo upwoepmok rkamspeLeirai  tLirtanbtrbahieiroalrerc ef-olyycrr l  ((oflnioneonoawsiD,NgtenDNnNss.:
g CPU)i re  N) tA cto V X ouinsb al ue the usiloseperations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
tructions in  the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in otherd TensorFlopfollowing erformance-critical operations:  AVX AVX2
To enableAVX2
To enable them in other operations, rebuild TensorFCPU instructions in performanclow with the appropriate compiler flags.
 them inw operati other operations, rebuild TensorFlow with the a ons, rebuild TensorFlow with the approwe-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
ppiriate compiler flags.
propriateth the appropriate compiler flags.
 compiler flags.
2023-07-27 23:10:46.771674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:10:46.773773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:10:46.789316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:10:46.792166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:10:46.796148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:10:46.801679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:10:46.803094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:10:46.863843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.04分 | step:   800 | performance: 0.7 | accuracy: 0.33 | loss: 2.45
update: 10/2000, 耗时:0.00分/0.06分 | step:  1600 | performance: 5.4 | accuracy: 0.41 | loss: 1.14
update: 15/2000, 耗时:0.00分/0.08分 | step:  2400 | performance: 4.8 | accuracy: 0.36 | loss: 2.30
update: 20/2000, 耗时:0.00分/0.10分 | step:  3200 | performance: 4.0 | accuracy: 0.35 | loss: 1.46
update: 25/2000, 耗时:0.00分/0.13分 | step:  4000 | performance: 3.8 | accuracy: 0.32 | loss: 7.65
update: 30/2000, 耗时:0.00分/0.15分 | step:  4800 | performance: 7.3 | accuracy: 0.34 | loss: 6.85
update: 35/2000, 耗时:0.00分/0.17分 | step:  5600 | performance: 4.1 | accuracy: 0.36 | loss: 4.21
update: 40/2000, 耗时:0.00分/0.20分 | step:  6400 | performance: 1.1 | accuracy: 0.36 | loss: 3.39
update: 45/2000, 耗时:0.00分/0.22分 | step:  7200 | performance: 0.3 | accuracy: 0.35 | loss: 3.55
update: 50/2000, 耗时:0.00分/0.25分 | step:  8000 | performance: 0.2 | accuracy: 0.34 | loss: 1.98
update: 55/2000, 耗时:0.01分/0.27分 | step:  8800 | performance: 0.1 | accuracy: 0.34 | loss: 1.34
update: 60/2000, 耗时:0.00分/0.30分 | step:  9600 | performance: 0.1 | accuracy: 0.33 | loss: 2.04
update: 65/2000, 耗时:0.00分/0.32分 | step: 10400 | performance: 0.2 | accuracy: 0.33 | loss: 1.65
update: 70/2000, 耗时:0.00分/0.35分 | step: 11200 | performance: 0.2 | accuracy: 0.33 | loss: 1.71
update: 75/2000, 耗时:0.00分/0.37分 | step: 12000 | performance: 0.2 | accuracy: 0.33 | loss: 1.50
update: 80/2000, 耗时:0.01分/0.40分 | step: 12800 | performance: 0.2 | accuracy: 0.33 | loss: 1.58
update: 85/2000, 耗时:0.01分/0.42分 | step: 13600 | performance: 1.4 | accuracy: 0.33 | loss: 14.44
update: 90/2000, 耗时:0.01分/0.45分 | step: 14400 | performance: 11.9 | accuracy: 0.34 | loss: 11.04
update: 95/2000, 耗时:0.01分/0.47分 | step: 15200 | performance: 14.1 | accuracy: 0.35 | loss: 3.24
update:100/2000, 耗时:0.00分/0.50分 | step: 16000 | performance: 1.3 | accuracy: 0.35 | loss: 5.05
update:105/2000, 耗时:0.00分/0.52分 | step: 16800 | performance: 0.6 | accuracy: 0.34 | loss: 1.61
update:110/2000, 耗时:0.00分/0.55分 | step: 17600 | performance: 0.7 | accuracy: 0.34 | loss: 1.48
update:115/2000, 耗时:0.01分/0.57分 | step: 18400 | performance: 1.6 | accuracy: 0.34 | loss: 1.38
update:120/2000, 耗时:0.01分/0.60分 | step: 19200 | performance: 0.4 | accuracy: 0.33 | loss: 1.65
update:125/2000, 耗时:0.00分/0.62分 | step: 20000 | performance: 0.4 | accuracy: 0.33 | loss: 1.56
update:130/2000, 耗时:0.01分/0.65分 | step: 20800 | performance: 0.4 | accuracy: 0.33 | loss: 1.29
update:135/2000, 耗时:0.00分/0.67分 | step: 21600 | performance: 0.4 | accuracy: 0.32 | loss: 0.61
update:140/2000, 耗时:0.00分/0.70分 | step: 22400 | performance: 0.8 | accuracy: 0.32 | loss: 1.73
update:145/2000, 耗时:0.00分/0.72分 | step: 23200 | performance: 1.1 | accuracy: 0.31 | loss: 0.47
update:150/2000, 耗时:0.01分/0.75分 | step: 24000 | performance: 1.1 | accuracy: 0.30 | loss: 0.74
update:155/2000, 耗时:0.01分/0.77分 | step: 24800 | performance: 1.4 | accuracy: 0.30 | loss: 0.61
Saving PPO weights in both H5 format and checkpoint @ update:158 
update:160/2000, 耗时:0.00分/0.80分 | step: 25600 | performance: 1.0 | accuracy: 0.26 | loss: 0.51
update:165/2000, 耗时:0.00分/0.82分 | step: 26400 | performance: 1.2 | accuracy: 0.19 | loss: 0.64
update:170/2000, 耗时:0.00分/0.85分 | step: 27200 | performance: 1.3 | accuracy: 0.19 | loss: 1.29
update:175/2000, 耗时:0.00分/0.87分 | step: 28000 | performance: 1.5 | accuracy: 0.20 | loss: 2.36
update:180/2000, 耗时:0.00分/0.90分 | step: 28800 | performance: 1.3 | accuracy: 0.18 | loss: 0.34
update:185/2000, 耗时:0.00分/0.92分 | step: 29600 | performance: 2.2 | accuracy: 0.19 | loss: 5.49
update:190/2000, 耗时:0.00分/0.94分 | step: 30400 | performance: 3.8 | accuracy: 0.20 | loss: 1.69
update:195/2000, 耗时:0.00分/0.97分 | step: 31200 | performance: 3.2 | accuracy: 0.21 | loss: 1.78
update:200/2000, 耗时:0.00分/0.99分 | step: 32000 | performance: 2.1 | accuracy: 0.20 | loss: 1.16
update:205/2000, 耗时:0.00分/1.02分 | step: 32800 | performance: 1.9 | accuracy: 0.19 | loss: 1.22
update:210/2000, 耗时:0.00分/1.04分 | step: 33600 | performance: 2.9 | accuracy: 0.20 | loss: 2.39
update:215/2000, 耗时:0.00分/1.06分 | step: 34400 | performance: 5.9 | accuracy: 0.20 | loss: 1.05
update:220/2000, 耗时:0.00分/1.09分 | step: 35200 | performance: 5.5 | accuracy: 0.20 | loss: 1.91
update:225/2000, 耗时:0.00分/1.11分 | step: 36000 | performance: 3.4 | accuracy: 0.20 | loss: 0.92
update:230/2000, 耗时:0.00分/1.14分 | step: 36800 | performance: 4.6 | accuracy: 0.20 | loss: 3.87
update:235/2000, 耗时:0.00分/1.16分 | step: 37600 | performance: 6.4 | accuracy: 0.20 | loss: 0.80
update:240/2000, 耗时:0.00分/1.19分 | step: 38400 | performance: 20.0 | accuracy: 0.21 | loss: 1.98
update:245/2000, 耗时:0.00分/1.21分 | step: 39200 | performance: 111.5 | accuracy: 0.23 | loss: 15.24
update:250/2000, 耗时:0.00分/1.23分 | step: 40000 | performance: 1513.3 | accuracy: 0.25 | loss: 8.31
update:255/2000, 耗时:0.00分/1.26分 | step: 40800 | performance: 1049.0 | accuracy: 0.26 | loss: 7.29
update:260/2000, 耗时:0.00分/1.28分 | step: 41600 | performance: 114.6 | accuracy: 0.26 | loss: 12.49
update:265/2000, 耗时:0.00分/1.31分 | step: 42400 | performance: 230.0 | accuracy: 0.27 | loss: 5.02
update:270/2000, 耗时:0.00分/1.33分 | step: 43200 | performance: 223.6 | accuracy: 0.28 | loss: 3.47
update:275/2000, 耗时:0.00分/1.36分 | step: 44000 | performance: 416.2 | accuracy: 0.29 | loss: 12.11
update:280/2000, 耗时:0.00分/1.38分 | step: 44800 | performance: 87.9 | accuracy: 0.29 | loss: 9.24
update:285/2000, 耗时:0.00分/1.40分 | step: 45600 | performance: 61.1 | accuracy: 0.29 | loss: 4.51
update:290/2000, 耗时:0.00分/1.43分 | step: 46400 | performance: 55.5 | accuracy: 0.29 | loss: 5.52
update:295/2000, 耗时:0.00分/1.45分 | step: 47200 | performance: 18.4 | accuracy: 0.29 | loss: 0.88
update:300/2000, 耗时:0.00分/1.47分 | step: 48000 | performance: 15.0 | accuracy: 0.28 | loss: 0.83
update:305/2000, 耗时:0.00分/1.50分 | step: 48800 | performance: 17.8 | accuracy: 0.27 | loss: 0.74
update:310/2000, 耗时:0.00分/1.52分 | step: 49600 | performance: 16.9 | accuracy: 0.27 | loss: 0.48
update:315/2000, 耗时:0.01分/1.55分 | step: 50400 | performance: 18.3 | accuracy: 0.26 | loss: 2.69
Saving PPO weights in both H5 format and checkpoint @ update:316 
update:320/2000, 耗时:0.00分/1.58分 | step: 51200 | performance: 1.1 | accuracy: 0.22 | loss: 0.73
update:325/2000, 耗时:0.00分/1.60分 | step: 52000 | performance: 0.7 | accuracy: 0.14 | loss: 0.25
step: 52473 | worker_0@n_step_19: average total_reward after train data exhaustion : 29.8 | max total_reward: 207.6
step: 52795 | worker_2@n_step_19: average total_reward after train data exhaustion : 25.9 | max total_reward: 207.6
update:330/2000, 耗时:0.00分/1.63分 | step: 52800 | performance: 0.8 | accuracy: 0.13 | loss: 0.62
update:335/2000, 耗时:0.00分/1.65分 | step: 53600 | performance: 0.7 | accuracy: 0.12 | loss: 0.30
update:340/2000, 耗时:0.00分/1.67分 | step: 54400 | performance: 0.8 | accuracy: 0.12 | loss: 0.35
update:345/2000, 耗时:0.00分/1.70分 | step: 55200 | performance: 1.7 | accuracy: 0.16 | loss: 6.47
step: 55835 | worker_2@n_step_19: average total_reward after train data exhaustion : 17.6 | max total_reward: 207.6
update:350/2000, 耗时:0.00分/1.72分 | step: 56000 | performance: 2.8 | accuracy: 0.20 | loss: 7.36
update:355/2000, 耗时:0.00分/1.74分 | step: 56800 | performance: 1.3 | accuracy: 0.21 | loss: 2.77
update:360/2000, 耗时:0.00分/1.77分 | step: 57600 | performance: 1.5 | accuracy: 0.21 | loss: 1.18
update:365/2000, 耗时:0.00分/1.79分 | step: 58400 | performance: 1.8 | accuracy: 0.20 | loss: 0.95
update:370/2000, 耗时:0.00分/1.81分 | step: 59200 | performance: 3.4 | accuracy: 0.21 | loss: 2.12
update:375/2000, 耗时:0.00分/1.84分 | step: 60000 | performance: 1.9 | accuracy: 0.21 | loss: 4.22
update:380/2000, 耗时:0.00分/1.86分 | step: 60800 | performance: 6.0 | accuracy: 0.23 | loss: 8.36
update:385/2000, 耗时:0.00分/1.89分 | step: 61600 | performance: 4.3 | accuracy: 0.23 | loss: 4.61
update:390/2000, 耗时:0.00分/1.91分 | step: 62400 | performance: 8.0 | accuracy: 0.25 | loss: 5.23
update:395/2000, 耗时:0.00分/1.93分 | step: 63200 | performance: 20.5 | accuracy: 0.26 | loss: 7.06
update:400/2000, 耗时:0.00分/1.95分 | step: 64000 | performance: 157.8 | accuracy: 0.28 | loss: 11.35
update:405/2000, 耗时:0.00分/1.98分 | step: 64800 | performance: 1214.1 | accuracy: 0.30 | loss: 11.24
update:410/2000, 耗时:0.00分/2.00分 | step: 65600 | performance: 6164.1 | accuracy: 0.31 | loss: 7.07
update:415/2000, 耗时:0.00分/2.02分 | step: 66400 | performance: 2149.7 | accuracy: 0.32 | loss: 11.48
update:420/2000, 耗时:0.00分/2.05分 | step: 67200 | performance: 534.9 | accuracy: 0.32 | loss: 7.28
update:425/2000, 耗时:0.00分/2.07分 | step: 68000 | performance: 2939.7 | accuracy: 0.33 | loss: 5.76
update:430/2000, 耗时:0.00分/2.09分 | step: 68800 | performance: 7871.1 | accuracy: 0.34 | loss: 16.09
update:435/2000, 耗时:0.00分/2.12分 | step: 69600 | performance: 3271.1 | accuracy: 0.35 | loss: 12.04
update:440/2000, 耗时:0.00分/2.14分 | step: 70400 | performance: 465.3 | accuracy: 0.35 | loss: 9.98
update:445/2000, 耗时:0.00分/2.17分 | step: 71200 | performance: 679.1 | accuracy: 0.35 | loss: 19.62
update:450/2000, 耗时:0.01分/2.19分 | step: 72000 | performance: 603.8 | accuracy: 0.36 | loss: 10.63
update:455/2000, 耗时:0.00分/2.22分 | step: 72800 | performance: 23.7 | accuracy: 0.36 | loss: 15.47
update:460/2000, 耗时:0.01分/2.24分 | step: 73600 | performance: 45.6 | accuracy: 0.36 | loss: 11.33
update:465/2000, 耗时:0.01分/2.27分 | step: 74400 | performance: 15.6 | accuracy: 0.36 | loss: 7.89
update:470/2000, 耗时:0.01分/2.30分 | step: 75200 | performance: 6.8 | accuracy: 0.36 | loss: 8.65
update:475/2000, 耗时:0.01分/2.32分 | step: 76000 | performance: 0.9 | accuracy: 0.33 | loss: 4.88
update:480/2000, 耗时:0.01分/2.35分 | step: 76800 | performance: 0.9 | accuracy: 0.40 | loss: 6.95
update:485/2000, 耗时:0.01分/2.37分 | step: 77600 | performance: 0.1 | accuracy: 0.37 | loss: 3.20
update:490/2000, 耗时:0.01分/2.40分 | step: 78400 | performance: 0.1 | accuracy: 0.39 | loss: 3.21
update:495/2000, 耗时:0.01分/2.42分 | step: 79200 | performance: 0.1 | accuracy: 0.41 | loss: 1.37
update:500/2000, 耗时:0.00分/2.45分 | step: 80000 | performance: 3.5 | accuracy: 0.46 | loss: 6.31
update:505/2000, 耗时:0.00分/2.48分 | step: 80800 | performance: 15.0 | accuracy: 0.48 | loss: 8.96
update:510/2000, 耗时:0.01分/2.50分 | step: 81600 | performance: 4.9 | accuracy: 0.47 | loss: 7.19
update:515/2000, 耗时:0.01分/2.53分 | step: 82400 | performance: 1.5 | accuracy: 0.46 | loss: 9.59
update:520/2000, 耗时:0.01分/2.55分 | step: 83200 | performance: 0.5 | accuracy: 0.45 | loss: 5.47
update:525/2000, 耗时:0.01分/2.58分 | step: 84000 | performance: 0.7 | accuracy: 0.45 | loss: 8.46
update:530/2000, 耗时:0.01分/2.60分 | step: 84800 | performance: 0.0 | accuracy: 0.45 | loss: 15.90
update:535/2000, 耗时:0.01分/2.63分 | step: 85600 | performance: 0.5 | accuracy: 0.47 | loss: 11.53
update:540/2000, 耗时:0.01分/2.66分 | step: 86400 | performance: 0.8 | accuracy: 0.47 | loss: 5.57
update:545/2000, 耗时:0.01分/2.68分 | step: 87200 | performance: 1.6 | accuracy: 0.48 | loss: 6.20
update:550/2000, 耗时:0.00分/2.71分 | step: 88000 | performance: 1.4 | accuracy: 0.48 | loss: 6.24
update:555/2000, 耗时:0.00分/2.73分 | step: 88800 | performance: 17.1 | accuracy: 0.49 | loss: 6.97
update:560/2000, 耗时:0.01分/2.76分 | step: 89600 | performance: 727.4 | accuracy: 0.50 | loss: 19.03
update:565/2000, 耗时:0.00分/2.78分 | step: 90400 | performance: 1366.5 | accuracy: 0.51 | loss: 13.28
update:570/2000, 耗时:0.01分/2.81分 | step: 91200 | performance: 3142.4 | accuracy: 0.51 | loss: 7.54
update:575/2000, 耗时:0.01分/2.83分 | step: 92000 | performance: 242.6 | accuracy: 0.51 | loss: 4.69
update:580/2000, 耗时:0.00分/2.86分 | step: 92800 | performance: 464.1 | accuracy: 0.50 | loss: 14.48
update:585/2000, 耗时:0.00分/2.88分 | step: 93600 | performance: 1019.4 | accuracy: 0.51 | loss: 10.20
update:590/2000, 耗时:0.00分/2.91分 | step: 94400 | performance: 3181.1 | accuracy: 0.51 | loss: 6.98
update:595/2000, 耗时:0.00分/2.93分 | step: 95200 | performance: 1158.6 | accuracy: 0.51 | loss: 9.69
update:600/2000, 耗时:0.00分/2.95分 | step: 96000 | performance: 431.4 | accuracy: 0.50 | loss: 12.30
update:605/2000, 耗时:0.01分/2.98分 | step: 96800 | performance: 612.6 | accuracy: 0.50 | loss: 13.89
update:610/2000, 耗时:0.00分/3.00分 | step: 97600 | performance: 57.3 | accuracy: 0.50 | loss: 10.54
update:615/2000, 耗时:0.01分/3.03分 | step: 98400 | performance: 7.4 | accuracy: 0.49 | loss: 9.82
update:620/2000, 耗时:0.01分/3.05分 | step: 99200 | performance: 6.9 | accuracy: 0.49 | loss: 7.22
update:625/2000, 耗时:0.00分/3.08分 | step: 100000 | performance: 5.1 | accuracy: 0.49 | loss: 8.49
update:630/2000, 耗时:0.01分/3.10分 | step: 100800 | performance: 2.7 | accuracy: 0.49 | loss: 5.19
update:635/2000, 耗时:0.01分/3.13分 | step: 101600 | performance: 1.0 | accuracy: 0.45 | loss: 6.56
update:640/2000, 耗时:0.00分/3.15分 | step: 102400 | performance: 0.1 | accuracy: 0.40 | loss: 10.02
update:645/2000, 耗时:0.00分/3.18分 | step: 103200 | performance: 0.0 | accuracy: 0.39 | loss: 14.01
update:650/2000, 耗时:0.01分/3.20分 | step: 104000 | performance: 0.0 | accuracy: 0.41 | loss: 4.00
update:655/2000, 耗时:0.01分/3.23分 | step: 104800 | performance: 0.2 | accuracy: 0.47 | loss: 5.97
update:660/2000, 耗时:0.01分/3.26分 | step: 105600 | performance: 1.1 | accuracy: 0.49 | loss: 11.04
update:665/2000, 耗时:0.01分/3.28分 | step: 106400 | performance: 2.7 | accuracy: 0.50 | loss: 8.55
update:670/2000, 耗时:0.01分/3.31分 | step: 107200 | performance: 2.6 | accuracy: 0.48 | loss: 13.13
update:675/2000, 耗时:0.01分/3.34分 | step: 108000 | performance: 0.6 | accuracy: 0.47 | loss: 3.96
update:680/2000, 耗时:0.01分/3.37分 | step: 108800 | performance: 0.3 | accuracy: 0.44 | loss: 1.99
update:685/2000, 耗时:0.01分/3.39分 | step: 109600 | performance: 0.7 | accuracy: 0.43 | loss: 4.98
update:690/2000, 耗时:0.01分/3.42分 | step: 110400 | performance: 0.3 | accuracy: 0.42 | loss: 4.48
update:695/2000, 耗时:0.01分/3.45分 | step: 111200 | performance: 0.5 | accuracy: 0.43 | loss: 8.86
update:700/2000, 耗时:0.01分/3.47分 | step: 112000 | performance: 0.5 | accuracy: 0.43 | loss: 4.80
update:705/2000, 耗时:0.01分/3.50分 | step: 112800 | performance: 0.8 | accuracy: 0.43 | loss: 8.75
update:710/2000, 耗时:0.01分/3.53分 | step: 113600 | performance: 1.2 | accuracy: 0.44 | loss: 4.09
update:715/2000, 耗时:0.01分/3.55分 | step: 114400 | performance: 4.8 | accuracy: 0.44 | loss: 8.68
update:720/2000, 耗时:0.01分/3.58分 | step: 115200 | performance: 87.8 | accuracy: 0.45 | loss: 19.59
update:725/2000, 耗时:0.01分/3.61分 | step: 116000 | performance: 745.7 | accuracy: 0.47 | loss: 14.53
update:730/2000, 耗时:0.01分/3.63分 | step: 116800 | performance: 706.4 | accuracy: 0.47 | loss: 11.68
update:735/2000, 耗时:0.01分/3.66分 | step: 117600 | performance: 56.4 | accuracy: 0.46 | loss: 11.34
update:740/2000, 耗时:0.01分/3.69分 | step: 118400 | performance: 160.1 | accuracy: 0.46 | loss: 10.38
update:745/2000, 耗时:0.01分/3.71分 | step: 119200 | performance: 275.9 | accuracy: 0.47 | loss: 11.42
update:750/2000, 耗时:0.01分/3.74分 | step: 120000 | performance: 256.4 | accuracy: 0.47 | loss: 14.76
update:755/2000, 耗时:0.01分/3.76分 | step: 120800 | performance: 72.2 | accuracy: 0.46 | loss: 14.07
update:760/2000, 耗时:0.01分/3.79分 | step: 121600 | performance: 38.4 | accuracy: 0.46 | loss: 12.34
update:765/2000, 耗时:0.00分/3.82分 | step: 122400 | performance: 38.0 | accuracy: 0.46 | loss: 6.13
update:770/2000, 耗时:0.00分/3.84分 | step: 123200 | performance: 2.5 | accuracy: 0.46 | loss: 14.29
update:775/2000, 耗时:0.01分/3.87分 | step: 124000 | performance: 3.4 | accuracy: 0.46 | loss: 10.40
update:780/2000, 耗时:0.00分/3.89分 | step: 124800 | performance: 1.7 | accuracy: 0.46 | loss: 6.94
update:785/2000, 耗时:0.00分/3.92分 | step: 125600 | performance: 1.0 | accuracy: 0.45 | loss: 6.27
update:790/2000, 耗时:0.01分/3.94分 | step: 126400 | performance: 0.7 | accuracy: 0.45 | loss: 3.62
update:795/2000, 耗时:0.00分/3.97分 | step: 127200 | performance: 0.9 | accuracy: 0.34 | loss: 2.77
update:800/2000, 耗时:0.01分/3.99分 | step: 128000 | performance: 0.2 | accuracy: 0.25 | loss: 4.02
update:805/2000, 耗时:0.00分/4.02分 | step: 128800 | performance: 0.2 | accuracy: 0.22 | loss: 0.84
update:810/2000, 耗时:0.00分/4.04分 | step: 129600 | performance: 0.2 | accuracy: 0.21 | loss: 1.03
update:815/2000, 耗时:0.01分/4.07分 | step: 130400 | performance: 1.1 | accuracy: 0.23 | loss: 5.73
step: 131193 | worker_0@n_step_19: average total_reward after train data exhaustion : 48.8 | max total_reward: 212.9
update:820/2000, 耗时:0.00分/4.09分 | step: 131200 | performance: 4.2 | accuracy: 0.25 | loss: 5.29
Saving PPO weights in both H5 format and checkpoint @ update:820 
Saving PPO weights in both H5 format and checkpoint @ update:823 
update:825/2000, 耗时:0.01分/4.12分 | step: 132000 | performance: 2.5 | accuracy: 0.27 | loss: 4.20
update:830/2000, 耗时:0.01分/4.15分 | step: 132800 | performance: 1.4 | accuracy: 0.27 | loss: 3.36
update:835/2000, 耗时:0.00分/4.17分 | step: 133600 | performance: 1.0 | accuracy: 0.27 | loss: 4.47
update:840/2000, 耗时:0.00分/4.20分 | step: 134400 | performance: 1.0 | accuracy: 0.26 | loss: 1.22
update:845/2000, 耗时:0.00分/4.22分 | step: 135200 | performance: 1.1 | accuracy: 0.26 | loss: 6.73
update:850/2000, 耗时:0.01分/4.25分 | step: 136000 | performance: 0.7 | accuracy: 0.27 | loss: 4.24
update:855/2000, 耗时:0.01分/4.27分 | step: 136800 | performance: 1.0 | accuracy: 0.28 | loss: 4.38
update:860/2000, 耗时:0.00分/4.30分 | step: 137600 | performance: 1.6 | accuracy: 0.29 | loss: 3.56
update:865/2000, 耗时:0.00分/4.32分 | step: 138400 | performance: 1.1 | accuracy: 0.29 | loss: 2.89
update:870/2000, 耗时:0.00分/4.35分 | step: 139200 | performance: 4.0 | accuracy: 0.30 | loss: 7.38
update:875/2000, 耗时:0.00分/4.37分 | step: 140000 | performance: 46.2 | accuracy: 0.32 | loss: 13.80
update:880/2000, 耗时:0.00分/4.40分 | step: 140800 | performance: 404.4 | accuracy: 0.34 | loss: 14.54
update:885/2000, 耗时:0.01分/4.42分 | step: 141600 | performance: 816.7 | accuracy: 0.35 | loss: 7.81
update:890/2000, 耗时:0.00分/4.45分 | step: 142400 | performance: 77.7 | accuracy: 0.35 | loss: 10.02
update:895/2000, 耗时:0.00分/4.47分 | step: 143200 | performance: 35.8 | accuracy: 0.35 | loss: 10.76
update:900/2000, 耗时:0.00分/4.50分 | step: 144000 | performance: 214.4 | accuracy: 0.36 | loss: 6.48
update:905/2000, 耗时:0.00分/4.52分 | step: 144800 | performance: 858.0 | accuracy: 0.37 | loss: 10.21
update:910/2000, 耗时:0.00分/4.54分 | step: 145600 | performance: 198.2 | accuracy: 0.37 | loss: 11.47
update:915/2000, 耗时:0.00分/4.57分 | step: 146400 | performance: 109.2 | accuracy: 0.38 | loss: 7.65
update:920/2000, 耗时:0.00分/4.59分 | step: 147200 | performance: 170.2 | accuracy: 0.38 | loss: 11.31
update:925/2000, 耗时:0.00分/4.62分 | step: 148000 | performance: 15.6 | accuracy: 0.38 | loss: 16.28
update:930/2000, 耗时:0.00分/4.64分 | step: 148800 | performance: 2.8 | accuracy: 0.38 | loss: 6.65
update:935/2000, 耗时:0.01分/4.67分 | step: 149600 | performance: 2.8 | accuracy: 0.38 | loss: 6.51
update:940/2000, 耗时:0.01分/4.69分 | step: 150400 | performance: 1.7 | accuracy: 0.38 | loss: 6.66
update:945/2000, 耗时:0.00分/4.72分 | step: 151200 | performance: 0.7 | accuracy: 0.38 | loss: 5.15
Saving PPO weights in both H5 format and checkpoint @ update:948 
Saving PPO weights in both H5 format and checkpoint @ update:949 
update:950/2000, 耗时:0.01分/4.75分 | step: 152000 | performance: 1.2 | accuracy: 0.44 | loss: 3.99
Saving PPO weights in both H5 format and checkpoint @ update:952 
update:955/2000, 耗时:0.00分/4.78分 | step: 152800 | performance: 0.8 | accuracy: 0.40 | loss: 4.37
update:960/2000, 耗时:0.00分/4.80分 | step: 153600 | performance: 0.7 | accuracy: 0.41 | loss: 3.28
update:965/2000, 耗时:0.00分/4.83分 | step: 154400 | performance: 0.7 | accuracy: 0.38 | loss: 1.71
update:970/2000, 耗时:0.00分/4.85分 | step: 155200 | performance: 1.1 | accuracy: 0.38 | loss: 3.28
update:975/2000, 耗时:0.00分/4.88分 | step: 156000 | performance: 5.0 | accuracy: 0.40 | loss: 5.85
Saving PPO weights in both H5 format and checkpoint @ update:978 
update:980/2000, 耗时:0.00分/4.90分 | step: 156800 | performance: 10.4 | accuracy: 0.41 | loss: 3.62
Saving PPO weights in both H5 format and checkpoint @ update:981 
update:985/2000, 耗时:0.00分/4.93分 | step: 157600 | performance: 12.1 | accuracy: 0.40 | loss: 2.92
update:990/2000, 耗时:0.00分/4.96分 | step: 158400 | performance: 6.1 | accuracy: 0.39 | loss: 1.41
update:995/2000, 耗时:0.00分/4.98分 | step: 159200 | performance: 5.7 | accuracy: 0.38 | loss: 1.17
update:1000/2000, 耗时:0.01分/5.01分 | step: 160000 | performance: 5.0 | accuracy: 0.36 | loss: 0.82
update:1005/2000, 耗时:0.01分/5.03分 | step: 160800 | performance: 5.3 | accuracy: 0.35 | loss: 3.03
update:1010/2000, 耗时:0.00分/5.06分 | step: 161600 | performance: 16.9 | accuracy: 0.36 | loss: 4.42
update:1015/2000, 耗时:0.00分/5.08分 | step: 162400 | performance: 13.9 | accuracy: 0.36 | loss: 3.92
update:1020/2000, 耗时:0.00分/5.10分 | step: 163200 | performance: 23.2 | accuracy: 0.36 | loss: 3.34
update:1025/2000, 耗时:0.00分/5.13分 | step: 164000 | performance: 34.0 | accuracy: 0.36 | loss: 5.87
update:1030/2000, 耗时:0.00分/5.15分 | step: 164800 | performance: 301.2 | accuracy: 0.37 | loss: 4.89
update:1035/2000, 耗时:0.01分/5.18分 | step: 165600 | performance: 1778.5 | accuracy: 0.38 | loss: 8.24
update:1040/2000, 耗时:0.00分/5.20分 | step: 166400 | performance: 20140.0 | accuracy: 0.39 | loss: 10.66
update:1045/2000, 耗时:0.00分/5.23分 | step: 167200 | performance: 15681.1 | accuracy: 0.40 | loss: 8.08
update:1050/2000, 耗时:0.00分/5.25分 | step: 168000 | performance: 1262.6 | accuracy: 0.39 | loss: 13.68
update:1055/2000, 耗时:0.00分/5.28分 | step: 168800 | performance: 4877.5 | accuracy: 0.40 | loss: 6.83
update:1060/2000, 耗时:0.00分/5.30分 | step: 169600 | performance: 4438.6 | accuracy: 0.40 | loss: 6.84
update:1065/2000, 耗时:0.01分/5.33分 | step: 170400 | performance: 14723.4 | accuracy: 0.41 | loss: 8.79
update:1070/2000, 耗时:0.00分/5.35分 | step: 171200 | performance: 3441.0 | accuracy: 0.41 | loss: 11.60
update:1075/2000, 耗时:0.01分/5.38分 | step: 172000 | performance: 3157.1 | accuracy: 0.41 | loss: 7.90
update:1080/2000, 耗时:0.00分/5.40分 | step: 172800 | performance: 3377.2 | accuracy: 0.41 | loss: 12.11
update:1085/2000, 耗时:0.00分/5.42分 | step: 173600 | performance: 690.0 | accuracy: 0.41 | loss: 14.58
update:1090/2000, 耗时:0.00分/5.45分 | step: 174400 | performance: 155.0 | accuracy: 0.41 | loss: 13.50
update:1095/2000, 耗时:0.00分/5.47分 | step: 175200 | performance: 68.2 | accuracy: 0.41 | loss: 7.22
update:1100/2000, 耗时:0.00分/5.50分 | step: 176000 | performance: 84.0 | accuracy: 0.41 | loss: 10.12
update:1105/2000, 耗时:0.00分/5.52分 | step: 176800 | performance: 24.4 | accuracy: 0.41 | loss: 4.96
Saving PPO weights in both H5 format and checkpoint @ update:1105 
Saving PPO weights in both H5 format and checkpoint @ update:1106 
Saving PPO weights in both H5 format and checkpoint @ update:1107 
update:1110/2000, 耗时:0.00分/5.56分 | step: 177600 | performance: 1.0 | accuracy: 0.49 | loss: 7.23
Saving PPO weights in both H5 format and checkpoint @ update:1110 
update:1115/2000, 耗时:0.00分/5.59分 | step: 178400 | performance: 0.0 | accuracy: 0.37 | loss: 16.19
update:1120/2000, 耗时:0.00分/5.61分 | step: 179200 | performance: 0.0 | accuracy: 0.40 | loss: 6.04
update:1125/2000, 耗时:0.01分/5.64分 | step: 180000 | performance: 0.1 | accuracy: 0.43 | loss: 6.82
update:1130/2000, 耗时:0.00分/5.66分 | step: 180800 | performance: 0.4 | accuracy: 0.49 | loss: 16.89
update:1135/2000, 耗时:0.00分/5.68分 | step: 181600 | performance: 12.8 | accuracy: 0.52 | loss: 12.61
Saving PPO weights in both H5 format and checkpoint @ update:1136 
Saving PPO weights in both H5 format and checkpoint @ update:1139 
update:1140/2000, 耗时:0.01分/5.72分 | step: 182400 | performance: 5.7 | accuracy: 0.51 | loss: 13.51
update:1145/2000, 耗时:0.00分/5.74分 | step: 183200 | performance: 2.0 | accuracy: 0.49 | loss: 10.26
update:1150/2000, 耗时:0.00分/5.77分 | step: 184000 | performance: 1.1 | accuracy: 0.48 | loss: 8.05
update:1155/2000, 耗时:0.00分/5.79分 | step: 184800 | performance: 1.8 | accuracy: 0.48 | loss: 7.51
update:1160/2000, 耗时:0.00分/5.81分 | step: 185600 | performance: 2.4 | accuracy: 0.48 | loss: 11.39
update:1165/2000, 耗时:0.00分/5.84分 | step: 186400 | performance: 1.0 | accuracy: 0.48 | loss: 13.91
update:1170/2000, 耗时:0.01分/5.86分 | step: 187200 | performance: 4.6 | accuracy: 0.50 | loss: 11.36
update:1175/2000, 耗时:0.00分/5.89分 | step: 188000 | performance: 7.5 | accuracy: 0.49 | loss: 8.24
update:1180/2000, 耗时:0.00分/5.91分 | step: 188800 | performance: 6.3 | accuracy: 0.50 | loss: 11.92
update:1185/2000, 耗时:0.00分/5.94分 | step: 189600 | performance: 27.1 | accuracy: 0.50 | loss: 7.45
update:1190/2000, 耗时:0.00分/5.96分 | step: 190400 | performance: 341.2 | accuracy: 0.51 | loss: 15.04
update:1195/2000, 耗时:0.00分/5.98分 | step: 191200 | performance: 6158.9 | accuracy: 0.52 | loss: 11.63
update:1200/2000, 耗时:0.00分/6.01分 | step: 192000 | performance: 13171.4 | accuracy: 0.52 | loss: 6.66
update:1205/2000, 耗时:0.00分/6.03分 | step: 192800 | performance: 1684.2 | accuracy: 0.52 | loss: 20.64
update:1210/2000, 耗时:0.00分/6.06分 | step: 193600 | performance: 704.6 | accuracy: 0.51 | loss: 8.63
update:1215/2000, 耗时:0.00分/6.08分 | step: 194400 | performance: 5003.5 | accuracy: 0.51 | loss: 8.22
update:1220/2000, 耗时:0.00分/6.11分 | step: 195200 | performance: 13341.4 | accuracy: 0.52 | loss: 11.46
update:1225/2000, 耗时:0.00分/6.13分 | step: 196000 | performance: 3689.4 | accuracy: 0.51 | loss: 12.00
update:1230/2000, 耗时:0.00分/6.16分 | step: 196800 | performance: 1040.7 | accuracy: 0.51 | loss: 14.67
update:1235/2000, 耗时:0.00分/6.18分 | step: 197600 | performance: 1515.2 | accuracy: 0.51 | loss: 8.78
update:1240/2000, 耗时:0.00分/6.21分 | step: 198400 | performance: 291.6 | accuracy: 0.50 | loss: 11.35
update:1245/2000, 耗时:0.00分/6.23分 | step: 199200 | performance: 31.3 | accuracy: 0.50 | loss: 12.14
update:1250/2000, 耗时:0.00分/6.25分 | step: 200000 | performance: 51.7 | accuracy: 0.50 | loss: 5.66
update:1255/2000, 耗时:0.00分/6.28分 | step: 200800 | performance: 24.2 | accuracy: 0.49 | loss: 3.61
update:1260/2000, 耗时:0.00分/6.30分 | step: 201600 | performance: 8.5 | accuracy: 0.49 | loss: 6.51
Saving PPO weights in both H5 format and checkpoint @ update:1263 
Saving PPO weights in both H5 format and checkpoint @ update:1264 
update:1265/2000, 耗时:0.01分/6.34分 | step: 202400 | performance: 1.0 | accuracy: 0.48 | loss: 9.98
Saving PPO weights in both H5 format and checkpoint @ update:1265 
Saving PPO weights in both H5 format and checkpoint @ update:1267 
update:1270/2000, 耗时:0.00分/6.37分 | step: 203200 | performance: 0.9 | accuracy: 0.45 | loss: 10.57
update:1275/2000, 耗时:0.00分/6.39分 | step: 204000 | performance: 0.1 | accuracy: 0.38 | loss: 14.94
update:1280/2000, 耗时:0.00分/6.42分 | step: 204800 | performance: 0.0 | accuracy: 0.41 | loss: 6.88
update:1285/2000, 耗时:0.00分/6.44分 | step: 205600 | performance: 0.2 | accuracy: 0.46 | loss: 11.04
update:1290/2000, 耗时:0.00分/6.47分 | step: 206400 | performance: 2.5 | accuracy: 0.51 | loss: 9.51
Saving PPO weights in both H5 format and checkpoint @ update:1293 
Saving PPO weights in both H5 format and checkpoint @ update:1294 
update:1295/2000, 耗时:0.01分/6.50分 | step: 207200 | performance: 4.0 | accuracy: 0.51 | loss: 9.32
Saving PPO weights in both H5 format and checkpoint @ update:1297 
update:1300/2000, 耗时:0.00分/6.53分 | step: 208000 | performance: 5.6 | accuracy: 0.51 | loss: 7.19
update:1305/2000, 耗时:0.00分/6.55分 | step: 208800 | performance: 1.2 | accuracy: 0.49 | loss: 6.27
update:1310/2000, 耗时:0.00分/6.58分 | step: 209600 | performance: 0.5 | accuracy: 0.47 | loss: 6.04
update:1315/2000, 耗时:0.01分/6.60分 | step: 210400 | performance: 1.6 | accuracy: 0.48 | loss: 9.45
update:1320/2000, 耗时:0.00分/6.62分 | step: 211200 | performance: 0.2 | accuracy: 0.48 | loss: 19.62
update:1325/2000, 耗时:0.00分/6.65分 | step: 212000 | performance: 0.9 | accuracy: 0.49 | loss: 14.29
update:1330/2000, 耗时:0.00分/6.67分 | step: 212800 | performance: 1.3 | accuracy: 0.49 | loss: 3.73
update:1335/2000, 耗时:0.00分/6.70分 | step: 213600 | performance: 2.6 | accuracy: 0.49 | loss: 3.69
update:1340/2000, 耗时:0.00分/6.72分 | step: 214400 | performance: 2.1 | accuracy: 0.49 | loss: 2.31
update:1345/2000, 耗时:0.00分/6.75分 | step: 215200 | performance: 4.6 | accuracy: 0.49 | loss: 4.87
update:1350/2000, 耗时:0.00分/6.77分 | step: 216000 | performance: 92.7 | accuracy: 0.50 | loss: 10.66
update:1355/2000, 耗时:0.00分/6.79分 | step: 216800 | performance: 381.8 | accuracy: 0.50 | loss: 9.58
update:1360/2000, 耗时:0.00分/6.82分 | step: 217600 | performance: 510.0 | accuracy: 0.50 | loss: 4.89
update:1365/2000, 耗时:0.00分/6.84分 | step: 218400 | performance: 93.7 | accuracy: 0.49 | loss: 10.22
update:1370/2000, 耗时:0.00分/6.86分 | step: 219200 | performance: 84.7 | accuracy: 0.49 | loss: 11.97
update:1375/2000, 耗时:0.00分/6.89分 | step: 220000 | performance: 137.4 | accuracy: 0.49 | loss: 5.46
update:1380/2000, 耗时:0.00分/6.91分 | step: 220800 | performance: 907.5 | accuracy: 0.49 | loss: 8.83
update:1385/2000, 耗时:0.00分/6.94分 | step: 221600 | performance: 224.4 | accuracy: 0.49 | loss: 10.01
update:1390/2000, 耗时:0.00分/6.96分 | step: 222400 | performance: 84.6 | accuracy: 0.49 | loss: 9.52
update:1395/2000, 耗时:0.00分/6.99分 | step: 223200 | performance: 93.3 | accuracy: 0.48 | loss: 14.77
update:1400/2000, 耗时:0.00分/7.01分 | step: 224000 | performance: 28.5 | accuracy: 0.48 | loss: 5.48
update:1405/2000, 耗时:0.00分/7.04分 | step: 224800 | performance: 13.5 | accuracy: 0.47 | loss: 5.85
update:1410/2000, 耗时:0.00分/7.06分 | step: 225600 | performance: 9.2 | accuracy: 0.47 | loss: 4.09
update:1415/2000, 耗时:0.00分/7.08分 | step: 226400 | performance: 11.2 | accuracy: 0.47 | loss: 2.30
update:1420/2000, 耗时:0.00分/7.11分 | step: 227200 | performance: 5.9 | accuracy: 0.47 | loss: 1.81
Saving PPO weights in both H5 format and checkpoint @ update:1421 
Saving PPO weights in both H5 format and checkpoint @ update:1422 
Saving PPO weights in both H5 format and checkpoint @ update:1423 
update:1425/2000, 耗时:0.00分/7.14分 | step: 228000 | performance: 0.9 | accuracy: 0.33 | loss: 1.50
update:1430/2000, 耗时:0.00分/7.17分 | step: 228800 | performance: 1.6 | accuracy: 0.41 | loss: 3.29
update:1435/2000, 耗时:0.00分/7.19分 | step: 229600 | performance: 1.0 | accuracy: 0.38 | loss: 4.27
update:1440/2000, 耗时:0.00分/7.22分 | step: 230400 | performance: 0.8 | accuracy: 0.39 | loss: 1.86
update:1445/2000, 耗时:0.00分/7.24分 | step: 231200 | performance: 0.5 | accuracy: 0.38 | loss: 1.41
update:1450/2000, 耗时:0.00分/7.26分 | step: 232000 | performance: 1.1 | accuracy: 0.38 | loss: 4.37
Saving PPO weights in both H5 format and checkpoint @ update:1451 
Saving PPO weights in both H5 format and checkpoint @ update:1452 
update:1455/2000, 耗时:0.00分/7.30分 | step: 232800 | performance: 1.2 | accuracy: 0.39 | loss: 4.00
update:1460/2000, 耗时:0.00分/7.32分 | step: 233600 | performance: 0.5 | accuracy: 0.38 | loss: 2.83
update:1465/2000, 耗时:0.00分/7.35分 | step: 234400 | performance: 0.3 | accuracy: 0.39 | loss: 1.74
update:1470/2000, 耗时:0.01分/7.37分 | step: 235200 | performance: 0.4 | accuracy: 0.38 | loss: 1.91
update:1475/2000, 耗时:0.00分/7.40分 | step: 236000 | performance: 0.1 | accuracy: 0.37 | loss: 3.13
update:1480/2000, 耗时:0.00分/7.42分 | step: 236800 | performance: 0.3 | accuracy: 0.37 | loss: 1.96
update:1485/2000, 耗时:0.00分/7.45分 | step: 237600 | performance: 0.1 | accuracy: 0.36 | loss: 4.63
update:1490/2000, 耗时:0.00分/7.47分 | step: 238400 | performance: 0.1 | accuracy: 0.36 | loss: 3.52
update:1495/2000, 耗时:0.00分/7.49分 | step: 239200 | performance: 0.1 | accuracy: 0.36 | loss: 6.70
update:1500/2000, 耗时:0.00分/7.52分 | step: 240000 | performance: 0.2 | accuracy: 0.36 | loss: 3.41
update:1505/2000, 耗时:0.00分/7.54分 | step: 240800 | performance: 1.7 | accuracy: 0.37 | loss: 8.81
update:1510/2000, 耗时:0.00分/7.57分 | step: 241600 | performance: 13.6 | accuracy: 0.37 | loss: 9.72
update:1515/2000, 耗时:0.00分/7.59分 | step: 242400 | performance: 74.8 | accuracy: 0.38 | loss: 6.30
update:1520/2000, 耗时:0.00分/7.62分 | step: 243200 | performance: 15.3 | accuracy: 0.39 | loss: 16.05
update:1525/2000, 耗时:0.00分/7.64分 | step: 244000 | performance: 5.0 | accuracy: 0.39 | loss: 7.43
update:1530/2000, 耗时:0.00分/7.67分 | step: 244800 | performance: 26.5 | accuracy: 0.39 | loss: 5.43
update:1535/2000, 耗时:0.00分/7.69分 | step: 245600 | performance: 83.0 | accuracy: 0.40 | loss: 15.03
update:1540/2000, 耗时:0.00分/7.71分 | step: 246400 | performance: 27.1 | accuracy: 0.40 | loss: 12.03
update:1545/2000, 耗时:0.00分/7.74分 | step: 247200 | performance: 5.5 | accuracy: 0.40 | loss: 7.80
update:1550/2000, 耗时:0.00分/7.76分 | step: 248000 | performance: 8.8 | accuracy: 0.40 | loss: 14.07
update:1555/2000, 耗时:0.00分/7.78分 | step: 248800 | performance: 7.3 | accuracy: 0.40 | loss: 8.52
update:1560/2000, 耗时:0.00分/7.81分 | step: 249600 | performance: 0.5 | accuracy: 0.39 | loss: 7.55
update:1565/2000, 耗时:0.00分/7.83分 | step: 250400 | performance: 0.8 | accuracy: 0.39 | loss: 7.93
update:1570/2000, 耗时:0.00分/7.86分 | step: 251200 | performance: 0.2 | accuracy: 0.39 | loss: 2.25
update:1575/2000, 耗时:0.00分/7.88分 | step: 252000 | performance: 0.4 | accuracy: 0.39 | loss: 3.43
update:1580/2000, 耗时:0.00分/7.91分 | step: 252800 | performance: 1.0 | accuracy: 0.38 | loss: 0.64
update:1585/2000, 耗时:0.00分/7.93分 | step: 253600 | performance: 1.3 | accuracy: 0.33 | loss: 3.89
update:1590/2000, 耗时:0.00分/7.95分 | step: 254400 | performance: 1.9 | accuracy: 0.29 | loss: 2.47
update:1595/2000, 耗时:0.00分/7.98分 | step: 255200 | performance: 1.7 | accuracy: 0.25 | loss: 0.54
update:1600/2000, 耗时:0.00分/8.00分 | step: 256000 | performance: 1.7 | accuracy: 0.23 | loss: 1.60
update:1605/2000, 耗时:0.00分/8.02分 | step: 256800 | performance: 1.6 | accuracy: 0.23 | loss: 2.63
update:1610/2000, 耗时:0.00分/8.05分 | step: 257600 | performance: 2.1 | accuracy: 0.24 | loss: 2.34
update:1615/2000, 耗时:0.00分/8.07分 | step: 258400 | performance: 1.6 | accuracy: 0.25 | loss: 1.73
update:1620/2000, 耗时:0.00分/8.09分 | step: 259200 | performance: 1.2 | accuracy: 0.25 | loss: 2.66
update:1625/2000, 耗时:0.00分/8.12分 | step: 260000 | performance: 1.5 | accuracy: 0.27 | loss: 1.56
update:1630/2000, 耗时:0.00分/8.14分 | step: 260800 | performance: 1.9 | accuracy: 0.27 | loss: 1.03
update:1635/2000, 耗时:0.00分/8.16分 | step: 261600 | performance: 0.2 | accuracy: 0.27 | loss: 8.12
update:1640/2000, 耗时:0.00分/8.19分 | step: 262400 | performance: 0.4 | accuracy: 0.28 | loss: 2.26
update:1645/2000, 耗时:0.00分/8.21分 | step: 263200 | performance: 0.4 | accuracy: 0.28 | loss: 3.75
update:1650/2000, 耗时:0.01分/8.24分 | step: 264000 | performance: 0.8 | accuracy: 0.29 | loss: 3.33
update:1655/2000, 耗时:0.00分/8.26分 | step: 264800 | performance: 0.4 | accuracy: 0.29 | loss: 2.24
update:1660/2000, 耗时:0.01分/8.29分 | step: 265600 | performance: 1.1 | accuracy: 0.29 | loss: 2.87
update:1665/2000, 耗时:0.01分/8.31分 | step: 266400 | performance: 30.0 | accuracy: 0.30 | loss: 10.77
update:1670/2000, 耗时:0.00分/8.34分 | step: 267200 | performance: 72.1 | accuracy: 0.32 | loss: 10.37
update:1675/2000, 耗时:0.01分/8.37分 | step: 268000 | performance: 160.2 | accuracy: 0.33 | loss: 7.14
update:1680/2000, 耗时:0.00分/8.39分 | step: 268800 | performance: 28.7 | accuracy: 0.33 | loss: 3.18
update:1685/2000, 耗时:0.01分/8.42分 | step: 269600 | performance: 44.9 | accuracy: 0.33 | loss: 6.90
update:1690/2000, 耗时:0.01分/8.44分 | step: 270400 | performance: 86.4 | accuracy: 0.33 | loss: 7.01
update:1695/2000, 耗时:0.00分/8.47分 | step: 271200 | performance: 246.9 | accuracy: 0.34 | loss: 5.13
update:1700/2000, 耗时:0.00分/8.49分 | step: 272000 | performance: 86.3 | accuracy: 0.34 | loss: 9.94
update:1705/2000, 耗时:0.01分/8.52分 | step: 272800 | performance: 37.8 | accuracy: 0.34 | loss: 11.67
update:1710/2000, 耗时:0.01分/8.54分 | step: 273600 | performance: 46.4 | accuracy: 0.35 | loss: 13.52
update:1715/2000, 耗时:0.01分/8.57分 | step: 274400 | performance: 4.9 | accuracy: 0.35 | loss: 7.87
update:1720/2000, 耗时:0.01分/8.59分 | step: 275200 | performance: 1.5 | accuracy: 0.35 | loss: 6.15
update:1725/2000, 耗时:0.01分/8.62分 | step: 276000 | performance: 1.4 | accuracy: 0.35 | loss: 5.37
update:1730/2000, 耗时:0.00分/8.64分 | step: 276800 | performance: 1.1 | accuracy: 0.35 | loss: 6.65
update:1735/2000, 耗时:0.01分/8.67分 | step: 277600 | performance: 0.8 | accuracy: 0.35 | loss: 4.26
update:1740/2000, 耗时:0.01分/8.69分 | step: 278400 | performance: 1.0 | accuracy: 0.41 | loss: 5.88
update:1745/2000, 耗时:0.00分/8.72分 | step: 279200 | performance: 0.1 | accuracy: 0.35 | loss: 9.34
update:1750/2000, 耗时:0.01分/8.74分 | step: 280000 | performance: 0.0 | accuracy: 0.34 | loss: 10.29
update:1755/2000, 耗时:0.00分/8.77分 | step: 280800 | performance: 0.1 | accuracy: 0.36 | loss: 6.65
update:1760/2000, 耗时:0.00分/8.79分 | step: 281600 | performance: 0.3 | accuracy: 0.42 | loss: 5.13
update:1765/2000, 耗时:0.00分/8.82分 | step: 282400 | performance: 1.4 | accuracy: 0.44 | loss: 9.87
Saving PPO weights in both H5 format and checkpoint @ update:1767 
Saving PPO weights in both H5 format and checkpoint @ update:1768 
update:1770/2000, 耗时:0.00分/8.85分 | step: 283200 | performance: 3.1 | accuracy: 0.45 | loss: 9.03
update:1775/2000, 耗时:0.00分/8.87分 | step: 284000 | performance: 2.1 | accuracy: 0.44 | loss: 11.90
update:1780/2000, 耗时:0.00分/8.90分 | step: 284800 | performance: 1.1 | accuracy: 0.42 | loss: 2.60
update:1785/2000, 耗时:0.00分/8.92分 | step: 285600 | performance: 0.9 | accuracy: 0.40 | loss: 1.73
update:1790/2000, 耗时:0.00分/8.95分 | step: 286400 | performance: 1.9 | accuracy: 0.40 | loss: 4.72
update:1795/2000, 耗时:0.01分/8.97分 | step: 287200 | performance: 0.5 | accuracy: 0.41 | loss: 8.54
update:1800/2000, 耗时:0.01分/9.00分 | step: 288000 | performance: 1.5 | accuracy: 0.42 | loss: 9.04
update:1805/2000, 耗时:0.00分/9.02分 | step: 288800 | performance: 1.6 | accuracy: 0.42 | loss: 7.51
update:1810/2000, 耗时:0.01分/9.05分 | step: 289600 | performance: 3.4 | accuracy: 0.43 | loss: 9.50
update:1815/2000, 耗时:0.00分/9.07分 | step: 290400 | performance: 6.7 | accuracy: 0.44 | loss: 7.91
update:1820/2000, 耗时:0.01分/9.10分 | step: 291200 | performance: 32.9 | accuracy: 0.45 | loss: 7.64
update:1825/2000, 耗时:0.00分/9.12分 | step: 292000 | performance: 546.2 | accuracy: 0.46 | loss: 21.57
update:1830/2000, 耗时:0.00分/9.15分 | step: 292800 | performance: 5993.3 | accuracy: 0.47 | loss: 14.21
update:1835/2000, 耗时:0.01分/9.17分 | step: 293600 | performance: 5023.8 | accuracy: 0.47 | loss: 12.43
update:1840/2000, 耗时:0.01分/9.20分 | step: 294400 | performance: 483.0 | accuracy: 0.47 | loss: 11.81
update:1845/2000, 耗时:0.01分/9.22分 | step: 295200 | performance: 1889.0 | accuracy: 0.47 | loss: 10.45
update:1850/2000, 耗时:0.01分/9.25分 | step: 296000 | performance: 3790.9 | accuracy: 0.47 | loss: 11.25
update:1855/2000, 耗时:0.01分/9.28分 | step: 296800 | performance: 3560.5 | accuracy: 0.47 | loss: 14.71
update:1860/2000, 耗时:0.01分/9.30分 | step: 297600 | performance: 959.7 | accuracy: 0.47 | loss: 14.26
update:1865/2000, 耗时:0.01分/9.33分 | step: 298400 | performance: 508.4 | accuracy: 0.47 | loss: 12.60
update:1870/2000, 耗时:0.01分/9.36分 | step: 299200 | performance: 502.9 | accuracy: 0.47 | loss: 5.85
update:1875/2000, 耗时:0.01分/9.39分 | step: 300000 | performance: 20.8 | accuracy: 0.46 | loss: 14.20
update:1880/2000, 耗时:0.01分/9.41分 | step: 300800 | performance: 34.3 | accuracy: 0.46 | loss: 11.34
update:1885/2000, 耗时:0.01分/9.44分 | step: 301600 | performance: 11.5 | accuracy: 0.46 | loss: 7.76
update:1890/2000, 耗时:0.01分/9.47分 | step: 302400 | performance: 5.2 | accuracy: 0.46 | loss: 6.90
update:1895/2000, 耗时:0.01分/9.49分 | step: 303200 | performance: 4.5 | accuracy: 0.46 | loss: 4.25
Saving PPO weights in both H5 format and checkpoint @ update:1896 
Saving PPO weights in both H5 format and checkpoint @ update:1899 
update:1900/2000, 耗时:0.01分/9.53分 | step: 304000 | performance: 0.9 | accuracy: 0.38 | loss: 3.93
update:1905/2000, 耗时:0.01分/9.56分 | step: 304800 | performance: 0.3 | accuracy: 0.36 | loss: 1.74
update:1910/2000, 耗时:0.01分/9.58分 | step: 305600 | performance: 0.2 | accuracy: 0.35 | loss: 2.62
update:1915/2000, 耗时:0.01分/9.61分 | step: 306400 | performance: 0.2 | accuracy: 0.35 | loss: 2.20
update:1920/2000, 耗时:0.01分/9.64分 | step: 307200 | performance: 0.1 | accuracy: 0.34 | loss: 1.49
update:1925/2000, 耗时:0.01分/9.67分 | step: 308000 | performance: 0.3 | accuracy: 0.33 | loss: 2.08
Saving PPO weights in both H5 format and checkpoint @ update:1925 
Saving PPO weights in both H5 format and checkpoint @ update:1928 
update:1930/2000, 耗时:0.00分/9.70分 | step: 308800 | performance: 0.2 | accuracy: 0.32 | loss: 1.30
update:1935/2000, 耗时:0.01分/9.73分 | step: 309600 | performance: 0.1 | accuracy: 0.31 | loss: 1.62
update:1940/2000, 耗时:0.01分/9.75分 | step: 310400 | performance: 0.2 | accuracy: 0.30 | loss: 2.51
update:1945/2000, 耗时:0.01分/9.78分 | step: 311200 | performance: 0.1 | accuracy: 0.28 | loss: 2.57
update:1950/2000, 耗时:0.00分/9.80分 | step: 312000 | performance: 0.1 | accuracy: 0.28 | loss: 1.82
update:1955/2000, 耗时:0.00分/9.83分 | step: 312800 | performance: 0.0 | accuracy: 0.29 | loss: 4.31
update:1960/2000, 耗时:0.01分/9.85分 | step: 313600 | performance: 0.1 | accuracy: 0.29 | loss: 1.76
update:1965/2000, 耗时:0.01分/9.88分 | step: 314400 | performance: 0.1 | accuracy: 0.29 | loss: 0.82
update:1970/2000, 耗时:0.00分/9.90分 | step: 315200 | performance: 0.1 | accuracy: 0.28 | loss: 0.76
update:1975/2000, 耗时:0.01分/9.93分 | step: 316000 | performance: 0.1 | accuracy: 0.28 | loss: 1.44
update:1980/2000, 耗时:0.00分/9.95分 | step: 316800 | performance: 0.7 | accuracy: 0.28 | loss: 6.56
update:1985/2000, 耗时:0.01分/9.98分 | step: 317600 | performance: 2.8 | accuracy: 0.29 | loss: 8.73
update:1990/2000, 耗时:0.00分/10.00分 | step: 318400 | performance: 3.3 | accuracy: 0.30 | loss: 6.93
update:1995/2000, 耗时:0.00分/10.03分 | step: 319200 | performance: 0.3 | accuracy: 0.30 | loss: 5.23
  0%|          | 0/391 [00:00<?, ?it/s]100%|| 391/391 [00:00<00:00, 97704.67it/s]
update:2000/2000, 耗时:0.01分/10.05分 | step: 320000 | performance: 0.1 | accuracy: 0.30 | loss: 5.76
----------------------------------------finished----------------------------------------
==================================================
2023-01-10T12:00:00 | *** START BACKTEST ***
2023-01-10T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1587.30
2023-07-24T12:00:00 | net performance [%] = 58.7301
2023-07-24T12:00:00 | number of trades [#] = 10
==================================================
Trial 10 Complete [00h 10m 29s]
net_wealth: 1588.8900329404723

Best net_wealth So Far: 1714.485333603393
Total elapsed time: 01h 17m 52s

Search: Running Trial #11

Value             |Best Value So Far |Hyperparameter
2                 |6                 |horizon
730               |225               |lookback
True              |True              |MarketFactor
14                |14                |lags
0.6               |0.85              |gamma
16                |32                |batch_size
64                |64                |n_step
0.96              |0.8               |gae_lambda
2                 |2                 |gradient_clip_norm
3                 |3                 |epochs
1e-05             |0.001             |actor_lr
5e-05             |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4299.000000   4301.000000
mean      0.000435    20113.607657  ...   20176.664105  20169.373185
std       0.027833    16040.642334  ...   16078.769271  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7739.330078   7730.930176
50%       0.000642    11571.842969  ...   11754.589844  11751.469727
75%       0.011590    29894.706152  ...   30014.465820  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-27 23:21:15.385401: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep N2023-07-27 23:21:15.385472: I tensorflow/core/platform/cpu_feature_guard.cc:142] This Tenso20rFlow e2bina20u2ral r03y2Networ -3k L07-ibrary (oneDNN) to 0-7-27 23:21:u2s17i5s. 385531: ope t2ti3:21:15 mIhe follo23-07-2.ized  wt7 23:21wing:318en5so55.1 ithCPU r3854in os0ne4t1fl:ow :A/core /plratfPIIo uDeI ermtcti pteen/csooprnfu_feature_gu aNselu in perfornrsoromancdf.lral Now/cwe-c/etwork Librocore/plare/rcc:142ry (oi] Tt2his0ap2tf i2lo0ant233Teerm-0/nf-oDc7alrmsc0 N/Ncp-27 23:21u)_7:-p ufoore2to _Faltpur1e_gerfatieo5w binary .27uuarsd oais 38o5p9te60 t24im.23:21:n:c cIs :31-0iz7e42-d: ]t1en2t5u sToh i7 AV re2s 3w:_gTX. h238eei f15:A915ou.arll3Vr718owd6.:f ncsIX 0tensorflow/c2otich 
8nogrer:Flo104:o Tw2I]  Th  /Ctinse APeploa tbflonoTremnwsPU/s I co/ienosoinarDy cipursFt r_efonearloptieepb l/wplferalumcNt utoizhem ti eaeudibotirw/r ecfoorannwirlamr/tncpeusy_ h_  gi n opneeoAfPutihrefa NIs Dtae eopuotrw orpde.crctioe:1rrreke p/amm4 Libtria_pNgeuu2nlcairey-ca]  (ToonnarritdtriafehsiDcsao ,.clT eNertzm/wlncN seodo:Npe)c rrka1 rwebi42toio p]ur_LinFfl seubiaTtlhoiws r uTe:narbe r yisorFlAntVhX_d   ogo(won nTAuaarrens ybeidV XiAnar2esDN PN ).o
ctcorFI  oupDst:imliez  eteopw  ewTioy o ttd wie1us4e  it2nNhathehe s ]ur bfoolpltThlea lt h thNoweimihzi imesd wng  oen eaA in epPTIe nstCwieD eeporofpo lNleouwikP tLornUi birnahr ornrtFohygspteriaelA PlINo rC  (wo  boertaPiDnuetweonaeUD  rekpNinscpt iNoeut Nrrya li sN e)r uceooLtiwborrcrmpkn Litaipttatoi usronoiblys (rsaen ie i,n psm ry tr flaonehi zeree(ioed  Drngesb.N
fwuiitldh No)Dnf  romnTNeNn eolltos orFloup)Ase a Ptoetnhceerf o wIo fDo-crmlalnowre iwnig ecithpew-tiCPU ic  tNhuseacnrel  thioepee raftu raagtili cCaPlpoo oUpllpnrso Nieep:orwt  aitng CPioni AVX AVX2
To nUswork tsructions in performan instrructien:stLaite ibrac ecompil-oncer flags.r riuAcsrVtt
iyXical operan AVX2a b(
otloe iontThem in other operations, rebuild TensorFlow with the appropriate compiler flags.
 eDNN) to use inno e nps:  enabrs ifAVX AVX2
ntoTo erlmance-c pernabitical operations:  AVX AVX2
rThe foole them in other operatio enable them in other operations, rebuild TensorFlow with the appropriate compiler flanls, rebuild TensorFlow with the approprformance-critical operations:  AVX AVX2liaowing CPU instrte compiler gs.

fulags.
To enable ctthem in otions in performance-criticaher l operoperations, rebuild TensorFlow with the appropriate compiler flags.
atione them in other operations, rebuild TensorFlow with the appropriate compiler flags.
s:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-27 23:21:15.977900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:21:16.001621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:21:16.005344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:21:16.011715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:21:16.021558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:21:16.033635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:21:16.034468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:21:16.036270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.06分 | step:  2560 | performance: 1.2 | accuracy: 0.27 | loss: 1.56
update: 10/2000, 耗时:0.01分/0.11分 | step:  5120 | performance: 1.8 | accuracy: 0.35 | loss: 3.04
update: 15/2000, 耗时:0.01分/0.15分 | step:  7680 | performance: 3.3 | accuracy: 0.34 | loss: 0.89
update: 20/2000, 耗时:0.01分/0.20分 | step: 10240 | performance: 4.4 | accuracy: 0.35 | loss: 1.22
update: 25/2000, 耗时:0.01分/0.25分 | step: 12800 | performance: 5.2 | accuracy: 0.35 | loss: 1.02
update: 30/2000, 耗时:0.01分/0.30分 | step: 15360 | performance: 21.6 | accuracy: 0.37 | loss: 0.99
update: 35/2000, 耗时:0.01分/0.35分 | step: 17920 | performance: 7.7 | accuracy: 0.35 | loss: 0.64
update: 40/2000, 耗时:0.01分/0.40分 | step: 20480 | performance: 4.8 | accuracy: 0.34 | loss: 0.84
update: 45/2000, 耗时:0.01分/0.45分 | step: 23040 | performance: 6.6 | accuracy: 0.34 | loss: 2.32
update: 50/2000, 耗时:0.01分/0.50分 | step: 25600 | performance: 1.0 | accuracy: 0.25 | loss: 0.46
Saving PPO weights in both H5 format and checkpoint @ update:50 
update: 55/2000, 耗时:0.01分/0.55分 | step: 28160 | performance: 0.8 | accuracy: 0.23 | loss: 0.80
update: 60/2000, 耗时:0.01分/0.60分 | step: 30720 | performance: 0.7 | accuracy: 0.32 | loss: 1.02
update: 65/2000, 耗时:0.01分/0.64分 | step: 33280 | performance: 0.4 | accuracy: 0.30 | loss: 0.82
update: 70/2000, 耗时:0.01分/0.69分 | step: 35840 | performance: 0.2 | accuracy: 0.32 | loss: 0.63
update: 75/2000, 耗时:0.01分/0.74分 | step: 38400 | performance: 0.4 | accuracy: 0.34 | loss: 1.16
update: 80/2000, 耗时:0.01分/0.78分 | step: 40960 | performance: 1.7 | accuracy: 0.35 | loss: 1.05
update: 85/2000, 耗时:0.01分/0.83分 | step: 43520 | performance: 2.2 | accuracy: 0.35 | loss: 0.71
update: 90/2000, 耗时:0.01分/0.87分 | step: 46080 | performance: 1.6 | accuracy: 0.34 | loss: 0.63
update: 95/2000, 耗时:0.01分/0.92分 | step: 48640 | performance: 1.6 | accuracy: 0.34 | loss: 1.05
Saving PPO weights in both H5 format and checkpoint @ update:99 
update:100/2000, 耗时:0.01分/0.97分 | step: 51200 | performance: 1.1 | accuracy: 0.26 | loss: 0.54
update:105/2000, 耗时:0.01分/1.02分 | step: 53760 | performance: 1.0 | accuracy: 0.25 | loss: 0.83
update:110/2000, 耗时:0.01分/1.06分 | step: 56320 | performance: 2.1 | accuracy: 0.34 | loss: 0.68
update:115/2000, 耗时:0.01分/1.11分 | step: 58880 | performance: 1.2 | accuracy: 0.33 | loss: 0.77
update:120/2000, 耗时:0.01分/1.16分 | step: 61440 | performance: 1.0 | accuracy: 0.34 | loss: 0.54
update:125/2000, 耗时:0.01分/1.20分 | step: 64000 | performance: 2.5 | accuracy: 0.36 | loss: 1.34
update:130/2000, 耗时:0.01分/1.25分 | step: 66560 | performance: 3.9 | accuracy: 0.36 | loss: 1.20
update:135/2000, 耗时:0.01分/1.29分 | step: 69120 | performance: 3.1 | accuracy: 0.35 | loss: 0.49
update:140/2000, 耗时:0.01分/1.34分 | step: 71680 | performance: 3.9 | accuracy: 0.34 | loss: 0.58
update:145/2000, 耗时:0.01分/1.39分 | step: 74240 | performance: 7.0 | accuracy: 0.35 | loss: 0.97
Saving PPO weights in both H5 format and checkpoint @ update:148 
update:150/2000, 耗时:0.01分/1.44分 | step: 76800 | performance: 1.0 | accuracy: 0.24 | loss: 0.45
update:155/2000, 耗时:0.01分/1.48分 | step: 79360 | performance: 0.9 | accuracy: 0.28 | loss: 0.85
update:160/2000, 耗时:0.01分/1.53分 | step: 81920 | performance: 1.5 | accuracy: 0.34 | loss: 0.64
update:165/2000, 耗时:0.01分/1.58分 | step: 84480 | performance: 1.2 | accuracy: 0.33 | loss: 0.85
update:170/2000, 耗时:0.01分/1.62分 | step: 87040 | performance: 1.8 | accuracy: 0.34 | loss: 0.83
update:175/2000, 耗时:0.01分/1.67分 | step: 89600 | performance: 5.3 | accuracy: 0.36 | loss: 1.63
update:180/2000, 耗时:0.01分/1.71分 | step: 92160 | performance: 5.2 | accuracy: 0.37 | loss: 0.77
update:185/2000, 耗时:0.01分/1.76分 | step: 94720 | performance: 4.7 | accuracy: 0.35 | loss: 0.48
update:190/2000, 耗时:0.01分/1.80分 | step: 97280 | performance: 4.8 | accuracy: 0.34 | loss: 0.71
update:195/2000, 耗时:0.01分/1.85分 | step: 99840 | performance: 8.7 | accuracy: 0.34 | loss: 0.82
Saving PPO weights in both H5 format and checkpoint @ update:197 
update:200/2000, 耗时:0.01分/1.90分 | step: 102400 | performance: 1.3 | accuracy: 0.22 | loss: 0.66
update:205/2000, 耗时:0.01分/1.95分 | step: 104960 | performance: 2.7 | accuracy: 0.31 | loss: 1.01
update:210/2000, 耗时:0.01分/1.99分 | step: 107520 | performance: 1.8 | accuracy: 0.34 | loss: 0.79
update:215/2000, 耗时:0.01分/2.04分 | step: 110080 | performance: 2.5 | accuracy: 0.33 | loss: 1.08
update:220/2000, 耗时:0.01分/2.08分 | step: 112640 | performance: 1.9 | accuracy: 0.33 | loss: 0.75
update:225/2000, 耗时:0.01分/2.13分 | step: 115200 | performance: 9.3 | accuracy: 0.35 | loss: 1.19
update:230/2000, 耗时:0.01分/2.17分 | step: 117760 | performance: 6.1 | accuracy: 0.35 | loss: 0.81
update:235/2000, 耗时:0.01分/2.22分 | step: 120320 | performance: 9.4 | accuracy: 0.34 | loss: 0.36
update:240/2000, 耗时:0.01分/2.27分 | step: 122880 | performance: 8.7 | accuracy: 0.33 | loss: 0.89
update:245/2000, 耗时:0.01分/2.31分 | step: 125440 | performance: 20.2 | accuracy: 0.34 | loss: 0.87
Saving PPO weights in both H5 format and checkpoint @ update:247 
update:250/2000, 耗时:0.01分/2.36分 | step: 128000 | performance: 1.5 | accuracy: 0.23 | loss: 0.75
update:255/2000, 耗时:0.01分/2.41分 | step: 130560 | performance: 1.7 | accuracy: 0.32 | loss: 1.04
update:260/2000, 耗时:0.01分/2.45分 | step: 133120 | performance: 1.7 | accuracy: 0.35 | loss: 0.70
update:265/2000, 耗时:0.01分/2.50分 | step: 135680 | performance: 1.4 | accuracy: 0.34 | loss: 0.86
update:270/2000, 耗时:0.01分/2.54分 | step: 138240 | performance: 1.1 | accuracy: 0.35 | loss: 0.52
update:275/2000, 耗时:0.01分/2.59分 | step: 140800 | performance: 10.9 | accuracy: 0.37 | loss: 1.19
update:280/2000, 耗时:0.01分/2.64分 | step: 143360 | performance: 12.0 | accuracy: 0.37 | loss: 0.76
update:285/2000, 耗时:0.01分/2.68分 | step: 145920 | performance: 7.1 | accuracy: 0.35 | loss: 0.45
update:290/2000, 耗时:0.01分/2.73分 | step: 148480 | performance: 8.2 | accuracy: 0.34 | loss: 0.97
update:295/2000, 耗时:0.01分/2.77分 | step: 151040 | performance: 13.7 | accuracy: 0.35 | loss: 0.66
Saving PPO weights in both H5 format and checkpoint @ update:296 
Saving PPO weights in both H5 format and checkpoint @ update:297 
update:300/2000, 耗时:0.01分/2.83分 | step: 153600 | performance: 2.1 | accuracy: 0.28 | loss: 0.51
update:305/2000, 耗时:0.01分/2.87分 | step: 156160 | performance: 3.1 | accuracy: 0.34 | loss: 1.47
update:310/2000, 耗时:0.01分/2.92分 | step: 158720 | performance: 1.3 | accuracy: 0.34 | loss: 0.63
update:315/2000, 耗时:0.01分/2.97分 | step: 161280 | performance: 0.8 | accuracy: 0.34 | loss: 0.83
update:320/2000, 耗时:0.01分/3.01分 | step: 163840 | performance: 1.1 | accuracy: 0.34 | loss: 0.78
update:325/2000, 耗时:0.01分/3.06分 | step: 166400 | performance: 6.9 | accuracy: 0.37 | loss: 0.93
update:330/2000, 耗时:0.01分/3.10分 | step: 168960 | performance: 4.2 | accuracy: 0.36 | loss: 0.55
update:335/2000, 耗时:0.01分/3.15分 | step: 171520 | performance: 5.9 | accuracy: 0.35 | loss: 0.54
update:340/2000, 耗时:0.01分/3.20分 | step: 174080 | performance: 8.0 | accuracy: 0.35 | loss: 1.10
update:345/2000, 耗时:0.01分/3.24分 | step: 176640 | performance: 1.0 | accuracy: 0.67 | loss: 0.50
Saving PPO weights in both H5 format and checkpoint @ update:345 
update:350/2000, 耗时:0.01分/3.29分 | step: 179200 | performance: 1.2 | accuracy: 0.34 | loss: 0.60
update:355/2000, 耗时:0.01分/3.34分 | step: 181760 | performance: 1.6 | accuracy: 0.35 | loss: 1.33
update:360/2000, 耗时:0.01分/3.38分 | step: 184320 | performance: 0.8 | accuracy: 0.34 | loss: 0.54
update:365/2000, 耗时:0.01分/3.43分 | step: 186880 | performance: 0.5 | accuracy: 0.35 | loss: 0.67
update:370/2000, 耗时:0.01分/3.47分 | step: 189440 | performance: 0.8 | accuracy: 0.35 | loss: 1.04
update:375/2000, 耗时:0.01分/3.52分 | step: 192000 | performance: 6.1 | accuracy: 0.38 | loss: 1.06
update:380/2000, 耗时:0.01分/3.57分 | step: 194560 | performance: 4.2 | accuracy: 0.37 | loss: 0.54
update:385/2000, 耗时:0.01分/3.61分 | step: 197120 | performance: 5.1 | accuracy: 0.35 | loss: 0.59
update:390/2000, 耗时:0.01分/3.66分 | step: 199680 | performance: 18.8 | accuracy: 0.36 | loss: 0.94
Saving PPO weights in both H5 format and checkpoint @ update:394 
update:395/2000, 耗时:0.01分/3.71分 | step: 202240 | performance: 1.0 | accuracy: 0.24 | loss: 0.43
Saving PPO weights in both H5 format and checkpoint @ update:395 
update:400/2000, 耗时:0.01分/3.76分 | step: 204800 | performance: 2.9 | accuracy: 0.32 | loss: 0.62
update:405/2000, 耗时:0.01分/3.81分 | step: 207360 | performance: 3.0 | accuracy: 0.36 | loss: 0.86
update:410/2000, 耗时:0.01分/3.85分 | step: 209920 | performance: 1.4 | accuracy: 0.34 | loss: 0.68
update:415/2000, 耗时:0.01分/3.90分 | step: 212480 | performance: 3.7 | accuracy: 0.34 | loss: 0.54
update:420/2000, 耗时:0.01分/3.95分 | step: 215040 | performance: 7.6 | accuracy: 0.36 | loss: 1.10
update:425/2000, 耗时:0.01分/4.00分 | step: 217600 | performance: 40.4 | accuracy: 0.38 | loss: 0.96
update:430/2000, 耗时:0.01分/4.05分 | step: 220160 | performance: 53.2 | accuracy: 0.38 | loss: 0.65
update:435/2000, 耗时:0.01分/4.10分 | step: 222720 | performance: 36.0 | accuracy: 0.36 | loss: 0.47
update:440/2000, 耗时:0.01分/4.15分 | step: 225280 | performance: 188.2 | accuracy: 0.36 | loss: 0.98
Saving PPO weights in both H5 format and checkpoint @ update:443 
Saving PPO weights in both H5 format and checkpoint @ update:444 
update:445/2000, 耗时:0.01分/4.21分 | step: 227840 | performance: 1.0 | accuracy: 0.26 | loss: 0.38
update:450/2000, 耗时:0.01分/4.26分 | step: 230400 | performance: 1.2 | accuracy: 0.26 | loss: 0.64
update:455/2000, 耗时:0.01分/4.30分 | step: 232960 | performance: 1.6 | accuracy: 0.33 | loss: 0.68
update:460/2000, 耗时:0.01分/4.35分 | step: 235520 | performance: 0.9 | accuracy: 0.33 | loss: 0.74
update:465/2000, 耗时:0.01分/4.40分 | step: 238080 | performance: 0.7 | accuracy: 0.33 | loss: 0.72
update:470/2000, 耗时:0.01分/4.44分 | step: 240640 | performance: 4.6 | accuracy: 0.36 | loss: 1.61
update:475/2000, 耗时:0.01分/4.49分 | step: 243200 | performance: 2.8 | accuracy: 0.37 | loss: 0.84
update:480/2000, 耗时:0.01分/4.54分 | step: 245760 | performance: 7.2 | accuracy: 0.37 | loss: 0.69
update:485/2000, 耗时:0.01分/4.58分 | step: 248320 | performance: 8.4 | accuracy: 0.36 | loss: 0.53
update:490/2000, 耗时:0.01分/4.63分 | step: 250880 | performance: 16.8 | accuracy: 0.36 | loss: 0.75
Saving PPO weights in both H5 format and checkpoint @ update:493 
update:495/2000, 耗时:0.01分/4.68分 | step: 253440 | performance: 1.3 | accuracy: 0.22 | loss: 0.56
update:500/2000, 耗时:0.01分/4.73分 | step: 256000 | performance: 1.2 | accuracy: 0.29 | loss: 0.71
update:505/2000, 耗时:0.01分/4.78分 | step: 258560 | performance: 1.0 | accuracy: 0.35 | loss: 0.75
update:510/2000, 耗时:0.01分/4.83分 | step: 261120 | performance: 1.1 | accuracy: 0.34 | loss: 1.05
update:515/2000, 耗时:0.01分/4.88分 | step: 263680 | performance: 1.0 | accuracy: 0.34 | loss: 0.71
update:520/2000, 耗时:0.01分/4.93分 | step: 266240 | performance: 6.0 | accuracy: 0.36 | loss: 1.37
update:525/2000, 耗时:0.01分/4.98分 | step: 268800 | performance: 3.8 | accuracy: 0.37 | loss: 0.65
update:530/2000, 耗时:0.01分/5.03分 | step: 271360 | performance: 6.2 | accuracy: 0.36 | loss: 0.47
update:535/2000, 耗时:0.01分/5.08分 | step: 273920 | performance: 5.7 | accuracy: 0.35 | loss: 0.62
update:540/2000, 耗时:0.01分/5.13分 | step: 276480 | performance: 6.5 | accuracy: 0.35 | loss: 0.79
Saving PPO weights in both H5 format and checkpoint @ update:542 
update:545/2000, 耗时:0.01分/5.18分 | step: 279040 | performance: 3.0 | accuracy: 0.31 | loss: 0.67
update:550/2000, 耗时:0.01分/5.23分 | step: 281600 | performance: 3.0 | accuracy: 0.31 | loss: 0.89
update:555/2000, 耗时:0.01分/5.28分 | step: 284160 | performance: 2.5 | accuracy: 0.35 | loss: 0.66
update:560/2000, 耗时:0.01分/5.32分 | step: 286720 | performance: 4.1 | accuracy: 0.33 | loss: 0.84
update:565/2000, 耗时:0.01分/5.37分 | step: 289280 | performance: 1.4 | accuracy: 0.32 | loss: 0.66
update:570/2000, 耗时:0.01分/5.41分 | step: 291840 | performance: 13.6 | accuracy: 0.35 | loss: 1.16
update:575/2000, 耗时:0.01分/5.46分 | step: 294400 | performance: 6.8 | accuracy: 0.36 | loss: 0.62
update:580/2000, 耗时:0.01分/5.51分 | step: 296960 | performance: 4.9 | accuracy: 0.35 | loss: 0.52
update:585/2000, 耗时:0.01分/5.55分 | step: 299520 | performance: 9.6 | accuracy: 0.34 | loss: 0.65
update:590/2000, 耗时:0.01分/5.60分 | step: 302080 | performance: 19.8 | accuracy: 0.34 | loss: 0.66
Saving PPO weights in both H5 format and checkpoint @ update:591 
Saving PPO weights in both H5 format and checkpoint @ update:592 
update:595/2000, 耗时:0.01分/5.65分 | step: 304640 | performance: 1.2 | accuracy: 0.26 | loss: 0.49
update:600/2000, 耗时:0.01分/5.70分 | step: 307200 | performance: 0.8 | accuracy: 0.29 | loss: 1.26
update:605/2000, 耗时:0.01分/5.75分 | step: 309760 | performance: 0.9 | accuracy: 0.33 | loss: 0.58
update:610/2000, 耗时:0.01分/5.79分 | step: 312320 | performance: 0.5 | accuracy: 0.32 | loss: 0.68
update:615/2000, 耗时:0.01分/5.84分 | step: 314880 | performance: 0.7 | accuracy: 0.33 | loss: 0.71
update:620/2000, 耗时:0.01分/5.88分 | step: 317440 | performance: 8.7 | accuracy: 0.37 | loss: 0.95
update:625/2000, 耗时:0.01分/5.93分 | step: 320000 | performance: 4.3 | accuracy: 0.36 | loss: 0.74
update:630/2000, 耗时:0.01分/5.98分 | step: 322560 | performance: 4.0 | accuracy: 0.35 | loss: 0.43
update:635/2000, 耗时:0.01分/6.02分 | step: 325120 | performance: 5.5 | accuracy: 0.34 | loss: 0.95
update:640/2000, 耗时:0.01分/6.07分 | step: 327680 | performance: 7.0 | accuracy: 0.35 | loss: 0.49
update:645/2000, 耗时:0.01分/6.11分 | step: 330240 | performance: 1.9 | accuracy: 0.29 | loss: 0.50
update:650/2000, 耗时:0.01分/6.16分 | step: 332800 | performance: 3.4 | accuracy: 0.33 | loss: 1.30
update:655/2000, 耗时:0.01分/6.21分 | step: 335360 | performance: 1.2 | accuracy: 0.33 | loss: 0.55
update:660/2000, 耗时:0.01分/6.25分 | step: 337920 | performance: 2.2 | accuracy: 0.33 | loss: 0.64
update:665/2000, 耗时:0.01分/6.30分 | step: 340480 | performance: 2.4 | accuracy: 0.34 | loss: 0.92
update:670/2000, 耗时:0.01分/6.34分 | step: 343040 | performance: 20.4 | accuracy: 0.37 | loss: 1.03
update:675/2000, 耗时:0.01分/6.39分 | step: 345600 | performance: 14.4 | accuracy: 0.36 | loss: 0.63
update:680/2000, 耗时:0.01分/6.43分 | step: 348160 | performance: 6.4 | accuracy: 0.34 | loss: 0.45
update:685/2000, 耗时:0.01分/6.48分 | step: 350720 | performance: 6.9 | accuracy: 0.33 | loss: 1.02
update:690/2000, 耗时:0.01分/6.53分 | step: 353280 | performance: 16.6 | accuracy: 0.33 | loss: 0.52
update:695/2000, 耗时:0.01分/6.57分 | step: 355840 | performance: 2.3 | accuracy: 0.26 | loss: 0.44
update:700/2000, 耗时:0.01分/6.62分 | step: 358400 | performance: 3.2 | accuracy: 0.32 | loss: 0.92
update:705/2000, 耗时:0.01分/6.66分 | step: 360960 | performance: 2.9 | accuracy: 0.31 | loss: 0.52
update:710/2000, 耗时:0.01分/6.71分 | step: 363520 | performance: 1.2 | accuracy: 0.30 | loss: 0.58
update:715/2000, 耗时:0.01分/6.76分 | step: 366080 | performance: 2.2 | accuracy: 0.32 | loss: 1.04
update:720/2000, 耗时:0.01分/6.80分 | step: 368640 | performance: 9.3 | accuracy: 0.35 | loss: 1.00
update:725/2000, 耗时:0.01分/6.85分 | step: 371200 | performance: 4.2 | accuracy: 0.33 | loss: 0.57
update:730/2000, 耗时:0.01分/6.89分 | step: 373760 | performance: 6.5 | accuracy: 0.32 | loss: 0.39
update:735/2000, 耗时:0.01分/6.94分 | step: 376320 | performance: 5.4 | accuracy: 0.32 | loss: 0.88
update:740/2000, 耗时:0.01分/6.99分 | step: 378880 | performance: 1.1 | accuracy: 0.37 | loss: 0.40
update:745/2000, 耗时:0.01分/7.03分 | step: 381440 | performance: 0.9 | accuracy: 0.26 | loss: 0.52
update:750/2000, 耗时:0.01分/7.08分 | step: 384000 | performance: 0.9 | accuracy: 0.29 | loss: 0.72
update:755/2000, 耗时:0.01分/7.12分 | step: 386560 | performance: 0.4 | accuracy: 0.28 | loss: 0.53
update:760/2000, 耗时:0.01分/7.17分 | step: 389120 | performance: 0.3 | accuracy: 0.27 | loss: 0.55
update:765/2000, 耗时:0.01分/7.22分 | step: 391680 | performance: 0.5 | accuracy: 0.30 | loss: 1.34
update:770/2000, 耗时:0.01分/7.26分 | step: 394240 | performance: 0.9 | accuracy: 0.32 | loss: 0.72
update:775/2000, 耗时:0.01分/7.31分 | step: 396800 | performance: 1.0 | accuracy: 0.31 | loss: 0.58
update:780/2000, 耗时:0.01分/7.35分 | step: 399360 | performance: 0.7 | accuracy: 0.29 | loss: 0.41
update:785/2000, 耗时:0.01分/7.40分 | step: 401920 | performance: 1.5 | accuracy: 0.29 | loss: 0.66
update:790/2000, 耗时:0.01分/7.44分 | step: 404480 | performance: 1.0 | accuracy: 0.19 | loss: 0.48
update:795/2000, 耗时:0.01分/7.49分 | step: 407040 | performance: 2.0 | accuracy: 0.24 | loss: 0.55
update:800/2000, 耗时:0.01分/7.53分 | step: 409600 | performance: 2.8 | accuracy: 0.29 | loss: 0.57
update:805/2000, 耗时:0.01分/7.58分 | step: 412160 | performance: 1.4 | accuracy: 0.27 | loss: 0.68
update:810/2000, 耗时:0.01分/7.63分 | step: 414720 | performance: 1.4 | accuracy: 0.26 | loss: 0.56
update:815/2000, 耗时:0.01分/7.67分 | step: 417280 | performance: 4.6 | accuracy: 0.29 | loss: 1.33
update:820/2000, 耗时:0.01分/7.72分 | step: 419840 | performance: 5.0 | accuracy: 0.30 | loss: 0.46
update:825/2000, 耗时:0.01分/7.76分 | step: 422400 | performance: 7.0 | accuracy: 0.29 | loss: 0.40
update:830/2000, 耗时:0.01分/7.81分 | step: 424960 | performance: 6.2 | accuracy: 0.28 | loss: 0.40
update:835/2000, 耗时:0.01分/7.85分 | step: 427520 | performance: 22.0 | accuracy: 0.28 | loss: 0.59
update:840/2000, 耗时:0.01分/7.90分 | step: 430080 | performance: 1.5 | accuracy: 0.24 | loss: 0.38
update:845/2000, 耗时:0.01分/7.94分 | step: 432640 | performance: 0.9 | accuracy: 0.22 | loss: 0.65
update:850/2000, 耗时:0.01分/7.99分 | step: 435200 | performance: 0.9 | accuracy: 0.27 | loss: 0.44
update:855/2000, 耗时:0.01分/8.04分 | step: 437760 | performance: 0.7 | accuracy: 0.24 | loss: 0.53
update:860/2000, 耗时:0.01分/8.08分 | step: 440320 | performance: 0.4 | accuracy: 0.24 | loss: 0.53
update:865/2000, 耗时:0.01分/8.13分 | step: 442880 | performance: 1.1 | accuracy: 0.27 | loss: 1.17
update:870/2000, 耗时:0.01分/8.17分 | step: 445440 | performance: 1.3 | accuracy: 0.29 | loss: 0.47
update:875/2000, 耗时:0.01分/8.22分 | step: 448000 | performance: 0.9 | accuracy: 0.28 | loss: 0.34
update:880/2000, 耗时:0.01分/8.26分 | step: 450560 | performance: 0.6 | accuracy: 0.26 | loss: 0.33
update:885/2000, 耗时:0.01分/8.31分 | step: 453120 | performance: 1.1 | accuracy: 0.27 | loss: 0.45
update:890/2000, 耗时:0.01分/8.35分 | step: 455680 | performance: 1.7 | accuracy: 0.23 | loss: 0.37
update:895/2000, 耗时:0.01分/8.40分 | step: 458240 | performance: 1.5 | accuracy: 0.19 | loss: 0.76
update:900/2000, 耗时:0.01分/8.44分 | step: 460800 | performance: 2.3 | accuracy: 0.23 | loss: 0.38
update:905/2000, 耗时:0.01分/8.49分 | step: 463360 | performance: 1.6 | accuracy: 0.22 | loss: 0.37
update:910/2000, 耗时:0.01分/8.54分 | step: 465920 | performance: 2.2 | accuracy: 0.23 | loss: 0.41
update:915/2000, 耗时:0.01分/8.58分 | step: 468480 | performance: 10.1 | accuracy: 0.26 | loss: 0.93
update:920/2000, 耗时:0.01分/8.63分 | step: 471040 | performance: 6.5 | accuracy: 0.26 | loss: 0.39
update:925/2000, 耗时:0.01分/8.67分 | step: 473600 | performance: 7.9 | accuracy: 0.25 | loss: 0.23
update:930/2000, 耗时:0.01分/8.72分 | step: 476160 | performance: 12.0 | accuracy: 0.24 | loss: 0.48
update:935/2000, 耗时:0.01分/8.76分 | step: 478720 | performance: 17.1 | accuracy: 0.25 | loss: 0.39
update:940/2000, 耗时:0.01分/8.81分 | step: 481280 | performance: 0.6 | accuracy: 0.16 | loss: 0.27
update:945/2000, 耗时:0.01分/8.86分 | step: 483840 | performance: 0.9 | accuracy: 0.18 | loss: 0.93
update:950/2000, 耗时:0.01分/8.90分 | step: 486400 | performance: 0.5 | accuracy: 0.20 | loss: 0.28
update:955/2000, 耗时:0.01分/8.95分 | step: 488960 | performance: 0.7 | accuracy: 0.19 | loss: 0.37
update:960/2000, 耗时:0.01分/8.99分 | step: 491520 | performance: 0.6 | accuracy: 0.20 | loss: 0.48
update:965/2000, 耗时:0.01分/9.04分 | step: 494080 | performance: 4.8 | accuracy: 0.24 | loss: 0.83
update:970/2000, 耗时:0.01分/9.09分 | step: 496640 | performance: 2.6 | accuracy: 0.23 | loss: 0.29
update:975/2000, 耗时:0.01分/9.13分 | step: 499200 | performance: 2.9 | accuracy: 0.22 | loss: 0.20
update:980/2000, 耗时:0.01分/9.18分 | step: 501760 | performance: 3.9 | accuracy: 0.20 | loss: 0.60
update:985/2000, 耗时:0.01分/9.23分 | step: 504320 | performance: 3.9 | accuracy: 0.20 | loss: 0.25
step: 504827 | worker_2@n_step_63: average total_reward after train data exhaustion : 101.4 | max total_reward: 254.5
update:990/2000, 耗时:0.01分/9.27分 | step: 506880 | performance: 1.1 | accuracy: 0.13 | loss: 0.23
update:995/2000, 耗时:0.01分/9.32分 | step: 509440 | performance: 1.4 | accuracy: 0.16 | loss: 0.66
update:1000/2000, 耗时:0.01分/9.37分 | step: 512000 | performance: 1.0 | accuracy: 0.16 | loss: 0.27
update:1005/2000, 耗时:0.01分/9.42分 | step: 514560 | performance: 1.2 | accuracy: 0.16 | loss: 0.30
update:1010/2000, 耗时:0.01分/9.46分 | step: 517120 | performance: 1.6 | accuracy: 0.17 | loss: 0.45
update:1015/2000, 耗时:0.01分/9.51分 | step: 519680 | performance: 2.9 | accuracy: 0.19 | loss: 0.60
update:1020/2000, 耗时:0.01分/9.56分 | step: 522240 | performance: 1.2 | accuracy: 0.18 | loss: 0.24
update:1025/2000, 耗时:0.01分/9.60分 | step: 524800 | performance: 1.3 | accuracy: 0.17 | loss: 0.18
update:1030/2000, 耗时:0.01分/9.65分 | step: 527360 | performance: 1.2 | accuracy: 0.16 | loss: 0.44
update:1035/2000, 耗时:0.01分/9.70分 | step: 529920 | performance: 0.9 | accuracy: 0.11 | loss: 0.23
update:1040/2000, 耗时:0.01分/9.74分 | step: 532480 | performance: 1.1 | accuracy: 0.12 | loss: 0.17
update:1045/2000, 耗时:0.01分/9.79分 | step: 535040 | performance: 1.4 | accuracy: 0.12 | loss: 0.37
update:1050/2000, 耗时:0.01分/9.84分 | step: 537600 | performance: 1.0 | accuracy: 0.13 | loss: 0.16
update:1055/2000, 耗时:0.01分/9.88分 | step: 540160 | performance: 1.2 | accuracy: 0.12 | loss: 0.23
update:1060/2000, 耗时:0.01分/9.93分 | step: 542720 | performance: 1.1 | accuracy: 0.12 | loss: 0.29
update:1065/2000, 耗时:0.01分/9.98分 | step: 545280 | performance: 1.4 | accuracy: 0.13 | loss: 0.35
update:1070/2000, 耗时:0.01分/10.02分 | step: 547840 | performance: 2.3 | accuracy: 0.13 | loss: 0.19
update:1075/2000, 耗时:0.01分/10.07分 | step: 550400 | performance: 2.0 | accuracy: 0.13 | loss: 0.16
update:1080/2000, 耗时:0.01分/10.12分 | step: 552960 | performance: 1.7 | accuracy: 0.12 | loss: 0.20
update:1085/2000, 耗时:0.01分/10.17分 | step: 555520 | performance: 1.6 | accuracy: 0.12 | loss: 0.19
update:1090/2000, 耗时:0.01分/10.21分 | step: 558080 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 560125 | worker_4@n_step_63: average total_reward after train data exhaustion : 3.7 | max total_reward: 254.5
step: 560634 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.5
step: 560640 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
update:1095/2000, 耗时:0.01分/10.26分 | step: 560640 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 562173 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.5
step: 562682 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
step: 563199 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1100/2000, 耗时:0.01分/10.31分 | step: 563200 | performance: 1.0 | accuracy: 0.16 | loss: 0.13
step: 564730 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.5
step: 564733 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.5
update:1105/2000, 耗时:0.01分/10.35分 | step: 565760 | performance: 1.0 | accuracy: 0.12 | loss: 0.11
step: 566782 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1110/2000, 耗时:0.01分/10.40分 | step: 568320 | performance: 1.0 | accuracy: 0.06 | loss: 0.08
step: 568827 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.5
update:1115/2000, 耗时:0.01分/10.45分 | step: 570880 | performance: 1.1 | accuracy: 0.13 | loss: 0.11
step: 572921 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.5
update:1120/2000, 耗时:0.01分/10.49分 | step: 573440 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
update:1125/2000, 耗时:0.01分/10.54分 | step: 576000 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 576510 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
step: 577021 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.5 | max total_reward: 254.5
step: 578047 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.5
update:1130/2000, 耗时:0.01分/10.59分 | step: 578560 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 579580 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.5
step: 581117 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
update:1135/2000, 耗时:0.01分/10.63分 | step: 581120 | performance: 1.0 | accuracy: 0.25 | loss: 0.11
update:1140/2000, 耗时:0.01分/10.68分 | step: 583680 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 584699 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
update:1145/2000, 耗时:0.01分/10.73分 | step: 586240 | performance: 1.0 | accuracy: 0.23 | loss: 0.15
step: 586751 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.5
update:1150/2000, 耗时:0.01分/10.78分 | step: 588800 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 590841 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
update:1155/2000, 耗时:0.01分/10.83分 | step: 591360 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 592384 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.5
step: 592890 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.5
update:1160/2000, 耗时:0.01分/10.88分 | step: 593920 | performance: 1.0 | accuracy: 0.17 | loss: 0.11
update:1165/2000, 耗时:0.01分/10.93分 | step: 596480 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 596991 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.5
step: 598521 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
step: 598522 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
update:1170/2000, 耗时:0.01分/10.97分 | step: 599040 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
update:1175/2000, 耗时:0.01分/11.03分 | step: 601600 | performance: 1.0 | accuracy: 0.25 | loss: 0.12
update:1180/2000, 耗时:0.01分/11.07分 | step: 604160 | performance: 1.0 | accuracy: 0.13 | loss: 0.09
step: 605695 | worker_6@n_step_63: average total_reward after train data exhaustion : -0.4 | max total_reward: 254.5
update:1185/2000, 耗时:0.01分/11.12分 | step: 606720 | performance: 1.0 | accuracy: 0.12 | loss: 0.09
step: 607226 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.5
step: 607743 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
step: 609275 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.5
update:1190/2000, 耗时:0.01分/11.17分 | step: 609280 | performance: 1.0 | accuracy: 0.11 | loss: 0.11
step: 610298 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
step: 610815 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 254.5
update:1195/2000, 耗时:0.01分/11.22分 | step: 611840 | performance: 1.0 | accuracy: 0.07 | loss: 0.10
step: 613884 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
update:1200/2000, 耗时:0.01分/11.27分 | step: 614400 | performance: 1.0 | accuracy: 0.15 | loss: 0.12
step: 615934 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.5
step: 616954 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
update:1205/2000, 耗时:0.01分/11.31分 | step: 616960 | performance: 1.0 | accuracy: 0.10 | loss: 0.07
update:1210/2000, 耗时:0.01分/11.36分 | step: 619520 | performance: 1.0 | accuracy: 0.18 | loss: 0.11
step: 620543 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.8 | max total_reward: 254.5
update:1215/2000, 耗时:0.01分/11.41分 | step: 622080 | performance: 1.0 | accuracy: 0.21 | loss: 0.11
update:1220/2000, 耗时:0.01分/11.45分 | step: 624640 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 626170 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.3 | max total_reward: 254.5
update:1225/2000, 耗时:0.01分/11.50分 | step: 627200 | performance: 1.0 | accuracy: 0.11 | loss: 0.19
step: 628729 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
step: 628736 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 254.5
update:1230/2000, 耗时:0.01分/11.55分 | step: 629760 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
step: 630269 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
step: 631289 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.5
step: 631808 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.5
update:1235/2000, 耗时:0.01分/11.59分 | step: 632320 | performance: 1.0 | accuracy: 0.08 | loss: 0.10
step: 633337 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.4 | max total_reward: 254.5
step: 633342 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 254.5
update:1240/2000, 耗时:0.01分/11.64分 | step: 634880 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 635388 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 254.5
step: 635904 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
step: 636922 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
update:1245/2000, 耗时:0.01分/11.69分 | step: 637440 | performance: 0.9 | accuracy: 0.14 | loss: 0.12
step: 639488 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.5
update:1250/2000, 耗时:0.01分/11.73分 | step: 640000 | performance: 1.0 | accuracy: 0.10 | loss: 0.07
step: 641022 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1255/2000, 耗时:0.01分/11.78分 | step: 642560 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 643070 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
step: 644090 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
update:1260/2000, 耗时:0.01分/11.82分 | step: 645120 | performance: 1.2 | accuracy: 0.11 | loss: 0.10
step: 645625 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.5
step: 647161 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 254.5
update:1265/2000, 耗时:0.01分/11.87分 | step: 647680 | performance: 1.0 | accuracy: 0.12 | loss: 0.13
step: 648186 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 254.5
step: 649209 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.5
update:1270/2000, 耗时:0.01分/11.92分 | step: 650240 | performance: 1.1 | accuracy: 0.12 | loss: 0.10
step: 650752 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 254.5
step: 651260 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1275/2000, 耗时:0.01分/11.96分 | step: 652800 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 653311 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.5
step: 653312 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.5
update:1280/2000, 耗时:0.01分/12.01分 | step: 655360 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 656891 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
update:1285/2000, 耗时:0.01分/12.05分 | step: 657920 | performance: 1.1 | accuracy: 0.14 | loss: 0.12
step: 658939 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
step: 659964 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 254.5
update:1290/2000, 耗时:0.01分/12.10分 | step: 660480 | performance: 1.0 | accuracy: 0.10 | loss: 0.10
step: 661504 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
step: 662010 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.5
step: 663033 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
update:1295/2000, 耗时:0.01分/12.15分 | step: 663040 | performance: 1.1 | accuracy: 0.15 | loss: 0.10
step: 663548 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
update:1300/2000, 耗时:0.01分/12.19分 | step: 665600 | performance: 1.4 | accuracy: 0.10 | loss: 0.10
step: 668157 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 254.5
update:1305/2000, 耗时:0.01分/12.24分 | step: 668160 | performance: 1.0 | accuracy: 0.15 | loss: 0.08
step: 669696 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.5
update:1310/2000, 耗时:0.01分/12.28分 | step: 670720 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 671228 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.5
step: 672249 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
step: 672254 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.5
update:1315/2000, 耗时:0.01分/12.33分 | step: 673280 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
update:1320/2000, 耗时:0.01分/12.38分 | step: 675840 | performance: 1.1 | accuracy: 0.13 | loss: 0.12
step: 676859 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
step: 677375 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.5
step: 677376 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.5
update:1325/2000, 耗时:0.01分/12.42分 | step: 678400 | performance: 1.1 | accuracy: 0.11 | loss: 0.16
step: 680441 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 254.5
update:1330/2000, 耗时:0.01分/12.47分 | step: 680960 | performance: 1.0 | accuracy: 0.10 | loss: 0.12
step: 683007 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 254.5
update:1335/2000, 耗时:0.01分/12.52分 | step: 683520 | performance: 1.0 | accuracy: 0.16 | loss: 0.10
step: 685055 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
update:1340/2000, 耗时:0.01分/12.56分 | step: 686080 | performance: 1.0 | accuracy: 0.50 | loss: 0.10
step: 686586 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.5
step: 686587 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
update:1345/2000, 耗时:0.01分/12.61分 | step: 688640 | performance: 1.1 | accuracy: 0.11 | loss: 0.12
step: 689146 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1350/2000, 耗时:0.01分/12.65分 | step: 691200 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
update:1355/2000, 耗时:0.01分/12.70分 | step: 693760 | performance: 1.0 | accuracy: 0.16 | loss: 0.11
step: 695806 | worker_5@n_step_63: average total_reward after train data exhaustion : 2.2 | max total_reward: 254.5
update:1360/2000, 耗时:0.01分/12.75分 | step: 696320 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
update:1365/2000, 耗时:0.01分/12.79分 | step: 698880 | performance: 1.1 | accuracy: 0.13 | loss: 0.11
update:1370/2000, 耗时:0.01分/12.84分 | step: 701440 | performance: 1.1 | accuracy: 0.14 | loss: 0.16
update:1375/2000, 耗时:0.01分/12.89分 | step: 704000 | performance: 1.8 | accuracy: 0.12 | loss: 0.13
step: 704511 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.5
step: 706042 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1380/2000, 耗时:0.01分/12.93分 | step: 706560 | performance: 1.0 | accuracy: 0.17 | loss: 0.10
update:1385/2000, 耗时:0.01分/12.98分 | step: 709120 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 709626 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 254.5
step: 709628 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
step: 710652 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 254.5
update:1390/2000, 耗时:0.01分/13.03分 | step: 711680 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
update:1395/2000, 耗时:0.01分/13.07分 | step: 714240 | performance: 1.1 | accuracy: 0.13 | loss: 0.11
step: 714752 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 254.5
update:1400/2000, 耗时:0.01分/13.12分 | step: 716800 | performance: 1.0 | accuracy: 0.16 | loss: 0.12
step: 717307 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 254.5
step: 718845 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 254.5
update:1405/2000, 耗时:0.01分/13.17分 | step: 719360 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
update:1410/2000, 耗时:0.01分/13.21分 | step: 721920 | performance: 1.0 | accuracy: 0.15 | loss: 0.14
step: 722940 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.0 | max total_reward: 254.5
update:1415/2000, 耗时:0.01分/13.26分 | step: 724480 | performance: 1.0 | accuracy: 0.16 | loss: 0.11
step: 724986 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 254.5
update:1420/2000, 耗时:0.01分/13.30分 | step: 727040 | performance: 1.0 | accuracy: 0.17 | loss: 0.10
step: 728063 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 254.5
update:1425/2000, 耗时:0.01分/13.35分 | step: 729600 | performance: 1.0 | accuracy: 0.19 | loss: 0.13
step: 731642 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
update:1430/2000, 耗时:0.01分/13.40分 | step: 732160 | performance: 1.0 | accuracy: 0.12 | loss: 0.11
step: 733177 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 254.5
update:1435/2000, 耗时:0.01分/13.44分 | step: 734720 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 736767 | worker_6@n_step_63: average total_reward after train data exhaustion : 2.6 | max total_reward: 254.5
step: 737280 | worker_7@n_step_63: average total_reward after train data exhaustion : 2.8 | max total_reward: 254.5
update:1440/2000, 耗时:0.01分/13.49分 | step: 737280 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 737789 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.5
step: 739327 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
update:1445/2000, 耗时:0.01分/13.53分 | step: 739840 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:1450/2000, 耗时:0.01分/13.58分 | step: 742400 | performance: 1.5 | accuracy: 0.12 | loss: 0.15
update:1455/2000, 耗时:0.01分/13.63分 | step: 744960 | performance: 1.1 | accuracy: 0.14 | loss: 0.12
update:1460/2000, 耗时:0.01分/13.67分 | step: 747520 | performance: 1.4 | accuracy: 0.11 | loss: 0.11
step: 750075 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 254.5
update:1465/2000, 耗时:0.01分/13.72分 | step: 750080 | performance: 1.1 | accuracy: 0.16 | loss: 0.17
step: 750592 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 254.5
update:1470/2000, 耗时:0.01分/13.76分 | step: 752640 | performance: 1.0 | accuracy: 0.08 | loss: 0.12
step: 753662 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.5
update:1475/2000, 耗时:0.01分/13.81分 | step: 755200 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 756221 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.5
update:1480/2000, 耗时:0.01分/13.86分 | step: 757760 | performance: 1.0 | accuracy: 0.08 | loss: 0.11
step: 758265 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
step: 758778 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 254.5
step: 760315 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 254.5
update:1485/2000, 耗时:0.01分/13.90分 | step: 760320 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
update:1490/2000, 耗时:0.01分/13.95分 | step: 762880 | performance: 0.9 | accuracy: 0.15 | loss: 0.15
update:1495/2000, 耗时:0.01分/13.99分 | step: 765440 | performance: 1.1 | accuracy: 0.11 | loss: 0.14
step: 767488 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1500/2000, 耗时:0.01分/14.04分 | step: 768000 | performance: 1.0 | accuracy: 0.15 | loss: 0.11
step: 769533 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 254.5
update:1505/2000, 耗时:0.01分/14.08分 | step: 770560 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:1510/2000, 耗时:0.01分/14.13分 | step: 773120 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
update:1515/2000, 耗时:0.01分/14.18分 | step: 775680 | performance: 1.0 | accuracy: 0.12 | loss: 0.16
step: 776704 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 254.5
update:1520/2000, 耗时:0.01分/14.22分 | step: 778240 | performance: 1.0 | accuracy: 0.07 | loss: 0.11
step: 779259 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.5 | max total_reward: 254.5
update:1525/2000, 耗时:0.01分/14.27分 | step: 780800 | performance: 0.9 | accuracy: 0.11 | loss: 0.12
step: 781817 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
step: 783358 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.8 | max total_reward: 254.5
update:1530/2000, 耗时:0.01分/14.31分 | step: 783360 | performance: 1.0 | accuracy: 0.17 | loss: 0.12
step: 783865 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 254.5
step: 784893 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 254.5
update:1535/2000, 耗时:0.01分/14.36分 | step: 785920 | performance: 1.0 | accuracy: 0.06 | loss: 0.08
step: 787961 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
update:1540/2000, 耗时:0.01分/14.41分 | step: 788480 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:1545/2000, 耗时:0.01分/14.45分 | step: 791040 | performance: 0.9 | accuracy: 0.11 | loss: 0.12
step: 792570 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 254.5
update:1550/2000, 耗时:0.01分/14.50分 | step: 793600 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
update:1555/2000, 耗时:0.01分/14.54分 | step: 796160 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 796669 | worker_4@n_step_63: average total_reward after train data exhaustion : 2.0 | max total_reward: 254.5
update:1560/2000, 耗时:0.01分/14.59分 | step: 798720 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
update:1565/2000, 耗时:0.01分/14.64分 | step: 801280 | performance: 1.0 | accuracy: 0.11 | loss: 0.15
update:1570/2000, 耗时:0.01分/14.68分 | step: 803840 | performance: 1.0 | accuracy: 0.19 | loss: 0.11
update:1575/2000, 耗时:0.01分/14.73分 | step: 806400 | performance: 1.2 | accuracy: 0.11 | loss: 0.13
update:1580/2000, 耗时:0.01分/14.78分 | step: 808960 | performance: 1.0 | accuracy: 0.06 | loss: 0.15
step: 810492 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
update:1585/2000, 耗时:0.01分/14.82分 | step: 811520 | performance: 1.0 | accuracy: 0.15 | loss: 0.16
update:1590/2000, 耗时:0.01分/14.87分 | step: 814080 | performance: 1.0 | accuracy: 0.23 | loss: 0.12
update:1595/2000, 耗时:0.01分/14.92分 | step: 816640 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 817657 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 254.5
update:1600/2000, 耗时:0.01分/14.96分 | step: 819200 | performance: 1.0 | accuracy: 0.20 | loss: 0.13
step: 820220 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
update:1605/2000, 耗时:0.01分/15.01分 | step: 821760 | performance: 1.0 | accuracy: 0.12 | loss: 0.12
step: 823295 | worker_6@n_step_63: average total_reward after train data exhaustion : 3.9 | max total_reward: 254.5
step: 823296 | worker_7@n_step_63: average total_reward after train data exhaustion : 3.9 | max total_reward: 254.5
update:1610/2000, 耗时:0.01分/15.06分 | step: 824320 | performance: 1.0 | accuracy: 0.15 | loss: 0.13
step: 825344 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
step: 825855 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 254.5
update:1615/2000, 耗时:0.01分/15.10分 | step: 826880 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:1620/2000, 耗时:0.01分/15.15分 | step: 829440 | performance: 1.2 | accuracy: 0.12 | loss: 0.15
step: 831996 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.5
update:1625/2000, 耗时:0.01分/15.19分 | step: 832000 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 833536 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.5
update:1630/2000, 耗时:0.01分/15.24分 | step: 834560 | performance: 1.0 | accuracy: 0.12 | loss: 0.13
step: 835582 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
step: 836608 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
update:1635/2000, 耗时:0.01分/15.29分 | step: 837120 | performance: 1.0 | accuracy: 0.12 | loss: 0.09
step: 837630 | worker_5@n_step_63: average total_reward after train data exhaustion : 2.6 | max total_reward: 254.5
update:1640/2000, 耗时:0.01分/15.33分 | step: 839680 | performance: 1.1 | accuracy: 0.25 | loss: 0.13
update:1645/2000, 耗时:0.01分/15.38分 | step: 842240 | performance: 1.1 | accuracy: 0.11 | loss: 0.15
step: 843263 | worker_6@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 254.5
update:1650/2000, 耗时:0.01分/15.42分 | step: 844800 | performance: 1.1 | accuracy: 0.12 | loss: 0.10
step: 846333 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
step: 846841 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.5
update:1655/2000, 耗时:0.01分/15.47分 | step: 847360 | performance: 1.0 | accuracy: 0.13 | loss: 0.08
update:1660/2000, 耗时:0.01分/15.51分 | step: 849920 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 850432 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
update:1665/2000, 耗时:0.01分/15.56分 | step: 852480 | performance: 1.0 | accuracy: 0.14 | loss: 0.14
step: 852989 | worker_4@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 254.5
step: 855033 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 254.5
update:1670/2000, 耗时:0.01分/15.61分 | step: 855040 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 855548 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 254.5
update:1675/2000, 耗时:0.01分/15.65分 | step: 857600 | performance: 1.0 | accuracy: 0.16 | loss: 0.14
step: 859129 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
step: 859130 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
step: 859647 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 254.5
update:1680/2000, 耗时:0.01分/15.70分 | step: 860160 | performance: 1.0 | accuracy: 0.13 | loss: 0.12
update:1685/2000, 耗时:0.01分/15.75分 | step: 862720 | performance: 1.1 | accuracy: 0.10 | loss: 0.12
step: 863230 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 254.5
update:1690/2000, 耗时:0.01分/15.79分 | step: 865280 | performance: 1.1 | accuracy: 0.15 | loss: 0.11
update:1695/2000, 耗时:0.01分/15.84分 | step: 867840 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:1700/2000, 耗时:0.01分/15.89分 | step: 870400 | performance: 1.3 | accuracy: 0.13 | loss: 0.15
step: 870905 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.5
step: 872445 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 254.5
update:1705/2000, 耗时:0.01分/15.93分 | step: 872960 | performance: 1.1 | accuracy: 0.10 | loss: 0.12
step: 873466 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.3 | max total_reward: 254.5
step: 875008 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
update:1710/2000, 耗时:0.01分/15.98分 | step: 875520 | performance: 1.0 | accuracy: 0.08 | loss: 0.12
step: 878077 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.8 | max total_reward: 254.5
update:1715/2000, 耗时:0.01分/16.03分 | step: 878080 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
update:1720/2000, 耗时:0.01分/16.08分 | step: 880640 | performance: 1.0 | accuracy: 0.11 | loss: 0.11
step: 882684 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.5
step: 882688 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.5
step: 883198 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.5
update:1725/2000, 耗时:0.01分/16.12分 | step: 883200 | performance: 1.1 | accuracy: 0.13 | loss: 0.10
update:1730/2000, 耗时:0.01分/16.17分 | step: 885760 | performance: 1.1 | accuracy: 0.14 | loss: 0.13
update:1735/2000, 耗时:0.01分/16.22分 | step: 888320 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 888831 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 254.5
step: 889849 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.5
step: 890363 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1740/2000, 耗时:0.01分/16.27分 | step: 890880 | performance: 1.0 | accuracy: 0.15 | loss: 0.11
step: 891390 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1745/2000, 耗时:0.01分/16.31分 | step: 893440 | performance: 1.4 | accuracy: 0.12 | loss: 0.11
update:1750/2000, 耗时:0.01分/16.36分 | step: 896000 | performance: 1.3 | accuracy: 0.11 | loss: 0.15
step: 896511 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 254.5
update:1755/2000, 耗时:0.01分/16.41分 | step: 898560 | performance: 1.0 | accuracy: 0.10 | loss: 0.12
step: 900090 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 254.5
update:1760/2000, 耗时:0.01分/16.45分 | step: 901120 | performance: 1.4 | accuracy: 0.12 | loss: 0.14
step: 901630 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
update:1765/2000, 耗时:0.01分/16.50分 | step: 903680 | performance: 1.5 | accuracy: 0.11 | loss: 0.10
update:1770/2000, 耗时:0.01分/16.55分 | step: 906240 | performance: 1.4 | accuracy: 0.11 | loss: 0.17
step: 908282 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 254.5
update:1775/2000, 耗时:0.01分/16.59分 | step: 908800 | performance: 1.6 | accuracy: 0.11 | loss: 0.14
step: 909308 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.0 | max total_reward: 254.5
step: 909822 | worker_5@n_step_63: average total_reward after train data exhaustion : 2.3 | max total_reward: 254.5
update:1780/2000, 耗时:0.01分/16.64分 | step: 911360 | performance: 2.1 | accuracy: 0.10 | loss: 0.14
step: 912380 | worker_3@n_step_63: average total_reward after train data exhaustion : 5.4 | max total_reward: 254.5
update:1785/2000, 耗时:0.01分/16.69分 | step: 913920 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 914937 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.5 | max total_reward: 254.5
update:1790/2000, 耗时:0.01分/16.73分 | step: 916480 | performance: 1.4 | accuracy: 0.12 | loss: 0.13
update:1795/2000, 耗时:0.01分/16.78分 | step: 919040 | performance: 1.1 | accuracy: 0.13 | loss: 0.11
update:1800/2000, 耗时:0.01分/16.83分 | step: 921600 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 922105 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
step: 922622 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 254.5
update:1805/2000, 耗时:0.01分/16.88分 | step: 924160 | performance: 1.0 | accuracy: 0.14 | loss: 0.12
step: 926202 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 254.5
step: 926715 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 254.5
update:1810/2000, 耗时:0.01分/16.93分 | step: 926720 | performance: 1.1 | accuracy: 0.15 | loss: 0.13
update:1815/2000, 耗时:0.01分/16.98分 | step: 929280 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 931838 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
update:1820/2000, 耗时:0.01分/17.03分 | step: 931840 | performance: 1.0 | accuracy: 0.23 | loss: 0.13
update:1825/2000, 耗时:0.01分/17.08分 | step: 934400 | performance: 0.9 | accuracy: 0.11 | loss: 0.12
step: 936957 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1830/2000, 耗时:0.01分/17.13分 | step: 936960 | performance: 1.0 | accuracy: 0.12 | loss: 0.11
step: 937983 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 254.5
update:1835/2000, 耗时:0.01分/17.18分 | step: 939520 | performance: 1.1 | accuracy: 0.17 | loss: 0.14
step: 940543 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.8 | max total_reward: 254.5
update:1840/2000, 耗时:0.01分/17.23分 | step: 942080 | performance: 1.5 | accuracy: 0.11 | loss: 0.13
update:1845/2000, 耗时:0.01分/17.28分 | step: 944640 | performance: 0.9 | accuracy: 0.12 | loss: 0.14
step: 946173 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 254.5
update:1850/2000, 耗时:0.01分/17.32分 | step: 947200 | performance: 1.1 | accuracy: 0.12 | loss: 0.12
update:1855/2000, 耗时:0.01分/17.37分 | step: 949760 | performance: 1.1 | accuracy: 0.12 | loss: 0.16
update:1860/2000, 耗时:0.01分/17.42分 | step: 952320 | performance: 1.0 | accuracy: 0.11 | loss: 0.18
step: 953338 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.6 | max total_reward: 254.5
update:1865/2000, 耗时:0.01分/17.46分 | step: 954880 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 956923 | worker_2@n_step_63: average total_reward after train data exhaustion : 2.7 | max total_reward: 254.5
update:1870/2000, 耗时:0.01分/17.51分 | step: 957440 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
update:1875/2000, 耗时:0.01分/17.56分 | step: 960000 | performance: 1.0 | accuracy: 0.14 | loss: 0.13
step: 961024 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
step: 962555 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 254.5
update:1880/2000, 耗时:0.01分/17.60分 | step: 962560 | performance: 1.0 | accuracy: 0.17 | loss: 0.12
step: 965116 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 254.5
update:1885/2000, 耗时:0.01分/17.65分 | step: 965120 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 966656 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
update:1890/2000, 耗时:0.01分/17.69分 | step: 967680 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
update:1895/2000, 耗时:0.01分/17.74分 | step: 970240 | performance: 1.0 | accuracy: 0.14 | loss: 0.11
step: 971772 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.5 | max total_reward: 254.5
step: 972795 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 254.5
update:1900/2000, 耗时:0.01分/17.79分 | step: 972800 | performance: 0.8 | accuracy: 0.11 | loss: 0.11
step: 974330 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 254.5
update:1905/2000, 耗时:0.01分/17.83分 | step: 975360 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 976381 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 254.5
step: 976890 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 254.5
step: 977918 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
update:1910/2000, 耗时:0.01分/17.88分 | step: 977920 | performance: 1.1 | accuracy: 0.13 | loss: 0.10
step: 979961 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.8 | max total_reward: 254.5
update:1915/2000, 耗时:0.01分/17.93分 | step: 980480 | performance: 1.0 | accuracy: 0.13 | loss: 0.12
update:1920/2000, 耗时:0.01分/17.97分 | step: 983040 | performance: 0.9 | accuracy: 0.12 | loss: 0.12
step: 985595 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.5
update:1925/2000, 耗时:0.01分/18.02分 | step: 985600 | performance: 1.1 | accuracy: 0.16 | loss: 0.12
update:1930/2000, 耗时:0.01分/18.07分 | step: 988160 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
update:1935/2000, 耗时:0.01分/18.11分 | step: 990720 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
update:1940/2000, 耗时:0.01分/18.16分 | step: 993280 | performance: 1.1 | accuracy: 0.19 | loss: 0.15
update:1945/2000, 耗时:0.01分/18.21分 | step: 995840 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 997371 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 254.5
update:1950/2000, 耗时:0.01分/18.25分 | step: 998400 | performance: 1.1 | accuracy: 0.12 | loss: 0.14
update:1955/2000, 耗时:0.01分/18.30分 | step: 1000960 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 1003007 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
update:1960/2000, 耗时:0.01分/18.34分 | step: 1003520 | performance: 1.4 | accuracy: 0.12 | loss: 0.11
step: 1005051 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 254.5
update:1965/2000, 耗时:0.01分/18.39分 | step: 1006080 | performance: 1.3 | accuracy: 0.10 | loss: 0.13
step: 1008635 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.5
update:1970/2000, 耗时:0.01分/18.44分 | step: 1008640 | performance: 1.1 | accuracy: 0.13 | loss: 0.09
step: 1010176 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
update:1975/2000, 耗时:0.01分/18.48分 | step: 1011200 | performance: 1.0 | accuracy: 0.16 | loss: 0.14
step: 1012222 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
step: 1012732 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.5 | max total_reward: 254.5
update:1980/2000, 耗时:0.01分/18.53分 | step: 1013760 | performance: 1.4 | accuracy: 0.13 | loss: 0.14
update:1985/2000, 耗时:0.01分/18.57分 | step: 1016320 | performance: 1.6 | accuracy: 0.10 | loss: 0.11
step: 1017344 | worker_7@n_step_63: average total_reward after train data exhaustion : 2.3 | max total_reward: 254.5
step: 1018876 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 254.5
update:1990/2000, 耗时:0.01分/18.62分 | step: 1018880 | performance: 1.2 | accuracy: 0.12 | loss: 0.11
update:1995/2000, 耗时:0.01分/18.67分 | step: 1021440 | performance: 0.8 | accuracy: 0.10 | loss: 0.11
step: 1021945 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.5
step: 1022464 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 254.5
  0%|          | 0/397 [00:00<?, ?it/s]100%|| 397/397 [00:00<00:00, 132038.59it/s]
update:2000/2000, 耗时:0.01分/18.71分 | step: 1024000 | performance: 1.0 | accuracy: 0.18 | loss: 0.12
----------------------------------------finished----------------------------------------
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 945.14
2023-07-24T12:00:00 | net performance [%] = -5.4864
2023-07-24T12:00:00 | number of trades [#] = 8
==================================================
Trial 11 Complete [00h 19m 09s]
net_wealth: 946.0820251181215

Best net_wealth So Far: 1714.485333603393
Total elapsed time: 01h 37m 01s

Search: Running Trial #12

Value             |Best Value So Far |Hyperparameter
1                 |6                 |horizon
225               |225               |lookback
False             |True              |MarketFactor
14                |14                |lags
0.9               |0.85              |gamma
16                |32                |batch_size
10                |64                |n_step
0.98              |0.8               |gae_lambda
0.1               |2                 |gradient_clip_norm
5                 |3                 |epochs
5e-05             |0.001             |actor_lr
0.0001            |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4314.000000   4315.000000
mean      0.000441    20062.255222  ...   20122.295285  20118.633889
std       0.027818    16039.874230  ...   16077.162832  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7691.585083   7690.540039
50%       0.000642    11554.824463  ...   11724.320312  11715.610352
75%       0.011655    29873.081836  ...   29925.802734  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-27 23:40:24.037986: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAP2023-07-27 23:40:24.2023-07-27 23:400I:24.038069: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow b2 inaDry2 i0023e2ep Neural Net-s0 woptimize3od-70-7r37987: I tensorflow/core/k-27 23:40:242 w7. 203it:3814pl20:247atf:  LibI. t0erarnsoh oneAPI ryfDeep Ne (oneDNN) tolo use trm/cpu_feature_guard.cc:14uow/core/platform/cpu_fe2238045]:0 I2hr e fo3 -2tlelaTahtn0i2ssor3o-0wu0 Tenri7lsor NFnle_egutgw orCoakr wPdUL  i.ncc:142s] T2itbrub0ci2h3is tionTe7-2f7low- 2/nas3r0ry  inissan:-7r-y (2coor74  p0eeron/epD orFl2NfNo2latf7)rmooprma/  ntc3t2o3c:e-4i:0p:u_featu:2w44re_gm iusue a.z b204e3di8ntr5d. arycwri00386.5:2 10cc:24::It  ish  o. iI0 t3ehtica8l5 1n4soornpt2t]i9e oenpemriaze ThteAsiosr ffoldTieonsPo wwitnhs:  A o/lVXIrcFoo rAVXnel eA9P/pflD2Io lloowiwD/a:
tTnce eIe petpe nNowg  bCfeo sNeoruin rePrfUmoraulraal rieo/wp yn a/blc nslatNeltew otr/chepmktuNetworkorforue  rLc Liiitisn  otbirab/mpoolpattfnrs/icapruymhizer_ e o(rm _/cpui_ffdea twofneeuopree_rnegiaaDNNuar tpieo) rynrattutstfurree__guarg,o  u or(sdh.umrebd oouildn.aanreDeNN) decc cTenAct.:oc 1PcI u:n1ce42-:s4esD t21]]c he4e trite h pT Tf2e f]h Thisi NoiorFllcolTenlse Thenow iswaso usToriolFtlwe ooperawnh the r absilFpotpiinlg oCnoorPrU aFiwnn borpyral isliowiw r iasntae nsroy:   ANVeb tiwnXgi pstcitCarro mApi uPcU myo riks  Loipltezeri iVdo filbmXi2zrnapraewd istyrgstt i(ut.h
imoineDNwco oNn)eAittnTs h zP
i ioI  eDneenaton eperfoodAPIo use e rmn Dweitbsl ei ntaenpc et-hc rN he fpiopteuniollow iNngh ceeraeeual rm fClP oin NpUrAaPIotohrer  eopret aitlmwDoe eineaNp etwornaNros: e uAVXrrk Lastructnicte-critical operations:  AVX AVX2
To enable them in other operations, rebuild k Library (oneDNN) to useli AVX2
ToT  Network to enaehns, rebebnsorFlow le them in other operations, rebuild TensorFlow with the appropriate  ocns in peLfuwitih rotiflormdoh lleibT braarmrpeinysonocwe-critical operations:  lringFlowearA VX y(on e(ro DAN nVeX2
To CwfilPDaNatUhNg)sN) to use th p .
thpe  inse tt rforooplrluiacowiteino use thenngst Cae f Pin oaU cble them ipompilpllo nrweopp ioriarn estrtfrlaei cnogufomptsc.t
rihlemangions in perform reCrPce U  in-stcrructfitiiooperncatis in performaalal nnaopongceres, rs-criticc.at
aei-ons: lcritical opera AVX AVX2
t ions:  AVToX pebuild Tenserao enabtorFiAVXolnow2s:
 wi Tt oAVXhl  AVe the appropriate come them in other operations, rebuild TensorFlow with the appropriatnable them in other operations, rebuild TensorFlow with the appropriate compilerpiel X fclags.
e2r
T fo elomnable them apilergsin oth .er 
operations, rebuild TensorFlowf with the appropriate compiler flags.
lags.
2023-07-27 23:40:24.667836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:40:24.673583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:40:24.677254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:40:24.683642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:40:24.690323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:40:24.703389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:40:24.704221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:40:24.724706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 0.7 | accuracy: 0.38 | loss: 2.14
update: 10/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 0.6 | accuracy: 0.31 | loss: 1.04
update: 15/2000, 耗时:0.00分/0.06分 | step:  1200 | performance: 0.6 | accuracy: 0.33 | loss: 1.51
update: 20/2000, 耗时:0.00分/0.08分 | step:  1600 | performance: 0.6 | accuracy: 0.29 | loss: 0.55
update: 25/2000, 耗时:0.00分/0.09分 | step:  2000 | performance: 0.5 | accuracy: 0.27 | loss: 1.11
update: 30/2000, 耗时:0.00分/0.11分 | step:  2400 | performance: 0.4 | accuracy: 0.26 | loss: 0.44
update: 35/2000, 耗时:0.00分/0.12分 | step:  2800 | performance: 0.4 | accuracy: 0.24 | loss: 0.58
update: 40/2000, 耗时:0.00分/0.14分 | step:  3200 | performance: 0.4 | accuracy: 0.23 | loss: 0.90
update: 45/2000, 耗时:0.00分/0.16分 | step:  3600 | performance: 0.3 | accuracy: 0.23 | loss: 0.91
update: 50/2000, 耗时:0.00分/0.17分 | step:  4000 | performance: 0.3 | accuracy: 0.23 | loss: 1.25
update: 55/2000, 耗时:0.00分/0.19分 | step:  4400 | performance: 0.3 | accuracy: 0.22 | loss: 0.79
update: 60/2000, 耗时:0.00分/0.21分 | step:  4800 | performance: 0.3 | accuracy: 0.22 | loss: 1.36
update: 65/2000, 耗时:0.00分/0.23分 | step:  5200 | performance: 0.3 | accuracy: 0.23 | loss: 0.67
update: 70/2000, 耗时:0.00分/0.24分 | step:  5600 | performance: 0.3 | accuracy: 0.21 | loss: 0.70
update: 75/2000, 耗时:0.00分/0.26分 | step:  6000 | performance: 0.3 | accuracy: 0.21 | loss: 0.74
update: 80/2000, 耗时:0.00分/0.28分 | step:  6400 | performance: 0.3 | accuracy: 0.22 | loss: 0.98
update: 85/2000, 耗时:0.00分/0.30分 | step:  6800 | performance: 0.3 | accuracy: 0.22 | loss: 1.01
update: 90/2000, 耗时:0.00分/0.32分 | step:  7200 | performance: 0.4 | accuracy: 0.22 | loss: 0.80
update: 95/2000, 耗时:0.00分/0.34分 | step:  7600 | performance: 0.4 | accuracy: 0.23 | loss: 1.87
update:100/2000, 耗时:0.00分/0.36分 | step:  8000 | performance: 0.4 | accuracy: 0.25 | loss: 0.82
update:105/2000, 耗时:0.00分/0.37分 | step:  8400 | performance: 0.7 | accuracy: 0.26 | loss: 1.26
update:110/2000, 耗时:0.00分/0.39分 | step:  8800 | performance: 0.9 | accuracy: 0.28 | loss: 2.21
update:115/2000, 耗时:0.00分/0.41分 | step:  9200 | performance: 0.9 | accuracy: 0.29 | loss: 0.99
update:120/2000, 耗时:0.00分/0.43分 | step:  9600 | performance: 0.7 | accuracy: 0.29 | loss: 2.48
update:125/2000, 耗时:0.00分/0.44分 | step: 10000 | performance: 0.8 | accuracy: 0.30 | loss: 1.19
update:130/2000, 耗时:0.00分/0.46分 | step: 10400 | performance: 0.8 | accuracy: 0.29 | loss: 1.12
update:135/2000, 耗时:0.00分/0.48分 | step: 10800 | performance: 0.8 | accuracy: 0.29 | loss: 0.81
update:140/2000, 耗时:0.00分/0.50分 | step: 11200 | performance: 0.8 | accuracy: 0.29 | loss: 0.40
update:145/2000, 耗时:0.00分/0.51分 | step: 11600 | performance: 0.9 | accuracy: 0.29 | loss: 0.13
update:150/2000, 耗时:0.00分/0.53分 | step: 12000 | performance: 0.9 | accuracy: 0.28 | loss: 1.32
update:155/2000, 耗时:0.00分/0.55分 | step: 12400 | performance: 0.9 | accuracy: 0.29 | loss: 2.97
update:160/2000, 耗时:0.00分/0.57分 | step: 12800 | performance: 0.9 | accuracy: 0.30 | loss: 1.29
update:165/2000, 耗时:0.00分/0.59分 | step: 13200 | performance: 1.5 | accuracy: 0.30 | loss: 1.26
update:170/2000, 耗时:0.00分/0.60分 | step: 13600 | performance: 1.3 | accuracy: 0.30 | loss: 0.33
update:175/2000, 耗时:0.00分/0.62分 | step: 14000 | performance: 1.5 | accuracy: 0.30 | loss: 1.97
update:180/2000, 耗时:0.00分/0.64分 | step: 14400 | performance: 1.3 | accuracy: 0.30 | loss: 1.52
update:185/2000, 耗时:0.00分/0.66分 | step: 14800 | performance: 1.2 | accuracy: 0.30 | loss: 1.35
update:190/2000, 耗时:0.00分/0.68分 | step: 15200 | performance: 1.3 | accuracy: 0.30 | loss: 0.92
update:195/2000, 耗时:0.00分/0.69分 | step: 15600 | performance: 1.3 | accuracy: 0.30 | loss: 0.61
update:200/2000, 耗时:0.00分/0.71分 | step: 16000 | performance: 1.1 | accuracy: 0.31 | loss: 0.93
update:205/2000, 耗时:0.00分/0.73分 | step: 16400 | performance: 1.3 | accuracy: 0.31 | loss: 1.52
update:210/2000, 耗时:0.00分/0.75分 | step: 16800 | performance: 1.4 | accuracy: 0.31 | loss: 0.91
update:215/2000, 耗时:0.00分/0.77分 | step: 17200 | performance: 1.8 | accuracy: 0.32 | loss: 1.68
update:220/2000, 耗时:0.00分/0.79分 | step: 17600 | performance: 2.3 | accuracy: 0.33 | loss: 2.94
update:225/2000, 耗时:0.00分/0.80分 | step: 18000 | performance: 2.6 | accuracy: 0.33 | loss: 1.69
update:230/2000, 耗时:0.00分/0.82分 | step: 18400 | performance: 3.8 | accuracy: 0.34 | loss: 0.81
update:235/2000, 耗时:0.00分/0.84分 | step: 18800 | performance: 4.7 | accuracy: 0.34 | loss: 1.48
update:240/2000, 耗时:0.00分/0.86分 | step: 19200 | performance: 4.5 | accuracy: 0.34 | loss: 1.28
update:245/2000, 耗时:0.00分/0.88分 | step: 19600 | performance: 5.4 | accuracy: 0.35 | loss: 0.99
update:250/2000, 耗时:0.00分/0.90分 | step: 20000 | performance: 4.4 | accuracy: 0.35 | loss: 0.40
update:255/2000, 耗时:0.00分/0.91分 | step: 20400 | performance: 4.1 | accuracy: 0.34 | loss: 0.29
update:260/2000, 耗时:0.00分/0.93分 | step: 20800 | performance: 4.3 | accuracy: 0.33 | loss: 0.33
update:265/2000, 耗时:0.00分/0.95分 | step: 21200 | performance: 3.7 | accuracy: 0.33 | loss: 1.12
update:270/2000, 耗时:0.00分/0.97分 | step: 21600 | performance: 4.5 | accuracy: 0.33 | loss: 0.90
update:275/2000, 耗时:0.00分/0.99分 | step: 22000 | performance: 3.7 | accuracy: 0.33 | loss: 1.37
update:280/2000, 耗时:0.00分/1.00分 | step: 22400 | performance: 4.9 | accuracy: 0.34 | loss: 2.43
update:285/2000, 耗时:0.00分/1.02分 | step: 22800 | performance: 5.0 | accuracy: 0.34 | loss: 1.19
update:290/2000, 耗时:0.00分/1.04分 | step: 23200 | performance: 3.3 | accuracy: 0.34 | loss: 1.08
update:295/2000, 耗时:0.00分/1.06分 | step: 23600 | performance: 3.3 | accuracy: 0.34 | loss: 0.56
update:300/2000, 耗时:0.00分/1.08分 | step: 24000 | performance: 3.4 | accuracy: 0.34 | loss: 0.39
update:305/2000, 耗时:0.00分/1.09分 | step: 24400 | performance: 3.5 | accuracy: 0.33 | loss: 0.48
update:310/2000, 耗时:0.00分/1.11分 | step: 24800 | performance: 3.2 | accuracy: 0.33 | loss: 0.68
update:315/2000, 耗时:0.00分/1.13分 | step: 25200 | performance: 3.1 | accuracy: 0.33 | loss: 0.97
update:320/2000, 耗时:0.00分/1.15分 | step: 25600 | performance: 3.6 | accuracy: 0.33 | loss: 0.34
update:325/2000, 耗时:0.00分/1.17分 | step: 26000 | performance: 3.3 | accuracy: 0.33 | loss: 0.12
update:330/2000, 耗时:0.00分/1.18分 | step: 26400 | performance: 3.6 | accuracy: 0.32 | loss: 0.28
update:335/2000, 耗时:0.00分/1.20分 | step: 26800 | performance: 3.1 | accuracy: 0.32 | loss: 0.23
update:340/2000, 耗时:0.00分/1.22分 | step: 27200 | performance: 3.3 | accuracy: 0.32 | loss: 0.47
update:345/2000, 耗时:0.00分/1.24分 | step: 27600 | performance: 3.2 | accuracy: 0.31 | loss: 0.37
update:350/2000, 耗时:0.00分/1.25分 | step: 28000 | performance: 2.8 | accuracy: 0.31 | loss: 0.76
update:355/2000, 耗时:0.00分/1.27分 | step: 28400 | performance: 2.9 | accuracy: 0.31 | loss: 0.49
update:360/2000, 耗时:0.00分/1.29分 | step: 28800 | performance: 2.3 | accuracy: 0.31 | loss: 0.16
update:365/2000, 耗时:0.00分/1.31分 | step: 29200 | performance: 2.4 | accuracy: 0.31 | loss: 0.76
Saving PPO weights in both H5 format and checkpoint @ update:367 
update:370/2000, 耗时:0.00分/1.33分 | step: 29600 | performance: 1.1 | accuracy: 0.56 | loss: 2.11
update:375/2000, 耗时:0.00分/1.35分 | step: 30000 | performance: 0.7 | accuracy: 0.44 | loss: 1.23
update:380/2000, 耗时:0.00分/1.36分 | step: 30400 | performance: 0.7 | accuracy: 0.39 | loss: 0.40
update:385/2000, 耗时:0.00分/1.38分 | step: 30800 | performance: 0.9 | accuracy: 0.34 | loss: 0.13
update:390/2000, 耗时:0.00分/1.40分 | step: 31200 | performance: 0.9 | accuracy: 0.28 | loss: 0.19
update:395/2000, 耗时:0.00分/1.41分 | step: 31600 | performance: 1.0 | accuracy: 0.27 | loss: 0.72
update:400/2000, 耗时:0.00分/1.43分 | step: 32000 | performance: 0.9 | accuracy: 0.26 | loss: 0.47
update:405/2000, 耗时:0.00分/1.45分 | step: 32400 | performance: 0.9 | accuracy: 0.24 | loss: 0.30
update:410/2000, 耗时:0.00分/1.47分 | step: 32800 | performance: 0.9 | accuracy: 0.24 | loss: 0.69
update:415/2000, 耗时:0.00分/1.48分 | step: 33200 | performance: 0.8 | accuracy: 0.23 | loss: 0.39
update:420/2000, 耗时:0.00分/1.50分 | step: 33600 | performance: 0.8 | accuracy: 0.23 | loss: 0.48
update:425/2000, 耗时:0.00分/1.52分 | step: 34000 | performance: 0.8 | accuracy: 0.21 | loss: 0.49
update:430/2000, 耗时:0.00分/1.53分 | step: 34400 | performance: 0.8 | accuracy: 0.22 | loss: 0.34
update:435/2000, 耗时:0.00分/1.55分 | step: 34800 | performance: 1.0 | accuracy: 0.21 | loss: 0.01
update:440/2000, 耗时:0.00分/1.57分 | step: 35200 | performance: 1.1 | accuracy: 0.20 | loss: 0.11
update:445/2000, 耗时:0.00分/1.59分 | step: 35600 | performance: 1.1 | accuracy: 0.20 | loss: 0.38
update:450/2000, 耗时:0.00分/1.60分 | step: 36000 | performance: 1.0 | accuracy: 0.19 | loss: 0.46
update:455/2000, 耗时:0.00分/1.62分 | step: 36400 | performance: 1.1 | accuracy: 0.20 | loss: 0.74
update:460/2000, 耗时:0.00分/1.64分 | step: 36800 | performance: 1.4 | accuracy: 0.21 | loss: 4.73
update:465/2000, 耗时:0.00分/1.66分 | step: 37200 | performance: 1.4 | accuracy: 0.23 | loss: 0.80
update:470/2000, 耗时:0.00分/1.67分 | step: 37600 | performance: 1.9 | accuracy: 0.25 | loss: 1.19
update:475/2000, 耗时:0.00分/1.69分 | step: 38000 | performance: 2.3 | accuracy: 0.26 | loss: 1.21
update:480/2000, 耗时:0.00分/1.71分 | step: 38400 | performance: 1.8 | accuracy: 0.27 | loss: 1.22
update:485/2000, 耗时:0.00分/1.73分 | step: 38800 | performance: 1.6 | accuracy: 0.28 | loss: 0.95
update:490/2000, 耗时:0.00分/1.74分 | step: 39200 | performance: 1.6 | accuracy: 0.28 | loss: 0.93
update:495/2000, 耗时:0.00分/1.76分 | step: 39600 | performance: 1.7 | accuracy: 0.28 | loss: 1.08
update:500/2000, 耗时:0.00分/1.78分 | step: 40000 | performance: 1.7 | accuracy: 0.28 | loss: 1.02
update:505/2000, 耗时:0.00分/1.80分 | step: 40400 | performance: 1.7 | accuracy: 0.28 | loss: 0.52
update:510/2000, 耗时:0.00分/1.81分 | step: 40800 | performance: 1.7 | accuracy: 0.27 | loss: 0.29
update:515/2000, 耗时:0.00分/1.83分 | step: 41200 | performance: 1.7 | accuracy: 0.27 | loss: 0.77
update:520/2000, 耗时:0.00分/1.85分 | step: 41600 | performance: 1.7 | accuracy: 0.27 | loss: 1.65
update:525/2000, 耗时:0.00分/1.86分 | step: 42000 | performance: 1.7 | accuracy: 0.28 | loss: 0.90
update:530/2000, 耗时:0.00分/1.88分 | step: 42400 | performance: 0.9 | accuracy: 0.28 | loss: 2.83
update:535/2000, 耗时:0.00分/1.90分 | step: 42800 | performance: 0.9 | accuracy: 0.28 | loss: 0.48
update:540/2000, 耗时:0.00分/1.91分 | step: 43200 | performance: 0.8 | accuracy: 0.27 | loss: 0.69
update:545/2000, 耗时:0.00分/1.93分 | step: 43600 | performance: 0.9 | accuracy: 0.28 | loss: 0.53
update:550/2000, 耗时:0.00分/1.95分 | step: 44000 | performance: 0.9 | accuracy: 0.28 | loss: 0.70
update:555/2000, 耗时:0.00分/1.96分 | step: 44400 | performance: 0.8 | accuracy: 0.27 | loss: 0.45
update:560/2000, 耗时:0.00分/1.98分 | step: 44800 | performance: 0.8 | accuracy: 0.28 | loss: 0.64
update:565/2000, 耗时:0.00分/2.00分 | step: 45200 | performance: 0.9 | accuracy: 0.28 | loss: 1.16
update:570/2000, 耗时:0.00分/2.02分 | step: 45600 | performance: 0.9 | accuracy: 0.28 | loss: 0.56
update:575/2000, 耗时:0.00分/2.03分 | step: 46000 | performance: 0.9 | accuracy: 0.28 | loss: 0.97
update:580/2000, 耗时:0.00分/2.05分 | step: 46400 | performance: 1.3 | accuracy: 0.29 | loss: 0.89
update:585/2000, 耗时:0.00分/2.07分 | step: 46800 | performance: 1.4 | accuracy: 0.30 | loss: 3.74
update:590/2000, 耗时:0.00分/2.08分 | step: 47200 | performance: 1.9 | accuracy: 0.30 | loss: 5.66
update:595/2000, 耗时:0.00分/2.10分 | step: 47600 | performance: 2.1 | accuracy: 0.31 | loss: 1.37
update:600/2000, 耗时:0.00分/2.12分 | step: 48000 | performance: 2.5 | accuracy: 0.31 | loss: 2.19
update:605/2000, 耗时:0.00分/2.14分 | step: 48400 | performance: 2.8 | accuracy: 0.31 | loss: 0.97
update:610/2000, 耗时:0.00分/2.15分 | step: 48800 | performance: 2.2 | accuracy: 0.31 | loss: 0.84
update:615/2000, 耗时:0.00分/2.17分 | step: 49200 | performance: 2.2 | accuracy: 0.31 | loss: 0.87
update:620/2000, 耗时:0.00分/2.19分 | step: 49600 | performance: 1.7 | accuracy: 0.31 | loss: 0.33
update:625/2000, 耗时:0.00分/2.20分 | step: 50000 | performance: 1.6 | accuracy: 0.30 | loss: 0.48
update:630/2000, 耗时:0.00分/2.22分 | step: 50400 | performance: 1.6 | accuracy: 0.30 | loss: 0.46
update:635/2000, 耗时:0.00分/2.24分 | step: 50800 | performance: 1.7 | accuracy: 0.30 | loss: 0.82
update:640/2000, 耗时:0.00分/2.25分 | step: 51200 | performance: 1.7 | accuracy: 0.30 | loss: 2.15
update:645/2000, 耗时:0.00分/2.27分 | step: 51600 | performance: 2.4 | accuracy: 0.30 | loss: 0.71
update:650/2000, 耗时:0.00分/2.29分 | step: 52000 | performance: 2.3 | accuracy: 0.30 | loss: 1.10
update:655/2000, 耗时:0.00分/2.31分 | step: 52400 | performance: 2.3 | accuracy: 0.30 | loss: 1.65
update:660/2000, 耗时:0.00分/2.32分 | step: 52800 | performance: 2.5 | accuracy: 0.30 | loss: 0.24
update:665/2000, 耗时:0.00分/2.34分 | step: 53200 | performance: 2.5 | accuracy: 0.30 | loss: 0.09
update:670/2000, 耗时:0.00分/2.36分 | step: 53600 | performance: 2.8 | accuracy: 0.30 | loss: 0.41
update:675/2000, 耗时:0.00分/2.38分 | step: 54000 | performance: 2.1 | accuracy: 0.29 | loss: 0.46
update:680/2000, 耗时:0.00分/2.39分 | step: 54400 | performance: 2.0 | accuracy: 0.29 | loss: 0.33
update:685/2000, 耗时:0.00分/2.41分 | step: 54800 | performance: 1.7 | accuracy: 0.29 | loss: 0.55
update:690/2000, 耗时:0.00分/2.43分 | step: 55200 | performance: 1.8 | accuracy: 0.29 | loss: 0.35
update:695/2000, 耗时:0.00分/2.45分 | step: 55600 | performance: 1.7 | accuracy: 0.29 | loss: 0.40
update:700/2000, 耗时:0.00分/2.46分 | step: 56000 | performance: 1.7 | accuracy: 0.28 | loss: 0.48
update:705/2000, 耗时:0.00分/2.48分 | step: 56400 | performance: 1.7 | accuracy: 0.28 | loss: 0.26
update:710/2000, 耗时:0.00分/2.50分 | step: 56800 | performance: 1.6 | accuracy: 0.28 | loss: 0.26
update:715/2000, 耗时:0.00分/2.51分 | step: 57200 | performance: 1.6 | accuracy: 0.28 | loss: 0.40
update:720/2000, 耗时:0.00分/2.53分 | step: 57600 | performance: 1.7 | accuracy: 0.28 | loss: 0.30
update:725/2000, 耗时:0.00分/2.55分 | step: 58000 | performance: 1.7 | accuracy: 0.27 | loss: 0.47
update:730/2000, 耗时:0.00分/2.57分 | step: 58400 | performance: 1.7 | accuracy: 0.27 | loss: 0.18
Saving PPO weights in both H5 format and checkpoint @ update:734 
update:735/2000, 耗时:0.00分/2.59分 | step: 58800 | performance: 1.1 | accuracy: 0.50 | loss: 0.95
update:740/2000, 耗时:0.00分/2.61分 | step: 59200 | performance: 0.9 | accuracy: 0.41 | loss: 0.98
update:745/2000, 耗时:0.00分/2.62分 | step: 59600 | performance: 0.9 | accuracy: 0.30 | loss: 0.65
update:750/2000, 耗时:0.00分/2.64分 | step: 60000 | performance: 1.0 | accuracy: 0.26 | loss: 0.21
update:755/2000, 耗时:0.00分/2.66分 | step: 60400 | performance: 1.0 | accuracy: 0.23 | loss: 0.30
update:760/2000, 耗时:0.00分/2.68分 | step: 60800 | performance: 1.0 | accuracy: 0.22 | loss: 0.32
update:765/2000, 耗时:0.00分/2.70分 | step: 61200 | performance: 1.0 | accuracy: 0.20 | loss: 0.45
update:770/2000, 耗时:0.00分/2.71分 | step: 61600 | performance: 1.1 | accuracy: 0.20 | loss: 0.39
update:775/2000, 耗时:0.00分/2.73分 | step: 62000 | performance: 1.1 | accuracy: 0.21 | loss: 0.50
update:780/2000, 耗时:0.00分/2.75分 | step: 62400 | performance: 1.2 | accuracy: 0.21 | loss: 0.53
update:785/2000, 耗时:0.00分/2.77分 | step: 62800 | performance: 1.3 | accuracy: 0.21 | loss: 0.51
update:790/2000, 耗时:0.00分/2.79分 | step: 63200 | performance: 1.4 | accuracy: 0.21 | loss: 0.23
update:795/2000, 耗时:0.00分/2.80分 | step: 63600 | performance: 1.4 | accuracy: 0.19 | loss: 0.86
update:800/2000, 耗时:0.00分/2.82分 | step: 64000 | performance: 1.5 | accuracy: 0.19 | loss: 0.30
update:805/2000, 耗时:0.00分/2.84分 | step: 64400 | performance: 1.7 | accuracy: 0.19 | loss: 0.13
update:810/2000, 耗时:0.00分/2.86分 | step: 64800 | performance: 1.6 | accuracy: 0.18 | loss: 0.42
update:815/2000, 耗时:0.00分/2.88分 | step: 65200 | performance: 1.7 | accuracy: 0.17 | loss: 0.26
update:820/2000, 耗时:0.00分/2.89分 | step: 65600 | performance: 1.5 | accuracy: 0.18 | loss: 0.23
update:825/2000, 耗时:0.00分/2.91分 | step: 66000 | performance: 1.5 | accuracy: 0.18 | loss: 0.53
update:830/2000, 耗时:0.00分/2.93分 | step: 66400 | performance: 1.8 | accuracy: 0.20 | loss: 1.09
update:835/2000, 耗时:0.00分/2.95分 | step: 66800 | performance: 2.6 | accuracy: 0.21 | loss: 0.91
update:840/2000, 耗时:0.00分/2.97分 | step: 67200 | performance: 2.5 | accuracy: 0.23 | loss: 0.51
update:845/2000, 耗时:0.00分/2.98分 | step: 67600 | performance: 3.2 | accuracy: 0.24 | loss: 1.88
update:850/2000, 耗时:0.00分/3.00分 | step: 68000 | performance: 3.0 | accuracy: 0.25 | loss: 0.99
update:855/2000, 耗时:0.00分/3.02分 | step: 68400 | performance: 2.5 | accuracy: 0.25 | loss: 0.65
update:860/2000, 耗时:0.00分/3.04分 | step: 68800 | performance: 3.0 | accuracy: 0.25 | loss: 0.72
update:865/2000, 耗时:0.00分/3.05分 | step: 69200 | performance: 3.0 | accuracy: 0.25 | loss: 0.10
update:870/2000, 耗时:0.00分/3.07分 | step: 69600 | performance: 3.0 | accuracy: 0.24 | loss: 0.39
update:875/2000, 耗时:0.00分/3.09分 | step: 70000 | performance: 3.0 | accuracy: 0.24 | loss: 0.32
update:880/2000, 耗时:0.00分/3.11分 | step: 70400 | performance: 3.2 | accuracy: 0.24 | loss: 0.14
update:885/2000, 耗时:0.00分/3.13分 | step: 70800 | performance: 3.4 | accuracy: 0.24 | loss: 0.30
update:890/2000, 耗时:0.00分/3.14分 | step: 71200 | performance: 3.3 | accuracy: 0.24 | loss: 0.68
update:895/2000, 耗时:0.00分/3.16分 | step: 71600 | performance: 2.7 | accuracy: 0.24 | loss: 0.89
update:900/2000, 耗时:0.00分/3.18分 | step: 72000 | performance: 1.6 | accuracy: 0.24 | loss: 0.15
update:905/2000, 耗时:0.00分/3.20分 | step: 72400 | performance: 1.6 | accuracy: 0.24 | loss: 0.33
update:910/2000, 耗时:0.00分/3.22分 | step: 72800 | performance: 1.7 | accuracy: 0.23 | loss: 0.67
update:915/2000, 耗时:0.00分/3.23分 | step: 73200 | performance: 1.4 | accuracy: 0.23 | loss: 0.79
update:920/2000, 耗时:0.00分/3.25分 | step: 73600 | performance: 1.4 | accuracy: 0.24 | loss: 0.83
update:925/2000, 耗时:0.00分/3.27分 | step: 74000 | performance: 1.5 | accuracy: 0.24 | loss: 0.87
update:930/2000, 耗时:0.00分/3.29分 | step: 74400 | performance: 1.4 | accuracy: 0.24 | loss: 0.83
update:935/2000, 耗时:0.00分/3.31分 | step: 74800 | performance: 1.2 | accuracy: 0.24 | loss: 0.37
update:940/2000, 耗时:0.00分/3.32分 | step: 75200 | performance: 1.4 | accuracy: 0.24 | loss: 0.62
update:945/2000, 耗时:0.00分/3.34分 | step: 75600 | performance: 1.8 | accuracy: 0.25 | loss: 0.98
update:950/2000, 耗时:0.00分/3.36分 | step: 76000 | performance: 1.9 | accuracy: 0.26 | loss: 1.84
update:955/2000, 耗时:0.00分/3.38分 | step: 76400 | performance: 2.5 | accuracy: 0.26 | loss: 0.87
update:960/2000, 耗时:0.00分/3.40分 | step: 76800 | performance: 3.1 | accuracy: 0.27 | loss: 1.54
update:965/2000, 耗时:0.00分/3.41分 | step: 77200 | performance: 3.4 | accuracy: 0.27 | loss: 1.72
update:970/2000, 耗时:0.00分/3.43分 | step: 77600 | performance: 3.4 | accuracy: 0.27 | loss: 0.94
update:975/2000, 耗时:0.00分/3.45分 | step: 78000 | performance: 3.4 | accuracy: 0.28 | loss: 0.48
update:980/2000, 耗时:0.00分/3.47分 | step: 78400 | performance: 2.8 | accuracy: 0.27 | loss: 0.37
update:985/2000, 耗时:0.00分/3.49分 | step: 78800 | performance: 2.4 | accuracy: 0.27 | loss: 0.40
update:990/2000, 耗时:0.00分/3.51分 | step: 79200 | performance: 2.3 | accuracy: 0.27 | loss: 0.34
update:995/2000, 耗时:0.00分/3.52分 | step: 79600 | performance: 2.5 | accuracy: 0.27 | loss: 0.26
update:1000/2000, 耗时:0.00分/3.54分 | step: 80000 | performance: 2.3 | accuracy: 0.26 | loss: 0.55
update:1005/2000, 耗时:0.00分/3.56分 | step: 80400 | performance: 2.1 | accuracy: 0.26 | loss: 0.52
update:1010/2000, 耗时:0.00分/3.58分 | step: 80800 | performance: 2.2 | accuracy: 0.26 | loss: 0.62
update:1015/2000, 耗时:0.00分/3.60分 | step: 81200 | performance: 2.1 | accuracy: 0.26 | loss: 1.08
update:1020/2000, 耗时:0.00分/3.62分 | step: 81600 | performance: 1.9 | accuracy: 0.26 | loss: 0.46
update:1025/2000, 耗时:0.00分/3.64分 | step: 82000 | performance: 1.9 | accuracy: 0.26 | loss: 0.35
update:1030/2000, 耗时:0.00分/3.66分 | step: 82400 | performance: 1.8 | accuracy: 0.26 | loss: 0.36
update:1035/2000, 耗时:0.00分/3.68分 | step: 82800 | performance: 1.7 | accuracy: 0.25 | loss: 0.08
update:1040/2000, 耗时:0.00分/3.70分 | step: 83200 | performance: 2.0 | accuracy: 0.25 | loss: 0.44
update:1045/2000, 耗时:0.00分/3.72分 | step: 83600 | performance: 2.1 | accuracy: 0.25 | loss: 0.41
update:1050/2000, 耗时:0.00分/3.74分 | step: 84000 | performance: 1.9 | accuracy: 0.25 | loss: 0.18
update:1055/2000, 耗时:0.00分/3.76分 | step: 84400 | performance: 2.0 | accuracy: 0.24 | loss: 0.12
update:1060/2000, 耗时:0.00分/3.78分 | step: 84800 | performance: 2.1 | accuracy: 0.24 | loss: 0.18
update:1065/2000, 耗时:0.00分/3.80分 | step: 85200 | performance: 1.9 | accuracy: 0.24 | loss: 0.24
update:1070/2000, 耗时:0.00分/3.82分 | step: 85600 | performance: 1.9 | accuracy: 0.24 | loss: 0.33
update:1075/2000, 耗时:0.00分/3.84分 | step: 86000 | performance: 2.0 | accuracy: 0.24 | loss: 0.24
update:1080/2000, 耗时:0.00分/3.86分 | step: 86400 | performance: 2.1 | accuracy: 0.24 | loss: 0.38
update:1085/2000, 耗时:0.00分/3.88分 | step: 86800 | performance: 2.0 | accuracy: 0.23 | loss: 0.13
update:1090/2000, 耗时:0.00分/3.90分 | step: 87200 | performance: 2.0 | accuracy: 0.23 | loss: 0.13
update:1095/2000, 耗时:0.00分/3.92分 | step: 87600 | performance: 1.9 | accuracy: 0.23 | loss: 0.16
update:1100/2000, 耗时:0.00分/3.94分 | step: 88000 | performance: 1.9 | accuracy: 0.23 | loss: 0.10
Saving PPO weights in both H5 format and checkpoint @ update:1101 
update:1105/2000, 耗时:0.00分/3.96分 | step: 88400 | performance: 1.0 | accuracy: 0.33 | loss: 0.66
update:1110/2000, 耗时:0.00分/3.98分 | step: 88800 | performance: 0.6 | accuracy: 0.21 | loss: 0.44
update:1115/2000, 耗时:0.00分/4.00分 | step: 89200 | performance: 0.6 | accuracy: 0.17 | loss: 0.42
update:1120/2000, 耗时:0.00分/4.02分 | step: 89600 | performance: 0.6 | accuracy: 0.14 | loss: 0.02
update:1125/2000, 耗时:0.00分/4.04分 | step: 90000 | performance: 0.5 | accuracy: 0.12 | loss: 0.15
update:1130/2000, 耗时:0.00分/4.06分 | step: 90400 | performance: 0.6 | accuracy: 0.11 | loss: 0.22
update:1135/2000, 耗时:0.00分/4.08分 | step: 90800 | performance: 0.6 | accuracy: 0.12 | loss: 0.60
update:1140/2000, 耗时:0.00分/4.10分 | step: 91200 | performance: 0.6 | accuracy: 0.12 | loss: 0.46
update:1145/2000, 耗时:0.00分/4.11分 | step: 91600 | performance: 0.6 | accuracy: 0.13 | loss: 0.16
update:1150/2000, 耗时:0.00分/4.13分 | step: 92000 | performance: 0.6 | accuracy: 0.12 | loss: 0.16
update:1155/2000, 耗时:0.00分/4.15分 | step: 92400 | performance: 0.6 | accuracy: 0.12 | loss: 0.06
update:1160/2000, 耗时:0.00分/4.17分 | step: 92800 | performance: 0.6 | accuracy: 0.12 | loss: 0.21
update:1165/2000, 耗时:0.00分/4.19分 | step: 93200 | performance: 0.6 | accuracy: 0.12 | loss: 0.08
update:1170/2000, 耗时:0.00分/4.20分 | step: 93600 | performance: 0.6 | accuracy: 0.11 | loss: 0.00
update:1175/2000, 耗时:0.00分/4.22分 | step: 94000 | performance: 0.6 | accuracy: 0.11 | loss: 0.10
update:1180/2000, 耗时:0.00分/4.24分 | step: 94400 | performance: 0.5 | accuracy: 0.11 | loss: 0.19
update:1185/2000, 耗时:0.00分/4.26分 | step: 94800 | performance: 0.5 | accuracy: 0.11 | loss: 0.12
update:1190/2000, 耗时:0.00分/4.28分 | step: 95200 | performance: 0.5 | accuracy: 0.11 | loss: 0.20
update:1195/2000, 耗时:0.00分/4.29分 | step: 95600 | performance: 0.5 | accuracy: 0.11 | loss: 0.69
update:1200/2000, 耗时:0.00分/4.31分 | step: 96000 | performance: 0.5 | accuracy: 0.13 | loss: 1.14
update:1205/2000, 耗时:0.00分/4.33分 | step: 96400 | performance: 0.8 | accuracy: 0.15 | loss: 0.65
update:1210/2000, 耗时:0.00分/4.35分 | step: 96800 | performance: 0.9 | accuracy: 0.16 | loss: 1.21
update:1215/2000, 耗时:0.00分/4.37分 | step: 97200 | performance: 0.7 | accuracy: 0.17 | loss: 0.77
update:1220/2000, 耗时:0.00分/4.39分 | step: 97600 | performance: 0.7 | accuracy: 0.17 | loss: 0.41
update:1225/2000, 耗时:0.00分/4.40分 | step: 98000 | performance: 0.7 | accuracy: 0.17 | loss: 0.45
update:1230/2000, 耗时:0.00分/4.42分 | step: 98400 | performance: 0.7 | accuracy: 0.17 | loss: 0.22
update:1235/2000, 耗时:0.00分/4.44分 | step: 98800 | performance: 0.7 | accuracy: 0.17 | loss: 0.05
update:1240/2000, 耗时:0.00分/4.46分 | step: 99200 | performance: 0.7 | accuracy: 0.16 | loss: 0.16
update:1245/2000, 耗时:0.00分/4.48分 | step: 99600 | performance: 0.7 | accuracy: 0.16 | loss: 0.11
update:1250/2000, 耗时:0.00分/4.49分 | step: 100000 | performance: 0.7 | accuracy: 0.16 | loss: 0.07
update:1255/2000, 耗时:0.00分/4.51分 | step: 100400 | performance: 0.7 | accuracy: 0.16 | loss: 0.54
update:1260/2000, 耗时:0.00分/4.53分 | step: 100800 | performance: 0.7 | accuracy: 0.17 | loss: 0.76
update:1265/2000, 耗时:0.00分/4.55分 | step: 101200 | performance: 0.7 | accuracy: 0.17 | loss: 0.28
update:1270/2000, 耗时:0.00分/4.57分 | step: 101600 | performance: 0.7 | accuracy: 0.17 | loss: 0.11
update:1275/2000, 耗时:0.00分/4.58分 | step: 102000 | performance: 0.6 | accuracy: 0.16 | loss: 0.51
update:1280/2000, 耗时:0.00分/4.60分 | step: 102400 | performance: 0.5 | accuracy: 0.17 | loss: 0.46
update:1285/2000, 耗时:0.00分/4.62分 | step: 102800 | performance: 0.5 | accuracy: 0.17 | loss: 0.55
update:1290/2000, 耗时:0.00分/4.64分 | step: 103200 | performance: 0.5 | accuracy: 0.17 | loss: 0.31
update:1295/2000, 耗时:0.00分/4.65分 | step: 103600 | performance: 0.5 | accuracy: 0.17 | loss: 1.05
update:1300/2000, 耗时:0.00分/4.67分 | step: 104000 | performance: 0.5 | accuracy: 0.17 | loss: 0.51
update:1305/2000, 耗时:0.00分/4.69分 | step: 104400 | performance: 0.5 | accuracy: 0.17 | loss: 0.30
update:1310/2000, 耗时:0.00分/4.70分 | step: 104800 | performance: 0.5 | accuracy: 0.17 | loss: 0.58
update:1315/2000, 耗时:0.00分/4.72分 | step: 105200 | performance: 0.6 | accuracy: 0.18 | loss: 2.89
update:1320/2000, 耗时:0.00分/4.74分 | step: 105600 | performance: 0.7 | accuracy: 0.19 | loss: 2.65
update:1325/2000, 耗时:0.00分/4.75分 | step: 106000 | performance: 0.8 | accuracy: 0.20 | loss: 1.07
update:1330/2000, 耗时:0.00分/4.77分 | step: 106400 | performance: 1.0 | accuracy: 0.20 | loss: 0.57
update:1335/2000, 耗时:0.00分/4.79分 | step: 106800 | performance: 1.1 | accuracy: 0.21 | loss: 2.79
update:1340/2000, 耗时:0.00分/4.80分 | step: 107200 | performance: 0.9 | accuracy: 0.21 | loss: 0.40
update:1345/2000, 耗时:0.00分/4.82分 | step: 107600 | performance: 0.9 | accuracy: 0.21 | loss: 0.76
update:1350/2000, 耗时:0.00分/4.84分 | step: 108000 | performance: 0.8 | accuracy: 0.21 | loss: 0.29
update:1355/2000, 耗时:0.00分/4.85分 | step: 108400 | performance: 0.8 | accuracy: 0.21 | loss: 0.04
update:1360/2000, 耗时:0.00分/4.87分 | step: 108800 | performance: 0.9 | accuracy: 0.20 | loss: 0.20
update:1365/2000, 耗时:0.00分/4.89分 | step: 109200 | performance: 0.8 | accuracy: 0.20 | loss: 0.09
update:1370/2000, 耗时:0.00分/4.91分 | step: 109600 | performance: 0.8 | accuracy: 0.20 | loss: 0.87
update:1375/2000, 耗时:0.00分/4.93分 | step: 110000 | performance: 0.7 | accuracy: 0.20 | loss: 0.32
update:1380/2000, 耗时:0.00分/4.94分 | step: 110400 | performance: 0.8 | accuracy: 0.21 | loss: 0.54
update:1385/2000, 耗时:0.00分/4.96分 | step: 110800 | performance: 0.8 | accuracy: 0.21 | loss: 0.90
update:1390/2000, 耗时:0.00分/4.98分 | step: 111200 | performance: 0.7 | accuracy: 0.21 | loss: 0.47
update:1395/2000, 耗时:0.00分/5.00分 | step: 111600 | performance: 0.7 | accuracy: 0.21 | loss: 0.06
update:1400/2000, 耗时:0.00分/5.01分 | step: 112000 | performance: 0.7 | accuracy: 0.21 | loss: 0.15
update:1405/2000, 耗时:0.00分/5.03分 | step: 112400 | performance: 0.7 | accuracy: 0.20 | loss: 0.24
update:1410/2000, 耗时:0.00分/5.05分 | step: 112800 | performance: 0.6 | accuracy: 0.20 | loss: 0.36
update:1415/2000, 耗时:0.00分/5.07分 | step: 113200 | performance: 0.6 | accuracy: 0.20 | loss: 0.38
update:1420/2000, 耗时:0.00分/5.08分 | step: 113600 | performance: 0.6 | accuracy: 0.20 | loss: 0.20
update:1425/2000, 耗时:0.00分/5.10分 | step: 114000 | performance: 0.6 | accuracy: 0.20 | loss: 0.09
update:1430/2000, 耗时:0.00分/5.12分 | step: 114400 | performance: 0.6 | accuracy: 0.20 | loss: 0.09
update:1435/2000, 耗时:0.00分/5.13分 | step: 114800 | performance: 0.5 | accuracy: 0.19 | loss: 0.14
update:1440/2000, 耗时:0.00分/5.15分 | step: 115200 | performance: 0.5 | accuracy: 0.19 | loss: 0.26
update:1445/2000, 耗时:0.00分/5.17分 | step: 115600 | performance: 0.5 | accuracy: 0.19 | loss: 0.24
update:1450/2000, 耗时:0.00分/5.19分 | step: 116000 | performance: 0.5 | accuracy: 0.19 | loss: 0.14
update:1455/2000, 耗时:0.00分/5.21分 | step: 116400 | performance: 0.5 | accuracy: 0.19 | loss: 0.08
update:1460/2000, 耗时:0.00分/5.22分 | step: 116800 | performance: 0.5 | accuracy: 0.19 | loss: 0.15
update:1465/2000, 耗时:0.00分/5.24分 | step: 117200 | performance: 0.5 | accuracy: 0.19 | loss: 0.11
Saving PPO weights in both H5 format and checkpoint @ update:1468 
update:1470/2000, 耗时:0.00分/5.26分 | step: 117600 | performance: 1.2 | accuracy: 0.61 | loss: 2.73
update:1475/2000, 耗时:0.00分/5.28分 | step: 118000 | performance: 0.7 | accuracy: 0.37 | loss: 0.62
update:1480/2000, 耗时:0.00分/5.30分 | step: 118400 | performance: 0.6 | accuracy: 0.26 | loss: 0.07
update:1485/2000, 耗时:0.00分/5.32分 | step: 118800 | performance: 0.5 | accuracy: 0.20 | loss: 0.16
update:1490/2000, 耗时:0.00分/5.33分 | step: 119200 | performance: 0.6 | accuracy: 0.18 | loss: 0.19
update:1495/2000, 耗时:0.00分/5.35分 | step: 119600 | performance: 0.6 | accuracy: 0.17 | loss: 0.16
update:1500/2000, 耗时:0.00分/5.37分 | step: 120000 | performance: 0.6 | accuracy: 0.16 | loss: 0.54
update:1505/2000, 耗时:0.00分/5.38分 | step: 120400 | performance: 0.6 | accuracy: 0.15 | loss: 0.16
update:1510/2000, 耗时:0.00分/5.40分 | step: 120800 | performance: 0.6 | accuracy: 0.15 | loss: 0.22
update:1515/2000, 耗时:0.00分/5.42分 | step: 121200 | performance: 0.5 | accuracy: 0.15 | loss: 0.21
update:1520/2000, 耗时:0.00分/5.44分 | step: 121600 | performance: 0.5 | accuracy: 0.14 | loss: 0.34
update:1525/2000, 耗时:0.00分/5.45分 | step: 122000 | performance: 0.5 | accuracy: 0.14 | loss: 0.12
update:1530/2000, 耗时:0.00分/5.47分 | step: 122400 | performance: 0.5 | accuracy: 0.14 | loss: 0.42
update:1535/2000, 耗时:0.00分/5.49分 | step: 122800 | performance: 0.6 | accuracy: 0.14 | loss: 0.24
update:1540/2000, 耗时:0.00分/5.50分 | step: 123200 | performance: 0.6 | accuracy: 0.13 | loss: 0.19
update:1545/2000, 耗时:0.00分/5.52分 | step: 123600 | performance: 0.6 | accuracy: 0.13 | loss: 0.20
update:1550/2000, 耗时:0.00分/5.54分 | step: 124000 | performance: 0.6 | accuracy: 0.12 | loss: 1.13
update:1555/2000, 耗时:0.00分/5.56分 | step: 124400 | performance: 0.6 | accuracy: 0.13 | loss: 0.25
update:1560/2000, 耗时:0.00分/5.57分 | step: 124800 | performance: 0.6 | accuracy: 0.13 | loss: 0.49
update:1565/2000, 耗时:0.00分/5.59分 | step: 125200 | performance: 0.6 | accuracy: 0.15 | loss: 1.34
update:1570/2000, 耗时:0.00分/5.61分 | step: 125600 | performance: 0.8 | accuracy: 0.17 | loss: 0.68
update:1575/2000, 耗时:0.00分/5.63分 | step: 126000 | performance: 0.8 | accuracy: 0.18 | loss: 0.99
update:1580/2000, 耗时:0.00分/5.64分 | step: 126400 | performance: 1.0 | accuracy: 0.20 | loss: 1.83
update:1585/2000, 耗时:0.00分/5.66分 | step: 126800 | performance: 1.2 | accuracy: 0.21 | loss: 0.48
update:1590/2000, 耗时:0.00分/5.68分 | step: 127200 | performance: 1.0 | accuracy: 0.21 | loss: 0.35
update:1595/2000, 耗时:0.00分/5.70分 | step: 127600 | performance: 1.0 | accuracy: 0.21 | loss: 0.32
update:1600/2000, 耗时:0.00分/5.71分 | step: 128000 | performance: 1.1 | accuracy: 0.20 | loss: 0.36
update:1605/2000, 耗时:0.00分/5.73分 | step: 128400 | performance: 1.0 | accuracy: 0.20 | loss: 0.34
update:1610/2000, 耗时:0.00分/5.75分 | step: 128800 | performance: 1.1 | accuracy: 0.20 | loss: 0.33
update:1615/2000, 耗时:0.00分/5.76分 | step: 129200 | performance: 1.0 | accuracy: 0.20 | loss: 0.84
update:1620/2000, 耗时:0.00分/5.78分 | step: 129600 | performance: 1.0 | accuracy: 0.20 | loss: 0.65
update:1625/2000, 耗时:0.00分/5.80分 | step: 130000 | performance: 1.0 | accuracy: 0.20 | loss: 0.60
update:1630/2000, 耗时:0.00分/5.81分 | step: 130400 | performance: 1.0 | accuracy: 0.20 | loss: 0.22
update:1635/2000, 耗时:0.00分/5.83分 | step: 130800 | performance: 1.1 | accuracy: 0.20 | loss: 0.18
update:1640/2000, 耗时:0.00分/5.85分 | step: 131200 | performance: 1.0 | accuracy: 0.20 | loss: 0.33
update:1645/2000, 耗时:0.00分/5.87分 | step: 131600 | performance: 0.9 | accuracy: 0.20 | loss: 0.41
update:1650/2000, 耗时:0.00分/5.88分 | step: 132000 | performance: 0.8 | accuracy: 0.20 | loss: 0.44
update:1655/2000, 耗时:0.00分/5.90分 | step: 132400 | performance: 0.8 | accuracy: 0.20 | loss: 0.72
update:1660/2000, 耗时:0.00分/5.92分 | step: 132800 | performance: 0.9 | accuracy: 0.20 | loss: 0.49
update:1665/2000, 耗时:0.00分/5.94分 | step: 133200 | performance: 0.8 | accuracy: 0.21 | loss: 0.73
update:1670/2000, 耗时:0.00分/5.96分 | step: 133600 | performance: 0.8 | accuracy: 0.20 | loss: 0.53
update:1675/2000, 耗时:0.00分/5.97分 | step: 134000 | performance: 0.9 | accuracy: 0.21 | loss: 0.57
update:1680/2000, 耗时:0.00分/5.99分 | step: 134400 | performance: 1.1 | accuracy: 0.21 | loss: 0.64
update:1685/2000, 耗时:0.00分/6.01分 | step: 134800 | performance: 1.3 | accuracy: 0.22 | loss: 2.44
update:1690/2000, 耗时:0.00分/6.03分 | step: 135200 | performance: 1.9 | accuracy: 0.23 | loss: 4.69
update:1695/2000, 耗时:0.00分/6.04分 | step: 135600 | performance: 2.1 | accuracy: 0.24 | loss: 1.23
update:1700/2000, 耗时:0.00分/6.06分 | step: 136000 | performance: 2.1 | accuracy: 0.24 | loss: 2.11
update:1705/2000, 耗时:0.00分/6.08分 | step: 136400 | performance: 2.4 | accuracy: 0.24 | loss: 0.89
update:1710/2000, 耗时:0.00分/6.10分 | step: 136800 | performance: 2.4 | accuracy: 0.24 | loss: 0.65
update:1715/2000, 耗时:0.00分/6.11分 | step: 137200 | performance: 2.6 | accuracy: 0.24 | loss: 0.38
update:1720/2000, 耗时:0.00分/6.13分 | step: 137600 | performance: 2.8 | accuracy: 0.24 | loss: 0.13
update:1725/2000, 耗时:0.00分/6.15分 | step: 138000 | performance: 2.8 | accuracy: 0.24 | loss: 0.08
update:1730/2000, 耗时:0.00分/6.17分 | step: 138400 | performance: 2.9 | accuracy: 0.23 | loss: 0.18
update:1735/2000, 耗时:0.00分/6.18分 | step: 138800 | performance: 2.9 | accuracy: 0.23 | loss: 0.66
update:1740/2000, 耗时:0.00分/6.20分 | step: 139200 | performance: 3.0 | accuracy: 0.23 | loss: 0.99
update:1745/2000, 耗时:0.00分/6.22分 | step: 139600 | performance: 3.0 | accuracy: 0.23 | loss: 0.82
update:1750/2000, 耗时:0.00分/6.24分 | step: 140000 | performance: 3.0 | accuracy: 0.23 | loss: 1.27
update:1755/2000, 耗时:0.00分/6.25分 | step: 140400 | performance: 2.7 | accuracy: 0.23 | loss: 0.25
update:1760/2000, 耗时:0.00分/6.27分 | step: 140800 | performance: 2.3 | accuracy: 0.23 | loss: 0.29
update:1765/2000, 耗时:0.00分/6.29分 | step: 141200 | performance: 2.3 | accuracy: 0.23 | loss: 0.08
update:1770/2000, 耗时:0.00分/6.31分 | step: 141600 | performance: 2.2 | accuracy: 0.22 | loss: 0.09
update:1775/2000, 耗时:0.00分/6.32分 | step: 142000 | performance: 2.2 | accuracy: 0.22 | loss: 0.07
update:1780/2000, 耗时:0.00分/6.34分 | step: 142400 | performance: 2.2 | accuracy: 0.22 | loss: 0.26
update:1785/2000, 耗时:0.00分/6.36分 | step: 142800 | performance: 2.2 | accuracy: 0.22 | loss: 0.18
update:1790/2000, 耗时:0.00分/6.38分 | step: 143200 | performance: 2.3 | accuracy: 0.21 | loss: 0.13
update:1795/2000, 耗时:0.00分/6.39分 | step: 143600 | performance: 2.3 | accuracy: 0.21 | loss: 0.09
update:1800/2000, 耗时:0.00分/6.41分 | step: 144000 | performance: 2.4 | accuracy: 0.21 | loss: 0.10
update:1805/2000, 耗时:0.00分/6.43分 | step: 144400 | performance: 2.3 | accuracy: 0.21 | loss: 0.19
update:1810/2000, 耗时:0.00分/6.44分 | step: 144800 | performance: 2.4 | accuracy: 0.21 | loss: 0.04
update:1815/2000, 耗时:0.00分/6.46分 | step: 145200 | performance: 2.4 | accuracy: 0.21 | loss: 0.28
update:1820/2000, 耗时:0.00分/6.48分 | step: 145600 | performance: 2.4 | accuracy: 0.20 | loss: 0.09
update:1825/2000, 耗时:0.00分/6.50分 | step: 146000 | performance: 2.4 | accuracy: 0.20 | loss: 0.02
update:1830/2000, 耗时:0.00分/6.51分 | step: 146400 | performance: 2.4 | accuracy: 0.20 | loss: 0.11
step: 146713 | worker_0@n_step_9: average total_reward after train data exhaustion : 218.7 | max total_reward: 291.2
step: 146714 | worker_1@n_step_9: average total_reward after train data exhaustion : 220.5 | max total_reward: 291.2
step: 146715 | worker_2@n_step_9: average total_reward after train data exhaustion : 220.0 | max total_reward: 291.2
step: 146716 | worker_3@n_step_9: average total_reward after train data exhaustion : 221.2 | max total_reward: 291.2
step: 146717 | worker_4@n_step_9: average total_reward after train data exhaustion : 221.8 | max total_reward: 291.2
step: 146718 | worker_5@n_step_9: average total_reward after train data exhaustion : 222.6 | max total_reward: 291.2
step: 146719 | worker_6@n_step_9: average total_reward after train data exhaustion : 222.9 | max total_reward: 291.2
step: 146720 | worker_7@n_step_9: average total_reward after train data exhaustion : 223.4 | max total_reward: 291.2
Saving PPO weights in both H5 format and checkpoint @ update:1834 
update:1835/2000, 耗时:0.00分/6.54分 | step: 146800 | performance: 1.1 | accuracy: 0.20 | loss: 0.93
update:1840/2000, 耗时:0.00分/6.55分 | step: 147200 | performance: 1.1 | accuracy: 0.27 | loss: 1.16
update:1845/2000, 耗时:0.00分/6.57分 | step: 147600 | performance: 1.1 | accuracy: 0.20 | loss: 0.29
update:1850/2000, 耗时:0.00分/6.59分 | step: 148000 | performance: 1.1 | accuracy: 0.19 | loss: 0.11
update:1855/2000, 耗时:0.00分/6.61分 | step: 148400 | performance: 1.1 | accuracy: 0.15 | loss: 0.18
update:1860/2000, 耗时:0.00分/6.63分 | step: 148800 | performance: 1.2 | accuracy: 0.13 | loss: 0.14
update:1865/2000, 耗时:0.00分/6.64分 | step: 149200 | performance: 1.1 | accuracy: 0.13 | loss: 1.11
update:1870/2000, 耗时:0.00分/6.66分 | step: 149600 | performance: 1.2 | accuracy: 0.14 | loss: 0.20
update:1875/2000, 耗时:0.00分/6.68分 | step: 150000 | performance: 1.4 | accuracy: 0.15 | loss: 0.24
update:1880/2000, 耗时:0.00分/6.70分 | step: 150400 | performance: 1.4 | accuracy: 0.15 | loss: 0.17
update:1885/2000, 耗时:0.00分/6.72分 | step: 150800 | performance: 1.5 | accuracy: 0.15 | loss: 0.10
update:1890/2000, 耗时:0.00分/6.73分 | step: 151200 | performance: 1.4 | accuracy: 0.15 | loss: 0.07
update:1895/2000, 耗时:0.00分/6.75分 | step: 151600 | performance: 1.4 | accuracy: 0.15 | loss: 0.56
update:1900/2000, 耗时:0.00分/6.77分 | step: 152000 | performance: 1.3 | accuracy: 0.15 | loss: 0.12
update:1905/2000, 耗时:0.00分/6.78分 | step: 152400 | performance: 1.5 | accuracy: 0.15 | loss: 0.53
update:1910/2000, 耗时:0.00分/6.80分 | step: 152800 | performance: 1.5 | accuracy: 0.14 | loss: 0.10
update:1915/2000, 耗时:0.00分/6.82分 | step: 153200 | performance: 1.6 | accuracy: 0.14 | loss: 0.13
update:1920/2000, 耗时:0.00分/6.83分 | step: 153600 | performance: 1.5 | accuracy: 0.14 | loss: 0.13
update:1925/2000, 耗时:0.00分/6.85分 | step: 154000 | performance: 1.6 | accuracy: 0.15 | loss: 0.21
update:1930/2000, 耗时:0.00分/6.87分 | step: 154400 | performance: 1.7 | accuracy: 0.15 | loss: 0.86
update:1935/2000, 耗时:0.00分/6.89分 | step: 154800 | performance: 2.0 | accuracy: 0.17 | loss: 1.84
update:1940/2000, 耗时:0.00分/6.90分 | step: 155200 | performance: 2.4 | accuracy: 0.18 | loss: 1.43
update:1945/2000, 耗时:0.00分/6.92分 | step: 155600 | performance: 2.6 | accuracy: 0.18 | loss: 2.15
update:1950/2000, 耗时:0.00分/6.94分 | step: 156000 | performance: 2.2 | accuracy: 0.19 | loss: 1.45
update:1955/2000, 耗时:0.00分/6.96分 | step: 156400 | performance: 2.2 | accuracy: 0.19 | loss: 0.92
update:1960/2000, 耗时:0.00分/6.97分 | step: 156800 | performance: 2.2 | accuracy: 0.19 | loss: 0.42
update:1965/2000, 耗时:0.00分/6.99分 | step: 157200 | performance: 2.2 | accuracy: 0.18 | loss: 0.86
update:1970/2000, 耗时:0.00分/7.01分 | step: 157600 | performance: 2.3 | accuracy: 0.18 | loss: 0.21
update:1975/2000, 耗时:0.00分/7.03分 | step: 158000 | performance: 2.3 | accuracy: 0.18 | loss: 0.35
update:1980/2000, 耗时:0.00分/7.04分 | step: 158400 | performance: 2.5 | accuracy: 0.18 | loss: 0.19
update:1985/2000, 耗时:0.00分/7.06分 | step: 158800 | performance: 2.4 | accuracy: 0.18 | loss: 0.17
update:1990/2000, 耗时:0.00分/7.08分 | step: 159200 | performance: 2.4 | accuracy: 0.18 | loss: 0.30
update:1995/2000, 耗时:0.00分/7.09分 | step: 159600 | performance: 2.5 | accuracy: 0.18 | loss: 0.50
  0%|          | 0/397 [00:00<?, ?it/s]100%|| 397/397 [00:00<00:00, 99417.20it/s]
update:2000/2000, 耗时:0.00分/7.11分 | step: 160000 | performance: 2.8 | accuracy: 0.18 | loss: 0.13
----------------------------------------finished----------------------------------------
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1654.62
2023-07-24T12:00:00 | net performance [%] = 65.4624
2023-07-24T12:00:00 | number of trades [#] = 16
==================================================
Trial 12 Complete [00h 07m 32s]
net_wealth: 1656.2804682287

Best net_wealth So Far: 1714.485333603393
Total elapsed time: 01h 44m 34s

Search: Running Trial #13

Value             |Best Value So Far |Hyperparameter
6                 |6                 |horizon
730               |225               |lookback
False             |True              |MarketFactor
10                |14                |lags
0.7               |0.85              |gamma
16                |32                |batch_size
10                |64                |n_step
0.85              |0.8               |gae_lambda
1                 |2                 |gradient_clip_norm
5                 |3                 |epochs
5e-05             |0.001             |actor_lr
0.0005            |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4309.000000   4315.000000
mean      0.000441    20062.255222  ...   20140.547965  20118.633889
std       0.027818    16039.874230  ...   16077.550480  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7699.189941   7690.540039
50%       0.000642    11554.824463  ...   11743.940430  11715.610352
75%       0.011655    29873.081836  ...   29950.949219  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-27 23:47:56.691131: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable2023-07-27 23:47:56.691247: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, 220 2the30m2 in o-3ther07-2023-0727 2--0273-7 27:  2323:47:56.op:4691747:e415: I: t5r6ensorflorati.w691383: I tenso/onsrcorf, elo/rebuwp/ild claoTe56t.nsorFlow with6ref/o91p2lratfo2e4:mrm/cp/buu_fcieaturel pud I_fe Tta_egutun2sorFe0nrale_gu2a3ro-sorwd.cd.c  rc:107-27 23:47:56.691653: I4c2 te] nsoThirf:1fl42]lo ow/core/Tw/core/phip2thel0ala2stformtf 3appro-o0rm//prcs7cpu_w-it27piah t2u_ efeathtfue0e appr2a3o-p0 rtrTur7ee-i2_ng7e 23 _s:4o2u7aa3r:56.:476gt9:1uar5r8 dd.4T6eF.l.com co9c:m c:1poil4p2e691785: I tewr]  fnslaiorflol binary igesr .fl
ccsa :owp/tgi1m42] Thisi TenzcI eodt wsenso.rTitrh oneAPIhe Deepflow/c oNr
issore eTnFulenr/osopwlatforaml N/ cbeitpnuw_rary isseor/pl FlaoFpltoiotmw wfiobrmi /fnzed witceature_ghp uary uard.cc_ofineAPI s: e142]aDoorpkett Liieup Neural Network mrbraryiz (Lede _iownebDNguN) to usararrebyd ithe  .nf(oneo DNN) tTllowicohnis g C Tc:ensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critiPU inaith oneAPI Destrucurty sicoanep Neure14 2thsa l]ies i nT f  opNepler tohlltowpeioirmrsationsk T formance-criLoiietw:inzns ic g CPoeAU d Vwith oiX AVX2
To enanstructions in performlnaeb APoperationslIraFnl:e  AV  Deep Neutralc eNXb rary (oneDNAVN) to use the followinXgow binh-em in other opacritr2 erations, rebuild Tensical operations:  AVCXo eyPrAFtwork 
To ena is lbolLeUV Xi2nws with the a them in othit
rTbraoepr op uctirty (oneoipmeDNN)inabzed with oneAPI Deep Neural Network Library (oneDNN)roprins in po perations, rebuild TensorFlo taltteo cw  wiueotehrforo  mse th matpitnhe appropriatece-criticae lf operatiuonsehems:  AVX  ic lom AVX2nepilerr 
To e naftohbte lhafollee fgrs .o
 llagsotwphem .olloi
in other operatioeratnisn,ons reg CPU insbui, rld TetnsorFlow with tebuilrwd iuTenchtsoreions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the approprFlow with the appropriate compiler flangs.
 apprg CPU instructions in performance-critical operations:  AVX AVX2
To enable them in opriate compiler ioftlags.
ate compiler flags.
her operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-27 23:47:57.279074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:47:57.288046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:47:57.294593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:47:57.305198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:47:57.316880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:47:57.322435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:47:57.325455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:47:57.347747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 1.7 | accuracy: 0.42 | loss: 1.02
update: 10/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 2.0 | accuracy: 0.40 | loss: 0.84
update: 15/2000, 耗时:0.00分/0.06分 | step:  1200 | performance: 2.2 | accuracy: 0.39 | loss: 1.22
update: 20/2000, 耗时:0.00分/0.08分 | step:  1600 | performance: 0.9 | accuracy: 0.36 | loss: 0.69
update: 25/2000, 耗时:0.00分/0.09分 | step:  2000 | performance: 0.7 | accuracy: 0.34 | loss: 0.58
update: 30/2000, 耗时:0.00分/0.11分 | step:  2400 | performance: 0.9 | accuracy: 0.34 | loss: 0.69
update: 35/2000, 耗时:0.00分/0.13分 | step:  2800 | performance: 0.5 | accuracy: 0.32 | loss: 1.05
update: 40/2000, 耗时:0.00分/0.14分 | step:  3200 | performance: 0.5 | accuracy: 0.33 | loss: 0.54
update: 45/2000, 耗时:0.00分/0.16分 | step:  3600 | performance: 0.6 | accuracy: 0.34 | loss: 1.25
update: 50/2000, 耗时:0.00分/0.18分 | step:  4000 | performance: 0.4 | accuracy: 0.33 | loss: 0.79
update: 55/2000, 耗时:0.00分/0.19分 | step:  4400 | performance: 0.6 | accuracy: 0.33 | loss: 1.17
update: 60/2000, 耗时:0.00分/0.21分 | step:  4800 | performance: 0.3 | accuracy: 0.33 | loss: 2.05
update: 65/2000, 耗时:0.00分/0.23分 | step:  5200 | performance: 0.4 | accuracy: 0.34 | loss: 0.92
update: 70/2000, 耗时:0.00分/0.25分 | step:  5600 | performance: 0.5 | accuracy: 0.33 | loss: 1.13
update: 75/2000, 耗时:0.00分/0.27分 | step:  6000 | performance: 0.8 | accuracy: 0.34 | loss: 0.44
update: 80/2000, 耗时:0.00分/0.28分 | step:  6400 | performance: 0.3 | accuracy: 0.34 | loss: 0.76
update: 85/2000, 耗时:0.00分/0.30分 | step:  6800 | performance: 0.7 | accuracy: 0.34 | loss: 0.94
update: 90/2000, 耗时:0.00分/0.32分 | step:  7200 | performance: 0.5 | accuracy: 0.34 | loss: 1.11
update: 95/2000, 耗时:0.00分/0.34分 | step:  7600 | performance: 0.6 | accuracy: 0.35 | loss: 0.94
update:100/2000, 耗时:0.00分/0.35分 | step:  8000 | performance: 0.5 | accuracy: 0.34 | loss: 0.64
update:105/2000, 耗时:0.00分/0.37分 | step:  8400 | performance: 0.5 | accuracy: 0.34 | loss: 1.03
update:110/2000, 耗时:0.00分/0.39分 | step:  8800 | performance: 0.4 | accuracy: 0.34 | loss: 0.76
update:115/2000, 耗时:0.00分/0.41分 | step:  9200 | performance: 0.2 | accuracy: 0.34 | loss: 1.35
update:120/2000, 耗时:0.00分/0.42分 | step:  9600 | performance: 0.2 | accuracy: 0.34 | loss: 1.07
update:125/2000, 耗时:0.00分/0.44分 | step: 10000 | performance: 0.2 | accuracy: 0.34 | loss: 0.60
update:130/2000, 耗时:0.00分/0.46分 | step: 10400 | performance: 0.1 | accuracy: 0.34 | loss: 0.70
update:135/2000, 耗时:0.00分/0.48分 | step: 10800 | performance: 0.1 | accuracy: 0.33 | loss: 0.69
update:140/2000, 耗时:0.00分/0.50分 | step: 11200 | performance: 0.1 | accuracy: 0.33 | loss: 0.54
update:145/2000, 耗时:0.00分/0.51分 | step: 11600 | performance: 0.1 | accuracy: 0.33 | loss: 0.20
update:150/2000, 耗时:0.00分/0.53分 | step: 12000 | performance: 0.1 | accuracy: 0.32 | loss: 0.55
update:155/2000, 耗时:0.00分/0.55分 | step: 12400 | performance: 0.1 | accuracy: 0.32 | loss: 0.38
update:160/2000, 耗时:0.00分/0.57分 | step: 12800 | performance: 0.1 | accuracy: 0.31 | loss: 0.23
update:165/2000, 耗时:0.00分/0.59分 | step: 13200 | performance: 0.0 | accuracy: 0.30 | loss: 0.07
update:170/2000, 耗时:0.00分/0.60分 | step: 13600 | performance: 0.0 | accuracy: 0.30 | loss: 0.17
update:175/2000, 耗时:0.00分/0.62分 | step: 14000 | performance: 0.0 | accuracy: 0.29 | loss: 0.02
update:180/2000, 耗时:0.00分/0.64分 | step: 14400 | performance: 0.0 | accuracy: 0.28 | loss: 0.03
update:185/2000, 耗时:0.00分/0.65分 | step: 14800 | performance: 0.0 | accuracy: 0.27 | loss: 0.06
update:190/2000, 耗时:0.00分/0.67分 | step: 15200 | performance: 0.0 | accuracy: 0.27 | loss: 0.11
update:195/2000, 耗时:0.00分/0.69分 | step: 15600 | performance: 0.0 | accuracy: 0.26 | loss: 0.13
update:200/2000, 耗时:0.00分/0.70分 | step: 16000 | performance: 0.0 | accuracy: 0.26 | loss: 0.94
update:205/2000, 耗时:0.00分/0.72分 | step: 16400 | performance: 0.0 | accuracy: 0.26 | loss: 0.75
update:210/2000, 耗时:0.00分/0.74分 | step: 16800 | performance: 0.0 | accuracy: 0.26 | loss: 0.57
update:215/2000, 耗时:0.00分/0.76分 | step: 17200 | performance: 0.0 | accuracy: 0.26 | loss: 0.46
update:220/2000, 耗时:0.00分/0.77分 | step: 17600 | performance: 0.0 | accuracy: 0.26 | loss: 0.36
update:225/2000, 耗时:0.00分/0.79分 | step: 18000 | performance: 0.0 | accuracy: 0.26 | loss: 0.49
update:230/2000, 耗时:0.00分/0.81分 | step: 18400 | performance: 0.0 | accuracy: 0.25 | loss: 0.13
update:235/2000, 耗时:0.00分/0.82分 | step: 18800 | performance: 0.0 | accuracy: 0.25 | loss: 0.14
update:240/2000, 耗时:0.00分/0.84分 | step: 19200 | performance: 0.0 | accuracy: 0.25 | loss: 0.46
update:245/2000, 耗时:0.00分/0.86分 | step: 19600 | performance: 0.0 | accuracy: 0.25 | loss: 0.76
update:250/2000, 耗时:0.00分/0.88分 | step: 20000 | performance: 0.0 | accuracy: 0.25 | loss: 0.89
update:255/2000, 耗时:0.00分/0.89分 | step: 20400 | performance: 0.0 | accuracy: 0.25 | loss: 1.14
update:260/2000, 耗时:0.00分/0.91分 | step: 20800 | performance: 0.0 | accuracy: 0.26 | loss: 0.87
update:265/2000, 耗时:0.00分/0.93分 | step: 21200 | performance: 0.0 | accuracy: 0.26 | loss: 0.83
update:270/2000, 耗时:0.00分/0.95分 | step: 21600 | performance: 0.0 | accuracy: 0.26 | loss: 1.47
update:275/2000, 耗时:0.00分/0.97分 | step: 22000 | performance: 0.0 | accuracy: 0.26 | loss: 0.65
update:280/2000, 耗时:0.00分/0.98分 | step: 22400 | performance: 0.0 | accuracy: 0.27 | loss: 0.86
update:285/2000, 耗时:0.00分/1.00分 | step: 22800 | performance: 0.0 | accuracy: 0.27 | loss: 1.02
update:290/2000, 耗时:0.00分/1.02分 | step: 23200 | performance: 0.0 | accuracy: 0.28 | loss: 0.97
update:295/2000, 耗时:0.00分/1.03分 | step: 23600 | performance: 0.0 | accuracy: 0.28 | loss: 1.35
update:300/2000, 耗时:0.00分/1.05分 | step: 24000 | performance: 0.0 | accuracy: 0.28 | loss: 0.85
update:305/2000, 耗时:0.00分/1.07分 | step: 24400 | performance: 0.0 | accuracy: 0.28 | loss: 0.66
update:310/2000, 耗时:0.00分/1.09分 | step: 24800 | performance: 0.0 | accuracy: 0.28 | loss: 0.73
update:315/2000, 耗时:0.00分/1.11分 | step: 25200 | performance: 0.0 | accuracy: 0.29 | loss: 0.40
Saving PPO weights in both H5 format and checkpoint @ update:317 
update:320/2000, 耗时:0.00分/1.13分 | step: 25600 | performance: 1.0 | accuracy: 0.30 | loss: 0.59
update:325/2000, 耗时:0.00分/1.15分 | step: 26000 | performance: 1.2 | accuracy: 0.37 | loss: 0.85
update:330/2000, 耗时:0.00分/1.17分 | step: 26400 | performance: 1.2 | accuracy: 0.38 | loss: 0.44
update:335/2000, 耗时:0.00分/1.18分 | step: 26800 | performance: 0.5 | accuracy: 0.39 | loss: 0.71
update:340/2000, 耗时:0.00分/1.20分 | step: 27200 | performance: 0.9 | accuracy: 0.42 | loss: 1.32
update:345/2000, 耗时:0.00分/1.22分 | step: 27600 | performance: 0.6 | accuracy: 0.41 | loss: 0.88
update:350/2000, 耗时:0.00分/1.24分 | step: 28000 | performance: 0.5 | accuracy: 0.41 | loss: 0.46
update:355/2000, 耗时:0.00分/1.26分 | step: 28400 | performance: 0.3 | accuracy: 0.40 | loss: 0.79
update:360/2000, 耗时:0.00分/1.27分 | step: 28800 | performance: 0.2 | accuracy: 0.40 | loss: 1.15
update:365/2000, 耗时:0.00分/1.29分 | step: 29200 | performance: 0.2 | accuracy: 0.40 | loss: 0.46
update:370/2000, 耗时:0.00分/1.31分 | step: 29600 | performance: 0.2 | accuracy: 0.37 | loss: 0.28
update:375/2000, 耗时:0.00分/1.33分 | step: 30000 | performance: 0.2 | accuracy: 0.35 | loss: 0.17
update:380/2000, 耗时:0.00分/1.35分 | step: 30400 | performance: 0.2 | accuracy: 0.32 | loss: 0.09
update:385/2000, 耗时:0.00分/1.37分 | step: 30800 | performance: 0.2 | accuracy: 0.30 | loss: 0.11
update:390/2000, 耗时:0.00分/1.38分 | step: 31200 | performance: 0.2 | accuracy: 0.29 | loss: 0.12
update:395/2000, 耗时:0.00分/1.40分 | step: 31600 | performance: 0.1 | accuracy: 0.27 | loss: 0.16
update:400/2000, 耗时:0.00分/1.42分 | step: 32000 | performance: 0.1 | accuracy: 0.27 | loss: 0.32
update:405/2000, 耗时:0.00分/1.44分 | step: 32400 | performance: 0.1 | accuracy: 0.26 | loss: 0.24
update:410/2000, 耗时:0.00分/1.46分 | step: 32800 | performance: 0.1 | accuracy: 0.26 | loss: 0.40
update:415/2000, 耗时:0.00分/1.48分 | step: 33200 | performance: 0.1 | accuracy: 0.26 | loss: 0.62
update:420/2000, 耗时:0.00分/1.50分 | step: 33600 | performance: 0.1 | accuracy: 0.25 | loss: 0.41
update:425/2000, 耗时:0.00分/1.52分 | step: 34000 | performance: 0.1 | accuracy: 0.25 | loss: 0.21
update:430/2000, 耗时:0.00分/1.53分 | step: 34400 | performance: 0.0 | accuracy: 0.24 | loss: 2.94
update:435/2000, 耗时:0.00分/1.55分 | step: 34800 | performance: 0.0 | accuracy: 0.25 | loss: 0.83
update:440/2000, 耗时:0.00分/1.57分 | step: 35200 | performance: 0.1 | accuracy: 0.25 | loss: 0.61
update:445/2000, 耗时:0.00分/1.59分 | step: 35600 | performance: 0.1 | accuracy: 0.25 | loss: 0.28
update:450/2000, 耗时:0.00分/1.61分 | step: 36000 | performance: 0.0 | accuracy: 0.24 | loss: 0.32
update:455/2000, 耗时:0.00分/1.63分 | step: 36400 | performance: 0.0 | accuracy: 0.24 | loss: 0.33
update:460/2000, 耗时:0.00分/1.64分 | step: 36800 | performance: 0.1 | accuracy: 0.24 | loss: 0.04
update:465/2000, 耗时:0.00分/1.66分 | step: 37200 | performance: 0.1 | accuracy: 0.23 | loss: 0.12
update:470/2000, 耗时:0.00分/1.68分 | step: 37600 | performance: 0.1 | accuracy: 0.23 | loss: 0.15
update:475/2000, 耗时:0.00分/1.70分 | step: 38000 | performance: 0.1 | accuracy: 0.22 | loss: 0.07
update:480/2000, 耗时:0.00分/1.72分 | step: 38400 | performance: 0.1 | accuracy: 0.21 | loss: 0.00
update:485/2000, 耗时:0.00分/1.73分 | step: 38800 | performance: 0.1 | accuracy: 0.21 | loss: 0.05
update:490/2000, 耗时:0.00分/1.75分 | step: 39200 | performance: 0.1 | accuracy: 0.20 | loss: 0.00
update:495/2000, 耗时:0.00分/1.77分 | step: 39600 | performance: 0.1 | accuracy: 0.20 | loss: 0.05
update:500/2000, 耗时:0.00分/1.79分 | step: 40000 | performance: 0.1 | accuracy: 0.19 | loss: 0.01
update:505/2000, 耗时:0.00分/1.81分 | step: 40400 | performance: 0.1 | accuracy: 0.19 | loss: 0.02
update:510/2000, 耗时:0.00分/1.82分 | step: 40800 | performance: 0.1 | accuracy: 0.18 | loss: 0.12
update:515/2000, 耗时:0.00分/1.84分 | step: 41200 | performance: 0.1 | accuracy: 0.18 | loss: 0.16
update:520/2000, 耗时:0.00分/1.86分 | step: 41600 | performance: 0.1 | accuracy: 0.18 | loss: 0.50
update:525/2000, 耗时:0.00分/1.88分 | step: 42000 | performance: 0.1 | accuracy: 0.18 | loss: 0.28
update:530/2000, 耗时:0.00分/1.90分 | step: 42400 | performance: 0.1 | accuracy: 0.18 | loss: 0.45
update:535/2000, 耗时:0.00分/1.92分 | step: 42800 | performance: 0.1 | accuracy: 0.18 | loss: 0.15
update:540/2000, 耗时:0.00分/1.93分 | step: 43200 | performance: 0.2 | accuracy: 0.18 | loss: 0.21
update:545/2000, 耗时:0.00分/1.95分 | step: 43600 | performance: 0.2 | accuracy: 0.18 | loss: 0.24
update:550/2000, 耗时:0.00分/1.97分 | step: 44000 | performance: 0.2 | accuracy: 0.17 | loss: 0.05
update:555/2000, 耗时:0.00分/1.99分 | step: 44400 | performance: 0.1 | accuracy: 0.17 | loss: 0.36
update:560/2000, 耗时:0.00分/2.01分 | step: 44800 | performance: 0.1 | accuracy: 0.17 | loss: 0.58
update:565/2000, 耗时:0.00分/2.03分 | step: 45200 | performance: 0.1 | accuracy: 0.17 | loss: 0.96
update:570/2000, 耗时:0.00分/2.04分 | step: 45600 | performance: 0.1 | accuracy: 0.17 | loss: 0.96
update:575/2000, 耗时:0.00分/2.06分 | step: 46000 | performance: 0.1 | accuracy: 0.18 | loss: 0.54
update:580/2000, 耗时:0.00分/2.08分 | step: 46400 | performance: 0.1 | accuracy: 0.18 | loss: 0.36
update:585/2000, 耗时:0.00分/2.10分 | step: 46800 | performance: 0.1 | accuracy: 0.18 | loss: 0.44
update:590/2000, 耗时:0.00分/2.12分 | step: 47200 | performance: 0.0 | accuracy: 0.18 | loss: 1.33
update:595/2000, 耗时:0.00分/2.14分 | step: 47600 | performance: 0.0 | accuracy: 0.18 | loss: 0.94
update:600/2000, 耗时:0.00分/2.16分 | step: 48000 | performance: 0.0 | accuracy: 0.19 | loss: 1.71
update:605/2000, 耗时:0.00分/2.18分 | step: 48400 | performance: 0.0 | accuracy: 0.19 | loss: 1.16
update:610/2000, 耗时:0.00分/2.20分 | step: 48800 | performance: 0.0 | accuracy: 0.19 | loss: 0.51
update:615/2000, 耗时:0.00分/2.22分 | step: 49200 | performance: 0.0 | accuracy: 0.20 | loss: 0.68
update:620/2000, 耗时:0.00分/2.24分 | step: 49600 | performance: 0.0 | accuracy: 0.20 | loss: 0.64
update:625/2000, 耗时:0.00分/2.26分 | step: 50000 | performance: 0.0 | accuracy: 0.20 | loss: 0.57
update:630/2000, 耗时:0.00分/2.28分 | step: 50400 | performance: 0.0 | accuracy: 0.20 | loss: 0.53
Saving PPO weights in both H5 format and checkpoint @ update:634 
update:635/2000, 耗时:0.00分/2.30分 | step: 50800 | performance: 0.7 | accuracy: 0.19 | loss: 0.32
Saving PPO weights in both H5 format and checkpoint @ update:636 
Saving PPO weights in both H5 format and checkpoint @ update:637 
Saving PPO weights in both H5 format and checkpoint @ update:638 
Saving PPO weights in both H5 format and checkpoint @ update:639 
update:640/2000, 耗时:0.00分/2.34分 | step: 51200 | performance: 0.7 | accuracy: 0.14 | loss: 0.14
Saving PPO weights in both H5 format and checkpoint @ update:641 
Saving PPO weights in both H5 format and checkpoint @ update:642 
Saving PPO weights in both H5 format and checkpoint @ update:643 
step: 51515 | worker_2@n_step_9: average total_reward after train data exhaustion : -18.5 | max total_reward: 63.5
Saving PPO weights in both H5 format and checkpoint @ update:644 
update:645/2000, 耗时:0.00分/2.38分 | step: 51600 | performance: 0.7 | accuracy: 0.12 | loss: 0.20
Saving PPO weights in both H5 format and checkpoint @ update:645 
Saving PPO weights in both H5 format and checkpoint @ update:646 
Saving PPO weights in both H5 format and checkpoint @ update:647 
Saving PPO weights in both H5 format and checkpoint @ update:648 
Saving PPO weights in both H5 format and checkpoint @ update:649 
update:650/2000, 耗时:0.00分/2.42分 | step: 52000 | performance: 1.1 | accuracy: 0.07 | loss: 0.77
Saving PPO weights in both H5 format and checkpoint @ update:650 
Saving PPO weights in both H5 format and checkpoint @ update:651 
Saving PPO weights in both H5 format and checkpoint @ update:652 
Saving PPO weights in both H5 format and checkpoint @ update:653 
Saving PPO weights in both H5 format and checkpoint @ update:654 
update:655/2000, 耗时:0.00分/2.46分 | step: 52400 | performance: 1.1 | accuracy: 0.07 | loss: 0.56
Saving PPO weights in both H5 format and checkpoint @ update:656 
step: 52560 | worker_7@n_step_9: average total_reward after train data exhaustion : -11.3 | max total_reward: 63.5
Saving PPO weights in both H5 format and checkpoint @ update:657 
Saving PPO weights in both H5 format and checkpoint @ update:659 
update:660/2000, 耗时:0.00分/2.50分 | step: 52800 | performance: 1.2 | accuracy: 0.15 | loss: 0.50
Saving PPO weights in both H5 format and checkpoint @ update:660 
Saving PPO weights in both H5 format and checkpoint @ update:662 
Saving PPO weights in both H5 format and checkpoint @ update:664 
update:665/2000, 耗时:0.00分/2.53分 | step: 53200 | performance: 0.8 | accuracy: 0.13 | loss: 0.35
Saving PPO weights in both H5 format and checkpoint @ update:666 
Saving PPO weights in both H5 format and checkpoint @ update:668 
step: 53520 | worker_7@n_step_9: average total_reward after train data exhaustion : -0.3 | max total_reward: 63.5
Saving PPO weights in both H5 format and checkpoint @ update:669 
update:670/2000, 耗时:0.00分/2.56分 | step: 53600 | performance: 0.8 | accuracy: 0.00 | loss: 0.36
Saving PPO weights in both H5 format and checkpoint @ update:670 
update:675/2000, 耗时:0.00分/2.58分 | step: 54000 | performance: 1.3 | accuracy: 0.18 | loss: 0.15
step: 54400 | worker_7@n_step_9: average total_reward after train data exhaustion : -0.9 | max total_reward: 63.5
update:680/2000, 耗时:0.00分/2.60分 | step: 54400 | performance: 1.0 | accuracy: 0.00 | loss: 0.33
update:685/2000, 耗时:0.00分/2.62分 | step: 54800 | performance: 1.2 | accuracy: 0.10 | loss: 0.12
step: 54878 | worker_5@n_step_9: average total_reward after train data exhaustion : -0.6 | max total_reward: 63.5
step: 55036 | worker_3@n_step_9: average total_reward after train data exhaustion : -0.3 | max total_reward: 63.5
update:690/2000, 耗时:0.00分/2.64分 | step: 55200 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
Saving PPO weights in both H5 format and checkpoint @ update:691 
Saving PPO weights in both H5 format and checkpoint @ update:692 
update:695/2000, 耗时:0.00分/2.67分 | step: 55600 | performance: 1.3 | accuracy: 0.19 | loss: 0.15
update:700/2000, 耗时:0.00分/2.69分 | step: 56000 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
Saving PPO weights in both H5 format and checkpoint @ update:701 
Saving PPO weights in both H5 format and checkpoint @ update:702 
Saving PPO weights in both H5 format and checkpoint @ update:703 
Saving PPO weights in both H5 format and checkpoint @ update:704 
update:705/2000, 耗时:0.00分/2.72分 | step: 56400 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
Saving PPO weights in both H5 format and checkpoint @ update:705 
Saving PPO weights in both H5 format and checkpoint @ update:706 
Saving PPO weights in both H5 format and checkpoint @ update:707 
Saving PPO weights in both H5 format and checkpoint @ update:708 
Saving PPO weights in both H5 format and checkpoint @ update:709 
step: 56800 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.5 | max total_reward: 63.5
update:710/2000, 耗时:0.00分/2.77分 | step: 56800 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
update:715/2000, 耗时:0.00分/2.79分 | step: 57200 | performance: 1.0 | accuracy: 0.06 | loss: 0.08
step: 57276 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.4 | max total_reward: 63.5
update:720/2000, 耗时:0.00分/2.80分 | step: 57600 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
step: 57758 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.3 | max total_reward: 63.5
step: 57920 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.2 | max total_reward: 63.5
update:725/2000, 耗时:0.00分/2.82分 | step: 58000 | performance: 1.1 | accuracy: 0.10 | loss: 0.08
step: 58394 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.3 | max total_reward: 63.5
step: 58396 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.3 | max total_reward: 63.5
update:730/2000, 耗时:0.00分/2.84分 | step: 58400 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
Saving PPO weights in both H5 format and checkpoint @ update:732 
step: 58635 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.6 | max total_reward: 63.5
update:735/2000, 耗时:0.00分/2.86分 | step: 58800 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 58878 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 63.5
step: 58960 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 63.5
Saving PPO weights in both H5 format and checkpoint @ update:738 
Saving PPO weights in both H5 format and checkpoint @ update:739 
update:740/2000, 耗时:0.00分/2.89分 | step: 59200 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
Saving PPO weights in both H5 format and checkpoint @ update:740 
step: 59274 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 63.5
Saving PPO weights in both H5 format and checkpoint @ update:741 
Saving PPO weights in both H5 format and checkpoint @ update:743 
update:745/2000, 耗时:0.00分/2.92分 | step: 59600 | performance: 1.3 | accuracy: 0.38 | loss: 0.22
step: 59675 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 63.5
update:750/2000, 耗时:0.00分/2.94分 | step: 60000 | performance: 1.3 | accuracy: 0.12 | loss: 0.18
step: 60318 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 63.5
step: 60320 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 63.5
update:755/2000, 耗时:0.00分/2.96分 | step: 60400 | performance: 1.0 | accuracy: 0.10 | loss: 0.20
step: 60635 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 63.5
update:760/2000, 耗时:0.00分/2.98分 | step: 60800 | performance: 1.1 | accuracy: 0.17 | loss: 0.16
Saving PPO weights in both H5 format and checkpoint @ update:761 
Saving PPO weights in both H5 format and checkpoint @ update:762 
step: 61040 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 63.5
update:765/2000, 耗时:0.00分/3.01分 | step: 61200 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 61514 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 63.5
update:770/2000, 耗时:0.00分/3.02分 | step: 61600 | performance: 1.2 | accuracy: 0.20 | loss: 0.31
Saving PPO weights in both H5 format and checkpoint @ update:772 
update:775/2000, 耗时:0.00分/3.05分 | step: 62000 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 62080 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 63.5
step: 62394 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 63.5
update:780/2000, 耗时:0.00分/3.06分 | step: 62400 | performance: 1.0 | accuracy: 0.10 | loss: 0.12
step: 62636 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 63.5
update:785/2000, 耗时:0.00分/3.08分 | step: 62800 | performance: 1.1 | accuracy: 0.12 | loss: 0.12
step: 62878 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 63.5
step: 63115 | worker_2@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 63.5
update:790/2000, 耗时:0.00分/3.10分 | step: 63200 | performance: 1.4 | accuracy: 0.20 | loss: 0.17
step: 63518 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 63.5
update:795/2000, 耗时:0.00分/3.12分 | step: 63600 | performance: 2.0 | accuracy: 0.21 | loss: 0.22
Saving PPO weights in both H5 format and checkpoint @ update:796 
Saving PPO weights in both H5 format and checkpoint @ update:797 
Saving PPO weights in both H5 format and checkpoint @ update:799 
update:800/2000, 耗时:0.00分/3.15分 | step: 64000 | performance: 2.1 | accuracy: 0.18 | loss: 0.26
update:805/2000, 耗时:0.00分/3.17分 | step: 64400 | performance: 5.5 | accuracy: 0.18 | loss: 0.24
Saving PPO weights in both H5 format and checkpoint @ update:807 
update:810/2000, 耗时:0.00分/3.19分 | step: 64800 | performance: 4.0 | accuracy: 0.17 | loss: 0.23
update:815/2000, 耗时:0.00分/3.21分 | step: 65200 | performance: 4.3 | accuracy: 0.16 | loss: 0.35
update:820/2000, 耗时:0.00分/3.22分 | step: 65600 | performance: 3.4 | accuracy: 0.16 | loss: 0.29
Saving PPO weights in both H5 format and checkpoint @ update:820 
update:825/2000, 耗时:0.00分/3.25分 | step: 66000 | performance: 3.3 | accuracy: 0.16 | loss: 0.28
update:830/2000, 耗时:0.00分/3.27分 | step: 66400 | performance: 2.2 | accuracy: 0.15 | loss: 0.20
update:835/2000, 耗时:0.00分/3.28分 | step: 66800 | performance: 1.8 | accuracy: 0.15 | loss: 0.24
update:840/2000, 耗时:0.00分/3.30分 | step: 67200 | performance: 1.4 | accuracy: 0.14 | loss: 0.17
step: 67279 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 63.5
Saving PPO weights in both H5 format and checkpoint @ update:841 
Saving PPO weights in both H5 format and checkpoint @ update:844 
update:845/2000, 耗时:0.00分/3.33分 | step: 67600 | performance: 1.0 | accuracy: 0.14 | loss: 0.15
step: 67919 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 63.5
update:850/2000, 耗时:0.00分/3.35分 | step: 68000 | performance: 1.4 | accuracy: 0.13 | loss: 0.30
update:855/2000, 耗时:0.00分/3.36分 | step: 68400 | performance: 1.0 | accuracy: 0.13 | loss: 0.19
update:860/2000, 耗时:0.00分/3.38分 | step: 68800 | performance: 1.0 | accuracy: 0.13 | loss: 0.09
Saving PPO weights in both H5 format and checkpoint @ update:864 
update:865/2000, 耗时:0.00分/3.40分 | step: 69200 | performance: 1.6 | accuracy: 0.13 | loss: 0.25
Saving PPO weights in both H5 format and checkpoint @ update:867 
step: 69594 | worker_1@n_step_9: average total_reward after train data exhaustion : 2.0 | max total_reward: 63.5
update:870/2000, 耗时:0.00分/3.42分 | step: 69600 | performance: 1.1 | accuracy: 0.13 | loss: 0.23
Saving PPO weights in both H5 format and checkpoint @ update:871 
update:875/2000, 耗时:0.00分/3.44分 | step: 70000 | performance: 1.3 | accuracy: 0.13 | loss: 0.13
Saving PPO weights in both H5 format and checkpoint @ update:875 
Saving PPO weights in both H5 format and checkpoint @ update:877 
Saving PPO weights in both H5 format and checkpoint @ update:879 
update:880/2000, 耗时:0.00分/3.47分 | step: 70400 | performance: 1.5 | accuracy: 0.13 | loss: 0.17
Saving PPO weights in both H5 format and checkpoint @ update:881 
step: 70553 | worker_0@n_step_9: average total_reward after train data exhaustion : 2.0 | max total_reward: 63.5
step: 70799 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.9 | max total_reward: 63.5
update:885/2000, 耗时:0.00分/3.49分 | step: 70800 | performance: 1.5 | accuracy: 0.13 | loss: 0.23
update:890/2000, 耗时:0.00分/3.51分 | step: 71200 | performance: 1.2 | accuracy: 0.12 | loss: 0.32
update:895/2000, 耗时:0.00分/3.53分 | step: 71600 | performance: 1.5 | accuracy: 0.13 | loss: 0.53
update:900/2000, 耗时:0.00分/3.54分 | step: 72000 | performance: 1.5 | accuracy: 0.13 | loss: 0.20
update:905/2000, 耗时:0.00分/3.56分 | step: 72400 | performance: 1.3 | accuracy: 0.13 | loss: 0.45
update:910/2000, 耗时:0.00分/3.58分 | step: 72800 | performance: 1.0 | accuracy: 0.13 | loss: 0.41
update:915/2000, 耗时:0.00分/3.60分 | step: 73200 | performance: 0.9 | accuracy: 0.12 | loss: 0.37
update:920/2000, 耗时:0.00分/3.61分 | step: 73600 | performance: 0.9 | accuracy: 0.12 | loss: 0.19
update:925/2000, 耗时:0.00分/3.63分 | step: 74000 | performance: 0.7 | accuracy: 0.12 | loss: 0.33
update:930/2000, 耗时:0.00分/3.65分 | step: 74400 | performance: 0.7 | accuracy: 0.12 | loss: 0.21
update:935/2000, 耗时:0.00分/3.67分 | step: 74800 | performance: 0.7 | accuracy: 0.13 | loss: 0.11
update:940/2000, 耗时:0.00分/3.69分 | step: 75200 | performance: 0.8 | accuracy: 0.13 | loss: 0.17
update:945/2000, 耗时:0.00分/3.70分 | step: 75600 | performance: 0.5 | accuracy: 0.13 | loss: 0.20
update:950/2000, 耗时:0.00分/3.72分 | step: 76000 | performance: 0.5 | accuracy: 0.12 | loss: 0.16
update:955/2000, 耗时:0.00分/3.74分 | step: 76400 | performance: 0.5 | accuracy: 0.12 | loss: 0.11
update:960/2000, 耗时:0.00分/3.75分 | step: 76800 | performance: 0.5 | accuracy: 0.12 | loss: 0.09
update:965/2000, 耗时:0.00分/3.77分 | step: 77200 | performance: 0.4 | accuracy: 0.12 | loss: 0.28
update:970/2000, 耗时:0.00分/3.79分 | step: 77600 | performance: 0.3 | accuracy: 0.12 | loss: 0.16
update:975/2000, 耗时:0.00分/3.81分 | step: 78000 | performance: 0.3 | accuracy: 0.11 | loss: 0.29
update:980/2000, 耗时:0.00分/3.82分 | step: 78400 | performance: 0.2 | accuracy: 0.11 | loss: 0.15
update:985/2000, 耗时:0.00分/3.84分 | step: 78800 | performance: 0.3 | accuracy: 0.11 | loss: 0.09
update:990/2000, 耗时:0.00分/3.86分 | step: 79200 | performance: 0.2 | accuracy: 0.11 | loss: 0.12
update:995/2000, 耗时:0.00分/3.88分 | step: 79600 | performance: 0.3 | accuracy: 0.11 | loss: 0.17
Saving PPO weights in both H5 format and checkpoint @ update:997 
step: 79996 | worker_3@n_step_9: average total_reward after train data exhaustion : 2.3 | max total_reward: 63.5
update:1000/2000, 耗时:0.00分/3.90分 | step: 80000 | performance: 0.2 | accuracy: 0.11 | loss: 0.33
update:1005/2000, 耗时:0.00分/3.92分 | step: 80400 | performance: 0.2 | accuracy: 0.11 | loss: 0.04
Saving PPO weights in both H5 format and checkpoint @ update:1007 
Saving PPO weights in both H5 format and checkpoint @ update:1009 
update:1010/2000, 耗时:0.00分/3.94分 | step: 80800 | performance: 0.2 | accuracy: 0.11 | loss: 0.03
step: 80956 | worker_3@n_step_9: average total_reward after train data exhaustion : 3.5 | max total_reward: 63.5
Saving PPO weights in both H5 format and checkpoint @ update:1012 
Saving PPO weights in both H5 format and checkpoint @ update:1014 
update:1015/2000, 耗时:0.00分/3.97分 | step: 81200 | performance: 0.2 | accuracy: 0.11 | loss: 0.15
Saving PPO weights in both H5 format and checkpoint @ update:1019 
step: 81598 | worker_5@n_step_9: average total_reward after train data exhaustion : 3.8 | max total_reward: 63.5
update:1020/2000, 耗时:0.00分/3.99分 | step: 81600 | performance: 0.2 | accuracy: 0.10 | loss: 0.07
Saving PPO weights in both H5 format and checkpoint @ update:1021 
update:1025/2000, 耗时:0.00分/4.02分 | step: 82000 | performance: 0.2 | accuracy: 0.10 | loss: 0.11
update:1030/2000, 耗时:0.00分/4.04分 | step: 82400 | performance: 0.3 | accuracy: 0.10 | loss: 0.07
step: 82556 | worker_3@n_step_9: average total_reward after train data exhaustion : 2.8 | max total_reward: 63.5
step: 82718 | worker_5@n_step_9: average total_reward after train data exhaustion : 2.6 | max total_reward: 63.5
update:1035/2000, 耗时:0.00分/4.05分 | step: 82800 | performance: 0.3 | accuracy: 0.10 | loss: 0.08
step: 82877 | worker_4@n_step_9: average total_reward after train data exhaustion : 2.6 | max total_reward: 63.5
update:1040/2000, 耗时:0.00分/4.07分 | step: 83200 | performance: 0.3 | accuracy: 0.10 | loss: 0.10
step: 83280 | worker_7@n_step_9: average total_reward after train data exhaustion : 2.6 | max total_reward: 63.5
update:1045/2000, 耗时:0.00分/4.09分 | step: 83600 | performance: 1.1 | accuracy: 0.11 | loss: 0.23
step: 83915 | worker_2@n_step_9: average total_reward after train data exhaustion : 3.5 | max total_reward: 63.5
update:1050/2000, 耗时:0.00分/4.11分 | step: 84000 | performance: 1.3 | accuracy: 0.14 | loss: 0.10
step: 84157 | worker_4@n_step_9: average total_reward after train data exhaustion : 3.2 | max total_reward: 63.5
update:1055/2000, 耗时:0.00分/4.12分 | step: 84400 | performance: 1.1 | accuracy: 0.11 | loss: 0.16
step: 84554 | worker_1@n_step_9: average total_reward after train data exhaustion : 4.3 | max total_reward: 75.4
Saving PPO weights in both H5 format and checkpoint @ update:1057 
update:1060/2000, 耗时:0.00分/4.15分 | step: 84800 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
Saving PPO weights in both H5 format and checkpoint @ update:1060 
step: 84958 | worker_5@n_step_9: average total_reward after train data exhaustion : 3.4 | max total_reward: 75.4
step: 85193 | worker_0@n_step_9: average total_reward after train data exhaustion : 2.3 | max total_reward: 75.4
step: 85197 | worker_4@n_step_9: average total_reward after train data exhaustion : 2.3 | max total_reward: 75.4
update:1065/2000, 耗时:0.00分/4.17分 | step: 85200 | performance: 1.1 | accuracy: 0.12 | loss: 0.13
step: 85279 | worker_6@n_step_9: average total_reward after train data exhaustion : 2.3 | max total_reward: 75.4
step: 85436 | worker_3@n_step_9: average total_reward after train data exhaustion : 2.3 | max total_reward: 75.4
update:1070/2000, 耗时:0.00分/4.19分 | step: 85600 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
update:1075/2000, 耗时:0.00分/4.20分 | step: 86000 | performance: 1.0 | accuracy: 0.12 | loss: 0.07
step: 86233 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.2 | max total_reward: 75.4
step: 86317 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.3 | max total_reward: 75.4
step: 86398 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.3 | max total_reward: 75.4
update:1080/2000, 耗时:0.00分/4.22分 | step: 86400 | performance: 1.2 | accuracy: 0.13 | loss: 0.13
step: 86479 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.3 | max total_reward: 75.4
update:1085/2000, 耗时:0.00分/4.24分 | step: 86800 | performance: 1.4 | accuracy: 0.31 | loss: 0.28
update:1090/2000, 耗时:0.00分/4.26分 | step: 87200 | performance: 1.4 | accuracy: 0.16 | loss: 0.43
step: 87517 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.4 | max total_reward: 75.4
update:1095/2000, 耗时:0.00分/4.28分 | step: 87600 | performance: 1.7 | accuracy: 0.19 | loss: 0.61
update:1100/2000, 耗时:0.00分/4.29分 | step: 88000 | performance: 2.8 | accuracy: 0.18 | loss: 0.47
update:1105/2000, 耗时:0.00分/4.31分 | step: 88400 | performance: 7.7 | accuracy: 0.23 | loss: 0.78
update:1110/2000, 耗时:0.00分/4.33分 | step: 88800 | performance: 4.4 | accuracy: 0.23 | loss: 0.90
update:1115/2000, 耗时:0.00分/4.35分 | step: 89200 | performance: 5.6 | accuracy: 0.26 | loss: 1.41
update:1120/2000, 耗时:0.00分/4.36分 | step: 89600 | performance: 3.8 | accuracy: 0.26 | loss: 0.98
update:1125/2000, 耗时:0.00分/4.38分 | step: 90000 | performance: 3.5 | accuracy: 0.26 | loss: 0.65
update:1130/2000, 耗时:0.00分/4.40分 | step: 90400 | performance: 2.7 | accuracy: 0.25 | loss: 0.38
update:1135/2000, 耗时:0.00分/4.42分 | step: 90800 | performance: 2.3 | accuracy: 0.23 | loss: 0.19
update:1140/2000, 耗时:0.00分/4.44分 | step: 91200 | performance: 1.9 | accuracy: 0.22 | loss: 0.26
update:1145/2000, 耗时:0.00分/4.45分 | step: 91600 | performance: 1.5 | accuracy: 0.21 | loss: 0.11
update:1150/2000, 耗时:0.00分/4.47分 | step: 92000 | performance: 1.7 | accuracy: 0.20 | loss: 0.14
update:1155/2000, 耗时:0.00分/4.49分 | step: 92400 | performance: 1.6 | accuracy: 0.19 | loss: 0.15
update:1160/2000, 耗时:0.00分/4.50分 | step: 92800 | performance: 1.6 | accuracy: 0.18 | loss: 0.22
update:1165/2000, 耗时:0.00分/4.52分 | step: 93200 | performance: 2.1 | accuracy: 0.18 | loss: 0.17
update:1170/2000, 耗时:0.00分/4.54分 | step: 93600 | performance: 1.5 | accuracy: 0.17 | loss: 0.23
update:1175/2000, 耗时:0.00分/4.56分 | step: 94000 | performance: 1.3 | accuracy: 0.17 | loss: 0.15
update:1180/2000, 耗时:0.00分/4.57分 | step: 94400 | performance: 1.2 | accuracy: 0.16 | loss: 0.15
update:1185/2000, 耗时:0.00分/4.59分 | step: 94800 | performance: 1.2 | accuracy: 0.15 | loss: 0.18
update:1190/2000, 耗时:0.00分/4.61分 | step: 95200 | performance: 0.8 | accuracy: 0.15 | loss: 0.20
update:1195/2000, 耗时:0.00分/4.63分 | step: 95600 | performance: 0.8 | accuracy: 0.15 | loss: 0.12
update:1200/2000, 耗时:0.00分/4.64分 | step: 96000 | performance: 0.6 | accuracy: 0.14 | loss: 0.08
update:1205/2000, 耗时:0.00分/4.66分 | step: 96400 | performance: 0.6 | accuracy: 0.14 | loss: 0.16
update:1210/2000, 耗时:0.00分/4.68分 | step: 96800 | performance: 0.8 | accuracy: 0.14 | loss: 0.17
update:1215/2000, 耗时:0.00分/4.70分 | step: 97200 | performance: 0.7 | accuracy: 0.13 | loss: 0.16
update:1220/2000, 耗时:0.00分/4.72分 | step: 97600 | performance: 0.7 | accuracy: 0.13 | loss: 0.13
update:1225/2000, 耗时:0.00分/4.73分 | step: 98000 | performance: 0.6 | accuracy: 0.13 | loss: 0.10
update:1230/2000, 耗时:0.00分/4.75分 | step: 98400 | performance: 0.7 | accuracy: 0.13 | loss: 0.09
update:1235/2000, 耗时:0.00分/4.77分 | step: 98800 | performance: 0.7 | accuracy: 0.13 | loss: 0.09
update:1240/2000, 耗时:0.00分/4.79分 | step: 99200 | performance: 0.8 | accuracy: 0.13 | loss: 0.07
update:1245/2000, 耗时:0.00分/4.80分 | step: 99600 | performance: 0.7 | accuracy: 0.12 | loss: 0.16
update:1250/2000, 耗时:0.00分/4.82分 | step: 100000 | performance: 0.7 | accuracy: 0.12 | loss: 0.02
update:1255/2000, 耗时:0.00分/4.84分 | step: 100400 | performance: 0.8 | accuracy: 0.12 | loss: 0.04
update:1260/2000, 耗时:0.00分/4.86分 | step: 100800 | performance: 0.8 | accuracy: 0.12 | loss: 0.22
update:1265/2000, 耗时:0.00分/4.87分 | step: 101200 | performance: 0.7 | accuracy: 0.12 | loss: 0.26
update:1270/2000, 耗时:0.00分/4.89分 | step: 101600 | performance: 0.7 | accuracy: 0.11 | loss: 0.09
update:1275/2000, 耗时:0.00分/4.91分 | step: 102000 | performance: 0.6 | accuracy: 0.11 | loss: 0.30
update:1280/2000, 耗时:0.00分/4.93分 | step: 102400 | performance: 0.6 | accuracy: 0.11 | loss: 0.13
update:1285/2000, 耗时:0.00分/4.94分 | step: 102800 | performance: 0.6 | accuracy: 0.11 | loss: 0.16
update:1290/2000, 耗时:0.00分/4.96分 | step: 103200 | performance: 0.7 | accuracy: 0.11 | loss: 0.05
update:1295/2000, 耗时:0.00分/4.98分 | step: 103600 | performance: 0.7 | accuracy: 0.11 | loss: 0.07
step: 103756 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.6 | max total_reward: 75.4
update:1300/2000, 耗时:0.00分/5.00分 | step: 104000 | performance: 0.6 | accuracy: 0.10 | loss: 0.02
update:1305/2000, 耗时:0.00分/5.02分 | step: 104400 | performance: 0.6 | accuracy: 0.10 | loss: 0.10
update:1310/2000, 耗时:0.00分/5.03分 | step: 104800 | performance: 0.8 | accuracy: 0.10 | loss: 0.14
step: 104876 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 75.4
step: 104953 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 75.4
update:1315/2000, 耗时:0.00分/5.05分 | step: 105200 | performance: 1.2 | accuracy: 0.08 | loss: 0.07
update:1320/2000, 耗时:0.00分/5.07分 | step: 105600 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 105679 | worker_6@n_step_9: average total_reward after train data exhaustion : 2.9 | max total_reward: 75.4
step: 105920 | worker_7@n_step_9: average total_reward after train data exhaustion : 2.7 | max total_reward: 75.4
step: 105996 | worker_3@n_step_9: average total_reward after train data exhaustion : 2.6 | max total_reward: 75.4
update:1325/2000, 耗时:0.00分/5.09分 | step: 106000 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 106073 | worker_0@n_step_9: average total_reward after train data exhaustion : 2.3 | max total_reward: 75.4
step: 106235 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 75.4
update:1330/2000, 耗时:0.00分/5.10分 | step: 106400 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 106799 | worker_6@n_step_9: average total_reward after train data exhaustion : 2.8 | max total_reward: 75.4
update:1335/2000, 耗时:0.00分/5.12分 | step: 106800 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 106957 | worker_4@n_step_9: average total_reward after train data exhaustion : 2.9 | max total_reward: 75.4
step: 107040 | worker_7@n_step_9: average total_reward after train data exhaustion : 2.9 | max total_reward: 75.4
step: 107116 | worker_3@n_step_9: average total_reward after train data exhaustion : 2.9 | max total_reward: 75.4
update:1340/2000, 耗时:0.00分/5.14分 | step: 107200 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 107433 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.1 | max total_reward: 75.4
step: 107595 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 75.4
update:1345/2000, 耗时:0.00分/5.16分 | step: 107600 | performance: 1.1 | accuracy: 0.11 | loss: 0.12
step: 108000 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 75.4
update:1350/2000, 耗时:0.00分/5.18分 | step: 108000 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
step: 108317 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 75.4
update:1355/2000, 耗时:0.00分/5.19分 | step: 108400 | performance: 1.2 | accuracy: 0.12 | loss: 0.15
step: 108553 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 75.4
step: 108554 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.6 | max total_reward: 75.4
update:1360/2000, 耗时:0.00分/5.21分 | step: 108800 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
step: 108959 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 75.4
step: 108960 | worker_7@n_step_9: average total_reward after train data exhaustion : 0.7 | max total_reward: 75.4
update:1365/2000, 耗时:0.00分/5.23分 | step: 109200 | performance: 1.4 | accuracy: 0.20 | loss: 0.30
step: 109598 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 75.4
update:1370/2000, 耗时:0.00分/5.25分 | step: 109600 | performance: 1.5 | accuracy: 0.15 | loss: 0.30
update:1375/2000, 耗时:0.00分/5.27分 | step: 110000 | performance: 1.6 | accuracy: 0.13 | loss: 0.52
update:1380/2000, 耗时:0.00分/5.28分 | step: 110400 | performance: 5.3 | accuracy: 0.19 | loss: 1.23
update:1385/2000, 耗时:0.00分/5.30分 | step: 110800 | performance: 5.7 | accuracy: 0.23 | loss: 0.78
update:1390/2000, 耗时:0.00分/5.32分 | step: 111200 | performance: 6.5 | accuracy: 0.25 | loss: 1.78
update:1395/2000, 耗时:0.00分/5.34分 | step: 111600 | performance: 7.2 | accuracy: 0.28 | loss: 1.31
update:1400/2000, 耗时:0.00分/5.35分 | step: 112000 | performance: 4.4 | accuracy: 0.28 | loss: 1.55
update:1405/2000, 耗时:0.00分/5.37分 | step: 112400 | performance: 2.1 | accuracy: 0.27 | loss: 0.64
update:1410/2000, 耗时:0.00分/5.39分 | step: 112800 | performance: 1.9 | accuracy: 0.25 | loss: 0.22
update:1415/2000, 耗时:0.00分/5.41分 | step: 113200 | performance: 1.7 | accuracy: 0.23 | loss: 0.23
update:1420/2000, 耗时:0.00分/5.43分 | step: 113600 | performance: 1.7 | accuracy: 0.22 | loss: 0.13
update:1425/2000, 耗时:0.00分/5.44分 | step: 114000 | performance: 1.6 | accuracy: 0.20 | loss: 0.17
update:1430/2000, 耗时:0.00分/5.46分 | step: 114400 | performance: 1.9 | accuracy: 0.20 | loss: 0.18
update:1435/2000, 耗时:0.00分/5.48分 | step: 114800 | performance: 1.5 | accuracy: 0.19 | loss: 0.14
update:1440/2000, 耗时:0.00分/5.50分 | step: 115200 | performance: 1.6 | accuracy: 0.19 | loss: 0.14
update:1445/2000, 耗时:0.00分/5.52分 | step: 115600 | performance: 1.5 | accuracy: 0.18 | loss: 0.13
update:1450/2000, 耗时:0.00分/5.53分 | step: 116000 | performance: 1.5 | accuracy: 0.17 | loss: 0.09
update:1455/2000, 耗时:0.00分/5.55分 | step: 116400 | performance: 1.4 | accuracy: 0.16 | loss: 0.12
update:1460/2000, 耗时:0.00分/5.57分 | step: 116800 | performance: 1.4 | accuracy: 0.16 | loss: 0.14
update:1465/2000, 耗时:0.00分/5.59分 | step: 117200 | performance: 1.4 | accuracy: 0.15 | loss: 0.12
update:1470/2000, 耗时:0.00分/5.60分 | step: 117600 | performance: 1.4 | accuracy: 0.15 | loss: 0.65
update:1475/2000, 耗时:0.00分/5.62分 | step: 118000 | performance: 1.4 | accuracy: 0.14 | loss: 0.19
update:1480/2000, 耗时:0.00分/5.64分 | step: 118400 | performance: 1.5 | accuracy: 0.14 | loss: 0.06
update:1485/2000, 耗时:0.00分/5.66分 | step: 118800 | performance: 1.8 | accuracy: 0.14 | loss: 0.04
update:1490/2000, 耗时:0.00分/5.67分 | step: 119200 | performance: 1.5 | accuracy: 0.13 | loss: 0.15
update:1495/2000, 耗时:0.00分/5.69分 | step: 119600 | performance: 1.7 | accuracy: 0.13 | loss: 0.16
update:1500/2000, 耗时:0.00分/5.71分 | step: 120000 | performance: 1.6 | accuracy: 0.13 | loss: 0.10
update:1505/2000, 耗时:0.00分/5.73分 | step: 120400 | performance: 1.7 | accuracy: 0.13 | loss: 0.12
update:1510/2000, 耗时:0.00分/5.75分 | step: 120800 | performance: 1.4 | accuracy: 0.12 | loss: 0.05
update:1515/2000, 耗时:0.00分/5.76分 | step: 121200 | performance: 1.4 | accuracy: 0.12 | loss: 0.03
update:1520/2000, 耗时:0.00分/5.78分 | step: 121600 | performance: 1.2 | accuracy: 0.12 | loss: 0.05
update:1525/2000, 耗时:0.00分/5.80分 | step: 122000 | performance: 1.2 | accuracy: 0.12 | loss: 0.05
update:1530/2000, 耗时:0.00分/5.82分 | step: 122400 | performance: 1.2 | accuracy: 0.11 | loss: 0.04
update:1535/2000, 耗时:0.00分/5.84分 | step: 122800 | performance: 1.2 | accuracy: 0.11 | loss: 0.01
update:1540/2000, 耗时:0.00分/5.85分 | step: 123200 | performance: 1.4 | accuracy: 0.11 | loss: 0.54
update:1545/2000, 耗时:0.00分/5.87分 | step: 123600 | performance: 1.5 | accuracy: 0.12 | loss: 0.36
update:1550/2000, 耗时:0.00分/5.89分 | step: 124000 | performance: 2.2 | accuracy: 0.12 | loss: 0.76
update:1555/2000, 耗时:0.00分/5.91分 | step: 124400 | performance: 2.2 | accuracy: 0.12 | loss: 0.61
update:1560/2000, 耗时:0.00分/5.92分 | step: 124800 | performance: 2.1 | accuracy: 0.12 | loss: 0.28
update:1565/2000, 耗时:0.00分/5.94分 | step: 125200 | performance: 2.0 | accuracy: 0.12 | loss: 0.12
update:1570/2000, 耗时:0.00分/5.96分 | step: 125600 | performance: 1.9 | accuracy: 0.11 | loss: 0.08
update:1575/2000, 耗时:0.00分/5.98分 | step: 126000 | performance: 1.3 | accuracy: 0.11 | loss: 0.05
update:1580/2000, 耗时:0.00分/5.99分 | step: 126400 | performance: 1.6 | accuracy: 0.11 | loss: 0.10
step: 126636 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 75.4
update:1585/2000, 耗时:0.00分/6.01分 | step: 126800 | performance: 1.3 | accuracy: 0.11 | loss: 0.09
update:1590/2000, 耗时:0.00分/6.03分 | step: 127200 | performance: 1.4 | accuracy: 0.11 | loss: 0.18
update:1595/2000, 耗时:0.00分/6.05分 | step: 127600 | performance: 1.5 | accuracy: 0.11 | loss: 0.04
step: 127756 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 75.4
update:1600/2000, 耗时:0.00分/6.06分 | step: 128000 | performance: 1.2 | accuracy: 0.11 | loss: 0.13
update:1605/2000, 耗时:0.00分/6.08分 | step: 128400 | performance: 1.2 | accuracy: 0.10 | loss: 0.11
update:1610/2000, 耗时:0.00分/6.10分 | step: 128800 | performance: 1.4 | accuracy: 0.10 | loss: 0.21
step: 129039 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 75.4
update:1615/2000, 耗时:0.00分/6.12分 | step: 129200 | performance: 1.4 | accuracy: 0.10 | loss: 0.12
update:1620/2000, 耗时:0.00分/6.13分 | step: 129600 | performance: 1.5 | accuracy: 0.10 | loss: 0.13
step: 129994 | worker_1@n_step_9: average total_reward after train data exhaustion : 2.6 | max total_reward: 75.4
step: 129996 | worker_3@n_step_9: average total_reward after train data exhaustion : 2.6 | max total_reward: 75.4
update:1625/2000, 耗时:0.00分/6.15分 | step: 130000 | performance: 1.3 | accuracy: 0.10 | loss: 0.13
update:1630/2000, 耗时:0.00分/6.17分 | step: 130400 | performance: 1.4 | accuracy: 0.10 | loss: 0.21
step: 130794 | worker_1@n_step_9: average total_reward after train data exhaustion : 2.0 | max total_reward: 75.4
update:1635/2000, 耗时:0.00分/6.19分 | step: 130800 | performance: 1.9 | accuracy: 0.10 | loss: 0.24
step: 131117 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 75.4
update:1640/2000, 耗时:0.00分/6.20分 | step: 131200 | performance: 2.7 | accuracy: 0.10 | loss: 0.34
step: 131436 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 75.4
update:1645/2000, 耗时:0.00分/6.22分 | step: 131600 | performance: 2.7 | accuracy: 0.10 | loss: 0.27
update:1650/2000, 耗时:0.00分/6.24分 | step: 132000 | performance: 2.9 | accuracy: 0.10 | loss: 0.33
update:1655/2000, 耗时:0.00分/6.26分 | step: 132400 | performance: 3.9 | accuracy: 0.11 | loss: 0.19
step: 132479 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 75.4
update:1660/2000, 耗时:0.00分/6.27分 | step: 132800 | performance: 3.1 | accuracy: 0.11 | loss: 0.44
update:1665/2000, 耗时:0.00分/6.29分 | step: 133200 | performance: 3.3 | accuracy: 0.11 | loss: 0.33
update:1670/2000, 耗时:0.00分/6.31分 | step: 133600 | performance: 6.6 | accuracy: 0.11 | loss: 0.83
update:1675/2000, 耗时:0.00分/6.33分 | step: 134000 | performance: 4.7 | accuracy: 0.11 | loss: 0.44
update:1680/2000, 耗时:0.00分/6.34分 | step: 134400 | performance: 1.1 | accuracy: 0.15 | loss: 0.34
Saving PPO weights in both H5 format and checkpoint @ update:1683 
update:1685/2000, 耗时:0.00分/6.37分 | step: 134800 | performance: 1.1 | accuracy: 0.16 | loss: 0.26
Saving PPO weights in both H5 format and checkpoint @ update:1685 
update:1690/2000, 耗时:0.00分/6.39分 | step: 135200 | performance: 0.9 | accuracy: 0.16 | loss: 0.26
Saving PPO weights in both H5 format and checkpoint @ update:1691 
update:1695/2000, 耗时:0.00分/6.41分 | step: 135600 | performance: 1.3 | accuracy: 0.17 | loss: 0.46
update:1700/2000, 耗时:0.00分/6.43分 | step: 136000 | performance: 1.9 | accuracy: 0.16 | loss: 0.20
update:1705/2000, 耗时:0.00分/6.45分 | step: 136400 | performance: 1.8 | accuracy: 0.16 | loss: 0.26
update:1710/2000, 耗时:0.00分/6.46分 | step: 136800 | performance: 2.0 | accuracy: 0.16 | loss: 0.33
update:1715/2000, 耗时:0.00分/6.48分 | step: 137200 | performance: 1.6 | accuracy: 0.15 | loss: 0.41
update:1720/2000, 耗时:0.00分/6.50分 | step: 137600 | performance: 1.6 | accuracy: 0.16 | loss: 0.23
update:1725/2000, 耗时:0.00分/6.51分 | step: 138000 | performance: 1.8 | accuracy: 0.16 | loss: 0.34
update:1730/2000, 耗时:0.00分/6.53分 | step: 138400 | performance: 1.5 | accuracy: 0.15 | loss: 0.18
update:1735/2000, 耗时:0.00分/6.55分 | step: 138800 | performance: 2.3 | accuracy: 0.16 | loss: 0.23
update:1740/2000, 耗时:0.00分/6.56分 | step: 139200 | performance: 1.7 | accuracy: 0.16 | loss: 0.29
update:1745/2000, 耗时:0.00分/6.58分 | step: 139600 | performance: 2.6 | accuracy: 0.16 | loss: 0.39
update:1750/2000, 耗时:0.00分/6.60分 | step: 140000 | performance: 2.3 | accuracy: 0.16 | loss: 0.33
update:1755/2000, 耗时:0.00分/6.62分 | step: 140400 | performance: 2.2 | accuracy: 0.16 | loss: 0.18
update:1760/2000, 耗时:0.00分/6.64分 | step: 140800 | performance: 3.1 | accuracy: 0.16 | loss: 0.37
update:1765/2000, 耗时:0.00分/6.65分 | step: 141200 | performance: 3.3 | accuracy: 0.16 | loss: 0.16
update:1770/2000, 耗时:0.00分/6.67分 | step: 141600 | performance: 3.8 | accuracy: 0.16 | loss: 0.14
update:1775/2000, 耗时:0.00分/6.69分 | step: 142000 | performance: 3.3 | accuracy: 0.16 | loss: 0.25
update:1780/2000, 耗时:0.00分/6.71分 | step: 142400 | performance: 2.7 | accuracy: 0.15 | loss: 0.21
update:1785/2000, 耗时:0.00分/6.72分 | step: 142800 | performance: 2.4 | accuracy: 0.15 | loss: 0.14
update:1790/2000, 耗时:0.00分/6.74分 | step: 143200 | performance: 3.4 | accuracy: 0.15 | loss: 0.30
update:1795/2000, 耗时:0.00分/6.76分 | step: 143600 | performance: 1.3 | accuracy: 0.15 | loss: 0.23
update:1800/2000, 耗时:0.00分/6.78分 | step: 144000 | performance: 1.4 | accuracy: 0.15 | loss: 0.21
update:1805/2000, 耗时:0.00分/6.80分 | step: 144400 | performance: 1.5 | accuracy: 0.15 | loss: 0.13
update:1810/2000, 耗时:0.00分/6.81分 | step: 144800 | performance: 1.4 | accuracy: 0.15 | loss: 0.29
update:1815/2000, 耗时:0.00分/6.83分 | step: 145200 | performance: 1.2 | accuracy: 0.15 | loss: 0.38
update:1820/2000, 耗时:0.00分/6.85分 | step: 145600 | performance: 1.0 | accuracy: 0.15 | loss: 0.29
update:1825/2000, 耗时:0.00分/6.87分 | step: 146000 | performance: 0.9 | accuracy: 0.15 | loss: 0.30
update:1830/2000, 耗时:0.00分/6.88分 | step: 146400 | performance: 0.7 | accuracy: 0.15 | loss: 0.51
update:1835/2000, 耗时:0.00分/6.90分 | step: 146800 | performance: 0.9 | accuracy: 0.16 | loss: 0.84
update:1840/2000, 耗时:0.00分/6.92分 | step: 147200 | performance: 1.4 | accuracy: 0.16 | loss: 0.65
update:1845/2000, 耗时:0.00分/6.94分 | step: 147600 | performance: 1.9 | accuracy: 0.16 | loss: 0.55
update:1850/2000, 耗时:0.00分/6.95分 | step: 148000 | performance: 2.8 | accuracy: 0.16 | loss: 0.78
update:1855/2000, 耗时:0.00分/6.97分 | step: 148400 | performance: 1.9 | accuracy: 0.16 | loss: 0.66
update:1860/2000, 耗时:0.00分/6.99分 | step: 148800 | performance: 4.2 | accuracy: 0.17 | loss: 1.03
update:1865/2000, 耗时:0.00分/7.01分 | step: 149200 | performance: 7.9 | accuracy: 0.17 | loss: 1.24
update:1870/2000, 耗时:0.00分/7.02分 | step: 149600 | performance: 9.2 | accuracy: 0.18 | loss: 0.93
update:1875/2000, 耗时:0.00分/7.04分 | step: 150000 | performance: 5.8 | accuracy: 0.18 | loss: 0.82
update:1880/2000, 耗时:0.00分/7.06分 | step: 150400 | performance: 2.1 | accuracy: 0.18 | loss: 0.66
update:1885/2000, 耗时:0.00分/7.08分 | step: 150800 | performance: 1.5 | accuracy: 0.18 | loss: 0.56
update:1890/2000, 耗时:0.00分/7.10分 | step: 151200 | performance: 1.3 | accuracy: 0.18 | loss: 0.63
update:1895/2000, 耗时:0.00分/7.11分 | step: 151600 | performance: 1.6 | accuracy: 0.18 | loss: 0.52
update:1900/2000, 耗时:0.00分/7.13分 | step: 152000 | performance: 2.0 | accuracy: 0.18 | loss: 0.43
update:1905/2000, 耗时:0.00分/7.15分 | step: 152400 | performance: 1.8 | accuracy: 0.18 | loss: 0.37
update:1910/2000, 耗时:0.00分/7.17分 | step: 152800 | performance: 1.9 | accuracy: 0.18 | loss: 0.77
update:1915/2000, 耗时:0.00分/7.19分 | step: 153200 | performance: 2.2 | accuracy: 0.18 | loss: 0.37
update:1920/2000, 耗时:0.00分/7.21分 | step: 153600 | performance: 2.3 | accuracy: 0.18 | loss: 0.35
update:1925/2000, 耗时:0.00分/7.23分 | step: 154000 | performance: 2.0 | accuracy: 0.18 | loss: 0.23
update:1930/2000, 耗时:0.00分/7.24分 | step: 154400 | performance: 2.0 | accuracy: 0.18 | loss: 0.28
update:1935/2000, 耗时:0.00分/7.26分 | step: 154800 | performance: 2.0 | accuracy: 0.18 | loss: 0.18
update:1940/2000, 耗时:0.00分/7.28分 | step: 155200 | performance: 1.6 | accuracy: 0.18 | loss: 0.22
update:1945/2000, 耗时:0.00分/7.30分 | step: 155600 | performance: 1.4 | accuracy: 0.17 | loss: 0.10
update:1950/2000, 耗时:0.00分/7.32分 | step: 156000 | performance: 1.1 | accuracy: 0.17 | loss: 0.17
update:1955/2000, 耗时:0.00分/7.34分 | step: 156400 | performance: 1.3 | accuracy: 0.17 | loss: 0.08
update:1960/2000, 耗时:0.00分/7.36分 | step: 156800 | performance: 1.5 | accuracy: 0.17 | loss: 0.13
Saving PPO weights in both H5 format and checkpoint @ update:1961 
step: 157114 | worker_1@n_step_9: average total_reward after train data exhaustion : 11.3 | max total_reward: 133.1
Saving PPO weights in both H5 format and checkpoint @ update:1964 
update:1965/2000, 耗时:0.00分/7.39分 | step: 157200 | performance: 1.4 | accuracy: 0.16 | loss: 0.20
Saving PPO weights in both H5 format and checkpoint @ update:1965 
Saving PPO weights in both H5 format and checkpoint @ update:1966 
Saving PPO weights in both H5 format and checkpoint @ update:1967 
step: 157516 | worker_3@n_step_9: average total_reward after train data exhaustion : 11.8 | max total_reward: 133.1
update:1970/2000, 耗时:0.00分/7.42分 | step: 157600 | performance: 1.4 | accuracy: 0.16 | loss: 0.14
step: 157677 | worker_4@n_step_9: average total_reward after train data exhaustion : 11.6 | max total_reward: 133.1
update:1975/2000, 耗时:0.00分/7.44分 | step: 158000 | performance: 1.1 | accuracy: 0.16 | loss: 0.08
Saving PPO weights in both H5 format and checkpoint @ update:1977 
Saving PPO weights in both H5 format and checkpoint @ update:1978 
update:1980/2000, 耗时:0.00分/7.46分 | step: 158400 | performance: 1.0 | accuracy: 0.16 | loss: 0.12
step: 158797 | worker_4@n_step_9: average total_reward after train data exhaustion : 12.3 | max total_reward: 133.1
update:1985/2000, 耗时:0.00分/7.48分 | step: 158800 | performance: 1.1 | accuracy: 0.16 | loss: 0.05
step: 158959 | worker_6@n_step_9: average total_reward after train data exhaustion : 12.3 | max total_reward: 133.1
update:1990/2000, 耗时:0.00分/7.50分 | step: 159200 | performance: 1.0 | accuracy: 0.16 | loss: 0.10
step: 159514 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 133.1
update:1995/2000, 耗时:0.00分/7.52分 | step: 159600 | performance: 1.0 | accuracy: 0.15 | loss: 0.10
update:2000/2000, 耗时:0.00分/7.54分 | step: 160000 | performance: 1.2 | accuracy: 0.14 | loss: 0.31
----------------------------------------finished----------------------------------------
  0%|          | 0/401 [00:00<?, ?it/s]==================================================
2023-01-05T12:00:00 | *** START BACKTEST ***
2023-01-05T12:00:00 | current balance = 1000.00
==================================================
100%|| 401/401 [00:00<00:00, 57346.51it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1174.40
2023-07-24T12:00:00 | net performance [%] = 17.4400
2023-07-24T12:00:00 | number of trades [#] = 22
==================================================
Trial 13 Complete [00h 07m 58s]
net_wealth: 1175.5757850984041

Best net_wealth So Far: 1714.485333603393
Total elapsed time: 01h 52m 32s

Search: Running Trial #14

Value             |Best Value So Far |Hyperparameter
1                 |6                 |horizon
730               |225               |lookback
False             |True              |MarketFactor
3                 |14                |lags
0.92              |0.85              |gamma
32                |32                |batch_size
1                 |64                |n_step
0.94              |0.8               |gae_lambda
5                 |2                 |gradient_clip_norm
5                 |3                 |epochs
0.0001            |0.001             |actor_lr
0.0005            |1e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4314.000000   4315.000000
mean      0.000441    20062.255222  ...   20122.295285  20118.633889
std       0.027818    16039.874230  ...   16077.162832  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7691.585083   7690.540039
50%       0.000642    11554.824463  ...   11724.320312  11715.610352
75%       0.011655    29873.081836  ...   29925.802734  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-27 23:55:55.076853: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-2023-07-27 23:55:55.076942: I tensorflow/2023-02c0232ritical ope-c7ore-0/p7-27 23:55:55l027at.for0276m97/3 7c:p2- 0I3:u_7f ea-ture5_guard52.:t57 52e.cc307nso:rfl65:ow142965/5]:c:55 .Trations:  AVX AVX2
T o enabIh is TensorFlot0enw binary issorfloole  re/platform/o7p6981: ttI imized wittehc nsohemnpu_featuroerfweA/low/core/co rpien latformot_hgPuI Deepa/platfor drm/.er cNeucope:cpu_1rati4f2ons]e/ Tcpu_feahait2,t0r2s023-07-2u rer23e _Teugnsub-are_grorFlow bduinaru0iy.cca:a14r22 isd.cc0]l: 14 oNlde22 73 23:-]7t -50277 w-27 TpTtio2r3himikhT s 2is z3eTe n:5sdens:o5T:555Lei5nsroorrFF:F 5ll5owowl.ow 0w ibti.tw5h ion0 :bn757a7r5eA7i4ybh thr5Pe appa r.yr o(14on:n8p0ai7 Ie 7s otrDeNptyi ris o6pt4i: mni0Ns) Imizedt ow us7zoerd ew iti ifalteth  Dh eetp oIoonewNhe/c  ecoompAnf:roie/Pe leIlt APtIr enslefla ouwnorfIDeep prianlg NNeleaursagstt wf.o 
Dorrme/eClopw /coNPkceUu rLal piun Nrestwi_eobft/rkper alratoarytuLlform/c (rofunrleeDpc _gtu_fuNieioatbrrwdenas.oa rcyct:1 i(n onorkw NN/ur)e Ltpoib4eD2Ncoreer/_plg] Nrary () to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow wit h thuuard.cc:142] This TensorFsoe neDNN) to ue approprsformalotne tchahtform/cpuew_ bie ffoeate-critiiatenlT chis Tensa rflolompiloyrolwicneowinFgl  isal oCgpero wPrU  CurePU instructions in performance-critical operations:  AVX a flagtioniAoVpXt inmssi:_ t szgbuiA2V
eTo enable tand with. on
herruAPIed.cti mcXc: oAa1D4e2ep nVs  irnXy ]i sThis i2
 NTensoe othuernF To er oplonpeablewr erfroati traolh mopnstimized with oneb,eN inaeArebuitworrkyP La lId  Tinbrary (DiensorFlow s oeep Nenwcieoptimiz-eDtcriNuN)h etd with oraltnihe approp ctoal oe m iAnPp e Nuseratoireoi attnworksIh:tthe feorll Deep  Libra AowViX e c AVX2
To enable them onpign rother   yC NPeur(oUon iompnstructioeerDpatns in peNilrefoiNrr )eorna tsa,l tfmlaNancogs.eet  usrebuild TensorFlow with the appropriate compi
-critical we oortler flags.
hpeieon sfrkol,  Lailbrtebiouwrariing CPU instructions in perlyf odnso:(o rman n eDNNc)eA tV-XT oe AVcrnXuse th2
TesorFlow with the appropriateo following CP enable U instriuctions in ttical operations:  AVX AVX2
To enab hem compiin opllter flagher operse.
rformance-critical operations:  AVX AVX2
To enable them ations, rebuild TensorFlow with the appropriate compiler flags.
in other operations, rebuild TensorFlow with the appropriate compiler flags.
e them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-27 23:55:55.688043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:55:55.697773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:55:55.699005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:55:55.703990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:55:55.713953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:55:55.724268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:55:55.726567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-27 23:55:55.733188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:    40 | performance: 1.0 | accuracy: 0.40 | loss: 0.53
update: 10/2000, 耗时:0.00分/0.04分 | step:    80 | performance: 1.0 | accuracy: 0.60 | loss: 0.43
update: 15/2000, 耗时:0.00分/0.05分 | step:   120 | performance: 1.0 | accuracy: 0.47 | loss: 0.24
update: 20/2000, 耗时:0.00分/0.06分 | step:   160 | performance: 0.9 | accuracy: 0.40 | loss: 0.31
update: 25/2000, 耗时:0.00分/0.07分 | step:   200 | performance: 0.9 | accuracy: 0.40 | loss: 0.65
update: 30/2000, 耗时:0.00分/0.08分 | step:   240 | performance: 0.9 | accuracy: 0.33 | loss: 0.46
update: 35/2000, 耗时:0.00分/0.09分 | step:   280 | performance: 0.9 | accuracy: 0.40 | loss: 0.33
update: 40/2000, 耗时:0.00分/0.10分 | step:   320 | performance: 0.9 | accuracy: 0.38 | loss: 0.37
update: 45/2000, 耗时:0.00分/0.11分 | step:   360 | performance: 0.9 | accuracy: 0.36 | loss: 0.47
update: 50/2000, 耗时:0.00分/0.12分 | step:   400 | performance: 0.9 | accuracy: 0.38 | loss: 0.19
update: 55/2000, 耗时:0.00分/0.13分 | step:   440 | performance: 0.9 | accuracy: 0.40 | loss: 0.04
update: 60/2000, 耗时:0.00分/0.15分 | step:   480 | performance: 0.9 | accuracy: 0.40 | loss: 0.44
update: 65/2000, 耗时:0.00分/0.16分 | step:   520 | performance: 0.9 | accuracy: 0.40 | loss: 0.42
update: 70/2000, 耗时:0.00分/0.17分 | step:   560 | performance: 0.9 | accuracy: 0.40 | loss: 0.46
update: 75/2000, 耗时:0.00分/0.18分 | step:   600 | performance: 0.9 | accuracy: 0.40 | loss: 0.45
update: 80/2000, 耗时:0.00分/0.19分 | step:   640 | performance: 0.9 | accuracy: 0.41 | loss: 0.44
update: 85/2000, 耗时:0.00分/0.21分 | step:   680 | performance: 0.9 | accuracy: 0.42 | loss: 0.23
update: 90/2000, 耗时:0.00分/0.22分 | step:   720 | performance: 0.9 | accuracy: 0.42 | loss: 0.64
update: 95/2000, 耗时:0.00分/0.23分 | step:   760 | performance: 0.9 | accuracy: 0.42 | loss: 0.24
update:100/2000, 耗时:0.00分/0.24分 | step:   800 | performance: 1.0 | accuracy: 0.43 | loss: 0.20
update:105/2000, 耗时:0.00分/0.25分 | step:   840 | performance: 0.9 | accuracy: 0.42 | loss: 0.37
update:110/2000, 耗时:0.00分/0.27分 | step:   880 | performance: 0.9 | accuracy: 0.43 | loss: 0.11
update:115/2000, 耗时:0.00分/0.28分 | step:   920 | performance: 0.9 | accuracy: 0.42 | loss: 0.36
update:120/2000, 耗时:0.00分/0.29分 | step:   960 | performance: 0.9 | accuracy: 0.41 | loss: 0.04
update:125/2000, 耗时:0.00分/0.30分 | step:  1000 | performance: 0.9 | accuracy: 0.39 | loss: 0.52
update:130/2000, 耗时:0.00分/0.32分 | step:  1040 | performance: 0.9 | accuracy: 0.39 | loss: 0.10
update:135/2000, 耗时:0.00分/0.33分 | step:  1080 | performance: 0.9 | accuracy: 0.38 | loss: 0.37
update:140/2000, 耗时:0.00分/0.34分 | step:  1120 | performance: 0.9 | accuracy: 0.39 | loss: -0.01
update:145/2000, 耗时:0.00分/0.35分 | step:  1160 | performance: 0.9 | accuracy: 0.38 | loss: 0.41
update:150/2000, 耗时:0.00分/0.37分 | step:  1200 | performance: 0.9 | accuracy: 0.38 | loss: 0.39
update:155/2000, 耗时:0.00分/0.38分 | step:  1240 | performance: 0.9 | accuracy: 0.38 | loss: 0.24
update:160/2000, 耗时:0.00分/0.39分 | step:  1280 | performance: 0.8 | accuracy: 0.38 | loss: 0.49
update:165/2000, 耗时:0.00分/0.40分 | step:  1320 | performance: 0.8 | accuracy: 0.38 | loss: 0.52
update:170/2000, 耗时:0.00分/0.42分 | step:  1360 | performance: 0.7 | accuracy: 0.37 | loss: 0.25
update:175/2000, 耗时:0.00分/0.43分 | step:  1400 | performance: 0.7 | accuracy: 0.38 | loss: 0.46
update:180/2000, 耗时:0.00分/0.44分 | step:  1440 | performance: 0.8 | accuracy: 0.38 | loss: 0.13
update:185/2000, 耗时:0.00分/0.45分 | step:  1480 | performance: 0.7 | accuracy: 0.38 | loss: 0.58
update:190/2000, 耗时:0.00分/0.47分 | step:  1520 | performance: 0.8 | accuracy: 0.38 | loss: 0.75
update:195/2000, 耗时:0.00分/0.48分 | step:  1560 | performance: 0.8 | accuracy: 0.38 | loss: 0.21
update:200/2000, 耗时:0.00分/0.49分 | step:  1600 | performance: 0.8 | accuracy: 0.38 | loss: 0.37
update:205/2000, 耗时:0.00分/0.50分 | step:  1640 | performance: 0.7 | accuracy: 0.39 | loss: 0.21
update:210/2000, 耗时:0.00分/0.52分 | step:  1680 | performance: 0.7 | accuracy: 0.39 | loss: 0.32
update:215/2000, 耗时:0.00分/0.53分 | step:  1720 | performance: 0.7 | accuracy: 0.38 | loss: 0.52
update:220/2000, 耗时:0.00分/0.54分 | step:  1760 | performance: 0.7 | accuracy: 0.38 | loss: 0.56
update:225/2000, 耗时:0.00分/0.55分 | step:  1800 | performance: 0.8 | accuracy: 0.39 | loss: 0.54
update:230/2000, 耗时:0.00分/0.57分 | step:  1840 | performance: 0.9 | accuracy: 0.40 | loss: 0.25
update:235/2000, 耗时:0.00分/0.58分 | step:  1880 | performance: 1.0 | accuracy: 0.40 | loss: 0.35
update:240/2000, 耗时:0.00分/0.59分 | step:  1920 | performance: 1.0 | accuracy: 0.40 | loss: 0.06
update:245/2000, 耗时:0.00分/0.60分 | step:  1960 | performance: 1.0 | accuracy: 0.39 | loss: 0.43
update:250/2000, 耗时:0.00分/0.61分 | step:  2000 | performance: 1.0 | accuracy: 0.39 | loss: 0.25
update:255/2000, 耗时:0.00分/0.63分 | step:  2040 | performance: 1.0 | accuracy: 0.39 | loss: 0.33
update:260/2000, 耗时:0.00分/0.64分 | step:  2080 | performance: 1.0 | accuracy: 0.40 | loss: 0.23
update:265/2000, 耗时:0.00分/0.65分 | step:  2120 | performance: 1.1 | accuracy: 0.40 | loss: 0.07
update:270/2000, 耗时:0.00分/0.66分 | step:  2160 | performance: 1.1 | accuracy: 0.40 | loss: 0.68
update:275/2000, 耗时:0.00分/0.67分 | step:  2200 | performance: 1.1 | accuracy: 0.40 | loss: 0.29
update:280/2000, 耗时:0.00分/0.68分 | step:  2240 | performance: 1.1 | accuracy: 0.40 | loss: 0.06
update:285/2000, 耗时:0.00分/0.70分 | step:  2280 | performance: 1.1 | accuracy: 0.40 | loss: 0.40
update:290/2000, 耗时:0.00分/0.71分 | step:  2320 | performance: 1.2 | accuracy: 0.40 | loss: 0.63
update:295/2000, 耗时:0.00分/0.72分 | step:  2360 | performance: 1.2 | accuracy: 0.41 | loss: 0.15
update:300/2000, 耗时:0.00分/0.73分 | step:  2400 | performance: 1.2 | accuracy: 0.41 | loss: 0.32
update:305/2000, 耗时:0.00分/0.74分 | step:  2440 | performance: 1.2 | accuracy: 0.41 | loss: 0.17
update:310/2000, 耗时:0.00分/0.75分 | step:  2480 | performance: 1.1 | accuracy: 0.42 | loss: 0.14
update:315/2000, 耗时:0.00分/0.77分 | step:  2520 | performance: 1.2 | accuracy: 0.43 | loss: -0.00
update:320/2000, 耗时:0.00分/0.78分 | step:  2560 | performance: 1.2 | accuracy: 0.42 | loss: 0.58
update:325/2000, 耗时:0.00分/0.79分 | step:  2600 | performance: 1.1 | accuracy: 0.42 | loss: 0.36
update:330/2000, 耗时:0.00分/0.80分 | step:  2640 | performance: 1.2 | accuracy: 0.42 | loss: 0.54
update:335/2000, 耗时:0.00分/0.81分 | step:  2680 | performance: 1.2 | accuracy: 0.42 | loss: 0.35
update:340/2000, 耗时:0.00分/0.82分 | step:  2720 | performance: 1.2 | accuracy: 0.42 | loss: 0.22
update:345/2000, 耗时:0.00分/0.84分 | step:  2760 | performance: 1.2 | accuracy: 0.42 | loss: 0.17
update:350/2000, 耗时:0.00分/0.85分 | step:  2800 | performance: 1.3 | accuracy: 0.43 | loss: 0.11
update:355/2000, 耗时:0.00分/0.86分 | step:  2840 | performance: 1.3 | accuracy: 0.43 | loss: 0.29
update:360/2000, 耗时:0.00分/0.87分 | step:  2880 | performance: 1.3 | accuracy: 0.43 | loss: 0.53
update:365/2000, 耗时:0.00分/0.88分 | step:  2920 | performance: 1.2 | accuracy: 0.43 | loss: -0.01
update:370/2000, 耗时:0.00分/0.90分 | step:  2960 | performance: 1.2 | accuracy: 0.43 | loss: 0.35
update:375/2000, 耗时:0.00分/0.91分 | step:  3000 | performance: 1.2 | accuracy: 0.43 | loss: 0.28
update:380/2000, 耗时:0.00分/0.92分 | step:  3040 | performance: 1.3 | accuracy: 0.43 | loss: 0.35
update:385/2000, 耗时:0.00分/0.93分 | step:  3080 | performance: 1.3 | accuracy: 0.43 | loss: 0.46
update:390/2000, 耗时:0.00分/0.95分 | step:  3120 | performance: 1.2 | accuracy: 0.44 | loss: 0.60
update:395/2000, 耗时:0.00分/0.96分 | step:  3160 | performance: 1.2 | accuracy: 0.44 | loss: 0.20
update:400/2000, 耗时:0.00分/0.97分 | step:  3200 | performance: 1.2 | accuracy: 0.43 | loss: 0.12
update:405/2000, 耗时:0.00分/0.98分 | step:  3240 | performance: 1.2 | accuracy: 0.43 | loss: 0.31
update:410/2000, 耗时:0.00分/0.99分 | step:  3280 | performance: 1.2 | accuracy: 0.43 | loss: 0.34
update:415/2000, 耗时:0.00分/1.01分 | step:  3320 | performance: 1.2 | accuracy: 0.43 | loss: 0.23
update:420/2000, 耗时:0.00分/1.02分 | step:  3360 | performance: 1.2 | accuracy: 0.43 | loss: 0.42
update:425/2000, 耗时:0.00分/1.03分 | step:  3400 | performance: 1.2 | accuracy: 0.43 | loss: 0.31
update:430/2000, 耗时:0.00分/1.04分 | step:  3440 | performance: 1.2 | accuracy: 0.43 | loss: 0.23
update:435/2000, 耗时:0.00分/1.05分 | step:  3480 | performance: 1.5 | accuracy: 0.43 | loss: 0.12
update:440/2000, 耗时:0.00分/1.07分 | step:  3520 | performance: 1.5 | accuracy: 0.43 | loss: 0.05
update:445/2000, 耗时:0.00分/1.08分 | step:  3560 | performance: 1.4 | accuracy: 0.43 | loss: 0.11
update:450/2000, 耗时:0.00分/1.09分 | step:  3600 | performance: 1.3 | accuracy: 0.43 | loss: 0.48
update:455/2000, 耗时:0.00分/1.10分 | step:  3640 | performance: 1.3 | accuracy: 0.43 | loss: -0.00
update:460/2000, 耗时:0.00分/1.11分 | step:  3680 | performance: 1.3 | accuracy: 0.43 | loss: 0.51
update:465/2000, 耗时:0.00分/1.12分 | step:  3720 | performance: 1.3 | accuracy: 0.43 | loss: 0.33
update:470/2000, 耗时:0.00分/1.13分 | step:  3760 | performance: 1.3 | accuracy: 0.42 | loss: 0.28
update:475/2000, 耗时:0.00分/1.15分 | step:  3800 | performance: 1.3 | accuracy: 0.43 | loss: 0.29
update:480/2000, 耗时:0.00分/1.16分 | step:  3840 | performance: 1.3 | accuracy: 0.42 | loss: 0.11
update:485/2000, 耗时:0.00分/1.17分 | step:  3880 | performance: 1.3 | accuracy: 0.42 | loss: 0.32
update:490/2000, 耗时:0.00分/1.18分 | step:  3920 | performance: 1.3 | accuracy: 0.42 | loss: 0.42
update:495/2000, 耗时:0.00分/1.19分 | step:  3960 | performance: 1.3 | accuracy: 0.42 | loss: 0.30
update:500/2000, 耗时:0.00分/1.20分 | step:  4000 | performance: 1.4 | accuracy: 0.42 | loss: 0.45
update:505/2000, 耗时:0.00分/1.21分 | step:  4040 | performance: 1.4 | accuracy: 0.42 | loss: 0.40
update:510/2000, 耗时:0.00分/1.23分 | step:  4080 | performance: 1.4 | accuracy: 0.42 | loss: 0.19
update:515/2000, 耗时:0.00分/1.24分 | step:  4120 | performance: 1.6 | accuracy: 0.42 | loss: 0.65
update:520/2000, 耗时:0.00分/1.25分 | step:  4160 | performance: 1.8 | accuracy: 0.42 | loss: 0.04
update:525/2000, 耗时:0.00分/1.26分 | step:  4200 | performance: 1.7 | accuracy: 0.42 | loss: 0.00
update:530/2000, 耗时:0.00分/1.27分 | step:  4240 | performance: 1.7 | accuracy: 0.42 | loss: 0.19
update:535/2000, 耗时:0.00分/1.29分 | step:  4280 | performance: 1.7 | accuracy: 0.42 | loss: -0.00
update:540/2000, 耗时:0.00分/1.30分 | step:  4320 | performance: 1.7 | accuracy: 0.42 | loss: 0.25
update:545/2000, 耗时:0.00分/1.31分 | step:  4360 | performance: 1.7 | accuracy: 0.42 | loss: 0.08
update:550/2000, 耗时:0.00分/1.32分 | step:  4400 | performance: 1.7 | accuracy: 0.41 | loss: 0.08
update:555/2000, 耗时:0.00分/1.33分 | step:  4440 | performance: 1.8 | accuracy: 0.41 | loss: -0.00
update:560/2000, 耗时:0.00分/1.34分 | step:  4480 | performance: 1.7 | accuracy: 0.41 | loss: 0.01
update:565/2000, 耗时:0.00分/1.36分 | step:  4520 | performance: 1.7 | accuracy: 0.41 | loss: 0.22
update:570/2000, 耗时:0.00分/1.37分 | step:  4560 | performance: 1.7 | accuracy: 0.41 | loss: 0.34
update:575/2000, 耗时:0.00分/1.38分 | step:  4600 | performance: 1.7 | accuracy: 0.41 | loss: 0.18
update:580/2000, 耗时:0.00分/1.39分 | step:  4640 | performance: 1.7 | accuracy: 0.40 | loss: 0.21
update:585/2000, 耗时:0.00分/1.40分 | step:  4680 | performance: 1.9 | accuracy: 0.40 | loss: 0.15
update:590/2000, 耗时:0.00分/1.41分 | step:  4720 | performance: 1.8 | accuracy: 0.40 | loss: 0.24
update:595/2000, 耗时:0.00分/1.42分 | step:  4760 | performance: 1.9 | accuracy: 0.40 | loss: 0.06
update:600/2000, 耗时:0.00分/1.44分 | step:  4800 | performance: 1.9 | accuracy: 0.40 | loss: 0.04
update:605/2000, 耗时:0.00分/1.45分 | step:  4840 | performance: 1.8 | accuracy: 0.40 | loss: 0.20
update:610/2000, 耗时:0.00分/1.46分 | step:  4880 | performance: 1.9 | accuracy: 0.40 | loss: 0.02
update:615/2000, 耗时:0.00分/1.47分 | step:  4920 | performance: 1.9 | accuracy: 0.39 | loss: 0.39
update:620/2000, 耗时:0.00分/1.48分 | step:  4960 | performance: 1.7 | accuracy: 0.39 | loss: 0.44
update:625/2000, 耗时:0.00分/1.49分 | step:  5000 | performance: 1.7 | accuracy: 0.39 | loss: 0.16
update:630/2000, 耗时:0.00分/1.50分 | step:  5040 | performance: 1.7 | accuracy: 0.39 | loss: 0.07
update:635/2000, 耗时:0.00分/1.52分 | step:  5080 | performance: 1.9 | accuracy: 0.39 | loss: 0.28
update:640/2000, 耗时:0.00分/1.53分 | step:  5120 | performance: 1.8 | accuracy: 0.38 | loss: 0.82
update:645/2000, 耗时:0.00分/1.54分 | step:  5160 | performance: 1.8 | accuracy: 0.38 | loss: -0.00
update:650/2000, 耗时:0.00分/1.55分 | step:  5200 | performance: 1.7 | accuracy: 0.38 | loss: 0.74
update:655/2000, 耗时:0.00分/1.56分 | step:  5240 | performance: 1.7 | accuracy: 0.38 | loss: 0.25
update:660/2000, 耗时:0.00分/1.57分 | step:  5280 | performance: 1.7 | accuracy: 0.38 | loss: 0.21
update:665/2000, 耗时:0.00分/1.58分 | step:  5320 | performance: 1.7 | accuracy: 0.38 | loss: 0.20
update:670/2000, 耗时:0.00分/1.60分 | step:  5360 | performance: 1.7 | accuracy: 0.38 | loss: 0.12
update:675/2000, 耗时:0.00分/1.61分 | step:  5400 | performance: 1.8 | accuracy: 0.38 | loss: 0.32
update:680/2000, 耗时:0.00分/1.62分 | step:  5440 | performance: 1.7 | accuracy: 0.38 | loss: 0.42
update:685/2000, 耗时:0.00分/1.63分 | step:  5480 | performance: 1.8 | accuracy: 0.38 | loss: 0.04
update:690/2000, 耗时:0.00分/1.64分 | step:  5520 | performance: 1.8 | accuracy: 0.38 | loss: 0.04
update:695/2000, 耗时:0.00分/1.65分 | step:  5560 | performance: 1.7 | accuracy: 0.37 | loss: -0.00
update:700/2000, 耗时:0.00分/1.66分 | step:  5600 | performance: 1.7 | accuracy: 0.37 | loss: 0.39
update:705/2000, 耗时:0.00分/1.67分 | step:  5640 | performance: 1.6 | accuracy: 0.37 | loss: 0.05
update:710/2000, 耗时:0.00分/1.68分 | step:  5680 | performance: 1.6 | accuracy: 0.37 | loss: 0.26
update:715/2000, 耗时:0.00分/1.70分 | step:  5720 | performance: 1.6 | accuracy: 0.37 | loss: 0.11
update:720/2000, 耗时:0.00分/1.71分 | step:  5760 | performance: 1.6 | accuracy: 0.37 | loss: 0.21
update:725/2000, 耗时:0.00分/1.72分 | step:  5800 | performance: 1.5 | accuracy: 0.36 | loss: -0.00
update:730/2000, 耗时:0.00分/1.73分 | step:  5840 | performance: 1.5 | accuracy: 0.36 | loss: 0.14
update:735/2000, 耗时:0.00分/1.74分 | step:  5880 | performance: 1.5 | accuracy: 0.36 | loss: 0.03
update:740/2000, 耗时:0.00分/1.75分 | step:  5920 | performance: 1.6 | accuracy: 0.36 | loss: 0.35
update:745/2000, 耗时:0.00分/1.76分 | step:  5960 | performance: 1.6 | accuracy: 0.36 | loss: 0.05
update:750/2000, 耗时:0.00分/1.77分 | step:  6000 | performance: 1.5 | accuracy: 0.36 | loss: -0.00
update:755/2000, 耗时:0.00分/1.78分 | step:  6040 | performance: 1.5 | accuracy: 0.36 | loss: -0.00
update:760/2000, 耗时:0.00分/1.79分 | step:  6080 | performance: 1.5 | accuracy: 0.36 | loss: 0.08
update:765/2000, 耗时:0.00分/1.81分 | step:  6120 | performance: 1.5 | accuracy: 0.36 | loss: 0.08
update:770/2000, 耗时:0.00分/1.82分 | step:  6160 | performance: 1.5 | accuracy: 0.36 | loss: 0.27
update:775/2000, 耗时:0.00分/1.83分 | step:  6200 | performance: 1.5 | accuracy: 0.36 | loss: 0.26
update:780/2000, 耗时:0.00分/1.84分 | step:  6240 | performance: 1.5 | accuracy: 0.36 | loss: 0.28
update:785/2000, 耗时:0.00分/1.85分 | step:  6280 | performance: 1.3 | accuracy: 0.36 | loss: 0.40
update:790/2000, 耗时:0.00分/1.86分 | step:  6320 | performance: 1.3 | accuracy: 0.36 | loss: 0.17
update:795/2000, 耗时:0.00分/1.87分 | step:  6360 | performance: 1.3 | accuracy: 0.36 | loss: 0.16
update:800/2000, 耗时:0.00分/1.89分 | step:  6400 | performance: 1.3 | accuracy: 0.36 | loss: 0.41
update:805/2000, 耗时:0.00分/1.90分 | step:  6440 | performance: 1.3 | accuracy: 0.36 | loss: 0.06
update:810/2000, 耗时:0.00分/1.91分 | step:  6480 | performance: 1.2 | accuracy: 0.36 | loss: 0.32
update:815/2000, 耗时:0.00分/1.92分 | step:  6520 | performance: 1.2 | accuracy: 0.36 | loss: 0.37
update:820/2000, 耗时:0.00分/1.93分 | step:  6560 | performance: 1.2 | accuracy: 0.36 | loss: 0.18
update:825/2000, 耗时:0.00分/1.94分 | step:  6600 | performance: 1.2 | accuracy: 0.36 | loss: 0.13
update:830/2000, 耗时:0.00分/1.95分 | step:  6640 | performance: 1.2 | accuracy: 0.36 | loss: 0.26
update:835/2000, 耗时:0.00分/1.96分 | step:  6680 | performance: 1.2 | accuracy: 0.36 | loss: 0.22
update:840/2000, 耗时:0.00分/1.98分 | step:  6720 | performance: 1.2 | accuracy: 0.36 | loss: 0.33
update:845/2000, 耗时:0.00分/1.99分 | step:  6760 | performance: 1.0 | accuracy: 0.36 | loss: 0.40
update:850/2000, 耗时:0.00分/2.00分 | step:  6800 | performance: 1.3 | accuracy: 0.36 | loss: 0.10
update:855/2000, 耗时:0.00分/2.01分 | step:  6840 | performance: 1.3 | accuracy: 0.36 | loss: 0.26
update:860/2000, 耗时:0.00分/2.02分 | step:  6880 | performance: 1.3 | accuracy: 0.36 | loss: 0.18
update:865/2000, 耗时:0.00分/2.03分 | step:  6920 | performance: 1.3 | accuracy: 0.35 | loss: 0.13
update:870/2000, 耗时:0.00分/2.04分 | step:  6960 | performance: 1.3 | accuracy: 0.35 | loss: 0.19
update:875/2000, 耗时:0.00分/2.05分 | step:  7000 | performance: 1.3 | accuracy: 0.35 | loss: 0.07
update:880/2000, 耗时:0.00分/2.07分 | step:  7040 | performance: 1.2 | accuracy: 0.35 | loss: 0.47
update:885/2000, 耗时:0.00分/2.08分 | step:  7080 | performance: 1.2 | accuracy: 0.35 | loss: 0.25
update:890/2000, 耗时:0.00分/2.09分 | step:  7120 | performance: 1.2 | accuracy: 0.35 | loss: 0.15
update:895/2000, 耗时:0.00分/2.10分 | step:  7160 | performance: 1.2 | accuracy: 0.35 | loss: 0.41
update:900/2000, 耗时:0.00分/2.11分 | step:  7200 | performance: 1.2 | accuracy: 0.35 | loss: 0.50
update:905/2000, 耗时:0.00分/2.12分 | step:  7240 | performance: 1.1 | accuracy: 0.35 | loss: 0.00
update:910/2000, 耗时:0.00分/2.14分 | step:  7280 | performance: 1.1 | accuracy: 0.35 | loss: 0.12
update:915/2000, 耗时:0.00分/2.15分 | step:  7320 | performance: 1.0 | accuracy: 0.35 | loss: 0.04
update:920/2000, 耗时:0.00分/2.16分 | step:  7360 | performance: 1.0 | accuracy: 0.34 | loss: 0.24
update:925/2000, 耗时:0.00分/2.17分 | step:  7400 | performance: 1.0 | accuracy: 0.34 | loss: 0.32
update:930/2000, 耗时:0.00分/2.18分 | step:  7440 | performance: 1.0 | accuracy: 0.35 | loss: 0.15
update:935/2000, 耗时:0.00分/2.19分 | step:  7480 | performance: 1.0 | accuracy: 0.35 | loss: 0.30
update:940/2000, 耗时:0.00分/2.20分 | step:  7520 | performance: 1.0 | accuracy: 0.35 | loss: 0.22
update:945/2000, 耗时:0.00分/2.21分 | step:  7560 | performance: 1.0 | accuracy: 0.34 | loss: 0.30
update:950/2000, 耗时:0.00分/2.22分 | step:  7600 | performance: 1.0 | accuracy: 0.34 | loss: 0.08
update:955/2000, 耗时:0.00分/2.23分 | step:  7640 | performance: 1.1 | accuracy: 0.34 | loss: 0.93
update:960/2000, 耗时:0.00分/2.25分 | step:  7680 | performance: 1.1 | accuracy: 0.34 | loss: 0.47
update:965/2000, 耗时:0.00分/2.26分 | step:  7720 | performance: 1.1 | accuracy: 0.35 | loss: 0.10
update:970/2000, 耗时:0.00分/2.27分 | step:  7760 | performance: 1.1 | accuracy: 0.35 | loss: 0.24
update:975/2000, 耗时:0.00分/2.28分 | step:  7800 | performance: 1.1 | accuracy: 0.35 | loss: 0.20
update:980/2000, 耗时:0.00分/2.29分 | step:  7840 | performance: 1.1 | accuracy: 0.35 | loss: 0.08
update:985/2000, 耗时:0.00分/2.30分 | step:  7880 | performance: 1.1 | accuracy: 0.35 | loss: 0.35
update:990/2000, 耗时:0.00分/2.31分 | step:  7920 | performance: 1.1 | accuracy: 0.35 | loss: 0.41
update:995/2000, 耗时:0.00分/2.33分 | step:  7960 | performance: 1.1 | accuracy: 0.35 | loss: 0.48
update:1000/2000, 耗时:0.00分/2.34分 | step:  8000 | performance: 1.1 | accuracy: 0.35 | loss: 0.05
update:1005/2000, 耗时:0.00分/2.35分 | step:  8040 | performance: 1.1 | accuracy: 0.35 | loss: 0.05
update:1010/2000, 耗时:0.00分/2.36分 | step:  8080 | performance: 1.2 | accuracy: 0.35 | loss: 0.08
update:1015/2000, 耗时:0.00分/2.37分 | step:  8120 | performance: 1.2 | accuracy: 0.35 | loss: 0.33
update:1020/2000, 耗时:0.00分/2.38分 | step:  8160 | performance: 1.2 | accuracy: 0.35 | loss: 0.40
update:1025/2000, 耗时:0.00分/2.40分 | step:  8200 | performance: 1.2 | accuracy: 0.35 | loss: 0.20
update:1030/2000, 耗时:0.00分/2.41分 | step:  8240 | performance: 1.2 | accuracy: 0.35 | loss: 0.40
update:1035/2000, 耗时:0.00分/2.42分 | step:  8280 | performance: 1.1 | accuracy: 0.35 | loss: 0.42
update:1040/2000, 耗时:0.00分/2.43分 | step:  8320 | performance: 1.1 | accuracy: 0.35 | loss: 0.16
update:1045/2000, 耗时:0.00分/2.44分 | step:  8360 | performance: 1.1 | accuracy: 0.35 | loss: -0.01
update:1050/2000, 耗时:0.00分/2.45分 | step:  8400 | performance: 1.1 | accuracy: 0.34 | loss: 0.19
update:1055/2000, 耗时:0.00分/2.46分 | step:  8440 | performance: 1.1 | accuracy: 0.34 | loss: 0.25
update:1060/2000, 耗时:0.00分/2.47分 | step:  8480 | performance: 1.1 | accuracy: 0.34 | loss: 0.16
update:1065/2000, 耗时:0.00分/2.49分 | step:  8520 | performance: 1.1 | accuracy: 0.34 | loss: 0.09
update:1070/2000, 耗时:0.00分/2.50分 | step:  8560 | performance: 1.1 | accuracy: 0.34 | loss: 0.29
update:1075/2000, 耗时:0.00分/2.51分 | step:  8600 | performance: 1.1 | accuracy: 0.34 | loss: 0.10
update:1080/2000, 耗时:0.00分/2.52分 | step:  8640 | performance: 1.1 | accuracy: 0.34 | loss: 0.26
update:1085/2000, 耗时:0.00分/2.53分 | step:  8680 | performance: 1.1 | accuracy: 0.34 | loss: 0.18
update:1090/2000, 耗时:0.00分/2.54分 | step:  8720 | performance: 1.1 | accuracy: 0.34 | loss: 0.15
update:1095/2000, 耗时:0.00分/2.55分 | step:  8760 | performance: 1.1 | accuracy: 0.34 | loss: 0.32
update:1100/2000, 耗时:0.00分/2.56分 | step:  8800 | performance: 1.1 | accuracy: 0.34 | loss: 0.18
update:1105/2000, 耗时:0.00分/2.57分 | step:  8840 | performance: 1.1 | accuracy: 0.34 | loss: 0.39
update:1110/2000, 耗时:0.00分/2.59分 | step:  8880 | performance: 1.1 | accuracy: 0.34 | loss: 0.48
update:1115/2000, 耗时:0.00分/2.60分 | step:  8920 | performance: 1.1 | accuracy: 0.34 | loss: 0.14
update:1120/2000, 耗时:0.00分/2.61分 | step:  8960 | performance: 1.0 | accuracy: 0.33 | loss: 0.00
update:1125/2000, 耗时:0.00分/2.62分 | step:  9000 | performance: 1.3 | accuracy: 0.34 | loss: 0.00
update:1130/2000, 耗时:0.00分/2.63分 | step:  9040 | performance: 1.5 | accuracy: 0.34 | loss: 0.36
update:1135/2000, 耗时:0.00分/2.64分 | step:  9080 | performance: 1.6 | accuracy: 0.34 | loss: 0.05
update:1140/2000, 耗时:0.00分/2.65分 | step:  9120 | performance: 1.4 | accuracy: 0.34 | loss: 0.59
update:1145/2000, 耗时:0.00分/2.66分 | step:  9160 | performance: 1.7 | accuracy: 0.34 | loss: 0.40
update:1150/2000, 耗时:0.00分/2.67分 | step:  9200 | performance: 1.8 | accuracy: 0.34 | loss: 1.06
update:1155/2000, 耗时:0.00分/2.69分 | step:  9240 | performance: 1.7 | accuracy: 0.34 | loss: 0.39
update:1160/2000, 耗时:0.00分/2.70分 | step:  9280 | performance: 1.7 | accuracy: 0.34 | loss: 0.91
update:1165/2000, 耗时:0.00分/2.71分 | step:  9320 | performance: 1.9 | accuracy: 0.34 | loss: 0.58
update:1170/2000, 耗时:0.00分/2.72分 | step:  9360 | performance: 1.9 | accuracy: 0.34 | loss: 0.13
update:1175/2000, 耗时:0.00分/2.73分 | step:  9400 | performance: 2.1 | accuracy: 0.34 | loss: 0.50
update:1180/2000, 耗时:0.00分/2.74分 | step:  9440 | performance: 2.1 | accuracy: 0.34 | loss: 0.15
update:1185/2000, 耗时:0.00分/2.76分 | step:  9480 | performance: 2.0 | accuracy: 0.34 | loss: 0.16
update:1190/2000, 耗时:0.00分/2.77分 | step:  9520 | performance: 2.0 | accuracy: 0.34 | loss: 0.34
update:1195/2000, 耗时:0.00分/2.78分 | step:  9560 | performance: 2.1 | accuracy: 0.34 | loss: 0.33
update:1200/2000, 耗时:0.00分/2.79分 | step:  9600 | performance: 2.1 | accuracy: 0.34 | loss: 0.46
update:1205/2000, 耗时:0.00分/2.80分 | step:  9640 | performance: 2.0 | accuracy: 0.34 | loss: 0.31
update:1210/2000, 耗时:0.00分/2.81分 | step:  9680 | performance: 2.2 | accuracy: 0.34 | loss: 0.20
update:1215/2000, 耗时:0.00分/2.82分 | step:  9720 | performance: 2.2 | accuracy: 0.34 | loss: 0.14
update:1220/2000, 耗时:0.00分/2.84分 | step:  9760 | performance: 2.3 | accuracy: 0.34 | loss: 0.63
update:1225/2000, 耗时:0.00分/2.85分 | step:  9800 | performance: 2.6 | accuracy: 0.34 | loss: 1.32
update:1230/2000, 耗时:0.00分/2.86分 | step:  9840 | performance: 2.5 | accuracy: 0.35 | loss: 0.74
update:1235/2000, 耗时:0.00分/2.87分 | step:  9880 | performance: 2.6 | accuracy: 0.34 | loss: 0.28
update:1240/2000, 耗时:0.00分/2.88分 | step:  9920 | performance: 2.7 | accuracy: 0.34 | loss: 3.22
update:1245/2000, 耗时:0.00分/2.89分 | step:  9960 | performance: 2.5 | accuracy: 0.34 | loss: 0.08
update:1250/2000, 耗时:0.00分/2.91分 | step: 10000 | performance: 2.5 | accuracy: 0.34 | loss: 0.33
update:1255/2000, 耗时:0.00分/2.92分 | step: 10040 | performance: 2.5 | accuracy: 0.34 | loss: 0.13
update:1260/2000, 耗时:0.00分/2.93分 | step: 10080 | performance: 2.5 | accuracy: 0.34 | loss: 0.37
update:1265/2000, 耗时:0.00分/2.94分 | step: 10120 | performance: 2.5 | accuracy: 0.34 | loss: 0.27
update:1270/2000, 耗时:0.00分/2.95分 | step: 10160 | performance: 2.5 | accuracy: 0.34 | loss: 0.27
update:1275/2000, 耗时:0.00分/2.96分 | step: 10200 | performance: 2.5 | accuracy: 0.34 | loss: 0.17
update:1280/2000, 耗时:0.00分/2.97分 | step: 10240 | performance: 2.5 | accuracy: 0.34 | loss: 0.41
update:1285/2000, 耗时:0.00分/2.98分 | step: 10280 | performance: 2.5 | accuracy: 0.34 | loss: 0.12
update:1290/2000, 耗时:0.00分/3.00分 | step: 10320 | performance: 2.5 | accuracy: 0.34 | loss: -0.00
update:1295/2000, 耗时:0.00分/3.01分 | step: 10360 | performance: 2.5 | accuracy: 0.34 | loss: 0.13
update:1300/2000, 耗时:0.00分/3.02分 | step: 10400 | performance: 2.5 | accuracy: 0.34 | loss: 0.17
update:1305/2000, 耗时:0.00分/3.03分 | step: 10440 | performance: 2.5 | accuracy: 0.34 | loss: 0.13
update:1310/2000, 耗时:0.00分/3.04分 | step: 10480 | performance: 2.6 | accuracy: 0.34 | loss: -0.00
update:1315/2000, 耗时:0.00分/3.05分 | step: 10520 | performance: 2.5 | accuracy: 0.34 | loss: 0.12
update:1320/2000, 耗时:0.00分/3.06分 | step: 10560 | performance: 2.5 | accuracy: 0.34 | loss: 0.24
update:1325/2000, 耗时:0.00分/3.08分 | step: 10600 | performance: 2.5 | accuracy: 0.34 | loss: 0.16
update:1330/2000, 耗时:0.00分/3.09分 | step: 10640 | performance: 2.6 | accuracy: 0.34 | loss: 0.14
update:1335/2000, 耗时:0.00分/3.10分 | step: 10680 | performance: 2.6 | accuracy: 0.34 | loss: 0.34
update:1340/2000, 耗时:0.00分/3.11分 | step: 10720 | performance: 2.6 | accuracy: 0.34 | loss: 0.08
update:1345/2000, 耗时:0.00分/3.12分 | step: 10760 | performance: 2.6 | accuracy: 0.34 | loss: 0.05
update:1350/2000, 耗时:0.00分/3.13分 | step: 10800 | performance: 2.6 | accuracy: 0.34 | loss: 0.13
update:1355/2000, 耗时:0.00分/3.14分 | step: 10840 | performance: 2.6 | accuracy: 0.34 | loss: 0.10
update:1360/2000, 耗时:0.00分/3.16分 | step: 10880 | performance: 2.7 | accuracy: 0.34 | loss: 0.19
update:1365/2000, 耗时:0.00分/3.17分 | step: 10920 | performance: 2.7 | accuracy: 0.34 | loss: 0.29
update:1370/2000, 耗时:0.00分/3.18分 | step: 10960 | performance: 2.7 | accuracy: 0.34 | loss: 0.22
update:1375/2000, 耗时:0.00分/3.19分 | step: 11000 | performance: 2.7 | accuracy: 0.34 | loss: 0.13
update:1380/2000, 耗时:0.00分/3.20分 | step: 11040 | performance: 2.7 | accuracy: 0.34 | loss: 0.13
update:1385/2000, 耗时:0.00分/3.21分 | step: 11080 | performance: 2.6 | accuracy: 0.34 | loss: 0.09
update:1390/2000, 耗时:0.00分/3.22分 | step: 11120 | performance: 2.7 | accuracy: 0.34 | loss: 0.36
update:1395/2000, 耗时:0.00分/3.24分 | step: 11160 | performance: 2.7 | accuracy: 0.34 | loss: 0.21
update:1400/2000, 耗时:0.00分/3.25分 | step: 11200 | performance: 2.9 | accuracy: 0.34 | loss: 0.02
update:1405/2000, 耗时:0.00分/3.26分 | step: 11240 | performance: 3.0 | accuracy: 0.34 | loss: 0.22
update:1410/2000, 耗时:0.00分/3.27分 | step: 11280 | performance: 3.1 | accuracy: 0.34 | loss: 0.12
update:1415/2000, 耗时:0.00分/3.28分 | step: 11320 | performance: 3.1 | accuracy: 0.34 | loss: 0.12
update:1420/2000, 耗时:0.00分/3.29分 | step: 11360 | performance: 3.1 | accuracy: 0.34 | loss: 0.07
update:1425/2000, 耗时:0.00分/3.30分 | step: 11400 | performance: 3.1 | accuracy: 0.34 | loss: 0.19
update:1430/2000, 耗时:0.00分/3.31分 | step: 11440 | performance: 3.1 | accuracy: 0.34 | loss: 0.05
update:1435/2000, 耗时:0.00分/3.33分 | step: 11480 | performance: 3.1 | accuracy: 0.34 | loss: 0.31
update:1440/2000, 耗时:0.00分/3.34分 | step: 11520 | performance: 3.1 | accuracy: 0.34 | loss: 0.16
update:1445/2000, 耗时:0.00分/3.35分 | step: 11560 | performance: 3.1 | accuracy: 0.33 | loss: 0.05
update:1450/2000, 耗时:0.00分/3.36分 | step: 11600 | performance: 3.1 | accuracy: 0.33 | loss: 0.05
update:1455/2000, 耗时:0.00分/3.37分 | step: 11640 | performance: 3.1 | accuracy: 0.33 | loss: -0.00
update:1460/2000, 耗时:0.00分/3.38分 | step: 11680 | performance: 3.1 | accuracy: 0.33 | loss: -0.00
update:1465/2000, 耗时:0.00分/3.39分 | step: 11720 | performance: 3.1 | accuracy: 0.33 | loss: 0.11
update:1470/2000, 耗时:0.00分/3.40分 | step: 11760 | performance: 3.1 | accuracy: 0.33 | loss: 0.23
update:1475/2000, 耗时:0.00分/3.42分 | step: 11800 | performance: 3.1 | accuracy: 0.33 | loss: -0.00
update:1480/2000, 耗时:0.00分/3.43分 | step: 11840 | performance: 3.1 | accuracy: 0.33 | loss: 0.13
update:1485/2000, 耗时:0.00分/3.44分 | step: 11880 | performance: 3.0 | accuracy: 0.33 | loss: 0.00
update:1490/2000, 耗时:0.00分/3.45分 | step: 11920 | performance: 3.1 | accuracy: 0.33 | loss: 0.07
update:1495/2000, 耗时:0.00分/3.46分 | step: 11960 | performance: 3.1 | accuracy: 0.33 | loss: 0.46
update:1500/2000, 耗时:0.00分/3.47分 | step: 12000 | performance: 3.1 | accuracy: 0.33 | loss: 0.12
update:1505/2000, 耗时:0.00分/3.48分 | step: 12040 | performance: 3.2 | accuracy: 0.33 | loss: 0.12
update:1510/2000, 耗时:0.00分/3.49分 | step: 12080 | performance: 3.1 | accuracy: 0.33 | loss: 0.22
update:1515/2000, 耗时:0.00分/3.51分 | step: 12120 | performance: 3.1 | accuracy: 0.33 | loss: 0.14
update:1520/2000, 耗时:0.00分/3.52分 | step: 12160 | performance: 3.2 | accuracy: 0.33 | loss: 0.12
update:1525/2000, 耗时:0.00分/3.53分 | step: 12200 | performance: 3.2 | accuracy: 0.33 | loss: 0.00
update:1530/2000, 耗时:0.00分/3.54分 | step: 12240 | performance: 3.3 | accuracy: 0.33 | loss: 0.08
update:1535/2000, 耗时:0.00分/3.55分 | step: 12280 | performance: 3.3 | accuracy: 0.33 | loss: 0.32
update:1540/2000, 耗时:0.00分/3.56分 | step: 12320 | performance: 3.3 | accuracy: 0.33 | loss: 0.48
update:1545/2000, 耗时:0.00分/3.58分 | step: 12360 | performance: 3.3 | accuracy: 0.33 | loss: 0.07
update:1550/2000, 耗时:0.00分/3.59分 | step: 12400 | performance: 3.4 | accuracy: 0.33 | loss: -0.00
update:1555/2000, 耗时:0.00分/3.60分 | step: 12440 | performance: 3.5 | accuracy: 0.33 | loss: 0.00
update:1560/2000, 耗时:0.00分/3.61分 | step: 12480 | performance: 3.4 | accuracy: 0.33 | loss: 0.17
update:1565/2000, 耗时:0.00分/3.62分 | step: 12520 | performance: 3.4 | accuracy: 0.33 | loss: 0.12
update:1570/2000, 耗时:0.00分/3.63分 | step: 12560 | performance: 3.6 | accuracy: 0.33 | loss: 0.20
update:1575/2000, 耗时:0.00分/3.64分 | step: 12600 | performance: 3.5 | accuracy: 0.33 | loss: 0.58
update:1580/2000, 耗时:0.00分/3.66分 | step: 12640 | performance: 3.6 | accuracy: 0.33 | loss: 0.05
update:1585/2000, 耗时:0.00分/3.67分 | step: 12680 | performance: 3.6 | accuracy: 0.33 | loss: 0.22
update:1590/2000, 耗时:0.00分/3.68分 | step: 12720 | performance: 3.6 | accuracy: 0.33 | loss: 0.15
update:1595/2000, 耗时:0.00分/3.69分 | step: 12760 | performance: 3.6 | accuracy: 0.33 | loss: -0.00
update:1600/2000, 耗时:0.00分/3.70分 | step: 12800 | performance: 3.7 | accuracy: 0.33 | loss: 0.11
update:1605/2000, 耗时:0.00分/3.71分 | step: 12840 | performance: 3.7 | accuracy: 0.32 | loss: 0.08
update:1610/2000, 耗时:0.00分/3.72分 | step: 12880 | performance: 3.7 | accuracy: 0.32 | loss: -0.00
update:1615/2000, 耗时:0.00分/3.74分 | step: 12920 | performance: 3.9 | accuracy: 0.32 | loss: 0.23
update:1620/2000, 耗时:0.00分/3.75分 | step: 12960 | performance: 3.7 | accuracy: 0.32 | loss: 0.36
update:1625/2000, 耗时:0.00分/3.76分 | step: 13000 | performance: 3.8 | accuracy: 0.32 | loss: -0.00
update:1630/2000, 耗时:0.00分/3.77分 | step: 13040 | performance: 3.8 | accuracy: 0.32 | loss: 0.00
update:1635/2000, 耗时:0.00分/3.78分 | step: 13080 | performance: 3.6 | accuracy: 0.32 | loss: 0.00
update:1640/2000, 耗时:0.00分/3.79分 | step: 13120 | performance: 3.8 | accuracy: 0.32 | loss: -0.00
update:1645/2000, 耗时:0.00分/3.80分 | step: 13160 | performance: 3.6 | accuracy: 0.32 | loss: 0.06
update:1650/2000, 耗时:0.00分/3.82分 | step: 13200 | performance: 3.7 | accuracy: 0.32 | loss: 0.10
update:1655/2000, 耗时:0.00分/3.83分 | step: 13240 | performance: 4.0 | accuracy: 0.32 | loss: -0.00
update:1660/2000, 耗时:0.00分/3.84分 | step: 13280 | performance: 4.0 | accuracy: 0.32 | loss: 0.06
update:1665/2000, 耗时:0.00分/3.85分 | step: 13320 | performance: 4.1 | accuracy: 0.32 | loss: -0.00
update:1670/2000, 耗时:0.00分/3.86分 | step: 13360 | performance: 4.0 | accuracy: 0.32 | loss: -0.00
update:1675/2000, 耗时:0.00分/3.87分 | step: 13400 | performance: 4.0 | accuracy: 0.32 | loss: 0.00
update:1680/2000, 耗时:0.00分/3.88分 | step: 13440 | performance: 4.0 | accuracy: 0.32 | loss: 0.00
update:1685/2000, 耗时:0.00分/3.89分 | step: 13480 | performance: 4.0 | accuracy: 0.32 | loss: 0.00
update:1690/2000, 耗时:0.00分/3.91分 | step: 13520 | performance: 4.0 | accuracy: 0.32 | loss: 0.44
update:1695/2000, 耗时:0.00分/3.92分 | step: 13560 | performance: 3.9 | accuracy: 0.32 | loss: 0.00
update:1700/2000, 耗时:0.00分/3.93分 | step: 13600 | performance: 4.0 | accuracy: 0.32 | loss: 0.41
update:1705/2000, 耗时:0.00分/3.94分 | step: 13640 | performance: 4.5 | accuracy: 0.32 | loss: 0.00
update:1710/2000, 耗时:0.00分/3.95分 | step: 13680 | performance: 4.7 | accuracy: 0.32 | loss: 0.15
update:1715/2000, 耗时:0.00分/3.96分 | step: 13720 | performance: 4.8 | accuracy: 0.32 | loss: 0.07
update:1720/2000, 耗时:0.00分/3.97分 | step: 13760 | performance: 5.5 | accuracy: 0.32 | loss: 0.18
update:1725/2000, 耗时:0.00分/3.98分 | step: 13800 | performance: 5.9 | accuracy: 0.32 | loss: 0.00
update:1730/2000, 耗时:0.00分/4.00分 | step: 13840 | performance: 6.3 | accuracy: 0.32 | loss: 0.08
update:1735/2000, 耗时:0.00分/4.01分 | step: 13880 | performance: 5.4 | accuracy: 0.32 | loss: 0.02
update:1740/2000, 耗时:0.00分/4.02分 | step: 13920 | performance: 6.1 | accuracy: 0.32 | loss: 0.36
update:1745/2000, 耗时:0.00分/4.03分 | step: 13960 | performance: 5.6 | accuracy: 0.32 | loss: 0.27
update:1750/2000, 耗时:0.00分/4.04分 | step: 14000 | performance: 5.7 | accuracy: 0.32 | loss: 0.08
update:1755/2000, 耗时:0.00分/4.05分 | step: 14040 | performance: 5.6 | accuracy: 0.32 | loss: 0.00
update:1760/2000, 耗时:0.00分/4.06分 | step: 14080 | performance: 5.9 | accuracy: 0.32 | loss: 0.00
update:1765/2000, 耗时:0.00分/4.08分 | step: 14120 | performance: 5.8 | accuracy: 0.32 | loss: 0.06
update:1770/2000, 耗时:0.00分/4.09分 | step: 14160 | performance: 5.7 | accuracy: 0.32 | loss: -0.00
update:1775/2000, 耗时:0.00分/4.10分 | step: 14200 | performance: 5.8 | accuracy: 0.32 | loss: 0.00
update:1780/2000, 耗时:0.00分/4.11分 | step: 14240 | performance: 6.0 | accuracy: 0.32 | loss: 0.00
update:1785/2000, 耗时:0.00分/4.12分 | step: 14280 | performance: 6.3 | accuracy: 0.32 | loss: 0.00
update:1790/2000, 耗时:0.00分/4.13分 | step: 14320 | performance: 6.3 | accuracy: 0.32 | loss: 0.00
update:1795/2000, 耗时:0.00分/4.15分 | step: 14360 | performance: 7.4 | accuracy: 0.32 | loss: -0.01
update:1800/2000, 耗时:0.00分/4.16分 | step: 14400 | performance: 7.4 | accuracy: 0.32 | loss: 1.10
update:1805/2000, 耗时:0.00分/4.17分 | step: 14440 | performance: 7.7 | accuracy: 0.32 | loss: 0.07
update:1810/2000, 耗时:0.00分/4.18分 | step: 14480 | performance: 7.8 | accuracy: 0.32 | loss: -0.00
update:1815/2000, 耗时:0.00分/4.19分 | step: 14520 | performance: 8.4 | accuracy: 0.32 | loss: 0.00
update:1820/2000, 耗时:0.00分/4.20分 | step: 14560 | performance: 7.3 | accuracy: 0.32 | loss: 1.91
update:1825/2000, 耗时:0.00分/4.22分 | step: 14600 | performance: 7.1 | accuracy: 0.32 | loss: 1.17
update:1830/2000, 耗时:0.00分/4.23分 | step: 14640 | performance: 7.1 | accuracy: 0.32 | loss: 0.00
update:1835/2000, 耗时:0.00分/4.24分 | step: 14680 | performance: 7.4 | accuracy: 0.32 | loss: 0.72
update:1840/2000, 耗时:0.00分/4.25分 | step: 14720 | performance: 7.5 | accuracy: 0.32 | loss: 0.00
update:1845/2000, 耗时:0.00分/4.26分 | step: 14760 | performance: 7.9 | accuracy: 0.32 | loss: -0.00
update:1850/2000, 耗时:0.00分/4.27分 | step: 14800 | performance: 8.2 | accuracy: 0.32 | loss: 0.03
update:1855/2000, 耗时:0.00分/4.29分 | step: 14840 | performance: 8.2 | accuracy: 0.32 | loss: -0.00
update:1860/2000, 耗时:0.00分/4.30分 | step: 14880 | performance: 8.0 | accuracy: 0.32 | loss: 1.35
update:1865/2000, 耗时:0.00分/4.31分 | step: 14920 | performance: 7.9 | accuracy: 0.32 | loss: 0.00
update:1870/2000, 耗时:0.00分/4.32分 | step: 14960 | performance: 7.8 | accuracy: 0.32 | loss: -0.00
update:1875/2000, 耗时:0.00分/4.33分 | step: 15000 | performance: 7.8 | accuracy: 0.32 | loss: 0.02
update:1880/2000, 耗时:0.00分/4.34分 | step: 15040 | performance: 7.8 | accuracy: 0.32 | loss: 0.00
update:1885/2000, 耗时:0.00分/4.36分 | step: 15080 | performance: 7.6 | accuracy: 0.32 | loss: 0.00
update:1890/2000, 耗时:0.00分/4.37分 | step: 15120 | performance: 7.9 | accuracy: 0.32 | loss: 0.00
update:1895/2000, 耗时:0.00分/4.38分 | step: 15160 | performance: 7.9 | accuracy: 0.32 | loss: -0.00
update:1900/2000, 耗时:0.00分/4.39分 | step: 15200 | performance: 7.7 | accuracy: 0.32 | loss: 0.02
update:1905/2000, 耗时:0.00分/4.40分 | step: 15240 | performance: 7.7 | accuracy: 0.32 | loss: 0.00
update:1910/2000, 耗时:0.00分/4.41分 | step: 15280 | performance: 7.5 | accuracy: 0.32 | loss: 0.06
update:1915/2000, 耗时:0.00分/4.42分 | step: 15320 | performance: 7.8 | accuracy: 0.32 | loss: 0.15
update:1920/2000, 耗时:0.00分/4.44分 | step: 15360 | performance: 7.8 | accuracy: 0.32 | loss: 0.01
update:1925/2000, 耗时:0.00分/4.45分 | step: 15400 | performance: 7.7 | accuracy: 0.32 | loss: 0.01
update:1930/2000, 耗时:0.00分/4.46分 | step: 15440 | performance: 6.9 | accuracy: 0.32 | loss: 0.28
update:1935/2000, 耗时:0.00分/4.47分 | step: 15480 | performance: 7.0 | accuracy: 0.32 | loss: 0.06
update:1940/2000, 耗时:0.00分/4.48分 | step: 15520 | performance: 7.3 | accuracy: 0.32 | loss: -0.00
update:1945/2000, 耗时:0.00分/4.49分 | step: 15560 | performance: 7.9 | accuracy: 0.32 | loss: 0.02
update:1950/2000, 耗时:0.00分/4.51分 | step: 15600 | performance: 7.9 | accuracy: 0.32 | loss: 0.03
update:1955/2000, 耗时:0.00分/4.52分 | step: 15640 | performance: 8.2 | accuracy: 0.32 | loss: 0.19
update:1960/2000, 耗时:0.00分/4.53分 | step: 15680 | performance: 8.2 | accuracy: 0.32 | loss: 0.00
update:1965/2000, 耗时:0.00分/4.54分 | step: 15720 | performance: 8.1 | accuracy: 0.32 | loss: 0.00
update:1970/2000, 耗时:0.00分/4.55分 | step: 15760 | performance: 8.2 | accuracy: 0.32 | loss: 0.06
update:1975/2000, 耗时:0.00分/4.56分 | step: 15800 | performance: 8.4 | accuracy: 0.32 | loss: 0.15
update:1980/2000, 耗时:0.00分/4.58分 | step: 15840 | performance: 8.4 | accuracy: 0.32 | loss: 0.01
update:1985/2000, 耗时:0.00分/4.59分 | step: 15880 | performance: 7.6 | accuracy: 0.32 | loss: 0.51
update:1990/2000, 耗时:0.00分/4.60分 | step: 15920 | performance: 6.8 | accuracy: 0.32 | loss: 0.00
update:1995/2000, 耗时:0.00分/4.61分 | step: 15960 | performance: 6.4 | accuracy: 0.32 | loss: 0.86
  0%|          | 0/408 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/4.62分 | step: 16000 | performance: 6.7 | accuracy: 0.32 | loss: 0.55
----------------------------------------finished----------------------------------------
==================================================
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
100%|| 408/408 [00:00<00:00, 102245.09it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1737.53
2023-07-24T12:00:00 | net performance [%] = 73.7525
2023-07-24T12:00:00 | number of trades [#] = 4
==================================================
Trial 14 Complete [00h 05m 03s]
net_wealth: 1739.2646221209268

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 01h 57m 35s

Search: Running Trial #15

Value             |Best Value So Far |Hyperparameter
7                 |1                 |horizon
225               |730               |lookback
False             |False             |MarketFactor
10                |3                 |lags
0.9               |0.92              |gamma
16                |32                |batch_size
3                 |1                 |n_step
0.94              |0.94              |gae_lambda
1                 |5                 |gradient_clip_norm
5                 |5                 |epochs
5e-05             |0.0001            |actor_lr
5e-05             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4308.000000   4315.000000
mean      0.000441    20062.255222  ...   20144.178930  20118.633889
std       0.027818    16039.874230  ...   16077.649782  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7710.492310   7690.540039
50%       0.000642    11554.824463  ...   11744.425293  11715.610352
75%       0.011655    29873.081836  ...   29961.684570  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 00:00:58.915859: I tensorflow/core/platform/cpu_fe2023-07-28 00:00:58.915900:2023-07-28 00:00:58.915918: I tensorflow/core/platform/cpu_feature_gature_guard.cc:142] T2hi0uard.cc22023-07-28 00:00:58.915994: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in pe :s TensorFl3o-w142] This TensorFlow  07-28 00binar:00:58Ir.yformance-crb is opti itnary mieis9n sozed w1optimith oneiiztical o5rflo2perations:  AV0w2857: I3/- 0tensc7oo-r228 00Xrefl /oAeAd20P2:w0023-0/ 0Ic7-o28 r3e 0/Deewpppl 0ith oVNXen2
:uaelAr0aatftf0::5l8.To9o5 8-0r7-Nem/.o91r6281t638m /cwp31090:u_0:o fe0rIa k:t5 tLiPensoI brfulowD e8/ecrerarn_.gcy (oeapb pNueo9r5la:1ural6 N etnw3o5rekI eL4/repd. ccDuN_fe:a lI Nti:b1rttate42 th)n urasorreyeftmon e_s ifnolo (wgu/oaorm/cop]trun echo_d.feateurDNN cTrh ioscpe:_r efru142] glusaT)eanreTthiiosw /to tdo.nccrsorFeh esl,:cT/e14ore fop2] T /p lunlse atatfotohrwfohre fsios  obllimrerbFlTneno/oasuoimcldp Te/w bcuri_rwnlslpinfnaeoya wtogrFureiiy n_srFgiluu aCrPUd ol ogw_wfienast b Ctsrinoau u PpUrocwrt pttioiymiin iss  iienonpziesdmtirz_ geuda  utchw.cwithttpimeir fc iiotrhto:oneAmahn1rPI Deenep zeNdcd oen4eAe-ur.a2 PI Dc]s wl ei n p TccheiithrN:14 oinetesrfoap2w]or tp icNTk LpreaAeim eanlruobPn TshpioIpr Dreorasereaprarcli aty tiNoe -e Fel tcwooTN(eurnroeonnsmaekwco pDiNlNL)r rteosi:ilF  l btNioAwr abriyn ceatlwor (V r af rbuislya iokneXg on aLriyb sispeeD A.r
aratsopt theimrionVy  fi (osozNNptiXlleo) to ud w:  A2
oTsno VmeieznaiXebeDle  tthhe   fAVowlilowNNn)d gw t itXiChno2 
PeUmoTgt uhs eo t n einCoPhee An folenab instrule lPctiotheroA owiPtIIn s h onigU n pDeep eDr CPU infiormance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flageep Neural Network Library nem in other operatios(oneDNN) to use the following pstCPU insructions in penrNefeormance-ctsrsrat, reburr.t
iouuuiral tNcntis, rebuionicild Tetios calie ltdnn Teospwe penosratio rk iorFnns pel:o wr Li nfswitoArormFblaorwn h thwaryicte aph e ptrformancVhe arppropriate coXe -cr(oiticalprian-toe A mecritioDNN)pcpc iaelV lroXotpo use the fomepelaratr2 floiilawiontg
Tos.
gn ions:ClPeU    sir : ensAfVtlragn aAX sble AtVX2uctions in performance-critical operations:  AVX AVX2
To enable .hV
em 
Xi AVX2Tothem in other operations, reb 
enable them innuild TTo enable them in  ote ontheostrhheorFlow  errw iop ooperthations, reb the appropriate ceuild Tenrations, rebuilpsooemd TerpFratlilioners, rebuild TensorFlow n flsorFlow with the appropriate comwopaw with tilith thehge aer flags.
 appropriate compiler flags.
s.
ppropriate compiler flags.
2023-07-28 00:00:59.537308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:00:59.557775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:00:59.562963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:00:59.569956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:00:59.572418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:00:59.572783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:00:59.576113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:00:59.590557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   120 | performance: 0.9 | accuracy: 0.27 | loss: 1.56
update: 10/2000, 耗时:0.00分/0.04分 | step:   240 | performance: 1.0 | accuracy: 0.27 | loss: 1.28
update: 15/2000, 耗时:0.00分/0.05分 | step:   360 | performance: 1.6 | accuracy: 0.33 | loss: 3.66
update: 20/2000, 耗时:0.00分/0.07分 | step:   480 | performance: 2.6 | accuracy: 0.32 | loss: 3.26
update: 25/2000, 耗时:0.00分/0.08分 | step:   600 | performance: 3.5 | accuracy: 0.32 | loss: 0.32
update: 30/2000, 耗时:0.00分/0.09分 | step:   720 | performance: 2.1 | accuracy: 0.31 | loss: 0.60
update: 35/2000, 耗时:0.00分/0.10分 | step:   840 | performance: 1.9 | accuracy: 0.28 | loss: 0.08
update: 40/2000, 耗时:0.00分/0.11分 | step:   960 | performance: 2.3 | accuracy: 0.27 | loss: 2.90
update: 45/2000, 耗时:0.00分/0.13分 | step:  1080 | performance: 3.1 | accuracy: 0.30 | loss: 0.82
update: 50/2000, 耗时:0.00分/0.14分 | step:  1200 | performance: 2.2 | accuracy: 0.29 | loss: 1.58
update: 55/2000, 耗时:0.00分/0.15分 | step:  1320 | performance: 2.7 | accuracy: 0.30 | loss: 1.05
update: 60/2000, 耗时:0.00分/0.16分 | step:  1440 | performance: 2.8 | accuracy: 0.30 | loss: 1.17
update: 65/2000, 耗时:0.00分/0.18分 | step:  1560 | performance: 3.0 | accuracy: 0.29 | loss: 1.23
update: 70/2000, 耗时:0.00分/0.19分 | step:  1680 | performance: 2.9 | accuracy: 0.29 | loss: 0.51
update: 75/2000, 耗时:0.00分/0.20分 | step:  1800 | performance: 2.7 | accuracy: 0.28 | loss: 1.03
update: 80/2000, 耗时:0.00分/0.22分 | step:  1920 | performance: 3.3 | accuracy: 0.30 | loss: 1.00
update: 85/2000, 耗时:0.00分/0.23分 | step:  2040 | performance: 4.1 | accuracy: 0.32 | loss: 0.91
update: 90/2000, 耗时:0.00分/0.25分 | step:  2160 | performance: 4.8 | accuracy: 0.33 | loss: 1.19
update: 95/2000, 耗时:0.00分/0.26分 | step:  2280 | performance: 5.6 | accuracy: 0.34 | loss: 0.92
update:100/2000, 耗时:0.00分/0.27分 | step:  2400 | performance: 6.9 | accuracy: 0.33 | loss: 1.32
update:105/2000, 耗时:0.00分/0.29分 | step:  2520 | performance: 8.4 | accuracy: 0.33 | loss: 0.79
update:110/2000, 耗时:0.00分/0.30分 | step:  2640 | performance: 9.0 | accuracy: 0.33 | loss: 0.40
update:115/2000, 耗时:0.00分/0.32分 | step:  2760 | performance: 7.1 | accuracy: 0.33 | loss: 1.35
update:120/2000, 耗时:0.00分/0.33分 | step:  2880 | performance: 6.6 | accuracy: 0.33 | loss: 0.86
update:125/2000, 耗时:0.00分/0.34分 | step:  3000 | performance: 7.4 | accuracy: 0.33 | loss: 0.87
update:130/2000, 耗时:0.00分/0.36分 | step:  3120 | performance: 6.7 | accuracy: 0.33 | loss: 0.56
update:135/2000, 耗时:0.00分/0.37分 | step:  3240 | performance: 7.4 | accuracy: 0.34 | loss: 1.32
update:140/2000, 耗时:0.00分/0.39分 | step:  3360 | performance: 5.8 | accuracy: 0.33 | loss: 0.89
update:145/2000, 耗时:0.00分/0.40分 | step:  3480 | performance: 9.2 | accuracy: 0.34 | loss: 1.22
update:150/2000, 耗时:0.00分/0.41分 | step:  3600 | performance: 9.5 | accuracy: 0.35 | loss: 0.93
update:155/2000, 耗时:0.00分/0.43分 | step:  3720 | performance: 8.3 | accuracy: 0.35 | loss: 0.49
update:160/2000, 耗时:0.00分/0.44分 | step:  3840 | performance: 8.5 | accuracy: 0.34 | loss: 0.64
update:165/2000, 耗时:0.00分/0.46分 | step:  3960 | performance: 9.4 | accuracy: 0.34 | loss: 1.12
update:170/2000, 耗时:0.00分/0.47分 | step:  4080 | performance: 7.7 | accuracy: 0.35 | loss: 2.97
update:175/2000, 耗时:0.00分/0.48分 | step:  4200 | performance: 5.8 | accuracy: 0.35 | loss: 1.00
update:180/2000, 耗时:0.00分/0.50分 | step:  4320 | performance: 6.2 | accuracy: 0.34 | loss: 0.57
update:185/2000, 耗时:0.00分/0.51分 | step:  4440 | performance: 6.3 | accuracy: 0.34 | loss: 0.75
update:190/2000, 耗时:0.00分/0.52分 | step:  4560 | performance: 6.3 | accuracy: 0.34 | loss: 0.65
update:195/2000, 耗时:0.00分/0.54分 | step:  4680 | performance: 7.8 | accuracy: 0.35 | loss: 0.44
update:200/2000, 耗时:0.00分/0.55分 | step:  4800 | performance: 5.4 | accuracy: 0.34 | loss: 1.72
update:205/2000, 耗时:0.00分/0.56分 | step:  4920 | performance: 5.6 | accuracy: 0.34 | loss: 0.65
update:210/2000, 耗时:0.00分/0.58分 | step:  5040 | performance: 5.3 | accuracy: 0.34 | loss: 0.38
update:215/2000, 耗时:0.00分/0.59分 | step:  5160 | performance: 5.0 | accuracy: 0.33 | loss: 0.55
update:220/2000, 耗时:0.00分/0.61分 | step:  5280 | performance: 6.2 | accuracy: 0.33 | loss: 3.22
update:225/2000, 耗时:0.00分/0.62分 | step:  5400 | performance: 4.7 | accuracy: 0.33 | loss: 0.80
update:230/2000, 耗时:0.00分/0.63分 | step:  5520 | performance: 4.5 | accuracy: 0.32 | loss: 0.49
update:235/2000, 耗时:0.00分/0.65分 | step:  5640 | performance: 3.3 | accuracy: 0.32 | loss: 0.42
update:240/2000, 耗时:0.00分/0.66分 | step:  5760 | performance: 2.8 | accuracy: 0.31 | loss: 0.25
update:245/2000, 耗时:0.00分/0.67分 | step:  5880 | performance: 2.5 | accuracy: 0.31 | loss: 3.33
update:250/2000, 耗时:0.00分/0.69分 | step:  6000 | performance: 2.8 | accuracy: 0.32 | loss: 0.58
update:255/2000, 耗时:0.00分/0.70分 | step:  6120 | performance: 2.3 | accuracy: 0.32 | loss: 1.29
update:260/2000, 耗时:0.00分/0.72分 | step:  6240 | performance: 2.6 | accuracy: 0.32 | loss: 0.32
update:265/2000, 耗时:0.00分/0.73分 | step:  6360 | performance: 2.6 | accuracy: 0.32 | loss: 0.27
update:270/2000, 耗时:0.00分/0.74分 | step:  6480 | performance: 2.6 | accuracy: 0.32 | loss: 1.27
update:275/2000, 耗时:0.00分/0.76分 | step:  6600 | performance: 2.4 | accuracy: 0.32 | loss: 0.79
update:280/2000, 耗时:0.00分/0.77分 | step:  6720 | performance: 2.3 | accuracy: 0.32 | loss: 0.90
update:285/2000, 耗时:0.00分/0.79分 | step:  6840 | performance: 1.8 | accuracy: 0.32 | loss: 0.76
update:290/2000, 耗时:0.00分/0.80分 | step:  6960 | performance: 1.6 | accuracy: 0.32 | loss: 1.26
update:295/2000, 耗时:0.00分/0.81分 | step:  7080 | performance: 1.5 | accuracy: 0.31 | loss: 0.47
update:300/2000, 耗时:0.00分/0.83分 | step:  7200 | performance: 1.3 | accuracy: 0.31 | loss: 0.44
update:305/2000, 耗时:0.00分/0.84分 | step:  7320 | performance: 1.3 | accuracy: 0.31 | loss: 0.36
update:310/2000, 耗时:0.00分/0.86分 | step:  7440 | performance: 0.7 | accuracy: 0.31 | loss: 1.70
update:315/2000, 耗时:0.00分/0.87分 | step:  7560 | performance: 1.3 | accuracy: 0.32 | loss: 1.07
update:320/2000, 耗时:0.00分/0.88分 | step:  7680 | performance: 1.5 | accuracy: 0.32 | loss: 2.52
update:325/2000, 耗时:0.00分/0.90分 | step:  7800 | performance: 1.8 | accuracy: 0.33 | loss: 1.68
update:330/2000, 耗时:0.00分/0.91分 | step:  7920 | performance: 2.5 | accuracy: 0.33 | loss: 2.13
update:335/2000, 耗时:0.00分/0.92分 | step:  8040 | performance: 5.9 | accuracy: 0.34 | loss: 3.07
update:340/2000, 耗时:0.00分/0.94分 | step:  8160 | performance: 11.5 | accuracy: 0.34 | loss: 4.34
update:345/2000, 耗时:0.00分/0.95分 | step:  8280 | performance: 18.1 | accuracy: 0.35 | loss: 1.23
update:350/2000, 耗时:0.00分/0.97分 | step:  8400 | performance: 28.7 | accuracy: 0.35 | loss: 0.20
update:355/2000, 耗时:0.00分/0.98分 | step:  8520 | performance: 15.0 | accuracy: 0.35 | loss: 0.70
update:360/2000, 耗时:0.00分/0.99分 | step:  8640 | performance: 25.5 | accuracy: 0.35 | loss: 1.47
update:365/2000, 耗时:0.00分/1.01分 | step:  8760 | performance: 71.9 | accuracy: 0.36 | loss: 2.68
update:370/2000, 耗时:0.00分/1.02分 | step:  8880 | performance: 62.1 | accuracy: 0.36 | loss: 5.62
update:375/2000, 耗时:0.00分/1.03分 | step:  9000 | performance: 125.1 | accuracy: 0.37 | loss: 1.64
update:380/2000, 耗时:0.00分/1.05分 | step:  9120 | performance: 32.6 | accuracy: 0.36 | loss: 4.70
update:385/2000, 耗时:0.00分/1.06分 | step:  9240 | performance: 27.0 | accuracy: 0.36 | loss: 0.66
update:390/2000, 耗时:0.00分/1.07分 | step:  9360 | performance: 23.7 | accuracy: 0.36 | loss: 1.69
update:395/2000, 耗时:0.00分/1.09分 | step:  9480 | performance: 35.4 | accuracy: 0.36 | loss: 0.35
update:400/2000, 耗时:0.00分/1.10分 | step:  9600 | performance: 15.0 | accuracy: 0.36 | loss: 3.63
update:405/2000, 耗时:0.00分/1.11分 | step:  9720 | performance: 14.2 | accuracy: 0.36 | loss: 0.58
update:410/2000, 耗时:0.00分/1.13分 | step:  9840 | performance: 15.0 | accuracy: 0.36 | loss: 0.49
update:415/2000, 耗时:0.00分/1.14分 | step:  9960 | performance: 15.9 | accuracy: 0.36 | loss: 0.45
update:420/2000, 耗时:0.00分/1.15分 | step: 10080 | performance: 16.0 | accuracy: 0.36 | loss: 0.90
update:425/2000, 耗时:0.00分/1.17分 | step: 10200 | performance: 16.5 | accuracy: 0.36 | loss: 0.66
update:430/2000, 耗时:0.00分/1.18分 | step: 10320 | performance: 20.6 | accuracy: 0.36 | loss: 0.78
update:435/2000, 耗时:0.00分/1.20分 | step: 10440 | performance: 20.4 | accuracy: 0.35 | loss: 0.15
update:440/2000, 耗时:0.00分/1.21分 | step: 10560 | performance: 19.3 | accuracy: 0.35 | loss: 0.13
update:445/2000, 耗时:0.00分/1.22分 | step: 10680 | performance: 20.3 | accuracy: 0.35 | loss: 0.39
update:450/2000, 耗时:0.00分/1.24分 | step: 10800 | performance: 10.6 | accuracy: 0.35 | loss: 0.59
update:455/2000, 耗时:0.00分/1.25分 | step: 10920 | performance: 10.4 | accuracy: 0.35 | loss: 0.72
update:460/2000, 耗时:0.00分/1.26分 | step: 11040 | performance: 8.7 | accuracy: 0.35 | loss: 0.69
update:465/2000, 耗时:0.00分/1.28分 | step: 11160 | performance: 10.7 | accuracy: 0.35 | loss: 1.39
update:470/2000, 耗时:0.00分/1.29分 | step: 11280 | performance: 11.4 | accuracy: 0.35 | loss: 0.69
update:475/2000, 耗时:0.00分/1.30分 | step: 11400 | performance: 11.2 | accuracy: 0.34 | loss: 1.03
update:480/2000, 耗时:0.00分/1.32分 | step: 11520 | performance: 13.4 | accuracy: 0.35 | loss: 1.07
update:485/2000, 耗时:0.00分/1.33分 | step: 11640 | performance: 11.2 | accuracy: 0.35 | loss: 0.91
update:490/2000, 耗时:0.00分/1.35分 | step: 11760 | performance: 11.0 | accuracy: 0.34 | loss: 0.89
update:495/2000, 耗时:0.00分/1.36分 | step: 11880 | performance: 8.9 | accuracy: 0.34 | loss: 0.86
update:500/2000, 耗时:0.00分/1.37分 | step: 12000 | performance: 8.6 | accuracy: 0.34 | loss: 0.58
update:505/2000, 耗时:0.00分/1.39分 | step: 12120 | performance: 9.7 | accuracy: 0.34 | loss: 1.47
update:510/2000, 耗时:0.00分/1.40分 | step: 12240 | performance: 12.7 | accuracy: 0.34 | loss: 2.40
update:515/2000, 耗时:0.00分/1.41分 | step: 12360 | performance: 14.8 | accuracy: 0.34 | loss: 0.65
update:520/2000, 耗时:0.00分/1.43分 | step: 12480 | performance: 22.0 | accuracy: 0.35 | loss: 0.80
update:525/2000, 耗时:0.00分/1.44分 | step: 12600 | performance: 16.3 | accuracy: 0.34 | loss: 2.35
update:530/2000, 耗时:0.00分/1.45分 | step: 12720 | performance: 10.2 | accuracy: 0.34 | loss: 3.69
update:535/2000, 耗时:0.00分/1.47分 | step: 12840 | performance: 8.7 | accuracy: 0.34 | loss: 0.72
update:540/2000, 耗时:0.00分/1.48分 | step: 12960 | performance: 5.8 | accuracy: 0.34 | loss: 6.06
update:545/2000, 耗时:0.00分/1.49分 | step: 13080 | performance: 3.7 | accuracy: 0.34 | loss: 0.45
update:550/2000, 耗时:0.00分/1.51分 | step: 13200 | performance: 3.2 | accuracy: 0.34 | loss: 0.22
update:555/2000, 耗时:0.00分/1.52分 | step: 13320 | performance: 3.3 | accuracy: 0.34 | loss: 0.38
update:560/2000, 耗时:0.00分/1.53分 | step: 13440 | performance: 4.3 | accuracy: 0.34 | loss: 0.77
update:565/2000, 耗时:0.00分/1.55分 | step: 13560 | performance: 4.2 | accuracy: 0.34 | loss: 0.80
update:570/2000, 耗时:0.00分/1.56分 | step: 13680 | performance: 3.7 | accuracy: 0.34 | loss: 0.66
update:575/2000, 耗时:0.00分/1.57分 | step: 13800 | performance: 3.1 | accuracy: 0.34 | loss: 0.62
update:580/2000, 耗时:0.00分/1.59分 | step: 13920 | performance: 2.2 | accuracy: 0.34 | loss: 2.51
update:585/2000, 耗时:0.00分/1.60分 | step: 14040 | performance: 3.5 | accuracy: 0.34 | loss: 0.66
update:590/2000, 耗时:0.00分/1.62分 | step: 14160 | performance: 3.1 | accuracy: 0.34 | loss: 0.88
update:595/2000, 耗时:0.00分/1.63分 | step: 14280 | performance: 3.0 | accuracy: 0.34 | loss: 0.62
update:600/2000, 耗时:0.00分/1.64分 | step: 14400 | performance: 2.6 | accuracy: 0.34 | loss: 1.10
update:605/2000, 耗时:0.00分/1.66分 | step: 14520 | performance: 2.1 | accuracy: 0.34 | loss: 1.02
update:610/2000, 耗时:0.00分/1.67分 | step: 14640 | performance: 2.0 | accuracy: 0.34 | loss: 1.12
update:615/2000, 耗时:0.00分/1.69分 | step: 14760 | performance: 1.9 | accuracy: 0.34 | loss: 0.71
update:620/2000, 耗时:0.00分/1.70分 | step: 14880 | performance: 1.8 | accuracy: 0.34 | loss: 0.54
update:625/2000, 耗时:0.00分/1.71分 | step: 15000 | performance: 1.8 | accuracy: 0.34 | loss: 0.63
update:630/2000, 耗时:0.00分/1.73分 | step: 15120 | performance: 1.5 | accuracy: 0.34 | loss: 0.77
update:635/2000, 耗时:0.00分/1.74分 | step: 15240 | performance: 2.0 | accuracy: 0.34 | loss: 0.33
update:640/2000, 耗时:0.00分/1.75分 | step: 15360 | performance: 2.5 | accuracy: 0.35 | loss: 1.12
update:645/2000, 耗时:0.00分/1.77分 | step: 15480 | performance: 2.8 | accuracy: 0.35 | loss: 2.02
update:650/2000, 耗时:0.00分/1.78分 | step: 15600 | performance: 2.4 | accuracy: 0.35 | loss: 0.85
update:655/2000, 耗时:0.00分/1.80分 | step: 15720 | performance: 2.5 | accuracy: 0.35 | loss: 0.84
update:660/2000, 耗时:0.00分/1.81分 | step: 15840 | performance: 1.2 | accuracy: 0.35 | loss: 0.56
update:665/2000, 耗时:0.00分/1.82分 | step: 15960 | performance: 1.1 | accuracy: 0.35 | loss: 0.56
update:670/2000, 耗时:0.00分/1.84分 | step: 16080 | performance: 0.9 | accuracy: 0.34 | loss: 0.84
update:675/2000, 耗时:0.00分/1.85分 | step: 16200 | performance: 0.8 | accuracy: 0.34 | loss: 0.62
update:680/2000, 耗时:0.00分/1.87分 | step: 16320 | performance: 0.8 | accuracy: 0.34 | loss: 1.57
update:685/2000, 耗时:0.00分/1.88分 | step: 16440 | performance: 1.0 | accuracy: 0.35 | loss: 0.70
update:690/2000, 耗时:0.00分/1.89分 | step: 16560 | performance: 1.9 | accuracy: 0.35 | loss: 2.18
update:695/2000, 耗时:0.00分/1.91分 | step: 16680 | performance: 2.6 | accuracy: 0.35 | loss: 1.44
update:700/2000, 耗时:0.00分/1.92分 | step: 16800 | performance: 6.1 | accuracy: 0.36 | loss: 2.34
update:705/2000, 耗时:0.00分/1.93分 | step: 16920 | performance: 8.3 | accuracy: 0.36 | loss: 0.17
update:710/2000, 耗时:0.00分/1.95分 | step: 17040 | performance: 21.1 | accuracy: 0.36 | loss: 0.74
update:715/2000, 耗时:0.00分/1.96分 | step: 17160 | performance: 21.8 | accuracy: 0.36 | loss: 2.20
update:720/2000, 耗时:0.00分/1.98分 | step: 17280 | performance: 23.5 | accuracy: 0.37 | loss: 1.93
update:725/2000, 耗时:0.00分/1.99分 | step: 17400 | performance: 30.4 | accuracy: 0.37 | loss: 1.80
update:730/2000, 耗时:0.00分/2.00分 | step: 17520 | performance: 66.1 | accuracy: 0.37 | loss: 3.80
update:735/2000, 耗时:0.00分/2.01分 | step: 17640 | performance: 247.9 | accuracy: 0.37 | loss: 1.49
update:740/2000, 耗时:0.00分/2.03分 | step: 17760 | performance: 1557.1 | accuracy: 0.38 | loss: 4.47
update:745/2000, 耗时:0.00分/2.04分 | step: 17880 | performance: 1654.8 | accuracy: 0.38 | loss: 0.25
update:750/2000, 耗时:0.00分/2.05分 | step: 18000 | performance: 710.0 | accuracy: 0.38 | loss: 9.74
update:755/2000, 耗时:0.00分/2.06分 | step: 18120 | performance: 836.9 | accuracy: 0.38 | loss: 1.38
update:760/2000, 耗时:0.00分/2.08分 | step: 18240 | performance: 1741.9 | accuracy: 0.38 | loss: 1.69
update:765/2000, 耗时:0.00分/2.09分 | step: 18360 | performance: 7931.0 | accuracy: 0.38 | loss: 0.68
update:770/2000, 耗时:0.00分/2.10分 | step: 18480 | performance: 23025.9 | accuracy: 0.39 | loss: 1.10
update:775/2000, 耗时:0.00分/2.11分 | step: 18600 | performance: 6650.0 | accuracy: 0.39 | loss: 0.79
update:780/2000, 耗时:0.00分/2.13分 | step: 18720 | performance: 11789.1 | accuracy: 0.39 | loss: 1.44
update:785/2000, 耗时:0.00分/2.14分 | step: 18840 | performance: 28554.7 | accuracy: 0.39 | loss: 4.41
update:790/2000, 耗时:0.00分/2.15分 | step: 18960 | performance: 22016.9 | accuracy: 0.39 | loss: 5.31
update:795/2000, 耗时:0.00分/2.17分 | step: 19080 | performance: 24974.2 | accuracy: 0.39 | loss: 1.39
update:800/2000, 耗时:0.00分/2.18分 | step: 19200 | performance: 22990.3 | accuracy: 0.39 | loss: 3.89
update:805/2000, 耗时:0.00分/2.19分 | step: 19320 | performance: 40651.0 | accuracy: 0.40 | loss: 1.08
update:810/2000, 耗时:0.00分/2.21分 | step: 19440 | performance: 13812.1 | accuracy: 0.39 | loss: 4.72
update:815/2000, 耗时:0.00分/2.22分 | step: 19560 | performance: 15089.8 | accuracy: 0.39 | loss: 0.40
update:820/2000, 耗时:0.00分/2.23分 | step: 19680 | performance: 16856.5 | accuracy: 0.40 | loss: 0.79
update:825/2000, 耗时:0.00分/2.24分 | step: 19800 | performance: 5980.7 | accuracy: 0.39 | loss: 6.04
update:830/2000, 耗时:0.00分/2.26分 | step: 19920 | performance: 1614.8 | accuracy: 0.39 | loss: 0.86
update:835/2000, 耗时:0.00分/2.27分 | step: 20040 | performance: 1552.7 | accuracy: 0.39 | loss: 0.54
update:840/2000, 耗时:0.00分/2.28分 | step: 20160 | performance: 1664.8 | accuracy: 0.39 | loss: 0.10
update:845/2000, 耗时:0.00分/2.30分 | step: 20280 | performance: 1551.8 | accuracy: 0.39 | loss: 0.23
update:850/2000, 耗时:0.00分/2.31分 | step: 20400 | performance: 1555.3 | accuracy: 0.39 | loss: 0.47
update:855/2000, 耗时:0.00分/2.32分 | step: 20520 | performance: 1216.6 | accuracy: 0.38 | loss: 0.86
update:860/2000, 耗时:0.00分/2.33分 | step: 20640 | performance: 1198.8 | accuracy: 0.38 | loss: 0.17
update:865/2000, 耗时:0.00分/2.35分 | step: 20760 | performance: 1249.4 | accuracy: 0.38 | loss: 0.43
update:870/2000, 耗时:0.00分/2.36分 | step: 20880 | performance: 1481.5 | accuracy: 0.38 | loss: 0.37
update:875/2000, 耗时:0.00分/2.37分 | step: 21000 | performance: 1134.7 | accuracy: 0.38 | loss: 0.79
update:880/2000, 耗时:0.00分/2.39分 | step: 21120 | performance: 878.4 | accuracy: 0.38 | loss: 0.65
update:885/2000, 耗时:0.00分/2.40分 | step: 21240 | performance: 2035.5 | accuracy: 0.38 | loss: 0.79
update:890/2000, 耗时:0.00分/2.41分 | step: 21360 | performance: 2085.5 | accuracy: 0.38 | loss: 1.82
update:895/2000, 耗时:0.00分/2.42分 | step: 21480 | performance: 2522.6 | accuracy: 0.38 | loss: 0.43
update:900/2000, 耗时:0.00分/2.44分 | step: 21600 | performance: 3228.7 | accuracy: 0.38 | loss: 1.40
update:905/2000, 耗时:0.00分/2.45分 | step: 21720 | performance: 1729.4 | accuracy: 0.38 | loss: 1.03
update:910/2000, 耗时:0.00分/2.46分 | step: 21840 | performance: 2073.9 | accuracy: 0.39 | loss: 3.95
update:915/2000, 耗时:0.00分/2.48分 | step: 21960 | performance: 1086.5 | accuracy: 0.39 | loss: 0.63
update:920/2000, 耗时:0.00分/2.49分 | step: 22080 | performance: 1794.5 | accuracy: 0.39 | loss: 2.28
update:925/2000, 耗时:0.00分/2.50分 | step: 22200 | performance: 4962.9 | accuracy: 0.39 | loss: 0.99
update:930/2000, 耗时:0.00分/2.52分 | step: 22320 | performance: 10260.4 | accuracy: 0.39 | loss: 0.67
update:935/2000, 耗时:0.00分/2.53分 | step: 22440 | performance: 8733.8 | accuracy: 0.39 | loss: 5.00
update:940/2000, 耗时:0.00分/2.54分 | step: 22560 | performance: 10075.3 | accuracy: 0.39 | loss: 0.52
update:945/2000, 耗时:0.00分/2.56分 | step: 22680 | performance: 15090.7 | accuracy: 0.39 | loss: 0.40
update:950/2000, 耗时:0.00分/2.57分 | step: 22800 | performance: 6821.0 | accuracy: 0.39 | loss: 6.01
update:955/2000, 耗时:0.00分/2.58分 | step: 22920 | performance: 4957.4 | accuracy: 0.39 | loss: 1.06
update:960/2000, 耗时:0.00分/2.60分 | step: 23040 | performance: 3259.6 | accuracy: 0.39 | loss: 3.95
update:965/2000, 耗时:0.00分/2.61分 | step: 23160 | performance: 1546.5 | accuracy: 0.39 | loss: 0.62
update:970/2000, 耗时:0.00分/2.62分 | step: 23280 | performance: 1340.3 | accuracy: 0.39 | loss: 0.69
update:975/2000, 耗时:0.00分/2.64分 | step: 23400 | performance: 1384.9 | accuracy: 0.39 | loss: 0.61
update:980/2000, 耗时:0.00分/2.65分 | step: 23520 | performance: 956.7 | accuracy: 0.39 | loss: 0.42
update:985/2000, 耗时:0.00分/2.66分 | step: 23640 | performance: 1062.7 | accuracy: 0.39 | loss: 0.30
update:990/2000, 耗时:0.00分/2.67分 | step: 23760 | performance: 1056.7 | accuracy: 0.39 | loss: 0.19
update:995/2000, 耗时:0.00分/2.69分 | step: 23880 | performance: 1321.4 | accuracy: 0.38 | loss: 0.15
update:1000/2000, 耗时:0.00分/2.70分 | step: 24000 | performance: 1307.0 | accuracy: 0.38 | loss: 0.07
update:1005/2000, 耗时:0.00分/2.71分 | step: 24120 | performance: 1668.0 | accuracy: 0.38 | loss: 0.25
update:1010/2000, 耗时:0.00分/2.73分 | step: 24240 | performance: 1649.7 | accuracy: 0.38 | loss: 0.47
update:1015/2000, 耗时:0.00分/2.74分 | step: 24360 | performance: 810.9 | accuracy: 0.38 | loss: 0.57
update:1020/2000, 耗时:0.00分/2.75分 | step: 24480 | performance: 650.6 | accuracy: 0.38 | loss: 0.32
update:1025/2000, 耗时:0.00分/2.76分 | step: 24600 | performance: 607.4 | accuracy: 0.38 | loss: 0.38
update:1030/2000, 耗时:0.00分/2.78分 | step: 24720 | performance: 559.0 | accuracy: 0.38 | loss: 0.31
update:1035/2000, 耗时:0.00分/2.79分 | step: 24840 | performance: 557.6 | accuracy: 0.38 | loss: 0.78
update:1040/2000, 耗时:0.00分/2.80分 | step: 24960 | performance: 570.1 | accuracy: 0.37 | loss: 1.80
update:1045/2000, 耗时:0.00分/2.82分 | step: 25080 | performance: 382.8 | accuracy: 0.37 | loss: 1.88
update:1050/2000, 耗时:0.00分/2.83分 | step: 25200 | performance: 271.7 | accuracy: 0.37 | loss: 0.66
update:1055/2000, 耗时:0.00分/2.84分 | step: 25320 | performance: 267.4 | accuracy: 0.37 | loss: 0.57
update:1060/2000, 耗时:0.00分/2.85分 | step: 25440 | performance: 280.1 | accuracy: 0.37 | loss: 0.35
update:1065/2000, 耗时:0.00分/2.87分 | step: 25560 | performance: 422.8 | accuracy: 0.37 | loss: 1.41
update:1070/2000, 耗时:0.00分/2.88分 | step: 25680 | performance: 474.1 | accuracy: 0.37 | loss: -0.00
update:1075/2000, 耗时:0.00分/2.89分 | step: 25800 | performance: 474.1 | accuracy: 0.37 | loss: 0.01
update:1080/2000, 耗时:0.00分/2.91分 | step: 25920 | performance: 474.1 | accuracy: 0.37 | loss: 0.01
update:1085/2000, 耗时:0.00分/2.92分 | step: 26040 | performance: 452.4 | accuracy: 0.36 | loss: 0.06
update:1090/2000, 耗时:0.00分/2.93分 | step: 26160 | performance: 886.5 | accuracy: 0.36 | loss: 0.26
update:1095/2000, 耗时:0.00分/2.94分 | step: 26280 | performance: 886.5 | accuracy: 0.36 | loss: 0.00
update:1100/2000, 耗时:0.00分/2.96分 | step: 26400 | performance: 886.5 | accuracy: 0.36 | loss: 0.10
update:1105/2000, 耗时:0.00分/2.97分 | step: 26520 | performance: 791.1 | accuracy: 0.36 | loss: 0.16
update:1110/2000, 耗时:0.00分/2.98分 | step: 26640 | performance: 747.3 | accuracy: 0.36 | loss: 0.47
update:1115/2000, 耗时:0.00分/3.00分 | step: 26760 | performance: 720.1 | accuracy: 0.36 | loss: 0.51
update:1120/2000, 耗时:0.00分/3.01分 | step: 26880 | performance: 854.6 | accuracy: 0.36 | loss: 0.32
update:1125/2000, 耗时:0.00分/3.02分 | step: 27000 | performance: 913.5 | accuracy: 0.36 | loss: 0.34
update:1130/2000, 耗时:0.00分/3.04分 | step: 27120 | performance: 1167.0 | accuracy: 0.36 | loss: 0.55
update:1135/2000, 耗时:0.00分/3.05分 | step: 27240 | performance: 1117.1 | accuracy: 0.36 | loss: 0.40
update:1140/2000, 耗时:0.00分/3.06分 | step: 27360 | performance: 1090.1 | accuracy: 0.36 | loss: 0.23
update:1145/2000, 耗时:0.00分/3.08分 | step: 27480 | performance: 1111.4 | accuracy: 0.36 | loss: 0.21
update:1150/2000, 耗时:0.00分/3.09分 | step: 27600 | performance: 1264.2 | accuracy: 0.35 | loss: 0.17
update:1155/2000, 耗时:0.00分/3.10分 | step: 27720 | performance: 1247.1 | accuracy: 0.35 | loss: 0.64
update:1160/2000, 耗时:0.00分/3.11分 | step: 27840 | performance: 1204.4 | accuracy: 0.35 | loss: 0.30
update:1165/2000, 耗时:0.00分/3.13分 | step: 27960 | performance: 1273.7 | accuracy: 0.35 | loss: 0.23
update:1170/2000, 耗时:0.00分/3.14分 | step: 28080 | performance: 1386.0 | accuracy: 0.35 | loss: 0.24
update:1175/2000, 耗时:0.00分/3.15分 | step: 28200 | performance: 1359.8 | accuracy: 0.35 | loss: 0.43
update:1180/2000, 耗时:0.00分/3.17分 | step: 28320 | performance: 1324.3 | accuracy: 0.35 | loss: 0.30
update:1185/2000, 耗时:0.00分/3.18分 | step: 28440 | performance: 1406.0 | accuracy: 0.35 | loss: 0.70
update:1190/2000, 耗时:0.00分/3.19分 | step: 28560 | performance: 1130.2 | accuracy: 0.35 | loss: 0.62
update:1195/2000, 耗时:0.00分/3.20分 | step: 28680 | performance: 1227.1 | accuracy: 0.35 | loss: 0.04
update:1200/2000, 耗时:0.00分/3.22分 | step: 28800 | performance: 1227.1 | accuracy: 0.35 | loss: 0.05
update:1205/2000, 耗时:0.00分/3.23分 | step: 28920 | performance: 1227.1 | accuracy: 0.35 | loss: -0.00
update:1210/2000, 耗时:0.00分/3.24分 | step: 29040 | performance: 1267.1 | accuracy: 0.35 | loss: 0.13
update:1215/2000, 耗时:0.00分/3.26分 | step: 29160 | performance: 1248.3 | accuracy: 0.34 | loss: 0.13
update:1220/2000, 耗时:0.00分/3.27分 | step: 29280 | performance: 1268.7 | accuracy: 0.34 | loss: 0.12
step: 29369 | worker_0@n_step_2: average total_reward after train data exhaustion : 114.3 | max total_reward: 114.3
step: 29370 | worker_1@n_step_2: average total_reward after train data exhaustion : 134.3 | max total_reward: 154.2
step: 29371 | worker_2@n_step_2: average total_reward after train data exhaustion : 114.6 | max total_reward: 154.2
step: 29372 | worker_3@n_step_2: average total_reward after train data exhaustion : 109.5 | max total_reward: 154.2
step: 29373 | worker_4@n_step_2: average total_reward after train data exhaustion : 121.9 | max total_reward: 171.7
step: 29374 | worker_5@n_step_2: average total_reward after train data exhaustion : 135.2 | max total_reward: 201.3
step: 29375 | worker_6@n_step_2: average total_reward after train data exhaustion : 141.6 | max total_reward: 201.3
step: 29376 | worker_7@n_step_2: average total_reward after train data exhaustion : 146.5 | max total_reward: 201.3
Saving PPO weights in both H5 format and checkpoint @ update:1224 
update:1225/2000, 耗时:0.00分/3.29分 | step: 29400 | performance: 1.0 | accuracy: 0.67 | loss: 1.07
update:1230/2000, 耗时:0.00分/3.30分 | step: 29520 | performance: 0.7 | accuracy: 0.50 | loss: 2.31
update:1235/2000, 耗时:0.00分/3.31分 | step: 29640 | performance: 1.6 | accuracy: 0.61 | loss: 6.40
update:1240/2000, 耗时:0.00分/3.32分 | step: 29760 | performance: 0.7 | accuracy: 0.52 | loss: 5.92
update:1245/2000, 耗时:0.00分/3.34分 | step: 29880 | performance: 0.2 | accuracy: 0.44 | loss: 1.13
update:1250/2000, 耗时:0.00分/3.35分 | step: 30000 | performance: 0.1 | accuracy: 0.40 | loss: 2.14
update:1255/2000, 耗时:0.00分/3.36分 | step: 30120 | performance: 0.1 | accuracy: 0.39 | loss: 0.73
update:1260/2000, 耗时:0.00分/3.38分 | step: 30240 | performance: 0.2 | accuracy: 0.38 | loss: 0.18
update:1265/2000, 耗时:0.00分/3.39分 | step: 30360 | performance: 0.1 | accuracy: 0.35 | loss: 1.05
update:1270/2000, 耗时:0.00分/3.40分 | step: 30480 | performance: 0.1 | accuracy: 0.34 | loss: 0.45
update:1275/2000, 耗时:0.00分/3.41分 | step: 30600 | performance: 0.1 | accuracy: 0.32 | loss: 1.02
update:1280/2000, 耗时:0.00分/3.43分 | step: 30720 | performance: 0.1 | accuracy: 0.29 | loss: 0.13
update:1285/2000, 耗时:0.00分/3.44分 | step: 30840 | performance: 0.1 | accuracy: 0.27 | loss: 0.08
update:1290/2000, 耗时:0.00分/3.45分 | step: 30960 | performance: 0.1 | accuracy: 0.26 | loss: 0.05
update:1295/2000, 耗时:0.00分/3.47分 | step: 31080 | performance: 0.1 | accuracy: 0.25 | loss: 0.06
update:1300/2000, 耗时:0.00分/3.48分 | step: 31200 | performance: 0.1 | accuracy: 0.24 | loss: 0.15
update:1305/2000, 耗时:0.00分/3.49分 | step: 31320 | performance: 0.1 | accuracy: 0.22 | loss: 0.24
update:1310/2000, 耗时:0.00分/3.50分 | step: 31440 | performance: 0.1 | accuracy: 0.22 | loss: 0.30
update:1315/2000, 耗时:0.00分/3.52分 | step: 31560 | performance: 0.1 | accuracy: 0.22 | loss: 0.30
update:1320/2000, 耗时:0.00分/3.53分 | step: 31680 | performance: 0.1 | accuracy: 0.23 | loss: 1.14
update:1325/2000, 耗时:0.00分/3.54分 | step: 31800 | performance: 0.1 | accuracy: 0.23 | loss: 0.52
update:1330/2000, 耗时:0.00分/3.55分 | step: 31920 | performance: 0.1 | accuracy: 0.24 | loss: 0.14
update:1335/2000, 耗时:0.00分/3.57分 | step: 32040 | performance: 0.1 | accuracy: 0.23 | loss: -0.01
update:1340/2000, 耗时:0.00分/3.58分 | step: 32160 | performance: 0.1 | accuracy: 0.23 | loss: 0.22
update:1345/2000, 耗时:0.00分/3.59分 | step: 32280 | performance: 0.1 | accuracy: 0.22 | loss: 0.02
update:1350/2000, 耗时:0.00分/3.60分 | step: 32400 | performance: 0.1 | accuracy: 0.21 | loss: 0.10
update:1355/2000, 耗时:0.00分/3.61分 | step: 32520 | performance: 0.1 | accuracy: 0.20 | loss: -0.00
update:1360/2000, 耗时:0.00分/3.63分 | step: 32640 | performance: 0.1 | accuracy: 0.19 | loss: 1.16
update:1365/2000, 耗时:0.00分/3.64分 | step: 32760 | performance: 0.1 | accuracy: 0.19 | loss: 0.51
update:1370/2000, 耗时:0.00分/3.65分 | step: 32880 | performance: 0.1 | accuracy: 0.19 | loss: 3.37
update:1375/2000, 耗时:0.00分/3.66分 | step: 33000 | performance: 0.1 | accuracy: 0.19 | loss: 1.53
update:1380/2000, 耗时:0.00分/3.67分 | step: 33120 | performance: 0.1 | accuracy: 0.19 | loss: 0.04
update:1385/2000, 耗时:0.00分/3.69分 | step: 33240 | performance: 0.1 | accuracy: 0.19 | loss: 0.11
update:1390/2000, 耗时:0.00分/3.70分 | step: 33360 | performance: 0.1 | accuracy: 0.19 | loss: 0.42
update:1395/2000, 耗时:0.00分/3.71分 | step: 33480 | performance: 0.1 | accuracy: 0.19 | loss: 2.29
update:1400/2000, 耗时:0.00分/3.72分 | step: 33600 | performance: 0.1 | accuracy: 0.20 | loss: 0.48
update:1405/2000, 耗时:0.00分/3.73分 | step: 33720 | performance: 0.1 | accuracy: 0.19 | loss: 0.28
update:1410/2000, 耗时:0.00分/3.75分 | step: 33840 | performance: 0.1 | accuracy: 0.20 | loss: 0.60
update:1415/2000, 耗时:0.00分/3.76分 | step: 33960 | performance: 0.1 | accuracy: 0.20 | loss: 0.68
update:1420/2000, 耗时:0.00分/3.77分 | step: 34080 | performance: 0.1 | accuracy: 0.20 | loss: 0.79
update:1425/2000, 耗时:0.00分/3.78分 | step: 34200 | performance: 0.1 | accuracy: 0.20 | loss: 0.26
update:1430/2000, 耗时:0.00分/3.79分 | step: 34320 | performance: 0.1 | accuracy: 0.19 | loss: 0.41
update:1435/2000, 耗时:0.00分/3.81分 | step: 34440 | performance: 0.1 | accuracy: 0.19 | loss: 0.27
update:1440/2000, 耗时:0.00分/3.82分 | step: 34560 | performance: 0.1 | accuracy: 0.19 | loss: 0.09
update:1445/2000, 耗时:0.00分/3.83分 | step: 34680 | performance: 0.1 | accuracy: 0.19 | loss: 0.93
update:1450/2000, 耗时:0.00分/3.84分 | step: 34800 | performance: 0.1 | accuracy: 0.19 | loss: 0.01
update:1455/2000, 耗时:0.00分/3.86分 | step: 34920 | performance: 0.1 | accuracy: 0.19 | loss: 0.03
update:1460/2000, 耗时:0.00分/3.87分 | step: 35040 | performance: 0.1 | accuracy: 0.19 | loss: 0.00
update:1465/2000, 耗时:0.00分/3.88分 | step: 35160 | performance: 0.1 | accuracy: 0.18 | loss: 0.00
update:1470/2000, 耗时:0.00分/3.89分 | step: 35280 | performance: 0.1 | accuracy: 0.18 | loss: 0.30
update:1475/2000, 耗时:0.00分/3.91分 | step: 35400 | performance: 0.1 | accuracy: 0.18 | loss: 0.13
update:1480/2000, 耗时:0.00分/3.92分 | step: 35520 | performance: 0.1 | accuracy: 0.18 | loss: 0.11
update:1485/2000, 耗时:0.00分/3.93分 | step: 35640 | performance: 0.1 | accuracy: 0.18 | loss: 0.07
update:1490/2000, 耗时:0.00分/3.94分 | step: 35760 | performance: 0.1 | accuracy: 0.17 | loss: 0.24
update:1495/2000, 耗时:0.00分/3.95分 | step: 35880 | performance: 0.1 | accuracy: 0.17 | loss: 0.35
update:1500/2000, 耗时:0.00分/3.96分 | step: 36000 | performance: 0.1 | accuracy: 0.17 | loss: 0.07
update:1505/2000, 耗时:0.00分/3.98分 | step: 36120 | performance: 0.1 | accuracy: 0.17 | loss: 0.17
update:1510/2000, 耗时:0.00分/3.99分 | step: 36240 | performance: 0.1 | accuracy: 0.17 | loss: 0.44
update:1515/2000, 耗时:0.00分/4.00分 | step: 36360 | performance: 0.1 | accuracy: 0.17 | loss: 0.60
update:1520/2000, 耗时:0.00分/4.01分 | step: 36480 | performance: 0.1 | accuracy: 0.17 | loss: 0.62
update:1525/2000, 耗时:0.00分/4.02分 | step: 36600 | performance: 0.1 | accuracy: 0.18 | loss: 0.64
update:1530/2000, 耗时:0.00分/4.04分 | step: 36720 | performance: 0.1 | accuracy: 0.18 | loss: 0.78
update:1535/2000, 耗时:0.00分/4.05分 | step: 36840 | performance: 0.2 | accuracy: 0.19 | loss: 3.75
update:1540/2000, 耗时:0.00分/4.06分 | step: 36960 | performance: 0.3 | accuracy: 0.19 | loss: 2.76
update:1545/2000, 耗时:0.00分/4.07分 | step: 37080 | performance: 0.3 | accuracy: 0.20 | loss: 1.28
update:1550/2000, 耗时:0.00分/4.09分 | step: 37200 | performance: 0.4 | accuracy: 0.21 | loss: 2.54
update:1555/2000, 耗时:0.00分/4.10分 | step: 37320 | performance: 0.5 | accuracy: 0.22 | loss: 1.67
update:1560/2000, 耗时:0.00分/4.11分 | step: 37440 | performance: 1.6 | accuracy: 0.23 | loss: 3.73
update:1565/2000, 耗时:0.00分/4.12分 | step: 37560 | performance: 3.6 | accuracy: 0.23 | loss: 0.26
update:1570/2000, 耗时:0.00分/4.13分 | step: 37680 | performance: 6.6 | accuracy: 0.24 | loss: 1.41
update:1575/2000, 耗时:0.00分/4.15分 | step: 37800 | performance: 5.8 | accuracy: 0.24 | loss: 4.60
update:1580/2000, 耗时:0.00分/4.16分 | step: 37920 | performance: 3.8 | accuracy: 0.25 | loss: 1.66
update:1585/2000, 耗时:0.00分/4.17分 | step: 38040 | performance: 9.1 | accuracy: 0.26 | loss: 1.05
update:1590/2000, 耗时:0.00分/4.18分 | step: 38160 | performance: 54.9 | accuracy: 0.27 | loss: 3.12
update:1595/2000, 耗时:0.00分/4.19分 | step: 38280 | performance: 32.4 | accuracy: 0.27 | loss: 0.29
update:1600/2000, 耗时:0.00分/4.20分 | step: 38400 | performance: 59.3 | accuracy: 0.27 | loss: 3.92
update:1605/2000, 耗时:0.00分/4.22分 | step: 38520 | performance: 14.7 | accuracy: 0.27 | loss: 1.49
update:1610/2000, 耗时:0.00分/4.23分 | step: 38640 | performance: 14.8 | accuracy: 0.27 | loss: 3.32
update:1615/2000, 耗时:0.00分/4.24分 | step: 38760 | performance: 14.2 | accuracy: 0.27 | loss: 2.05
update:1620/2000, 耗时:0.00分/4.25分 | step: 38880 | performance: 24.3 | accuracy: 0.28 | loss: 3.19
update:1625/2000, 耗时:0.00分/4.27分 | step: 39000 | performance: 10.0 | accuracy: 0.28 | loss: 0.66
update:1630/2000, 耗时:0.00分/4.28分 | step: 39120 | performance: 9.3 | accuracy: 0.28 | loss: 0.75
update:1635/2000, 耗时:0.00分/4.29分 | step: 39240 | performance: 7.6 | accuracy: 0.28 | loss: 0.90
update:1640/2000, 耗时:0.00分/4.31分 | step: 39360 | performance: 6.7 | accuracy: 0.28 | loss: 0.51
update:1645/2000, 耗时:0.00分/4.32分 | step: 39480 | performance: 7.3 | accuracy: 0.28 | loss: 0.59
update:1650/2000, 耗时:0.00分/4.33分 | step: 39600 | performance: 8.3 | accuracy: 0.28 | loss: 1.04
update:1655/2000, 耗时:0.00分/4.34分 | step: 39720 | performance: 10.3 | accuracy: 0.28 | loss: 0.58
update:1660/2000, 耗时:0.00分/4.35分 | step: 39840 | performance: 10.3 | accuracy: 0.28 | loss: 0.01
update:1665/2000, 耗时:0.00分/4.37分 | step: 39960 | performance: 10.6 | accuracy: 0.28 | loss: 0.04
update:1670/2000, 耗时:0.00分/4.38分 | step: 40080 | performance: 10.9 | accuracy: 0.27 | loss: -0.00
update:1675/2000, 耗时:0.00分/4.39分 | step: 40200 | performance: 8.8 | accuracy: 0.27 | loss: 0.14
update:1680/2000, 耗时:0.00分/4.40分 | step: 40320 | performance: 9.1 | accuracy: 0.27 | loss: 0.12
update:1685/2000, 耗时:0.00分/4.42分 | step: 40440 | performance: 8.6 | accuracy: 0.27 | loss: 0.23
update:1690/2000, 耗时:0.00分/4.43分 | step: 40560 | performance: 12.7 | accuracy: 0.27 | loss: 0.71
update:1695/2000, 耗时:0.00分/4.44分 | step: 40680 | performance: 12.9 | accuracy: 0.27 | loss: 0.05
update:1700/2000, 耗时:0.00分/4.45分 | step: 40800 | performance: 12.7 | accuracy: 0.27 | loss: 0.03
update:1705/2000, 耗时:0.00分/4.46分 | step: 40920 | performance: 14.8 | accuracy: 0.27 | loss: 0.12
update:1710/2000, 耗时:0.00分/4.48分 | step: 41040 | performance: 13.7 | accuracy: 0.27 | loss: 0.32
update:1715/2000, 耗时:0.00分/4.49分 | step: 41160 | performance: 13.6 | accuracy: 0.27 | loss: 0.15
update:1720/2000, 耗时:0.00分/4.50分 | step: 41280 | performance: 11.6 | accuracy: 0.26 | loss: 0.17
update:1725/2000, 耗时:0.00分/4.51分 | step: 41400 | performance: 9.5 | accuracy: 0.26 | loss: 1.28
update:1730/2000, 耗时:0.00分/4.52分 | step: 41520 | performance: 9.5 | accuracy: 0.26 | loss: 0.77
update:1735/2000, 耗时:0.00分/4.54分 | step: 41640 | performance: 11.0 | accuracy: 0.26 | loss: 1.71
update:1740/2000, 耗时:0.00分/4.55分 | step: 41760 | performance: 13.8 | accuracy: 0.27 | loss: 1.51
update:1745/2000, 耗时:0.00分/4.56分 | step: 41880 | performance: 23.1 | accuracy: 0.27 | loss: 1.30
update:1750/2000, 耗时:0.00分/4.57分 | step: 42000 | performance: 15.2 | accuracy: 0.27 | loss: 2.74
update:1755/2000, 耗时:0.00分/4.59分 | step: 42120 | performance: 7.0 | accuracy: 0.27 | loss: 3.33
update:1760/2000, 耗时:0.00分/4.60分 | step: 42240 | performance: 7.7 | accuracy: 0.27 | loss: 0.64
update:1765/2000, 耗时:0.00分/4.61分 | step: 42360 | performance: 28.1 | accuracy: 0.28 | loss: 4.63
update:1770/2000, 耗时:0.00分/4.62分 | step: 42480 | performance: 46.2 | accuracy: 0.28 | loss: 0.07
update:1775/2000, 耗时:0.00分/4.64分 | step: 42600 | performance: 41.1 | accuracy: 0.27 | loss: 0.07
update:1780/2000, 耗时:0.00分/4.65分 | step: 42720 | performance: 39.3 | accuracy: 0.27 | loss: -0.03
update:1785/2000, 耗时:0.00分/4.66分 | step: 42840 | performance: 37.6 | accuracy: 0.27 | loss: 0.16
update:1790/2000, 耗时:0.00分/4.67分 | step: 42960 | performance: 35.4 | accuracy: 0.27 | loss: 0.35
update:1795/2000, 耗时:0.00分/4.69分 | step: 43080 | performance: 33.2 | accuracy: 0.27 | loss: 0.30
update:1800/2000, 耗时:0.00分/4.70分 | step: 43200 | performance: 37.1 | accuracy: 0.27 | loss: 0.51
update:1805/2000, 耗时:0.00分/4.71分 | step: 43320 | performance: 38.1 | accuracy: 0.27 | loss: 3.02
update:1810/2000, 耗时:0.00分/4.72分 | step: 43440 | performance: 47.3 | accuracy: 0.27 | loss: 2.41
update:1815/2000, 耗时:0.00分/4.74分 | step: 43560 | performance: 31.7 | accuracy: 0.27 | loss: 1.35
update:1820/2000, 耗时:0.00分/4.75分 | step: 43680 | performance: 38.2 | accuracy: 0.27 | loss: 0.52
update:1825/2000, 耗时:0.00分/4.76分 | step: 43800 | performance: 34.2 | accuracy: 0.27 | loss: 1.65
update:1830/2000, 耗时:0.00分/4.77分 | step: 43920 | performance: 33.5 | accuracy: 0.28 | loss: 1.63
update:1835/2000, 耗时:0.00分/4.78分 | step: 44040 | performance: 30.1 | accuracy: 0.28 | loss: 1.08
update:1840/2000, 耗时:0.00分/4.80分 | step: 44160 | performance: 30.3 | accuracy: 0.28 | loss: 0.63
update:1845/2000, 耗时:0.00分/4.81分 | step: 44280 | performance: 29.9 | accuracy: 0.28 | loss: 0.43
update:1850/2000, 耗时:0.00分/4.82分 | step: 44400 | performance: 30.8 | accuracy: 0.28 | loss: 0.84
update:1855/2000, 耗时:0.00分/4.83分 | step: 44520 | performance: 26.0 | accuracy: 0.28 | loss: 1.04
update:1860/2000, 耗时:0.00分/4.85分 | step: 44640 | performance: 25.0 | accuracy: 0.28 | loss: 2.50
update:1865/2000, 耗时:0.00分/4.86分 | step: 44760 | performance: 32.3 | accuracy: 0.28 | loss: 2.48
update:1870/2000, 耗时:0.00分/4.87分 | step: 44880 | performance: 38.5 | accuracy: 0.28 | loss: 0.54
update:1875/2000, 耗时:0.00分/4.88分 | step: 45000 | performance: 28.0 | accuracy: 0.28 | loss: 1.53
update:1880/2000, 耗时:0.00分/4.90分 | step: 45120 | performance: 20.9 | accuracy: 0.28 | loss: 2.36
update:1885/2000, 耗时:0.00分/4.91分 | step: 45240 | performance: 12.1 | accuracy: 0.28 | loss: 1.05
update:1890/2000, 耗时:0.00分/4.92分 | step: 45360 | performance: 14.5 | accuracy: 0.29 | loss: 0.82
update:1895/2000, 耗时:0.00分/4.93分 | step: 45480 | performance: 13.9 | accuracy: 0.29 | loss: 1.01
update:1900/2000, 耗时:0.00分/4.95分 | step: 45600 | performance: 14.6 | accuracy: 0.29 | loss: 0.50
update:1905/2000, 耗时:0.00分/4.96分 | step: 45720 | performance: 18.0 | accuracy: 0.29 | loss: 0.86
update:1910/2000, 耗时:0.00分/4.97分 | step: 45840 | performance: 18.9 | accuracy: 0.29 | loss: 0.27
update:1915/2000, 耗时:0.00分/4.98分 | step: 45960 | performance: 37.9 | accuracy: 0.29 | loss: 1.35
update:1920/2000, 耗时:0.00分/5.00分 | step: 46080 | performance: 52.2 | accuracy: 0.30 | loss: 0.66
update:1925/2000, 耗时:0.00分/5.01分 | step: 46200 | performance: 113.9 | accuracy: 0.30 | loss: 3.77
update:1930/2000, 耗时:0.00分/5.02分 | step: 46320 | performance: 215.6 | accuracy: 0.31 | loss: 1.55
update:1935/2000, 耗时:0.00分/5.03分 | step: 46440 | performance: 465.2 | accuracy: 0.31 | loss: 0.48
update:1940/2000, 耗时:0.00分/5.05分 | step: 46560 | performance: 526.6 | accuracy: 0.31 | loss: 0.42
update:1945/2000, 耗时:0.00分/5.06分 | step: 46680 | performance: 403.5 | accuracy: 0.31 | loss: 6.15
update:1950/2000, 耗时:0.00分/5.07分 | step: 46800 | performance: 1007.0 | accuracy: 0.32 | loss: 3.23
update:1955/2000, 耗时:0.00分/5.08分 | step: 46920 | performance: 2261.9 | accuracy: 0.32 | loss: 0.91
update:1960/2000, 耗时:0.00分/5.10分 | step: 47040 | performance: 8987.6 | accuracy: 0.32 | loss: 0.77
update:1965/2000, 耗时:0.00分/5.11分 | step: 47160 | performance: 77081.7 | accuracy: 0.33 | loss: 1.53
update:1970/2000, 耗时:0.00分/5.12分 | step: 47280 | performance: 51090.9 | accuracy: 0.33 | loss: 2.65
update:1975/2000, 耗时:0.00分/5.14分 | step: 47400 | performance: 17320.5 | accuracy: 0.33 | loss: 2.61
update:1980/2000, 耗时:0.00分/5.15分 | step: 47520 | performance: 23616.9 | accuracy: 0.33 | loss: 1.54
update:1985/2000, 耗时:0.00分/5.16分 | step: 47640 | performance: 70059.1 | accuracy: 0.33 | loss: 1.88
update:1990/2000, 耗时:0.00分/5.17分 | step: 47760 | performance: 242581.0 | accuracy: 0.34 | loss: 0.52
update:1995/2000, 耗时:0.00分/5.18分 | step: 47880 | performance: 500601.5 | accuracy: 0.34 | loss: 7.68
  0%|          | 0/401 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/5.20分 | step: 48000 | performance: 237299.9 | accuracy: 0.34 | loss: 0.13
----------------------------------------finished----------------------------------------
100%|| 401/401 [00:00<00:00, 66763.89it/s]
==================================================
2023-01-05T12:00:00 | *** START BACKTEST ***
2023-01-05T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1310.15
2023-07-24T12:00:00 | net performance [%] = 31.0149
2023-07-24T12:00:00 | number of trades [#] = 32
==================================================
Trial 15 Complete [00h 05m 38s]
net_wealth: 1311.4603382382454

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 02h 03m 14s

Search: Running Trial #16

Value             |Best Value So Far |Hyperparameter
2                 |1                 |horizon
365               |730               |lookback
True              |False             |MarketFactor
5                 |3                 |lags
0.7               |0.92              |gamma
32                |32                |batch_size
1                 |1                 |n_step
0.96              |0.94              |gae_lambda
2                 |5                 |gradient_clip_norm
5                 |5                 |epochs
0.0001            |0.0001            |actor_lr
0.0005            |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4299.000000   4301.000000
mean      0.000435    20113.607657  ...   20176.664105  20169.373185
std       0.027833    16040.642334  ...   16078.769271  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7739.330078   7730.930176
50%       0.000642    11571.842969  ...   11754.589844  11751.469727
75%       0.011590    29894.706152  ...   30014.465820  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 00:06:37.121869: I tensorflow/core/platform/cpu_feature_guard.cc:142] Thi2023-07-28 00:06:37.121911: I te2023-07-28 00:06:37.121937: I tensorflow/core/platform/cpu_feature_guard.cc:142] Thi2023-07-28 00:06:37.121983: I tensorflow/core/platform/cpu_feature_guard.cns TensorFlow bisorfcs: 1l4Te2o]w nT/hsicso oTrFlowre e/pbinary is nlsooartFpltimiofwz eboirnmadr with oneAPI Dey/ ep Nicse 2023-07-nary is optimized with on2eural NetApwPI ou_rk Library (ooDneDeptieNNpmiz ) Ned etoural Network Librar82y (o 00:new use tifteh06atur: 3Do7neAP.NN) to use thI12211 e8:2 f ID0e23-07-28e tenp sorN 0eural N02feeh_3-g2020euao3-ll7ortdw.l-ow/co28o0 r 0rcc0f07-wek/ Li::b2ipnglatfo r8arrC0y6:3 P(U7 . o10i0n:en2026:33s5t8r7D.Nuc1tNi) o:2 ntso 2 ol494: ul:Ise tIh t0o6:inmensorfe/ lfo3l 7w.pcpelrifuo_ow/ngo C1fweatcioPUrr223u n8m9ere_ggia n:c Cu1atens/ 42]eo-rfIPnrd.pllo UTchcarit ci :tfw14i2c] ionrsm/ctraulte Tcnpsu/hoo_cftireiapeofosr atnrsTelue/noswo/ ctsrreptoiin srFonsl_pelrora tguctTfor: f we/AuVaXrde.onrm  cAVsanXo2r
Flcec-:crbiitiTcalo  ooen1a4wpe2r]  iboTbaitnhsismnary inio/ sin le capp eTn topplu_hrty sfeaitmifzeeeio:s  Ans orFado VX wltpAtioVirure_mtiwXfozghe2dr m 
u woabTiino etahrcenma bdl.ec conn-tehr m/cpeAciritu:amrPnn_f ei Io in1y42tDeeA haet eP]i srurIe _D  pc aloooTphi pteirmatghuNsa rdietTeeen.ocpisonosr,F lcoezup:w1rr er e 42] Tophieadl  wNirsa TNeettteeuwohinonbsbursatirr ko ni:oail NeteonraFLnlsrAy  PwdoliIibr ,A V rToewn sbsrak  DoirnebX  oAptLiuilVXebrrarya2ry F loeipm N(ewu d( 
ToTeoonn nrsoarlF elonye wiiaswite D NoNpDhz ttihmee da pwbN)pi zteo lrdoNp)i rei atthewiN tte cmh eoneoA PtIw oDrik oLwtuhs imen oues nthe ei bepp Noetuhrit efoa rthAlPlIaheer oto wDil ere rhln apypgerafteep  fNoelulroawi l(a ponsoNgCsPUnle .
, rropriate ienNtewosrttD rcwekbomoN upcrkuition ngN )CPil LiUL iibtildn srsbtructio rary (onTnaeeDs inriensorFrN  lyo (nNw) w ppo ntoefietDhre rfolram foance-c ugsorrmanitshee Nti.c
e-c raical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow witupse thpropriate compiler flags.
tical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
the following CPU instructionsh the appropriate compiler flags.
N) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
e fol in performance-lowing CPU instructions in performance-critical operations:  AVX criAVX2
Ttical operations:  AVX AVX2
To enable tho eem in other operations, rebuild TensorFlow with the appropriate compilenable ther flags.
m in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 00:06:37.730243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:06:37.736082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:06:37.753078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:06:37.761506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:06:37.767152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:06:37.782020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-02023-07-27-28 00:06:37.8 00:78525106:37:. 7I8 tensorf5251: Ilow/co tensorflowr/core/e/common_runcotimmon_runtime/gpu/gpu_device.cc:1510]me/gpu/gpu_device.cc:1510] Created device /job:localhos Created dt/replica:0/taskevic:0/device:GPU:0 with 5e /job:localhost/replica:0/task:0/device:GPU:0 wi4t54 MB mehmory: 5454 MB memory:  -> dev  -> deice: 0, name: NVIDIA GeForce RTX 3070, pciv bius id: c00e: 0, name: N00:01:00.0, compute capabilVIDIA Gity: 8.6e
Force RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:    40 | performance: 1.0 | accuracy: 0.60 | loss: 0.24
update: 10/2000, 耗时:0.00分/0.04分 | step:    80 | performance: 0.9 | accuracy: 0.50 | loss: -0.00
update: 15/2000, 耗时:0.00分/0.05分 | step:   120 | performance: 1.2 | accuracy: 0.60 | loss: 0.71
update: 20/2000, 耗时:0.00分/0.06分 | step:   160 | performance: 1.3 | accuracy: 0.65 | loss: 0.03
update: 25/2000, 耗时:0.00分/0.06分 | step:   200 | performance: 1.2 | accuracy: 0.60 | loss: 0.55
update: 30/2000, 耗时:0.00分/0.07分 | step:   240 | performance: 1.1 | accuracy: 0.57 | loss: 0.44
update: 35/2000, 耗时:0.00分/0.08分 | step:   280 | performance: 1.1 | accuracy: 0.49 | loss: 0.38
update: 40/2000, 耗时:0.00分/0.09分 | step:   320 | performance: 1.3 | accuracy: 0.55 | loss: 0.38
update: 45/2000, 耗时:0.00分/0.10分 | step:   360 | performance: 1.4 | accuracy: 0.53 | loss: 0.78
update: 50/2000, 耗时:0.00分/0.11分 | step:   400 | performance: 1.7 | accuracy: 0.54 | loss: 0.17
update: 55/2000, 耗时:0.00分/0.12分 | step:   440 | performance: 1.5 | accuracy: 0.53 | loss: 0.74
update: 60/2000, 耗时:0.00分/0.13分 | step:   480 | performance: 1.7 | accuracy: 0.53 | loss: -0.00
update: 65/2000, 耗时:0.00分/0.14分 | step:   520 | performance: 1.6 | accuracy: 0.51 | loss: 0.21
update: 70/2000, 耗时:0.00分/0.15分 | step:   560 | performance: 1.6 | accuracy: 0.50 | loss: 0.25
update: 75/2000, 耗时:0.00分/0.16分 | step:   600 | performance: 1.6 | accuracy: 0.48 | loss: 0.29
update: 80/2000, 耗时:0.00分/0.17分 | step:   640 | performance: 1.5 | accuracy: 0.45 | loss: 0.00
update: 85/2000, 耗时:0.00分/0.18分 | step:   680 | performance: 1.4 | accuracy: 0.42 | loss: 0.52
update: 90/2000, 耗时:0.00分/0.19分 | step:   720 | performance: 1.3 | accuracy: 0.40 | loss: 0.28
update: 95/2000, 耗时:0.00分/0.20分 | step:   760 | performance: 1.3 | accuracy: 0.39 | loss: 0.15
update:100/2000, 耗时:0.00分/0.21分 | step:   800 | performance: 1.3 | accuracy: 0.37 | loss: 0.34
update:105/2000, 耗时:0.00分/0.22分 | step:   840 | performance: 1.3 | accuracy: 0.36 | loss: 0.49
update:110/2000, 耗时:0.00分/0.23分 | step:   880 | performance: 1.3 | accuracy: 0.36 | loss: 0.08
update:115/2000, 耗时:0.00分/0.24分 | step:   920 | performance: 1.4 | accuracy: 0.37 | loss: 0.64
update:120/2000, 耗时:0.00分/0.25分 | step:   960 | performance: 1.5 | accuracy: 0.39 | loss: 0.81
update:125/2000, 耗时:0.00分/0.26分 | step:  1000 | performance: 1.4 | accuracy: 0.38 | loss: 0.05
update:130/2000, 耗时:0.00分/0.27分 | step:  1040 | performance: 1.3 | accuracy: 0.38 | loss: 0.58
update:135/2000, 耗时:0.00分/0.28分 | step:  1080 | performance: 1.4 | accuracy: 0.39 | loss: 0.30
update:140/2000, 耗时:0.00分/0.30分 | step:  1120 | performance: 1.3 | accuracy: 0.38 | loss: 0.37
update:145/2000, 耗时:0.00分/0.31分 | step:  1160 | performance: 1.2 | accuracy: 0.37 | loss: 0.03
update:150/2000, 耗时:0.00分/0.32分 | step:  1200 | performance: 1.2 | accuracy: 0.37 | loss: 0.51
update:155/2000, 耗时:0.00分/0.33分 | step:  1240 | performance: 1.2 | accuracy: 0.35 | loss: 0.36
update:160/2000, 耗时:0.00分/0.34分 | step:  1280 | performance: 1.2 | accuracy: 0.34 | loss: 0.17
update:165/2000, 耗时:0.00分/0.35分 | step:  1320 | performance: 1.1 | accuracy: 0.34 | loss: 0.16
update:170/2000, 耗时:0.00分/0.36分 | step:  1360 | performance: 1.1 | accuracy: 0.33 | loss: 0.03
update:175/2000, 耗时:0.00分/0.37分 | step:  1400 | performance: 1.1 | accuracy: 0.32 | loss: 0.00
update:180/2000, 耗时:0.00分/0.38分 | step:  1440 | performance: 1.1 | accuracy: 0.31 | loss: -0.00
update:185/2000, 耗时:0.00分/0.39分 | step:  1480 | performance: 1.1 | accuracy: 0.31 | loss: 0.02
update:190/2000, 耗时:0.00分/0.40分 | step:  1520 | performance: 1.1 | accuracy: 0.30 | loss: 0.07
update:195/2000, 耗时:0.00分/0.42分 | step:  1560 | performance: 1.1 | accuracy: 0.29 | loss: 0.33
update:200/2000, 耗时:0.00分/0.43分 | step:  1600 | performance: 1.1 | accuracy: 0.29 | loss: 0.19
update:205/2000, 耗时:0.00分/0.44分 | step:  1640 | performance: 1.1 | accuracy: 0.29 | loss: -0.00
update:210/2000, 耗时:0.00分/0.45分 | step:  1680 | performance: 1.1 | accuracy: 0.28 | loss: -0.00
update:215/2000, 耗时:0.00分/0.46分 | step:  1720 | performance: 1.1 | accuracy: 0.27 | loss: -0.00
update:220/2000, 耗时:0.00分/0.47分 | step:  1760 | performance: 1.1 | accuracy: 0.27 | loss: 0.03
update:225/2000, 耗时:0.00分/0.48分 | step:  1800 | performance: 1.1 | accuracy: 0.27 | loss: 0.10
update:230/2000, 耗时:0.00分/0.50分 | step:  1840 | performance: 1.2 | accuracy: 0.27 | loss: 0.08
update:235/2000, 耗时:0.00分/0.51分 | step:  1880 | performance: 1.2 | accuracy: 0.26 | loss: -0.00
update:240/2000, 耗时:0.00分/0.52分 | step:  1920 | performance: 1.2 | accuracy: 0.26 | loss: 0.04
update:245/2000, 耗时:0.00分/0.53分 | step:  1960 | performance: 1.2 | accuracy: 0.25 | loss: -0.00
update:250/2000, 耗时:0.00分/0.54分 | step:  2000 | performance: 1.2 | accuracy: 0.25 | loss: 0.16
update:255/2000, 耗时:0.00分/0.55分 | step:  2040 | performance: 1.2 | accuracy: 0.25 | loss: 0.04
update:260/2000, 耗时:0.00分/0.57分 | step:  2080 | performance: 1.2 | accuracy: 0.25 | loss: 0.09
update:265/2000, 耗时:0.00分/0.58分 | step:  2120 | performance: 1.2 | accuracy: 0.24 | loss: 0.13
update:270/2000, 耗时:0.00分/0.59分 | step:  2160 | performance: 1.2 | accuracy: 0.24 | loss: -0.00
update:275/2000, 耗时:0.00分/0.60分 | step:  2200 | performance: 1.2 | accuracy: 0.24 | loss: 0.65
update:280/2000, 耗时:0.00分/0.61分 | step:  2240 | performance: 1.2 | accuracy: 0.24 | loss: 0.00
update:285/2000, 耗时:0.00分/0.62分 | step:  2280 | performance: 1.2 | accuracy: 0.23 | loss: 0.03
update:290/2000, 耗时:0.00分/0.64分 | step:  2320 | performance: 1.2 | accuracy: 0.23 | loss: 0.34
update:295/2000, 耗时:0.00分/0.65分 | step:  2360 | performance: 1.1 | accuracy: 0.23 | loss: 0.36
update:300/2000, 耗时:0.00分/0.66分 | step:  2400 | performance: 1.1 | accuracy: 0.24 | loss: 0.19
update:305/2000, 耗时:0.00分/0.67分 | step:  2440 | performance: 1.1 | accuracy: 0.24 | loss: 0.12
update:310/2000, 耗时:0.00分/0.68分 | step:  2480 | performance: 1.3 | accuracy: 0.24 | loss: 0.18
update:315/2000, 耗时:0.00分/0.69分 | step:  2520 | performance: 1.3 | accuracy: 0.24 | loss: 0.10
update:320/2000, 耗时:0.00分/0.71分 | step:  2560 | performance: 1.3 | accuracy: 0.24 | loss: 0.09
update:325/2000, 耗时:0.00分/0.72分 | step:  2600 | performance: 1.3 | accuracy: 0.24 | loss: 0.14
update:330/2000, 耗时:0.00分/0.73分 | step:  2640 | performance: 1.3 | accuracy: 0.24 | loss: 0.02
update:335/2000, 耗时:0.00分/0.74分 | step:  2680 | performance: 1.3 | accuracy: 0.23 | loss: -0.00
update:340/2000, 耗时:0.00分/0.76分 | step:  2720 | performance: 1.3 | accuracy: 0.23 | loss: 0.04
update:345/2000, 耗时:0.00分/0.77分 | step:  2760 | performance: 1.3 | accuracy: 0.23 | loss: 0.17
update:350/2000, 耗时:0.00分/0.78分 | step:  2800 | performance: 1.2 | accuracy: 0.23 | loss: 0.00
update:355/2000, 耗时:0.00分/0.79分 | step:  2840 | performance: 1.2 | accuracy: 0.22 | loss: -0.00
update:360/2000, 耗时:0.00分/0.80分 | step:  2880 | performance: 1.2 | accuracy: 0.22 | loss: 0.22
update:365/2000, 耗时:0.00分/0.81分 | step:  2920 | performance: 1.2 | accuracy: 0.22 | loss: 0.05
update:370/2000, 耗时:0.00分/0.83分 | step:  2960 | performance: 1.2 | accuracy: 0.22 | loss: 0.03
update:375/2000, 耗时:0.00分/0.84分 | step:  3000 | performance: 1.2 | accuracy: 0.21 | loss: 0.03
update:380/2000, 耗时:0.00分/0.85分 | step:  3040 | performance: 1.2 | accuracy: 0.22 | loss: 0.05
update:385/2000, 耗时:0.00分/0.86分 | step:  3080 | performance: 1.2 | accuracy: 0.21 | loss: 0.03
update:390/2000, 耗时:0.00分/0.87分 | step:  3120 | performance: 1.2 | accuracy: 0.22 | loss: 0.07
update:395/2000, 耗时:0.00分/0.89分 | step:  3160 | performance: 1.2 | accuracy: 0.22 | loss: -0.00
update:400/2000, 耗时:0.00分/0.90分 | step:  3200 | performance: 1.2 | accuracy: 0.21 | loss: -0.00
update:405/2000, 耗时:0.00分/0.91分 | step:  3240 | performance: 1.2 | accuracy: 0.21 | loss: -0.00
update:410/2000, 耗时:0.00分/0.92分 | step:  3280 | performance: 1.2 | accuracy: 0.21 | loss: 0.21
update:415/2000, 耗时:0.00分/0.93分 | step:  3320 | performance: 1.2 | accuracy: 0.21 | loss: 0.03
update:420/2000, 耗时:0.00分/0.94分 | step:  3360 | performance: 1.2 | accuracy: 0.21 | loss: 0.14
update:425/2000, 耗时:0.00分/0.96分 | step:  3400 | performance: 1.2 | accuracy: 0.21 | loss: 0.14
update:430/2000, 耗时:0.00分/0.97分 | step:  3440 | performance: 1.2 | accuracy: 0.20 | loss: -0.00
update:435/2000, 耗时:0.00分/0.98分 | step:  3480 | performance: 1.2 | accuracy: 0.20 | loss: 0.03
update:440/2000, 耗时:0.00分/0.99分 | step:  3520 | performance: 1.2 | accuracy: 0.20 | loss: 0.03
update:445/2000, 耗时:0.00分/1.00分 | step:  3560 | performance: 1.1 | accuracy: 0.20 | loss: 0.19
update:450/2000, 耗时:0.00分/1.01分 | step:  3600 | performance: 1.1 | accuracy: 0.20 | loss: 0.15
update:455/2000, 耗时:0.00分/1.02分 | step:  3640 | performance: 1.1 | accuracy: 0.20 | loss: 0.02
update:460/2000, 耗时:0.00分/1.04分 | step:  3680 | performance: 1.1 | accuracy: 0.20 | loss: 0.01
update:465/2000, 耗时:0.00分/1.05分 | step:  3720 | performance: 1.1 | accuracy: 0.20 | loss: 0.22
update:470/2000, 耗时:0.00分/1.06分 | step:  3760 | performance: 1.1 | accuracy: 0.20 | loss: 0.13
update:475/2000, 耗时:0.00分/1.07分 | step:  3800 | performance: 1.1 | accuracy: 0.20 | loss: -0.00
update:480/2000, 耗时:0.00分/1.08分 | step:  3840 | performance: 1.1 | accuracy: 0.19 | loss: 0.03
update:485/2000, 耗时:0.00分/1.09分 | step:  3880 | performance: 1.1 | accuracy: 0.19 | loss: 0.03
update:490/2000, 耗时:0.00分/1.11分 | step:  3920 | performance: 1.1 | accuracy: 0.19 | loss: -0.00
update:495/2000, 耗时:0.00分/1.12分 | step:  3960 | performance: 1.1 | accuracy: 0.19 | loss: -0.00
update:500/2000, 耗时:0.00分/1.13分 | step:  4000 | performance: 1.1 | accuracy: 0.19 | loss: 0.01
update:505/2000, 耗时:0.00分/1.14分 | step:  4040 | performance: 1.1 | accuracy: 0.19 | loss: 0.26
update:510/2000, 耗时:0.00分/1.15分 | step:  4080 | performance: 1.1 | accuracy: 0.19 | loss: 0.00
update:515/2000, 耗时:0.00分/1.16分 | step:  4120 | performance: 1.3 | accuracy: 0.19 | loss: 0.40
update:520/2000, 耗时:0.00分/1.17分 | step:  4160 | performance: 1.3 | accuracy: 0.19 | loss: 0.00
update:525/2000, 耗时:0.00分/1.19分 | step:  4200 | performance: 1.6 | accuracy: 0.20 | loss: 0.29
update:530/2000, 耗时:0.00分/1.20分 | step:  4240 | performance: 1.8 | accuracy: 0.20 | loss: 0.01
update:535/2000, 耗时:0.00分/1.21分 | step:  4280 | performance: 1.5 | accuracy: 0.19 | loss: 0.77
update:540/2000, 耗时:0.00分/1.22分 | step:  4320 | performance: 1.6 | accuracy: 0.19 | loss: 0.00
update:545/2000, 耗时:0.00分/1.23分 | step:  4360 | performance: 1.6 | accuracy: 0.19 | loss: 0.00
update:550/2000, 耗时:0.00分/1.24分 | step:  4400 | performance: 1.6 | accuracy: 0.19 | loss: 0.11
update:555/2000, 耗时:0.00分/1.26分 | step:  4440 | performance: 1.6 | accuracy: 0.19 | loss: 0.25
update:560/2000, 耗时:0.00分/1.27分 | step:  4480 | performance: 1.7 | accuracy: 0.19 | loss: -0.00
update:565/2000, 耗时:0.00分/1.28分 | step:  4520 | performance: 1.6 | accuracy: 0.19 | loss: 0.00
update:570/2000, 耗时:0.00分/1.29分 | step:  4560 | performance: 1.6 | accuracy: 0.19 | loss: 0.03
update:575/2000, 耗时:0.00分/1.30分 | step:  4600 | performance: 1.4 | accuracy: 0.18 | loss: -0.00
update:580/2000, 耗时:0.00分/1.31分 | step:  4640 | performance: 1.4 | accuracy: 0.18 | loss: 0.00
update:585/2000, 耗时:0.00分/1.33分 | step:  4680 | performance: 1.4 | accuracy: 0.18 | loss: -0.00
update:590/2000, 耗时:0.00分/1.34分 | step:  4720 | performance: 1.4 | accuracy: 0.18 | loss: 0.28
update:595/2000, 耗时:0.00分/1.35分 | step:  4760 | performance: 1.4 | accuracy: 0.18 | loss: 0.00
update:600/2000, 耗时:0.00分/1.36分 | step:  4800 | performance: 1.5 | accuracy: 0.18 | loss: -0.00
update:605/2000, 耗时:0.00分/1.37分 | step:  4840 | performance: 1.5 | accuracy: 0.18 | loss: -0.00
update:610/2000, 耗时:0.00分/1.38分 | step:  4880 | performance: 1.5 | accuracy: 0.18 | loss: -0.00
update:615/2000, 耗时:0.00分/1.40分 | step:  4920 | performance: 1.5 | accuracy: 0.18 | loss: -0.00
update:620/2000, 耗时:0.00分/1.41分 | step:  4960 | performance: 1.5 | accuracy: 0.18 | loss: 0.00
update:625/2000, 耗时:0.00分/1.42分 | step:  5000 | performance: 1.5 | accuracy: 0.17 | loss: 0.11
update:630/2000, 耗时:0.00分/1.43分 | step:  5040 | performance: 1.5 | accuracy: 0.17 | loss: 0.07
update:635/2000, 耗时:0.00分/1.44分 | step:  5080 | performance: 1.5 | accuracy: 0.17 | loss: -0.00
update:640/2000, 耗时:0.00分/1.46分 | step:  5120 | performance: 1.5 | accuracy: 0.17 | loss: 0.00
update:645/2000, 耗时:0.00分/1.47分 | step:  5160 | performance: 1.5 | accuracy: 0.17 | loss: 0.02
update:650/2000, 耗时:0.00分/1.48分 | step:  5200 | performance: 1.5 | accuracy: 0.17 | loss: -0.00
update:655/2000, 耗时:0.00分/1.49分 | step:  5240 | performance: 1.5 | accuracy: 0.17 | loss: 0.00
update:660/2000, 耗时:0.00分/1.50分 | step:  5280 | performance: 1.5 | accuracy: 0.17 | loss: 0.19
update:665/2000, 耗时:0.00分/1.52分 | step:  5320 | performance: 1.5 | accuracy: 0.17 | loss: -0.01
update:670/2000, 耗时:0.00分/1.53分 | step:  5360 | performance: 1.5 | accuracy: 0.17 | loss: -0.00
update:675/2000, 耗时:0.00分/1.54分 | step:  5400 | performance: 1.6 | accuracy: 0.17 | loss: 0.00
update:680/2000, 耗时:0.00分/1.55分 | step:  5440 | performance: 1.5 | accuracy: 0.17 | loss: 0.28
update:685/2000, 耗时:0.00分/1.56分 | step:  5480 | performance: 1.5 | accuracy: 0.17 | loss: 0.27
update:690/2000, 耗时:0.00分/1.58分 | step:  5520 | performance: 1.5 | accuracy: 0.17 | loss: -0.00
update:695/2000, 耗时:0.00分/1.59分 | step:  5560 | performance: 1.5 | accuracy: 0.17 | loss: 0.05
update:700/2000, 耗时:0.00分/1.60分 | step:  5600 | performance: 1.5 | accuracy: 0.17 | loss: 0.00
update:705/2000, 耗时:0.00分/1.61分 | step:  5640 | performance: 1.5 | accuracy: 0.17 | loss: 0.00
update:710/2000, 耗时:0.00分/1.62分 | step:  5680 | performance: 1.5 | accuracy: 0.17 | loss: 0.01
update:715/2000, 耗时:0.00分/1.64分 | step:  5720 | performance: 1.5 | accuracy: 0.17 | loss: 0.41
update:720/2000, 耗时:0.00分/1.65分 | step:  5760 | performance: 1.5 | accuracy: 0.17 | loss: -0.00
update:725/2000, 耗时:0.00分/1.66分 | step:  5800 | performance: 1.5 | accuracy: 0.17 | loss: 0.19
update:730/2000, 耗时:0.00分/1.67分 | step:  5840 | performance: 1.5 | accuracy: 0.17 | loss: -0.00
update:735/2000, 耗时:0.00分/1.68分 | step:  5880 | performance: 1.5 | accuracy: 0.17 | loss: -0.00
update:740/2000, 耗时:0.00分/1.70分 | step:  5920 | performance: 1.5 | accuracy: 0.17 | loss: 0.00
update:745/2000, 耗时:0.00分/1.71分 | step:  5960 | performance: 1.5 | accuracy: 0.17 | loss: 0.09
update:750/2000, 耗时:0.00分/1.72分 | step:  6000 | performance: 1.5 | accuracy: 0.17 | loss: -0.00
update:755/2000, 耗时:0.00分/1.73分 | step:  6040 | performance: 1.5 | accuracy: 0.17 | loss: 0.10
update:760/2000, 耗时:0.00分/1.74分 | step:  6080 | performance: 1.5 | accuracy: 0.17 | loss: 0.03
update:765/2000, 耗时:0.00分/1.76分 | step:  6120 | performance: 1.5 | accuracy: 0.17 | loss: 0.00
update:770/2000, 耗时:0.00分/1.77分 | step:  6160 | performance: 1.5 | accuracy: 0.17 | loss: 0.02
update:775/2000, 耗时:0.00分/1.78分 | step:  6200 | performance: 1.5 | accuracy: 0.17 | loss: 0.03
update:780/2000, 耗时:0.00分/1.79分 | step:  6240 | performance: 1.5 | accuracy: 0.17 | loss: 0.07
update:785/2000, 耗时:0.00分/1.80分 | step:  6280 | performance: 1.8 | accuracy: 0.17 | loss: 7.02
update:790/2000, 耗时:0.00分/1.82分 | step:  6320 | performance: 1.8 | accuracy: 0.17 | loss: 0.00
update:795/2000, 耗时:0.00分/1.83分 | step:  6360 | performance: 1.8 | accuracy: 0.17 | loss: -0.00
update:800/2000, 耗时:0.00分/1.84分 | step:  6400 | performance: 1.9 | accuracy: 0.17 | loss: 0.05
update:805/2000, 耗时:0.00分/1.85分 | step:  6440 | performance: 1.9 | accuracy: 0.17 | loss: 0.38
update:810/2000, 耗时:0.00分/1.86分 | step:  6480 | performance: 1.8 | accuracy: 0.17 | loss: 0.40
update:815/2000, 耗时:0.00分/1.87分 | step:  6520 | performance: 1.8 | accuracy: 0.17 | loss: 0.12
update:820/2000, 耗时:0.00分/1.88分 | step:  6560 | performance: 1.8 | accuracy: 0.17 | loss: 0.21
update:825/2000, 耗时:0.00分/1.89分 | step:  6600 | performance: 1.9 | accuracy: 0.17 | loss: 0.05
update:830/2000, 耗时:0.00分/1.91分 | step:  6640 | performance: 1.8 | accuracy: 0.17 | loss: 0.05
update:835/2000, 耗时:0.00分/1.92分 | step:  6680 | performance: 1.8 | accuracy: 0.17 | loss: 0.00
update:840/2000, 耗时:0.00分/1.93分 | step:  6720 | performance: 1.8 | accuracy: 0.17 | loss: 0.48
update:845/2000, 耗时:0.00分/1.94分 | step:  6760 | performance: 1.9 | accuracy: 0.17 | loss: 0.43
update:850/2000, 耗时:0.00分/1.95分 | step:  6800 | performance: 1.9 | accuracy: 0.17 | loss: 0.08
update:855/2000, 耗时:0.00分/1.96分 | step:  6840 | performance: 2.0 | accuracy: 0.17 | loss: 0.40
update:860/2000, 耗时:0.00分/1.97分 | step:  6880 | performance: 2.3 | accuracy: 0.18 | loss: 0.27
update:865/2000, 耗时:0.00分/1.98分 | step:  6920 | performance: 2.7 | accuracy: 0.18 | loss: 0.15
update:870/2000, 耗时:0.00分/1.99分 | step:  6960 | performance: 2.7 | accuracy: 0.18 | loss: 0.12
update:875/2000, 耗时:0.00分/2.00分 | step:  7000 | performance: 2.3 | accuracy: 0.18 | loss: 1.04
update:880/2000, 耗时:0.00分/2.02分 | step:  7040 | performance: 2.4 | accuracy: 0.18 | loss: 0.21
update:885/2000, 耗时:0.00分/2.03分 | step:  7080 | performance: 2.6 | accuracy: 0.19 | loss: 0.39
update:890/2000, 耗时:0.00分/2.04分 | step:  7120 | performance: 2.5 | accuracy: 0.19 | loss: 0.52
update:895/2000, 耗时:0.00分/2.05分 | step:  7160 | performance: 2.6 | accuracy: 0.19 | loss: 1.25
update:900/2000, 耗时:0.00分/2.06分 | step:  7200 | performance: 2.3 | accuracy: 0.19 | loss: 0.59
update:905/2000, 耗时:0.00分/2.07分 | step:  7240 | performance: 2.6 | accuracy: 0.19 | loss: 0.47
update:910/2000, 耗时:0.00分/2.08分 | step:  7280 | performance: 2.0 | accuracy: 0.19 | loss: 0.46
update:915/2000, 耗时:0.00分/2.09分 | step:  7320 | performance: 2.1 | accuracy: 0.19 | loss: 0.35
update:920/2000, 耗时:0.00分/2.10分 | step:  7360 | performance: 2.1 | accuracy: 0.19 | loss: 0.36
update:925/2000, 耗时:0.00分/2.12分 | step:  7400 | performance: 2.1 | accuracy: 0.19 | loss: 0.41
update:930/2000, 耗时:0.00分/2.13分 | step:  7440 | performance: 2.3 | accuracy: 0.20 | loss: 0.81
update:935/2000, 耗时:0.00分/2.14分 | step:  7480 | performance: 2.6 | accuracy: 0.20 | loss: 0.26
update:940/2000, 耗时:0.00分/2.15分 | step:  7520 | performance: 2.6 | accuracy: 0.20 | loss: 0.21
update:945/2000, 耗时:0.00分/2.16分 | step:  7560 | performance: 3.5 | accuracy: 0.21 | loss: 0.22
update:950/2000, 耗时:0.00分/2.17分 | step:  7600 | performance: 3.7 | accuracy: 0.21 | loss: 0.53
update:955/2000, 耗时:0.00分/2.18分 | step:  7640 | performance: 4.1 | accuracy: 0.21 | loss: 7.71
update:960/2000, 耗时:0.00分/2.19分 | step:  7680 | performance: 4.3 | accuracy: 0.21 | loss: 3.80
update:965/2000, 耗时:0.00分/2.21分 | step:  7720 | performance: 3.3 | accuracy: 0.21 | loss: 0.01
update:970/2000, 耗时:0.00分/2.22分 | step:  7760 | performance: 4.1 | accuracy: 0.21 | loss: 0.33
update:975/2000, 耗时:0.00分/2.23分 | step:  7800 | performance: 4.4 | accuracy: 0.22 | loss: 0.01
update:980/2000, 耗时:0.00分/2.24分 | step:  7840 | performance: 5.5 | accuracy: 0.22 | loss: 0.00
update:985/2000, 耗时:0.00分/2.25分 | step:  7880 | performance: 4.6 | accuracy: 0.22 | loss: 0.02
update:990/2000, 耗时:0.00分/2.26分 | step:  7920 | performance: 3.5 | accuracy: 0.22 | loss: 1.05
update:995/2000, 耗时:0.00分/2.27分 | step:  7960 | performance: 2.9 | accuracy: 0.22 | loss: 0.03
update:1000/2000, 耗时:0.00分/2.28分 | step:  8000 | performance: 3.2 | accuracy: 0.22 | loss: 0.59
update:1005/2000, 耗时:0.00分/2.30分 | step:  8040 | performance: 3.1 | accuracy: 0.22 | loss: 0.06
update:1010/2000, 耗时:0.00分/2.31分 | step:  8080 | performance: 2.8 | accuracy: 0.22 | loss: 0.47
update:1015/2000, 耗时:0.00分/2.32分 | step:  8120 | performance: 2.6 | accuracy: 0.22 | loss: 0.22
update:1020/2000, 耗时:0.00分/2.33分 | step:  8160 | performance: 2.5 | accuracy: 0.22 | loss: 0.41
update:1025/2000, 耗时:0.00分/2.34分 | step:  8200 | performance: 2.9 | accuracy: 0.23 | loss: 0.28
update:1030/2000, 耗时:0.00分/2.35分 | step:  8240 | performance: 2.8 | accuracy: 0.23 | loss: 0.53
update:1035/2000, 耗时:0.00分/2.37分 | step:  8280 | performance: 2.9 | accuracy: 0.23 | loss: 0.07
update:1040/2000, 耗时:0.00分/2.38分 | step:  8320 | performance: 3.1 | accuracy: 0.23 | loss: 0.28
update:1045/2000, 耗时:0.00分/2.39分 | step:  8360 | performance: 2.9 | accuracy: 0.23 | loss: 0.40
update:1050/2000, 耗时:0.00分/2.40分 | step:  8400 | performance: 2.5 | accuracy: 0.23 | loss: 0.43
update:1055/2000, 耗时:0.00分/2.41分 | step:  8440 | performance: 2.2 | accuracy: 0.23 | loss: 0.17
update:1060/2000, 耗时:0.00分/2.42分 | step:  8480 | performance: 2.3 | accuracy: 0.23 | loss: 0.04
update:1065/2000, 耗时:0.00分/2.43分 | step:  8520 | performance: 2.2 | accuracy: 0.23 | loss: 0.14
update:1070/2000, 耗时:0.00分/2.44分 | step:  8560 | performance: 2.2 | accuracy: 0.23 | loss: 0.30
update:1075/2000, 耗时:0.00分/2.45分 | step:  8600 | performance: 2.2 | accuracy: 0.23 | loss: 0.40
update:1080/2000, 耗时:0.00分/2.46分 | step:  8640 | performance: 2.0 | accuracy: 0.23 | loss: 0.18
update:1085/2000, 耗时:0.00分/2.48分 | step:  8680 | performance: 2.0 | accuracy: 0.23 | loss: 0.01
update:1090/2000, 耗时:0.00分/2.49分 | step:  8720 | performance: 2.2 | accuracy: 0.24 | loss: 0.60
update:1095/2000, 耗时:0.00分/2.50分 | step:  8760 | performance: 2.3 | accuracy: 0.24 | loss: -0.01
update:1100/2000, 耗时:0.00分/2.51分 | step:  8800 | performance: 2.1 | accuracy: 0.24 | loss: -0.02
update:1105/2000, 耗时:0.00分/2.52分 | step:  8840 | performance: 2.0 | accuracy: 0.24 | loss: 0.43
update:1110/2000, 耗时:0.00分/2.53分 | step:  8880 | performance: 2.1 | accuracy: 0.24 | loss: 0.29
update:1115/2000, 耗时:0.00分/2.54分 | step:  8920 | performance: 2.0 | accuracy: 0.24 | loss: 0.54
update:1120/2000, 耗时:0.00分/2.55分 | step:  8960 | performance: 2.0 | accuracy: 0.23 | loss: 0.01
update:1125/2000, 耗时:0.00分/2.56分 | step:  9000 | performance: 2.0 | accuracy: 0.23 | loss: 0.04
update:1130/2000, 耗时:0.00分/2.58分 | step:  9040 | performance: 2.0 | accuracy: 0.23 | loss: 0.02
update:1135/2000, 耗时:0.00分/2.59分 | step:  9080 | performance: 1.9 | accuracy: 0.23 | loss: 0.15
update:1140/2000, 耗时:0.00分/2.60分 | step:  9120 | performance: 1.9 | accuracy: 0.23 | loss: 0.04
update:1145/2000, 耗时:0.00分/2.61分 | step:  9160 | performance: 1.8 | accuracy: 0.23 | loss: 0.06
update:1150/2000, 耗时:0.00分/2.62分 | step:  9200 | performance: 1.8 | accuracy: 0.23 | loss: 0.01
update:1155/2000, 耗时:0.00分/2.63分 | step:  9240 | performance: 1.8 | accuracy: 0.23 | loss: 0.00
update:1160/2000, 耗时:0.00分/2.64分 | step:  9280 | performance: 1.8 | accuracy: 0.23 | loss: 0.07
update:1165/2000, 耗时:0.00分/2.65分 | step:  9320 | performance: 1.8 | accuracy: 0.23 | loss: 0.36
update:1170/2000, 耗时:0.00分/2.66分 | step:  9360 | performance: 1.8 | accuracy: 0.23 | loss: -0.00
update:1175/2000, 耗时:0.00分/2.67分 | step:  9400 | performance: 1.8 | accuracy: 0.23 | loss: -0.01
update:1180/2000, 耗时:0.00分/2.68分 | step:  9440 | performance: 1.8 | accuracy: 0.23 | loss: -0.00
update:1185/2000, 耗时:0.00分/2.70分 | step:  9480 | performance: 1.8 | accuracy: 0.23 | loss: 0.05
update:1190/2000, 耗时:0.00分/2.71分 | step:  9520 | performance: 1.8 | accuracy: 0.23 | loss: -0.00
update:1195/2000, 耗时:0.00分/2.72分 | step:  9560 | performance: 1.8 | accuracy: 0.23 | loss: 0.00
update:1200/2000, 耗时:0.00分/2.73分 | step:  9600 | performance: 2.0 | accuracy: 0.23 | loss: 0.00
update:1205/2000, 耗时:0.00分/2.74分 | step:  9640 | performance: 2.0 | accuracy: 0.23 | loss: 0.00
update:1210/2000, 耗时:0.00分/2.75分 | step:  9680 | performance: 2.0 | accuracy: 0.22 | loss: 0.09
update:1215/2000, 耗时:0.00分/2.76分 | step:  9720 | performance: 2.0 | accuracy: 0.22 | loss: 0.03
update:1220/2000, 耗时:0.00分/2.77分 | step:  9760 | performance: 2.0 | accuracy: 0.22 | loss: -0.00
update:1225/2000, 耗时:0.00分/2.78分 | step:  9800 | performance: 2.0 | accuracy: 0.22 | loss: 0.00
update:1230/2000, 耗时:0.00分/2.79分 | step:  9840 | performance: 2.0 | accuracy: 0.22 | loss: 0.08
update:1235/2000, 耗时:0.00分/2.80分 | step:  9880 | performance: 2.0 | accuracy: 0.22 | loss: -0.00
update:1240/2000, 耗时:0.00分/2.81分 | step:  9920 | performance: 2.0 | accuracy: 0.22 | loss: -0.00
update:1245/2000, 耗时:0.00分/2.83分 | step:  9960 | performance: 2.0 | accuracy: 0.22 | loss: -0.00
update:1250/2000, 耗时:0.00分/2.84分 | step: 10000 | performance: 2.0 | accuracy: 0.22 | loss: -0.00
update:1255/2000, 耗时:0.00分/2.85分 | step: 10040 | performance: 2.0 | accuracy: 0.22 | loss: 0.00
update:1260/2000, 耗时:0.00分/2.86分 | step: 10080 | performance: 2.0 | accuracy: 0.22 | loss: 0.00
update:1265/2000, 耗时:0.00分/2.87分 | step: 10120 | performance: 2.0 | accuracy: 0.22 | loss: -0.00
update:1270/2000, 耗时:0.00分/2.88分 | step: 10160 | performance: 2.0 | accuracy: 0.22 | loss: -0.00
update:1275/2000, 耗时:0.00分/2.89分 | step: 10200 | performance: 2.0 | accuracy: 0.22 | loss: -0.00
update:1280/2000, 耗时:0.00分/2.90分 | step: 10240 | performance: 2.1 | accuracy: 0.22 | loss: 0.00
update:1285/2000, 耗时:0.00分/2.91分 | step: 10280 | performance: 2.1 | accuracy: 0.22 | loss: 0.00
update:1290/2000, 耗时:0.00分/2.93分 | step: 10320 | performance: 2.0 | accuracy: 0.22 | loss: 0.00
update:1295/2000, 耗时:0.00分/2.94分 | step: 10360 | performance: 2.0 | accuracy: 0.22 | loss: 0.06
update:1300/2000, 耗时:0.00分/2.95分 | step: 10400 | performance: 2.0 | accuracy: 0.21 | loss: 0.00
update:1305/2000, 耗时:0.00分/2.96分 | step: 10440 | performance: 2.0 | accuracy: 0.21 | loss: 0.03
update:1310/2000, 耗时:0.00分/2.97分 | step: 10480 | performance: 2.0 | accuracy: 0.21 | loss: -0.00
update:1315/2000, 耗时:0.00分/2.98分 | step: 10520 | performance: 2.0 | accuracy: 0.21 | loss: -0.00
update:1320/2000, 耗时:0.00分/2.99分 | step: 10560 | performance: 2.0 | accuracy: 0.21 | loss: 0.01
update:1325/2000, 耗时:0.00分/3.00分 | step: 10600 | performance: 2.0 | accuracy: 0.21 | loss: -0.00
update:1330/2000, 耗时:0.00分/3.01分 | step: 10640 | performance: 2.0 | accuracy: 0.21 | loss: 0.00
update:1335/2000, 耗时:0.00分/3.03分 | step: 10680 | performance: 2.0 | accuracy: 0.21 | loss: 0.06
update:1340/2000, 耗时:0.00分/3.04分 | step: 10720 | performance: 2.0 | accuracy: 0.21 | loss: 0.01
update:1345/2000, 耗时:0.00分/3.05分 | step: 10760 | performance: 2.3 | accuracy: 0.21 | loss: 0.75
update:1350/2000, 耗时:0.00分/3.06分 | step: 10800 | performance: 2.1 | accuracy: 0.21 | loss: 0.00
update:1355/2000, 耗时:0.00分/3.07分 | step: 10840 | performance: 2.1 | accuracy: 0.21 | loss: 0.00
update:1360/2000, 耗时:0.00分/3.08分 | step: 10880 | performance: 2.0 | accuracy: 0.21 | loss: 0.00
update:1365/2000, 耗时:0.00分/3.09分 | step: 10920 | performance: 2.0 | accuracy: 0.21 | loss: 0.32
update:1370/2000, 耗时:0.00分/3.10分 | step: 10960 | performance: 2.0 | accuracy: 0.21 | loss: -0.00
update:1375/2000, 耗时:0.00分/3.11分 | step: 11000 | performance: 2.0 | accuracy: 0.21 | loss: 0.05
update:1380/2000, 耗时:0.00分/3.12分 | step: 11040 | performance: 2.0 | accuracy: 0.21 | loss: 0.00
update:1385/2000, 耗时:0.00分/3.13分 | step: 11080 | performance: 2.2 | accuracy: 0.21 | loss: 0.47
update:1390/2000, 耗时:0.00分/3.14分 | step: 11120 | performance: 2.3 | accuracy: 0.21 | loss: 0.00
update:1395/2000, 耗时:0.00分/3.16分 | step: 11160 | performance: 2.3 | accuracy: 0.21 | loss: 0.00
update:1400/2000, 耗时:0.00分/3.17分 | step: 11200 | performance: 2.2 | accuracy: 0.21 | loss: 0.03
update:1405/2000, 耗时:0.00分/3.18分 | step: 11240 | performance: 2.3 | accuracy: 0.21 | loss: 0.17
update:1410/2000, 耗时:0.00分/3.19分 | step: 11280 | performance: 2.2 | accuracy: 0.21 | loss: 0.37
update:1415/2000, 耗时:0.00分/3.20分 | step: 11320 | performance: 2.2 | accuracy: 0.21 | loss: -0.00
update:1420/2000, 耗时:0.00分/3.21分 | step: 11360 | performance: 2.1 | accuracy: 0.21 | loss: 0.00
update:1425/2000, 耗时:0.00分/3.22分 | step: 11400 | performance: 2.1 | accuracy: 0.21 | loss: 0.00
update:1430/2000, 耗时:0.00分/3.23分 | step: 11440 | performance: 2.1 | accuracy: 0.21 | loss: -0.00
update:1435/2000, 耗时:0.00分/3.24分 | step: 11480 | performance: 2.1 | accuracy: 0.21 | loss: 0.00
update:1440/2000, 耗时:0.00分/3.25分 | step: 11520 | performance: 2.0 | accuracy: 0.21 | loss: 0.25
update:1445/2000, 耗时:0.00分/3.26分 | step: 11560 | performance: 2.0 | accuracy: 0.21 | loss: -0.00
update:1450/2000, 耗时:0.00分/3.28分 | step: 11600 | performance: 2.0 | accuracy: 0.21 | loss: 0.00
update:1455/2000, 耗时:0.00分/3.29分 | step: 11640 | performance: 2.0 | accuracy: 0.21 | loss: 0.03
update:1460/2000, 耗时:0.00分/3.30分 | step: 11680 | performance: 2.0 | accuracy: 0.21 | loss: 0.00
update:1465/2000, 耗时:0.00分/3.31分 | step: 11720 | performance: 2.0 | accuracy: 0.21 | loss: 0.00
update:1470/2000, 耗时:0.00分/3.32分 | step: 11760 | performance: 2.0 | accuracy: 0.21 | loss: 0.00
update:1475/2000, 耗时:0.00分/3.33分 | step: 11800 | performance: 2.0 | accuracy: 0.21 | loss: 0.76
update:1480/2000, 耗时:0.00分/3.34分 | step: 11840 | performance: 2.0 | accuracy: 0.21 | loss: 0.00
update:1485/2000, 耗时:0.00分/3.35分 | step: 11880 | performance: 2.1 | accuracy: 0.21 | loss: 0.00
update:1490/2000, 耗时:0.00分/3.37分 | step: 11920 | performance: 1.8 | accuracy: 0.20 | loss: -0.00
update:1495/2000, 耗时:0.00分/3.38分 | step: 11960 | performance: 1.8 | accuracy: 0.20 | loss: 0.00
update:1500/2000, 耗时:0.00分/3.39分 | step: 12000 | performance: 1.8 | accuracy: 0.20 | loss: 0.00
update:1505/2000, 耗时:0.00分/3.40分 | step: 12040 | performance: 1.8 | accuracy: 0.20 | loss: -0.00
update:1510/2000, 耗时:0.00分/3.41分 | step: 12080 | performance: 1.8 | accuracy: 0.20 | loss: 0.03
update:1515/2000, 耗时:0.00分/3.42分 | step: 12120 | performance: 1.8 | accuracy: 0.20 | loss: -0.00
update:1520/2000, 耗时:0.00分/3.43分 | step: 12160 | performance: 1.8 | accuracy: 0.20 | loss: 0.00
update:1525/2000, 耗时:0.00分/3.44分 | step: 12200 | performance: 1.8 | accuracy: 0.20 | loss: -0.00
update:1530/2000, 耗时:0.00分/3.46分 | step: 12240 | performance: 1.8 | accuracy: 0.20 | loss: 0.00
update:1535/2000, 耗时:0.00分/3.47分 | step: 12280 | performance: 1.8 | accuracy: 0.20 | loss: 0.00
update:1540/2000, 耗时:0.00分/3.48分 | step: 12320 | performance: 1.8 | accuracy: 0.20 | loss: -0.00
update:1545/2000, 耗时:0.00分/3.49分 | step: 12360 | performance: 1.8 | accuracy: 0.20 | loss: 0.00
update:1550/2000, 耗时:0.00分/3.50分 | step: 12400 | performance: 1.8 | accuracy: 0.20 | loss: 0.06
update:1555/2000, 耗时:0.00分/3.51分 | step: 12440 | performance: 1.8 | accuracy: 0.20 | loss: 0.00
update:1560/2000, 耗时:0.00分/3.52分 | step: 12480 | performance: 1.8 | accuracy: 0.20 | loss: 0.00
update:1565/2000, 耗时:0.00分/3.53分 | step: 12520 | performance: 1.8 | accuracy: 0.19 | loss: -0.00
update:1570/2000, 耗时:0.00分/3.54分 | step: 12560 | performance: 1.8 | accuracy: 0.19 | loss: -0.00
update:1575/2000, 耗时:0.00分/3.56分 | step: 12600 | performance: 1.7 | accuracy: 0.19 | loss: 0.00
update:1580/2000, 耗时:0.00分/3.57分 | step: 12640 | performance: 1.7 | accuracy: 0.19 | loss: -0.00
update:1585/2000, 耗时:0.00分/3.58分 | step: 12680 | performance: 1.7 | accuracy: 0.19 | loss: -0.00
update:1590/2000, 耗时:0.00分/3.59分 | step: 12720 | performance: 1.7 | accuracy: 0.19 | loss: 0.00
update:1595/2000, 耗时:0.00分/3.60分 | step: 12760 | performance: 1.7 | accuracy: 0.19 | loss: 0.00
update:1600/2000, 耗时:0.00分/3.61分 | step: 12800 | performance: 1.7 | accuracy: 0.19 | loss: 0.07
update:1605/2000, 耗时:0.00分/3.62分 | step: 12840 | performance: 1.7 | accuracy: 0.19 | loss: 0.00
update:1610/2000, 耗时:0.00分/3.63分 | step: 12880 | performance: 1.7 | accuracy: 0.19 | loss: -0.00
update:1615/2000, 耗时:0.00分/3.64分 | step: 12920 | performance: 1.7 | accuracy: 0.19 | loss: 0.01
update:1620/2000, 耗时:0.00分/3.65分 | step: 12960 | performance: 1.7 | accuracy: 0.19 | loss: -0.00
update:1625/2000, 耗时:0.00分/3.66分 | step: 13000 | performance: 1.8 | accuracy: 0.19 | loss: -0.00
update:1630/2000, 耗时:0.00分/3.68分 | step: 13040 | performance: 1.8 | accuracy: 0.19 | loss: -0.00
update:1635/2000, 耗时:0.00分/3.69分 | step: 13080 | performance: 1.8 | accuracy: 0.19 | loss: 0.06
update:1640/2000, 耗时:0.00分/3.70分 | step: 13120 | performance: 1.8 | accuracy: 0.19 | loss: 0.17
update:1645/2000, 耗时:0.00分/3.71分 | step: 13160 | performance: 1.8 | accuracy: 0.19 | loss: 0.03
update:1650/2000, 耗时:0.00分/3.72分 | step: 13200 | performance: 1.8 | accuracy: 0.19 | loss: 0.23
update:1655/2000, 耗时:0.00分/3.73分 | step: 13240 | performance: 1.7 | accuracy: 0.19 | loss: 0.27
update:1660/2000, 耗时:0.00分/3.74分 | step: 13280 | performance: 1.7 | accuracy: 0.19 | loss: 0.00
update:1665/2000, 耗时:0.00分/3.76分 | step: 13320 | performance: 1.8 | accuracy: 0.19 | loss: 0.02
update:1670/2000, 耗时:0.00分/3.77分 | step: 13360 | performance: 1.8 | accuracy: 0.19 | loss: 0.02
update:1675/2000, 耗时:0.00分/3.78分 | step: 13400 | performance: 1.8 | accuracy: 0.19 | loss: -0.00
update:1680/2000, 耗时:0.00分/3.79分 | step: 13440 | performance: 1.9 | accuracy: 0.19 | loss: 0.03
update:1685/2000, 耗时:0.00分/3.80分 | step: 13480 | performance: 1.8 | accuracy: 0.19 | loss: -0.01
update:1690/2000, 耗时:0.00分/3.81分 | step: 13520 | performance: 1.8 | accuracy: 0.19 | loss: -0.00
update:1695/2000, 耗时:0.00分/3.82分 | step: 13560 | performance: 1.8 | accuracy: 0.19 | loss: 0.03
update:1700/2000, 耗时:0.00分/3.83分 | step: 13600 | performance: 1.8 | accuracy: 0.19 | loss: 0.00
update:1705/2000, 耗时:0.00分/3.85分 | step: 13640 | performance: 1.9 | accuracy: 0.19 | loss: 0.16
update:1710/2000, 耗时:0.00分/3.86分 | step: 13680 | performance: 1.9 | accuracy: 0.19 | loss: -0.00
update:1715/2000, 耗时:0.00分/3.87分 | step: 13720 | performance: 1.9 | accuracy: 0.19 | loss: -0.00
update:1720/2000, 耗时:0.00分/3.88分 | step: 13760 | performance: 1.9 | accuracy: 0.19 | loss: 0.02
update:1725/2000, 耗时:0.00分/3.89分 | step: 13800 | performance: 1.9 | accuracy: 0.19 | loss: 0.05
update:1730/2000, 耗时:0.00分/3.90分 | step: 13840 | performance: 1.9 | accuracy: 0.19 | loss: 0.07
update:1735/2000, 耗时:0.00分/3.91分 | step: 13880 | performance: 1.9 | accuracy: 0.19 | loss: 0.26
update:1740/2000, 耗时:0.00分/3.92分 | step: 13920 | performance: 1.9 | accuracy: 0.19 | loss: 0.00
update:1745/2000, 耗时:0.00分/3.93分 | step: 13960 | performance: 1.9 | accuracy: 0.19 | loss: -0.00
update:1750/2000, 耗时:0.00分/3.95分 | step: 14000 | performance: 1.8 | accuracy: 0.19 | loss: -0.00
update:1755/2000, 耗时:0.00分/3.96分 | step: 14040 | performance: 1.8 | accuracy: 0.19 | loss: 0.03
update:1760/2000, 耗时:0.00分/3.97分 | step: 14080 | performance: 2.0 | accuracy: 0.19 | loss: 0.22
update:1765/2000, 耗时:0.00分/3.98分 | step: 14120 | performance: 2.0 | accuracy: 0.19 | loss: -0.00
update:1770/2000, 耗时:0.00分/3.99分 | step: 14160 | performance: 2.0 | accuracy: 0.19 | loss: 0.03
update:1775/2000, 耗时:0.00分/4.00分 | step: 14200 | performance: 2.0 | accuracy: 0.19 | loss: 0.14
update:1780/2000, 耗时:0.00分/4.01分 | step: 14240 | performance: 2.0 | accuracy: 0.19 | loss: 0.12
update:1785/2000, 耗时:0.00分/4.02分 | step: 14280 | performance: 2.0 | accuracy: 0.19 | loss: 0.09
update:1790/2000, 耗时:0.00分/4.03分 | step: 14320 | performance: 2.1 | accuracy: 0.19 | loss: 0.12
update:1795/2000, 耗时:0.00分/4.04分 | step: 14360 | performance: 2.1 | accuracy: 0.19 | loss: 0.12
update:1800/2000, 耗时:0.00分/4.05分 | step: 14400 | performance: 2.1 | accuracy: 0.19 | loss: 0.48
update:1805/2000, 耗时:0.00分/4.06分 | step: 14440 | performance: 2.0 | accuracy: 0.19 | loss: 0.54
update:1810/2000, 耗时:0.00分/4.08分 | step: 14480 | performance: 2.0 | accuracy: 0.19 | loss: 0.17
update:1815/2000, 耗时:0.00分/4.09分 | step: 14520 | performance: 2.1 | accuracy: 0.19 | loss: 0.08
update:1820/2000, 耗时:0.00分/4.10分 | step: 14560 | performance: 2.1 | accuracy: 0.19 | loss: 0.26
update:1825/2000, 耗时:0.00分/4.11分 | step: 14600 | performance: 1.8 | accuracy: 0.19 | loss: 0.37
update:1830/2000, 耗时:0.00分/4.12分 | step: 14640 | performance: 1.8 | accuracy: 0.19 | loss: -0.00
update:1835/2000, 耗时:0.00分/4.13分 | step: 14680 | performance: 1.9 | accuracy: 0.19 | loss: 0.20
update:1840/2000, 耗时:0.00分/4.14分 | step: 14720 | performance: 1.9 | accuracy: 0.19 | loss: 0.11
update:1845/2000, 耗时:0.00分/4.15分 | step: 14760 | performance: 1.8 | accuracy: 0.19 | loss: 0.27
update:1850/2000, 耗时:0.00分/4.16分 | step: 14800 | performance: 1.9 | accuracy: 0.19 | loss: 0.57
update:1855/2000, 耗时:0.00分/4.18分 | step: 14840 | performance: 1.9 | accuracy: 0.19 | loss: 0.26
update:1860/2000, 耗时:0.00分/4.19分 | step: 14880 | performance: 1.7 | accuracy: 0.19 | loss: 0.23
update:1865/2000, 耗时:0.00分/4.20分 | step: 14920 | performance: 1.8 | accuracy: 0.19 | loss: 0.27
update:1870/2000, 耗时:0.00分/4.21分 | step: 14960 | performance: 1.8 | accuracy: 0.19 | loss: 0.52
update:1875/2000, 耗时:0.00分/4.22分 | step: 15000 | performance: 1.8 | accuracy: 0.19 | loss: 0.18
update:1880/2000, 耗时:0.00分/4.23分 | step: 15040 | performance: 1.8 | accuracy: 0.19 | loss: 0.08
update:1885/2000, 耗时:0.00分/4.24分 | step: 15080 | performance: 1.8 | accuracy: 0.19 | loss: 0.21
update:1890/2000, 耗时:0.00分/4.25分 | step: 15120 | performance: 1.8 | accuracy: 0.20 | loss: 0.39
update:1895/2000, 耗时:0.00分/4.26分 | step: 15160 | performance: 2.0 | accuracy: 0.20 | loss: 0.00
update:1900/2000, 耗时:0.00分/4.28分 | step: 15200 | performance: 2.0 | accuracy: 0.20 | loss: 1.08
update:1905/2000, 耗时:0.00分/4.29分 | step: 15240 | performance: 2.1 | accuracy: 0.20 | loss: 0.01
update:1910/2000, 耗时:0.00分/4.30分 | step: 15280 | performance: 2.1 | accuracy: 0.20 | loss: 0.04
update:1915/2000, 耗时:0.00分/4.31分 | step: 15320 | performance: 2.1 | accuracy: 0.20 | loss: 0.02
update:1920/2000, 耗时:0.00分/4.32分 | step: 15360 | performance: 2.3 | accuracy: 0.20 | loss: 0.01
update:1925/2000, 耗时:0.00分/4.33分 | step: 15400 | performance: 2.3 | accuracy: 0.20 | loss: 0.09
update:1930/2000, 耗时:0.00分/4.34分 | step: 15440 | performance: 2.4 | accuracy: 0.20 | loss: 0.53
update:1935/2000, 耗时:0.00分/4.36分 | step: 15480 | performance: 2.5 | accuracy: 0.20 | loss: 0.31
update:1940/2000, 耗时:0.00分/4.37分 | step: 15520 | performance: 2.6 | accuracy: 0.20 | loss: 0.27
update:1945/2000, 耗时:0.00分/4.38分 | step: 15560 | performance: 2.6 | accuracy: 0.20 | loss: 0.29
update:1950/2000, 耗时:0.00分/4.39分 | step: 15600 | performance: 2.8 | accuracy: 0.20 | loss: 0.07
update:1955/2000, 耗时:0.00分/4.40分 | step: 15640 | performance: 2.8 | accuracy: 0.20 | loss: 0.01
update:1960/2000, 耗时:0.00分/4.41分 | step: 15680 | performance: 2.8 | accuracy: 0.20 | loss: 0.25
update:1965/2000, 耗时:0.00分/4.43分 | step: 15720 | performance: 2.8 | accuracy: 0.21 | loss: 0.56
update:1970/2000, 耗时:0.00分/4.44分 | step: 15760 | performance: 2.8 | accuracy: 0.21 | loss: 0.37
update:1975/2000, 耗时:0.00分/4.45分 | step: 15800 | performance: 3.3 | accuracy: 0.21 | loss: 0.10
update:1980/2000, 耗时:0.00分/4.46分 | step: 15840 | performance: 3.6 | accuracy: 0.21 | loss: 0.12
update:1985/2000, 耗时:0.00分/4.47分 | step: 15880 | performance: 3.5 | accuracy: 0.21 | loss: 0.88
update:1990/2000, 耗时:0.00分/4.48分 | step: 15920 | performance: 3.3 | accuracy: 0.21 | loss: 1.48
update:1995/2000, 耗时:0.00分/4.50分 | step: 15960 | performance: 3.1 | accuracy: 0.21 | loss: 0.17
update:2000/2000, 耗时:0.00分/4.51分 | step: 16000 | performance: 3.7 | accuracy: 0.21 | loss: 0.24
----------------------------------------finished----------------------------------------
  0%|          | 0/406 [00:00<?, ?it/s]100%|| 406/406 [00:00<00:00, 101356.31it/s]
==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1714.24
2023-07-24T12:00:00 | net performance [%] = 71.4236
2023-07-24T12:00:00 | number of trades [#] = 2
==================================================
Trial 16 Complete [00h 04m 57s]
net_wealth: 1715.952446010363

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 02h 08m 11s

Search: Running Trial #17

Value             |Best Value So Far |Hyperparameter
4                 |1                 |horizon
365               |730               |lookback
False             |False             |MarketFactor
10                |3                 |lags
0.6               |0.92              |gamma
16                |32                |batch_size
10                |1                 |n_step
0.85              |0.94              |gae_lambda
2                 |5                 |gradient_clip_norm
5                 |5                 |epochs
0.0005            |0.0001            |actor_lr
5e-05             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4311.000000   4315.000000
mean      0.000441    20062.255222  ...   20133.281642  20118.633889
std       0.027818    16039.874230  ...   16077.358923  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7695.614990   7690.540039
50%       0.000642    11554.824463  ...   11741.480469  11715.610352
75%       0.011655    29873.081836  ...   29939.474609  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 00:11:33.716304: I tensorflow2023-07-28 00:11:33.716330: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instruc2202023-07-283/ c-20702023-07-28 00:11:33.716435: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neura0tions -2l2 3-08N7 -00:11:330.28 0e7t1:1160:w4o2011:r:k:33 3I3 .teo.71ns r6e3o0r4Lib:/frarylow/c oIprle /p ain performance-critical operations:  AVX AVX2
To enable them in other operations, rebu7(oneDNN) to use th1la6tieltfd4o rmTen4/c6s:o puIr _feFtealntow wit2sortform/cpuure_hn thee fol _fealoswtgfoiunrge_ ulgCroaardpPpU.cc0w uir/ocpa2rnsro:f3142i]2 tdrT.atruccl0ohewc/:1ec2o tionrce/3s 4po2-lat0-0mpii7s7-2fn-i8o rp2 0]0: T8 1/ plhie10a:33s.trf TeTn0fo7oe1674:19rs1o:lens:3morrF lowfla3 gI tenrFlsoor bsw.if
lown /bacinaorymry is op rr/e/pctimpliis atfoozurpe_mftd/ wimcpu_.it/featurchea7e_g1ituu6 ro8nza6rd.2cceAPI:edm Dee_gpu wi1ue4p2:_atrh d] featureNaence-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the I teural N.cc:nesappropriat_ 1twore compiler flaggk Library (oneDNN) to use the following CPU instructions in performance-critical operas42].
orflouat  TwoirThd.ichcs Teons:  nsorFlow binary is optimized wi:142] This TensorFltneh oneAPI D/Aeep core/owAPpVli sb NTeeural Network LnIinary iisorFlow biaX AVX2tfbnsa ryoor rmpis optary (oneDNN) to use the fimized with oneAPI Deep Neural Networo/cllotimized wiwk Li Deep Neural Network Liitbrng 
Tbahr oneAy (oneDNN) to use the following pPu_foI Deep Neural Network LCeCPU instrPU iatbraururayr ee_n c(try (ioiguoonnsaaner nstbdier.ucc:14cDNNle) tno2 ]th  usteDp eeirfTNN) t tons in performance-co use the folormance-critical operatihhroenii sfotmlli:  oAVcal X Al iwooVperations: n X2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
wins ig CPT enostheng oU insrFlow binartAVX AVXrr ouctCPyiUo perations, rebuild TensorFlow winnstruc2
T iotti oenishns  sthae ibnle  appropria inperfoortm ptpaenimizede c ew-ithcrr itfhoretic ooneAPI Deep Nm immcaanen pulcoi loraetphlereer-r Nect  rflaotwiags.
ork Library (oneDNN) to use ttperationiheicaonlss ,:o   rebuildA TensorFlow with the appropriate comVpiler Xfollp ef lagsrations:  .AA
VVX2
To X AVX2
To enablenable them in other ooe them in poerations, rebuild TensorFlther ow with operatiothewin appropriate cong Cs,mPU instr rebuild TensorFlow witupiler flags.
ctions in perforh the appropriate compiler flags.mance-critical operations:  AVX AVX2
To enable them in other operations, rebuild T
ensorFlow with the appropriate compiler flags.
2023-07-28 00:11:34.346121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:11:34.353378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:11:34.358767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:11:34.359637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:11:34.359836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:11:34.371564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:11:34.375360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:11:34.379237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
Saving PPO weights in both H5 format and checkpoint @ update:2 
update:  5/2000, 耗时:0.00分/0.04分 | step:   400 | performance: 0.7 | accuracy: 0.28 | loss: 0.85
update: 10/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 0.5 | accuracy: 0.34 | loss: 1.31
update: 15/2000, 耗时:0.00分/0.07分 | step:  1200 | performance: 0.8 | accuracy: 0.40 | loss: 0.78
update: 20/2000, 耗时:0.00分/0.08分 | step:  1600 | performance: 1.7 | accuracy: 0.44 | loss: 2.10
update: 25/2000, 耗时:0.00分/0.10分 | step:  2000 | performance: 2.2 | accuracy: 0.45 | loss: 0.89
update: 30/2000, 耗时:0.00分/0.11分 | step:  2400 | performance: 1.8 | accuracy: 0.44 | loss: 1.09
update: 35/2000, 耗时:0.00分/0.13分 | step:  2800 | performance: 1.9 | accuracy: 0.44 | loss: 0.76
update: 40/2000, 耗时:0.00分/0.14分 | step:  3200 | performance: 2.4 | accuracy: 0.43 | loss: 1.10
update: 45/2000, 耗时:0.00分/0.16分 | step:  3600 | performance: 2.5 | accuracy: 0.43 | loss: 1.46
update: 50/2000, 耗时:0.00分/0.18分 | step:  4000 | performance: 1.8 | accuracy: 0.42 | loss: 1.66
update: 55/2000, 耗时:0.00分/0.20分 | step:  4400 | performance: 13.0 | accuracy: 0.45 | loss: 2.62
update: 60/2000, 耗时:0.00分/0.21分 | step:  4800 | performance: 20.0 | accuracy: 0.46 | loss: 2.04
update: 65/2000, 耗时:0.00分/0.23分 | step:  5200 | performance: 24.5 | accuracy: 0.46 | loss: 1.38
update: 70/2000, 耗时:0.00分/0.25分 | step:  5600 | performance: 23.9 | accuracy: 0.46 | loss: 1.24
update: 75/2000, 耗时:0.00分/0.27分 | step:  6000 | performance: 20.5 | accuracy: 0.46 | loss: 1.15
update: 80/2000, 耗时:0.00分/0.28分 | step:  6400 | performance: 7.8 | accuracy: 0.45 | loss: 1.90
update: 85/2000, 耗时:0.00分/0.30分 | step:  6800 | performance: 8.6 | accuracy: 0.45 | loss: 0.70
update: 90/2000, 耗时:0.00分/0.32分 | step:  7200 | performance: 48.6 | accuracy: 0.46 | loss: 1.62
update: 95/2000, 耗时:0.00分/0.34分 | step:  7600 | performance: 78.3 | accuracy: 0.47 | loss: 0.90
update:100/2000, 耗时:0.00分/0.36分 | step:  8000 | performance: 95.6 | accuracy: 0.47 | loss: 2.69
update:105/2000, 耗时:0.00分/0.37分 | step:  8400 | performance: 143.9 | accuracy: 0.48 | loss: 1.21
update:110/2000, 耗时:0.00分/0.39分 | step:  8800 | performance: 83.2 | accuracy: 0.47 | loss: 0.65
update:115/2000, 耗时:0.00分/0.41分 | step:  9200 | performance: 45.5 | accuracy: 0.46 | loss: 0.54
update:120/2000, 耗时:0.00分/0.43分 | step:  9600 | performance: 62.9 | accuracy: 0.46 | loss: 1.26
update:125/2000, 耗时:0.00分/0.44分 | step: 10000 | performance: 34.1 | accuracy: 0.46 | loss: 0.78
update:130/2000, 耗时:0.00分/0.46分 | step: 10400 | performance: 59.4 | accuracy: 0.47 | loss: 1.42
update:135/2000, 耗时:0.00分/0.48分 | step: 10800 | performance: 45.0 | accuracy: 0.47 | loss: 2.62
update:140/2000, 耗时:0.00分/0.50分 | step: 11200 | performance: 30.6 | accuracy: 0.46 | loss: 1.14
update:145/2000, 耗时:0.00分/0.52分 | step: 11600 | performance: 31.5 | accuracy: 0.46 | loss: 0.88
update:150/2000, 耗时:0.00分/0.53分 | step: 12000 | performance: 41.7 | accuracy: 0.46 | loss: 3.20
update:155/2000, 耗时:0.00分/0.55分 | step: 12400 | performance: 18.9 | accuracy: 0.45 | loss: 0.60
update:160/2000, 耗时:0.00分/0.57分 | step: 12800 | performance: 17.8 | accuracy: 0.45 | loss: 2.20
update:165/2000, 耗时:0.00分/0.59分 | step: 13200 | performance: 14.2 | accuracy: 0.45 | loss: 0.55
update:170/2000, 耗时:0.00分/0.60分 | step: 13600 | performance: 12.2 | accuracy: 0.44 | loss: 0.20
update:175/2000, 耗时:0.00分/0.62分 | step: 14000 | performance: 11.9 | accuracy: 0.43 | loss: 0.26
update:180/2000, 耗时:0.00分/0.64分 | step: 14400 | performance: 13.1 | accuracy: 0.43 | loss: 0.50
update:185/2000, 耗时:0.00分/0.66分 | step: 14800 | performance: 10.9 | accuracy: 0.42 | loss: 0.06
update:190/2000, 耗时:0.00分/0.68分 | step: 15200 | performance: 9.9 | accuracy: 0.42 | loss: 0.49
update:195/2000, 耗时:0.00分/0.69分 | step: 15600 | performance: 19.3 | accuracy: 0.42 | loss: 1.26
update:200/2000, 耗时:0.00分/0.71分 | step: 16000 | performance: 45.3 | accuracy: 0.43 | loss: 2.10
update:205/2000, 耗时:0.00分/0.73分 | step: 16400 | performance: 144.8 | accuracy: 0.43 | loss: 1.41
update:210/2000, 耗时:0.00分/0.75分 | step: 16800 | performance: 925.0 | accuracy: 0.44 | loss: 1.90
update:215/2000, 耗时:0.00分/0.76分 | step: 17200 | performance: 2083.7 | accuracy: 0.44 | loss: 1.53
update:220/2000, 耗时:0.00分/0.78分 | step: 17600 | performance: 2684.5 | accuracy: 0.45 | loss: 2.15
update:225/2000, 耗时:0.00分/0.80分 | step: 18000 | performance: 4921.8 | accuracy: 0.45 | loss: 1.45
update:230/2000, 耗时:0.00分/0.82分 | step: 18400 | performance: 2808.6 | accuracy: 0.45 | loss: 2.47
update:235/2000, 耗时:0.00分/0.84分 | step: 18800 | performance: 952.9 | accuracy: 0.45 | loss: 2.56
update:240/2000, 耗时:0.00分/0.85分 | step: 19200 | performance: 1007.9 | accuracy: 0.45 | loss: 1.75
update:245/2000, 耗时:0.00分/0.87分 | step: 19600 | performance: 473.6 | accuracy: 0.45 | loss: 1.19
update:250/2000, 耗时:0.00分/0.89分 | step: 20000 | performance: 862.0 | accuracy: 0.45 | loss: 1.92
update:255/2000, 耗时:0.00分/0.91分 | step: 20400 | performance: 2112.2 | accuracy: 0.45 | loss: 1.28
update:260/2000, 耗时:0.00分/0.92分 | step: 20800 | performance: 1270.1 | accuracy: 0.45 | loss: 1.94
update:265/2000, 耗时:0.00分/0.94分 | step: 21200 | performance: 4361.6 | accuracy: 0.46 | loss: 1.44
update:270/2000, 耗时:0.00分/0.96分 | step: 21600 | performance: 4868.8 | accuracy: 0.46 | loss: 1.41
update:275/2000, 耗时:0.00分/0.98分 | step: 22000 | performance: 2174.1 | accuracy: 0.45 | loss: 1.76
update:280/2000, 耗时:0.00分/1.00分 | step: 22400 | performance: 1668.7 | accuracy: 0.45 | loss: 1.32
update:285/2000, 耗时:0.00分/1.01分 | step: 22800 | performance: 654.6 | accuracy: 0.45 | loss: 0.89
update:290/2000, 耗时:0.00分/1.03分 | step: 23200 | performance: 717.6 | accuracy: 0.45 | loss: 2.42
update:295/2000, 耗时:0.00分/1.05分 | step: 23600 | performance: 782.4 | accuracy: 0.45 | loss: 1.55
update:300/2000, 耗时:0.00分/1.07分 | step: 24000 | performance: 784.3 | accuracy: 0.45 | loss: 1.89
update:305/2000, 耗时:0.00分/1.09分 | step: 24400 | performance: 531.2 | accuracy: 0.45 | loss: 0.87
update:310/2000, 耗时:0.00分/1.10分 | step: 24800 | performance: 143.3 | accuracy: 0.45 | loss: 0.87
update:315/2000, 耗时:0.00分/1.12分 | step: 25200 | performance: 142.7 | accuracy: 0.44 | loss: 1.40
update:320/2000, 耗时:0.00分/1.14分 | step: 25600 | performance: 118.9 | accuracy: 0.44 | loss: 1.39
update:325/2000, 耗时:0.00分/1.16分 | step: 26000 | performance: 128.7 | accuracy: 0.44 | loss: 0.45
update:330/2000, 耗时:0.00分/1.18分 | step: 26400 | performance: 159.2 | accuracy: 0.44 | loss: 0.82
update:335/2000, 耗时:0.00分/1.19分 | step: 26800 | performance: 127.6 | accuracy: 0.44 | loss: 0.67
update:340/2000, 耗时:0.00分/1.21分 | step: 27200 | performance: 113.6 | accuracy: 0.44 | loss: 1.10
update:345/2000, 耗时:0.00分/1.23分 | step: 27600 | performance: 284.0 | accuracy: 0.44 | loss: 1.30
update:350/2000, 耗时:0.00分/1.25分 | step: 28000 | performance: 228.3 | accuracy: 0.44 | loss: 1.26
Saving PPO weights in both H5 format and checkpoint @ update:354 
update:355/2000, 耗时:0.00分/1.27分 | step: 28400 | performance: 1.0 | accuracy: 0.39 | loss: 0.79
Saving PPO weights in both H5 format and checkpoint @ update:355 
update:360/2000, 耗时:0.00分/1.29分 | step: 28800 | performance: 2.8 | accuracy: 0.47 | loss: 1.53
update:365/2000, 耗时:0.00分/1.31分 | step: 29200 | performance: 0.8 | accuracy: 0.38 | loss: 1.06
update:370/2000, 耗时:0.00分/1.33分 | step: 29600 | performance: 1.9 | accuracy: 0.42 | loss: 1.63
update:375/2000, 耗时:0.00分/1.35分 | step: 30000 | performance: 3.1 | accuracy: 0.44 | loss: 1.42
update:380/2000, 耗时:0.00分/1.36分 | step: 30400 | performance: 4.0 | accuracy: 0.45 | loss: 1.04
update:385/2000, 耗时:0.00分/1.38分 | step: 30800 | performance: 4.2 | accuracy: 0.46 | loss: 1.44
update:390/2000, 耗时:0.00分/1.40分 | step: 31200 | performance: 2.6 | accuracy: 0.44 | loss: 1.19
update:395/2000, 耗时:0.00分/1.42分 | step: 31600 | performance: 4.2 | accuracy: 0.44 | loss: 1.30
update:400/2000, 耗时:0.00分/1.43分 | step: 32000 | performance: 4.6 | accuracy: 0.45 | loss: 0.99
update:405/2000, 耗时:0.00分/1.45分 | step: 32400 | performance: 8.8 | accuracy: 0.46 | loss: 1.77
update:410/2000, 耗时:0.00分/1.47分 | step: 32800 | performance: 69.5 | accuracy: 0.49 | loss: 0.99
update:415/2000, 耗时:0.00分/1.49分 | step: 33200 | performance: 45.3 | accuracy: 0.48 | loss: 1.18
update:420/2000, 耗时:0.00分/1.51分 | step: 33600 | performance: 74.5 | accuracy: 0.48 | loss: 1.11
update:425/2000, 耗时:0.00分/1.52分 | step: 34000 | performance: 48.5 | accuracy: 0.48 | loss: 1.02
update:430/2000, 耗时:0.00分/1.54分 | step: 34400 | performance: 44.8 | accuracy: 0.47 | loss: 1.00
update:435/2000, 耗时:0.00分/1.56分 | step: 34800 | performance: 17.4 | accuracy: 0.46 | loss: 0.85
update:440/2000, 耗时:0.00分/1.58分 | step: 35200 | performance: 24.1 | accuracy: 0.46 | loss: 1.31
update:445/2000, 耗时:0.00分/1.60分 | step: 35600 | performance: 44.2 | accuracy: 0.46 | loss: 2.11
update:450/2000, 耗时:0.00分/1.62分 | step: 36000 | performance: 205.5 | accuracy: 0.47 | loss: 1.68
update:455/2000, 耗时:0.00分/1.63分 | step: 36400 | performance: 102.1 | accuracy: 0.47 | loss: 1.89
update:460/2000, 耗时:0.00分/1.65分 | step: 36800 | performance: 135.7 | accuracy: 0.48 | loss: 0.98
update:465/2000, 耗时:0.00分/1.67分 | step: 37200 | performance: 116.4 | accuracy: 0.48 | loss: 1.51
update:470/2000, 耗时:0.00分/1.69分 | step: 37600 | performance: 77.6 | accuracy: 0.48 | loss: 1.43
update:475/2000, 耗时:0.00分/1.71分 | step: 38000 | performance: 49.1 | accuracy: 0.48 | loss: 1.46
update:480/2000, 耗时:0.00分/1.72分 | step: 38400 | performance: 138.8 | accuracy: 0.49 | loss: 1.16
update:485/2000, 耗时:0.00分/1.74分 | step: 38800 | performance: 146.7 | accuracy: 0.49 | loss: 1.16
update:490/2000, 耗时:0.00分/1.76分 | step: 39200 | performance: 72.1 | accuracy: 0.48 | loss: 1.77
update:495/2000, 耗时:0.00分/1.78分 | step: 39600 | performance: 54.7 | accuracy: 0.48 | loss: 0.53
update:500/2000, 耗时:0.00分/1.80分 | step: 40000 | performance: 24.9 | accuracy: 0.47 | loss: 0.85
update:505/2000, 耗时:0.00分/1.82分 | step: 40400 | performance: 34.1 | accuracy: 0.47 | loss: 1.49
update:510/2000, 耗时:0.00分/1.83分 | step: 40800 | performance: 21.7 | accuracy: 0.46 | loss: 0.36
update:515/2000, 耗时:0.00分/1.85分 | step: 41200 | performance: 38.0 | accuracy: 0.46 | loss: 1.15
update:520/2000, 耗时:0.00分/1.87分 | step: 41600 | performance: 26.8 | accuracy: 0.46 | loss: 0.75
update:525/2000, 耗时:0.00分/1.89分 | step: 42000 | performance: 24.0 | accuracy: 0.46 | loss: 0.49
update:530/2000, 耗时:0.00分/1.91分 | step: 42400 | performance: 34.6 | accuracy: 0.46 | loss: 1.38
update:535/2000, 耗时:0.00分/1.93分 | step: 42800 | performance: 33.8 | accuracy: 0.46 | loss: 0.90
update:540/2000, 耗时:0.00分/1.94分 | step: 43200 | performance: 18.1 | accuracy: 0.46 | loss: 1.02
update:545/2000, 耗时:0.00分/1.96分 | step: 43600 | performance: 22.6 | accuracy: 0.46 | loss: 0.55
update:550/2000, 耗时:0.00分/1.98分 | step: 44000 | performance: 74.1 | accuracy: 0.47 | loss: 0.93
update:555/2000, 耗时:0.00分/2.00分 | step: 44400 | performance: 166.1 | accuracy: 0.47 | loss: 1.57
update:560/2000, 耗时:0.00分/2.02分 | step: 44800 | performance: 790.7 | accuracy: 0.48 | loss: 0.88
update:565/2000, 耗时:0.00分/2.03分 | step: 45200 | performance: 1268.9 | accuracy: 0.48 | loss: 2.34
update:570/2000, 耗时:0.00分/2.05分 | step: 45600 | performance: 8324.0 | accuracy: 0.49 | loss: 0.88
update:575/2000, 耗时:0.00分/2.07分 | step: 46000 | performance: 9999.2 | accuracy: 0.49 | loss: 1.81
update:580/2000, 耗时:0.00分/2.09分 | step: 46400 | performance: 11893.0 | accuracy: 0.49 | loss: 1.27
update:585/2000, 耗时:0.00分/2.11分 | step: 46800 | performance: 8677.7 | accuracy: 0.49 | loss: 1.49
update:590/2000, 耗时:0.00分/2.13分 | step: 47200 | performance: 1386.9 | accuracy: 0.48 | loss: 1.56
update:595/2000, 耗时:0.00分/2.14分 | step: 47600 | performance: 929.4 | accuracy: 0.48 | loss: 2.16
update:600/2000, 耗时:0.00分/2.16分 | step: 48000 | performance: 642.6 | accuracy: 0.48 | loss: 1.03
update:605/2000, 耗时:0.00分/2.18分 | step: 48400 | performance: 2470.6 | accuracy: 0.49 | loss: 1.16
update:610/2000, 耗时:0.00分/2.20分 | step: 48800 | performance: 3466.8 | accuracy: 0.49 | loss: 0.94
update:615/2000, 耗时:0.00分/2.22分 | step: 49200 | performance: 2649.0 | accuracy: 0.48 | loss: 2.33
update:620/2000, 耗时:0.00分/2.23分 | step: 49600 | performance: 6288.4 | accuracy: 0.49 | loss: 1.32
update:625/2000, 耗时:0.00分/2.25分 | step: 50000 | performance: 5563.1 | accuracy: 0.49 | loss: 1.92
update:630/2000, 耗时:0.00分/2.27分 | step: 50400 | performance: 2420.0 | accuracy: 0.49 | loss: 1.29
update:635/2000, 耗时:0.00分/2.29分 | step: 50800 | performance: 1271.2 | accuracy: 0.48 | loss: 1.40
update:640/2000, 耗时:0.00分/2.31分 | step: 51200 | performance: 838.0 | accuracy: 0.48 | loss: 1.30
update:645/2000, 耗时:0.00分/2.33分 | step: 51600 | performance: 1184.5 | accuracy: 0.48 | loss: 1.90
update:650/2000, 耗时:0.00分/2.34分 | step: 52000 | performance: 1262.0 | accuracy: 0.48 | loss: 1.63
update:655/2000, 耗时:0.00分/2.36分 | step: 52400 | performance: 904.6 | accuracy: 0.48 | loss: 1.33
update:660/2000, 耗时:0.00分/2.38分 | step: 52800 | performance: 593.5 | accuracy: 0.48 | loss: 0.89
update:665/2000, 耗时:0.00分/2.40分 | step: 53200 | performance: 611.7 | accuracy: 0.48 | loss: 1.04
update:670/2000, 耗时:0.00分/2.42分 | step: 53600 | performance: 2886.7 | accuracy: 0.48 | loss: 1.26
update:675/2000, 耗时:0.00分/2.44分 | step: 54000 | performance: 1612.2 | accuracy: 0.48 | loss: 2.19
update:680/2000, 耗时:0.00分/2.46分 | step: 54400 | performance: 2476.7 | accuracy: 0.48 | loss: 1.17
update:685/2000, 耗时:0.00分/2.48分 | step: 54800 | performance: 3419.7 | accuracy: 0.48 | loss: 1.57
update:690/2000, 耗时:0.00分/2.50分 | step: 55200 | performance: 4314.6 | accuracy: 0.49 | loss: 1.37
update:695/2000, 耗时:0.00分/2.52分 | step: 55600 | performance: 2976.3 | accuracy: 0.48 | loss: 0.74
update:700/2000, 耗时:0.00分/2.54分 | step: 56000 | performance: 2198.7 | accuracy: 0.48 | loss: 1.26
update:705/2000, 耗时:0.00分/2.56分 | step: 56400 | performance: 2406.9 | accuracy: 0.48 | loss: 0.96
Saving PPO weights in both H5 format and checkpoint @ update:707 
Saving PPO weights in both H5 format and checkpoint @ update:709 
update:710/2000, 耗时:0.00分/2.59分 | step: 56800 | performance: 0.6 | accuracy: 0.31 | loss: 0.76
update:715/2000, 耗时:0.00分/2.61分 | step: 57200 | performance: 0.5 | accuracy: 0.41 | loss: 3.13
update:720/2000, 耗时:0.00分/2.63分 | step: 57600 | performance: 0.3 | accuracy: 0.39 | loss: 0.61
update:725/2000, 耗时:0.00分/2.65分 | step: 58000 | performance: 0.7 | accuracy: 0.44 | loss: 1.34
update:730/2000, 耗时:0.00分/2.67分 | step: 58400 | performance: 2.0 | accuracy: 0.47 | loss: 1.24
update:735/2000, 耗时:0.00分/2.69分 | step: 58800 | performance: 0.7 | accuracy: 0.45 | loss: 1.51
update:740/2000, 耗时:0.00分/2.71分 | step: 59200 | performance: 1.5 | accuracy: 0.48 | loss: 1.81
update:745/2000, 耗时:0.00分/2.73分 | step: 59600 | performance: 1.8 | accuracy: 0.47 | loss: 0.65
update:750/2000, 耗时:0.00分/2.74分 | step: 60000 | performance: 1.6 | accuracy: 0.46 | loss: 0.98
update:755/2000, 耗时:0.00分/2.76分 | step: 60400 | performance: 1.9 | accuracy: 0.48 | loss: 1.21
update:760/2000, 耗时:0.00分/2.78分 | step: 60800 | performance: 13.1 | accuracy: 0.49 | loss: 1.71
update:765/2000, 耗时:0.00分/2.80分 | step: 61200 | performance: 13.9 | accuracy: 0.49 | loss: 4.16
update:770/2000, 耗时:0.00分/2.82分 | step: 61600 | performance: 22.3 | accuracy: 0.50 | loss: 1.24
update:775/2000, 耗时:0.00分/2.84分 | step: 62000 | performance: 22.6 | accuracy: 0.49 | loss: 1.32
update:780/2000, 耗时:0.00分/2.86分 | step: 62400 | performance: 18.6 | accuracy: 0.49 | loss: 1.06
update:785/2000, 耗时:0.00分/2.88分 | step: 62800 | performance: 14.6 | accuracy: 0.48 | loss: 1.24
update:790/2000, 耗时:0.00分/2.90分 | step: 63200 | performance: 7.3 | accuracy: 0.48 | loss: 0.67
update:795/2000, 耗时:0.00分/2.92分 | step: 63600 | performance: 33.0 | accuracy: 0.49 | loss: 2.60
update:800/2000, 耗时:0.00分/2.94分 | step: 64000 | performance: 36.9 | accuracy: 0.49 | loss: 1.50
update:805/2000, 耗时:0.00分/2.96分 | step: 64400 | performance: 165.4 | accuracy: 0.50 | loss: 1.56
update:810/2000, 耗时:0.00分/2.98分 | step: 64800 | performance: 90.0 | accuracy: 0.50 | loss: 1.63
update:815/2000, 耗时:0.00分/3.00分 | step: 65200 | performance: 79.0 | accuracy: 0.50 | loss: 0.67
update:820/2000, 耗时:0.00分/3.01分 | step: 65600 | performance: 76.6 | accuracy: 0.49 | loss: 0.85
update:825/2000, 耗时:0.00分/3.03分 | step: 66000 | performance: 73.9 | accuracy: 0.49 | loss: 1.11
update:830/2000, 耗时:0.00分/3.05分 | step: 66400 | performance: 38.7 | accuracy: 0.49 | loss: 0.79
update:835/2000, 耗时:0.00分/3.07分 | step: 66800 | performance: 82.2 | accuracy: 0.50 | loss: 1.39
update:840/2000, 耗时:0.00分/3.09分 | step: 67200 | performance: 94.2 | accuracy: 0.50 | loss: 1.36
update:845/2000, 耗时:0.00分/3.11分 | step: 67600 | performance: 50.7 | accuracy: 0.49 | loss: 1.23
update:850/2000, 耗时:0.00分/3.12分 | step: 68000 | performance: 21.9 | accuracy: 0.49 | loss: 1.25
update:855/2000, 耗时:0.00分/3.14分 | step: 68400 | performance: 46.6 | accuracy: 0.48 | loss: 2.69
update:860/2000, 耗时:0.00分/3.16分 | step: 68800 | performance: 9.7 | accuracy: 0.47 | loss: 1.16
update:865/2000, 耗时:0.00分/3.18分 | step: 69200 | performance: 10.6 | accuracy: 0.47 | loss: 1.45
update:870/2000, 耗时:0.00分/3.20分 | step: 69600 | performance: 10.0 | accuracy: 0.47 | loss: 0.77
update:875/2000, 耗时:0.00分/3.22分 | step: 70000 | performance: 8.5 | accuracy: 0.47 | loss: 0.79
update:880/2000, 耗时:0.00分/3.23分 | step: 70400 | performance: 5.9 | accuracy: 0.46 | loss: 0.43
update:885/2000, 耗时:0.00分/3.25分 | step: 70800 | performance: 11.5 | accuracy: 0.46 | loss: 0.73
update:890/2000, 耗时:0.00分/3.27分 | step: 71200 | performance: 7.6 | accuracy: 0.46 | loss: 1.96
update:895/2000, 耗时:0.00分/3.29分 | step: 71600 | performance: 8.3 | accuracy: 0.46 | loss: 0.69
update:900/2000, 耗时:0.00分/3.30分 | step: 72000 | performance: 16.8 | accuracy: 0.47 | loss: 0.86
update:905/2000, 耗时:0.00分/3.32分 | step: 72400 | performance: 59.5 | accuracy: 0.48 | loss: 1.01
update:910/2000, 耗时:0.00分/3.34分 | step: 72800 | performance: 72.4 | accuracy: 0.48 | loss: 1.03
update:915/2000, 耗时:0.00分/3.36分 | step: 73200 | performance: 1364.3 | accuracy: 0.49 | loss: 1.02
update:920/2000, 耗时:0.00分/3.38分 | step: 73600 | performance: 781.7 | accuracy: 0.49 | loss: 1.07
update:925/2000, 耗时:0.00分/3.40分 | step: 74000 | performance: 1990.8 | accuracy: 0.49 | loss: 3.48
update:930/2000, 耗时:0.00分/3.41分 | step: 74400 | performance: 3363.2 | accuracy: 0.49 | loss: 3.99
update:935/2000, 耗时:0.00分/3.43分 | step: 74800 | performance: 3845.3 | accuracy: 0.49 | loss: 3.93
update:940/2000, 耗时:0.00分/3.45分 | step: 75200 | performance: 1873.8 | accuracy: 0.49 | loss: 2.77
update:945/2000, 耗时:0.00分/3.47分 | step: 75600 | performance: 982.4 | accuracy: 0.49 | loss: 0.99
update:950/2000, 耗时:0.00分/3.49分 | step: 76000 | performance: 676.6 | accuracy: 0.49 | loss: 1.40
update:955/2000, 耗时:0.00分/3.50分 | step: 76400 | performance: 398.1 | accuracy: 0.49 | loss: 2.69
update:960/2000, 耗时:0.00分/3.52分 | step: 76800 | performance: 500.6 | accuracy: 0.49 | loss: 1.41
update:965/2000, 耗时:0.00分/3.54分 | step: 77200 | performance: 342.0 | accuracy: 0.49 | loss: 0.76
update:970/2000, 耗时:0.00分/3.56分 | step: 77600 | performance: 197.6 | accuracy: 0.48 | loss: 1.52
update:975/2000, 耗时:0.00分/3.58分 | step: 78000 | performance: 280.1 | accuracy: 0.49 | loss: 0.91
update:980/2000, 耗时:0.00分/3.59分 | step: 78400 | performance: 209.9 | accuracy: 0.48 | loss: 0.99
update:985/2000, 耗时:0.00分/3.61分 | step: 78800 | performance: 362.1 | accuracy: 0.48 | loss: 0.94
update:990/2000, 耗时:0.00分/3.63分 | step: 79200 | performance: 469.3 | accuracy: 0.48 | loss: 1.05
update:995/2000, 耗时:0.00分/3.65分 | step: 79600 | performance: 302.6 | accuracy: 0.48 | loss: 1.44
update:1000/2000, 耗时:0.00分/3.66分 | step: 80000 | performance: 299.1 | accuracy: 0.48 | loss: 1.64
update:1005/2000, 耗时:0.00分/3.68分 | step: 80400 | performance: 501.3 | accuracy: 0.48 | loss: 1.13
update:1010/2000, 耗时:0.00分/3.70分 | step: 80800 | performance: 392.2 | accuracy: 0.48 | loss: 0.69
update:1015/2000, 耗时:0.00分/3.72分 | step: 81200 | performance: 592.9 | accuracy: 0.48 | loss: 0.83
update:1020/2000, 耗时:0.00分/3.74分 | step: 81600 | performance: 2864.5 | accuracy: 0.49 | loss: 1.78
update:1025/2000, 耗时:0.00分/3.75分 | step: 82000 | performance: 3075.3 | accuracy: 0.49 | loss: 1.34
update:1030/2000, 耗时:0.00分/3.77分 | step: 82400 | performance: 1480.2 | accuracy: 0.49 | loss: 0.91
update:1035/2000, 耗时:0.00分/3.79分 | step: 82800 | performance: 2684.5 | accuracy: 0.49 | loss: 0.87
update:1040/2000, 耗时:0.00分/3.81分 | step: 83200 | performance: 2817.8 | accuracy: 0.49 | loss: 0.77
update:1045/2000, 耗时:0.00分/3.82分 | step: 83600 | performance: 2798.5 | accuracy: 0.49 | loss: 1.17
update:1050/2000, 耗时:0.00分/3.84分 | step: 84000 | performance: 4951.7 | accuracy: 0.49 | loss: 1.06
update:1055/2000, 耗时:0.00分/3.86分 | step: 84400 | performance: 4746.7 | accuracy: 0.49 | loss: 0.97
update:1060/2000, 耗时:0.00分/3.88分 | step: 84800 | performance: 0.9 | accuracy: 0.00 | loss: 0.68
Saving PPO weights in both H5 format and checkpoint @ update:1060 
Saving PPO weights in both H5 format and checkpoint @ update:1062 
update:1065/2000, 耗时:0.00分/3.91分 | step: 85200 | performance: 6.5 | accuracy: 0.65 | loss: 2.66
update:1070/2000, 耗时:0.00分/3.92分 | step: 85600 | performance: 2.4 | accuracy: 0.50 | loss: 2.41
update:1075/2000, 耗时:0.00分/3.94分 | step: 86000 | performance: 4.0 | accuracy: 0.53 | loss: 1.34
update:1080/2000, 耗时:0.00分/3.96分 | step: 86400 | performance: 10.6 | accuracy: 0.55 | loss: 2.31
update:1085/2000, 耗时:0.00分/3.98分 | step: 86800 | performance: 10.0 | accuracy: 0.52 | loss: 0.83
update:1090/2000, 耗时:0.00分/3.99分 | step: 87200 | performance: 6.5 | accuracy: 0.52 | loss: 2.03
update:1095/2000, 耗时:0.00分/4.01分 | step: 87600 | performance: 10.7 | accuracy: 0.52 | loss: 1.61
update:1100/2000, 耗时:0.00分/4.03分 | step: 88000 | performance: 12.3 | accuracy: 0.50 | loss: 1.38
update:1105/2000, 耗时:0.00分/4.05分 | step: 88400 | performance: 11.3 | accuracy: 0.50 | loss: 1.76
update:1110/2000, 耗时:0.00分/4.06分 | step: 88800 | performance: 15.1 | accuracy: 0.51 | loss: 1.39
update:1115/2000, 耗时:0.00分/4.08分 | step: 89200 | performance: 116.8 | accuracy: 0.53 | loss: 1.34
update:1120/2000, 耗时:0.00分/4.10分 | step: 89600 | performance: 141.5 | accuracy: 0.53 | loss: 1.91
update:1125/2000, 耗时:0.00分/4.12分 | step: 90000 | performance: 186.3 | accuracy: 0.52 | loss: 1.19
update:1130/2000, 耗时:0.00分/4.14分 | step: 90400 | performance: 178.1 | accuracy: 0.52 | loss: 1.52
update:1135/2000, 耗时:0.00分/4.15分 | step: 90800 | performance: 170.5 | accuracy: 0.51 | loss: 1.33
update:1140/2000, 耗时:0.00分/4.17分 | step: 91200 | performance: 92.9 | accuracy: 0.51 | loss: 1.33
update:1145/2000, 耗时:0.00分/4.19分 | step: 91600 | performance: 118.9 | accuracy: 0.51 | loss: 1.53
update:1150/2000, 耗时:0.00分/4.21分 | step: 92000 | performance: 573.4 | accuracy: 0.52 | loss: 1.29
update:1155/2000, 耗时:0.00分/4.22分 | step: 92400 | performance: 1119.4 | accuracy: 0.52 | loss: 1.76
update:1160/2000, 耗时:0.00分/4.24分 | step: 92800 | performance: 569.2 | accuracy: 0.52 | loss: 3.30
update:1165/2000, 耗时:0.00分/4.26分 | step: 93200 | performance: 1297.8 | accuracy: 0.52 | loss: 1.69
update:1170/2000, 耗时:0.00分/4.28分 | step: 93600 | performance: 697.7 | accuracy: 0.52 | loss: 0.95
update:1175/2000, 耗时:0.00分/4.29分 | step: 94000 | performance: 272.7 | accuracy: 0.50 | loss: 0.65
update:1180/2000, 耗时:0.00分/4.31分 | step: 94400 | performance: 209.0 | accuracy: 0.50 | loss: 1.85
update:1185/2000, 耗时:0.00分/4.33分 | step: 94800 | performance: 177.6 | accuracy: 0.50 | loss: 1.10
update:1190/2000, 耗时:0.00分/4.34分 | step: 95200 | performance: 304.6 | accuracy: 0.51 | loss: 0.92
update:1195/2000, 耗时:0.00分/4.36分 | step: 95600 | performance: 195.9 | accuracy: 0.50 | loss: 1.96
update:1200/2000, 耗时:0.00分/4.38分 | step: 96000 | performance: 158.9 | accuracy: 0.50 | loss: 0.73
update:1205/2000, 耗时:0.00分/4.39分 | step: 96400 | performance: 129.9 | accuracy: 0.50 | loss: 1.39
update:1210/2000, 耗时:0.00分/4.41分 | step: 96800 | performance: 405.9 | accuracy: 0.50 | loss: 1.71
update:1215/2000, 耗时:0.00分/4.43分 | step: 97200 | performance: 435.0 | accuracy: 0.50 | loss: 1.25
update:1220/2000, 耗时:0.00分/4.45分 | step: 97600 | performance: 819.0 | accuracy: 0.50 | loss: 2.20
update:1225/2000, 耗时:0.00分/4.46分 | step: 98000 | performance: 548.7 | accuracy: 0.50 | loss: 0.39
update:1230/2000, 耗时:0.00分/4.48分 | step: 98400 | performance: 641.1 | accuracy: 0.49 | loss: 0.60
update:1235/2000, 耗时:0.00分/4.50分 | step: 98800 | performance: 525.0 | accuracy: 0.48 | loss: 0.49
update:1240/2000, 耗时:0.00分/4.52分 | step: 99200 | performance: 684.9 | accuracy: 0.48 | loss: 0.50
update:1245/2000, 耗时:0.00分/4.53分 | step: 99600 | performance: 637.7 | accuracy: 0.47 | loss: 0.15
update:1250/2000, 耗时:0.00分/4.55分 | step: 100000 | performance: 710.4 | accuracy: 0.47 | loss: 0.77
update:1255/2000, 耗时:0.00分/4.57分 | step: 100400 | performance: 1648.1 | accuracy: 0.47 | loss: 0.81
update:1260/2000, 耗时:0.00分/4.59分 | step: 100800 | performance: 4262.0 | accuracy: 0.48 | loss: 1.81
update:1265/2000, 耗时:0.00分/4.60分 | step: 101200 | performance: 11411.0 | accuracy: 0.48 | loss: 0.80
update:1270/2000, 耗时:0.00分/4.62分 | step: 101600 | performance: 62111.4 | accuracy: 0.49 | loss: 2.50
update:1275/2000, 耗时:0.00分/4.64分 | step: 102000 | performance: 154594.4 | accuracy: 0.49 | loss: 1.29
update:1280/2000, 耗时:0.00分/4.66分 | step: 102400 | performance: 233030.0 | accuracy: 0.49 | loss: 1.87
update:1285/2000, 耗时:0.00分/4.67分 | step: 102800 | performance: 334228.2 | accuracy: 0.50 | loss: 1.41
update:1290/2000, 耗时:0.00分/4.69分 | step: 103200 | performance: 244473.7 | accuracy: 0.49 | loss: 2.26
update:1295/2000, 耗时:0.00分/4.71分 | step: 103600 | performance: 44569.1 | accuracy: 0.49 | loss: 2.17
update:1300/2000, 耗时:0.00分/4.72分 | step: 104000 | performance: 45706.7 | accuracy: 0.49 | loss: 1.84
update:1305/2000, 耗时:0.00分/4.74分 | step: 104400 | performance: 23381.2 | accuracy: 0.49 | loss: 1.14
update:1310/2000, 耗时:0.00分/4.76分 | step: 104800 | performance: 46668.1 | accuracy: 0.49 | loss: 1.98
update:1315/2000, 耗时:0.00分/4.78分 | step: 105200 | performance: 83807.9 | accuracy: 0.49 | loss: 1.37
update:1320/2000, 耗时:0.00分/4.79分 | step: 105600 | performance: 51061.0 | accuracy: 0.49 | loss: 1.33
update:1325/2000, 耗时:0.00分/4.81分 | step: 106000 | performance: 219098.9 | accuracy: 0.50 | loss: 0.84
update:1330/2000, 耗时:0.00分/4.83分 | step: 106400 | performance: 214130.6 | accuracy: 0.50 | loss: 1.66
update:1335/2000, 耗时:0.00分/4.85分 | step: 106800 | performance: 68328.8 | accuracy: 0.49 | loss: 1.34
update:1340/2000, 耗时:0.00分/4.86分 | step: 107200 | performance: 50198.2 | accuracy: 0.49 | loss: 0.63
update:1345/2000, 耗时:0.00分/4.88分 | step: 107600 | performance: 16752.2 | accuracy: 0.49 | loss: 1.23
update:1350/2000, 耗时:0.00分/4.90分 | step: 108000 | performance: 16963.6 | accuracy: 0.49 | loss: 3.06
update:1355/2000, 耗时:0.00分/4.92分 | step: 108400 | performance: 24029.3 | accuracy: 0.49 | loss: 1.21
update:1360/2000, 耗时:0.00分/4.94分 | step: 108800 | performance: 20354.1 | accuracy: 0.49 | loss: 1.79
update:1365/2000, 耗时:0.00分/4.95分 | step: 109200 | performance: 11079.2 | accuracy: 0.49 | loss: 1.68
update:1370/2000, 耗时:0.00分/4.97分 | step: 109600 | performance: 6020.6 | accuracy: 0.49 | loss: 1.96
update:1375/2000, 耗时:0.00分/4.99分 | step: 110000 | performance: 1182.9 | accuracy: 0.48 | loss: 1.49
update:1380/2000, 耗时:0.00分/5.00分 | step: 110400 | performance: 1563.3 | accuracy: 0.48 | loss: 2.12
update:1385/2000, 耗时:0.00分/5.02分 | step: 110800 | performance: 1762.9 | accuracy: 0.48 | loss: 0.89
update:1390/2000, 耗时:0.00分/5.04分 | step: 111200 | performance: 1039.4 | accuracy: 0.48 | loss: 1.94
update:1395/2000, 耗时:0.00分/5.06分 | step: 111600 | performance: 818.5 | accuracy: 0.48 | loss: 1.27
update:1400/2000, 耗时:0.00分/5.07分 | step: 112000 | performance: 877.7 | accuracy: 0.48 | loss: 1.38
update:1405/2000, 耗时:0.00分/5.09分 | step: 112400 | performance: 342.4 | accuracy: 0.48 | loss: 1.45
update:1410/2000, 耗时:0.00分/5.11分 | step: 112800 | performance: 330.8 | accuracy: 0.48 | loss: 1.04
update:1415/2000, 耗时:0.00分/5.13分 | step: 113200 | performance: 0.4 | accuracy: 0.36 | loss: 1.29
update:1420/2000, 耗时:0.00分/5.14分 | step: 113600 | performance: 0.1 | accuracy: 0.36 | loss: 1.85
update:1425/2000, 耗时:0.00分/5.16分 | step: 114000 | performance: 0.4 | accuracy: 0.49 | loss: 1.15
update:1430/2000, 耗时:0.00分/5.18分 | step: 114400 | performance: 0.1 | accuracy: 0.44 | loss: 1.33
update:1435/2000, 耗时:0.00分/5.20分 | step: 114800 | performance: 0.1 | accuracy: 0.45 | loss: 1.86
update:1440/2000, 耗时:0.00分/5.21分 | step: 115200 | performance: 0.1 | accuracy: 0.47 | loss: 1.66
update:1445/2000, 耗时:0.00分/5.23分 | step: 115600 | performance: 0.1 | accuracy: 0.45 | loss: 2.04
update:1450/2000, 耗时:0.00分/5.25分 | step: 116000 | performance: 0.1 | accuracy: 0.48 | loss: 1.68
update:1455/2000, 耗时:0.00分/5.27分 | step: 116400 | performance: 0.1 | accuracy: 0.48 | loss: 1.24
update:1460/2000, 耗时:0.00分/5.28分 | step: 116800 | performance: 0.1 | accuracy: 0.47 | loss: 1.00
update:1465/2000, 耗时:0.00分/5.30分 | step: 117200 | performance: 0.0 | accuracy: 0.46 | loss: 1.48
update:1470/2000, 耗时:0.00分/5.32分 | step: 117600 | performance: 0.0 | accuracy: 0.44 | loss: 0.79
update:1475/2000, 耗时:0.00分/5.33分 | step: 118000 | performance: 0.0 | accuracy: 0.45 | loss: 1.35
update:1480/2000, 耗时:0.00分/5.35分 | step: 118400 | performance: 0.0 | accuracy: 0.45 | loss: 1.40
update:1485/2000, 耗时:0.00分/5.37分 | step: 118800 | performance: 0.0 | accuracy: 0.46 | loss: 1.22
update:1490/2000, 耗时:0.00分/5.39分 | step: 119200 | performance: 0.0 | accuracy: 0.46 | loss: 1.01
update:1495/2000, 耗时:0.00分/5.40分 | step: 119600 | performance: 0.0 | accuracy: 0.48 | loss: 1.32
update:1500/2000, 耗时:0.00分/5.42分 | step: 120000 | performance: 0.1 | accuracy: 0.49 | loss: 2.85
update:1505/2000, 耗时:0.00分/5.44分 | step: 120400 | performance: 0.1 | accuracy: 0.49 | loss: 1.95
update:1510/2000, 耗时:0.00分/5.46分 | step: 120800 | performance: 0.3 | accuracy: 0.50 | loss: 3.39
update:1515/2000, 耗时:0.00分/5.47分 | step: 121200 | performance: 0.2 | accuracy: 0.50 | loss: 1.43
update:1520/2000, 耗时:0.00分/5.49分 | step: 121600 | performance: 0.3 | accuracy: 0.50 | loss: 1.04
update:1525/2000, 耗时:0.00分/5.51分 | step: 122000 | performance: 0.2 | accuracy: 0.50 | loss: 1.01
update:1530/2000, 耗时:0.00分/5.53分 | step: 122400 | performance: 0.1 | accuracy: 0.49 | loss: 1.72
update:1535/2000, 耗时:0.00分/5.54分 | step: 122800 | performance: 0.1 | accuracy: 0.49 | loss: 1.46
update:1540/2000, 耗时:0.00分/5.56分 | step: 123200 | performance: 0.1 | accuracy: 0.48 | loss: 1.94
update:1545/2000, 耗时:0.00分/5.58分 | step: 123600 | performance: 0.1 | accuracy: 0.48 | loss: 1.07
update:1550/2000, 耗时:0.00分/5.60分 | step: 124000 | performance: 0.1 | accuracy: 0.49 | loss: 1.71
update:1555/2000, 耗时:0.00分/5.61分 | step: 124400 | performance: 0.2 | accuracy: 0.49 | loss: 0.99
update:1560/2000, 耗时:0.00分/5.63分 | step: 124800 | performance: 0.1 | accuracy: 0.49 | loss: 1.47
update:1565/2000, 耗时:0.00分/5.65分 | step: 125200 | performance: 0.0 | accuracy: 0.48 | loss: 1.34
update:1570/2000, 耗时:0.00分/5.67分 | step: 125600 | performance: 0.0 | accuracy: 0.49 | loss: 2.05
update:1575/2000, 耗时:0.00分/5.68分 | step: 126000 | performance: 0.1 | accuracy: 0.49 | loss: 1.88
update:1580/2000, 耗时:0.00分/5.70分 | step: 126400 | performance: 0.1 | accuracy: 0.50 | loss: 0.88
update:1585/2000, 耗时:0.00分/5.72分 | step: 126800 | performance: 0.0 | accuracy: 0.49 | loss: 1.14
update:1590/2000, 耗时:0.00分/5.73分 | step: 127200 | performance: 0.1 | accuracy: 0.50 | loss: 1.37
update:1595/2000, 耗时:0.00分/5.75分 | step: 127600 | performance: 0.1 | accuracy: 0.50 | loss: 1.35
update:1600/2000, 耗时:0.00分/5.77分 | step: 128000 | performance: 0.1 | accuracy: 0.50 | loss: 1.83
update:1605/2000, 耗时:0.00分/5.79分 | step: 128400 | performance: 0.1 | accuracy: 0.50 | loss: 0.76
update:1610/2000, 耗时:0.00分/5.80分 | step: 128800 | performance: 0.4 | accuracy: 0.51 | loss: 0.72
update:1615/2000, 耗时:0.00分/5.82分 | step: 129200 | performance: 0.6 | accuracy: 0.51 | loss: 1.66
update:1620/2000, 耗时:0.00分/5.84分 | step: 129600 | performance: 4.0 | accuracy: 0.52 | loss: 0.84
update:1625/2000, 耗时:0.00分/5.85分 | step: 130000 | performance: 4.4 | accuracy: 0.52 | loss: 1.21
update:1630/2000, 耗时:0.00分/5.87分 | step: 130400 | performance: 45.4 | accuracy: 0.52 | loss: 1.15
update:1635/2000, 耗时:0.00分/5.89分 | step: 130800 | performance: 45.2 | accuracy: 0.52 | loss: 1.79
update:1640/2000, 耗时:0.00分/5.91分 | step: 131200 | performance: 49.8 | accuracy: 0.52 | loss: 0.86
update:1645/2000, 耗时:0.00分/5.92分 | step: 131600 | performance: 33.1 | accuracy: 0.52 | loss: 1.10
update:1650/2000, 耗时:0.00分/5.94分 | step: 132000 | performance: 10.5 | accuracy: 0.52 | loss: 1.42
update:1655/2000, 耗时:0.00分/5.96分 | step: 132400 | performance: 4.6 | accuracy: 0.51 | loss: 1.31
update:1660/2000, 耗时:0.00分/5.98分 | step: 132800 | performance: 4.5 | accuracy: 0.50 | loss: 0.19
update:1665/2000, 耗时:0.00分/5.99分 | step: 133200 | performance: 6.9 | accuracy: 0.50 | loss: 0.95
update:1670/2000, 耗时:0.00分/6.01分 | step: 133600 | performance: 5.2 | accuracy: 0.50 | loss: 1.50
update:1675/2000, 耗时:0.00分/6.03分 | step: 134000 | performance: 4.5 | accuracy: 0.50 | loss: 1.10
update:1680/2000, 耗时:0.00分/6.04分 | step: 134400 | performance: 9.9 | accuracy: 0.50 | loss: 1.22
update:1685/2000, 耗时:0.00分/6.06分 | step: 134800 | performance: 7.7 | accuracy: 0.50 | loss: 1.25
update:1690/2000, 耗时:0.00分/6.08分 | step: 135200 | performance: 6.0 | accuracy: 0.50 | loss: 0.75
update:1695/2000, 耗时:0.00分/6.10分 | step: 135600 | performance: 4.4 | accuracy: 0.49 | loss: 0.50
update:1700/2000, 耗时:0.00分/6.11分 | step: 136000 | performance: 7.6 | accuracy: 0.49 | loss: 0.99
update:1705/2000, 耗时:0.00分/6.13分 | step: 136400 | performance: 9.0 | accuracy: 0.49 | loss: 1.29
update:1710/2000, 耗时:0.00分/6.15分 | step: 136800 | performance: 11.8 | accuracy: 0.49 | loss: 0.83
update:1715/2000, 耗时:0.00分/6.17分 | step: 137200 | performance: 8.8 | accuracy: 0.49 | loss: 0.80
update:1720/2000, 耗时:0.00分/6.18分 | step: 137600 | performance: 3.1 | accuracy: 0.48 | loss: 1.01
update:1725/2000, 耗时:0.00分/6.20分 | step: 138000 | performance: 3.3 | accuracy: 0.48 | loss: 0.98
update:1730/2000, 耗时:0.00分/6.22分 | step: 138400 | performance: 3.1 | accuracy: 0.48 | loss: 1.43
update:1735/2000, 耗时:0.00分/6.24分 | step: 138800 | performance: 1.5 | accuracy: 0.48 | loss: 1.47
update:1740/2000, 耗时:0.00分/6.25分 | step: 139200 | performance: 2.0 | accuracy: 0.48 | loss: 0.57
update:1745/2000, 耗时:0.00分/6.27分 | step: 139600 | performance: 3.3 | accuracy: 0.48 | loss: 1.34
update:1750/2000, 耗时:0.00分/6.29分 | step: 140000 | performance: 3.8 | accuracy: 0.49 | loss: 0.94
update:1755/2000, 耗时:0.00分/6.31分 | step: 140400 | performance: 3.7 | accuracy: 0.48 | loss: 1.29
update:1760/2000, 耗时:0.00分/6.32分 | step: 140800 | performance: 4.2 | accuracy: 0.48 | loss: 1.30
update:1765/2000, 耗时:0.00分/6.34分 | step: 141200 | performance: 4.7 | accuracy: 0.48 | loss: 0.77
step: 141273 | worker_0@n_step_9: average total_reward after train data exhaustion : 182.3 | max total_reward: 403.3
step: 141275 | worker_2@n_step_9: average total_reward after train data exhaustion : 180.9 | max total_reward: 403.3
step: 141276 | worker_3@n_step_9: average total_reward after train data exhaustion : 181.2 | max total_reward: 403.3
step: 141278 | worker_5@n_step_9: average total_reward after train data exhaustion : 179.9 | max total_reward: 403.3
step: 141279 | worker_6@n_step_9: average total_reward after train data exhaustion : 179.0 | max total_reward: 403.3
step: 141280 | worker_7@n_step_9: average total_reward after train data exhaustion : 178.1 | max total_reward: 403.3
update:1770/2000, 耗时:0.00分/6.36分 | step: 141600 | performance: 0.5 | accuracy: 0.30 | loss: 1.11
update:1775/2000, 耗时:0.00分/6.37分 | step: 142000 | performance: 0.7 | accuracy: 0.46 | loss: 1.94
update:1780/2000, 耗时:0.00分/6.39分 | step: 142400 | performance: 0.5 | accuracy: 0.44 | loss: 1.37
update:1785/2000, 耗时:0.00分/6.41分 | step: 142800 | performance: 0.8 | accuracy: 0.46 | loss: 1.10
update:1790/2000, 耗时:0.00分/6.42分 | step: 143200 | performance: 1.7 | accuracy: 0.49 | loss: 1.82
update:1795/2000, 耗时:0.00分/6.44分 | step: 143600 | performance: 0.7 | accuracy: 0.47 | loss: 1.93
update:1800/2000, 耗时:0.00分/6.46分 | step: 144000 | performance: 1.8 | accuracy: 0.49 | loss: 1.71
update:1805/2000, 耗时:0.00分/6.47分 | step: 144400 | performance: 1.8 | accuracy: 0.47 | loss: 1.18
update:1810/2000, 耗时:0.00分/6.49分 | step: 144800 | performance: 1.7 | accuracy: 0.47 | loss: 0.83
update:1815/2000, 耗时:0.00分/6.51分 | step: 145200 | performance: 2.0 | accuracy: 0.48 | loss: 0.95
update:1820/2000, 耗时:0.00分/6.53分 | step: 145600 | performance: 13.8 | accuracy: 0.49 | loss: 1.68
update:1825/2000, 耗时:0.00分/6.54分 | step: 146000 | performance: 15.3 | accuracy: 0.50 | loss: 1.81
update:1830/2000, 耗时:0.00分/6.56分 | step: 146400 | performance: 23.2 | accuracy: 0.50 | loss: 0.97
update:1835/2000, 耗时:0.00分/6.58分 | step: 146800 | performance: 23.1 | accuracy: 0.49 | loss: 1.44
update:1840/2000, 耗时:0.00分/6.60分 | step: 147200 | performance: 18.8 | accuracy: 0.49 | loss: 1.23
update:1845/2000, 耗时:0.00分/6.61分 | step: 147600 | performance: 11.3 | accuracy: 0.48 | loss: 1.32
update:1850/2000, 耗时:0.00分/6.63分 | step: 148000 | performance: 6.6 | accuracy: 0.47 | loss: 0.81
update:1855/2000, 耗时:0.00分/6.65分 | step: 148400 | performance: 20.4 | accuracy: 0.47 | loss: 1.87
update:1860/2000, 耗时:0.00分/6.66分 | step: 148800 | performance: 32.6 | accuracy: 0.48 | loss: 1.91
update:1865/2000, 耗时:0.00分/6.68分 | step: 149200 | performance: 103.6 | accuracy: 0.49 | loss: 2.11
update:1870/2000, 耗时:0.00分/6.70分 | step: 149600 | performance: 77.4 | accuracy: 0.49 | loss: 1.87
update:1875/2000, 耗时:0.00分/6.72分 | step: 150000 | performance: 34.2 | accuracy: 0.48 | loss: 1.63
update:1880/2000, 耗时:0.00分/6.73分 | step: 150400 | performance: 30.2 | accuracy: 0.48 | loss: 0.98
update:1885/2000, 耗时:0.00分/6.75分 | step: 150800 | performance: 37.6 | accuracy: 0.48 | loss: 1.95
update:1890/2000, 耗时:0.00分/6.77分 | step: 151200 | performance: 26.3 | accuracy: 0.48 | loss: 0.98
update:1895/2000, 耗时:0.00分/6.78分 | step: 151600 | performance: 51.7 | accuracy: 0.49 | loss: 1.70
update:1900/2000, 耗时:0.00分/6.80分 | step: 152000 | performance: 67.2 | accuracy: 0.49 | loss: 1.20
update:1905/2000, 耗时:0.00分/6.82分 | step: 152400 | performance: 37.2 | accuracy: 0.49 | loss: 1.44
update:1910/2000, 耗时:0.00分/6.84分 | step: 152800 | performance: 17.5 | accuracy: 0.48 | loss: 0.99
update:1915/2000, 耗时:0.00分/6.85分 | step: 153200 | performance: 113.0 | accuracy: 0.48 | loss: 2.25
update:1920/2000, 耗时:0.00分/6.87分 | step: 153600 | performance: 34.8 | accuracy: 0.48 | loss: 1.42
update:1925/2000, 耗时:0.00分/6.89分 | step: 154000 | performance: 18.6 | accuracy: 0.47 | loss: 0.96
update:1930/2000, 耗时:0.00分/6.91分 | step: 154400 | performance: 12.7 | accuracy: 0.47 | loss: 0.99
update:1935/2000, 耗时:0.00分/6.92分 | step: 154800 | performance: 10.9 | accuracy: 0.47 | loss: 1.01
update:1940/2000, 耗时:0.00分/6.94分 | step: 155200 | performance: 10.1 | accuracy: 0.47 | loss: 0.57
update:1945/2000, 耗时:0.00分/6.96分 | step: 155600 | performance: 16.6 | accuracy: 0.48 | loss: 0.99
update:1950/2000, 耗时:0.00分/6.98分 | step: 156000 | performance: 8.8 | accuracy: 0.48 | loss: 1.41
update:1955/2000, 耗时:0.00分/7.00分 | step: 156400 | performance: 8.3 | accuracy: 0.48 | loss: 1.05
update:1960/2000, 耗时:0.00分/7.01分 | step: 156800 | performance: 20.4 | accuracy: 0.48 | loss: 0.70
update:1965/2000, 耗时:0.00分/7.03分 | step: 157200 | performance: 68.6 | accuracy: 0.49 | loss: 0.81
update:1970/2000, 耗时:0.00分/7.05分 | step: 157600 | performance: 124.9 | accuracy: 0.49 | loss: 1.43
update:1975/2000, 耗时:0.00分/7.07分 | step: 158000 | performance: 985.9 | accuracy: 0.50 | loss: 2.49
update:1980/2000, 耗时:0.00分/7.08分 | step: 158400 | performance: 1030.8 | accuracy: 0.50 | loss: 1.45
update:1985/2000, 耗时:0.00分/7.10分 | step: 158800 | performance: 2762.0 | accuracy: 0.50 | loss: 2.23
update:1990/2000, 耗时:0.00分/7.12分 | step: 159200 | performance: 4137.3 | accuracy: 0.50 | loss: 2.32
update:1995/2000, 耗时:0.00分/7.13分 | step: 159600 | performance: 4160.3 | accuracy: 0.50 | loss: 2.07
update:2000/2000, 耗时:0.00分/7.15分 | step: 160000 | performance: 1894.2 | accuracy: 0.50 | loss: 1.97
----------------------------------------finished----------------------------------------
==================================================
2023-01-05T12:00:00 | *** START BACKTEST ***
2023-01-05T12:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/401 [00:00<?, ?it/s]100%|| 401/401 [00:00<00:00, 134006.53it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1408.17
2023-07-24T12:00:00 | net performance [%] = 40.8166
2023-07-24T12:00:00 | number of trades [#] = 20
==================================================
Trial 17 Complete [00h 07m 35s]
net_wealth: 1409.5759210258743

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 02h 15m 46s

Search: Running Trial #18

Value             |Best Value So Far |Hyperparameter
2                 |1                 |horizon
730               |730               |lookback
True              |False             |MarketFactor
8                 |3                 |lags
0.9               |0.92              |gamma
32                |32                |batch_size
3                 |1                 |n_step
0.8               |0.94              |gae_lambda
10                |5                 |gradient_clip_norm
3                 |5                 |epochs
0.0001            |0.0001            |actor_lr
0.0001            |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4299.000000   4301.000000
mean      0.000435    20113.607657  ...   20176.664105  20169.373185
std       0.027833    16040.642334  ...   16078.769271  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7739.330078   7730.930176
50%       0.000642    11571.842969  ...   11754.589844  11751.469727
75%       0.011590    29894.706152  ...   30014.465820  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 00:19:09.133953: I tensorflow/core/platform/cpu_feature_guard.cc:142] T2023-07-28 00:19:09.133992: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library 2023-07-28 00:19:09.134073: (oneDNN) to us2his TensorFlow bin0I23 tensorfl2023-07-28 00:19:09.1341oew/2 the3co :f re/platforoIm /tlleconpwsorfluio_nwfg/e cCoPU ature_ginruseat/rrpdul.ctiona-cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Librarts in perfforyma0r/c7y -pu_fi2se 8 00:19:oatp09utr.e_guaormance-critical opir1 d.cc(emrizatiooenns: eDNN) t AVdoX A  VwuXi32
T4th oneAPo10 se I2: ent hDeep Ie f atNeurb:14lal No2lletee]2w oT2n0so0hrwiionr23-s0 Te7fk2  -02328l 0L-t0gh :19eimb0C:o0w97.-/281P3U  c4in52n otso1h230-0roF07:- I eternr :o1sao2p8er rlarryef9l: o(/opwltai0ow0tfoonr/mc0/ ncsp,:i9e.uD_Nf1e9:ao nr0N9et.ubinary is 1op)/pstrur3lt e4_act5g2u1atioo :rdtinusm s.ei zecdc w rebIu itl1 t:h1di3eenfo4rm4i  5T/e6ns2ot8nfrol]:  Ilosh  onpotrFlefelwoinAgr fThenwori /cPcmanpouw_ swoCrfoPIclifUeatot e-crith iDuwn/sei ctructahle  aorcoteree_/gppions uapropilprd.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the sriate n  pf re/TpelNperaoeurallatantfoteifowlonirfcor mNetwork Library (snogm:r oop m/cpiler  A/rcVmasX AnfClPnaegDup_uoUV cfes_.i
n-cfestructNaNXi2r
tTrooeFatnis tuur inrleei cpoe_rgfuoawanr) b ito use nalmtahne_ce-criatirble tde ry.cc:142 foo clperations:  AVX AVX2
To enabl] is opltoThis waheiemizT themenli nimeguarsorFlow bid.cc:142] This nnary is optimized with oneAPI Deep Neural N other operations, rebTensu oietwork Library ( lidno d woitg Tenrhn sFleDoo oNoNCPnUe r)F lipw binanry iststo uArtherPoIs Deeep Neur w auoclt iwopn stithh t eien prh eraatfNtions:erfoieons, app r Ao llmance orpeVX AVX2
To build-cropriate cetoon aTbenlmpilsewimi rengriote itCrPhU tfwei liaznFocsmalowed w itgrr su.ct
iolwkn opesi r tLaitihnoi  nbtpsrhe:ae anith p  prrrfotho oorym (onepDriNN) to ance-critical operations:  AVuse the foAlerlnoVXwi nega  CPXAUt AVe VAo ipcPoXmpierI D2aetep Neuler fX
T2ions, rebuild Tenrnstrlsoruacl
 TNoao entgs.
ions in perf eFnoalarbbmolwe leetw  wthaem ncte-ihem init otcrher opnh oetr the appiticaork Librarl ryo (oneDNN) to use the following CPU ipohnesrperations:  AVX AVX2
To enable them in otrr opeuctions in performance-criticaattirationls, reher operations, rebuild TensorFlow with the appropriate compiler flags.
build TensorFlao opwi with the appropriate compiler flags.
erations:  AVX AVX2
To enable them in other operations, rebuild TensorFlons, rebuild TensorFlow with ttow with the appropriate compiler flags.
e compiler flags.
he appropriate compiler flags.
2023-07-28 00:19:09.746215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:19:09.760666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:19:09.762505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:19:09.768645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:19:09.787791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:19:09.788717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:19:09.796261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:19:09.805200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   120 | performance: 1.1 | accuracy: 0.33 | loss: 0.64
update: 10/2000, 耗时:0.00分/0.03分 | step:   240 | performance: 1.1 | accuracy: 0.37 | loss: 1.31
update: 15/2000, 耗时:0.00分/0.04分 | step:   360 | performance: 1.1 | accuracy: 0.33 | loss: 0.76
update: 20/2000, 耗时:0.00分/0.05分 | step:   480 | performance: 1.1 | accuracy: 0.32 | loss: 0.31
update: 25/2000, 耗时:0.00分/0.06分 | step:   600 | performance: 1.2 | accuracy: 0.35 | loss: 0.75
update: 30/2000, 耗时:0.00分/0.07分 | step:   720 | performance: 1.1 | accuracy: 0.32 | loss: 0.47
update: 35/2000, 耗时:0.00分/0.07分 | step:   840 | performance: 1.0 | accuracy: 0.34 | loss: 0.63
update: 40/2000, 耗时:0.00分/0.08分 | step:   960 | performance: 1.1 | accuracy: 0.37 | loss: 0.52
update: 45/2000, 耗时:0.00分/0.09分 | step:  1080 | performance: 1.1 | accuracy: 0.38 | loss: 0.33
update: 50/2000, 耗时:0.00分/0.10分 | step:  1200 | performance: 1.1 | accuracy: 0.37 | loss: 0.68
update: 55/2000, 耗时:0.00分/0.10分 | step:  1320 | performance: 1.1 | accuracy: 0.37 | loss: 1.01
update: 60/2000, 耗时:0.00分/0.11分 | step:  1440 | performance: 1.0 | accuracy: 0.36 | loss: 1.25
update: 65/2000, 耗时:0.00分/0.12分 | step:  1560 | performance: 1.0 | accuracy: 0.37 | loss: 0.69
update: 70/2000, 耗时:0.00分/0.13分 | step:  1680 | performance: 0.7 | accuracy: 0.37 | loss: 0.79
update: 75/2000, 耗时:0.00分/0.14分 | step:  1800 | performance: 0.8 | accuracy: 0.37 | loss: 1.02
update: 80/2000, 耗时:0.00分/0.14分 | step:  1920 | performance: 0.8 | accuracy: 0.38 | loss: 0.78
update: 85/2000, 耗时:0.00分/0.15分 | step:  2040 | performance: 1.0 | accuracy: 0.39 | loss: 0.84
update: 90/2000, 耗时:0.00分/0.16分 | step:  2160 | performance: 0.9 | accuracy: 0.39 | loss: 0.75
update: 95/2000, 耗时:0.00分/0.17分 | step:  2280 | performance: 1.0 | accuracy: 0.40 | loss: 0.51
update:100/2000, 耗时:0.00分/0.18分 | step:  2400 | performance: 1.1 | accuracy: 0.41 | loss: 0.68
update:105/2000, 耗时:0.00分/0.19分 | step:  2520 | performance: 1.1 | accuracy: 0.41 | loss: 0.89
update:110/2000, 耗时:0.00分/0.20分 | step:  2640 | performance: 1.1 | accuracy: 0.41 | loss: 0.71
update:115/2000, 耗时:0.00分/0.21分 | step:  2760 | performance: 1.2 | accuracy: 0.41 | loss: 0.73
update:120/2000, 耗时:0.00分/0.22分 | step:  2880 | performance: 1.4 | accuracy: 0.42 | loss: 0.75
update:125/2000, 耗时:0.00分/0.23分 | step:  3000 | performance: 1.3 | accuracy: 0.42 | loss: 0.46
update:130/2000, 耗时:0.00分/0.23分 | step:  3120 | performance: 1.3 | accuracy: 0.41 | loss: 0.70
update:135/2000, 耗时:0.00分/0.24分 | step:  3240 | performance: 1.4 | accuracy: 0.42 | loss: 0.73
update:140/2000, 耗时:0.00分/0.25分 | step:  3360 | performance: 1.7 | accuracy: 0.41 | loss: 1.08
update:145/2000, 耗时:0.00分/0.26分 | step:  3480 | performance: 1.5 | accuracy: 0.40 | loss: 0.50
update:150/2000, 耗时:0.00分/0.27分 | step:  3600 | performance: 1.4 | accuracy: 0.40 | loss: 0.32
update:155/2000, 耗时:0.00分/0.28分 | step:  3720 | performance: 1.4 | accuracy: 0.39 | loss: 0.42
update:160/2000, 耗时:0.00分/0.29分 | step:  3840 | performance: 1.4 | accuracy: 0.39 | loss: 0.77
update:165/2000, 耗时:0.00分/0.30分 | step:  3960 | performance: 1.3 | accuracy: 0.38 | loss: 0.60
update:170/2000, 耗时:0.00分/0.31分 | step:  4080 | performance: 1.3 | accuracy: 0.37 | loss: 1.72
update:175/2000, 耗时:0.00分/0.32分 | step:  4200 | performance: 1.3 | accuracy: 0.38 | loss: 0.62
update:180/2000, 耗时:0.00分/0.33分 | step:  4320 | performance: 1.5 | accuracy: 0.37 | loss: 0.35
update:185/2000, 耗时:0.00分/0.34分 | step:  4440 | performance: 1.4 | accuracy: 0.37 | loss: 0.87
update:190/2000, 耗时:0.00分/0.34分 | step:  4560 | performance: 1.5 | accuracy: 0.37 | loss: 0.28
update:195/2000, 耗时:0.00分/0.35分 | step:  4680 | performance: 1.8 | accuracy: 0.37 | loss: 0.12
update:200/2000, 耗时:0.00分/0.36分 | step:  4800 | performance: 1.4 | accuracy: 0.36 | loss: 1.84
update:205/2000, 耗时:0.00分/0.37分 | step:  4920 | performance: 1.5 | accuracy: 0.35 | loss: 0.19
update:210/2000, 耗时:0.00分/0.38分 | step:  5040 | performance: 1.3 | accuracy: 0.35 | loss: 0.66
update:215/2000, 耗时:0.00分/0.39分 | step:  5160 | performance: 1.2 | accuracy: 0.35 | loss: 0.33
update:220/2000, 耗时:0.00分/0.40分 | step:  5280 | performance: 1.3 | accuracy: 0.36 | loss: 0.29
update:225/2000, 耗时:0.00分/0.41分 | step:  5400 | performance: 1.3 | accuracy: 0.35 | loss: 0.43
update:230/2000, 耗时:0.00分/0.42分 | step:  5520 | performance: 1.0 | accuracy: 0.35 | loss: 0.68
update:235/2000, 耗时:0.00分/0.43分 | step:  5640 | performance: 0.9 | accuracy: 0.35 | loss: 0.60
update:240/2000, 耗时:0.00分/0.43分 | step:  5760 | performance: 0.8 | accuracy: 0.34 | loss: 0.44
update:245/2000, 耗时:0.00分/0.44分 | step:  5880 | performance: 1.0 | accuracy: 0.34 | loss: 0.11
update:250/2000, 耗时:0.00分/0.45分 | step:  6000 | performance: 1.0 | accuracy: 0.34 | loss: 0.31
update:255/2000, 耗时:0.00分/0.46分 | step:  6120 | performance: 0.8 | accuracy: 0.33 | loss: 0.61
update:260/2000, 耗时:0.00分/0.47分 | step:  6240 | performance: 0.8 | accuracy: 0.33 | loss: 0.26
update:265/2000, 耗时:0.00分/0.48分 | step:  6360 | performance: 0.8 | accuracy: 0.33 | loss: 0.49
update:270/2000, 耗时:0.00分/0.49分 | step:  6480 | performance: 0.7 | accuracy: 0.33 | loss: 0.47
update:275/2000, 耗时:0.00分/0.50分 | step:  6600 | performance: 0.8 | accuracy: 0.33 | loss: 0.25
update:280/2000, 耗时:0.00分/0.51分 | step:  6720 | performance: 1.2 | accuracy: 0.33 | loss: 0.03
update:285/2000, 耗时:0.00分/0.52分 | step:  6840 | performance: 1.1 | accuracy: 0.33 | loss: 0.38
update:290/2000, 耗时:0.00分/0.53分 | step:  6960 | performance: 1.1 | accuracy: 0.33 | loss: 0.54
update:295/2000, 耗时:0.00分/0.54分 | step:  7080 | performance: 1.1 | accuracy: 0.33 | loss: 0.63
update:300/2000, 耗时:0.00分/0.54分 | step:  7200 | performance: 1.1 | accuracy: 0.33 | loss: 0.11
update:305/2000, 耗时:0.00分/0.55分 | step:  7320 | performance: 1.1 | accuracy: 0.33 | loss: 0.49
update:310/2000, 耗时:0.00分/0.56分 | step:  7440 | performance: 1.1 | accuracy: 0.33 | loss: 0.77
update:315/2000, 耗时:0.00分/0.57分 | step:  7560 | performance: 1.2 | accuracy: 0.33 | loss: 0.82
update:320/2000, 耗时:0.00分/0.58分 | step:  7680 | performance: 1.2 | accuracy: 0.33 | loss: 0.28
update:325/2000, 耗时:0.00分/0.59分 | step:  7800 | performance: 1.3 | accuracy: 0.33 | loss: 0.35
update:330/2000, 耗时:0.00分/0.60分 | step:  7920 | performance: 1.3 | accuracy: 0.32 | loss: 0.57
update:335/2000, 耗时:0.00分/0.61分 | step:  8040 | performance: 1.3 | accuracy: 0.32 | loss: 0.33
update:340/2000, 耗时:0.00分/0.62分 | step:  8160 | performance: 1.5 | accuracy: 0.32 | loss: 0.23
update:345/2000, 耗时:0.00分/0.63分 | step:  8280 | performance: 1.6 | accuracy: 0.32 | loss: 0.21
update:350/2000, 耗时:0.00分/0.64分 | step:  8400 | performance: 1.6 | accuracy: 0.32 | loss: 0.12
update:355/2000, 耗时:0.00分/0.64分 | step:  8520 | performance: 1.7 | accuracy: 0.32 | loss: 0.16
update:360/2000, 耗时:0.00分/0.65分 | step:  8640 | performance: 1.6 | accuracy: 0.32 | loss: 0.44
update:365/2000, 耗时:0.00分/0.66分 | step:  8760 | performance: 1.8 | accuracy: 0.32 | loss: 0.42
update:370/2000, 耗时:0.00分/0.67分 | step:  8880 | performance: 1.7 | accuracy: 0.31 | loss: 0.57
update:375/2000, 耗时:0.00分/0.68分 | step:  9000 | performance: 1.7 | accuracy: 0.31 | loss: 0.20
update:380/2000, 耗时:0.00分/0.69分 | step:  9120 | performance: 1.8 | accuracy: 0.31 | loss: 0.30
update:385/2000, 耗时:0.00分/0.70分 | step:  9240 | performance: 2.0 | accuracy: 0.31 | loss: 0.10
update:390/2000, 耗时:0.00分/0.71分 | step:  9360 | performance: 1.8 | accuracy: 0.31 | loss: 0.70
update:395/2000, 耗时:0.00分/0.72分 | step:  9480 | performance: 1.7 | accuracy: 0.31 | loss: 0.55
update:400/2000, 耗时:0.00分/0.73分 | step:  9600 | performance: 1.9 | accuracy: 0.31 | loss: 0.44
update:405/2000, 耗时:0.00分/0.74分 | step:  9720 | performance: 1.8 | accuracy: 0.30 | loss: 0.28
update:410/2000, 耗时:0.00分/0.74分 | step:  9840 | performance: 2.2 | accuracy: 0.30 | loss: 0.48
update:415/2000, 耗时:0.00分/0.75分 | step:  9960 | performance: 2.2 | accuracy: 0.30 | loss: 0.14
update:420/2000, 耗时:0.00分/0.76分 | step: 10080 | performance: 2.2 | accuracy: 0.30 | loss: 0.50
update:425/2000, 耗时:0.00分/0.77分 | step: 10200 | performance: 2.2 | accuracy: 0.30 | loss: 0.15
update:430/2000, 耗时:0.00分/0.78分 | step: 10320 | performance: 2.4 | accuracy: 0.30 | loss: 0.33
update:435/2000, 耗时:0.00分/0.79分 | step: 10440 | performance: 2.4 | accuracy: 0.30 | loss: 0.35
update:440/2000, 耗时:0.00分/0.80分 | step: 10560 | performance: 2.4 | accuracy: 0.30 | loss: 0.58
update:445/2000, 耗时:0.00分/0.81分 | step: 10680 | performance: 2.4 | accuracy: 0.30 | loss: 0.26
update:450/2000, 耗时:0.00分/0.82分 | step: 10800 | performance: 2.6 | accuracy: 0.29 | loss: 0.07
update:455/2000, 耗时:0.00分/0.83分 | step: 10920 | performance: 2.5 | accuracy: 0.29 | loss: 0.62
update:460/2000, 耗时:0.00分/0.84分 | step: 11040 | performance: 2.6 | accuracy: 0.29 | loss: 0.07
update:465/2000, 耗时:0.00分/0.84分 | step: 11160 | performance: 2.6 | accuracy: 0.29 | loss: 0.08
update:470/2000, 耗时:0.00分/0.85分 | step: 11280 | performance: 2.6 | accuracy: 0.28 | loss: 0.12
update:475/2000, 耗时:0.00分/0.86分 | step: 11400 | performance: 2.5 | accuracy: 0.28 | loss: 0.04
update:480/2000, 耗时:0.00分/0.87分 | step: 11520 | performance: 2.5 | accuracy: 0.28 | loss: 0.00
update:485/2000, 耗时:0.00分/0.88分 | step: 11640 | performance: 2.5 | accuracy: 0.27 | loss: 0.04
update:490/2000, 耗时:0.00分/0.89分 | step: 11760 | performance: 2.5 | accuracy: 0.27 | loss: 0.07
update:495/2000, 耗时:0.00分/0.90分 | step: 11880 | performance: 2.5 | accuracy: 0.27 | loss: 0.25
update:500/2000, 耗时:0.00分/0.91分 | step: 12000 | performance: 2.5 | accuracy: 0.27 | loss: 0.18
update:505/2000, 耗时:0.00分/0.92分 | step: 12120 | performance: 2.6 | accuracy: 0.27 | loss: 0.19
update:510/2000, 耗时:0.00分/0.93分 | step: 12240 | performance: 2.5 | accuracy: 0.26 | loss: 0.05
update:515/2000, 耗时:0.00分/0.94分 | step: 12360 | performance: 2.6 | accuracy: 0.26 | loss: 0.02
update:520/2000, 耗时:0.00分/0.95分 | step: 12480 | performance: 2.6 | accuracy: 0.26 | loss: 0.02
update:525/2000, 耗时:0.00分/0.96分 | step: 12600 | performance: 2.6 | accuracy: 0.26 | loss: 0.00
update:530/2000, 耗时:0.00分/0.97分 | step: 12720 | performance: 2.7 | accuracy: 0.26 | loss: 0.01
update:535/2000, 耗时:0.00分/0.98分 | step: 12840 | performance: 2.7 | accuracy: 0.26 | loss: 0.03
update:540/2000, 耗时:0.00分/0.99分 | step: 12960 | performance: 2.7 | accuracy: 0.25 | loss: 0.04
update:545/2000, 耗时:0.00分/1.00分 | step: 13080 | performance: 2.9 | accuracy: 0.25 | loss: 0.10
update:550/2000, 耗时:0.00分/1.01分 | step: 13200 | performance: 3.0 | accuracy: 0.25 | loss: 0.02
update:555/2000, 耗时:0.00分/1.02分 | step: 13320 | performance: 3.0 | accuracy: 0.25 | loss: 0.06
update:560/2000, 耗时:0.00分/1.03分 | step: 13440 | performance: 3.0 | accuracy: 0.25 | loss: 0.06
update:565/2000, 耗时:0.00分/1.04分 | step: 13560 | performance: 3.0 | accuracy: 0.25 | loss: 0.08
update:570/2000, 耗时:0.00分/1.05分 | step: 13680 | performance: 3.5 | accuracy: 0.25 | loss: 0.32
update:575/2000, 耗时:0.00分/1.06分 | step: 13800 | performance: 3.0 | accuracy: 0.25 | loss: 1.19
update:580/2000, 耗时:0.00分/1.07分 | step: 13920 | performance: 2.8 | accuracy: 0.25 | loss: 0.51
update:585/2000, 耗时:0.00分/1.08分 | step: 14040 | performance: 2.4 | accuracy: 0.25 | loss: 0.19
update:590/2000, 耗时:0.00分/1.09分 | step: 14160 | performance: 2.8 | accuracy: 0.24 | loss: 0.24
update:595/2000, 耗时:0.00分/1.10分 | step: 14280 | performance: 3.0 | accuracy: 0.24 | loss: 0.80
update:600/2000, 耗时:0.00分/1.11分 | step: 14400 | performance: 3.4 | accuracy: 0.24 | loss: 0.11
update:605/2000, 耗时:0.00分/1.12分 | step: 14520 | performance: 2.9 | accuracy: 0.24 | loss: 0.49
update:610/2000, 耗时:0.00分/1.12分 | step: 14640 | performance: 3.4 | accuracy: 0.25 | loss: 1.13
update:615/2000, 耗时:0.00分/1.13分 | step: 14760 | performance: 3.2 | accuracy: 0.24 | loss: 0.46
update:620/2000, 耗时:0.00分/1.14分 | step: 14880 | performance: 2.7 | accuracy: 0.25 | loss: 1.76
update:625/2000, 耗时:0.00分/1.15分 | step: 15000 | performance: 3.1 | accuracy: 0.25 | loss: 0.53
update:630/2000, 耗时:0.00分/1.16分 | step: 15120 | performance: 3.0 | accuracy: 0.25 | loss: 0.83
update:635/2000, 耗时:0.00分/1.17分 | step: 15240 | performance: 3.2 | accuracy: 0.25 | loss: 0.49
update:640/2000, 耗时:0.00分/1.18分 | step: 15360 | performance: 2.4 | accuracy: 0.25 | loss: 2.40
update:645/2000, 耗时:0.00分/1.19分 | step: 15480 | performance: 3.2 | accuracy: 0.26 | loss: 0.72
update:650/2000, 耗时:0.00分/1.20分 | step: 15600 | performance: 3.4 | accuracy: 0.26 | loss: 0.50
update:655/2000, 耗时:0.00分/1.21分 | step: 15720 | performance: 2.6 | accuracy: 0.26 | loss: 0.32
update:660/2000, 耗时:0.00分/1.22分 | step: 15840 | performance: 1.3 | accuracy: 0.26 | loss: 0.85
update:665/2000, 耗时:0.00分/1.23分 | step: 15960 | performance: 1.3 | accuracy: 0.26 | loss: 1.28
update:670/2000, 耗时:0.00分/1.24分 | step: 16080 | performance: 1.1 | accuracy: 0.26 | loss: 1.24
update:675/2000, 耗时:0.00分/1.25分 | step: 16200 | performance: 1.2 | accuracy: 0.26 | loss: 0.53
update:680/2000, 耗时:0.00分/1.26分 | step: 16320 | performance: 0.9 | accuracy: 0.26 | loss: 1.04
update:685/2000, 耗时:0.00分/1.27分 | step: 16440 | performance: 0.9 | accuracy: 0.26 | loss: 0.56
update:690/2000, 耗时:0.00分/1.28分 | step: 16560 | performance: 0.8 | accuracy: 0.26 | loss: 0.99
update:695/2000, 耗时:0.00分/1.29分 | step: 16680 | performance: 0.7 | accuracy: 0.26 | loss: 0.96
update:700/2000, 耗时:0.00分/1.30分 | step: 16800 | performance: 0.7 | accuracy: 0.26 | loss: 0.32
update:705/2000, 耗时:0.00分/1.31分 | step: 16920 | performance: 0.7 | accuracy: 0.26 | loss: 0.37
update:710/2000, 耗时:0.00分/1.31分 | step: 17040 | performance: 0.8 | accuracy: 0.26 | loss: 1.50
update:715/2000, 耗时:0.00分/1.32分 | step: 17160 | performance: 0.9 | accuracy: 0.26 | loss: 0.28
update:720/2000, 耗时:0.00分/1.33分 | step: 17280 | performance: 0.8 | accuracy: 0.26 | loss: 0.35
update:725/2000, 耗时:0.00分/1.34分 | step: 17400 | performance: 0.9 | accuracy: 0.26 | loss: 0.88
update:730/2000, 耗时:0.00分/1.35分 | step: 17520 | performance: 0.9 | accuracy: 0.26 | loss: 0.41
update:735/2000, 耗时:0.00分/1.36分 | step: 17640 | performance: 0.9 | accuracy: 0.26 | loss: 0.96
update:740/2000, 耗时:0.00分/1.37分 | step: 17760 | performance: 0.8 | accuracy: 0.26 | loss: 0.56
update:745/2000, 耗时:0.00分/1.38分 | step: 17880 | performance: 0.8 | accuracy: 0.26 | loss: 0.88
update:750/2000, 耗时:0.00分/1.39分 | step: 18000 | performance: 1.0 | accuracy: 0.26 | loss: 0.12
update:755/2000, 耗时:0.00分/1.40分 | step: 18120 | performance: 0.9 | accuracy: 0.26 | loss: 0.44
update:760/2000, 耗时:0.00分/1.40分 | step: 18240 | performance: 1.0 | accuracy: 0.26 | loss: 0.13
update:765/2000, 耗时:0.00分/1.41分 | step: 18360 | performance: 0.9 | accuracy: 0.26 | loss: 0.46
update:770/2000, 耗时:0.00分/1.42分 | step: 18480 | performance: 0.9 | accuracy: 0.26 | loss: 0.28
update:775/2000, 耗时:0.00分/1.43分 | step: 18600 | performance: 1.0 | accuracy: 0.26 | loss: 0.23
update:780/2000, 耗时:0.00分/1.44分 | step: 18720 | performance: 1.0 | accuracy: 0.26 | loss: 0.62
update:785/2000, 耗时:0.00分/1.45分 | step: 18840 | performance: 0.9 | accuracy: 0.26 | loss: 0.41
update:790/2000, 耗时:0.00分/1.46分 | step: 18960 | performance: 0.7 | accuracy: 0.26 | loss: 0.73
update:795/2000, 耗时:0.00分/1.47分 | step: 19080 | performance: 0.7 | accuracy: 0.26 | loss: 1.02
update:800/2000, 耗时:0.00分/1.48分 | step: 19200 | performance: 0.6 | accuracy: 0.26 | loss: 0.77
update:805/2000, 耗时:0.00分/1.49分 | step: 19320 | performance: 0.6 | accuracy: 0.26 | loss: 0.06
update:810/2000, 耗时:0.00分/1.50分 | step: 19440 | performance: 0.5 | accuracy: 0.26 | loss: 0.44
update:815/2000, 耗时:0.00分/1.50分 | step: 19560 | performance: 0.5 | accuracy: 0.26 | loss: 0.58
update:820/2000, 耗时:0.00分/1.51分 | step: 19680 | performance: 0.5 | accuracy: 0.26 | loss: 0.20
update:825/2000, 耗时:0.00分/1.52分 | step: 19800 | performance: 0.6 | accuracy: 0.26 | loss: 0.59
update:830/2000, 耗时:0.00分/1.53分 | step: 19920 | performance: 0.6 | accuracy: 0.26 | loss: 0.28
update:835/2000, 耗时:0.00分/1.54分 | step: 20040 | performance: 0.7 | accuracy: 0.26 | loss: 0.10
update:840/2000, 耗时:0.00分/1.55分 | step: 20160 | performance: 0.7 | accuracy: 0.26 | loss: 0.23
update:845/2000, 耗时:0.00分/1.56分 | step: 20280 | performance: 0.8 | accuracy: 0.26 | loss: 1.19
update:850/2000, 耗时:0.00分/1.57分 | step: 20400 | performance: 0.6 | accuracy: 0.26 | loss: 0.19
update:855/2000, 耗时:0.00分/1.58分 | step: 20520 | performance: 0.8 | accuracy: 0.26 | loss: 0.69
update:860/2000, 耗时:0.00分/1.59分 | step: 20640 | performance: 0.8 | accuracy: 0.26 | loss: 0.14
update:865/2000, 耗时:0.00分/1.59分 | step: 20760 | performance: 0.7 | accuracy: 0.26 | loss: 0.04
update:870/2000, 耗时:0.00分/1.60分 | step: 20880 | performance: 0.7 | accuracy: 0.26 | loss: 0.16
update:875/2000, 耗时:0.00分/1.61分 | step: 21000 | performance: 0.7 | accuracy: 0.26 | loss: 0.78
update:880/2000, 耗时:0.00分/1.62分 | step: 21120 | performance: 0.6 | accuracy: 0.26 | loss: 0.16
update:885/2000, 耗时:0.00分/1.63分 | step: 21240 | performance: 0.7 | accuracy: 0.26 | loss: 0.49
update:890/2000, 耗时:0.00分/1.64分 | step: 21360 | performance: 0.7 | accuracy: 0.26 | loss: 0.35
update:895/2000, 耗时:0.00分/1.65分 | step: 21480 | performance: 0.6 | accuracy: 0.26 | loss: 1.21
update:900/2000, 耗时:0.00分/1.66分 | step: 21600 | performance: 0.6 | accuracy: 0.26 | loss: 0.74
update:905/2000, 耗时:0.00分/1.67分 | step: 21720 | performance: 0.6 | accuracy: 0.26 | loss: 0.36
update:910/2000, 耗时:0.00分/1.68分 | step: 21840 | performance: 0.5 | accuracy: 0.26 | loss: 0.09
update:915/2000, 耗时:0.00分/1.69分 | step: 21960 | performance: 0.5 | accuracy: 0.26 | loss: 0.31
update:920/2000, 耗时:0.00分/1.69分 | step: 22080 | performance: 0.3 | accuracy: 0.26 | loss: 0.26
update:925/2000, 耗时:0.00分/1.70分 | step: 22200 | performance: 0.2 | accuracy: 0.26 | loss: 0.66
update:930/2000, 耗时:0.00分/1.71分 | step: 22320 | performance: 0.2 | accuracy: 0.26 | loss: 0.26
update:935/2000, 耗时:0.00分/1.72分 | step: 22440 | performance: 0.2 | accuracy: 0.26 | loss: 0.52
update:940/2000, 耗时:0.00分/1.73分 | step: 22560 | performance: 0.3 | accuracy: 0.26 | loss: 0.88
update:945/2000, 耗时:0.00分/1.74分 | step: 22680 | performance: 0.2 | accuracy: 0.26 | loss: 0.08
update:950/2000, 耗时:0.00分/1.75分 | step: 22800 | performance: 0.2 | accuracy: 0.26 | loss: 0.14
update:955/2000, 耗时:0.00分/1.76分 | step: 22920 | performance: 0.2 | accuracy: 0.26 | loss: 0.20
update:960/2000, 耗时:0.00分/1.77分 | step: 23040 | performance: 0.2 | accuracy: 0.25 | loss: 0.22
update:965/2000, 耗时:0.00分/1.77分 | step: 23160 | performance: 0.2 | accuracy: 0.25 | loss: 0.51
update:970/2000, 耗时:0.00分/1.78分 | step: 23280 | performance: 0.2 | accuracy: 0.25 | loss: 0.57
update:975/2000, 耗时:0.00分/1.79分 | step: 23400 | performance: 0.2 | accuracy: 0.25 | loss: 0.07
update:980/2000, 耗时:0.00分/1.80分 | step: 23520 | performance: 0.2 | accuracy: 0.25 | loss: 0.02
update:985/2000, 耗时:0.00分/1.81分 | step: 23640 | performance: 0.2 | accuracy: 0.25 | loss: 0.48
update:990/2000, 耗时:0.00分/1.82分 | step: 23760 | performance: 0.2 | accuracy: 0.25 | loss: 0.18
update:995/2000, 耗时:0.00分/1.83分 | step: 23880 | performance: 0.2 | accuracy: 0.25 | loss: 0.19
update:1000/2000, 耗时:0.00分/1.84分 | step: 24000 | performance: 0.2 | accuracy: 0.25 | loss: 0.04
update:1005/2000, 耗时:0.00分/1.85分 | step: 24120 | performance: 0.2 | accuracy: 0.25 | loss: 0.17
update:1010/2000, 耗时:0.00分/1.85分 | step: 24240 | performance: 0.2 | accuracy: 0.25 | loss: 0.04
update:1015/2000, 耗时:0.00分/1.86分 | step: 24360 | performance: 0.2 | accuracy: 0.25 | loss: 0.07
update:1020/2000, 耗时:0.00分/1.87分 | step: 24480 | performance: 0.2 | accuracy: 0.25 | loss: 1.23
update:1025/2000, 耗时:0.00分/1.88分 | step: 24600 | performance: 0.2 | accuracy: 0.25 | loss: 0.81
update:1030/2000, 耗时:0.00分/1.89分 | step: 24720 | performance: 0.2 | accuracy: 0.25 | loss: 0.78
update:1035/2000, 耗时:0.00分/1.90分 | step: 24840 | performance: 0.2 | accuracy: 0.25 | loss: 0.12
update:1040/2000, 耗时:0.00分/1.91分 | step: 24960 | performance: 0.2 | accuracy: 0.25 | loss: 0.02
update:1045/2000, 耗时:0.00分/1.91分 | step: 25080 | performance: 0.2 | accuracy: 0.25 | loss: 0.25
update:1050/2000, 耗时:0.00分/1.92分 | step: 25200 | performance: 0.2 | accuracy: 0.25 | loss: 0.14
Saving PPO weights in both H5 format and checkpoint @ update:1052 
update:1055/2000, 耗时:0.00分/1.94分 | step: 25320 | performance: 1.0 | accuracy: 0.20 | loss: 0.35
update:1060/2000, 耗时:0.00分/1.94分 | step: 25440 | performance: 1.0 | accuracy: 0.20 | loss: 0.25
step: 25507 | worker_2@n_step_2: average total_reward after train data exhaustion : 27.8 | max total_reward: 53.1
update:1065/2000, 耗时:0.00分/1.95分 | step: 25560 | performance: 1.0 | accuracy: 0.12 | loss: 0.19
step: 25679 | worker_6@n_step_2: average total_reward after train data exhaustion : 15.8 | max total_reward: 53.1
update:1070/2000, 耗时:0.00分/1.96分 | step: 25680 | performance: 1.0 | accuracy: 0.00 | loss: 0.28
update:1075/2000, 耗时:0.00分/1.97分 | step: 25800 | performance: 1.0 | accuracy: 0.00 | loss: 0.25
update:1080/2000, 耗时:0.00分/1.98分 | step: 25920 | performance: 1.0 | accuracy: 0.24 | loss: 0.15
update:1085/2000, 耗时:0.00分/1.99分 | step: 26040 | performance: 1.0 | accuracy: 0.16 | loss: 0.10
step: 26087 | worker_6@n_step_2: average total_reward after train data exhaustion : 12.1 | max total_reward: 53.1
step: 26107 | worker_2@n_step_2: average total_reward after train data exhaustion : 11.6 | max total_reward: 53.1
update:1090/2000, 耗时:0.00分/2.00分 | step: 26160 | performance: 1.0 | accuracy: 0.13 | loss: 0.18
update:1095/2000, 耗时:0.00分/2.00分 | step: 26280 | performance: 1.0 | accuracy: 0.15 | loss: 0.14
update:1100/2000, 耗时:0.00分/2.01分 | step: 26400 | performance: 1.0 | accuracy: 0.14 | loss: 0.31
update:1105/2000, 耗时:0.00分/2.02分 | step: 26520 | performance: 1.0 | accuracy: 0.13 | loss: 0.31
update:1110/2000, 耗时:0.00分/2.03分 | step: 26640 | performance: 1.0 | accuracy: 0.11 | loss: 0.52
update:1115/2000, 耗时:0.00分/2.04分 | step: 26760 | performance: 1.0 | accuracy: 0.12 | loss: 0.43
update:1120/2000, 耗时:0.00分/2.05分 | step: 26880 | performance: 1.0 | accuracy: 0.13 | loss: 0.52
step: 26923 | worker_2@n_step_2: average total_reward after train data exhaustion : 9.6 | max total_reward: 53.1
update:1125/2000, 耗时:0.00分/2.05分 | step: 27000 | performance: 0.8 | accuracy: 0.13 | loss: 0.30
update:1130/2000, 耗时:0.00分/2.06分 | step: 27120 | performance: 1.0 | accuracy: 0.14 | loss: 0.64
update:1135/2000, 耗时:0.00分/2.07分 | step: 27240 | performance: 1.5 | accuracy: 0.19 | loss: 0.53
step: 27331 | worker_2@n_step_2: average total_reward after train data exhaustion : 8.6 | max total_reward: 53.1
update:1140/2000, 耗时:0.00分/2.08分 | step: 27360 | performance: 1.6 | accuracy: 0.18 | loss: 0.16
update:1145/2000, 耗时:0.00分/2.09分 | step: 27480 | performance: 1.7 | accuracy: 0.18 | loss: 0.45
update:1150/2000, 耗时:0.00分/2.10分 | step: 27600 | performance: 1.6 | accuracy: 0.19 | loss: 0.68
update:1155/2000, 耗时:0.00分/2.11分 | step: 27720 | performance: 1.6 | accuracy: 0.20 | loss: 0.50
step: 27739 | worker_2@n_step_2: average total_reward after train data exhaustion : 7.8 | max total_reward: 53.1
update:1160/2000, 耗时:0.00分/2.11分 | step: 27840 | performance: 1.7 | accuracy: 0.19 | loss: 0.83
update:1165/2000, 耗时:0.00分/2.12分 | step: 27960 | performance: 1.7 | accuracy: 0.19 | loss: 0.37
update:1170/2000, 耗时:0.00分/2.13分 | step: 28080 | performance: 1.8 | accuracy: 0.21 | loss: 0.50
update:1175/2000, 耗时:0.00分/2.14分 | step: 28200 | performance: 1.8 | accuracy: 0.21 | loss: 0.39
update:1180/2000, 耗时:0.00分/2.15分 | step: 28320 | performance: 1.8 | accuracy: 0.20 | loss: 0.12
update:1185/2000, 耗时:0.00分/2.16分 | step: 28440 | performance: 1.7 | accuracy: 0.20 | loss: 0.22
step: 28555 | worker_2@n_step_2: average total_reward after train data exhaustion : 7.0 | max total_reward: 53.1
update:1190/2000, 耗时:0.00分/2.17分 | step: 28560 | performance: 1.7 | accuracy: 0.19 | loss: 0.09
update:1195/2000, 耗时:0.00分/2.17分 | step: 28680 | performance: 1.7 | accuracy: 0.19 | loss: 0.07
update:1200/2000, 耗时:0.00分/2.18分 | step: 28800 | performance: 1.7 | accuracy: 0.18 | loss: 0.07
update:1205/2000, 耗时:0.00分/2.19分 | step: 28920 | performance: 1.7 | accuracy: 0.18 | loss: 0.05
step: 28963 | worker_2@n_step_2: average total_reward after train data exhaustion : 6.5 | max total_reward: 53.1
update:1210/2000, 耗时:0.00分/2.20分 | step: 29040 | performance: 1.7 | accuracy: 0.17 | loss: 0.03
update:1215/2000, 耗时:0.00分/2.21分 | step: 29160 | performance: 1.7 | accuracy: 0.17 | loss: 0.13
update:1220/2000, 耗时:0.00分/2.21分 | step: 29280 | performance: 1.7 | accuracy: 0.16 | loss: 0.08
step: 29371 | worker_2@n_step_2: average total_reward after train data exhaustion : 6.1 | max total_reward: 53.1
update:1225/2000, 耗时:0.00分/2.22分 | step: 29400 | performance: 1.7 | accuracy: 0.16 | loss: 0.24
update:1230/2000, 耗时:0.00分/2.23分 | step: 29520 | performance: 1.7 | accuracy: 0.16 | loss: 0.09
update:1235/2000, 耗时:0.00分/2.24分 | step: 29640 | performance: 1.7 | accuracy: 0.15 | loss: 0.15
update:1240/2000, 耗时:0.00分/2.24分 | step: 29760 | performance: 1.7 | accuracy: 0.15 | loss: 0.10
step: 29779 | worker_2@n_step_2: average total_reward after train data exhaustion : 5.6 | max total_reward: 53.1
update:1245/2000, 耗时:0.00分/2.25分 | step: 29880 | performance: 1.7 | accuracy: 0.14 | loss: 0.00
update:1250/2000, 耗时:0.00分/2.26分 | step: 30000 | performance: 1.8 | accuracy: 0.15 | loss: 0.41
update:1255/2000, 耗时:0.00分/2.27分 | step: 30120 | performance: 1.8 | accuracy: 0.15 | loss: 0.49
step: 30187 | worker_2@n_step_2: average total_reward after train data exhaustion : 4.0 | max total_reward: 53.1
update:1260/2000, 耗时:0.00分/2.28分 | step: 30240 | performance: 1.9 | accuracy: 0.15 | loss: 0.28
update:1265/2000, 耗时:0.00分/2.28分 | step: 30360 | performance: 2.0 | accuracy: 0.15 | loss: 1.36
update:1270/2000, 耗时:0.00分/2.29分 | step: 30480 | performance: 2.4 | accuracy: 0.15 | loss: 0.12
step: 30595 | worker_2@n_step_2: average total_reward after train data exhaustion : 1.4 | max total_reward: 53.1
update:1275/2000, 耗时:0.00分/2.30分 | step: 30600 | performance: 2.9 | accuracy: 0.15 | loss: 0.38
update:1280/2000, 耗时:0.00分/2.31分 | step: 30720 | performance: 2.8 | accuracy: 0.15 | loss: 0.52
update:1285/2000, 耗时:0.00分/2.32分 | step: 30840 | performance: 2.1 | accuracy: 0.15 | loss: 0.18
update:1290/2000, 耗时:0.00分/2.32分 | step: 30960 | performance: 1.9 | accuracy: 0.15 | loss: 0.22
step: 31003 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.9 | max total_reward: 53.1
update:1295/2000, 耗时:0.00分/2.33分 | step: 31080 | performance: 2.0 | accuracy: 0.15 | loss: 0.06
update:1300/2000, 耗时:0.00分/2.34分 | step: 31200 | performance: 2.0 | accuracy: 0.15 | loss: 0.02
update:1305/2000, 耗时:0.00分/2.35分 | step: 31320 | performance: 1.9 | accuracy: 0.14 | loss: 0.10
step: 31411 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.6 | max total_reward: 53.1
update:1310/2000, 耗时:0.00分/2.36分 | step: 31440 | performance: 1.8 | accuracy: 0.14 | loss: 0.02
update:1315/2000, 耗时:0.00分/2.37分 | step: 31560 | performance: 1.8 | accuracy: 0.14 | loss: 0.05
update:1320/2000, 耗时:0.00分/2.37分 | step: 31680 | performance: 1.8 | accuracy: 0.14 | loss: 0.02
update:1325/2000, 耗时:0.00分/2.38分 | step: 31800 | performance: 1.8 | accuracy: 0.14 | loss: 0.09
step: 31819 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.6 | max total_reward: 53.1
update:1330/2000, 耗时:0.00分/2.39分 | step: 31920 | performance: 1.8 | accuracy: 0.14 | loss: 0.09
update:1335/2000, 耗时:0.00分/2.40分 | step: 32040 | performance: 1.8 | accuracy: 0.14 | loss: 0.14
update:1340/2000, 耗时:0.00分/2.41分 | step: 32160 | performance: 1.8 | accuracy: 0.14 | loss: 0.21
step: 32227 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.4 | max total_reward: 53.1
update:1345/2000, 耗时:0.00分/2.42分 | step: 32280 | performance: 1.8 | accuracy: 0.14 | loss: 0.09
update:1350/2000, 耗时:0.00分/2.43分 | step: 32400 | performance: 1.8 | accuracy: 0.14 | loss: 0.00
update:1355/2000, 耗时:0.00分/2.43分 | step: 32520 | performance: 1.8 | accuracy: 0.13 | loss: 0.07
step: 32635 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.4 | max total_reward: 53.1
update:1360/2000, 耗时:0.00分/2.44分 | step: 32640 | performance: 1.8 | accuracy: 0.13 | loss: 0.10
update:1365/2000, 耗时:0.00分/2.45分 | step: 32760 | performance: 1.8 | accuracy: 0.13 | loss: 0.13
update:1370/2000, 耗时:0.00分/2.46分 | step: 32880 | performance: 1.8 | accuracy: 0.13 | loss: 0.13
update:1375/2000, 耗时:0.00分/2.47分 | step: 33000 | performance: 1.8 | accuracy: 0.13 | loss: 0.01
step: 33043 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.3 | max total_reward: 53.1
update:1380/2000, 耗时:0.00分/2.48分 | step: 33120 | performance: 1.8 | accuracy: 0.13 | loss: 0.00
update:1385/2000, 耗时:0.00分/2.49分 | step: 33240 | performance: 1.8 | accuracy: 0.13 | loss: 0.16
update:1390/2000, 耗时:0.00分/2.49分 | step: 33360 | performance: 2.0 | accuracy: 0.13 | loss: 0.25
step: 33451 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.2 | max total_reward: 53.1
update:1395/2000, 耗时:0.00分/2.50分 | step: 33480 | performance: 2.0 | accuracy: 0.13 | loss: 0.04
update:1400/2000, 耗时:0.00分/2.51分 | step: 33600 | performance: 1.9 | accuracy: 0.13 | loss: 0.19
step: 33713 | worker_0@n_step_2: average total_reward after train data exhaustion : 0.9 | max total_reward: 58.5
update:1405/2000, 耗时:0.00分/2.52分 | step: 33720 | performance: 1.9 | accuracy: 0.13 | loss: 0.24
update:1410/2000, 耗时:0.00分/2.53分 | step: 33840 | performance: 1.9 | accuracy: 0.13 | loss: 0.18
update:1415/2000, 耗时:0.00分/2.54分 | step: 33960 | performance: 1.8 | accuracy: 0.13 | loss: 0.05
step: 34027 | worker_2@n_step_2: average total_reward after train data exhaustion : 1.0 | max total_reward: 58.5
update:1420/2000, 耗时:0.00分/2.54分 | step: 34080 | performance: 1.8 | accuracy: 0.13 | loss: 0.18
step: 34121 | worker_0@n_step_2: average total_reward after train data exhaustion : 1.0 | max total_reward: 58.5
update:1425/2000, 耗时:0.00分/2.55分 | step: 34200 | performance: 1.8 | accuracy: 0.13 | loss: 0.32
update:1430/2000, 耗时:0.00分/2.56分 | step: 34320 | performance: 1.8 | accuracy: 0.12 | loss: 0.04
step: 34435 | worker_2@n_step_2: average total_reward after train data exhaustion : 1.0 | max total_reward: 58.5
update:1435/2000, 耗时:0.00分/2.57分 | step: 34440 | performance: 1.8 | accuracy: 0.12 | loss: 0.26
update:1440/2000, 耗时:0.00分/2.58分 | step: 34560 | performance: 1.9 | accuracy: 0.12 | loss: 0.28
update:1445/2000, 耗时:0.00分/2.59分 | step: 34680 | performance: 1.9 | accuracy: 0.12 | loss: 0.09
step: 34697 | worker_0@n_step_2: average total_reward after train data exhaustion : 1.0 | max total_reward: 58.5
update:1450/2000, 耗时:0.00分/2.60分 | step: 34800 | performance: 1.8 | accuracy: 0.12 | loss: 0.01
step: 34843 | worker_2@n_step_2: average total_reward after train data exhaustion : 1.1 | max total_reward: 58.5
update:1455/2000, 耗时:0.00分/2.61分 | step: 34920 | performance: 1.8 | accuracy: 0.12 | loss: 0.12
update:1460/2000, 耗时:0.00分/2.61分 | step: 35040 | performance: 1.8 | accuracy: 0.12 | loss: 0.07
step: 35105 | worker_0@n_step_2: average total_reward after train data exhaustion : 1.1 | max total_reward: 58.5
update:1465/2000, 耗时:0.00分/2.62分 | step: 35160 | performance: 1.9 | accuracy: 0.12 | loss: 0.07
update:1470/2000, 耗时:0.00分/2.63分 | step: 35280 | performance: 1.8 | accuracy: 0.12 | loss: 0.21
update:1475/2000, 耗时:0.00分/2.64分 | step: 35400 | performance: 1.8 | accuracy: 0.12 | loss: 0.22
step: 35419 | worker_2@n_step_2: average total_reward after train data exhaustion : 1.1 | max total_reward: 58.5
step: 35513 | worker_0@n_step_2: average total_reward after train data exhaustion : 1.1 | max total_reward: 58.5
update:1480/2000, 耗时:0.00分/2.65分 | step: 35520 | performance: 1.8 | accuracy: 0.12 | loss: 0.07
update:1485/2000, 耗时:0.00分/2.66分 | step: 35640 | performance: 1.8 | accuracy: 0.12 | loss: 0.12
update:1490/2000, 耗时:0.00分/2.67分 | step: 35760 | performance: 1.8 | accuracy: 0.11 | loss: 0.04
step: 35827 | worker_2@n_step_2: average total_reward after train data exhaustion : 1.1 | max total_reward: 58.5
update:1495/2000, 耗时:0.00分/2.67分 | step: 35880 | performance: 1.8 | accuracy: 0.11 | loss: -0.00
step: 35921 | worker_0@n_step_2: average total_reward after train data exhaustion : 1.1 | max total_reward: 58.5
update:1500/2000, 耗时:0.00分/2.68分 | step: 36000 | performance: 1.8 | accuracy: 0.12 | loss: 0.03
update:1505/2000, 耗时:0.00分/2.69分 | step: 36120 | performance: 1.8 | accuracy: 0.12 | loss: 0.04
step: 36235 | worker_2@n_step_2: average total_reward after train data exhaustion : 1.0 | max total_reward: 58.5
update:1510/2000, 耗时:0.00分/2.70分 | step: 36240 | performance: 1.8 | accuracy: 0.12 | loss: 0.00
step: 36329 | worker_0@n_step_2: average total_reward after train data exhaustion : 1.0 | max total_reward: 58.5
update:1515/2000, 耗时:0.00分/2.71分 | step: 36360 | performance: 1.8 | accuracy: 0.12 | loss: 0.03
update:1520/2000, 耗时:0.00分/2.72分 | step: 36480 | performance: 1.8 | accuracy: 0.11 | loss: 0.05
update:1525/2000, 耗时:0.00分/2.73分 | step: 36600 | performance: 1.8 | accuracy: 0.11 | loss: 0.03
step: 36643 | worker_2@n_step_2: average total_reward after train data exhaustion : 1.0 | max total_reward: 58.5
update:1530/2000, 耗时:0.00分/2.74分 | step: 36720 | performance: 1.9 | accuracy: 0.11 | loss: -0.00
step: 36737 | worker_0@n_step_2: average total_reward after train data exhaustion : 1.0 | max total_reward: 58.5
update:1535/2000, 耗时:0.00分/2.74分 | step: 36840 | performance: 1.9 | accuracy: 0.11 | loss: 0.06
update:1540/2000, 耗时:0.00分/2.75分 | step: 36960 | performance: 1.9 | accuracy: 0.11 | loss: 0.18
step: 37031 | worker_6@n_step_2: average total_reward after train data exhaustion : 1.5 | max total_reward: 81.5
step: 37051 | worker_2@n_step_2: average total_reward after train data exhaustion : 1.5 | max total_reward: 81.5
update:1545/2000, 耗时:0.00分/2.76分 | step: 37080 | performance: 1.9 | accuracy: 0.11 | loss: 0.07
step: 37145 | worker_0@n_step_2: average total_reward after train data exhaustion : 1.5 | max total_reward: 81.5
update:1550/2000, 耗时:0.00分/2.77分 | step: 37200 | performance: 1.9 | accuracy: 0.11 | loss: 0.00
update:1555/2000, 耗时:0.00分/2.78分 | step: 37320 | performance: 1.9 | accuracy: 0.11 | loss: 0.00
step: 37439 | worker_6@n_step_2: average total_reward after train data exhaustion : 1.5 | max total_reward: 81.5
update:1560/2000, 耗时:0.00分/2.79分 | step: 37440 | performance: 1.9 | accuracy: 0.11 | loss: 0.11
step: 37459 | worker_2@n_step_2: average total_reward after train data exhaustion : 1.5 | max total_reward: 81.5
step: 37553 | worker_0@n_step_2: average total_reward after train data exhaustion : 1.5 | max total_reward: 81.5
update:1565/2000, 耗时:0.00分/2.80分 | step: 37560 | performance: 1.9 | accuracy: 0.11 | loss: 0.04
update:1570/2000, 耗时:0.00分/2.81分 | step: 37680 | performance: 1.8 | accuracy: 0.11 | loss: 0.05
update:1575/2000, 耗时:0.00分/2.81分 | step: 37800 | performance: 1.8 | accuracy: 0.11 | loss: 0.02
step: 37847 | worker_6@n_step_2: average total_reward after train data exhaustion : 2.9 | max total_reward: 81.5
step: 37867 | worker_2@n_step_2: average total_reward after train data exhaustion : 2.9 | max total_reward: 81.5
step: 37869 | worker_4@n_step_2: average total_reward after train data exhaustion : 3.0 | max total_reward: 81.5
update:1580/2000, 耗时:0.00分/2.82分 | step: 37920 | performance: 2.0 | accuracy: 0.11 | loss: 0.02
step: 37961 | worker_0@n_step_2: average total_reward after train data exhaustion : 3.0 | max total_reward: 81.5
update:1585/2000, 耗时:0.00分/2.83分 | step: 38040 | performance: 2.0 | accuracy: 0.11 | loss: 0.00
update:1590/2000, 耗时:0.00分/2.84分 | step: 38160 | performance: 2.0 | accuracy: 0.11 | loss: 0.00
step: 38255 | worker_6@n_step_2: average total_reward after train data exhaustion : 4.6 | max total_reward: 81.5
step: 38275 | worker_2@n_step_2: average total_reward after train data exhaustion : 4.6 | max total_reward: 81.5
step: 38277 | worker_4@n_step_2: average total_reward after train data exhaustion : 4.6 | max total_reward: 81.5
update:1595/2000, 耗时:0.00分/2.85分 | step: 38280 | performance: 2.0 | accuracy: 0.11 | loss: 0.00
step: 38324 | worker_3@n_step_2: average total_reward after train data exhaustion : 4.6 | max total_reward: 81.5
step: 38369 | worker_0@n_step_2: average total_reward after train data exhaustion : 4.6 | max total_reward: 81.5
update:1600/2000, 耗时:0.00分/2.86分 | step: 38400 | performance: 2.0 | accuracy: 0.10 | loss: 0.03
update:1605/2000, 耗时:0.00分/2.87分 | step: 38520 | performance: 2.0 | accuracy: 0.10 | loss: 0.03
step: 38586 | worker_1@n_step_2: average total_reward after train data exhaustion : 4.4 | max total_reward: 81.5
update:1610/2000, 耗时:0.00分/2.88分 | step: 38640 | performance: 2.0 | accuracy: 0.10 | loss: 0.04
step: 38663 | worker_6@n_step_2: average total_reward after train data exhaustion : 4.4 | max total_reward: 81.5
step: 38683 | worker_2@n_step_2: average total_reward after train data exhaustion : 4.4 | max total_reward: 81.5
step: 38685 | worker_4@n_step_2: average total_reward after train data exhaustion : 4.4 | max total_reward: 81.5
step: 38732 | worker_3@n_step_2: average total_reward after train data exhaustion : 4.5 | max total_reward: 81.5
update:1615/2000, 耗时:0.00分/2.88分 | step: 38760 | performance: 2.0 | accuracy: 0.10 | loss: 0.02
step: 38777 | worker_0@n_step_2: average total_reward after train data exhaustion : 4.5 | max total_reward: 81.5
update:1620/2000, 耗时:0.00分/2.89分 | step: 38880 | performance: 2.0 | accuracy: 0.10 | loss: 0.07
step: 38994 | worker_1@n_step_2: average total_reward after train data exhaustion : 4.5 | max total_reward: 81.5
update:1625/2000, 耗时:0.00分/2.90分 | step: 39000 | performance: 2.0 | accuracy: 0.10 | loss: 0.00
step: 39071 | worker_6@n_step_2: average total_reward after train data exhaustion : 3.0 | max total_reward: 81.5
step: 39091 | worker_2@n_step_2: average total_reward after train data exhaustion : 3.0 | max total_reward: 81.5
step: 39093 | worker_4@n_step_2: average total_reward after train data exhaustion : 3.0 | max total_reward: 81.5
update:1630/2000, 耗时:0.00分/2.91分 | step: 39120 | performance: 2.0 | accuracy: 0.10 | loss: 0.01
step: 39140 | worker_3@n_step_2: average total_reward after train data exhaustion : 3.0 | max total_reward: 81.5
step: 39185 | worker_0@n_step_2: average total_reward after train data exhaustion : 3.0 | max total_reward: 81.5
update:1635/2000, 耗时:0.00分/2.92分 | step: 39240 | performance: 2.0 | accuracy: 0.10 | loss: 0.00
update:1640/2000, 耗时:0.00分/2.93分 | step: 39360 | performance: 2.0 | accuracy: 0.10 | loss: 0.01
step: 39402 | worker_1@n_step_2: average total_reward after train data exhaustion : 3.5 | max total_reward: 104.4
step: 39479 | worker_6@n_step_2: average total_reward after train data exhaustion : 3.5 | max total_reward: 104.4
update:1645/2000, 耗时:0.00分/2.94分 | step: 39480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 39499 | worker_2@n_step_2: average total_reward after train data exhaustion : 3.5 | max total_reward: 104.4
step: 39501 | worker_4@n_step_2: average total_reward after train data exhaustion : 3.5 | max total_reward: 104.4
step: 39528 | worker_7@n_step_2: average total_reward after train data exhaustion : 3.5 | max total_reward: 104.4
step: 39548 | worker_3@n_step_2: average total_reward after train data exhaustion : 2.1 | max total_reward: 104.4
step: 39593 | worker_0@n_step_2: average total_reward after train data exhaustion : 2.1 | max total_reward: 104.4
update:1650/2000, 耗时:0.00分/2.95分 | step: 39600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1655/2000, 耗时:0.00分/2.95分 | step: 39720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 39810 | worker_1@n_step_2: average total_reward after train data exhaustion : 2.1 | max total_reward: 104.4
update:1660/2000, 耗时:0.00分/2.96分 | step: 39840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 39887 | worker_6@n_step_2: average total_reward after train data exhaustion : 2.1 | max total_reward: 104.4
step: 39907 | worker_2@n_step_2: average total_reward after train data exhaustion : 2.1 | max total_reward: 104.4
step: 39909 | worker_4@n_step_2: average total_reward after train data exhaustion : 2.1 | max total_reward: 104.4
step: 39936 | worker_7@n_step_2: average total_reward after train data exhaustion : 2.1 | max total_reward: 104.4
step: 39956 | worker_3@n_step_2: average total_reward after train data exhaustion : 2.1 | max total_reward: 104.4
update:1665/2000, 耗时:0.00分/2.97分 | step: 39960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 40001 | worker_0@n_step_2: average total_reward after train data exhaustion : 2.1 | max total_reward: 104.4
update:1670/2000, 耗时:0.00分/2.98分 | step: 40080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 40126 | worker_5@n_step_2: average total_reward after train data exhaustion : 4.0 | max total_reward: 104.4
update:1675/2000, 耗时:0.00分/2.99分 | step: 40200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 40218 | worker_1@n_step_2: average total_reward after train data exhaustion : 4.0 | max total_reward: 104.4
step: 40295 | worker_6@n_step_2: average total_reward after train data exhaustion : 4.0 | max total_reward: 104.4
step: 40315 | worker_2@n_step_2: average total_reward after train data exhaustion : 4.1 | max total_reward: 104.4
step: 40317 | worker_4@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
update:1680/2000, 耗时:0.00分/3.00分 | step: 40320 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 40344 | worker_7@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
step: 40364 | worker_3@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
step: 40409 | worker_0@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
update:1685/2000, 耗时:0.00分/3.01分 | step: 40440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 40534 | worker_5@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
update:1690/2000, 耗时:0.00分/3.02分 | step: 40560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 40626 | worker_1@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
update:1695/2000, 耗时:0.00分/3.02分 | step: 40680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 40703 | worker_6@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
step: 40723 | worker_2@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
step: 40725 | worker_4@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
step: 40752 | worker_7@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
step: 40772 | worker_3@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
update:1700/2000, 耗时:0.00分/3.03分 | step: 40800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 40817 | worker_0@n_step_2: average total_reward after train data exhaustion : 2.0 | max total_reward: 104.4
update:1705/2000, 耗时:0.00分/3.04分 | step: 40920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 40942 | worker_5@n_step_2: average total_reward after train data exhaustion : 1.9 | max total_reward: 104.4
step: 41034 | worker_1@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1710/2000, 耗时:0.00分/3.05分 | step: 41040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 41111 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 41131 | worker_2@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 41133 | worker_4@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 41160 | worker_7@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1715/2000, 耗时:0.00分/3.06分 | step: 41160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 41180 | worker_3@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 41225 | worker_0@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
update:1720/2000, 耗时:0.00分/3.07分 | step: 41280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 41350 | worker_5@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
update:1725/2000, 耗时:0.00分/3.08分 | step: 41400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 41442 | worker_1@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 41519 | worker_6@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
update:1730/2000, 耗时:0.00分/3.08分 | step: 41520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 41539 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 41541 | worker_4@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 41568 | worker_7@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 41588 | worker_3@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 41633 | worker_0@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
update:1735/2000, 耗时:0.00分/3.09分 | step: 41640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 41758 | worker_5@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
update:1740/2000, 耗时:0.00分/3.10分 | step: 41760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 41850 | worker_1@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
update:1745/2000, 耗时:0.00分/3.11分 | step: 41880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 41927 | worker_6@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 41947 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 41949 | worker_4@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 41976 | worker_7@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 41996 | worker_3@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
update:1750/2000, 耗时:0.00分/3.12分 | step: 42000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 42041 | worker_0@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
update:1755/2000, 耗时:0.00分/3.13分 | step: 42120 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 42166 | worker_5@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
update:1760/2000, 耗时:0.00分/3.14分 | step: 42240 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 42258 | worker_1@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 42335 | worker_6@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 42355 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
step: 42357 | worker_4@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 104.4
update:1765/2000, 耗时:0.00分/3.15分 | step: 42360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 42384 | worker_7@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 42404 | worker_3@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 42449 | worker_0@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1770/2000, 耗时:0.00分/3.16分 | step: 42480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 42574 | worker_5@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1775/2000, 耗时:0.00分/3.16分 | step: 42600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 42666 | worker_1@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1780/2000, 耗时:0.00分/3.17分 | step: 42720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 42743 | worker_6@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 42763 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 42765 | worker_4@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 42792 | worker_7@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 42812 | worker_3@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1785/2000, 耗时:0.00分/3.18分 | step: 42840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 42857 | worker_0@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1790/2000, 耗时:0.00分/3.19分 | step: 42960 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 42982 | worker_5@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43074 | worker_1@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1795/2000, 耗时:0.00分/3.20分 | step: 43080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 43151 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43171 | worker_2@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43173 | worker_4@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43200 | worker_7@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1800/2000, 耗时:0.00分/3.21分 | step: 43200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 43220 | worker_3@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43265 | worker_0@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1805/2000, 耗时:0.00分/3.22分 | step: 43320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 43390 | worker_5@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1810/2000, 耗时:0.00分/3.22分 | step: 43440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 43482 | worker_1@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43559 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1815/2000, 耗时:0.00分/3.23分 | step: 43560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 43579 | worker_2@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43581 | worker_4@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43608 | worker_7@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43628 | worker_3@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43673 | worker_0@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1820/2000, 耗时:0.00分/3.24分 | step: 43680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 43798 | worker_5@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1825/2000, 耗时:0.00分/3.25分 | step: 43800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 43890 | worker_1@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1830/2000, 耗时:0.00分/3.26分 | step: 43920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 43967 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43987 | worker_2@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 43989 | worker_4@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 44016 | worker_7@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 44036 | worker_3@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1835/2000, 耗时:0.00分/3.27分 | step: 44040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 44081 | worker_0@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1840/2000, 耗时:0.00分/3.28分 | step: 44160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 44206 | worker_5@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1845/2000, 耗时:0.00分/3.29分 | step: 44280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 44298 | worker_1@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 44375 | worker_6@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 44395 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 44397 | worker_4@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1850/2000, 耗时:0.00分/3.30分 | step: 44400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 44424 | worker_7@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 44444 | worker_3@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 44489 | worker_0@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1855/2000, 耗时:0.00分/3.30分 | step: 44520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 44614 | worker_5@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1860/2000, 耗时:0.00分/3.31分 | step: 44640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 44706 | worker_1@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1865/2000, 耗时:0.00分/3.32分 | step: 44760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 44783 | worker_6@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 44803 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 44805 | worker_4@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 44832 | worker_7@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 44852 | worker_3@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1870/2000, 耗时:0.00分/3.33分 | step: 44880 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 44897 | worker_0@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1875/2000, 耗时:0.00分/3.34分 | step: 45000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 45022 | worker_5@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 45114 | worker_1@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1880/2000, 耗时:0.00分/3.35分 | step: 45120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 45191 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 45211 | worker_2@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 45213 | worker_4@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 45240 | worker_7@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1885/2000, 耗时:0.00分/3.36分 | step: 45240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 45260 | worker_3@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 45305 | worker_0@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1890/2000, 耗时:0.00分/3.37分 | step: 45360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 45430 | worker_5@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1895/2000, 耗时:0.00分/3.37分 | step: 45480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 45522 | worker_1@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 45599 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1900/2000, 耗时:0.00分/3.38分 | step: 45600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 45619 | worker_2@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 45621 | worker_4@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 45648 | worker_7@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 45668 | worker_3@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 45713 | worker_0@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1905/2000, 耗时:0.00分/3.39分 | step: 45720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 45838 | worker_5@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1910/2000, 耗时:0.00分/3.40分 | step: 45840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 45930 | worker_1@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1915/2000, 耗时:0.00分/3.41分 | step: 45960 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 46007 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 46027 | worker_2@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 46029 | worker_4@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 46056 | worker_7@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 46076 | worker_3@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1920/2000, 耗时:0.00分/3.42分 | step: 46080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 46121 | worker_0@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1925/2000, 耗时:0.00分/3.43分 | step: 46200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 46246 | worker_5@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1930/2000, 耗时:0.00分/3.44分 | step: 46320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 46338 | worker_1@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 46415 | worker_6@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 46435 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 46437 | worker_4@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1935/2000, 耗时:0.00分/3.45分 | step: 46440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 46464 | worker_7@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 46484 | worker_3@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 46529 | worker_0@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1940/2000, 耗时:0.00分/3.45分 | step: 46560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 46654 | worker_5@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1945/2000, 耗时:0.00分/3.46分 | step: 46680 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 46746 | worker_1@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1950/2000, 耗时:0.00分/3.47分 | step: 46800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 46823 | worker_6@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 46843 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 46845 | worker_4@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 46872 | worker_7@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
step: 46892 | worker_3@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1955/2000, 耗时:0.00分/3.48分 | step: 46920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 46937 | worker_0@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 104.4
update:1960/2000, 耗时:0.00分/3.49分 | step: 47040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 47062 | worker_5@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 47154 | worker_1@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1965/2000, 耗时:0.00分/3.50分 | step: 47160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 47231 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 47251 | worker_2@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 47253 | worker_4@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 47280 | worker_7@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1970/2000, 耗时:0.00分/3.51分 | step: 47280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 47300 | worker_3@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 47345 | worker_0@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1975/2000, 耗时:0.00分/3.52分 | step: 47400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 47470 | worker_5@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1980/2000, 耗时:0.00分/3.53分 | step: 47520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 47562 | worker_1@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 47639 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1985/2000, 耗时:0.00分/3.53分 | step: 47640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 47659 | worker_2@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 47661 | worker_4@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 47688 | worker_7@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 47708 | worker_3@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
step: 47753 | worker_0@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1990/2000, 耗时:0.00分/3.54分 | step: 47760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 47878 | worker_5@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:1995/2000, 耗时:0.00分/3.55分 | step: 47880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 47970 | worker_1@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 104.4
update:2000/2000, 耗时:0.00分/3.56分 | step: 48000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
  0%|          | 0/403 [00:00<?, ?it/s]100%|| 403/403 [00:00<00:00, 100889.61it/s]
----------------------------------------finished----------------------------------------
==================================================
2023-01-04T12:00:00 | *** START BACKTEST ***
2023-01-04T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1015.32
2023-07-24T12:00:00 | net performance [%] = 1.5317
2023-07-24T12:00:00 | number of trades [#] = 2
==================================================
Trial 18 Complete [00h 04m 00s]
net_wealth: 1016.3331121870366

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 02h 19m 46s

Search: Running Trial #19

Value             |Best Value So Far |Hyperparameter
4                 |1                 |horizon
225               |730               |lookback
False             |False             |MarketFactor
7                 |3                 |lags
0.6               |0.92              |gamma
16                |32                |batch_size
10                |1                 |n_step
0.98              |0.94              |gae_lambda
0.1               |5                 |gradient_clip_norm
3                 |5                 |epochs
0.001             |0.0001            |actor_lr
0.0001            |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4311.000000   4315.000000
mean      0.000441    20062.255222  ...   20133.281642  20118.633889
std       0.027818    16039.874230  ...   16077.358923  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7695.614990   7690.540039
50%       0.000642    11554.824463  ...   11741.480469  11715.610352
75%       0.011655    29873.081836  ...   29939.474609  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 00:23:08.891194: I tensorflow/core/platform/cpu_feature_guard.cc:142] 2023-07-28 00:23:08.891232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU ins2023-07-28 022023-07-28 00:23:08.0t8r023:uct9-07-2i8o213:083.n3 009: I tenss in :o823:91329:08r.p eI tflow/ceorernsorflow/f8c/91340: IpoThis  Tensortenslororefatlro/platfmaorformn/ceFcplow u_-bcinarwritic/coalf eaturem_y is guard2opo023-p07/-2timc8 0r0:e23:0.i/8.cc:18z9pue16_pfed eraattilwointhsuar :e to_n feogua4rArVd.cc2mX/ cApV:X2u2_fAPI De01ea]t4ue823p N eT26u:his 2Tr
Tor]al -e_0gN0 7en2enusaa3 --e2o8rd0.tThwo7-cc:ir 28 I  tr001s 0:20T43k:enso02rF:82l.owbl89 ]e eThis  nsL 1tihbreaobinr7arfmrly (oo9F2:n wil/oyc wo n  eDbNiorIe 3Te/:ipnnstalrorheratNeFy t) fnloow br mis oispos/onrfcptp olptowiu_ot i0/c8fusemomeiz eterar.idhee a/p lawitt8h9f1taryi oo tfioznssu,n rr oebeed uriwldp_m/c8g 04eAitT:euPaIr Dd.eh onlslepcuco :I142] wi_orFTn ogf ChpealioPtennwU etsso  wuAr tiNPrie_gfiTthmueI De iazrudr.aep Nl tecedn cw:ietshenhN ose twaoornteFrrkAPuIcpplr tuoroal D wp NeibritLiiebeoansnapw  in pertfeorlNeuorom1 4raarrcaorwnyc ek-cr Llyi i2b]r aTrh/ctoiycais risem /(l ( oneDoNo NpNe)pTertawtoiroennso ieDlokp tnerFilsmitzNer:L i b od  urplwsef laAaVaiotw hbtfrgXi nAyteN )f otlVlXoowoi nags. 
hCP U  r(rinoyn isou opemAPI2t
isminT/osz edD ee eetnawicDprNtb utchheNe)ul folt _ep lioo Nofewns in ing tneAPI ChatPU inupres_tgreueuaucetm  trrrDoe use the folliond.s inowing Cin e perforcc:142] This TensorFlow binary is optimized with oneAPI Deep Neural PoUaNetwork Libralmther ope rr Networy ak Librariynstructions in performance-ctions, rrfitiocal operations:  AVa( p(orn enecbXoDnNeNDmeui-ca)Neu trnice-critical otilpNo use the following CPU instru ral NetwAdecractionos  ationTensorFlow with the approrVX2
Tokin performance-critl pr N) to usicaiea thetsl :oe   oLppibfecoollroawmpiler flrinera tiationarye (sonsg:s.no neaD
b gA NNAl)V t : CVPX UoeAX   AinVstXt Vu2
To enableructions in p hem in oX 2
erTAVX AVX2
To enathem in other operatitbhseoleeons  them  r otein, rnpaferatohe eobble theu rmiitlhm ainnceo following Cndo r etheoperatior operations, res-, rebuTcenbusi,ld Tein nrlsrsioorFtical operaPloUr Fltoiionsnswd:   AtructioTw witensnVXo sw iebuild TensorFlow witn  prith FhAVte rh thtXleow with hhe2
To enable th the appropriate compiler feappropriate m  ieformanl ags.n
 oather operapparoctioons, ppmpilecrprroprierbuiieaatte cl e co-crid Tentical opeorfsmamtpioler flags.
pilrionFlow els:wagrith the ap s .
 flags.
propriaAVX AVX2
To enable them in other operations, rebuild TensorFlow with the approtpriate compilee compr flags.
iler flags.
2023-07-28 00:23:09.504904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:23:09.512352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:23:09.526512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:23:09.540734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:23:09.554863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:23:09.556380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:23:09.577803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:23:09.578814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 0.7 | accuracy: 0.40 | loss: 1.54
update: 10/2000, 耗时:0.00分/0.04分 | step:   800 | performance: 0.4 | accuracy: 0.35 | loss: 1.47
update: 15/2000, 耗时:0.00分/0.05分 | step:  1200 | performance: 0.5 | accuracy: 0.33 | loss: 0.46
update: 20/2000, 耗时:0.00分/0.07分 | step:  1600 | performance: 0.4 | accuracy: 0.29 | loss: 0.49
update: 25/2000, 耗时:0.00分/0.08分 | step:  2000 | performance: 0.3 | accuracy: 0.24 | loss: 0.31
update: 30/2000, 耗时:0.00分/0.09分 | step:  2400 | performance: 0.3 | accuracy: 0.23 | loss: 0.24
update: 35/2000, 耗时:0.00分/0.10分 | step:  2800 | performance: 0.3 | accuracy: 0.22 | loss: 0.54
update: 40/2000, 耗时:0.00分/0.11分 | step:  3200 | performance: 0.2 | accuracy: 0.21 | loss: 0.38
update: 45/2000, 耗时:0.00分/0.13分 | step:  3600 | performance: 0.3 | accuracy: 0.22 | loss: 1.30
update: 50/2000, 耗时:0.00分/0.14分 | step:  4000 | performance: 0.4 | accuracy: 0.23 | loss: 0.51
update: 55/2000, 耗时:0.00分/0.15分 | step:  4400 | performance: 0.4 | accuracy: 0.23 | loss: 0.37
update: 60/2000, 耗时:0.00分/0.16分 | step:  4800 | performance: 0.4 | accuracy: 0.24 | loss: 0.56
update: 65/2000, 耗时:0.00分/0.18分 | step:  5200 | performance: 0.4 | accuracy: 0.23 | loss: 0.23
update: 70/2000, 耗时:0.00分/0.19分 | step:  5600 | performance: 0.5 | accuracy: 0.22 | loss: 0.14
update: 75/2000, 耗时:0.00分/0.21分 | step:  6000 | performance: 0.4 | accuracy: 0.21 | loss: 0.33
update: 80/2000, 耗时:0.00分/0.22分 | step:  6400 | performance: 0.5 | accuracy: 0.20 | loss: 0.07
update: 85/2000, 耗时:0.00分/0.23分 | step:  6800 | performance: 0.5 | accuracy: 0.20 | loss: 0.78
update: 90/2000, 耗时:0.00分/0.25分 | step:  7200 | performance: 0.4 | accuracy: 0.20 | loss: 0.72
update: 95/2000, 耗时:0.00分/0.26分 | step:  7600 | performance: 0.2 | accuracy: 0.21 | loss: 1.30
update:100/2000, 耗时:0.00分/0.28分 | step:  8000 | performance: 0.2 | accuracy: 0.22 | loss: 1.15
update:105/2000, 耗时:0.00分/0.29分 | step:  8400 | performance: 0.5 | accuracy: 0.24 | loss: 2.18
update:110/2000, 耗时:0.00分/0.31分 | step:  8800 | performance: 1.2 | accuracy: 0.25 | loss: 3.37
update:115/2000, 耗时:0.00分/0.32分 | step:  9200 | performance: 0.9 | accuracy: 0.26 | loss: 2.12
update:120/2000, 耗时:0.00分/0.33分 | step:  9600 | performance: 1.1 | accuracy: 0.27 | loss: 1.91
update:125/2000, 耗时:0.00分/0.35分 | step: 10000 | performance: 0.6 | accuracy: 0.28 | loss: 0.84
update:130/2000, 耗时:0.00分/0.36分 | step: 10400 | performance: 0.7 | accuracy: 0.28 | loss: 0.55
update:135/2000, 耗时:0.00分/0.38分 | step: 10800 | performance: 0.4 | accuracy: 0.28 | loss: 3.14
update:140/2000, 耗时:0.00分/0.39分 | step: 11200 | performance: 0.7 | accuracy: 0.29 | loss: 1.95
update:145/2000, 耗时:0.00分/0.40分 | step: 11600 | performance: 1.1 | accuracy: 0.30 | loss: 1.22
update:150/2000, 耗时:0.00分/0.42分 | step: 12000 | performance: 0.8 | accuracy: 0.30 | loss: 1.45
update:155/2000, 耗时:0.00分/0.43分 | step: 12400 | performance: 0.6 | accuracy: 0.30 | loss: 0.53
update:160/2000, 耗时:0.00分/0.45分 | step: 12800 | performance: 0.4 | accuracy: 0.31 | loss: 3.03
update:165/2000, 耗时:0.00分/0.46分 | step: 13200 | performance: 0.2 | accuracy: 0.30 | loss: 0.89
update:170/2000, 耗时:0.00分/0.47分 | step: 13600 | performance: 0.2 | accuracy: 0.30 | loss: 1.17
update:175/2000, 耗时:0.00分/0.49分 | step: 14000 | performance: 0.1 | accuracy: 0.30 | loss: 1.22
update:180/2000, 耗时:0.00分/0.50分 | step: 14400 | performance: 0.1 | accuracy: 0.31 | loss: 0.66
update:185/2000, 耗时:0.00分/0.52分 | step: 14800 | performance: 0.1 | accuracy: 0.31 | loss: 0.70
update:190/2000, 耗时:0.00分/0.53分 | step: 15200 | performance: 0.1 | accuracy: 0.31 | loss: 1.41
update:195/2000, 耗时:0.00分/0.55分 | step: 15600 | performance: 0.1 | accuracy: 0.32 | loss: 3.32
update:200/2000, 耗时:0.00分/0.56分 | step: 16000 | performance: 0.1 | accuracy: 0.32 | loss: 0.37
update:205/2000, 耗时:0.00分/0.57分 | step: 16400 | performance: 0.1 | accuracy: 0.31 | loss: 0.66
update:210/2000, 耗时:0.00分/0.59分 | step: 16800 | performance: 0.1 | accuracy: 0.32 | loss: 1.66
update:215/2000, 耗时:0.00分/0.60分 | step: 17200 | performance: 0.3 | accuracy: 0.33 | loss: 2.33
update:220/2000, 耗时:0.00分/0.62分 | step: 17600 | performance: 0.7 | accuracy: 0.34 | loss: 0.80
update:225/2000, 耗时:0.00分/0.63分 | step: 18000 | performance: 3.2 | accuracy: 0.34 | loss: 3.53
update:230/2000, 耗时:0.00分/0.65分 | step: 18400 | performance: 5.6 | accuracy: 0.35 | loss: 0.72
update:235/2000, 耗时:0.00分/0.66分 | step: 18800 | performance: 9.8 | accuracy: 0.36 | loss: 2.23
update:240/2000, 耗时:0.00分/0.68分 | step: 19200 | performance: 10.9 | accuracy: 0.36 | loss: 1.30
update:245/2000, 耗时:0.00分/0.69分 | step: 19600 | performance: 8.1 | accuracy: 0.36 | loss: 1.31
update:250/2000, 耗时:0.00分/0.70分 | step: 20000 | performance: 3.0 | accuracy: 0.36 | loss: 0.43
update:255/2000, 耗时:0.00分/0.72分 | step: 20400 | performance: 2.6 | accuracy: 0.36 | loss: 0.91
update:260/2000, 耗时:0.00分/0.73分 | step: 20800 | performance: 4.3 | accuracy: 0.36 | loss: 1.06
update:265/2000, 耗时:0.00分/0.75分 | step: 21200 | performance: 2.9 | accuracy: 0.36 | loss: 0.83
update:270/2000, 耗时:0.00分/0.76分 | step: 21600 | performance: 2.7 | accuracy: 0.36 | loss: 1.42
update:275/2000, 耗时:0.00分/0.77分 | step: 22000 | performance: 1.6 | accuracy: 0.36 | loss: 1.04
update:280/2000, 耗时:0.00分/0.79分 | step: 22400 | performance: 5.1 | accuracy: 0.36 | loss: 1.19
update:285/2000, 耗时:0.00分/0.80分 | step: 22800 | performance: 4.8 | accuracy: 0.37 | loss: 1.62
update:290/2000, 耗时:0.00分/0.81分 | step: 23200 | performance: 1.6 | accuracy: 0.37 | loss: 0.89
update:295/2000, 耗时:0.00分/0.83分 | step: 23600 | performance: 1.5 | accuracy: 0.36 | loss: 0.20
update:300/2000, 耗时:0.00分/0.84分 | step: 24000 | performance: 1.2 | accuracy: 0.36 | loss: 1.94
update:305/2000, 耗时:0.00分/0.86分 | step: 24400 | performance: 1.2 | accuracy: 0.36 | loss: 0.40
update:310/2000, 耗时:0.00分/0.87分 | step: 24800 | performance: 0.8 | accuracy: 0.36 | loss: 0.54
update:315/2000, 耗时:0.00分/0.88分 | step: 25200 | performance: 0.5 | accuracy: 0.35 | loss: 0.73
update:320/2000, 耗时:0.00分/0.90分 | step: 25600 | performance: 0.5 | accuracy: 0.35 | loss: 1.40
update:325/2000, 耗时:0.00分/0.91分 | step: 26000 | performance: 0.6 | accuracy: 0.35 | loss: 1.46
update:330/2000, 耗时:0.00分/0.93分 | step: 26400 | performance: 1.2 | accuracy: 0.36 | loss: 1.67
update:335/2000, 耗时:0.00分/0.94分 | step: 26800 | performance: 0.9 | accuracy: 0.36 | loss: 1.77
update:340/2000, 耗时:0.00分/0.96分 | step: 27200 | performance: 0.7 | accuracy: 0.36 | loss: 0.96
update:345/2000, 耗时:0.00分/0.97分 | step: 27600 | performance: 0.8 | accuracy: 0.36 | loss: 3.87
update:350/2000, 耗时:0.00分/0.98分 | step: 28000 | performance: 1.1 | accuracy: 0.36 | loss: 1.71
update:355/2000, 耗时:0.00分/1.00分 | step: 28400 | performance: 1.0 | accuracy: 0.36 | loss: 1.01
update:360/2000, 耗时:0.00分/1.01分 | step: 28800 | performance: 1.8 | accuracy: 0.37 | loss: 1.16
update:365/2000, 耗时:0.00分/1.03分 | step: 29200 | performance: 1.8 | accuracy: 0.37 | loss: 1.20
Saving PPO weights in both H5 format and checkpoint @ update:368 
update:370/2000, 耗时:0.00分/1.04分 | step: 29600 | performance: 0.5 | accuracy: 0.40 | loss: 1.50
update:375/2000, 耗时:0.00分/1.06分 | step: 30000 | performance: 0.4 | accuracy: 0.40 | loss: 1.11
update:380/2000, 耗时:0.00分/1.07分 | step: 30400 | performance: 0.7 | accuracy: 0.39 | loss: 2.32
update:385/2000, 耗时:0.00分/1.08分 | step: 30800 | performance: 1.9 | accuracy: 0.44 | loss: 1.50
update:390/2000, 耗时:0.00分/1.10分 | step: 31200 | performance: 2.3 | accuracy: 0.47 | loss: 3.28
update:395/2000, 耗时:0.00分/1.11分 | step: 31600 | performance: 1.4 | accuracy: 0.45 | loss: 2.13
update:400/2000, 耗时:0.00分/1.12分 | step: 32000 | performance: 3.3 | accuracy: 0.47 | loss: 2.01
update:405/2000, 耗时:0.00分/1.14分 | step: 32400 | performance: 7.7 | accuracy: 0.48 | loss: 1.17
update:410/2000, 耗时:0.00分/1.15分 | step: 32800 | performance: 4.1 | accuracy: 0.47 | loss: 1.30
update:415/2000, 耗时:0.00分/1.16分 | step: 33200 | performance: 5.5 | accuracy: 0.47 | loss: 1.17
update:420/2000, 耗时:0.00分/1.17分 | step: 33600 | performance: 5.8 | accuracy: 0.46 | loss: 1.25
update:425/2000, 耗时:0.00分/1.19分 | step: 34000 | performance: 5.0 | accuracy: 0.44 | loss: 0.77
update:430/2000, 耗时:0.00分/1.20分 | step: 34400 | performance: 4.1 | accuracy: 0.43 | loss: 1.14
update:435/2000, 耗时:0.00分/1.21分 | step: 34800 | performance: 6.6 | accuracy: 0.41 | loss: 0.77
update:440/2000, 耗时:0.00分/1.23分 | step: 35200 | performance: 10.2 | accuracy: 0.41 | loss: 2.00
update:445/2000, 耗时:0.00分/1.24分 | step: 35600 | performance: 8.2 | accuracy: 0.41 | loss: 1.46
update:450/2000, 耗时:0.00分/1.26分 | step: 36000 | performance: 9.2 | accuracy: 0.40 | loss: 0.37
update:455/2000, 耗时:0.00分/1.27分 | step: 36400 | performance: 6.9 | accuracy: 0.39 | loss: 0.71
update:460/2000, 耗时:0.00分/1.28分 | step: 36800 | performance: 5.5 | accuracy: 0.39 | loss: 0.99
update:465/2000, 耗时:0.00分/1.30分 | step: 37200 | performance: 6.0 | accuracy: 0.40 | loss: 0.86
update:470/2000, 耗时:0.00分/1.31分 | step: 37600 | performance: 16.2 | accuracy: 0.41 | loss: 3.25
update:475/2000, 耗时:0.00分/1.32分 | step: 38000 | performance: 21.9 | accuracy: 0.41 | loss: 0.83
update:480/2000, 耗时:0.00分/1.34分 | step: 38400 | performance: 87.0 | accuracy: 0.43 | loss: 1.24
update:485/2000, 耗时:0.00分/1.35分 | step: 38800 | performance: 47.1 | accuracy: 0.43 | loss: 0.83
update:490/2000, 耗时:0.00分/1.36分 | step: 39200 | performance: 38.0 | accuracy: 0.43 | loss: 0.69
update:495/2000, 耗时:0.00分/1.38分 | step: 39600 | performance: 29.7 | accuracy: 0.41 | loss: 0.19
update:500/2000, 耗时:0.00分/1.39分 | step: 40000 | performance: 34.3 | accuracy: 0.41 | loss: 0.60
update:505/2000, 耗时:0.00分/1.40分 | step: 40400 | performance: 24.3 | accuracy: 0.41 | loss: 0.74
update:510/2000, 耗时:0.00分/1.42分 | step: 40800 | performance: 54.7 | accuracy: 0.42 | loss: 1.49
update:515/2000, 耗时:0.00分/1.43分 | step: 41200 | performance: 52.0 | accuracy: 0.42 | loss: 1.44
update:520/2000, 耗时:0.00分/1.44分 | step: 41600 | performance: 31.6 | accuracy: 0.41 | loss: 0.37
update:525/2000, 耗时:0.00分/1.45分 | step: 42000 | performance: 34.0 | accuracy: 0.42 | loss: 1.54
update:530/2000, 耗时:0.00分/1.47分 | step: 42400 | performance: 4.2 | accuracy: 0.41 | loss: 2.29
update:535/2000, 耗时:0.00分/1.48分 | step: 42800 | performance: 1.7 | accuracy: 0.41 | loss: 0.84
update:540/2000, 耗时:0.00分/1.49分 | step: 43200 | performance: 1.2 | accuracy: 0.40 | loss: 0.85
update:545/2000, 耗时:0.00分/1.51分 | step: 43600 | performance: 1.0 | accuracy: 0.41 | loss: 0.94
update:550/2000, 耗时:0.00分/1.52分 | step: 44000 | performance: 1.0 | accuracy: 0.41 | loss: 1.94
update:555/2000, 耗时:0.00分/1.53分 | step: 44400 | performance: 0.9 | accuracy: 0.41 | loss: 0.84
update:560/2000, 耗时:0.00分/1.55分 | step: 44800 | performance: 2.0 | accuracy: 0.41 | loss: 0.65
update:565/2000, 耗时:0.00分/1.56分 | step: 45200 | performance: 1.2 | accuracy: 0.42 | loss: 2.81
update:570/2000, 耗时:0.00分/1.57分 | step: 45600 | performance: 1.1 | accuracy: 0.41 | loss: 0.62
update:575/2000, 耗时:0.00分/1.59分 | step: 46000 | performance: 1.9 | accuracy: 0.41 | loss: 3.13
update:580/2000, 耗时:0.00分/1.60分 | step: 46400 | performance: 6.3 | accuracy: 0.42 | loss: 1.71
update:585/2000, 耗时:0.00分/1.61分 | step: 46800 | performance: 7.9 | accuracy: 0.42 | loss: 2.20
update:590/2000, 耗时:0.00分/1.63分 | step: 47200 | performance: 112.2 | accuracy: 0.43 | loss: 1.65
update:595/2000, 耗时:0.00分/1.64分 | step: 47600 | performance: 70.9 | accuracy: 0.43 | loss: 1.64
update:600/2000, 耗时:0.00分/1.65分 | step: 48000 | performance: 269.8 | accuracy: 0.44 | loss: 6.50
update:605/2000, 耗时:0.00分/1.67分 | step: 48400 | performance: 464.4 | accuracy: 0.44 | loss: 3.01
update:610/2000, 耗时:0.00分/1.68分 | step: 48800 | performance: 654.9 | accuracy: 0.45 | loss: 2.65
update:615/2000, 耗时:0.00分/1.69分 | step: 49200 | performance: 394.5 | accuracy: 0.45 | loss: 2.32
update:620/2000, 耗时:0.00分/1.71分 | step: 49600 | performance: 273.0 | accuracy: 0.44 | loss: 0.82
update:625/2000, 耗时:0.00分/1.72分 | step: 50000 | performance: 154.7 | accuracy: 0.43 | loss: 0.60
update:630/2000, 耗时:0.00分/1.73分 | step: 50400 | performance: 149.3 | accuracy: 0.43 | loss: 1.72
update:635/2000, 耗时:0.00分/1.75分 | step: 50800 | performance: 136.6 | accuracy: 0.43 | loss: 0.79
update:640/2000, 耗时:0.00分/1.76分 | step: 51200 | performance: 142.8 | accuracy: 0.43 | loss: 0.88
update:645/2000, 耗时:0.00分/1.77分 | step: 51600 | performance: 87.5 | accuracy: 0.42 | loss: 0.90
update:650/2000, 耗时:0.00分/1.79分 | step: 52000 | performance: 136.5 | accuracy: 0.43 | loss: 0.93
update:655/2000, 耗时:0.00分/1.80分 | step: 52400 | performance: 106.5 | accuracy: 0.42 | loss: 0.39
update:660/2000, 耗时:0.00分/1.81分 | step: 52800 | performance: 70.5 | accuracy: 0.42 | loss: 0.48
update:665/2000, 耗时:0.00分/1.83分 | step: 53200 | performance: 66.1 | accuracy: 0.42 | loss: 0.46
update:670/2000, 耗时:0.00分/1.84分 | step: 53600 | performance: 71.1 | accuracy: 0.41 | loss: 0.72
update:675/2000, 耗时:0.00分/1.86分 | step: 54000 | performance: 78.0 | accuracy: 0.41 | loss: 0.64
update:680/2000, 耗时:0.00分/1.87分 | step: 54400 | performance: 67.8 | accuracy: 0.41 | loss: 0.43
update:685/2000, 耗时:0.00分/1.89分 | step: 54800 | performance: 48.7 | accuracy: 0.41 | loss: 0.25
update:690/2000, 耗时:0.00分/1.90分 | step: 55200 | performance: 60.1 | accuracy: 0.40 | loss: 0.12
update:695/2000, 耗时:0.00分/1.91分 | step: 55600 | performance: 110.5 | accuracy: 0.40 | loss: 1.42
update:700/2000, 耗时:0.00分/1.93分 | step: 56000 | performance: 112.8 | accuracy: 0.40 | loss: 1.07
update:705/2000, 耗时:0.00分/1.94分 | step: 56400 | performance: 77.2 | accuracy: 0.39 | loss: 0.47
update:710/2000, 耗时:0.00分/1.96分 | step: 56800 | performance: 82.2 | accuracy: 0.39 | loss: 0.26
update:715/2000, 耗时:0.00分/1.97分 | step: 57200 | performance: 70.6 | accuracy: 0.39 | loss: 0.19
update:720/2000, 耗时:0.00分/1.99分 | step: 57600 | performance: 76.8 | accuracy: 0.39 | loss: 0.39
update:725/2000, 耗时:0.00分/2.00分 | step: 58000 | performance: 75.1 | accuracy: 0.38 | loss: 0.28
update:730/2000, 耗时:0.00分/2.01分 | step: 58400 | performance: 63.6 | accuracy: 0.38 | loss: 0.26
step: 58793 | worker_0@n_step_9: average total_reward after train data exhaustion : 140.0 | max total_reward: 173.3
step: 58794 | worker_1@n_step_9: average total_reward after train data exhaustion : 141.5 | max total_reward: 173.3
step: 58795 | worker_2@n_step_9: average total_reward after train data exhaustion : 141.6 | max total_reward: 173.3
step: 58796 | worker_3@n_step_9: average total_reward after train data exhaustion : 140.2 | max total_reward: 173.3
step: 58797 | worker_4@n_step_9: average total_reward after train data exhaustion : 143.6 | max total_reward: 184.5
step: 58798 | worker_5@n_step_9: average total_reward after train data exhaustion : 145.1 | max total_reward: 184.5
step: 58799 | worker_6@n_step_9: average total_reward after train data exhaustion : 145.7 | max total_reward: 184.5
step: 58800 | worker_7@n_step_9: average total_reward after train data exhaustion : 145.1 | max total_reward: 184.5
update:735/2000, 耗时:0.00分/2.03分 | step: 58800 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
Saving PPO weights in both H5 format and checkpoint @ update:735 
update:740/2000, 耗时:0.00分/2.04分 | step: 59200 | performance: 0.1 | accuracy: 0.24 | loss: 1.11
update:745/2000, 耗时:0.00分/2.06分 | step: 59600 | performance: 0.1 | accuracy: 0.17 | loss: 0.40
update:750/2000, 耗时:0.00分/2.07分 | step: 60000 | performance: 0.1 | accuracy: 0.14 | loss: 0.08
update:755/2000, 耗时:0.00分/2.09分 | step: 60400 | performance: 0.1 | accuracy: 0.10 | loss: 0.05
update:760/2000, 耗时:0.00分/2.10分 | step: 60800 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
update:765/2000, 耗时:0.00分/2.12分 | step: 61200 | performance: 1.6 | accuracy: 0.14 | loss: 0.34
step: 61279 | worker_6@n_step_9: average total_reward after train data exhaustion : 50.5 | max total_reward: 184.5
step: 61280 | worker_7@n_step_9: average total_reward after train data exhaustion : 49.4 | max total_reward: 184.5
step: 61433 | worker_0@n_step_9: average total_reward after train data exhaustion : 41.3 | max total_reward: 184.5
update:770/2000, 耗时:0.00分/2.13分 | step: 61600 | performance: 1.3 | accuracy: 0.26 | loss: 0.52
step: 61674 | worker_1@n_step_9: average total_reward after train data exhaustion : 29.7 | max total_reward: 184.5
update:775/2000, 耗时:0.00分/2.15分 | step: 62000 | performance: 1.6 | accuracy: 0.21 | loss: 0.57
update:780/2000, 耗时:0.00分/2.16分 | step: 62400 | performance: 3.6 | accuracy: 0.24 | loss: 0.95
update:785/2000, 耗时:0.00分/2.17分 | step: 62800 | performance: 4.5 | accuracy: 0.23 | loss: 0.46
update:790/2000, 耗时:0.00分/2.19分 | step: 63200 | performance: 5.2 | accuracy: 0.21 | loss: 0.35
update:795/2000, 耗时:0.00分/2.20分 | step: 63600 | performance: 3.6 | accuracy: 0.18 | loss: 0.25
update:800/2000, 耗时:0.00分/2.22分 | step: 64000 | performance: 4.6 | accuracy: 0.16 | loss: 0.49
update:805/2000, 耗时:0.00分/2.23分 | step: 64400 | performance: 5.8 | accuracy: 0.17 | loss: 0.81
update:810/2000, 耗时:0.00分/2.25分 | step: 64800 | performance: 5.8 | accuracy: 0.18 | loss: 0.70
update:815/2000, 耗时:0.00分/2.26分 | step: 65200 | performance: 7.6 | accuracy: 0.19 | loss: 0.97
update:820/2000, 耗时:0.00分/2.28分 | step: 65600 | performance: 6.2 | accuracy: 0.19 | loss: 0.81
update:825/2000, 耗时:0.00分/2.29分 | step: 66000 | performance: 5.2 | accuracy: 0.20 | loss: 0.30
update:830/2000, 耗时:0.00分/2.31分 | step: 66400 | performance: 5.8 | accuracy: 0.21 | loss: 0.37
update:835/2000, 耗时:0.00分/2.32分 | step: 66800 | performance: 8.8 | accuracy: 0.21 | loss: 1.16
update:840/2000, 耗时:0.00分/2.34分 | step: 67200 | performance: 15.8 | accuracy: 0.23 | loss: 2.55
update:845/2000, 耗时:0.00分/2.35分 | step: 67600 | performance: 11.6 | accuracy: 0.23 | loss: 1.24
update:850/2000, 耗时:0.00分/2.37分 | step: 68000 | performance: 12.2 | accuracy: 0.24 | loss: 0.83
update:855/2000, 耗时:0.00分/2.38分 | step: 68400 | performance: 10.8 | accuracy: 0.24 | loss: 0.52
update:860/2000, 耗时:0.00分/2.39分 | step: 68800 | performance: 9.5 | accuracy: 0.23 | loss: 0.33
update:865/2000, 耗时:0.00分/2.41分 | step: 69200 | performance: 6.5 | accuracy: 0.23 | loss: 0.22
update:870/2000, 耗时:0.00分/2.42分 | step: 69600 | performance: 5.5 | accuracy: 0.22 | loss: 0.33
update:875/2000, 耗时:0.00分/2.44分 | step: 70000 | performance: 6.4 | accuracy: 0.21 | loss: 0.03
update:880/2000, 耗时:0.00分/2.45分 | step: 70400 | performance: 6.4 | accuracy: 0.20 | loss: 0.05
update:885/2000, 耗时:0.00分/2.47分 | step: 70800 | performance: 6.0 | accuracy: 0.20 | loss: 0.08
update:890/2000, 耗时:0.00分/2.48分 | step: 71200 | performance: 6.0 | accuracy: 0.19 | loss: 0.08
update:895/2000, 耗时:0.00分/2.49分 | step: 71600 | performance: 5.8 | accuracy: 0.19 | loss: 0.09
update:900/2000, 耗时:0.00分/2.51分 | step: 72000 | performance: 6.3 | accuracy: 0.18 | loss: 0.01
update:905/2000, 耗时:0.00分/2.52分 | step: 72400 | performance: 6.2 | accuracy: 0.18 | loss: 0.00
update:910/2000, 耗时:0.00分/2.54分 | step: 72800 | performance: 6.5 | accuracy: 0.17 | loss: 0.19
update:915/2000, 耗时:0.00分/2.55分 | step: 73200 | performance: 7.3 | accuracy: 0.17 | loss: 0.27
update:920/2000, 耗时:0.00分/2.57分 | step: 73600 | performance: 5.9 | accuracy: 0.17 | loss: 0.15
update:925/2000, 耗时:0.00分/2.58分 | step: 74000 | performance: 5.9 | accuracy: 0.17 | loss: 0.04
update:930/2000, 耗时:0.00分/2.59分 | step: 74400 | performance: 5.9 | accuracy: 0.16 | loss: 0.38
update:935/2000, 耗时:0.00分/2.61分 | step: 74800 | performance: 5.9 | accuracy: 0.16 | loss: 0.07
update:940/2000, 耗时:0.00分/2.62分 | step: 75200 | performance: 5.7 | accuracy: 0.15 | loss: 0.07
update:945/2000, 耗时:0.00分/2.64分 | step: 75600 | performance: 5.6 | accuracy: 0.15 | loss: 0.01
update:950/2000, 耗时:0.00分/2.65分 | step: 76000 | performance: 5.6 | accuracy: 0.15 | loss: 0.03
update:955/2000, 耗时:0.00分/2.67分 | step: 76400 | performance: 5.6 | accuracy: 0.15 | loss: 0.20
update:960/2000, 耗时:0.00分/2.68分 | step: 76800 | performance: 5.7 | accuracy: 0.14 | loss: 0.33
update:965/2000, 耗时:0.00分/2.69分 | step: 77200 | performance: 5.3 | accuracy: 0.15 | loss: 1.03
update:970/2000, 耗时:0.00分/2.71分 | step: 77600 | performance: 5.8 | accuracy: 0.15 | loss: 1.05
update:975/2000, 耗时:0.00分/2.72分 | step: 78000 | performance: 11.6 | accuracy: 0.16 | loss: 1.65
update:980/2000, 耗时:0.00分/2.74分 | step: 78400 | performance: 32.0 | accuracy: 0.18 | loss: 1.39
update:985/2000, 耗时:0.00分/2.75分 | step: 78800 | performance: 41.5 | accuracy: 0.19 | loss: 2.07
update:990/2000, 耗时:0.00分/2.76分 | step: 79200 | performance: 420.2 | accuracy: 0.20 | loss: 2.50
update:995/2000, 耗时:0.00分/2.78分 | step: 79600 | performance: 393.5 | accuracy: 0.21 | loss: 1.89
update:1000/2000, 耗时:0.00分/2.79分 | step: 80000 | performance: 1733.1 | accuracy: 0.22 | loss: 3.11
update:1005/2000, 耗时:0.00分/2.81分 | step: 80400 | performance: 2773.2 | accuracy: 0.23 | loss: 2.19
update:1010/2000, 耗时:0.00分/2.82分 | step: 80800 | performance: 3356.0 | accuracy: 0.23 | loss: 1.86
update:1015/2000, 耗时:0.00分/2.84分 | step: 81200 | performance: 2028.7 | accuracy: 0.23 | loss: 1.64
update:1020/2000, 耗时:0.00分/2.85分 | step: 81600 | performance: 1592.7 | accuracy: 0.24 | loss: 0.90
update:1025/2000, 耗时:0.00分/2.87分 | step: 82000 | performance: 1924.6 | accuracy: 0.24 | loss: 1.30
update:1030/2000, 耗时:0.00分/2.88分 | step: 82400 | performance: 2781.0 | accuracy: 0.25 | loss: 1.52
update:1035/2000, 耗时:0.00分/2.90分 | step: 82800 | performance: 1961.7 | accuracy: 0.25 | loss: 0.75
update:1040/2000, 耗时:0.00分/2.91分 | step: 83200 | performance: 1817.9 | accuracy: 0.25 | loss: 1.18
update:1045/2000, 耗时:0.00分/2.93分 | step: 83600 | performance: 2878.2 | accuracy: 0.25 | loss: 0.67
update:1050/2000, 耗时:0.00分/2.94分 | step: 84000 | performance: 2961.2 | accuracy: 0.26 | loss: 1.05
update:1055/2000, 耗时:0.00分/2.96分 | step: 84400 | performance: 2622.4 | accuracy: 0.26 | loss: 1.26
update:1060/2000, 耗时:0.00分/2.98分 | step: 84800 | performance: 3448.0 | accuracy: 0.26 | loss: 0.52
update:1065/2000, 耗时:0.00分/2.99分 | step: 85200 | performance: 3768.2 | accuracy: 0.26 | loss: 0.76
update:1070/2000, 耗时:0.00分/3.01分 | step: 85600 | performance: 3929.5 | accuracy: 0.26 | loss: 0.79
update:1075/2000, 耗时:0.00分/3.02分 | step: 86000 | performance: 3104.6 | accuracy: 0.26 | loss: 0.48
update:1080/2000, 耗时:0.00分/3.04分 | step: 86400 | performance: 3141.0 | accuracy: 0.26 | loss: 0.40
update:1085/2000, 耗时:0.00分/3.05分 | step: 86800 | performance: 2814.5 | accuracy: 0.26 | loss: 0.35
update:1090/2000, 耗时:0.00分/3.07分 | step: 87200 | performance: 5852.2 | accuracy: 0.26 | loss: 0.91
update:1095/2000, 耗时:0.00分/3.08分 | step: 87600 | performance: 21771.9 | accuracy: 0.27 | loss: 2.50
update:1100/2000, 耗时:0.00分/3.10分 | step: 88000 | performance: 26460.6 | accuracy: 0.27 | loss: 2.35
update:1105/2000, 耗时:0.00分/3.11分 | step: 88400 | performance: 26441.9 | accuracy: 0.28 | loss: 1.01
update:1110/2000, 耗时:0.00分/3.13分 | step: 88800 | performance: 41958.5 | accuracy: 0.28 | loss: 1.02
update:1115/2000, 耗时:0.00分/3.15分 | step: 89200 | performance: 51591.1 | accuracy: 0.28 | loss: 1.47
update:1120/2000, 耗时:0.00分/3.16分 | step: 89600 | performance: 51188.6 | accuracy: 0.29 | loss: 1.65
update:1125/2000, 耗时:0.00分/3.18分 | step: 90000 | performance: 99462.6 | accuracy: 0.29 | loss: 2.47
update:1130/2000, 耗时:0.00分/3.19分 | step: 90400 | performance: 104850.9 | accuracy: 0.29 | loss: 1.00
step: 90797 | worker_4@n_step_9: average total_reward after train data exhaustion : 32.1 | max total_reward: 258.7
update:1135/2000, 耗时:0.00分/3.21分 | step: 90800 | performance: 128855.7 | accuracy: 0.30 | loss: 1.50
update:1140/2000, 耗时:0.00分/3.22分 | step: 91200 | performance: 1.5 | accuracy: 0.48 | loss: 2.43
update:1145/2000, 耗时:0.00分/3.24分 | step: 91600 | performance: 23.7 | accuracy: 0.56 | loss: 3.23
update:1150/2000, 耗时:0.00分/3.25分 | step: 92000 | performance: 11.8 | accuracy: 0.45 | loss: 1.59
update:1155/2000, 耗时:0.00分/3.27分 | step: 92400 | performance: 41.6 | accuracy: 0.46 | loss: 1.43
update:1160/2000, 耗时:0.00分/3.28分 | step: 92800 | performance: 14.9 | accuracy: 0.43 | loss: 1.31
update:1165/2000, 耗时:0.00分/3.30分 | step: 93200 | performance: 13.3 | accuracy: 0.41 | loss: 1.52
update:1170/2000, 耗时:0.00分/3.32分 | step: 93600 | performance: 29.6 | accuracy: 0.43 | loss: 2.08
update:1175/2000, 耗时:0.00分/3.33分 | step: 94000 | performance: 22.6 | accuracy: 0.42 | loss: 1.43
update:1180/2000, 耗时:0.00分/3.34分 | step: 94400 | performance: 19.2 | accuracy: 0.43 | loss: 1.72
update:1185/2000, 耗时:0.00分/3.36分 | step: 94800 | performance: 21.7 | accuracy: 0.43 | loss: 2.20
update:1190/2000, 耗时:0.00分/3.37分 | step: 95200 | performance: 37.4 | accuracy: 0.43 | loss: 0.82
update:1195/2000, 耗时:0.00分/3.38分 | step: 95600 | performance: 37.2 | accuracy: 0.43 | loss: 0.97
update:1200/2000, 耗时:0.00分/3.40分 | step: 96000 | performance: 45.2 | accuracy: 0.43 | loss: 0.58
update:1205/2000, 耗时:0.00分/3.41分 | step: 96400 | performance: 100.1 | accuracy: 0.42 | loss: 1.15
update:1210/2000, 耗时:0.00分/3.43分 | step: 96800 | performance: 116.1 | accuracy: 0.43 | loss: 1.18
update:1215/2000, 耗时:0.00分/3.44分 | step: 97200 | performance: 134.9 | accuracy: 0.43 | loss: 0.86
update:1220/2000, 耗时:0.00分/3.46分 | step: 97600 | performance: 121.5 | accuracy: 0.42 | loss: 0.66
update:1225/2000, 耗时:0.00分/3.47分 | step: 98000 | performance: 88.4 | accuracy: 0.41 | loss: 0.35
update:1230/2000, 耗时:0.00分/3.48分 | step: 98400 | performance: 138.1 | accuracy: 0.40 | loss: 0.71
update:1235/2000, 耗时:0.00分/3.50分 | step: 98800 | performance: 178.6 | accuracy: 0.40 | loss: 0.78
update:1240/2000, 耗时:0.00分/3.51分 | step: 99200 | performance: 418.1 | accuracy: 0.40 | loss: 0.84
update:1245/2000, 耗时:0.00分/3.53分 | step: 99600 | performance: 594.3 | accuracy: 0.40 | loss: 1.17
update:1250/2000, 耗时:0.00分/3.54分 | step: 100000 | performance: 387.0 | accuracy: 0.39 | loss: 1.22
update:1255/2000, 耗时:0.00分/3.56分 | step: 100400 | performance: 527.9 | accuracy: 0.39 | loss: 0.75
update:1260/2000, 耗时:0.00分/3.57分 | step: 100800 | performance: 476.1 | accuracy: 0.38 | loss: 0.53
update:1265/2000, 耗时:0.00分/3.58分 | step: 101200 | performance: 350.1 | accuracy: 0.38 | loss: 0.37
update:1270/2000, 耗时:0.00分/3.60分 | step: 101600 | performance: 301.4 | accuracy: 0.36 | loss: 0.50
update:1275/2000, 耗时:0.00分/3.61分 | step: 102000 | performance: 348.8 | accuracy: 0.36 | loss: 0.50
update:1280/2000, 耗时:0.00分/3.63分 | step: 102400 | performance: 452.0 | accuracy: 0.36 | loss: 0.83
update:1285/2000, 耗时:0.00分/3.64分 | step: 102800 | performance: 439.0 | accuracy: 0.36 | loss: 0.24
update:1290/2000, 耗时:0.00分/3.66分 | step: 103200 | performance: 422.1 | accuracy: 0.35 | loss: 0.35
update:1295/2000, 耗时:0.00分/3.67分 | step: 103600 | performance: 323.1 | accuracy: 0.35 | loss: 0.51
update:1300/2000, 耗时:0.00分/3.68分 | step: 104000 | performance: 94.7 | accuracy: 0.35 | loss: 0.51
update:1305/2000, 耗时:0.00分/3.70分 | step: 104400 | performance: 117.4 | accuracy: 0.35 | loss: 0.31
update:1310/2000, 耗时:0.00分/3.71分 | step: 104800 | performance: 124.5 | accuracy: 0.34 | loss: 0.71
update:1315/2000, 耗时:0.00分/3.73分 | step: 105200 | performance: 143.2 | accuracy: 0.34 | loss: 0.39
update:1320/2000, 耗时:0.00分/3.74分 | step: 105600 | performance: 131.1 | accuracy: 0.33 | loss: 0.36
update:1325/2000, 耗时:0.00分/3.75分 | step: 106000 | performance: 152.0 | accuracy: 0.33 | loss: 0.39
update:1330/2000, 耗时:0.00分/3.77分 | step: 106400 | performance: 213.3 | accuracy: 0.33 | loss: 0.87
update:1335/2000, 耗时:0.00分/3.78分 | step: 106800 | performance: 135.5 | accuracy: 0.33 | loss: 0.97
update:1340/2000, 耗时:0.00分/3.80分 | step: 107200 | performance: 143.0 | accuracy: 0.33 | loss: 0.35
update:1345/2000, 耗时:0.00分/3.81分 | step: 107600 | performance: 194.5 | accuracy: 0.33 | loss: 1.41
update:1350/2000, 耗时:0.00分/3.82分 | step: 108000 | performance: 453.3 | accuracy: 0.34 | loss: 1.56
update:1355/2000, 耗时:0.00分/3.84分 | step: 108400 | performance: 1252.5 | accuracy: 0.35 | loss: 1.19
update:1360/2000, 耗时:0.00分/3.85分 | step: 108800 | performance: 4278.3 | accuracy: 0.35 | loss: 2.42
update:1365/2000, 耗时:0.00分/3.86分 | step: 109200 | performance: 7396.7 | accuracy: 0.36 | loss: 1.09
update:1370/2000, 耗时:0.00分/3.88分 | step: 109600 | performance: 10901.8 | accuracy: 0.36 | loss: 1.96
update:1375/2000, 耗时:0.00分/3.89分 | step: 110000 | performance: 13645.8 | accuracy: 0.37 | loss: 1.26
update:1380/2000, 耗时:0.00分/3.91分 | step: 110400 | performance: 11102.3 | accuracy: 0.37 | loss: 1.09
update:1385/2000, 耗时:0.00分/3.92分 | step: 110800 | performance: 6759.5 | accuracy: 0.36 | loss: 0.80
update:1390/2000, 耗时:0.00分/3.93分 | step: 111200 | performance: 9979.7 | accuracy: 0.36 | loss: 1.00
update:1395/2000, 耗时:0.00分/3.95分 | step: 111600 | performance: 10956.3 | accuracy: 0.36 | loss: 0.53
update:1400/2000, 耗时:0.00分/3.96分 | step: 112000 | performance: 11123.2 | accuracy: 0.36 | loss: 0.56
update:1405/2000, 耗时:0.00分/3.97分 | step: 112400 | performance: 12980.5 | accuracy: 0.36 | loss: 0.47
update:1410/2000, 耗时:0.00分/3.99分 | step: 112800 | performance: 11398.9 | accuracy: 0.36 | loss: 0.73
update:1415/2000, 耗时:0.00分/4.00分 | step: 113200 | performance: 19088.7 | accuracy: 0.36 | loss: 1.01
update:1420/2000, 耗时:0.00分/4.02分 | step: 113600 | performance: 13842.9 | accuracy: 0.36 | loss: 1.29
update:1425/2000, 耗时:0.00分/4.03分 | step: 114000 | performance: 8252.5 | accuracy: 0.36 | loss: 0.49
update:1430/2000, 耗时:0.00分/4.04分 | step: 114400 | performance: 9659.1 | accuracy: 0.36 | loss: 0.40
update:1435/2000, 耗时:0.00分/4.06分 | step: 114800 | performance: 10277.8 | accuracy: 0.35 | loss: 0.63
update:1440/2000, 耗时:0.00分/4.07分 | step: 115200 | performance: 9046.2 | accuracy: 0.35 | loss: 0.63
update:1445/2000, 耗时:0.00分/4.08分 | step: 115600 | performance: 6148.2 | accuracy: 0.35 | loss: 0.64
update:1450/2000, 耗时:0.00分/4.10分 | step: 116000 | performance: 7302.3 | accuracy: 0.35 | loss: 0.39
update:1455/2000, 耗时:0.00分/4.11分 | step: 116400 | performance: 7005.0 | accuracy: 0.35 | loss: 0.41
update:1460/2000, 耗时:0.00分/4.12分 | step: 116800 | performance: 6634.2 | accuracy: 0.35 | loss: 0.69
update:1465/2000, 耗时:0.00分/4.14分 | step: 117200 | performance: 18788.0 | accuracy: 0.35 | loss: 1.93
step: 117596 | worker_3@n_step_9: average total_reward after train data exhaustion : 41.8 | max total_reward: 374.2
update:1470/2000, 耗时:0.00分/4.15分 | step: 117600 | performance: 15449.1 | accuracy: 0.35 | loss: 1.29
update:1475/2000, 耗时:0.00分/4.16分 | step: 118000 | performance: 14478.0 | accuracy: 0.35 | loss: 0.66
update:1480/2000, 耗时:0.00分/4.18分 | step: 118400 | performance: 12798.6 | accuracy: 0.35 | loss: 1.17
update:1485/2000, 耗时:0.00分/4.19分 | step: 118800 | performance: 10901.5 | accuracy: 0.35 | loss: 0.42
update:1490/2000, 耗时:0.00分/4.21分 | step: 119200 | performance: 10862.7 | accuracy: 0.35 | loss: 0.24
update:1495/2000, 耗时:0.00分/4.22分 | step: 119600 | performance: 14153.9 | accuracy: 0.34 | loss: 0.38
update:1500/2000, 耗时:0.00分/4.23分 | step: 120000 | performance: 14721.2 | accuracy: 0.34 | loss: 0.27
step: 120079 | worker_6@n_step_9: average total_reward after train data exhaustion : 41.7 | max total_reward: 374.2
step: 120233 | worker_0@n_step_9: average total_reward after train data exhaustion : 55.9 | max total_reward: 374.2
update:1505/2000, 耗时:0.00分/4.25分 | step: 120400 | performance: 0.5 | accuracy: 0.39 | loss: 1.96
step: 120474 | worker_1@n_step_9: average total_reward after train data exhaustion : 71.0 | max total_reward: 374.2
update:1510/2000, 耗时:0.00分/4.26分 | step: 120800 | performance: 0.2 | accuracy: 0.33 | loss: 0.62
update:1515/2000, 耗时:0.00分/4.28分 | step: 121200 | performance: 0.1 | accuracy: 0.25 | loss: 0.54
update:1520/2000, 耗时:0.00分/4.29分 | step: 121600 | performance: 0.1 | accuracy: 0.23 | loss: 0.33
update:1525/2000, 耗时:0.00分/4.30分 | step: 122000 | performance: 0.1 | accuracy: 0.22 | loss: 0.36
update:1530/2000, 耗时:0.00分/4.32分 | step: 122400 | performance: 0.1 | accuracy: 0.21 | loss: 0.35
update:1535/2000, 耗时:0.00分/4.33分 | step: 122800 | performance: 0.1 | accuracy: 0.21 | loss: 0.30
update:1540/2000, 耗时:0.00分/4.34分 | step: 123200 | performance: 0.1 | accuracy: 0.20 | loss: 0.33
update:1545/2000, 耗时:0.00分/4.36分 | step: 123600 | performance: 0.1 | accuracy: 0.19 | loss: 0.48
update:1550/2000, 耗时:0.00分/4.37分 | step: 124000 | performance: 0.1 | accuracy: 0.19 | loss: 0.33
update:1555/2000, 耗时:0.00分/4.38分 | step: 124400 | performance: 0.1 | accuracy: 0.19 | loss: 0.23
update:1560/2000, 耗时:0.00分/4.40分 | step: 124800 | performance: 0.1 | accuracy: 0.19 | loss: 0.27
update:1565/2000, 耗时:0.00分/4.41分 | step: 125200 | performance: 0.1 | accuracy: 0.19 | loss: 0.34
update:1570/2000, 耗时:0.00分/4.42分 | step: 125600 | performance: 0.1 | accuracy: 0.18 | loss: 0.45
update:1575/2000, 耗时:0.00分/4.43分 | step: 126000 | performance: 0.2 | accuracy: 0.19 | loss: 0.81
update:1580/2000, 耗时:0.00分/4.45分 | step: 126400 | performance: 0.2 | accuracy: 0.20 | loss: 0.65
update:1585/2000, 耗时:0.00分/4.46分 | step: 126800 | performance: 0.2 | accuracy: 0.20 | loss: 0.43
update:1590/2000, 耗时:0.00分/4.47分 | step: 127200 | performance: 0.1 | accuracy: 0.20 | loss: 0.26
update:1595/2000, 耗时:0.00分/4.49分 | step: 127600 | performance: 0.1 | accuracy: 0.20 | loss: 0.34
update:1600/2000, 耗时:0.00分/4.50分 | step: 128000 | performance: 0.1 | accuracy: 0.22 | loss: 0.54
update:1605/2000, 耗时:0.00分/4.51分 | step: 128400 | performance: 0.5 | accuracy: 0.23 | loss: 2.45
update:1610/2000, 耗时:0.00分/4.53分 | step: 128800 | performance: 0.6 | accuracy: 0.24 | loss: 1.12
update:1615/2000, 耗时:0.00分/4.54分 | step: 129200 | performance: 0.7 | accuracy: 0.25 | loss: 1.49
update:1620/2000, 耗时:0.00分/4.55分 | step: 129600 | performance: 0.5 | accuracy: 0.26 | loss: 0.97
update:1625/2000, 耗时:0.00分/4.57分 | step: 130000 | performance: 0.8 | accuracy: 0.27 | loss: 0.89
update:1630/2000, 耗时:0.00分/4.58分 | step: 130400 | performance: 1.0 | accuracy: 0.27 | loss: 0.91
update:1635/2000, 耗时:0.00分/4.60分 | step: 130800 | performance: 1.2 | accuracy: 0.27 | loss: 0.45
update:1640/2000, 耗时:0.00分/4.61分 | step: 131200 | performance: 0.8 | accuracy: 0.27 | loss: 0.39
update:1645/2000, 耗时:0.00分/4.62分 | step: 131600 | performance: 0.7 | accuracy: 0.26 | loss: 0.61
update:1650/2000, 耗时:0.00分/4.64分 | step: 132000 | performance: 0.7 | accuracy: 0.26 | loss: 0.47
update:1655/2000, 耗时:0.00分/4.65分 | step: 132400 | performance: 0.7 | accuracy: 0.26 | loss: 0.36
update:1660/2000, 耗时:0.00分/4.66分 | step: 132800 | performance: 0.8 | accuracy: 0.27 | loss: 0.53
update:1665/2000, 耗时:0.00分/4.68分 | step: 133200 | performance: 0.5 | accuracy: 0.26 | loss: 0.64
update:1670/2000, 耗时:0.00分/4.69分 | step: 133600 | performance: 0.5 | accuracy: 0.26 | loss: 0.33
update:1675/2000, 耗时:0.00分/4.71分 | step: 134000 | performance: 0.6 | accuracy: 0.26 | loss: 0.53
update:1680/2000, 耗时:0.00分/4.72分 | step: 134400 | performance: 0.7 | accuracy: 0.26 | loss: 0.48
update:1685/2000, 耗时:0.00分/4.73分 | step: 134800 | performance: 0.5 | accuracy: 0.25 | loss: 0.47
update:1690/2000, 耗时:0.00分/4.75分 | step: 135200 | performance: 0.5 | accuracy: 0.25 | loss: 0.21
update:1695/2000, 耗时:0.00分/4.76分 | step: 135600 | performance: 0.8 | accuracy: 0.25 | loss: 0.60
update:1700/2000, 耗时:0.00分/4.77分 | step: 136000 | performance: 0.9 | accuracy: 0.26 | loss: 1.11
update:1705/2000, 耗时:0.00分/4.79分 | step: 136400 | performance: 0.8 | accuracy: 0.26 | loss: 0.47
update:1710/2000, 耗时:0.00分/4.80分 | step: 136800 | performance: 0.9 | accuracy: 0.26 | loss: 0.53
update:1715/2000, 耗时:0.00分/4.81分 | step: 137200 | performance: 1.8 | accuracy: 0.27 | loss: 1.24
update:1720/2000, 耗时:0.00分/4.83分 | step: 137600 | performance: 2.1 | accuracy: 0.27 | loss: 2.05
update:1725/2000, 耗时:0.00分/4.84分 | step: 138000 | performance: 17.3 | accuracy: 0.28 | loss: 1.97
update:1730/2000, 耗时:0.00分/4.85分 | step: 138400 | performance: 15.1 | accuracy: 0.29 | loss: 1.46
update:1735/2000, 耗时:0.00分/4.87分 | step: 138800 | performance: 53.7 | accuracy: 0.29 | loss: 2.63
update:1740/2000, 耗时:0.00分/4.88分 | step: 139200 | performance: 75.5 | accuracy: 0.30 | loss: 1.91
update:1745/2000, 耗时:0.00分/4.89分 | step: 139600 | performance: 95.1 | accuracy: 0.30 | loss: 1.43
update:1750/2000, 耗时:0.00分/4.91分 | step: 140000 | performance: 86.5 | accuracy: 0.30 | loss: 1.24
update:1755/2000, 耗时:0.00分/4.92分 | step: 140400 | performance: 24.9 | accuracy: 0.30 | loss: 0.64
update:1760/2000, 耗时:0.00分/4.93分 | step: 140800 | performance: 15.8 | accuracy: 0.30 | loss: 0.35
update:1765/2000, 耗时:0.00分/4.95分 | step: 141200 | performance: 15.6 | accuracy: 0.30 | loss: 0.62
update:1770/2000, 耗时:0.00分/4.96分 | step: 141600 | performance: 18.4 | accuracy: 0.30 | loss: 0.60
update:1775/2000, 耗时:0.00分/4.98分 | step: 142000 | performance: 13.6 | accuracy: 0.30 | loss: 0.95
update:1780/2000, 耗时:0.00分/4.99分 | step: 142400 | performance: 9.1 | accuracy: 0.30 | loss: 0.55
update:1785/2000, 耗时:0.00分/5.00分 | step: 142800 | performance: 11.7 | accuracy: 0.30 | loss: 0.81
update:1790/2000, 耗时:0.00分/5.02分 | step: 143200 | performance: 8.1 | accuracy: 0.30 | loss: 0.53
update:1795/2000, 耗时:0.00分/5.03分 | step: 143600 | performance: 6.5 | accuracy: 0.30 | loss: 0.38
update:1800/2000, 耗时:0.00分/5.04分 | step: 144000 | performance: 6.0 | accuracy: 0.30 | loss: 0.36
update:1805/2000, 耗时:0.00分/5.06分 | step: 144400 | performance: 8.6 | accuracy: 0.30 | loss: 0.54
update:1810/2000, 耗时:0.00分/5.07分 | step: 144800 | performance: 13.3 | accuracy: 0.30 | loss: 0.41
update:1815/2000, 耗时:0.00分/5.08分 | step: 145200 | performance: 12.5 | accuracy: 0.30 | loss: 0.55
update:1820/2000, 耗时:0.00分/5.10分 | step: 145600 | performance: 10.8 | accuracy: 0.29 | loss: 0.27
update:1825/2000, 耗时:0.00分/5.11分 | step: 146000 | performance: 8.0 | accuracy: 0.29 | loss: 0.31
update:1830/2000, 耗时:0.00分/5.12分 | step: 146400 | performance: 14.4 | accuracy: 0.29 | loss: 0.97
update:1835/2000, 耗时:0.00分/5.14分 | step: 146800 | performance: 14.7 | accuracy: 0.29 | loss: 1.30
update:1840/2000, 耗时:0.00分/5.15分 | step: 147200 | performance: 7.7 | accuracy: 0.29 | loss: 0.91
update:1845/2000, 耗时:0.00分/5.16分 | step: 147600 | performance: 7.9 | accuracy: 0.29 | loss: 0.66
update:1850/2000, 耗时:0.00分/5.18分 | step: 148000 | performance: 5.8 | accuracy: 0.29 | loss: 0.59
update:1855/2000, 耗时:0.00分/5.19分 | step: 148400 | performance: 5.2 | accuracy: 0.29 | loss: 0.46
update:1860/2000, 耗时:0.00分/5.20分 | step: 148800 | performance: 4.7 | accuracy: 0.29 | loss: 0.46
update:1865/2000, 耗时:0.00分/5.22分 | step: 149200 | performance: 4.2 | accuracy: 0.29 | loss: 0.25
step: 149597 | worker_4@n_step_9: average total_reward after train data exhaustion : 79.9 | max total_reward: 374.2
update:1870/2000, 耗时:0.00分/5.23分 | step: 149600 | performance: 3.9 | accuracy: 0.29 | loss: 0.72
update:1875/2000, 耗时:0.00分/5.25分 | step: 150000 | performance: 1.2 | accuracy: 0.52 | loss: 1.15
update:1880/2000, 耗时:0.00分/5.26分 | step: 150400 | performance: 0.9 | accuracy: 0.41 | loss: 0.70
update:1885/2000, 耗时:0.00分/5.27分 | step: 150800 | performance: 1.1 | accuracy: 0.35 | loss: 0.63
update:1890/2000, 耗时:0.00分/5.29分 | step: 151200 | performance: 1.2 | accuracy: 0.30 | loss: 0.67
update:1895/2000, 耗时:0.00分/5.30分 | step: 151600 | performance: 1.2 | accuracy: 0.29 | loss: 0.37
update:1900/2000, 耗时:0.00分/5.31分 | step: 152000 | performance: 1.5 | accuracy: 0.30 | loss: 0.42
update:1905/2000, 耗时:0.00分/5.33分 | step: 152400 | performance: 1.6 | accuracy: 0.28 | loss: 0.74
update:1910/2000, 耗时:0.00分/5.34分 | step: 152800 | performance: 1.7 | accuracy: 0.29 | loss: 0.82
update:1915/2000, 耗时:0.00分/5.35分 | step: 153200 | performance: 1.1 | accuracy: 0.28 | loss: 0.47
update:1920/2000, 耗时:0.00分/5.36分 | step: 153600 | performance: 1.3 | accuracy: 0.30 | loss: 0.49
update:1925/2000, 耗时:0.00分/5.38分 | step: 154000 | performance: 1.5 | accuracy: 0.29 | loss: 0.35
update:1930/2000, 耗时:0.00分/5.39分 | step: 154400 | performance: 1.7 | accuracy: 0.29 | loss: 0.51
update:1935/2000, 耗时:0.00分/5.40分 | step: 154800 | performance: 1.5 | accuracy: 0.29 | loss: 0.46
update:1940/2000, 耗时:0.00分/5.42分 | step: 155200 | performance: 1.8 | accuracy: 0.29 | loss: 0.82
update:1945/2000, 耗时:0.00分/5.43分 | step: 155600 | performance: 2.9 | accuracy: 0.30 | loss: 0.74
update:1950/2000, 耗时:0.00分/5.44分 | step: 156000 | performance: 3.6 | accuracy: 0.30 | loss: 0.41
update:1955/2000, 耗时:0.00分/5.46分 | step: 156400 | performance: 3.7 | accuracy: 0.30 | loss: 0.45
update:1960/2000, 耗时:0.00分/5.47分 | step: 156800 | performance: 3.8 | accuracy: 0.29 | loss: 0.68
update:1965/2000, 耗时:0.00分/5.48分 | step: 157200 | performance: 5.1 | accuracy: 0.29 | loss: 0.67
update:1970/2000, 耗时:0.00分/5.50分 | step: 157600 | performance: 6.2 | accuracy: 0.30 | loss: 1.00
update:1975/2000, 耗时:0.00分/5.51分 | step: 158000 | performance: 19.7 | accuracy: 0.32 | loss: 1.83
update:1980/2000, 耗时:0.00分/5.52分 | step: 158400 | performance: 48.7 | accuracy: 0.32 | loss: 2.13
update:1985/2000, 耗时:0.00分/5.54分 | step: 158800 | performance: 17.3 | accuracy: 0.32 | loss: 1.39
update:1990/2000, 耗时:0.00分/5.55分 | step: 159200 | performance: 20.4 | accuracy: 0.33 | loss: 0.71
update:1995/2000, 耗时:0.00分/5.57分 | step: 159600 | performance: 14.6 | accuracy: 0.32 | loss: 0.44
update:2000/2000, 耗时:0.00分/5.58分 | step: 160000 | performance: 10.3 | accuracy: 0.32 | loss: 0.39
----------------------------------------finished----------------------------------------
==================================================
2023-01-04T00:00:00 | *** START BACKTEST ***
2023-01-04T00:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/404 [00:00<?, ?it/s]100%|| 404/404 [00:00<00:00, 101164.11it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1121.91
2023-07-24T12:00:00 | net performance [%] = 12.1908
2023-07-24T12:00:00 | number of trades [#] = 56
==================================================
Trial 19 Complete [00h 06m 01s]
net_wealth: 1123.030598612165

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 02h 25m 47s

Search: Running Trial #20

Value             |Best Value So Far |Hyperparameter
3                 |1                 |horizon
365               |730               |lookback
True              |False             |MarketFactor
3                 |3                 |lags
0.6               |0.92              |gamma
16                |32                |batch_size
32                |1                 |n_step
0.9               |0.94              |gae_lambda
2                 |5                 |gradient_clip_norm
5                 |5                 |epochs
0.0005            |0.0001            |actor_lr
0.001             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4298.000000   4301.000000
mean      0.000435    20113.607657  ...   20180.392273  20169.373185
std       0.027833    16040.642334  ...   16078.781641  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7741.750122   7730.930176
50%       0.000642    11571.842969  ...   11754.949707  11751.469727
75%       0.011590    29894.706152  ...   30015.383301  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 00:29:09.796127: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is op2023-07-28 00:29:timized with oneAPI Deep N202eura3l N029023-07-28- 00:2e.twork 796182: I tenso07-28 00:29:09.9:09L7.i7b9r6207fl: 9Io6 228: I tensorflo2rtensorfloary w/wco0re2(oneDNN) to3-/platf0 7wu-se2/ thec8 00o :r29:0e/platformf9/.ollow7cpu_featu/icr9on2rm023-07-26/gc4po 48 00eu__gCu:re/pPar2 Ud02.3-l0atIffea  7-2ointrum/tcstru8 00:crctpc:0ee:2_9guard.cc:14:214n90s9:.0799i.796614: I tensorflow/co2r]orfleoo w/conThru_feature_gi/plsuaardes TensorFl tform/i/2n ]657p0l:ao pt fTohiw serfo2c 0Iprrm2Tbeannscoe-umirnc _atFe/3rit-ilcrof0ec7aty-2 is on8spu_f ow b0u0ienat.u:ptimaccizerd wie_rel_:14th2 agr yrgfloopeuua] own/erTr is opcAPathIa itirDmios Teep29ein:09r.e/s79684o dz4d.edcr:  I FtlwN.oeitcucra:lch1  w: eNetwonb42r1o4i2sko] rnneAP]af ILTopni lThsi:bsr Deep haryNoelr   iTwa /Asc otrueey/ f(ornpslroanVXomi s eorDNNApF) ttatfoVo rXmi2ml
 Ti/zedcpluuoT_feaen wN tosueirw  btin/teh aechpeetnuo_fnea_bewaogle A tuurPyI De is eprafer_kthesrd.cc L:1g42ooilrl]u bmTa rFdh.isl cooTeinn wcw: 1bisother oi42] Trnnohary raFrlow gbinias Te(npeyry  iiors   oCsPsoneDNa pUtorFptt NioN)lionstim wteruize o uicd putsiemmb toiwnrthnaairoenl s si tihn fy, i soNl onretweor loopkb uwtiLeAnPiig brlICiamriP yd zeU Diensiepiztru (Toe deNnep wienuseotrFrDzNedr wha onfiNllo wNod)  witthh  terec totmAaPniwo useoiwtnonceeA-hcr ntoPrist iI ithcea lfoeIn  De h lpkeAeDpeol oLPi Nbrea raepurIeyppwr pDrefroartmieonail  N s(:etanoNwno p nogce-ceural NrAri CPUterVX tweD iAkVoeNnipicasXt2r
a uNrlToctk  eopi eN) naLteebuirbarla rNye t(wlr oonoenesa ti r LDNNkicoi)b r nmthto puio arlnspe yts:the efro e rfelm  ionr (L onAoVtXoleifhm aAnDber o VcXe2-opuelrase
 warTaorigNtNi)o nst nhtcse.go CP,n ab ryier
Uleuse t  e thfebutioclahlolild (oemTwe  on infpeinsoeDn raiornNlt FotlostNgloww ) th riuconoeCiwPit ussh: n eArU g  CVX  opei AVXrnstP2ati
ons, rtTthe apprroho ebUu uecnabiptiornileitaitonnss ele tin  rcuc tphoemfotmi oin opdsnlls iile  Tensoitnrnh  performance-critical operations:  AVX AVX2
To enable them in opeerfor mthaflnce-critical operations:  AVX AVX2
To enable them in other operationsags.
r,o Ferre orwlp ofriwo rmaewonnreationsith thpgerations, rebuild TensorFlow with the appropriate compiler flags.
, rebuild TensorFlow wce-criitical oe appropriatpbe compth erations:  AVX AVX2
To i CPU instrltueenauild crtbT efnlile them inso onas ign rFoperformancest.hhleoew- cr rwiita pprh 
tical operations:  AVX AVX2
Tothoe  oepapprperriate compiler flags.
opriate compiler flags.
nable them in oatiother ons, rebuilperations, rebuild TensorFlow with the d Tappropriate coensompiler flags.
rFlow with the appropriate compiler flags.
2023-07-28 00:29:10.405073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:29:10.410410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:29:10.416568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:29:10.426155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:29:10.441579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:29:10.444772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:29:10.449124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:29:10.471714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
Saving PPO weights in both H5 format and checkpoint @ update:1 
update:  5/2000, 耗时:0.01分/0.05分 | step:  1280 | performance: 1.0 | accuracy: 0.21 | loss: 0.59
update: 10/2000, 耗时:0.01分/0.08分 | step:  2560 | performance: 0.9 | accuracy: 0.30 | loss: 0.85
update: 15/2000, 耗时:0.01分/0.11分 | step:  3840 | performance: 0.7 | accuracy: 0.30 | loss: 0.65
update: 20/2000, 耗时:0.01分/0.14分 | step:  5120 | performance: 1.0 | accuracy: 0.29 | loss: 0.70
update: 25/2000, 耗时:0.01分/0.17分 | step:  6400 | performance: 0.7 | accuracy: 0.28 | loss: 0.21
update: 30/2000, 耗时:0.01分/0.21分 | step:  7680 | performance: 0.4 | accuracy: 0.24 | loss: 0.09
update: 35/2000, 耗时:0.01分/0.24分 | step:  8960 | performance: 0.4 | accuracy: 0.21 | loss: 0.02
update: 40/2000, 耗时:0.01分/0.28分 | step: 10240 | performance: 0.5 | accuracy: 0.19 | loss: 0.05
update: 45/2000, 耗时:0.01分/0.31分 | step: 11520 | performance: 0.5 | accuracy: 0.17 | loss: 0.02
update: 50/2000, 耗时:0.01分/0.34分 | step: 12800 | performance: 0.5 | accuracy: 0.16 | loss: 0.01
update: 55/2000, 耗时:0.01分/0.38分 | step: 14080 | performance: 0.5 | accuracy: 0.15 | loss: 0.02
update: 60/2000, 耗时:0.01分/0.41分 | step: 15360 | performance: 0.5 | accuracy: 0.14 | loss: 0.05
update: 65/2000, 耗时:0.01分/0.45分 | step: 16640 | performance: 0.5 | accuracy: 0.13 | loss: 0.09
update: 70/2000, 耗时:0.01分/0.48分 | step: 17920 | performance: 0.7 | accuracy: 0.13 | loss: 0.16
update: 75/2000, 耗时:0.01分/0.51分 | step: 19200 | performance: 0.7 | accuracy: 0.12 | loss: 0.02
update: 80/2000, 耗时:0.01分/0.55分 | step: 20480 | performance: 0.7 | accuracy: 0.12 | loss: 0.01
update: 85/2000, 耗时:0.01分/0.58分 | step: 21760 | performance: 0.7 | accuracy: 0.11 | loss: 0.02
update: 90/2000, 耗时:0.01分/0.61分 | step: 23040 | performance: 0.7 | accuracy: 0.11 | loss: 0.02
update: 95/2000, 耗时:0.01分/0.65分 | step: 24320 | performance: 0.7 | accuracy: 0.10 | loss: 0.00
Saving PPO weights in both H5 format and checkpoint @ update:97 
step: 25337 | worker_0@n_step_31: average total_reward after train data exhaustion : 10.2 | max total_reward: 54.7
update:100/2000, 耗时:0.01分/0.69分 | step: 25600 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
Saving PPO weights in both H5 format and checkpoint @ update:102 
step: 26367 | worker_6@n_step_31: average total_reward after train data exhaustion : 9.2 | max total_reward: 86.6
update:105/2000, 耗时:0.01分/0.73分 | step: 26880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 27136 | worker_7@n_step_31: average total_reward after train data exhaustion : 3.0 | max total_reward: 86.6
step: 28157 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.9 | max total_reward: 97.5
update:110/2000, 耗时:0.01分/0.76分 | step: 28160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 28666 | worker_1@n_step_31: average total_reward after train data exhaustion : 3.0 | max total_reward: 151.2
step: 28668 | worker_3@n_step_31: average total_reward after train data exhaustion : 3.0 | max total_reward: 151.2
step: 28670 | worker_5@n_step_31: average total_reward after train data exhaustion : 3.0 | max total_reward: 151.2
update:115/2000, 耗时:0.01分/0.80分 | step: 29440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 29689 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 30719 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:120/2000, 耗时:0.01分/0.83分 | step: 30720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 31488 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:125/2000, 耗时:0.01分/0.86分 | step: 32000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 32251 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 32509 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 33018 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 33020 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 33022 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 151.2
update:130/2000, 耗时:0.01分/0.89分 | step: 33280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 34041 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:135/2000, 耗时:0.01分/0.93分 | step: 34560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 35071 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 35840 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 151.2
update:140/2000, 耗时:0.01分/0.96分 | step: 35840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 36603 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 36861 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:145/2000, 耗时:0.01分/0.99分 | step: 37120 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 37370 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 37372 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 37374 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 38393 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 151.2
update:150/2000, 耗时:0.01分/1.03分 | step: 38400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 39423 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:155/2000, 耗时:0.01分/1.06分 | step: 39680 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 40192 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 40955 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:160/2000, 耗时:0.01分/1.09分 | step: 40960 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 41213 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 41722 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 41724 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 41726 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:165/2000, 耗时:0.01分/1.13分 | step: 42240 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 42745 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:170/2000, 耗时:0.01分/1.16分 | step: 43520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 43775 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 44544 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:175/2000, 耗时:0.01分/1.19分 | step: 44800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 45307 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 45565 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 46074 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 46076 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 46078 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:180/2000, 耗时:0.01分/1.22分 | step: 46080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 47097 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:185/2000, 耗时:0.01分/1.26分 | step: 47360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 48127 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:190/2000, 耗时:0.01分/1.29分 | step: 48640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 48896 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 151.2
step: 49659 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 49917 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:195/2000, 耗时:0.01分/1.32分 | step: 49920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 50426 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 50428 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
step: 50430 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 151.2
update:200/2000, 耗时:0.01分/1.36分 | step: 51200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 51449 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 151.2
update:205/2000, 耗时:0.01分/1.39分 | step: 52480 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:210/2000, 耗时:0.01分/1.42分 | step: 53760 | performance: 0.8 | accuracy: 0.12 | loss: 0.28
update:215/2000, 耗时:0.01分/1.46分 | step: 55040 | performance: 0.7 | accuracy: 0.12 | loss: 0.34
update:220/2000, 耗时:0.01分/1.49分 | step: 56320 | performance: 1.3 | accuracy: 0.16 | loss: 0.42
update:225/2000, 耗时:0.01分/1.52分 | step: 57600 | performance: 1.7 | accuracy: 0.17 | loss: 0.40
update:230/2000, 耗时:0.01分/1.55分 | step: 58880 | performance: 2.4 | accuracy: 0.20 | loss: 0.26
update:235/2000, 耗时:0.01分/1.58分 | step: 60160 | performance: 1.5 | accuracy: 0.18 | loss: 0.10
update:240/2000, 耗时:0.01分/1.62分 | step: 61440 | performance: 1.8 | accuracy: 0.15 | loss: 0.02
update:245/2000, 耗时:0.01分/1.65分 | step: 62720 | performance: 1.7 | accuracy: 0.14 | loss: 0.07
update:250/2000, 耗时:0.01分/1.68分 | step: 64000 | performance: 1.7 | accuracy: 0.13 | loss: 0.02
update:255/2000, 耗时:0.01分/1.71分 | step: 65280 | performance: 1.9 | accuracy: 0.13 | loss: 0.09
update:260/2000, 耗时:0.01分/1.75分 | step: 66560 | performance: 2.3 | accuracy: 0.12 | loss: 0.05
update:265/2000, 耗时:0.01分/1.78分 | step: 67840 | performance: 2.3 | accuracy: 0.12 | loss: 0.05
update:270/2000, 耗时:0.01分/1.81分 | step: 69120 | performance: 2.6 | accuracy: 0.12 | loss: 0.37
update:275/2000, 耗时:0.01分/1.84分 | step: 70400 | performance: 5.9 | accuracy: 0.13 | loss: 0.60
step: 71419 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 151.2
update:280/2000, 耗时:0.01分/1.88分 | step: 71680 | performance: 7.3 | accuracy: 0.12 | loss: 0.04
update:285/2000, 耗时:0.01分/1.91分 | step: 72960 | performance: 8.8 | accuracy: 0.12 | loss: 0.04
update:290/2000, 耗时:0.01分/1.94分 | step: 74240 | performance: 10.0 | accuracy: 0.12 | loss: 0.07
step: 75259 | worker_2@n_step_31: average total_reward after train data exhaustion : 3.7 | max total_reward: 151.2
update:295/2000, 耗时:0.01分/1.98分 | step: 75520 | performance: 9.3 | accuracy: 0.11 | loss: 0.03
update:300/2000, 耗时:0.01分/2.01分 | step: 76800 | performance: 7.8 | accuracy: 0.11 | loss: 0.03
step: 77050 | worker_1@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 151.2
step: 77565 | worker_4@n_step_31: average total_reward after train data exhaustion : 2.0 | max total_reward: 151.2
step: 78078 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.4 | max total_reward: 151.2
update:305/2000, 耗时:0.01分/2.04分 | step: 78080 | performance: 7.6 | accuracy: 0.10 | loss: 0.03
step: 78587 | worker_2@n_step_31: average total_reward after train data exhaustion : 2.5 | max total_reward: 151.2
update:310/2000, 耗时:0.01分/2.08分 | step: 79360 | performance: 8.7 | accuracy: 0.10 | loss: 0.31
update:315/2000, 耗时:0.01分/2.11分 | step: 80640 | performance: 13.6 | accuracy: 0.11 | loss: 0.12
update:320/2000, 耗时:0.01分/2.15分 | step: 81920 | performance: 1.2 | accuracy: 0.13 | loss: 0.36
update:325/2000, 耗时:0.01分/2.18分 | step: 83200 | performance: 1.7 | accuracy: 0.15 | loss: 0.26
update:330/2000, 耗时:0.01分/2.21分 | step: 84480 | performance: 1.6 | accuracy: 0.16 | loss: 0.27
update:335/2000, 耗时:0.01分/2.25分 | step: 85760 | performance: 1.7 | accuracy: 0.16 | loss: 0.13
update:340/2000, 耗时:0.01分/2.28分 | step: 87040 | performance: 1.7 | accuracy: 0.14 | loss: 0.03
update:345/2000, 耗时:0.01分/2.31分 | step: 88320 | performance: 1.7 | accuracy: 0.12 | loss: 0.03
update:350/2000, 耗时:0.01分/2.34分 | step: 89600 | performance: 1.7 | accuracy: 0.11 | loss: 0.03
Saving PPO weights in both H5 format and checkpoint @ update:354 
update:355/2000, 耗时:0.01分/2.38分 | step: 90880 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
Saving PPO weights in both H5 format and checkpoint @ update:355 
step: 91136 | worker_7@n_step_31: average total_reward after train data exhaustion : 13.9 | max total_reward: 168.1
step: 91389 | worker_4@n_step_31: average total_reward after train data exhaustion : 6.4 | max total_reward: 168.1
step: 91898 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 168.1
step: 92155 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 168.1
update:360/2000, 耗时:0.01分/2.42分 | step: 92160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 92414 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.6 | max total_reward: 168.1
step: 92924 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 168.1
update:365/2000, 耗时:0.01分/2.45分 | step: 93440 | performance: 1.7 | accuracy: 0.21 | loss: 0.21
update:370/2000, 耗时:0.01分/2.48分 | step: 94720 | performance: 1.3 | accuracy: 0.12 | loss: 0.18
update:375/2000, 耗时:0.01分/2.51分 | step: 96000 | performance: 1.7 | accuracy: 0.14 | loss: 0.21
update:380/2000, 耗时:0.01分/2.55分 | step: 97280 | performance: 1.5 | accuracy: 0.13 | loss: 0.19
update:385/2000, 耗时:0.01分/2.58分 | step: 98560 | performance: 2.0 | accuracy: 0.12 | loss: 0.12
update:390/2000, 耗时:0.01分/2.61分 | step: 99840 | performance: 1.9 | accuracy: 0.12 | loss: 0.12
step: 100859 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.5 | max total_reward: 168.1
update:395/2000, 耗时:0.01分/2.64分 | step: 101120 | performance: 2.5 | accuracy: 0.11 | loss: 0.24
step: 101629 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.6 | max total_reward: 168.1
update:400/2000, 耗时:0.01分/2.68分 | step: 102400 | performance: 2.5 | accuracy: 0.10 | loss: 0.06
update:405/2000, 耗时:0.01分/2.71分 | step: 103680 | performance: 2.1 | accuracy: 0.10 | loss: 0.11
update:410/2000, 耗时:0.01分/2.74分 | step: 104960 | performance: 2.5 | accuracy: 0.10 | loss: 0.30
update:415/2000, 耗时:0.01分/2.77分 | step: 106240 | performance: 2.3 | accuracy: 0.10 | loss: 0.13
step: 107514 | worker_1@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 168.1
update:420/2000, 耗时:0.01分/2.80分 | step: 107520 | performance: 2.4 | accuracy: 0.10 | loss: 0.11
update:425/2000, 耗时:0.01分/2.84分 | step: 108800 | performance: 2.3 | accuracy: 0.10 | loss: 0.21
update:430/2000, 耗时:0.01分/2.87分 | step: 110080 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:435/2000, 耗时:0.01分/2.91分 | step: 111360 | performance: 1.1 | accuracy: 0.14 | loss: 0.25
update:440/2000, 耗时:0.01分/2.94分 | step: 112640 | performance: 1.3 | accuracy: 0.13 | loss: 0.17
update:445/2000, 耗时:0.01分/2.97分 | step: 113920 | performance: 1.3 | accuracy: 0.10 | loss: 0.11
step: 114939 | worker_2@n_step_31: average total_reward after train data exhaustion : 2.9 | max total_reward: 168.1
update:450/2000, 耗时:0.01分/3.01分 | step: 115200 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
update:455/2000, 耗时:0.01分/3.04分 | step: 116480 | performance: 1.7 | accuracy: 0.17 | loss: 0.29
update:460/2000, 耗时:0.01分/3.08分 | step: 117760 | performance: 1.3 | accuracy: 0.12 | loss: 0.23
update:465/2000, 耗时:0.01分/3.11分 | step: 119040 | performance: 1.2 | accuracy: 0.11 | loss: 0.14
update:470/2000, 耗时:0.01分/3.15分 | step: 120320 | performance: 1.5 | accuracy: 0.12 | loss: 0.32
update:475/2000, 耗时:0.01分/3.18分 | step: 121600 | performance: 1.4 | accuracy: 0.13 | loss: 0.20
update:480/2000, 耗时:0.01分/3.22分 | step: 122880 | performance: 0.9 | accuracy: 0.12 | loss: 0.13
update:485/2000, 耗时:0.01分/3.25分 | step: 124160 | performance: 0.7 | accuracy: 0.11 | loss: 0.03
update:490/2000, 耗时:0.01分/3.28分 | step: 125440 | performance: 0.8 | accuracy: 0.10 | loss: 0.04
update:495/2000, 耗时:0.01分/3.32分 | step: 126720 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 126972 | worker_3@n_step_31: average total_reward after train data exhaustion : 2.3 | max total_reward: 168.1
step: 127999 | worker_6@n_step_31: average total_reward after train data exhaustion : 6.5 | max total_reward: 168.1
update:500/2000, 耗时:0.01分/3.35分 | step: 128000 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 128256 | worker_7@n_step_31: average total_reward after train data exhaustion : 6.4 | max total_reward: 168.1
step: 128510 | worker_5@n_step_31: average total_reward after train data exhaustion : 7.9 | max total_reward: 168.1
update:505/2000, 耗时:0.01分/3.38分 | step: 129280 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:510/2000, 耗时:0.01分/3.42分 | step: 130560 | performance: 1.3 | accuracy: 0.11 | loss: 0.12
update:515/2000, 耗时:0.01分/3.45分 | step: 131840 | performance: 1.5 | accuracy: 0.16 | loss: 0.26
update:520/2000, 耗时:0.01分/3.48分 | step: 133120 | performance: 1.6 | accuracy: 0.12 | loss: 0.20
update:525/2000, 耗时:0.01分/3.51分 | step: 134400 | performance: 1.5 | accuracy: 0.12 | loss: 0.28
update:530/2000, 耗时:0.01分/3.55分 | step: 135680 | performance: 2.6 | accuracy: 0.16 | loss: 0.37
update:535/2000, 耗时:0.01分/3.58分 | step: 136960 | performance: 3.1 | accuracy: 0.18 | loss: 0.58
update:540/2000, 耗时:0.01分/3.61分 | step: 138240 | performance: 1.8 | accuracy: 0.17 | loss: 0.22
update:545/2000, 耗时:0.01分/3.65分 | step: 139520 | performance: 1.0 | accuracy: 0.16 | loss: 0.06
update:550/2000, 耗时:0.01分/3.68分 | step: 140800 | performance: 1.2 | accuracy: 0.15 | loss: 0.10
update:555/2000, 耗时:0.01分/3.71分 | step: 142080 | performance: 1.3 | accuracy: 0.14 | loss: 0.13
update:560/2000, 耗时:0.01分/3.75分 | step: 143360 | performance: 1.2 | accuracy: 0.13 | loss: 0.05
update:565/2000, 耗时:0.01分/3.78分 | step: 144640 | performance: 1.2 | accuracy: 0.12 | loss: 0.06
update:570/2000, 耗时:0.01分/3.81分 | step: 145920 | performance: 1.2 | accuracy: 0.12 | loss: 0.08
update:575/2000, 耗时:0.01分/3.84分 | step: 147200 | performance: 1.2 | accuracy: 0.11 | loss: 0.03
update:580/2000, 耗时:0.01分/3.88分 | step: 148480 | performance: 1.3 | accuracy: 0.11 | loss: 0.00
update:585/2000, 耗时:0.01分/3.91分 | step: 149760 | performance: 1.3 | accuracy: 0.10 | loss: 0.01
step: 150523 | worker_2@n_step_31: average total_reward after train data exhaustion : 3.9 | max total_reward: 168.1
step: 151036 | worker_3@n_step_31: average total_reward after train data exhaustion : 2.8 | max total_reward: 168.1
step: 151039 | worker_6@n_step_31: average total_reward after train data exhaustion : 2.8 | max total_reward: 168.1
update:590/2000, 耗时:0.01分/3.94分 | step: 151040 | performance: 1.1 | accuracy: 0.33 | loss: 0.06
update:595/2000, 耗时:0.01分/3.97分 | step: 152320 | performance: 1.4 | accuracy: 0.19 | loss: 0.27
update:600/2000, 耗时:0.01分/4.01分 | step: 153600 | performance: 1.8 | accuracy: 0.17 | loss: 0.25
update:605/2000, 耗时:0.01分/4.04分 | step: 154880 | performance: 1.4 | accuracy: 0.16 | loss: 0.33
update:610/2000, 耗时:0.01分/4.07分 | step: 156160 | performance: 1.8 | accuracy: 0.15 | loss: 0.26
update:615/2000, 耗时:0.01分/4.10分 | step: 157440 | performance: 3.2 | accuracy: 0.17 | loss: 0.34
update:620/2000, 耗时:0.01分/4.14分 | step: 158720 | performance: 2.6 | accuracy: 0.16 | loss: 0.11
update:625/2000, 耗时:0.01分/4.17分 | step: 160000 | performance: 2.1 | accuracy: 0.14 | loss: 0.03
update:630/2000, 耗时:0.01分/4.20分 | step: 161280 | performance: 2.1 | accuracy: 0.12 | loss: 0.04
update:635/2000, 耗时:0.01分/4.24分 | step: 162560 | performance: 2.1 | accuracy: 0.12 | loss: 0.04
update:640/2000, 耗时:0.01分/4.27分 | step: 163840 | performance: 2.0 | accuracy: 0.11 | loss: 0.02
step: 165118 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.9 | max total_reward: 168.1
update:645/2000, 耗时:0.01分/4.30分 | step: 165120 | performance: 1.1 | accuracy: 0.20 | loss: 0.04
step: 166394 | worker_1@n_step_31: average total_reward after train data exhaustion : 6.0 | max total_reward: 168.1
update:650/2000, 耗时:0.01分/4.33分 | step: 166400 | performance: 1.2 | accuracy: 0.25 | loss: 0.14
step: 166649 | worker_0@n_step_31: average total_reward after train data exhaustion : 5.7 | max total_reward: 168.1
update:655/2000, 耗时:0.01分/4.37分 | step: 167680 | performance: 1.0 | accuracy: 0.14 | loss: 0.16
step: 167931 | worker_2@n_step_31: average total_reward after train data exhaustion : 2.2 | max total_reward: 168.1
step: 168704 | worker_7@n_step_31: average total_reward after train data exhaustion : 5.1 | max total_reward: 168.1
update:660/2000, 耗时:0.01分/4.40分 | step: 168960 | performance: 0.9 | accuracy: 0.00 | loss: 0.14
step: 169981 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.9 | max total_reward: 168.1
update:665/2000, 耗时:0.01分/4.43分 | step: 170240 | performance: 1.4 | accuracy: 0.17 | loss: 0.16
update:670/2000, 耗时:0.01分/4.46分 | step: 171520 | performance: 1.4 | accuracy: 0.11 | loss: 0.11
update:675/2000, 耗时:0.01分/4.50分 | step: 172800 | performance: 1.5 | accuracy: 0.11 | loss: 0.16
update:680/2000, 耗时:0.01分/4.53分 | step: 174080 | performance: 2.2 | accuracy: 0.13 | loss: 0.17
update:685/2000, 耗时:0.01分/4.56分 | step: 175360 | performance: 1.5 | accuracy: 0.14 | loss: 0.24
update:690/2000, 耗时:0.01分/4.59分 | step: 176640 | performance: 1.3 | accuracy: 0.14 | loss: 0.32
update:695/2000, 耗时:0.01分/4.63分 | step: 177920 | performance: 1.1 | accuracy: 0.14 | loss: 0.26
update:700/2000, 耗时:0.01分/4.66分 | step: 179200 | performance: 0.9 | accuracy: 0.14 | loss: 0.30
update:705/2000, 耗时:0.01分/4.69分 | step: 180480 | performance: 0.8 | accuracy: 0.14 | loss: 0.17
update:710/2000, 耗时:0.01分/4.72分 | step: 181760 | performance: 0.7 | accuracy: 0.13 | loss: 0.16
update:715/2000, 耗时:0.01分/4.76分 | step: 183040 | performance: 0.5 | accuracy: 0.13 | loss: 0.11
update:720/2000, 耗时:0.01分/4.79分 | step: 184320 | performance: 0.6 | accuracy: 0.13 | loss: 0.12
update:725/2000, 耗时:0.01分/4.82分 | step: 185600 | performance: 0.5 | accuracy: 0.13 | loss: 0.08
update:730/2000, 耗时:0.01分/4.85分 | step: 186880 | performance: 0.5 | accuracy: 0.12 | loss: 0.06
update:735/2000, 耗时:0.01分/4.88分 | step: 188160 | performance: 0.6 | accuracy: 0.11 | loss: 0.05
step: 188415 | worker_6@n_step_31: average total_reward after train data exhaustion : 5.3 | max total_reward: 175.3
update:740/2000, 耗时:0.01分/4.92分 | step: 189440 | performance: 0.6 | accuracy: 0.11 | loss: 0.06
update:745/2000, 耗时:0.01分/4.95分 | step: 190720 | performance: 0.5 | accuracy: 0.11 | loss: 0.04
step: 191998 | worker_5@n_step_31: average total_reward after train data exhaustion : 4.5 | max total_reward: 175.3
update:750/2000, 耗时:0.01分/4.98分 | step: 192000 | performance: 0.5 | accuracy: 0.10 | loss: 0.06
step: 192511 | worker_6@n_step_31: average total_reward after train data exhaustion : 8.1 | max total_reward: 175.3
step: 193274 | worker_1@n_step_31: average total_reward after train data exhaustion : 8.1 | max total_reward: 175.3
update:755/2000, 耗时:0.01分/5.02分 | step: 193280 | performance: 1.4 | accuracy: 0.31 | loss: 0.11
step: 194556 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.8 | max total_reward: 175.3
update:760/2000, 耗时:0.01分/5.05分 | step: 194560 | performance: 1.4 | accuracy: 0.14 | loss: 0.18
update:765/2000, 耗时:0.01分/5.08分 | step: 195840 | performance: 1.2 | accuracy: 0.16 | loss: 0.26
update:770/2000, 耗时:0.01分/5.11分 | step: 197120 | performance: 2.6 | accuracy: 0.19 | loss: 0.38
update:775/2000, 耗时:0.01分/5.15分 | step: 198400 | performance: 2.5 | accuracy: 0.19 | loss: 0.26
update:780/2000, 耗时:0.01分/5.18分 | step: 199680 | performance: 4.4 | accuracy: 0.19 | loss: 0.28
update:785/2000, 耗时:0.01分/5.21分 | step: 200960 | performance: 4.3 | accuracy: 0.17 | loss: 0.10
update:790/2000, 耗时:0.01分/5.24分 | step: 202240 | performance: 4.2 | accuracy: 0.15 | loss: 0.06
update:795/2000, 耗时:0.01分/5.28分 | step: 203520 | performance: 4.6 | accuracy: 0.13 | loss: 0.02
update:800/2000, 耗时:0.01分/5.31分 | step: 204800 | performance: 3.5 | accuracy: 0.13 | loss: 0.07
update:805/2000, 耗时:0.01分/5.34分 | step: 206080 | performance: 3.4 | accuracy: 0.12 | loss: 0.05
update:810/2000, 耗时:0.01分/5.37分 | step: 207360 | performance: 2.4 | accuracy: 0.11 | loss: 0.02
update:815/2000, 耗时:0.01分/5.41分 | step: 208640 | performance: 2.4 | accuracy: 0.10 | loss: 0.06
update:820/2000, 耗时:0.01分/5.44分 | step: 209920 | performance: 2.4 | accuracy: 0.10 | loss: 0.05
update:825/2000, 耗时:0.01分/5.47分 | step: 211200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 211453 | worker_4@n_step_31: average total_reward after train data exhaustion : 6.4 | max total_reward: 175.3
step: 211712 | worker_7@n_step_31: average total_reward after train data exhaustion : 8.4 | max total_reward: 175.3
step: 212474 | worker_1@n_step_31: average total_reward after train data exhaustion : 7.3 | max total_reward: 175.3
update:830/2000, 耗时:0.01分/5.50分 | step: 212480 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 213246 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.1 | max total_reward: 175.3
update:835/2000, 耗时:0.01分/5.54分 | step: 213760 | performance: 1.2 | accuracy: 0.14 | loss: 0.06
step: 214528 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 175.3
step: 214781 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 175.3
update:840/2000, 耗时:0.01分/5.57分 | step: 215040 | performance: 1.4 | accuracy: 0.23 | loss: 0.25
update:845/2000, 耗时:0.01分/5.60分 | step: 216320 | performance: 1.8 | accuracy: 0.17 | loss: 0.19
update:850/2000, 耗时:0.01分/5.63分 | step: 217600 | performance: 1.5 | accuracy: 0.17 | loss: 0.23
update:855/2000, 耗时:0.01分/5.67分 | step: 218880 | performance: 2.1 | accuracy: 0.16 | loss: 0.26
update:860/2000, 耗时:0.01分/5.70分 | step: 220160 | performance: 3.1 | accuracy: 0.16 | loss: 0.32
update:865/2000, 耗时:0.01分/5.73分 | step: 221440 | performance: 2.5 | accuracy: 0.15 | loss: 0.17
update:870/2000, 耗时:0.01分/5.76分 | step: 222720 | performance: 2.1 | accuracy: 0.13 | loss: 0.05
update:875/2000, 耗时:0.01分/5.80分 | step: 224000 | performance: 1.9 | accuracy: 0.12 | loss: 0.04
update:880/2000, 耗时:0.01分/5.83分 | step: 225280 | performance: 2.0 | accuracy: 0.12 | loss: 0.08
update:885/2000, 耗时:0.01分/5.86分 | step: 226560 | performance: 2.4 | accuracy: 0.11 | loss: 0.19
update:890/2000, 耗时:0.01分/5.89分 | step: 227840 | performance: 2.6 | accuracy: 0.11 | loss: 0.11
update:895/2000, 耗时:0.01分/5.92分 | step: 229120 | performance: 3.0 | accuracy: 0.11 | loss: 0.15
update:900/2000, 耗时:0.01分/5.96分 | step: 230400 | performance: 3.0 | accuracy: 0.11 | loss: 0.09
step: 230649 | worker_0@n_step_31: average total_reward after train data exhaustion : 3.4 | max total_reward: 175.3
update:905/2000, 耗时:0.01分/5.99分 | step: 231680 | performance: 2.8 | accuracy: 0.10 | loss: 0.15
update:910/2000, 耗时:0.01分/6.02分 | step: 232960 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:915/2000, 耗时:0.01分/6.06分 | step: 234240 | performance: 1.0 | accuracy: 0.16 | loss: 0.37
update:920/2000, 耗时:0.01分/6.09分 | step: 235520 | performance: 1.3 | accuracy: 0.14 | loss: 0.29
update:925/2000, 耗时:0.01分/6.12分 | step: 236800 | performance: 1.3 | accuracy: 0.13 | loss: 0.20
update:930/2000, 耗时:0.01分/6.15分 | step: 238080 | performance: 3.9 | accuracy: 0.15 | loss: 0.41
update:935/2000, 耗时:0.01分/6.18分 | step: 239360 | performance: 3.4 | accuracy: 0.15 | loss: 0.12
update:940/2000, 耗时:0.01分/6.22分 | step: 240640 | performance: 3.1 | accuracy: 0.13 | loss: 0.09
update:945/2000, 耗时:0.01分/6.25分 | step: 241920 | performance: 2.0 | accuracy: 0.12 | loss: 0.06
update:950/2000, 耗时:0.01分/6.28分 | step: 243200 | performance: 2.7 | accuracy: 0.12 | loss: 0.10
update:955/2000, 耗时:0.01分/6.31分 | step: 244480 | performance: 2.0 | accuracy: 0.12 | loss: 0.33
update:960/2000, 耗时:0.01分/6.35分 | step: 245760 | performance: 2.7 | accuracy: 0.12 | loss: 0.21
step: 247035 | worker_2@n_step_31: average total_reward after train data exhaustion : 7.9 | max total_reward: 175.3
update:965/2000, 耗时:0.01分/6.38分 | step: 247040 | performance: 2.1 | accuracy: 0.11 | loss: 0.11
step: 247802 | worker_1@n_step_31: average total_reward after train data exhaustion : 7.6 | max total_reward: 175.3
update:970/2000, 耗时:0.01分/6.41分 | step: 248320 | performance: 2.4 | accuracy: 0.11 | loss: 0.16
step: 249083 | worker_2@n_step_31: average total_reward after train data exhaustion : 5.5 | max total_reward: 175.3
update:975/2000, 耗时:0.01分/6.44分 | step: 249600 | performance: 1.7 | accuracy: 0.11 | loss: 0.06
step: 250874 | worker_1@n_step_31: average total_reward after train data exhaustion : 4.6 | max total_reward: 175.3
update:980/2000, 耗时:0.01分/6.47分 | step: 250880 | performance: 1.7 | accuracy: 0.10 | loss: 0.04
step: 251645 | worker_4@n_step_31: average total_reward after train data exhaustion : 4.1 | max total_reward: 175.3
update:985/2000, 耗时:0.01分/6.51分 | step: 252160 | performance: 1.3 | accuracy: 0.21 | loss: 0.16
step: 252413 | worker_4@n_step_31: average total_reward after train data exhaustion : 3.7 | max total_reward: 175.3
update:990/2000, 耗时:0.01分/6.54分 | step: 253440 | performance: 2.2 | accuracy: 0.18 | loss: 0.13
step: 253691 | worker_2@n_step_31: average total_reward after train data exhaustion : 3.2 | max total_reward: 175.3
update:995/2000, 耗时:0.01分/6.57分 | step: 254720 | performance: 1.9 | accuracy: 0.15 | loss: 0.44
update:1000/2000, 耗时:0.01分/6.61分 | step: 256000 | performance: 2.1 | accuracy: 0.16 | loss: 0.40
update:1005/2000, 耗时:0.01分/6.64分 | step: 257280 | performance: 6.3 | accuracy: 0.18 | loss: 0.44
update:1010/2000, 耗时:0.01分/6.67分 | step: 258560 | performance: 5.3 | accuracy: 0.19 | loss: 0.40
update:1015/2000, 耗时:0.01分/6.70分 | step: 259840 | performance: 1.6 | accuracy: 0.17 | loss: 0.14
update:1020/2000, 耗时:0.01分/6.74分 | step: 261120 | performance: 1.7 | accuracy: 0.16 | loss: 0.08
update:1025/2000, 耗时:0.01分/6.77分 | step: 262400 | performance: 1.9 | accuracy: 0.15 | loss: 0.05
update:1030/2000, 耗时:0.01分/6.80分 | step: 263680 | performance: 1.8 | accuracy: 0.14 | loss: 0.03
update:1035/2000, 耗时:0.01分/6.83分 | step: 264960 | performance: 1.7 | accuracy: 0.13 | loss: 0.02
update:1040/2000, 耗时:0.01分/6.86分 | step: 266240 | performance: 1.7 | accuracy: 0.12 | loss: 0.03
update:1045/2000, 耗时:0.01分/6.90分 | step: 267520 | performance: 1.7 | accuracy: 0.11 | loss: 0.04
update:1050/2000, 耗时:0.01分/6.93分 | step: 268800 | performance: 1.7 | accuracy: 0.11 | loss: 0.02
update:1055/2000, 耗时:0.01分/6.96分 | step: 270080 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 270330 | worker_1@n_step_31: average total_reward after train data exhaustion : 5.8 | max total_reward: 175.3
step: 270589 | worker_4@n_step_31: average total_reward after train data exhaustion : 7.2 | max total_reward: 175.3
update:1060/2000, 耗时:0.01分/7.00分 | step: 271360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 271616 | worker_7@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 175.3
step: 271871 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 175.3
step: 272121 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 175.3
update:1065/2000, 耗时:0.01分/7.03分 | step: 272640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 273660 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 175.3
update:1070/2000, 耗时:0.01分/7.06分 | step: 273920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 274427 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 175.3
step: 274682 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 175.3
step: 274941 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 175.3
step: 274942 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 175.3
update:1075/2000, 耗时:0.01分/7.09分 | step: 275200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 275968 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 175.3
step: 276223 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 175.3
step: 276473 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 175.3
update:1080/2000, 耗时:0.01分/7.13分 | step: 276480 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:1085/2000, 耗时:0.01分/7.16分 | step: 277760 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 278267 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 175.3
step: 278270 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 175.3
step: 279035 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 175.3
update:1090/2000, 耗时:0.01分/7.19分 | step: 279040 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
update:1095/2000, 耗时:0.01分/7.22分 | step: 280320 | performance: 1.9 | accuracy: 0.18 | loss: 0.18
update:1100/2000, 耗时:0.01分/7.25分 | step: 281600 | performance: 2.7 | accuracy: 0.18 | loss: 0.23
update:1105/2000, 耗时:0.01分/7.28分 | step: 282880 | performance: 2.8 | accuracy: 0.16 | loss: 0.17
update:1110/2000, 耗时:0.01分/7.31分 | step: 284160 | performance: 4.0 | accuracy: 0.15 | loss: 0.21
update:1115/2000, 耗时:0.01分/7.34分 | step: 285440 | performance: 3.3 | accuracy: 0.14 | loss: 0.07
update:1120/2000, 耗时:0.01分/7.37分 | step: 286720 | performance: 3.0 | accuracy: 0.13 | loss: 0.02
update:1125/2000, 耗时:0.01分/7.41分 | step: 288000 | performance: 2.8 | accuracy: 0.11 | loss: 0.05
step: 289022 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.6 | max total_reward: 175.3
update:1130/2000, 耗时:0.01分/7.44分 | step: 289280 | performance: 2.4 | accuracy: 0.11 | loss: 0.09
update:1135/2000, 耗时:0.01分/7.47分 | step: 290560 | performance: 2.3 | accuracy: 0.11 | loss: 0.19
update:1140/2000, 耗时:0.01分/7.51分 | step: 291840 | performance: 1.1 | accuracy: 0.10 | loss: 0.15
update:1145/2000, 耗时:0.01分/7.54分 | step: 293120 | performance: 0.8 | accuracy: 0.10 | loss: 0.20
update:1150/2000, 耗时:0.01分/7.57分 | step: 294400 | performance: 0.8 | accuracy: 0.11 | loss: 0.37
update:1155/2000, 耗时:0.01分/7.60分 | step: 295680 | performance: 0.4 | accuracy: 0.11 | loss: 0.28
update:1160/2000, 耗时:0.01分/7.63分 | step: 296960 | performance: 0.3 | accuracy: 0.10 | loss: 0.10
update:1165/2000, 耗时:0.01分/7.67分 | step: 298240 | performance: 1.1 | accuracy: 0.14 | loss: 0.05
update:1170/2000, 耗时:0.01分/7.70分 | step: 299520 | performance: 1.1 | accuracy: 0.50 | loss: 0.14
step: 299776 | worker_7@n_step_31: average total_reward after train data exhaustion : 9.0 | max total_reward: 175.3
update:1175/2000, 耗时:0.01分/7.73分 | step: 300800 | performance: 1.1 | accuracy: 0.25 | loss: 0.14
update:1180/2000, 耗时:0.01分/7.76分 | step: 302080 | performance: 1.5 | accuracy: 0.18 | loss: 0.28
update:1185/2000, 耗时:0.01分/7.80分 | step: 303360 | performance: 1.4 | accuracy: 0.13 | loss: 0.30
update:1190/2000, 耗时:0.01分/7.83分 | step: 304640 | performance: 1.7 | accuracy: 0.14 | loss: 0.11
update:1195/2000, 耗时:0.01分/7.86分 | step: 305920 | performance: 2.8 | accuracy: 0.14 | loss: 0.11
update:1200/2000, 耗时:0.01分/7.90分 | step: 307200 | performance: 3.0 | accuracy: 0.13 | loss: 0.06
update:1205/2000, 耗时:0.01分/7.93分 | step: 308480 | performance: 3.0 | accuracy: 0.12 | loss: 0.08
update:1210/2000, 耗时:0.01分/7.96分 | step: 309760 | performance: 2.3 | accuracy: 0.11 | loss: 0.07
step: 310521 | worker_0@n_step_31: average total_reward after train data exhaustion : 6.3 | max total_reward: 175.3
step: 310781 | worker_4@n_step_31: average total_reward after train data exhaustion : 7.4 | max total_reward: 175.3
step: 310782 | worker_5@n_step_31: average total_reward after train data exhaustion : 7.3 | max total_reward: 175.3
update:1215/2000, 耗时:0.01分/8.00分 | step: 311040 | performance: 2.7 | accuracy: 0.10 | loss: 0.06
step: 312057 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 175.3
step: 312064 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 175.3
update:1220/2000, 耗时:0.01分/8.03分 | step: 312320 | performance: 1.5 | accuracy: 0.36 | loss: 0.20
update:1225/2000, 耗时:0.01分/8.06分 | step: 313600 | performance: 1.6 | accuracy: 0.14 | loss: 0.21
update:1230/2000, 耗时:0.01分/8.10分 | step: 314880 | performance: 1.5 | accuracy: 0.11 | loss: 0.16
update:1235/2000, 耗时:0.01分/8.13分 | step: 316160 | performance: 1.4 | accuracy: 0.13 | loss: 0.16
update:1240/2000, 耗时:0.01分/8.17分 | step: 317440 | performance: 1.9 | accuracy: 0.14 | loss: 0.27
update:1245/2000, 耗时:0.01分/8.20分 | step: 318720 | performance: 1.4 | accuracy: 0.14 | loss: 0.26
update:1250/2000, 耗时:0.01分/8.23分 | step: 320000 | performance: 1.5 | accuracy: 0.13 | loss: 0.09
update:1255/2000, 耗时:0.01分/8.27分 | step: 321280 | performance: 1.5 | accuracy: 0.12 | loss: 0.05
update:1260/2000, 耗时:0.01分/8.30分 | step: 322560 | performance: 1.6 | accuracy: 0.11 | loss: 0.05
update:1265/2000, 耗时:0.01分/8.34分 | step: 323840 | performance: 1.7 | accuracy: 0.11 | loss: 0.04
step: 324860 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.4 | max total_reward: 175.3
step: 325113 | worker_0@n_step_31: average total_reward after train data exhaustion : 4.1 | max total_reward: 175.3
update:1270/2000, 耗时:0.01分/8.37分 | step: 325120 | performance: 3.2 | accuracy: 0.10 | loss: 0.04
step: 326400 | worker_7@n_step_31: average total_reward after train data exhaustion : 3.0 | max total_reward: 175.3
update:1275/2000, 耗时:0.01分/8.40分 | step: 326400 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:1280/2000, 耗时:0.01分/8.44分 | step: 327680 | performance: 1.4 | accuracy: 0.21 | loss: 0.17
step: 328186 | worker_1@n_step_31: average total_reward after train data exhaustion : 3.1 | max total_reward: 175.3
update:1285/2000, 耗时:0.01分/8.47分 | step: 328960 | performance: 1.4 | accuracy: 0.10 | loss: 0.16
update:1290/2000, 耗时:0.01分/8.50分 | step: 330240 | performance: 1.5 | accuracy: 0.29 | loss: 0.19
update:1295/2000, 耗时:0.01分/8.53分 | step: 331520 | performance: 2.1 | accuracy: 0.14 | loss: 0.33
update:1300/2000, 耗时:0.01分/8.57分 | step: 332800 | performance: 2.1 | accuracy: 0.15 | loss: 0.37
update:1305/2000, 耗时:0.01分/8.60分 | step: 334080 | performance: 2.2 | accuracy: 0.14 | loss: 0.31
update:1310/2000, 耗时:0.01分/8.64分 | step: 335360 | performance: 7.4 | accuracy: 0.17 | loss: 0.32
update:1315/2000, 耗时:0.01分/8.67分 | step: 336640 | performance: 5.7 | accuracy: 0.17 | loss: 0.10
update:1320/2000, 耗时:0.01分/8.70分 | step: 337920 | performance: 5.1 | accuracy: 0.14 | loss: 0.04
update:1325/2000, 耗时:0.01分/8.74分 | step: 339200 | performance: 5.0 | accuracy: 0.13 | loss: 0.07
update:1330/2000, 耗时:0.01分/8.77分 | step: 340480 | performance: 5.2 | accuracy: 0.12 | loss: 0.05
update:1335/2000, 耗时:0.01分/8.80分 | step: 341760 | performance: 5.4 | accuracy: 0.11 | loss: 0.01
step: 342010 | worker_1@n_step_31: average total_reward after train data exhaustion : 2.6 | max total_reward: 175.3
step: 342526 | worker_5@n_step_31: average total_reward after train data exhaustion : 4.7 | max total_reward: 175.3
update:1340/2000, 耗时:0.01分/8.84分 | step: 343040 | performance: 5.7 | accuracy: 0.10 | loss: 0.02
step: 343804 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 175.3
update:1345/2000, 耗时:0.01分/8.87分 | step: 344320 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 345085 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 175.3
step: 345343 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 175.3
update:1350/2000, 耗时:0.01分/8.91分 | step: 345600 | performance: 1.0 | accuracy: 0.00 | loss: -0.01
update:1355/2000, 耗时:0.01分/8.94分 | step: 346880 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
step: 348159 | worker_6@n_step_31: average total_reward after train data exhaustion : 3.2 | max total_reward: 175.3
update:1360/2000, 耗时:0.01分/8.98分 | step: 348160 | performance: 1.9 | accuracy: 0.14 | loss: 0.22
update:1365/2000, 耗时:0.01分/9.01分 | step: 349440 | performance: 3.3 | accuracy: 0.15 | loss: 0.26
update:1370/2000, 耗时:0.01分/9.05分 | step: 350720 | performance: 2.9 | accuracy: 0.14 | loss: 0.13
update:1375/2000, 耗时:0.01分/9.08分 | step: 352000 | performance: 3.5 | accuracy: 0.14 | loss: 0.21
update:1380/2000, 耗时:0.01分/9.12分 | step: 353280 | performance: 3.4 | accuracy: 0.14 | loss: 0.15
update:1385/2000, 耗时:0.01分/9.15分 | step: 354560 | performance: 2.3 | accuracy: 0.12 | loss: 0.13
update:1390/2000, 耗时:0.01分/9.19分 | step: 355840 | performance: 2.0 | accuracy: 0.11 | loss: 0.03
step: 356350 | worker_5@n_step_31: average total_reward after train data exhaustion : 3.7 | max total_reward: 175.3
update:1395/2000, 耗时:0.01分/9.22分 | step: 357120 | performance: 2.0 | accuracy: 0.10 | loss: 0.04
step: 358399 | worker_6@n_step_31: average total_reward after train data exhaustion : 7.9 | max total_reward: 175.3
update:1400/2000, 耗时:0.01分/9.26分 | step: 358400 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 359165 | worker_4@n_step_31: average total_reward after train data exhaustion : 4.1 | max total_reward: 175.3
update:1405/2000, 耗时:0.01分/9.30分 | step: 359680 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:1410/2000, 耗时:0.01分/9.33分 | step: 360960 | performance: 1.2 | accuracy: 0.17 | loss: 0.22
update:1415/2000, 耗时:0.01分/9.36分 | step: 362240 | performance: 2.2 | accuracy: 0.18 | loss: 0.30
update:1420/2000, 耗时:0.01分/9.39分 | step: 363520 | performance: 2.1 | accuracy: 0.19 | loss: 0.40
update:1425/2000, 耗时:0.01分/9.43分 | step: 364800 | performance: 5.5 | accuracy: 0.22 | loss: 0.41
update:1430/2000, 耗时:0.01分/9.46分 | step: 366080 | performance: 4.7 | accuracy: 0.21 | loss: 0.14
update:1435/2000, 耗时:0.01分/9.49分 | step: 367360 | performance: 3.9 | accuracy: 0.18 | loss: 0.10
update:1440/2000, 耗时:0.01分/9.53分 | step: 368640 | performance: 4.2 | accuracy: 0.16 | loss: 0.02
update:1445/2000, 耗时:0.01分/9.56分 | step: 369920 | performance: 4.2 | accuracy: 0.15 | loss: 0.04
update:1450/2000, 耗时:0.01分/9.59分 | step: 371200 | performance: 4.3 | accuracy: 0.14 | loss: 0.03
update:1455/2000, 耗时:0.01分/9.63分 | step: 372480 | performance: 4.6 | accuracy: 0.13 | loss: 0.06
update:1460/2000, 耗时:0.01分/9.66分 | step: 373760 | performance: 4.7 | accuracy: 0.12 | loss: 0.04
update:1465/2000, 耗时:0.01分/9.69分 | step: 375040 | performance: 4.9 | accuracy: 0.12 | loss: 0.01
update:1470/2000, 耗时:0.01分/9.73分 | step: 376320 | performance: 4.9 | accuracy: 0.11 | loss: 0.00
step: 377594 | worker_1@n_step_31: average total_reward after train data exhaustion : 9.3 | max total_reward: 175.3
step: 377596 | worker_3@n_step_31: average total_reward after train data exhaustion : 9.2 | max total_reward: 175.3
update:1475/2000, 耗时:0.01分/9.76分 | step: 377600 | performance: 5.3 | accuracy: 0.10 | loss: -0.00
update:1480/2000, 耗时:0.01分/9.79分 | step: 378880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 379385 | worker_0@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 175.3
step: 379387 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 175.3
update:1485/2000, 耗时:0.01分/9.83分 | step: 380160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 380670 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 175.3
step: 380927 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 175.3
step: 381436 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 175.3
step: 381437 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 175.3
update:1490/2000, 耗时:0.01分/9.86分 | step: 381440 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 381952 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 175.3
step: 382714 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 175.3
update:1495/2000, 耗时:0.01分/9.89分 | step: 382720 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
update:1500/2000, 耗时:0.01分/9.93分 | step: 384000 | performance: 0.9 | accuracy: 0.15 | loss: 0.26
update:1505/2000, 耗时:0.01分/9.96分 | step: 385280 | performance: 1.1 | accuracy: 0.15 | loss: 0.21
update:1510/2000, 耗时:0.01分/9.99分 | step: 386560 | performance: 0.9 | accuracy: 0.15 | loss: 0.30
update:1515/2000, 耗时:0.01分/10.03分 | step: 387840 | performance: 1.1 | accuracy: 0.16 | loss: 0.29
update:1520/2000, 耗时:0.01分/10.06分 | step: 389120 | performance: 1.2 | accuracy: 0.16 | loss: 0.21
update:1525/2000, 耗时:0.01分/10.09分 | step: 390400 | performance: 0.9 | accuracy: 0.15 | loss: 0.10
update:1530/2000, 耗时:0.01分/10.13分 | step: 391680 | performance: 0.8 | accuracy: 0.13 | loss: 0.06
update:1535/2000, 耗时:0.01分/10.16分 | step: 392960 | performance: 0.8 | accuracy: 0.13 | loss: 0.08
update:1540/2000, 耗时:0.01分/10.19分 | step: 394240 | performance: 0.8 | accuracy: 0.12 | loss: 0.03
update:1545/2000, 耗时:0.01分/10.23分 | step: 395520 | performance: 1.1 | accuracy: 0.11 | loss: 0.06
update:1550/2000, 耗时:0.01分/10.26分 | step: 396800 | performance: 1.1 | accuracy: 0.11 | loss: 0.06
step: 397307 | worker_2@n_step_31: average total_reward after train data exhaustion : 6.8 | max total_reward: 175.3
step: 398078 | worker_5@n_step_31: average total_reward after train data exhaustion : 7.9 | max total_reward: 175.3
update:1555/2000, 耗时:0.01分/10.29分 | step: 398080 | performance: 1.2 | accuracy: 0.11 | loss: 0.23
update:1560/2000, 耗时:0.01分/10.32分 | step: 399360 | performance: 0.8 | accuracy: 0.11 | loss: 0.29
update:1565/2000, 耗时:0.01分/10.36分 | step: 400640 | performance: 1.0 | accuracy: 0.10 | loss: 0.11
step: 400893 | worker_4@n_step_31: average total_reward after train data exhaustion : 8.4 | max total_reward: 175.3
update:1570/2000, 耗时:0.01分/10.39分 | step: 401920 | performance: 1.2 | accuracy: 0.17 | loss: 0.16
update:1575/2000, 耗时:0.01分/10.42分 | step: 403200 | performance: 1.5 | accuracy: 0.30 | loss: 0.24
update:1580/2000, 耗时:0.01分/10.46分 | step: 404480 | performance: 1.6 | accuracy: 0.14 | loss: 0.22
update:1585/2000, 耗时:0.01分/10.49分 | step: 405760 | performance: 2.2 | accuracy: 0.11 | loss: 0.07
update:1590/2000, 耗时:0.01分/10.52分 | step: 407040 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
update:1595/2000, 耗时:0.01分/10.55分 | step: 408320 | performance: 1.2 | accuracy: 0.15 | loss: 0.18
update:1600/2000, 耗时:0.01分/10.59分 | step: 409600 | performance: 1.5 | accuracy: 0.16 | loss: 0.24
update:1605/2000, 耗时:0.01分/10.62分 | step: 410880 | performance: 1.1 | accuracy: 0.15 | loss: 0.34
update:1610/2000, 耗时:0.01分/10.65分 | step: 412160 | performance: 1.7 | accuracy: 0.19 | loss: 0.45
update:1615/2000, 耗时:0.01分/10.68分 | step: 413440 | performance: 2.3 | accuracy: 0.19 | loss: 0.34
update:1620/2000, 耗时:0.01分/10.72分 | step: 414720 | performance: 2.0 | accuracy: 0.18 | loss: 0.13
update:1625/2000, 耗时:0.01分/10.75分 | step: 416000 | performance: 1.6 | accuracy: 0.16 | loss: 0.05
update:1630/2000, 耗时:0.01分/10.78分 | step: 417280 | performance: 1.6 | accuracy: 0.14 | loss: 0.02
update:1635/2000, 耗时:0.01分/10.81分 | step: 418560 | performance: 1.6 | accuracy: 0.13 | loss: 0.05
update:1640/2000, 耗时:0.01分/10.85分 | step: 419840 | performance: 1.7 | accuracy: 0.12 | loss: 0.02
update:1645/2000, 耗时:0.01分/10.88分 | step: 421120 | performance: 1.7 | accuracy: 0.11 | loss: 0.01
step: 421628 | worker_3@n_step_31: average total_reward after train data exhaustion : 3.8 | max total_reward: 175.3
step: 421885 | worker_4@n_step_31: average total_reward after train data exhaustion : 3.6 | max total_reward: 175.3
step: 422398 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.4 | max total_reward: 175.3
update:1650/2000, 耗时:0.01分/10.91分 | step: 422400 | performance: 1.6 | accuracy: 0.10 | loss: 0.10
update:1655/2000, 耗时:0.01分/10.95分 | step: 423680 | performance: 1.5 | accuracy: 0.10 | loss: 0.08
update:1660/2000, 耗时:0.01分/10.98分 | step: 424960 | performance: 1.1 | accuracy: 0.13 | loss: 0.15
step: 425213 | worker_4@n_step_31: average total_reward after train data exhaustion : 6.3 | max total_reward: 175.3
update:1665/2000, 耗时:0.01分/11.01分 | step: 426240 | performance: 1.5 | accuracy: 0.21 | loss: 0.29
update:1670/2000, 耗时:0.01分/11.05分 | step: 427520 | performance: 2.0 | accuracy: 0.14 | loss: 0.21
update:1675/2000, 耗时:0.01分/11.08分 | step: 428800 | performance: 2.0 | accuracy: 0.18 | loss: 0.32
update:1680/2000, 耗时:0.01分/11.11分 | step: 430080 | performance: 3.8 | accuracy: 0.20 | loss: 0.38
update:1685/2000, 耗时:0.01分/11.15分 | step: 431360 | performance: 4.2 | accuracy: 0.20 | loss: 0.46
update:1690/2000, 耗时:0.01分/11.18分 | step: 432640 | performance: 2.7 | accuracy: 0.19 | loss: 0.35
update:1695/2000, 耗时:0.01分/11.22分 | step: 433920 | performance: 2.3 | accuracy: 0.17 | loss: 0.11
update:1700/2000, 耗时:0.01分/11.25分 | step: 435200 | performance: 2.3 | accuracy: 0.16 | loss: 0.06
update:1705/2000, 耗时:0.01分/11.28分 | step: 436480 | performance: 1.9 | accuracy: 0.14 | loss: 0.07
update:1710/2000, 耗时:0.01分/11.32分 | step: 437760 | performance: 2.1 | accuracy: 0.13 | loss: 0.06
update:1715/2000, 耗时:0.01分/11.35分 | step: 439040 | performance: 1.9 | accuracy: 0.13 | loss: 0.07
update:1720/2000, 耗时:0.01分/11.38分 | step: 440320 | performance: 1.9 | accuracy: 0.12 | loss: 0.07
step: 441343 | worker_6@n_step_31: average total_reward after train data exhaustion : 3.2 | max total_reward: 175.3
update:1725/2000, 耗时:0.01分/11.42分 | step: 441600 | performance: 2.0 | accuracy: 0.12 | loss: 0.04
update:1730/2000, 耗时:0.01分/11.45分 | step: 442880 | performance: 1.8 | accuracy: 0.11 | loss: 0.03
step: 443645 | worker_4@n_step_31: average total_reward after train data exhaustion : 7.2 | max total_reward: 175.3
update:1735/2000, 耗时:0.01分/11.48分 | step: 444160 | performance: 1.6 | accuracy: 0.10 | loss: 0.01
step: 444922 | worker_1@n_step_31: average total_reward after train data exhaustion : 3.2 | max total_reward: 175.3
step: 444924 | worker_3@n_step_31: average total_reward after train data exhaustion : 3.3 | max total_reward: 175.3
update:1740/2000, 耗时:0.01分/11.52分 | step: 445440 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 445695 | worker_6@n_step_31: average total_reward after train data exhaustion : 2.0 | max total_reward: 175.3
update:1745/2000, 耗时:0.01分/11.55分 | step: 446720 | performance: 1.2 | accuracy: 0.18 | loss: 0.11
step: 446972 | worker_3@n_step_31: average total_reward after train data exhaustion : 3.1 | max total_reward: 175.3
step: 447482 | worker_1@n_step_31: average total_reward after train data exhaustion : 3.4 | max total_reward: 175.3
update:1750/2000, 耗时:0.01分/11.58分 | step: 448000 | performance: 1.5 | accuracy: 0.18 | loss: 0.36
update:1755/2000, 耗时:0.01分/11.62分 | step: 449280 | performance: 2.0 | accuracy: 0.15 | loss: 0.24
update:1760/2000, 耗时:0.01分/11.65分 | step: 450560 | performance: 2.0 | accuracy: 0.16 | loss: 0.21
update:1765/2000, 耗时:0.01分/11.68分 | step: 451840 | performance: 2.4 | accuracy: 0.15 | loss: 0.28
update:1770/2000, 耗时:0.01分/11.71分 | step: 453120 | performance: 2.1 | accuracy: 0.15 | loss: 0.25
update:1775/2000, 耗时:0.01分/11.74分 | step: 454400 | performance: 1.9 | accuracy: 0.13 | loss: 0.04
update:1780/2000, 耗时:0.01分/11.78分 | step: 455680 | performance: 1.9 | accuracy: 0.12 | loss: 0.03
update:1785/2000, 耗时:0.01分/11.81分 | step: 456960 | performance: 1.6 | accuracy: 0.11 | loss: 0.05
update:1790/2000, 耗时:0.01分/11.84分 | step: 458240 | performance: 1.5 | accuracy: 0.11 | loss: 0.05
step: 458750 | worker_5@n_step_31: average total_reward after train data exhaustion : 6.2 | max total_reward: 175.3
update:1795/2000, 耗时:0.01分/11.88分 | step: 459520 | performance: 1.1 | accuracy: 0.10 | loss: 0.15
update:1800/2000, 耗时:0.01分/11.91分 | step: 460800 | performance: 1.6 | accuracy: 0.12 | loss: 0.21
update:1805/2000, 耗时:0.01分/11.94分 | step: 462080 | performance: 2.2 | accuracy: 0.15 | loss: 0.19
update:1810/2000, 耗时:0.01分/11.97分 | step: 463360 | performance: 1.9 | accuracy: 0.12 | loss: 0.12
update:1815/2000, 耗时:0.01分/12.01分 | step: 464640 | performance: 3.0 | accuracy: 0.11 | loss: 0.07
update:1820/2000, 耗时:0.01分/12.04分 | step: 465920 | performance: 3.1 | accuracy: 0.12 | loss: 0.13
update:1825/2000, 耗时:0.01分/12.07分 | step: 467200 | performance: 2.8 | accuracy: 0.11 | loss: 0.08
update:1830/2000, 耗时:0.01分/12.11分 | step: 468480 | performance: 1.2 | accuracy: 0.22 | loss: 0.13
step: 468986 | worker_1@n_step_31: average total_reward after train data exhaustion : 4.7 | max total_reward: 175.3
step: 469501 | worker_4@n_step_31: average total_reward after train data exhaustion : 4.5 | max total_reward: 175.3
update:1835/2000, 耗时:0.01分/12.14分 | step: 469760 | performance: 1.3 | accuracy: 0.10 | loss: 0.09
update:1840/2000, 耗时:0.01分/12.17分 | step: 471040 | performance: 1.3 | accuracy: 0.10 | loss: 0.18
step: 471294 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.3 | max total_reward: 175.3
update:1845/2000, 耗时:0.01分/12.21分 | step: 472320 | performance: 1.4 | accuracy: 0.11 | loss: 0.14
update:1850/2000, 耗时:0.01分/12.24分 | step: 473600 | performance: 1.5 | accuracy: 0.11 | loss: 0.18
step: 473849 | worker_0@n_step_31: average total_reward after train data exhaustion : 5.3 | max total_reward: 175.3
update:1855/2000, 耗时:0.01分/12.27分 | step: 474880 | performance: 1.2 | accuracy: 0.11 | loss: 0.16
step: 475131 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 175.3
update:1860/2000, 耗时:0.01分/12.30分 | step: 476160 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 476667 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.9 | max total_reward: 175.3
update:1865/2000, 耗时:0.01分/12.34分 | step: 477440 | performance: 1.1 | accuracy: 0.09 | loss: 0.14
step: 478720 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 175.3
update:1870/2000, 耗时:0.01分/12.37分 | step: 478720 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:1875/2000, 耗时:0.01分/12.40分 | step: 480000 | performance: 1.7 | accuracy: 0.17 | loss: 0.40
update:1880/2000, 耗时:0.01分/12.44分 | step: 481280 | performance: 1.4 | accuracy: 0.16 | loss: 0.29
update:1885/2000, 耗时:0.01分/12.47分 | step: 482560 | performance: 1.7 | accuracy: 0.16 | loss: 0.35
update:1890/2000, 耗时:0.01分/12.50分 | step: 483840 | performance: 2.4 | accuracy: 0.17 | loss: 0.28
update:1895/2000, 耗时:0.01分/12.54分 | step: 485120 | performance: 1.8 | accuracy: 0.16 | loss: 0.20
update:1900/2000, 耗时:0.01分/12.57分 | step: 486400 | performance: 1.6 | accuracy: 0.14 | loss: 0.04
update:1905/2000, 耗时:0.01分/12.60分 | step: 487680 | performance: 1.6 | accuracy: 0.12 | loss: 0.01
update:1910/2000, 耗时:0.01分/12.63分 | step: 488960 | performance: 1.6 | accuracy: 0.12 | loss: 0.04
update:1915/2000, 耗时:0.01分/12.67分 | step: 490240 | performance: 1.7 | accuracy: 0.11 | loss: 0.01
update:1920/2000, 耗时:0.01分/12.70分 | step: 491520 | performance: 1.7 | accuracy: 0.10 | loss: 0.01
step: 492286 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.0 | max total_reward: 175.3
step: 492543 | worker_6@n_step_31: average total_reward after train data exhaustion : 2.0 | max total_reward: 175.3
update:1925/2000, 耗时:0.01分/12.73分 | step: 492800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 494080 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 175.3
update:1930/2000, 耗时:0.01分/12.77分 | step: 494080 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 494585 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.9 | max total_reward: 175.3
step: 494842 | worker_1@n_step_31: average total_reward after train data exhaustion : 2.0 | max total_reward: 175.3
step: 494845 | worker_4@n_step_31: average total_reward after train data exhaustion : 2.0 | max total_reward: 175.3
step: 495355 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 175.3
update:1935/2000, 耗时:0.01分/12.80分 | step: 495360 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 495612 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 175.3
step: 496126 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 175.3
step: 496380 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 175.3
update:1940/2000, 耗时:0.01分/12.83分 | step: 496640 | performance: 1.3 | accuracy: 0.15 | loss: 0.17
update:1945/2000, 耗时:0.01分/12.86分 | step: 497920 | performance: 1.2 | accuracy: 0.11 | loss: 0.18
update:1950/2000, 耗时:0.01分/12.90分 | step: 499200 | performance: 1.1 | accuracy: 0.15 | loss: 0.14
update:1955/2000, 耗时:0.01分/12.93分 | step: 500480 | performance: 1.4 | accuracy: 0.16 | loss: 0.12
step: 500986 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.4 | max total_reward: 175.3
update:1960/2000, 耗时:0.01分/12.96分 | step: 501760 | performance: 1.2 | accuracy: 0.14 | loss: 0.10
update:1965/2000, 耗时:0.01分/13.00分 | step: 503040 | performance: 1.3 | accuracy: 0.11 | loss: 0.15
step: 503802 | worker_1@n_step_31: average total_reward after train data exhaustion : 2.0 | max total_reward: 175.3
update:1970/2000, 耗时:0.01分/13.03分 | step: 504320 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 504828 | worker_3@n_step_31: average total_reward after train data exhaustion : 2.4 | max total_reward: 175.3
update:1975/2000, 耗时:0.01分/13.06分 | step: 505600 | performance: 1.1 | accuracy: 0.11 | loss: 0.19
update:1980/2000, 耗时:0.01分/13.10分 | step: 506880 | performance: 1.9 | accuracy: 0.13 | loss: 0.23
update:1985/2000, 耗时:0.01分/13.13分 | step: 508160 | performance: 2.2 | accuracy: 0.12 | loss: 0.21
update:1990/2000, 耗时:0.01分/13.16分 | step: 509440 | performance: 2.1 | accuracy: 0.12 | loss: 0.21
step: 510202 | worker_1@n_step_31: average total_reward after train data exhaustion : 3.7 | max total_reward: 175.3
update:1995/2000, 耗时:0.01分/13.20分 | step: 510720 | performance: 2.9 | accuracy: 0.12 | loss: 0.29
update:2000/2000, 耗时:0.01分/13.23分 | step: 512000 | performance: 3.4 | accuracy: 0.13 | loss: 0.20
----------------------------------------finished----------------------------------------
  0%|          | 0/408 [00:00<?, ?it/s]100%|| 408/408 [00:00<00:00, 45345.03it/s]
==================================================
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1000.00
2023-07-24T12:00:00 | net performance [%] = 0.0000
2023-07-24T12:00:00 | number of trades [#] = 0
==================================================
Trial 20 Complete [00h 13m 40s]
net_wealth: 1000.0

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 02h 39m 26s

Search: Running Trial #21

Value             |Best Value So Far |Hyperparameter
3                 |1                 |horizon
225               |730               |lookback
True              |False             |MarketFactor
3                 |3                 |lags
0.6               |0.92              |gamma
16                |32                |batch_size
5                 |1                 |n_step
0.94              |0.94              |gae_lambda
2                 |5                 |gradient_clip_norm
3                 |5                 |epochs
0.001             |0.0001            |actor_lr
0.0001            |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4298.000000   4301.000000
mean      0.000435    20113.607657  ...   20180.392273  20169.373185
std       0.027833    16040.642334  ...   16078.781641  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7741.750122   7730.930176
50%       0.000642    11571.842969  ...   11754.949707  11751.469727
75%       0.011590    29894.706152  ...   30015.383301  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 00:42:49.929750: I tensorflow/core/platform/cp22023023-07-28 00:42:49.929781: I tensorflow/core/pl2023-07-28 00:42:49.929817: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to u_featu-are_gu0ta7fr-od28 00:42:49.c.rm/c929789pc:u :1I_feat4 2t] ensorfTulhis ore_guard.ccw/:c142] o202Te3-07-28 00:42:49us.n93so000re 4: IFth tele nsoowrf Tlow/chibfoosllro TensorFlwiirowe /ng CPU instpelna/platfotarrm/fy icpu_os featropturemim_guair/zce2d burc2t0d.0c23-07-pu_f23-207c0:i1e-a2i482n wtiaro2n8syt 03 0is o0p h0: o-:inneAPI  0pDt4ium2e]7e2:42:44 9-iT2ze8hierd s9.p  Neu.0903093 0wf2o5r:manictral N24re_g4etwouh on5r:ard.eAce kI 2T ecP:142L:-Itincsor4en]F lsorr9iThi.s Te4tficl: 9o3w onIwbaDe l/ 0osc rbat2ensipoorronep 3FlarNeratiy i8rf:e/pllow orys  o wb/incIat(noa s:onpefDo t imNiorrtrmzye ieN/scA)endpuVX AV/epu_ to  sfeoarfluseoXlw t2
To  wiothharalp tiemtn/auc ooblre ernthNteie_/etwofepm izeloratdform/ng uoardAe rfom/.ccc pwui_kctlpl oLwiib:P1Inrguh  oa 4feanDeC2Ptee]UruArPe_ ipI gTuhn sNteruais Trurc_tfit d.cDch:oenayl eNe1e nsser4 o2 pieatwo ]Not (oneuTrhrinrFpe_ epDlke rLaitiboswuNNrgroaelrafrun  NTeetnss,o a )b itnoarry eiboyrsu oil rumw orkrse(do.Flow bi dcap nLniecncte b-ctairrhe rT:e1Danrsyim42NfNolti]c aTl) l orFhtilosiozp eTreon eowwinuassgdt wie iCor PU i(Folnoe Don wthNnsyithN itst h s):w o nte tro AuPbptieoIhe AV fm  Xa o iinzecAuDsppltiaedr oVeoenps pXr2l oiwnii 
wTot Nartyepehurn i e fg etehna CrPol lcforaUonomman  Nblelopie ttwhoermeicAPnssk  ILi bD ioee-cetwirlietri cfpn  pinlgr Naaourarly toCtphcei u(rPaemetl izred U o orNiniwpationeoierasDNNensntsttrw)ogrsu:h  o.ncetAiPo
tiin ko nIs ,D  tL r npeeeeAoVX rfos in iAr mbbVpXapr aNe2unicle-
uTsorfed croure rrma Tyiticene (atabhlanosle  NfetonnoelDlrolceew tw iopFlnorNoNw k ) whge mCtoeLii rabtriPthu  the sin oteha thereonsapp: yro  (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To AV enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
rU X AV pirfXoinate cosoptructile-l2o
To enable tmcritical operations:  pilons in performance-critical ohAem ier flagws.praVXi
ngtein  raotions:  AVX ACns,PA VothX 2U i
To eVX2
To ennsraeebtlbruildnr ea btolpeuctieratioh em in thnos, emT  iroebetuhinnsorFlow er operations, rebwith n otherluilds id Tensor TensF lonrFlotph opwoewree appropriatrforae man with the appropriate compiler flags.
with the appropriate compiler f compiler flags.
tioce-criticalln osperations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the apags.
propriate compiler, rebuild TensorFlow with the appropriate compiler flags.
 flags.
2023-07-28 00:42:50.526611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:42:50.542344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:42:50.543830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:42:50.547069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:42:50.565321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:42:50.566277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:42:50.574734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:42:50.586104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
Saving PPO weights in both H5 format and checkpoint @ update:4 
update:  5/2000, 耗时:0.00分/0.03分 | step:   200 | performance: 1.2 | accuracy: 0.24 | loss: 1.97
update: 10/2000, 耗时:0.00分/0.04分 | step:   400 | performance: 0.7 | accuracy: 0.14 | loss: 0.81
update: 15/2000, 耗时:0.00分/0.05分 | step:   600 | performance: 0.7 | accuracy: 0.11 | loss: 0.43
step: 675 | worker_2@n_step_4: average total_reward after train data exhaustion : -3.8 | max total_reward: 0.1
step: 677 | worker_4@n_step_4: average total_reward after train data exhaustion : -3.3 | max total_reward: 1.7
step: 678 | worker_5@n_step_4: average total_reward after train data exhaustion : -3.0 | max total_reward: 1.7
update: 20/2000, 耗时:0.00分/0.06分 | step:   800 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 834 | worker_1@n_step_4: average total_reward after train data exhaustion : -2.1 | max total_reward: 1.7
step: 916 | worker_3@n_step_4: average total_reward after train data exhaustion : -2.0 | max total_reward: 1.7
step: 920 | worker_7@n_step_4: average total_reward after train data exhaustion : -1.9 | max total_reward: 1.7
update: 25/2000, 耗时:0.00分/0.06分 | step:  1000 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
update: 30/2000, 耗时:0.00分/0.07分 | step:  1200 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
Saving PPO weights in both H5 format and checkpoint @ update:31 
Saving PPO weights in both H5 format and checkpoint @ update:32 
step: 1355 | worker_2@n_step_4: average total_reward after train data exhaustion : -1.6 | max total_reward: 1.7
step: 1357 | worker_4@n_step_4: average total_reward after train data exhaustion : -1.6 | max total_reward: 1.7
step: 1358 | worker_5@n_step_4: average total_reward after train data exhaustion : -1.6 | max total_reward: 1.7
update: 35/2000, 耗时:0.00分/0.09分 | step:  1400 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 1514 | worker_1@n_step_4: average total_reward after train data exhaustion : -1.3 | max total_reward: 1.7
step: 1553 | worker_0@n_step_4: average total_reward after train data exhaustion : -1.1 | max total_reward: 1.7
step: 1559 | worker_6@n_step_4: average total_reward after train data exhaustion : -1.0 | max total_reward: 1.7
Saving PPO weights in both H5 format and checkpoint @ update:39 
step: 1596 | worker_3@n_step_4: average total_reward after train data exhaustion : -0.9 | max total_reward: 1.7
step: 1600 | worker_7@n_step_4: average total_reward after train data exhaustion : -0.9 | max total_reward: 1.7
update: 40/2000, 耗时:0.00分/0.10分 | step:  1600 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
Saving PPO weights in both H5 format and checkpoint @ update:40 
Saving PPO weights in both H5 format and checkpoint @ update:41 
Saving PPO weights in both H5 format and checkpoint @ update:43 
update: 45/2000, 耗时:0.00分/0.13分 | step:  1800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update: 50/2000, 耗时:0.00分/0.14分 | step:  2000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 2035 | worker_2@n_step_4: average total_reward after train data exhaustion : -0.6 | max total_reward: 1.7
step: 2037 | worker_4@n_step_4: average total_reward after train data exhaustion : -0.6 | max total_reward: 1.7
step: 2038 | worker_5@n_step_4: average total_reward after train data exhaustion : -0.6 | max total_reward: 1.7
Saving PPO weights in both H5 format and checkpoint @ update:53 
Saving PPO weights in both H5 format and checkpoint @ update:54 
step: 2194 | worker_1@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 1.7
update: 55/2000, 耗时:0.00分/0.16分 | step:  2200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
Saving PPO weights in both H5 format and checkpoint @ update:55 
step: 2233 | worker_0@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 1.7
step: 2239 | worker_6@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 1.7
step: 2276 | worker_3@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 1.7
step: 2280 | worker_7@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 1.7
update: 60/2000, 耗时:0.00分/0.17分 | step:  2400 | performance: 0.9 | accuracy: 0.00 | loss: 0.28
step: 2478 | worker_5@n_step_4: average total_reward after train data exhaustion : 0.0 | max total_reward: 2.8
update: 65/2000, 耗时:0.00分/0.18分 | step:  2600 | performance: 0.9 | accuracy: 0.13 | loss: 0.54
step: 2634 | worker_1@n_step_4: average total_reward after train data exhaustion : -0.1 | max total_reward: 2.8
step: 2673 | worker_0@n_step_4: average total_reward after train data exhaustion : -0.3 | max total_reward: 2.8
step: 2715 | worker_2@n_step_4: average total_reward after train data exhaustion : -0.4 | max total_reward: 2.8
update: 70/2000, 耗时:0.00分/0.19分 | step:  2800 | performance: 1.2 | accuracy: 0.12 | loss: 0.05
step: 2919 | worker_6@n_step_4: average total_reward after train data exhaustion : -0.2 | max total_reward: 5.7
step: 2956 | worker_3@n_step_4: average total_reward after train data exhaustion : -0.2 | max total_reward: 5.7
update: 75/2000, 耗时:0.00分/0.20分 | step:  3000 | performance: 1.0 | accuracy: 0.25 | loss: 0.31
update: 80/2000, 耗时:0.00分/0.21分 | step:  3200 | performance: 1.0 | accuracy: 0.17 | loss: 0.99
update: 85/2000, 耗时:0.00分/0.23分 | step:  3400 | performance: 1.2 | accuracy: 0.15 | loss: 0.07
update: 90/2000, 耗时:0.00分/0.24分 | step:  3600 | performance: 1.3 | accuracy: 0.15 | loss: 0.25
step: 3714 | worker_1@n_step_4: average total_reward after train data exhaustion : -0.5 | max total_reward: 5.7
update: 95/2000, 耗时:0.00分/0.25分 | step:  3800 | performance: 1.6 | accuracy: 0.16 | loss: 0.96
update:100/2000, 耗时:0.00分/0.26分 | step:  4000 | performance: 1.9 | accuracy: 0.19 | loss: 0.78
update:105/2000, 耗时:0.00分/0.27分 | step:  4200 | performance: 1.7 | accuracy: 0.19 | loss: 0.78
update:110/2000, 耗时:0.00分/0.28分 | step:  4400 | performance: 2.2 | accuracy: 0.21 | loss: 0.25
update:115/2000, 耗时:0.00分/0.29分 | step:  4600 | performance: 2.5 | accuracy: 0.22 | loss: 0.46
update:120/2000, 耗时:0.00分/0.30分 | step:  4800 | performance: 2.7 | accuracy: 0.23 | loss: 0.60
update:125/2000, 耗时:0.00分/0.31分 | step:  5000 | performance: 2.6 | accuracy: 0.24 | loss: 0.64
update:130/2000, 耗时:0.00分/0.32分 | step:  5200 | performance: 3.0 | accuracy: 0.25 | loss: 0.65
update:135/2000, 耗时:0.00分/0.33分 | step:  5400 | performance: 3.9 | accuracy: 0.26 | loss: 1.02
update:140/2000, 耗时:0.00分/0.34分 | step:  5600 | performance: 4.0 | accuracy: 0.27 | loss: 0.70
update:145/2000, 耗时:0.00分/0.35分 | step:  5800 | performance: 5.6 | accuracy: 0.28 | loss: 0.99
update:150/2000, 耗时:0.00分/0.36分 | step:  6000 | performance: 6.6 | accuracy: 0.30 | loss: 0.96
update:155/2000, 耗时:0.00分/0.37分 | step:  6200 | performance: 6.5 | accuracy: 0.30 | loss: 1.66
update:160/2000, 耗时:0.00分/0.38分 | step:  6400 | performance: 5.0 | accuracy: 0.30 | loss: 0.37
update:165/2000, 耗时:0.00分/0.40分 | step:  6600 | performance: 7.9 | accuracy: 0.31 | loss: 0.91
update:170/2000, 耗时:0.00分/0.41分 | step:  6800 | performance: 8.1 | accuracy: 0.31 | loss: 0.89
update:175/2000, 耗时:0.00分/0.42分 | step:  7000 | performance: 6.1 | accuracy: 0.30 | loss: 1.63
update:180/2000, 耗时:0.00分/0.43分 | step:  7200 | performance: 8.2 | accuracy: 0.31 | loss: 1.21
update:185/2000, 耗时:0.00分/0.44分 | step:  7400 | performance: 8.2 | accuracy: 0.32 | loss: 0.78
update:190/2000, 耗时:0.00分/0.45分 | step:  7600 | performance: 9.8 | accuracy: 0.33 | loss: 1.61
update:195/2000, 耗时:0.00分/0.46分 | step:  7800 | performance: 8.8 | accuracy: 0.33 | loss: 1.06
update:200/2000, 耗时:0.00分/0.47分 | step:  8000 | performance: 9.4 | accuracy: 0.35 | loss: 0.81
update:205/2000, 耗时:0.00分/0.48分 | step:  8200 | performance: 14.6 | accuracy: 0.35 | loss: 1.15
update:210/2000, 耗时:0.00分/0.49分 | step:  8400 | performance: 39.6 | accuracy: 0.37 | loss: 1.53
update:215/2000, 耗时:0.00分/0.50分 | step:  8600 | performance: 71.6 | accuracy: 0.38 | loss: 1.87
update:220/2000, 耗时:0.00分/0.51分 | step:  8800 | performance: 59.0 | accuracy: 0.38 | loss: 1.02
update:225/2000, 耗时:0.00分/0.52分 | step:  9000 | performance: 48.8 | accuracy: 0.37 | loss: 2.03
update:230/2000, 耗时:0.00分/0.53分 | step:  9200 | performance: 65.1 | accuracy: 0.38 | loss: 0.96
update:235/2000, 耗时:0.00分/0.55分 | step:  9400 | performance: 78.7 | accuracy: 0.39 | loss: 0.94
update:240/2000, 耗时:0.00分/0.56分 | step:  9600 | performance: 71.0 | accuracy: 0.39 | loss: 1.25
update:245/2000, 耗时:0.00分/0.57分 | step:  9800 | performance: 61.0 | accuracy: 0.38 | loss: 0.87
update:250/2000, 耗时:0.00分/0.58分 | step: 10000 | performance: 58.6 | accuracy: 0.38 | loss: 0.90
update:255/2000, 耗时:0.00分/0.59分 | step: 10200 | performance: 55.7 | accuracy: 0.38 | loss: 0.87
update:260/2000, 耗时:0.00分/0.60分 | step: 10400 | performance: 31.0 | accuracy: 0.38 | loss: 0.49
update:265/2000, 耗时:0.00分/0.61分 | step: 10600 | performance: 31.2 | accuracy: 0.37 | loss: 0.36
update:270/2000, 耗时:0.00分/0.62分 | step: 10800 | performance: 30.7 | accuracy: 0.36 | loss: 0.11
update:275/2000, 耗时:0.00分/0.63分 | step: 11000 | performance: 30.7 | accuracy: 0.36 | loss: 0.01
update:280/2000, 耗时:0.00分/0.64分 | step: 11200 | performance: 30.7 | accuracy: 0.35 | loss: 0.03
update:285/2000, 耗时:0.00分/0.65分 | step: 11400 | performance: 30.7 | accuracy: 0.34 | loss: 0.07
update:290/2000, 耗时:0.00分/0.66分 | step: 11600 | performance: 33.3 | accuracy: 0.34 | loss: 0.18
update:295/2000, 耗时:0.00分/0.67分 | step: 11800 | performance: 37.2 | accuracy: 0.34 | loss: 1.63
update:300/2000, 耗时:0.00分/0.68分 | step: 12000 | performance: 54.2 | accuracy: 0.34 | loss: 1.23
update:305/2000, 耗时:0.00分/0.69分 | step: 12200 | performance: 50.7 | accuracy: 0.34 | loss: 0.45
update:310/2000, 耗时:0.00分/0.70分 | step: 12400 | performance: 65.9 | accuracy: 0.34 | loss: 0.75
update:315/2000, 耗时:0.00分/0.72分 | step: 12600 | performance: 52.6 | accuracy: 0.35 | loss: 0.92
update:320/2000, 耗时:0.00分/0.73分 | step: 12800 | performance: 38.4 | accuracy: 0.35 | loss: 0.93
update:325/2000, 耗时:0.00分/0.74分 | step: 13000 | performance: 43.6 | accuracy: 0.35 | loss: 0.65
update:330/2000, 耗时:0.00分/0.75分 | step: 13200 | performance: 46.6 | accuracy: 0.34 | loss: 0.79
update:335/2000, 耗时:0.00分/0.76分 | step: 13400 | performance: 43.7 | accuracy: 0.34 | loss: 0.49
update:340/2000, 耗时:0.00分/0.77分 | step: 13600 | performance: 40.3 | accuracy: 0.34 | loss: 0.97
update:345/2000, 耗时:0.00分/0.78分 | step: 13800 | performance: 32.4 | accuracy: 0.34 | loss: 0.15
update:350/2000, 耗时:0.00分/0.79分 | step: 14000 | performance: 37.6 | accuracy: 0.34 | loss: 0.67
update:355/2000, 耗时:0.00分/0.80分 | step: 14200 | performance: 51.4 | accuracy: 0.34 | loss: 1.18
update:360/2000, 耗时:0.00分/0.81分 | step: 14400 | performance: 56.2 | accuracy: 0.34 | loss: 0.86
update:365/2000, 耗时:0.00分/0.82分 | step: 14600 | performance: 52.7 | accuracy: 0.35 | loss: 1.15
update:370/2000, 耗时:0.00分/0.83分 | step: 14800 | performance: 56.0 | accuracy: 0.35 | loss: 1.90
update:375/2000, 耗时:0.00分/0.84分 | step: 15000 | performance: 35.1 | accuracy: 0.35 | loss: 0.98
update:380/2000, 耗时:0.00分/0.85分 | step: 15200 | performance: 30.9 | accuracy: 0.35 | loss: 0.81
update:385/2000, 耗时:0.00分/0.86分 | step: 15400 | performance: 28.9 | accuracy: 0.35 | loss: 0.98
update:390/2000, 耗时:0.00分/0.87分 | step: 15600 | performance: 28.7 | accuracy: 0.35 | loss: 1.27
update:395/2000, 耗时:0.00分/0.88分 | step: 15800 | performance: 32.9 | accuracy: 0.35 | loss: 1.29
update:400/2000, 耗时:0.00分/0.89分 | step: 16000 | performance: 83.7 | accuracy: 0.36 | loss: 2.28
update:405/2000, 耗时:0.00分/0.90分 | step: 16200 | performance: 73.9 | accuracy: 0.36 | loss: 0.86
update:410/2000, 耗时:0.00分/0.91分 | step: 16400 | performance: 63.2 | accuracy: 0.36 | loss: 1.05
update:415/2000, 耗时:0.00分/0.92分 | step: 16600 | performance: 53.1 | accuracy: 0.36 | loss: 0.37
update:420/2000, 耗时:0.00分/0.94分 | step: 16800 | performance: 52.9 | accuracy: 0.36 | loss: 0.76
update:425/2000, 耗时:0.00分/0.95分 | step: 17000 | performance: 47.0 | accuracy: 0.35 | loss: 0.36
update:430/2000, 耗时:0.00分/0.96分 | step: 17200 | performance: 49.7 | accuracy: 0.35 | loss: 0.13
update:435/2000, 耗时:0.00分/0.97分 | step: 17400 | performance: 49.5 | accuracy: 0.35 | loss: 0.07
update:440/2000, 耗时:0.00分/0.98分 | step: 17600 | performance: 49.5 | accuracy: 0.34 | loss: 0.00
update:445/2000, 耗时:0.00分/0.99分 | step: 17800 | performance: 49.5 | accuracy: 0.34 | loss: 0.04
update:450/2000, 耗时:0.00分/1.00分 | step: 18000 | performance: 49.5 | accuracy: 0.34 | loss: 0.01
update:455/2000, 耗时:0.00分/1.01分 | step: 18200 | performance: 49.5 | accuracy: 0.33 | loss: 0.04
update:460/2000, 耗时:0.00分/1.02分 | step: 18400 | performance: 49.5 | accuracy: 0.33 | loss: 0.07
update:465/2000, 耗时:0.00分/1.03分 | step: 18600 | performance: 50.5 | accuracy: 0.33 | loss: 0.08
update:470/2000, 耗时:0.00分/1.04分 | step: 18800 | performance: 49.8 | accuracy: 0.32 | loss: 0.12
update:475/2000, 耗时:0.00分/1.05分 | step: 19000 | performance: 49.8 | accuracy: 0.32 | loss: 0.05
update:480/2000, 耗时:0.00分/1.06分 | step: 19200 | performance: 49.8 | accuracy: 0.32 | loss: 0.48
update:485/2000, 耗时:0.00分/1.07分 | step: 19400 | performance: 56.4 | accuracy: 0.32 | loss: 0.68
update:490/2000, 耗时:0.00分/1.08分 | step: 19600 | performance: 93.1 | accuracy: 0.33 | loss: 1.12
update:495/2000, 耗时:0.00分/1.09分 | step: 19800 | performance: 127.7 | accuracy: 0.33 | loss: 1.07
update:500/2000, 耗时:0.00分/1.10分 | step: 20000 | performance: 217.9 | accuracy: 0.34 | loss: 1.13
update:505/2000, 耗时:0.00分/1.12分 | step: 20200 | performance: 213.9 | accuracy: 0.34 | loss: 1.09
update:510/2000, 耗时:0.00分/1.13分 | step: 20400 | performance: 378.1 | accuracy: 0.34 | loss: 1.19
update:515/2000, 耗时:0.00分/1.14分 | step: 20600 | performance: 714.6 | accuracy: 0.35 | loss: 1.35
update:520/2000, 耗时:0.00分/1.15分 | step: 20800 | performance: 1382.5 | accuracy: 0.35 | loss: 2.26
update:525/2000, 耗时:0.00分/1.16分 | step: 21000 | performance: 910.3 | accuracy: 0.35 | loss: 1.70
update:530/2000, 耗时:0.00分/1.17分 | step: 21200 | performance: 1593.1 | accuracy: 0.35 | loss: 0.96
update:535/2000, 耗时:0.00分/1.18分 | step: 21400 | performance: 4398.7 | accuracy: 0.36 | loss: 2.70
update:540/2000, 耗时:0.00分/1.19分 | step: 21600 | performance: 2760.9 | accuracy: 0.36 | loss: 1.64
update:545/2000, 耗时:0.00分/1.21分 | step: 21800 | performance: 4371.7 | accuracy: 0.36 | loss: 1.37
update:550/2000, 耗时:0.00分/1.22分 | step: 22000 | performance: 4581.7 | accuracy: 0.36 | loss: 0.98
update:555/2000, 耗时:0.00分/1.23分 | step: 22200 | performance: 4845.4 | accuracy: 0.37 | loss: 1.80
update:560/2000, 耗时:0.00分/1.24分 | step: 22400 | performance: 2770.2 | accuracy: 0.37 | loss: 1.79
update:565/2000, 耗时:0.00分/1.25分 | step: 22600 | performance: 4041.1 | accuracy: 0.37 | loss: 1.21
update:570/2000, 耗时:0.00分/1.26分 | step: 22800 | performance: 1575.5 | accuracy: 0.37 | loss: 1.95
update:575/2000, 耗时:0.00分/1.28分 | step: 23000 | performance: 999.5 | accuracy: 0.37 | loss: 1.43
update:580/2000, 耗时:0.00分/1.29分 | step: 23200 | performance: 765.2 | accuracy: 0.37 | loss: 1.58
update:585/2000, 耗时:0.00分/1.30分 | step: 23400 | performance: 762.8 | accuracy: 0.37 | loss: 0.99
update:590/2000, 耗时:0.00分/1.31分 | step: 23600 | performance: 840.6 | accuracy: 0.37 | loss: 1.07
update:595/2000, 耗时:0.00分/1.32分 | step: 23800 | performance: 805.9 | accuracy: 0.37 | loss: 1.01
update:600/2000, 耗时:0.00分/1.33分 | step: 24000 | performance: 1697.5 | accuracy: 0.37 | loss: 1.58
update:605/2000, 耗时:0.00分/1.34分 | step: 24200 | performance: 2648.6 | accuracy: 0.37 | loss: 1.30
update:610/2000, 耗时:0.00分/1.35分 | step: 24400 | performance: 2549.6 | accuracy: 0.37 | loss: 1.09
update:615/2000, 耗时:0.00分/1.37分 | step: 24600 | performance: 2391.0 | accuracy: 0.37 | loss: 1.75
update:620/2000, 耗时:0.00分/1.38分 | step: 24800 | performance: 1896.7 | accuracy: 0.37 | loss: 1.64
update:625/2000, 耗时:0.00分/1.39分 | step: 25000 | performance: 2502.4 | accuracy: 0.38 | loss: 1.10
update:630/2000, 耗时:0.00分/1.40分 | step: 25200 | performance: 5014.0 | accuracy: 0.38 | loss: 1.25
update:635/2000, 耗时:0.00分/1.41分 | step: 25400 | performance: 4664.2 | accuracy: 0.38 | loss: 0.99
update:640/2000, 耗时:0.00分/1.42分 | step: 25600 | performance: 6352.9 | accuracy: 0.38 | loss: 1.43
update:645/2000, 耗时:0.00分/1.43分 | step: 25800 | performance: 3877.3 | accuracy: 0.38 | loss: 1.53
update:650/2000, 耗时:0.00分/1.45分 | step: 26000 | performance: 2255.5 | accuracy: 0.38 | loss: 1.77
update:655/2000, 耗时:0.00分/1.46分 | step: 26200 | performance: 2023.7 | accuracy: 0.38 | loss: 1.11
update:660/2000, 耗时:0.00分/1.47分 | step: 26400 | performance: 2009.4 | accuracy: 0.38 | loss: 1.17
update:665/2000, 耗时:0.00分/1.48分 | step: 26600 | performance: 1524.2 | accuracy: 0.38 | loss: 0.60
update:670/2000, 耗时:0.00分/1.49分 | step: 26800 | performance: 1381.9 | accuracy: 0.38 | loss: 0.35
update:675/2000, 耗时:0.00分/1.50分 | step: 27000 | performance: 1320.9 | accuracy: 0.38 | loss: 0.08
update:680/2000, 耗时:0.00分/1.51分 | step: 27200 | performance: 1403.3 | accuracy: 0.38 | loss: 0.13
update:685/2000, 耗时:0.00分/1.53分 | step: 27400 | performance: 1414.8 | accuracy: 0.37 | loss: 0.05
update:690/2000, 耗时:0.00分/1.54分 | step: 27600 | performance: 1434.1 | accuracy: 0.37 | loss: 0.03
update:695/2000, 耗时:0.00分/1.55分 | step: 27800 | performance: 1441.0 | accuracy: 0.37 | loss: 0.07
update:700/2000, 耗时:0.00分/1.56分 | step: 28000 | performance: 1356.3 | accuracy: 0.36 | loss: 0.07
update:705/2000, 耗时:0.00分/1.57分 | step: 28200 | performance: 1389.5 | accuracy: 0.36 | loss: 0.02
update:710/2000, 耗时:0.00分/1.58分 | step: 28400 | performance: 1389.5 | accuracy: 0.36 | loss: 0.01
update:715/2000, 耗时:0.00分/1.60分 | step: 28600 | performance: 1389.5 | accuracy: 0.36 | loss: 0.02
update:720/2000, 耗时:0.00分/1.61分 | step: 28800 | performance: 1389.5 | accuracy: 0.35 | loss: 0.02
update:725/2000, 耗时:0.00分/1.62分 | step: 29000 | performance: 1389.5 | accuracy: 0.35 | loss: -0.00
update:730/2000, 耗时:0.00分/1.63分 | step: 29200 | performance: 1407.5 | accuracy: 0.35 | loss: -0.01
update:735/2000, 耗时:0.00分/1.64分 | step: 29400 | performance: 1407.5 | accuracy: 0.35 | loss: 0.03
update:740/2000, 耗时:0.00分/1.65分 | step: 29600 | performance: 1407.5 | accuracy: 0.34 | loss: 0.00
update:745/2000, 耗时:0.00分/1.66分 | step: 29800 | performance: 1407.5 | accuracy: 0.34 | loss: 0.00
update:750/2000, 耗时:0.00分/1.67分 | step: 30000 | performance: 1407.5 | accuracy: 0.34 | loss: 0.00
update:755/2000, 耗时:0.00分/1.68分 | step: 30200 | performance: 1401.7 | accuracy: 0.34 | loss: 0.02
update:760/2000, 耗时:0.00分/1.69分 | step: 30400 | performance: 1401.7 | accuracy: 0.33 | loss: 0.02
update:765/2000, 耗时:0.00分/1.70分 | step: 30600 | performance: 1401.7 | accuracy: 0.33 | loss: 0.00
update:770/2000, 耗时:0.00分/1.72分 | step: 30800 | performance: 1401.7 | accuracy: 0.33 | loss: 0.00
update:775/2000, 耗时:0.00分/1.73分 | step: 31000 | performance: 1401.7 | accuracy: 0.33 | loss: 0.10
update:780/2000, 耗时:0.00分/1.74分 | step: 31200 | performance: 1401.7 | accuracy: 0.33 | loss: 0.01
update:785/2000, 耗时:0.00分/1.75分 | step: 31400 | performance: 1401.7 | accuracy: 0.32 | loss: 0.00
update:790/2000, 耗时:0.00分/1.76分 | step: 31600 | performance: 1401.7 | accuracy: 0.32 | loss: 0.06
update:795/2000, 耗时:0.00分/1.77分 | step: 31800 | performance: 1401.7 | accuracy: 0.32 | loss: 0.04
update:800/2000, 耗时:0.00分/1.78分 | step: 32000 | performance: 1401.7 | accuracy: 0.32 | loss: 0.02
update:805/2000, 耗时:0.00分/1.79分 | step: 32200 | performance: 1400.8 | accuracy: 0.32 | loss: 0.07
Saving PPO weights in both H5 format and checkpoint @ update:805 
step: 32239 | worker_6@n_step_4: average total_reward after train data exhaustion : 6.8 | max total_reward: 133.7
Saving PPO weights in both H5 format and checkpoint @ update:806 
step: 32276 | worker_3@n_step_4: average total_reward after train data exhaustion : 13.2 | max total_reward: 174.1
Saving PPO weights in both H5 format and checkpoint @ update:807 
Saving PPO weights in both H5 format and checkpoint @ update:808 
update:810/2000, 耗时:0.00分/1.82分 | step: 32400 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 32478 | worker_5@n_step_4: average total_reward after train data exhaustion : 17.6 | max total_reward: 222.2
Saving PPO weights in both H5 format and checkpoint @ update:813 
step: 32560 | worker_7@n_step_4: average total_reward after train data exhaustion : 17.7 | max total_reward: 222.2
Saving PPO weights in both H5 format and checkpoint @ update:814 
update:815/2000, 耗时:0.00分/1.84分 | step: 32600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 32637 | worker_4@n_step_4: average total_reward after train data exhaustion : 17.6 | max total_reward: 222.2
step: 32673 | worker_0@n_step_4: average total_reward after train data exhaustion : 17.7 | max total_reward: 222.2
step: 32715 | worker_2@n_step_4: average total_reward after train data exhaustion : 17.7 | max total_reward: 222.2
Saving PPO weights in both H5 format and checkpoint @ update:818 
Saving PPO weights in both H5 format and checkpoint @ update:819 
update:820/2000, 耗时:0.00分/1.85分 | step: 32800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
Saving PPO weights in both H5 format and checkpoint @ update:820 
Saving PPO weights in both H5 format and checkpoint @ update:821 
step: 32919 | worker_6@n_step_4: average total_reward after train data exhaustion : 18.0 | max total_reward: 222.2
step: 32956 | worker_3@n_step_4: average total_reward after train data exhaustion : 18.0 | max total_reward: 222.2
update:825/2000, 耗时:0.00分/1.87分 | step: 33000 | performance: 1.3 | accuracy: 0.75 | loss: 0.75
step: 33034 | worker_1@n_step_4: average total_reward after train data exhaustion : 23.7 | max total_reward: 289.5
Saving PPO weights in both H5 format and checkpoint @ update:826 
update:830/2000, 耗时:0.00分/1.89分 | step: 33200 | performance: 1.4 | accuracy: 0.41 | loss: 1.01
update:835/2000, 耗时:0.00分/1.90分 | step: 33400 | performance: 1.3 | accuracy: 0.24 | loss: 0.03
update:840/2000, 耗时:0.00分/1.91分 | step: 33600 | performance: 1.3 | accuracy: 0.16 | loss: -0.00
step: 33717 | worker_4@n_step_4: average total_reward after train data exhaustion : 23.7 | max total_reward: 289.5
step: 33795 | worker_2@n_step_4: average total_reward after train data exhaustion : 23.6 | max total_reward: 289.5
update:845/2000, 耗时:0.00分/1.92分 | step: 33800 | performance: 1.3 | accuracy: 0.12 | loss: 0.05
Saving PPO weights in both H5 format and checkpoint @ update:847 
step: 33913 | worker_0@n_step_4: average total_reward after train data exhaustion : 22.3 | max total_reward: 289.5
step: 33998 | worker_5@n_step_4: average total_reward after train data exhaustion : 13.6 | max total_reward: 289.5
update:850/2000, 耗时:0.00分/1.94分 | step: 34000 | performance: 1.3 | accuracy: 0.10 | loss: 0.04
step: 34079 | worker_6@n_step_4: average total_reward after train data exhaustion : 5.8 | max total_reward: 289.5
update:855/2000, 耗时:0.00分/1.95分 | step: 34200 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 34397 | worker_4@n_step_4: average total_reward after train data exhaustion : 5.9 | max total_reward: 289.5
update:860/2000, 耗时:0.00分/1.96分 | step: 34400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 34436 | worker_3@n_step_4: average total_reward after train data exhaustion : 5.9 | max total_reward: 289.5
step: 34475 | worker_2@n_step_4: average total_reward after train data exhaustion : 5.9 | max total_reward: 289.5
step: 34514 | worker_1@n_step_4: average total_reward after train data exhaustion : 5.9 | max total_reward: 289.5
step: 34560 | worker_7@n_step_4: average total_reward after train data exhaustion : 5.9 | max total_reward: 289.5
step: 34593 | worker_0@n_step_4: average total_reward after train data exhaustion : 5.9 | max total_reward: 289.5
update:865/2000, 耗时:0.00分/1.97分 | step: 34600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 34678 | worker_5@n_step_4: average total_reward after train data exhaustion : 5.9 | max total_reward: 289.5
step: 34759 | worker_6@n_step_4: average total_reward after train data exhaustion : 0.3 | max total_reward: 289.5
update:870/2000, 耗时:0.00分/1.98分 | step: 34800 | performance: 0.9 | accuracy: 0.00 | loss: 0.00
step: 35000 | worker_7@n_step_4: average total_reward after train data exhaustion : 0.2 | max total_reward: 289.5
update:875/2000, 耗时:0.00分/1.99分 | step: 35000 | performance: 1.0 | accuracy: 0.00 | loss: 0.30
step: 35116 | worker_3@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 289.5
step: 35155 | worker_2@n_step_4: average total_reward after train data exhaustion : -0.0 | max total_reward: 289.5
step: 35193 | worker_0@n_step_4: average total_reward after train data exhaustion : 0.0 | max total_reward: 289.5
step: 35194 | worker_1@n_step_4: average total_reward after train data exhaustion : 0.0 | max total_reward: 289.5
step: 35199 | worker_6@n_step_4: average total_reward after train data exhaustion : 0.0 | max total_reward: 289.5
update:880/2000, 耗时:0.00分/2.00分 | step: 35200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 35358 | worker_5@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 289.5
update:885/2000, 耗时:0.00分/2.01分 | step: 35400 | performance: 1.0 | accuracy: 0.06 | loss: 0.02
step: 35556 | worker_3@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 289.5
update:890/2000, 耗时:0.00分/2.02分 | step: 35600 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 35639 | worker_6@n_step_4: average total_reward after train data exhaustion : 0.2 | max total_reward: 289.5
step: 35680 | worker_7@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 289.5
update:895/2000, 耗时:0.00分/2.03分 | step: 35800 | performance: 0.9 | accuracy: 0.00 | loss: 0.03
step: 35873 | worker_0@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 289.5
step: 35874 | worker_1@n_step_4: average total_reward after train data exhaustion : 0.1 | max total_reward: 289.5
step: 35958 | worker_5@n_step_4: average total_reward after train data exhaustion : 0.2 | max total_reward: 289.5
update:900/2000, 耗时:0.00分/2.04分 | step: 36000 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 36156 | worker_3@n_step_4: average total_reward after train data exhaustion : 0.2 | max total_reward: 289.5
update:905/2000, 耗时:0.00分/2.05分 | step: 36200 | performance: 0.9 | accuracy: 0.00 | loss: 0.03
step: 36319 | worker_6@n_step_4: average total_reward after train data exhaustion : 0.2 | max total_reward: 289.5
update:910/2000, 耗时:0.00分/2.06分 | step: 36400 | performance: 1.1 | accuracy: 1.00 | loss: 0.51
update:915/2000, 耗时:0.00分/2.07分 | step: 36600 | performance: 1.5 | accuracy: 0.31 | loss: 0.61
update:920/2000, 耗时:0.00分/2.08分 | step: 36800 | performance: 1.2 | accuracy: 0.24 | loss: 0.23
step: 36958 | worker_5@n_step_4: average total_reward after train data exhaustion : 0.2 | max total_reward: 289.5
update:925/2000, 耗时:0.00分/2.10分 | step: 37000 | performance: 1.2 | accuracy: 0.16 | loss: 0.05
step: 37117 | worker_4@n_step_4: average total_reward after train data exhaustion : 0.3 | max total_reward: 289.5
step: 37156 | worker_3@n_step_4: average total_reward after train data exhaustion : 0.2 | max total_reward: 289.5
update:930/2000, 耗时:0.00分/2.11分 | step: 37200 | performance: 1.2 | accuracy: 0.12 | loss: 0.04
update:935/2000, 耗时:0.00分/2.12分 | step: 37400 | performance: 1.1 | accuracy: 0.10 | loss: 0.23
step: 37440 | worker_7@n_step_4: average total_reward after train data exhaustion : 0.3 | max total_reward: 289.5
update:940/2000, 耗时:0.00分/2.13分 | step: 37600 | performance: 1.1 | accuracy: 0.15 | loss: 0.12
update:945/2000, 耗时:0.00分/2.14分 | step: 37800 | performance: 0.5 | accuracy: 0.11 | loss: 0.74
update:950/2000, 耗时:0.00分/2.15分 | step: 38000 | performance: 1.0 | accuracy: 0.21 | loss: 0.42
update:955/2000, 耗时:0.00分/2.16分 | step: 38200 | performance: 0.7 | accuracy: 0.25 | loss: 0.79
update:960/2000, 耗时:0.00分/2.17分 | step: 38400 | performance: 0.6 | accuracy: 0.16 | loss: 0.35
update:965/2000, 耗时:0.00分/2.18分 | step: 38600 | performance: 1.2 | accuracy: 0.20 | loss: 0.60
update:970/2000, 耗时:0.00分/2.19分 | step: 38800 | performance: 1.1 | accuracy: 0.22 | loss: 0.63
update:975/2000, 耗时:0.00分/2.20分 | step: 39000 | performance: 1.3 | accuracy: 0.24 | loss: 0.98
update:980/2000, 耗时:0.00分/2.21分 | step: 39200 | performance: 1.2 | accuracy: 0.24 | loss: 0.87
update:985/2000, 耗时:0.00分/2.22分 | step: 39400 | performance: 1.6 | accuracy: 0.27 | loss: 0.50
update:990/2000, 耗时:0.00分/2.23分 | step: 39600 | performance: 2.1 | accuracy: 0.28 | loss: 0.64
update:995/2000, 耗时:0.00分/2.24分 | step: 39800 | performance: 2.3 | accuracy: 0.29 | loss: 0.57
update:1000/2000, 耗时:0.00分/2.25分 | step: 40000 | performance: 2.4 | accuracy: 0.30 | loss: 0.64
update:1005/2000, 耗时:0.00分/2.26分 | step: 40200 | performance: 2.9 | accuracy: 0.32 | loss: 0.54
update:1010/2000, 耗时:0.00分/2.27分 | step: 40400 | performance: 2.9 | accuracy: 0.31 | loss: 0.57
update:1015/2000, 耗时:0.00分/2.28分 | step: 40600 | performance: 3.7 | accuracy: 0.33 | loss: 0.62
update:1020/2000, 耗时:0.00分/2.29分 | step: 40800 | performance: 3.4 | accuracy: 0.32 | loss: 0.62
update:1025/2000, 耗时:0.00分/2.30分 | step: 41000 | performance: 3.0 | accuracy: 0.31 | loss: 0.65
update:1030/2000, 耗时:0.00分/2.31分 | step: 41200 | performance: 2.4 | accuracy: 0.30 | loss: 0.48
update:1035/2000, 耗时:0.00分/2.32分 | step: 41400 | performance: 3.0 | accuracy: 0.30 | loss: 0.60
update:1040/2000, 耗时:0.00分/2.33分 | step: 41600 | performance: 3.5 | accuracy: 0.30 | loss: 0.61
update:1045/2000, 耗时:0.00分/2.34分 | step: 41800 | performance: 3.0 | accuracy: 0.30 | loss: 0.68
update:1050/2000, 耗时:0.00分/2.35分 | step: 42000 | performance: 3.5 | accuracy: 0.30 | loss: 1.09
update:1055/2000, 耗时:0.00分/2.36分 | step: 42200 | performance: 3.2 | accuracy: 0.30 | loss: 0.41
update:1060/2000, 耗时:0.00分/2.37分 | step: 42400 | performance: 3.5 | accuracy: 0.31 | loss: 0.73
update:1065/2000, 耗时:0.00分/2.38分 | step: 42600 | performance: 3.6 | accuracy: 0.31 | loss: 0.55
update:1070/2000, 耗时:0.00分/2.39分 | step: 42800 | performance: 4.1 | accuracy: 0.32 | loss: 1.23
update:1075/2000, 耗时:0.00分/2.40分 | step: 43000 | performance: 4.0 | accuracy: 0.32 | loss: 1.34
update:1080/2000, 耗时:0.00分/2.41分 | step: 43200 | performance: 12.4 | accuracy: 0.34 | loss: 1.13
update:1085/2000, 耗时:0.00分/2.42分 | step: 43400 | performance: 19.1 | accuracy: 0.35 | loss: 0.94
update:1090/2000, 耗时:0.00分/2.43分 | step: 43600 | performance: 13.8 | accuracy: 0.34 | loss: 0.80
update:1095/2000, 耗时:0.00分/2.44分 | step: 43800 | performance: 13.0 | accuracy: 0.34 | loss: 1.02
update:1100/2000, 耗时:0.00分/2.45分 | step: 44000 | performance: 15.2 | accuracy: 0.34 | loss: 0.50
update:1105/2000, 耗时:0.00分/2.46分 | step: 44200 | performance: 15.5 | accuracy: 0.34 | loss: 0.38
update:1110/2000, 耗时:0.00分/2.47分 | step: 44400 | performance: 16.2 | accuracy: 0.34 | loss: 0.09
update:1115/2000, 耗时:0.00分/2.48分 | step: 44600 | performance: 18.2 | accuracy: 0.34 | loss: 0.09
update:1120/2000, 耗时:0.00分/2.49分 | step: 44800 | performance: 19.2 | accuracy: 0.33 | loss: 0.50
update:1125/2000, 耗时:0.00分/2.50分 | step: 45000 | performance: 20.6 | accuracy: 0.34 | loss: 0.95
update:1130/2000, 耗时:0.00分/2.51分 | step: 45200 | performance: 22.0 | accuracy: 0.34 | loss: 1.17
update:1135/2000, 耗时:0.00分/2.52分 | step: 45400 | performance: 39.7 | accuracy: 0.35 | loss: 1.36
update:1140/2000, 耗时:0.00分/2.53分 | step: 45600 | performance: 48.1 | accuracy: 0.36 | loss: 1.03
update:1145/2000, 耗时:0.00分/2.54分 | step: 45800 | performance: 60.4 | accuracy: 0.36 | loss: 0.76
update:1150/2000, 耗时:0.00分/2.55分 | step: 46000 | performance: 150.1 | accuracy: 0.37 | loss: 1.50
update:1155/2000, 耗时:0.00分/2.56分 | step: 46200 | performance: 156.6 | accuracy: 0.38 | loss: 1.54
update:1160/2000, 耗时:0.00分/2.57分 | step: 46400 | performance: 133.9 | accuracy: 0.38 | loss: 1.14
update:1165/2000, 耗时:0.00分/2.58分 | step: 46600 | performance: 468.2 | accuracy: 0.39 | loss: 1.31
update:1170/2000, 耗时:0.00分/2.59分 | step: 46800 | performance: 442.9 | accuracy: 0.39 | loss: 1.19
update:1175/2000, 耗时:0.00分/2.60分 | step: 47000 | performance: 314.9 | accuracy: 0.39 | loss: 1.90
update:1180/2000, 耗时:0.00分/2.61分 | step: 47200 | performance: 268.5 | accuracy: 0.39 | loss: 1.17
update:1185/2000, 耗时:0.00分/2.62分 | step: 47400 | performance: 253.2 | accuracy: 0.39 | loss: 0.45
update:1190/2000, 耗时:0.00分/2.63分 | step: 47600 | performance: 233.4 | accuracy: 0.39 | loss: 0.36
update:1195/2000, 耗时:0.00分/2.64分 | step: 47800 | performance: 244.2 | accuracy: 0.39 | loss: 0.63
update:1200/2000, 耗时:0.00分/2.65分 | step: 48000 | performance: 254.5 | accuracy: 0.39 | loss: 0.70
update:1205/2000, 耗时:0.00分/2.66分 | step: 48200 | performance: 316.0 | accuracy: 0.39 | loss: 0.99
update:1210/2000, 耗时:0.00分/2.68分 | step: 48400 | performance: 317.3 | accuracy: 0.39 | loss: 0.49
update:1215/2000, 耗时:0.00分/2.69分 | step: 48600 | performance: 236.5 | accuracy: 0.39 | loss: 0.58
update:1220/2000, 耗时:0.00分/2.70分 | step: 48800 | performance: 253.9 | accuracy: 0.39 | loss: 0.83
update:1225/2000, 耗时:0.00分/2.71分 | step: 49000 | performance: 467.6 | accuracy: 0.40 | loss: 1.10
update:1230/2000, 耗时:0.00分/2.72分 | step: 49200 | performance: 456.4 | accuracy: 0.40 | loss: 2.02
update:1235/2000, 耗时:0.00分/2.73分 | step: 49400 | performance: 486.9 | accuracy: 0.40 | loss: 1.30
update:1240/2000, 耗时:0.00分/2.74分 | step: 49600 | performance: 422.5 | accuracy: 0.40 | loss: 0.55
update:1245/2000, 耗时:0.00分/2.75分 | step: 49800 | performance: 348.4 | accuracy: 0.40 | loss: 0.48
update:1250/2000, 耗时:0.00分/2.76分 | step: 50000 | performance: 369.4 | accuracy: 0.39 | loss: 0.30
update:1255/2000, 耗时:0.00分/2.77分 | step: 50200 | performance: 314.5 | accuracy: 0.39 | loss: 0.06
update:1260/2000, 耗时:0.00分/2.78分 | step: 50400 | performance: 304.2 | accuracy: 0.38 | loss: 0.02
update:1265/2000, 耗时:0.00分/2.79分 | step: 50600 | performance: 304.2 | accuracy: 0.38 | loss: 0.00
update:1270/2000, 耗时:0.00分/2.80分 | step: 50800 | performance: 304.2 | accuracy: 0.37 | loss: 0.02
update:1275/2000, 耗时:0.00分/2.81分 | step: 51000 | performance: 304.2 | accuracy: 0.36 | loss: 0.01
update:1280/2000, 耗时:0.00分/2.82分 | step: 51200 | performance: 292.8 | accuracy: 0.36 | loss: 0.04
update:1285/2000, 耗时:0.00分/2.83分 | step: 51400 | performance: 292.8 | accuracy: 0.36 | loss: 0.03
update:1290/2000, 耗时:0.00分/2.84分 | step: 51600 | performance: 292.8 | accuracy: 0.35 | loss: 0.05
update:1295/2000, 耗时:0.00分/2.85分 | step: 51800 | performance: 292.8 | accuracy: 0.35 | loss: 0.04
update:1300/2000, 耗时:0.00分/2.86分 | step: 52000 | performance: 292.8 | accuracy: 0.34 | loss: 0.01
update:1305/2000, 耗时:0.00分/2.87分 | step: 52200 | performance: 292.8 | accuracy: 0.34 | loss: 0.00
update:1310/2000, 耗时:0.00分/2.88分 | step: 52400 | performance: 292.8 | accuracy: 0.33 | loss: 0.02
update:1315/2000, 耗时:0.00分/2.89分 | step: 52600 | performance: 292.8 | accuracy: 0.33 | loss: 0.03
update:1320/2000, 耗时:0.00分/2.91分 | step: 52800 | performance: 292.8 | accuracy: 0.32 | loss: 0.05
update:1325/2000, 耗时:0.00分/2.92分 | step: 53000 | performance: 292.8 | accuracy: 0.32 | loss: 0.02
update:1330/2000, 耗时:0.00分/2.93分 | step: 53200 | performance: 292.8 | accuracy: 0.32 | loss: 0.02
update:1335/2000, 耗时:0.00分/2.94分 | step: 53400 | performance: 292.8 | accuracy: 0.32 | loss: 0.07
update:1340/2000, 耗时:0.00分/2.95分 | step: 53600 | performance: 292.8 | accuracy: 0.31 | loss: 0.04
update:1345/2000, 耗时:0.00分/2.96分 | step: 53800 | performance: 292.8 | accuracy: 0.31 | loss: 0.02
update:1350/2000, 耗时:0.00分/2.97分 | step: 54000 | performance: 292.8 | accuracy: 0.31 | loss: 0.00
update:1355/2000, 耗时:0.00分/2.98分 | step: 54200 | performance: 292.8 | accuracy: 0.30 | loss: 0.00
update:1360/2000, 耗时:0.00分/2.99分 | step: 54400 | performance: 292.8 | accuracy: 0.30 | loss: 0.00
update:1365/2000, 耗时:0.00分/3.00分 | step: 54600 | performance: 292.8 | accuracy: 0.30 | loss: 0.00
update:1370/2000, 耗时:0.00分/3.01分 | step: 54800 | performance: 292.8 | accuracy: 0.29 | loss: 0.00
update:1375/2000, 耗时:0.00分/3.02分 | step: 55000 | performance: 292.8 | accuracy: 0.29 | loss: 0.00
update:1380/2000, 耗时:0.00分/3.03分 | step: 55200 | performance: 292.8 | accuracy: 0.29 | loss: 0.00
update:1385/2000, 耗时:0.00分/3.04分 | step: 55400 | performance: 292.8 | accuracy: 0.28 | loss: 0.00
update:1390/2000, 耗时:0.00分/3.05分 | step: 55600 | performance: 292.8 | accuracy: 0.28 | loss: 0.03
update:1395/2000, 耗时:0.00分/3.06分 | step: 55800 | performance: 292.8 | accuracy: 0.28 | loss: 0.00
update:1400/2000, 耗时:0.00分/3.07分 | step: 56000 | performance: 292.8 | accuracy: 0.27 | loss: 0.00
update:1405/2000, 耗时:0.00分/3.08分 | step: 56200 | performance: 292.8 | accuracy: 0.27 | loss: 0.00
update:1410/2000, 耗时:0.00分/3.09分 | step: 56400 | performance: 292.8 | accuracy: 0.27 | loss: 0.00
update:1415/2000, 耗时:0.00分/3.10分 | step: 56600 | performance: 292.8 | accuracy: 0.27 | loss: 0.02
update:1420/2000, 耗时:0.00分/3.11分 | step: 56800 | performance: 292.8 | accuracy: 0.26 | loss: 0.00
update:1425/2000, 耗时:0.00分/3.12分 | step: 57000 | performance: 292.8 | accuracy: 0.26 | loss: 0.10
update:1430/2000, 耗时:0.00分/3.13分 | step: 57200 | performance: 292.8 | accuracy: 0.26 | loss: 0.00
update:1435/2000, 耗时:0.00分/3.15分 | step: 57400 | performance: 292.8 | accuracy: 0.26 | loss: 0.00
update:1440/2000, 耗时:0.00分/3.16分 | step: 57600 | performance: 292.8 | accuracy: 0.25 | loss: 0.00
update:1445/2000, 耗时:0.00分/3.17分 | step: 57800 | performance: 292.8 | accuracy: 0.25 | loss: 0.03
update:1450/2000, 耗时:0.00分/3.18分 | step: 58000 | performance: 293.7 | accuracy: 0.25 | loss: 0.66
update:1455/2000, 耗时:0.00分/3.19分 | step: 58200 | performance: 257.7 | accuracy: 0.25 | loss: 0.29
update:1460/2000, 耗时:0.00分/3.20分 | step: 58400 | performance: 361.5 | accuracy: 0.25 | loss: 0.60
update:1465/2000, 耗时:0.00分/3.21分 | step: 58600 | performance: 405.7 | accuracy: 0.25 | loss: 0.13
update:1470/2000, 耗时:0.00分/3.22分 | step: 58800 | performance: 515.7 | accuracy: 0.25 | loss: 0.34
update:1475/2000, 耗时:0.00分/3.23分 | step: 59000 | performance: 452.3 | accuracy: 0.25 | loss: 0.17
update:1480/2000, 耗时:0.00分/3.24分 | step: 59200 | performance: 456.4 | accuracy: 0.25 | loss: 0.07
update:1485/2000, 耗时:0.00分/3.25分 | step: 59400 | performance: 499.0 | accuracy: 0.25 | loss: 0.02
update:1490/2000, 耗时:0.00分/3.26分 | step: 59600 | performance: 485.9 | accuracy: 0.25 | loss: 0.28
update:1495/2000, 耗时:0.00分/3.27分 | step: 59800 | performance: 468.8 | accuracy: 0.24 | loss: 0.24
update:1500/2000, 耗时:0.00分/3.28分 | step: 60000 | performance: 475.5 | accuracy: 0.24 | loss: 0.20
update:1505/2000, 耗时:0.00分/3.29分 | step: 60200 | performance: 438.5 | accuracy: 0.24 | loss: 0.27
update:1510/2000, 耗时:0.00分/3.30分 | step: 60400 | performance: 494.0 | accuracy: 0.24 | loss: 0.45
update:1515/2000, 耗时:0.00分/3.31分 | step: 60600 | performance: 452.7 | accuracy: 0.24 | loss: 0.27
update:1520/2000, 耗时:0.00分/3.32分 | step: 60800 | performance: 497.0 | accuracy: 0.24 | loss: 0.34
update:1525/2000, 耗时:0.00分/3.33分 | step: 61000 | performance: 533.3 | accuracy: 0.24 | loss: 0.39
update:1530/2000, 耗时:0.00分/3.35分 | step: 61200 | performance: 441.5 | accuracy: 0.24 | loss: 0.27
update:1535/2000, 耗时:0.00分/3.36分 | step: 61400 | performance: 536.2 | accuracy: 0.25 | loss: 0.78
update:1540/2000, 耗时:0.00分/3.37分 | step: 61600 | performance: 599.8 | accuracy: 0.25 | loss: 0.43
update:1545/2000, 耗时:0.00分/3.38分 | step: 61800 | performance: 706.2 | accuracy: 0.25 | loss: 1.06
update:1550/2000, 耗时:0.00分/3.39分 | step: 62000 | performance: 518.6 | accuracy: 0.25 | loss: 1.13
update:1555/2000, 耗时:0.00分/3.40分 | step: 62200 | performance: 717.8 | accuracy: 0.25 | loss: 0.55
update:1560/2000, 耗时:0.00分/3.41分 | step: 62400 | performance: 750.8 | accuracy: 0.25 | loss: 0.29
update:1565/2000, 耗时:0.00分/3.42分 | step: 62600 | performance: 704.8 | accuracy: 0.25 | loss: 0.49
update:1570/2000, 耗时:0.00分/3.43分 | step: 62800 | performance: 605.9 | accuracy: 0.25 | loss: 0.88
update:1575/2000, 耗时:0.00分/3.44分 | step: 63000 | performance: 918.0 | accuracy: 0.25 | loss: 0.68
update:1580/2000, 耗时:0.00分/3.45分 | step: 63200 | performance: 1021.2 | accuracy: 0.25 | loss: 0.90
update:1585/2000, 耗时:0.00分/3.46分 | step: 63400 | performance: 2098.2 | accuracy: 0.26 | loss: 1.56
update:1590/2000, 耗时:0.00分/3.47分 | step: 63600 | performance: 2282.5 | accuracy: 0.26 | loss: 1.19
update:1595/2000, 耗时:0.00分/3.49分 | step: 63800 | performance: 2284.6 | accuracy: 0.26 | loss: 2.26
update:1600/2000, 耗时:0.00分/3.50分 | step: 64000 | performance: 6166.8 | accuracy: 0.26 | loss: 1.44
update:1605/2000, 耗时:0.00分/3.51分 | step: 64200 | performance: 6815.0 | accuracy: 0.27 | loss: 1.72
update:1610/2000, 耗时:0.00分/3.52分 | step: 64400 | performance: 7062.3 | accuracy: 0.27 | loss: 1.25
update:1615/2000, 耗时:0.00分/3.53分 | step: 64600 | performance: 5200.1 | accuracy: 0.27 | loss: 1.04
update:1620/2000, 耗时:0.00分/3.54分 | step: 64800 | performance: 4596.2 | accuracy: 0.27 | loss: 0.95
update:1625/2000, 耗时:0.00分/3.55分 | step: 65000 | performance: 5564.8 | accuracy: 0.27 | loss: 1.15
update:1630/2000, 耗时:0.00分/3.56分 | step: 65200 | performance: 7240.3 | accuracy: 0.27 | loss: 0.99
update:1635/2000, 耗时:0.00分/3.57分 | step: 65400 | performance: 5963.9 | accuracy: 0.28 | loss: 1.05
update:1640/2000, 耗时:0.00分/3.58分 | step: 65600 | performance: 8980.1 | accuracy: 0.28 | loss: 0.79
update:1645/2000, 耗时:0.00分/3.59分 | step: 65800 | performance: 8435.3 | accuracy: 0.28 | loss: 1.48
update:1650/2000, 耗时:0.00分/3.60分 | step: 66000 | performance: 9246.8 | accuracy: 0.28 | loss: 1.67
update:1655/2000, 耗时:0.00分/3.61分 | step: 66200 | performance: 7788.6 | accuracy: 0.28 | loss: 1.20
update:1660/2000, 耗时:0.00分/3.62分 | step: 66400 | performance: 14426.6 | accuracy: 0.29 | loss: 0.92
step: 66476 | worker_3@n_step_4: average total_reward after train data exhaustion : 8.0 | max total_reward: 289.5
update:1665/2000, 耗时:0.00分/3.63分 | step: 66600 | performance: 15441.5 | accuracy: 0.29 | loss: 0.97
update:1670/2000, 耗时:0.00分/3.64分 | step: 66800 | performance: 13973.0 | accuracy: 0.29 | loss: 1.06
Saving PPO weights in both H5 format and checkpoint @ update:1672 
Saving PPO weights in both H5 format and checkpoint @ update:1674 
update:1675/2000, 耗时:0.00分/3.67分 | step: 67000 | performance: 15247.3 | accuracy: 0.29 | loss: 1.20
update:1680/2000, 耗时:0.00分/3.68分 | step: 67200 | performance: 0.9 | accuracy: 0.25 | loss: 1.88
Saving PPO weights in both H5 format and checkpoint @ update:1680 
update:1685/2000, 耗时:0.00分/3.69分 | step: 67400 | performance: 0.9 | accuracy: 0.48 | loss: 1.67
update:1690/2000, 耗时:0.00分/3.70分 | step: 67600 | performance: 1.9 | accuracy: 0.50 | loss: 1.67
update:1695/2000, 耗时:0.00分/3.71分 | step: 67800 | performance: 4.1 | accuracy: 0.56 | loss: 1.59
update:1700/2000, 耗时:0.00分/3.72分 | step: 68000 | performance: 3.1 | accuracy: 0.50 | loss: 2.26
update:1705/2000, 耗时:0.00分/3.73分 | step: 68200 | performance: 2.6 | accuracy: 0.50 | loss: 2.00
update:1710/2000, 耗时:0.00分/3.74分 | step: 68400 | performance: 4.1 | accuracy: 0.49 | loss: 1.36
update:1715/2000, 耗时:0.00分/3.75分 | step: 68600 | performance: 5.5 | accuracy: 0.50 | loss: 1.60
update:1720/2000, 耗时:0.00分/3.76分 | step: 68800 | performance: 10.6 | accuracy: 0.51 | loss: 0.95
update:1725/2000, 耗时:0.00分/3.77分 | step: 69000 | performance: 5.6 | accuracy: 0.48 | loss: 1.08
update:1730/2000, 耗时:0.00分/3.78分 | step: 69200 | performance: 4.0 | accuracy: 0.46 | loss: 1.22
update:1735/2000, 耗时:0.00分/3.79分 | step: 69400 | performance: 5.0 | accuracy: 0.47 | loss: 1.00
update:1740/2000, 耗时:0.00分/3.80分 | step: 69600 | performance: 7.7 | accuracy: 0.48 | loss: 1.39
update:1745/2000, 耗时:0.00分/3.81分 | step: 69800 | performance: 7.1 | accuracy: 0.48 | loss: 1.61
update:1750/2000, 耗时:0.00分/3.82分 | step: 70000 | performance: 10.5 | accuracy: 0.49 | loss: 1.16
update:1755/2000, 耗时:0.00分/3.83分 | step: 70200 | performance: 12.1 | accuracy: 0.49 | loss: 1.60
update:1760/2000, 耗时:0.00分/3.84分 | step: 70400 | performance: 12.3 | accuracy: 0.49 | loss: 0.95
update:1765/2000, 耗时:0.00分/3.86分 | step: 70600 | performance: 6.6 | accuracy: 0.48 | loss: 0.90
update:1770/2000, 耗时:0.00分/3.87分 | step: 70800 | performance: 14.4 | accuracy: 0.50 | loss: 1.53
update:1775/2000, 耗时:0.00分/3.88分 | step: 71000 | performance: 14.2 | accuracy: 0.50 | loss: 1.20
update:1780/2000, 耗时:0.00分/3.89分 | step: 71200 | performance: 10.5 | accuracy: 0.48 | loss: 0.91
update:1785/2000, 耗时:0.00分/3.90分 | step: 71400 | performance: 15.5 | accuracy: 0.49 | loss: 0.85
update:1790/2000, 耗时:0.00分/3.91分 | step: 71600 | performance: 15.1 | accuracy: 0.49 | loss: 0.94
update:1795/2000, 耗时:0.00分/3.92分 | step: 71800 | performance: 18.0 | accuracy: 0.49 | loss: 0.92
update:1800/2000, 耗时:0.00分/3.93分 | step: 72000 | performance: 16.1 | accuracy: 0.49 | loss: 1.08
update:1805/2000, 耗时:0.00分/3.94分 | step: 72200 | performance: 17.4 | accuracy: 0.49 | loss: 1.55
update:1810/2000, 耗时:0.00分/3.95分 | step: 72400 | performance: 26.8 | accuracy: 0.50 | loss: 1.07
update:1815/2000, 耗时:0.00分/3.96分 | step: 72600 | performance: 68.5 | accuracy: 0.50 | loss: 1.58
update:1820/2000, 耗时:0.00分/3.97分 | step: 72800 | performance: 124.0 | accuracy: 0.51 | loss: 1.18
update:1825/2000, 耗时:0.00分/3.98分 | step: 73000 | performance: 93.9 | accuracy: 0.50 | loss: 1.52
update:1830/2000, 耗时:0.00分/3.99分 | step: 73200 | performance: 79.6 | accuracy: 0.50 | loss: 1.06
update:1835/2000, 耗时:0.00分/4.00分 | step: 73400 | performance: 106.1 | accuracy: 0.50 | loss: 0.82
update:1840/2000, 耗时:0.00分/4.01分 | step: 73600 | performance: 128.3 | accuracy: 0.50 | loss: 1.28
update:1845/2000, 耗时:0.00分/4.02分 | step: 73800 | performance: 115.7 | accuracy: 0.50 | loss: 0.79
update:1850/2000, 耗时:0.00分/4.03分 | step: 74000 | performance: 99.8 | accuracy: 0.49 | loss: 1.00
update:1855/2000, 耗时:0.00分/4.04分 | step: 74200 | performance: 96.0 | accuracy: 0.49 | loss: 1.22
update:1860/2000, 耗时:0.00分/4.05分 | step: 74400 | performance: 91.2 | accuracy: 0.48 | loss: 1.07
update:1865/2000, 耗时:0.00分/4.06分 | step: 74600 | performance: 49.2 | accuracy: 0.48 | loss: 1.81
update:1870/2000, 耗时:0.00分/4.07分 | step: 74800 | performance: 43.6 | accuracy: 0.47 | loss: 1.74
update:1875/2000, 耗时:0.00分/4.08分 | step: 75000 | performance: 43.0 | accuracy: 0.47 | loss: 1.28
update:1880/2000, 耗时:0.00分/4.09分 | step: 75200 | performance: 18.2 | accuracy: 0.47 | loss: 1.05
update:1885/2000, 耗时:0.00分/4.10分 | step: 75400 | performance: 12.9 | accuracy: 0.46 | loss: 1.57
update:1890/2000, 耗时:0.00分/4.11分 | step: 75600 | performance: 14.3 | accuracy: 0.46 | loss: 2.33
update:1895/2000, 耗时:0.00分/4.12分 | step: 75800 | performance: 9.1 | accuracy: 0.46 | loss: 2.08
update:1900/2000, 耗时:0.00分/4.13分 | step: 76000 | performance: 5.6 | accuracy: 0.46 | loss: 1.59
update:1905/2000, 耗时:0.00分/4.14分 | step: 76200 | performance: 5.3 | accuracy: 0.46 | loss: 1.02
update:1910/2000, 耗时:0.00分/4.15分 | step: 76400 | performance: 7.9 | accuracy: 0.46 | loss: 1.25
update:1915/2000, 耗时:0.00分/4.16分 | step: 76600 | performance: 4.6 | accuracy: 0.45 | loss: 1.02
update:1920/2000, 耗时:0.00分/4.18分 | step: 76800 | performance: 6.2 | accuracy: 0.45 | loss: 1.24
update:1925/2000, 耗时:0.00分/4.19分 | step: 77000 | performance: 8.8 | accuracy: 0.46 | loss: 0.99
update:1930/2000, 耗时:0.00分/4.20分 | step: 77200 | performance: 7.5 | accuracy: 0.46 | loss: 1.67
update:1935/2000, 耗时:0.00分/4.21分 | step: 77400 | performance: 15.7 | accuracy: 0.46 | loss: 1.33
update:1940/2000, 耗时:0.00分/4.22分 | step: 77600 | performance: 15.2 | accuracy: 0.47 | loss: 1.41
update:1945/2000, 耗时:0.00分/4.23分 | step: 77800 | performance: 15.9 | accuracy: 0.47 | loss: 1.30
update:1950/2000, 耗时:0.00分/4.24分 | step: 78000 | performance: 11.7 | accuracy: 0.47 | loss: 1.43
update:1955/2000, 耗时:0.00分/4.25分 | step: 78200 | performance: 15.1 | accuracy: 0.47 | loss: 1.23
update:1960/2000, 耗时:0.00分/4.26分 | step: 78400 | performance: 23.0 | accuracy: 0.47 | loss: 1.19
update:1965/2000, 耗时:0.00分/4.27分 | step: 78600 | performance: 25.7 | accuracy: 0.47 | loss: 1.44
update:1970/2000, 耗时:0.00分/4.28分 | step: 78800 | performance: 24.3 | accuracy: 0.47 | loss: 1.45
update:1975/2000, 耗时:0.00分/4.29分 | step: 79000 | performance: 25.8 | accuracy: 0.48 | loss: 1.56
update:1980/2000, 耗时:0.00分/4.30分 | step: 79200 | performance: 15.3 | accuracy: 0.47 | loss: 1.45
update:1985/2000, 耗时:0.00分/4.31分 | step: 79400 | performance: 13.5 | accuracy: 0.47 | loss: 2.14
update:1990/2000, 耗时:0.00分/4.32分 | step: 79600 | performance: 11.3 | accuracy: 0.47 | loss: 1.72
update:1995/2000, 耗时:0.00分/4.33分 | step: 79800 | performance: 11.9 | accuracy: 0.47 | loss: 1.60
  0%|          | 0/408 [00:00<?, ?it/s]100%|| 408/408 [00:00<00:00, 102220.66it/s]
update:2000/2000, 耗时:0.00分/4.34分 | step: 80000 | performance: 15.9 | accuracy: 0.47 | loss: 1.07
----------------------------------------finished----------------------------------------
==================================================
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1000.00
2023-07-24T12:00:00 | net performance [%] = 0.0000
2023-07-24T12:00:00 | number of trades [#] = 0
==================================================
Trial 21 Complete [00h 04m 47s]
net_wealth: 1000.0

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 02h 44m 13s

Search: Running Trial #22

Value             |Best Value So Far |Hyperparameter
4                 |1                 |horizon
225               |730               |lookback
True              |False             |MarketFactor
14                |3                 |lags
0.98              |0.92              |gamma
16                |32                |batch_size
64                |1                 |n_step
0.99              |0.94              |gae_lambda
1                 |5                 |gradient_clip_norm
3                 |5                 |epochs
0.0001            |0.0001            |actor_lr
0.001             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4297.000000   4301.000000
mean      0.000435    20113.607657  ...   20184.134484  20169.373185
std       0.027833    16040.642334  ...   16078.780856  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7747.959961   7730.930176
50%       0.000642    11571.842969  ...   11755.309570  11751.469727
75%       0.011590    29894.706152  ...   30016.300781  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 00:47:362023-07-28 00:47:36.2023-07-28 00:47:36.413361: I tensorflow/core/platform/cpu_feature_guard.c.c:44142]2113338:023-07 I tensorflow/core/platform/cpu_featu20re2_-3g-07-2u2302 8 302T0ha8235: is T ensoI0-0 te0rd:7-2:47:3.crc8 0Flo:ns6or.flow4/0113c:442or417e]/ :3Tp2l6ha: Ii.tw4  tbeinn13s33orf9o:f lIo wtear/crom/syr nscpuor4_featue /Tfre_plguileos own/atform/cpu_pasfteaticro7d:.c3cmi2ur60.2z413441:edo  wIir:3e/t -p0th1 oeln7e-Aan4P2tforI Dso2]8 rm/2ee0p N Thic20es 0r:3Fl-oTe0477fe:wpluo_w/u3r_ngsfoeaaurcl  N6t.orF4l1e3o7taeworrwd u/rpelbbiinkar yL9i0b_g-ra:r uIn.aara ytcrc dt.i:y1 4(so e2 nicnoescs:o1 pot]iD mTNfr4fhoir2p]tizNi Tlho2wedm/) tms /Teocn cwor8is or ussei tieFzph/l0eu_ f Totdehapolatef otr efnnoml/ueAw slocror0bpFileu_wguo:_wfiieaatt4hn7wu r d.occnreg: bCinnar:1aer_yg 4P23uiasPUI 6r]. yT hdA.  oiissc T4PipetnismoicI D:e14 12repFnlowz3stD]er 8 b6in3 eepN :Tu haIceNre y ituirs tiuoenonraslT apstieonssN rd lwmo in NizertFloed pwtoiwm ipteh rfi woitrzobniheftek Libr Aneod rwPlwaorrmiIt yoaryh  i Doanneswoce(ok  /eenoepDcANoN)Li-bPr It nacrtyirDoeee/ peuAr ilticP(pa tsIe  DeNethme ipfal oz Nfoooeldlonreu rme/wcwpiDperuarnegN aluCPi_lNf)U Ne twpo  tthor N eoek ausNieauttw oer tLurnkiitbhrearns ofnoe trryuslel_ L(aAcPgilo NneuIoawirnbtdiDoNgN :.) Dteeepra otwo rkC LinNse uirna ur lb rPUp erys a(f oN AoVXrnreetweyi mnaso r ntchee(DANVNkocnte) -tcor i DrNuNucsec tt i:thXe2 )fo1i
c Tnoo4llf oewLotlslnowini2al] o iaob ginblues tenr   gp eCT thCPPhUU  iineshapertforrummrae f oin ocalrlyttntsohieonrsitwriu s:ngc tio o p(o nT eAVCiPnUo Xi nns eADesrianVsnos Xin nt itopreu2pNecctn
rTfoes-rorNcf,o m)rr eebia utilitrnmdoonarn aTbeF sl cieninlc-scnucsea-creolr Foloowe i tw  bri npewaitpiettrheymirtr foiai hi nrst iotohcacalh eo npemta spfeolln irm ia:o opppraoptrcetzii eoantledAse-h :c re oo mcpwiwiarr oAptnVliierteVgXo  AXi calf oVp nsCePrUAr ViXlXa2igsatns:t
ti o nA2aTtsr:u V
XoT oe enahbi oAnn.a
bctli  lee  AtVXoVheXo theAmnmnVe AisPs  iiI,n r nD2X
Teo ontb ee 2e
 pou TtohhNenaei prl d ublre aenabeTrelt ooppeerrataehriefle ttmn s inNooo iootnher nreFostsw,orpker  rLlhoaw t, writeem iirmanobnhe nthuild TensorFlow with the appropriate compiler fl e approproithast,er ope compe rearabguild TensorFlow with the approprs.
ibrary (oneDNN)btions, rebuuiiate il dtoic le uled Tsencoes r fthem-Toreclags followrp.
nsingFiler flalorFlo oiwt wCiPcaUiwth  wit thil opengst rths.hructi
e appropriate compeatons in performanici apons: plerropriate   flags.
compiler flags.
Ae-cVX AVX2
To eritical operations:  AVX AVX2nable
To e thenable them in other operations, rebuild TensorFlow with thm in oe appropriate compiler flags.
ther operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 00:47:37.016764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:47:37.019902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:47:37.043972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:47:37.051001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory: 2023-07-28  00:47:37.051072: I tenso-> device: 0, name: rflow/core/cNVIDIA GeFommon_runtorce RTX 3i070, pci bus id: 000me/gpu/gpu_dev0:01:00.0, coice.cc:1510] Created device /job:localmpute host/replica:0/tacapabsk:0/device:GPU:0 with 5454 ility:MB memo 8.6
ry:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:47:37.051943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:47:37.081329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 00:47:37.085715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.06分 | step:  2560 | performance: 0.2 | accuracy: 0.25 | loss: 6.13
update: 10/2000, 耗时:0.01分/0.10分 | step:  5120 | performance: 0.1 | accuracy: 0.28 | loss: 5.17
update: 15/2000, 耗时:0.01分/0.15分 | step:  7680 | performance: 0.1 | accuracy: 0.31 | loss: 2.97
update: 20/2000, 耗时:0.01分/0.20分 | step: 10240 | performance: 0.1 | accuracy: 0.30 | loss: 9.65
update: 25/2000, 耗时:0.01分/0.25分 | step: 12800 | performance: 0.1 | accuracy: 0.30 | loss: 5.70
update: 30/2000, 耗时:0.01分/0.30分 | step: 15360 | performance: 0.0 | accuracy: 0.30 | loss: 12.67
update: 35/2000, 耗时:0.01分/0.35分 | step: 17920 | performance: 0.1 | accuracy: 0.30 | loss: 14.78
update: 40/2000, 耗时:0.01分/0.40分 | step: 20480 | performance: 0.1 | accuracy: 0.31 | loss: 13.71
update: 45/2000, 耗时:0.01分/0.45分 | step: 23040 | performance: 0.0 | accuracy: 0.31 | loss: 17.97
update: 50/2000, 耗时:0.01分/0.49分 | step: 25600 | performance: 0.0 | accuracy: 0.32 | loss: 5.07
update: 55/2000, 耗时:0.01分/0.54分 | step: 28160 | performance: 0.0 | accuracy: 0.32 | loss: 5.02
Saving PPO weights in both H5 format and checkpoint @ update:58 
update: 60/2000, 耗时:0.01分/0.60分 | step: 30720 | performance: 1.0 | accuracy: 0.34 | loss: 7.21
update: 65/2000, 耗时:0.01分/0.64分 | step: 33280 | performance: 0.3 | accuracy: 0.34 | loss: 6.04
update: 70/2000, 耗时:0.01分/0.69分 | step: 35840 | performance: 0.3 | accuracy: 0.36 | loss: 8.33
update: 75/2000, 耗时:0.01分/0.74分 | step: 38400 | performance: 0.2 | accuracy: 0.35 | loss: 12.76
update: 80/2000, 耗时:0.01分/0.78分 | step: 40960 | performance: 0.2 | accuracy: 0.36 | loss: 7.11
update: 85/2000, 耗时:0.01分/0.83分 | step: 43520 | performance: 0.1 | accuracy: 0.37 | loss: 5.34
update: 90/2000, 耗时:0.01分/0.88分 | step: 46080 | performance: 0.8 | accuracy: 0.39 | loss: 23.88
update: 95/2000, 耗时:0.01分/0.93分 | step: 48640 | performance: 46.2 | accuracy: 0.41 | loss: 7.61
update:100/2000, 耗时:0.01分/0.97分 | step: 51200 | performance: 35.8 | accuracy: 0.41 | loss: 9.21
update:105/2000, 耗时:0.01分/1.02分 | step: 53760 | performance: 42.6 | accuracy: 0.42 | loss: 6.55
update:110/2000, 耗时:0.01分/1.06分 | step: 56320 | performance: 13.9 | accuracy: 0.41 | loss: 10.96
update:115/2000, 耗时:0.01分/1.11分 | step: 58880 | performance: 0.6 | accuracy: 0.29 | loss: 14.41
Saving PPO weights in both H5 format and checkpoint @ update:115 
update:120/2000, 耗时:0.01分/1.16分 | step: 61440 | performance: 0.6 | accuracy: 0.34 | loss: 7.68
update:125/2000, 耗时:0.01分/1.21分 | step: 64000 | performance: 0.2 | accuracy: 0.33 | loss: 11.65
update:130/2000, 耗时:0.01分/1.26分 | step: 66560 | performance: 1.1 | accuracy: 0.38 | loss: 22.44
update:135/2000, 耗时:0.01分/1.30分 | step: 69120 | performance: 4.5 | accuracy: 0.39 | loss: 6.40
update:140/2000, 耗时:0.01分/1.35分 | step: 71680 | performance: 1.9 | accuracy: 0.39 | loss: 14.68
update:145/2000, 耗时:0.01分/1.40分 | step: 74240 | performance: 2.1 | accuracy: 0.40 | loss: 6.75
update:150/2000, 耗时:0.01分/1.45分 | step: 76800 | performance: 202.9 | accuracy: 0.42 | loss: 73.42
update:155/2000, 耗时:0.01分/1.50分 | step: 79360 | performance: 26.2 | accuracy: 0.42 | loss: 16.83
update:160/2000, 耗时:0.01分/1.54分 | step: 81920 | performance: 36.2 | accuracy: 0.42 | loss: 8.12
update:165/2000, 耗时:0.01分/1.59分 | step: 84480 | performance: 3.6 | accuracy: 0.42 | loss: 16.26
update:170/2000, 耗时:0.01分/1.64分 | step: 87040 | performance: 3.0 | accuracy: 0.41 | loss: 5.54
Saving PPO weights in both H5 format and checkpoint @ update:172 
update:175/2000, 耗时:0.01分/1.69分 | step: 89600 | performance: 0.2 | accuracy: 0.35 | loss: 26.45
update:180/2000, 耗时:0.01分/1.74分 | step: 92160 | performance: 0.0 | accuracy: 0.35 | loss: 7.06
update:185/2000, 耗时:0.01分/1.78分 | step: 94720 | performance: 0.1 | accuracy: 0.38 | loss: 5.60
update:190/2000, 耗时:0.01分/1.83分 | step: 97280 | performance: 1.4 | accuracy: 0.42 | loss: 11.77
update:195/2000, 耗时:0.01分/1.88分 | step: 99840 | performance: 1.0 | accuracy: 0.41 | loss: 12.91
update:200/2000, 耗时:0.01分/1.93分 | step: 102400 | performance: 0.3 | accuracy: 0.42 | loss: 8.96
update:205/2000, 耗时:0.01分/1.97分 | step: 104960 | performance: 2.3 | accuracy: 0.43 | loss: 12.34
update:210/2000, 耗时:0.01分/2.02分 | step: 107520 | performance: 19.6 | accuracy: 0.45 | loss: 51.69
update:215/2000, 耗时:0.01分/2.07分 | step: 110080 | performance: 34.0 | accuracy: 0.45 | loss: 29.58
update:220/2000, 耗时:0.01分/2.11分 | step: 112640 | performance: 7.6 | accuracy: 0.45 | loss: 14.42
update:225/2000, 耗时:0.01分/2.16分 | step: 115200 | performance: 3.2 | accuracy: 0.44 | loss: 9.18
Saving PPO weights in both H5 format and checkpoint @ update:229 
update:230/2000, 耗时:0.01分/2.21分 | step: 117760 | performance: 0.4 | accuracy: 0.38 | loss: 17.20
update:235/2000, 耗时:0.01分/2.26分 | step: 120320 | performance: 0.1 | accuracy: 0.40 | loss: 7.95
update:240/2000, 耗时:0.01分/2.31分 | step: 122880 | performance: 0.0 | accuracy: 0.39 | loss: 11.72
update:245/2000, 耗时:0.01分/2.36分 | step: 125440 | performance: 0.1 | accuracy: 0.41 | loss: 15.23
update:250/2000, 耗时:0.01分/2.41分 | step: 128000 | performance: 0.1 | accuracy: 0.41 | loss: 10.03
update:255/2000, 耗时:0.01分/2.46分 | step: 130560 | performance: 0.1 | accuracy: 0.40 | loss: 13.80
update:260/2000, 耗时:0.01分/2.51分 | step: 133120 | performance: 0.0 | accuracy: 0.40 | loss: 7.73
update:265/2000, 耗时:0.01分/2.56分 | step: 135680 | performance: 7.1 | accuracy: 0.42 | loss: 20.87
update:270/2000, 耗时:0.01分/2.61分 | step: 138240 | performance: 8.1 | accuracy: 0.42 | loss: 11.77
update:275/2000, 耗时:0.01分/2.66分 | step: 140800 | performance: 2.0 | accuracy: 0.43 | loss: 17.92
update:280/2000, 耗时:0.01分/2.70分 | step: 143360 | performance: 0.2 | accuracy: 0.42 | loss: 13.89
update:285/2000, 耗时:0.01分/2.76分 | step: 145920 | performance: 0.2 | accuracy: 0.42 | loss: 6.99
Saving PPO weights in both H5 format and checkpoint @ update:286 
update:290/2000, 耗时:0.01分/2.81分 | step: 148480 | performance: 0.1 | accuracy: 0.38 | loss: 21.69
update:295/2000, 耗时:0.01分/2.86分 | step: 151040 | performance: 0.1 | accuracy: 0.42 | loss: 12.55
update:300/2000, 耗时:0.01分/2.91分 | step: 153600 | performance: 0.0 | accuracy: 0.42 | loss: 43.14
update:305/2000, 耗时:0.01分/2.95分 | step: 156160 | performance: 0.3 | accuracy: 0.44 | loss: 6.43
update:310/2000, 耗时:0.01分/3.00分 | step: 158720 | performance: 0.1 | accuracy: 0.43 | loss: 16.00
update:315/2000, 耗时:0.01分/3.05分 | step: 161280 | performance: 0.2 | accuracy: 0.44 | loss: 27.99
update:320/2000, 耗时:0.01分/3.09分 | step: 163840 | performance: 41.0 | accuracy: 0.47 | loss: 152.66
update:325/2000, 耗时:0.01分/3.14分 | step: 166400 | performance: 17.1 | accuracy: 0.47 | loss: 11.61
update:330/2000, 耗时:0.01分/3.19分 | step: 168960 | performance: 54.8 | accuracy: 0.47 | loss: 23.23
update:335/2000, 耗时:0.01分/3.23分 | step: 171520 | performance: 7.6 | accuracy: 0.46 | loss: 24.90
update:340/2000, 耗时:0.01分/3.28分 | step: 174080 | performance: 1.9 | accuracy: 0.46 | loss: 10.78
Saving PPO weights in both H5 format and checkpoint @ update:343 
update:345/2000, 耗时:0.01分/3.34分 | step: 176640 | performance: 0.3 | accuracy: 0.42 | loss: 11.59
update:350/2000, 耗时:0.01分/3.39分 | step: 179200 | performance: 0.0 | accuracy: 0.42 | loss: 21.05
update:355/2000, 耗时:0.01分/3.43分 | step: 181760 | performance: 0.0 | accuracy: 0.41 | loss: 9.41
update:360/2000, 耗时:0.01分/3.48分 | step: 184320 | performance: 0.8 | accuracy: 0.45 | loss: 32.69
update:365/2000, 耗时:0.01分/3.53分 | step: 186880 | performance: 0.2 | accuracy: 0.44 | loss: 8.11
update:370/2000, 耗时:0.01分/3.57分 | step: 189440 | performance: 0.2 | accuracy: 0.45 | loss: 10.73
update:375/2000, 耗时:0.01分/3.62分 | step: 192000 | performance: 0.4 | accuracy: 0.46 | loss: 46.56
update:380/2000, 耗时:0.01分/3.67分 | step: 194560 | performance: 72.6 | accuracy: 0.48 | loss: 11.89
update:385/2000, 耗时:0.01分/3.72分 | step: 197120 | performance: 13.7 | accuracy: 0.47 | loss: 9.96
update:390/2000, 耗时:0.01分/3.76分 | step: 199680 | performance: 11.3 | accuracy: 0.47 | loss: 12.32
update:395/2000, 耗时:0.01分/3.81分 | step: 202240 | performance: 0.6 | accuracy: 0.45 | loss: 7.24
update:400/2000, 耗时:0.01分/3.85分 | step: 204800 | performance: 1.5 | accuracy: 0.50 | loss: 7.48
Saving PPO weights in both H5 format and checkpoint @ update:400 
update:405/2000, 耗时:0.01分/3.90分 | step: 207360 | performance: 1.1 | accuracy: 0.39 | loss: 8.05
update:410/2000, 耗时:0.01分/3.95分 | step: 209920 | performance: 0.5 | accuracy: 0.40 | loss: 15.93
update:415/2000, 耗时:0.01分/4.00分 | step: 212480 | performance: 0.4 | accuracy: 0.40 | loss: 14.84
update:420/2000, 耗时:0.01分/4.04分 | step: 215040 | performance: 1.0 | accuracy: 0.42 | loss: 11.17
update:425/2000, 耗时:0.01分/4.09分 | step: 217600 | performance: 0.3 | accuracy: 0.41 | loss: 26.69
update:430/2000, 耗时:0.01分/4.13分 | step: 220160 | performance: 0.4 | accuracy: 0.42 | loss: 6.98
update:435/2000, 耗时:0.01分/4.18分 | step: 222720 | performance: 14.7 | accuracy: 0.44 | loss: 14.95
update:440/2000, 耗时:0.01分/4.22分 | step: 225280 | performance: 23.9 | accuracy: 0.44 | loss: 13.92
update:445/2000, 耗时:0.01分/4.27分 | step: 227840 | performance: 142.6 | accuracy: 0.45 | loss: 9.38
update:450/2000, 耗时:0.01分/4.32分 | step: 230400 | performance: 60.8 | accuracy: 0.44 | loss: 14.82
update:455/2000, 耗时:0.01分/4.36分 | step: 232960 | performance: 14.0 | accuracy: 0.44 | loss: 7.46
Saving PPO weights in both H5 format and checkpoint @ update:457 
update:460/2000, 耗时:0.01分/4.41分 | step: 235520 | performance: 0.5 | accuracy: 0.46 | loss: 18.06
update:465/2000, 耗时:0.01分/4.46分 | step: 238080 | performance: 0.2 | accuracy: 0.43 | loss: 14.98
update:470/2000, 耗时:0.01分/4.51分 | step: 240640 | performance: 0.0 | accuracy: 0.42 | loss: 6.72
update:475/2000, 耗时:0.01分/4.55分 | step: 243200 | performance: 0.2 | accuracy: 0.44 | loss: 16.90
update:480/2000, 耗时:0.01分/4.60分 | step: 245760 | performance: 0.1 | accuracy: 0.42 | loss: 13.74
update:485/2000, 耗时:0.01分/4.64分 | step: 248320 | performance: 0.1 | accuracy: 0.42 | loss: 9.70
update:490/2000, 耗时:0.01分/4.69分 | step: 250880 | performance: 0.5 | accuracy: 0.43 | loss: 34.35
update:495/2000, 耗时:0.01分/4.74分 | step: 253440 | performance: 16.6 | accuracy: 0.45 | loss: 13.59
update:500/2000, 耗时:0.01分/4.78分 | step: 256000 | performance: 27.0 | accuracy: 0.45 | loss: 44.88
update:505/2000, 耗时:0.01分/4.83分 | step: 258560 | performance: 11.6 | accuracy: 0.44 | loss: 10.92
update:510/2000, 耗时:0.01分/4.87分 | step: 261120 | performance: 1.6 | accuracy: 0.43 | loss: 11.25
Saving PPO weights in both H5 format and checkpoint @ update:514 
update:515/2000, 耗时:0.01分/4.92分 | step: 263680 | performance: 0.3 | accuracy: 0.36 | loss: 40.25
update:520/2000, 耗时:0.01分/4.97分 | step: 266240 | performance: 0.1 | accuracy: 0.40 | loss: 9.56
update:525/2000, 耗时:0.01分/5.01分 | step: 268800 | performance: 0.0 | accuracy: 0.39 | loss: 15.71
update:530/2000, 耗时:0.01分/5.06分 | step: 271360 | performance: 0.1 | accuracy: 0.41 | loss: 21.68
update:535/2000, 耗时:0.01分/5.11分 | step: 273920 | performance: 0.1 | accuracy: 0.40 | loss: 7.21
update:540/2000, 耗时:0.01分/5.15分 | step: 276480 | performance: 0.1 | accuracy: 0.40 | loss: 12.45
update:545/2000, 耗时:0.01分/5.20分 | step: 279040 | performance: 0.1 | accuracy: 0.41 | loss: 8.34
update:550/2000, 耗时:0.01分/5.24分 | step: 281600 | performance: 19.3 | accuracy: 0.43 | loss: 32.06
update:555/2000, 耗时:0.01分/5.29分 | step: 284160 | performance: 3.1 | accuracy: 0.42 | loss: 21.09
update:560/2000, 耗时:0.01分/5.33分 | step: 286720 | performance: 2.0 | accuracy: 0.42 | loss: 20.84
update:565/2000, 耗时:0.01分/5.38分 | step: 289280 | performance: 0.1 | accuracy: 0.41 | loss: 28.79
update:570/2000, 耗时:0.01分/5.43分 | step: 291840 | performance: 0.1 | accuracy: 0.41 | loss: 6.36
Saving PPO weights in both H5 format and checkpoint @ update:571 
update:575/2000, 耗时:0.01分/5.48分 | step: 294400 | performance: 0.3 | accuracy: 0.39 | loss: 7.00
update:580/2000, 耗时:0.01分/5.52分 | step: 296960 | performance: 0.2 | accuracy: 0.38 | loss: 3.68
update:585/2000, 耗时:0.01分/5.57分 | step: 299520 | performance: 0.2 | accuracy: 0.38 | loss: 4.08
update:590/2000, 耗时:0.01分/5.62分 | step: 302080 | performance: 2.7 | accuracy: 0.40 | loss: 6.93
update:595/2000, 耗时:0.01分/5.66分 | step: 304640 | performance: 5.7 | accuracy: 0.39 | loss: 9.34
update:600/2000, 耗时:0.01分/5.71分 | step: 307200 | performance: 1.2 | accuracy: 0.38 | loss: 4.53
update:605/2000, 耗时:0.01分/5.75分 | step: 309760 | performance: 10.8 | accuracy: 0.40 | loss: 16.10
update:610/2000, 耗时:0.01分/5.80分 | step: 312320 | performance: 91.7 | accuracy: 0.40 | loss: 25.28
update:615/2000, 耗时:0.01分/5.84分 | step: 314880 | performance: 86.0 | accuracy: 0.39 | loss: 5.79
update:620/2000, 耗时:0.01分/5.89分 | step: 317440 | performance: 4.7 | accuracy: 0.38 | loss: 18.85
update:625/2000, 耗时:0.01分/5.93分 | step: 320000 | performance: 9.3 | accuracy: 0.38 | loss: 3.13
Saving PPO weights in both H5 format and checkpoint @ update:629 
update:630/2000, 耗时:0.01分/5.98分 | step: 322560 | performance: 3.2 | accuracy: 0.41 | loss: 13.04
update:635/2000, 耗时:0.01分/6.03分 | step: 325120 | performance: 1.6 | accuracy: 0.34 | loss: 6.00
update:640/2000, 耗时:0.01分/6.08分 | step: 327680 | performance: 1.7 | accuracy: 0.33 | loss: 3.31
update:645/2000, 耗时:0.01分/6.12分 | step: 330240 | performance: 23.7 | accuracy: 0.35 | loss: 16.92
update:650/2000, 耗时:0.01分/6.17分 | step: 332800 | performance: 8.4 | accuracy: 0.35 | loss: 9.33
update:655/2000, 耗时:0.01分/6.21分 | step: 335360 | performance: 20.3 | accuracy: 0.34 | loss: 9.99
update:660/2000, 耗时:0.01分/6.26分 | step: 337920 | performance: 27.2 | accuracy: 0.34 | loss: 8.23
update:665/2000, 耗时:0.01分/6.30分 | step: 340480 | performance: 1247.7 | accuracy: 0.35 | loss: 12.06
update:670/2000, 耗时:0.01分/6.35分 | step: 343040 | performance: 159.4 | accuracy: 0.34 | loss: 3.84
update:675/2000, 耗时:0.01分/6.39分 | step: 345600 | performance: 168.5 | accuracy: 0.34 | loss: 7.15
update:680/2000, 耗时:0.01分/6.44分 | step: 348160 | performance: 26.4 | accuracy: 0.33 | loss: 6.25
update:685/2000, 耗时:0.01分/6.49分 | step: 350720 | performance: 17.2 | accuracy: 0.33 | loss: 4.46
Saving PPO weights in both H5 format and checkpoint @ update:686 
update:690/2000, 耗时:0.01分/6.54分 | step: 353280 | performance: 0.2 | accuracy: 0.27 | loss: 6.31
update:695/2000, 耗时:0.01分/6.58分 | step: 355840 | performance: 0.0 | accuracy: 0.25 | loss: 3.05
update:700/2000, 耗时:0.01分/6.63分 | step: 358400 | performance: 0.0 | accuracy: 0.25 | loss: 18.97
update:705/2000, 耗时:0.01分/6.67分 | step: 360960 | performance: 0.2 | accuracy: 0.28 | loss: 10.42
update:710/2000, 耗时:0.01分/6.72分 | step: 363520 | performance: 0.1 | accuracy: 0.27 | loss: 7.15
update:715/2000, 耗时:0.01分/6.77分 | step: 366080 | performance: 0.0 | accuracy: 0.26 | loss: 11.48
update:720/2000, 耗时:0.01分/6.81分 | step: 368640 | performance: 0.2 | accuracy: 0.27 | loss: 14.87
update:725/2000, 耗时:0.01分/6.86分 | step: 371200 | performance: 0.2 | accuracy: 0.27 | loss: 5.31
update:730/2000, 耗时:0.01分/6.90分 | step: 373760 | performance: 0.2 | accuracy: 0.27 | loss: 8.55
update:735/2000, 耗时:0.01分/6.95分 | step: 376320 | performance: 0.0 | accuracy: 0.27 | loss: 11.41
update:740/2000, 耗时:0.01分/6.99分 | step: 378880 | performance: 0.0 | accuracy: 0.26 | loss: 4.17
update:745/2000, 耗时:0.01分/7.04分 | step: 381440 | performance: 0.4 | accuracy: 0.26 | loss: 4.44
update:750/2000, 耗时:0.01分/7.09分 | step: 384000 | performance: 0.2 | accuracy: 0.28 | loss: 9.50
update:755/2000, 耗时:0.01分/7.13分 | step: 386560 | performance: 0.1 | accuracy: 0.28 | loss: 5.05
update:760/2000, 耗时:0.01分/7.18分 | step: 389120 | performance: 0.5 | accuracy: 0.30 | loss: 8.32
update:765/2000, 耗时:0.01分/7.22分 | step: 391680 | performance: 0.1 | accuracy: 0.29 | loss: 3.68
update:770/2000, 耗时:0.01分/7.27分 | step: 394240 | performance: 0.0 | accuracy: 0.28 | loss: 5.17
update:775/2000, 耗时:0.01分/7.31分 | step: 396800 | performance: 0.1 | accuracy: 0.28 | loss: 9.09
update:780/2000, 耗时:0.01分/7.36分 | step: 399360 | performance: 0.4 | accuracy: 0.29 | loss: 6.16
update:785/2000, 耗时:0.01分/7.41分 | step: 401920 | performance: 2.1 | accuracy: 0.30 | loss: 6.51
update:790/2000, 耗时:0.01分/7.45分 | step: 404480 | performance: 1.1 | accuracy: 0.30 | loss: 7.44
update:795/2000, 耗时:0.01分/7.50分 | step: 407040 | performance: 0.4 | accuracy: 0.29 | loss: 4.52
update:800/2000, 耗时:0.01分/7.55分 | step: 409600 | performance: 1.0 | accuracy: 0.32 | loss: 5.39
update:805/2000, 耗时:0.01分/7.59分 | step: 412160 | performance: 1.4 | accuracy: 0.27 | loss: 4.95
update:810/2000, 耗时:0.01分/7.64分 | step: 414720 | performance: 2.4 | accuracy: 0.24 | loss: 3.66
update:815/2000, 耗时:0.01分/7.69分 | step: 417280 | performance: 9.3 | accuracy: 0.26 | loss: 10.58
update:820/2000, 耗时:0.01分/7.74分 | step: 419840 | performance: 22.2 | accuracy: 0.26 | loss: 2.36
update:825/2000, 耗时:0.01分/7.78分 | step: 422400 | performance: 33.2 | accuracy: 0.27 | loss: 7.00
update:830/2000, 耗时:0.01分/7.83分 | step: 424960 | performance: 83.8 | accuracy: 0.27 | loss: 2.69
update:835/2000, 耗时:0.01分/7.88分 | step: 427520 | performance: 375.0 | accuracy: 0.28 | loss: 9.04
update:840/2000, 耗时:0.01分/7.93分 | step: 430080 | performance: 294.6 | accuracy: 0.28 | loss: 4.48
update:845/2000, 耗时:0.01分/7.98分 | step: 432640 | performance: 333.1 | accuracy: 0.28 | loss: 4.34
update:850/2000, 耗时:0.01分/8.02分 | step: 435200 | performance: 300.3 | accuracy: 0.27 | loss: 3.55
update:855/2000, 耗时:0.01分/8.07分 | step: 437760 | performance: 385.3 | accuracy: 0.27 | loss: 4.07
update:860/2000, 耗时:0.01分/8.11分 | step: 440320 | performance: 2.0 | accuracy: 0.20 | loss: 4.28
update:865/2000, 耗时:0.01分/8.16分 | step: 442880 | performance: 2.3 | accuracy: 0.19 | loss: 3.64
update:870/2000, 耗时:0.01分/8.21分 | step: 445440 | performance: 3.8 | accuracy: 0.19 | loss: 1.14
update:875/2000, 耗时:0.01分/8.25分 | step: 448000 | performance: 9.5 | accuracy: 0.20 | loss: 3.95
update:880/2000, 耗时:0.01分/8.30分 | step: 450560 | performance: 7.8 | accuracy: 0.19 | loss: 2.44
update:885/2000, 耗时:0.01分/8.35分 | step: 453120 | performance: 14.1 | accuracy: 0.19 | loss: 2.06
update:890/2000, 耗时:0.01分/8.39分 | step: 455680 | performance: 24.4 | accuracy: 0.18 | loss: 4.26
update:895/2000, 耗时:0.01分/8.44分 | step: 458240 | performance: 25.2 | accuracy: 0.18 | loss: 3.99
update:900/2000, 耗时:0.01分/8.49分 | step: 460800 | performance: 26.8 | accuracy: 0.18 | loss: 3.43
update:905/2000, 耗时:0.01分/8.54分 | step: 463360 | performance: 40.7 | accuracy: 0.18 | loss: 2.43
update:910/2000, 耗时:0.01分/8.58分 | step: 465920 | performance: 50.5 | accuracy: 0.17 | loss: 1.70
update:915/2000, 耗时:0.01分/8.63分 | step: 468480 | performance: 0.7 | accuracy: 0.17 | loss: 4.73
update:920/2000, 耗时:0.01分/8.68分 | step: 471040 | performance: 1.0 | accuracy: 0.17 | loss: 1.94
update:925/2000, 耗时:0.01分/8.73分 | step: 473600 | performance: 2.8 | accuracy: 0.17 | loss: 3.50
update:930/2000, 耗时:0.01分/8.78分 | step: 476160 | performance: 5.6 | accuracy: 0.17 | loss: 2.55
update:935/2000, 耗时:0.01分/8.83分 | step: 478720 | performance: 9.3 | accuracy: 0.16 | loss: 1.94
update:940/2000, 耗时:0.01分/8.88分 | step: 481280 | performance: 10.2 | accuracy: 0.15 | loss: 2.36
update:945/2000, 耗时:0.01分/8.92分 | step: 483840 | performance: 15.2 | accuracy: 0.15 | loss: 1.31
update:950/2000, 耗时:0.01分/8.97分 | step: 486400 | performance: 20.5 | accuracy: 0.14 | loss: 2.99
update:955/2000, 耗时:0.01分/9.02分 | step: 488960 | performance: 19.8 | accuracy: 0.14 | loss: 1.65
update:960/2000, 耗时:0.01分/9.06分 | step: 491520 | performance: 14.3 | accuracy: 0.14 | loss: 0.79
update:965/2000, 耗时:0.01分/9.11分 | step: 494080 | performance: 15.9 | accuracy: 0.13 | loss: 1.54
update:970/2000, 耗时:0.01分/9.16分 | step: 496640 | performance: 17.0 | accuracy: 0.13 | loss: 2.19
update:975/2000, 耗时:0.01分/9.20分 | step: 499200 | performance: 1.1 | accuracy: 0.11 | loss: 3.03
step: 500733 | worker_4@n_step_63: average total_reward after train data exhaustion : 35.3 | max total_reward: 218.2
update:980/2000, 耗时:0.01分/9.25分 | step: 501760 | performance: 1.6 | accuracy: 0.11 | loss: 1.45
update:985/2000, 耗时:0.01分/9.30分 | step: 504320 | performance: 2.2 | accuracy: 0.11 | loss: 1.26
step: 506363 | worker_2@n_step_63: average total_reward after train data exhaustion : -0.4 | max total_reward: 218.2
update:990/2000, 耗时:0.01分/9.34分 | step: 506880 | performance: 0.9 | accuracy: 0.11 | loss: 1.04
update:995/2000, 耗时:0.01分/9.39分 | step: 509440 | performance: 2.2 | accuracy: 0.14 | loss: 3.34
step: 510459 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 218.2
step: 510972 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.8 | max total_reward: 218.2
step: 511488 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.5 | max total_reward: 218.2
update:1000/2000, 耗时:0.01分/9.43分 | step: 512000 | performance: 1.1 | accuracy: 0.08 | loss: 2.00
step: 513535 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 218.2
update:1005/2000, 耗时:0.01分/9.48分 | step: 514560 | performance: 1.0 | accuracy: 0.00 | loss: 1.10
update:1010/2000, 耗时:0.01分/9.53分 | step: 517120 | performance: 2.2 | accuracy: 0.13 | loss: 1.30
update:1015/2000, 耗时:0.01分/9.58分 | step: 519680 | performance: 2.4 | accuracy: 0.11 | loss: 1.47
update:1020/2000, 耗时:0.01分/9.62分 | step: 522240 | performance: 2.6 | accuracy: 0.11 | loss: 1.61
update:1025/2000, 耗时:0.01分/9.67分 | step: 524800 | performance: 3.1 | accuracy: 0.10 | loss: 2.50
update:1030/2000, 耗时:0.01分/9.72分 | step: 527360 | performance: 4.0 | accuracy: 0.11 | loss: 1.16
update:1035/2000, 耗时:0.01分/9.76分 | step: 529920 | performance: 7.2 | accuracy: 0.11 | loss: 2.52
update:1040/2000, 耗时:0.01分/9.81分 | step: 532480 | performance: 6.1 | accuracy: 0.11 | loss: 2.28
update:1045/2000, 耗时:0.01分/9.86分 | step: 535040 | performance: 8.7 | accuracy: 0.11 | loss: 1.97
update:1050/2000, 耗时:0.01分/9.90分 | step: 537600 | performance: 12.2 | accuracy: 0.11 | loss: 2.46
update:1055/2000, 耗时:0.01分/9.95分 | step: 540160 | performance: 8.9 | accuracy: 0.11 | loss: 1.26
update:1060/2000, 耗时:0.01分/9.99分 | step: 542720 | performance: 6.4 | accuracy: 0.11 | loss: 2.23
update:1065/2000, 耗时:0.01分/10.04分 | step: 545280 | performance: 0.9 | accuracy: 0.14 | loss: 2.39
update:1070/2000, 耗时:0.01分/10.08分 | step: 547840 | performance: 1.5 | accuracy: 0.11 | loss: 2.64
update:1075/2000, 耗时:0.01分/10.13分 | step: 550400 | performance: 1.5 | accuracy: 0.11 | loss: 1.41
step: 550911 | worker_6@n_step_63: average total_reward after train data exhaustion : -0.2 | max total_reward: 218.2
update:1080/2000, 耗时:0.01分/10.18分 | step: 552960 | performance: 1.7 | accuracy: 0.11 | loss: 1.75
update:1085/2000, 耗时:0.01分/10.22分 | step: 555520 | performance: 1.5 | accuracy: 0.10 | loss: 1.32
update:1090/2000, 耗时:0.01分/10.27分 | step: 558080 | performance: 2.0 | accuracy: 0.11 | loss: 1.94
update:1095/2000, 耗时:0.01分/10.31分 | step: 560640 | performance: 2.0 | accuracy: 0.11 | loss: 1.18
update:1100/2000, 耗时:0.01分/10.36分 | step: 563200 | performance: 4.6 | accuracy: 0.12 | loss: 1.72
update:1105/2000, 耗时:0.01分/10.41分 | step: 565760 | performance: 4.0 | accuracy: 0.11 | loss: 2.42
update:1110/2000, 耗时:0.01分/10.45分 | step: 568320 | performance: 4.3 | accuracy: 0.12 | loss: 1.54
update:1115/2000, 耗时:0.01分/10.50分 | step: 570880 | performance: 3.1 | accuracy: 0.11 | loss: 1.70
update:1120/2000, 耗时:0.01分/10.54分 | step: 573440 | performance: 1.7 | accuracy: 0.12 | loss: 4.68
update:1125/2000, 耗时:0.01分/10.59分 | step: 576000 | performance: 3.9 | accuracy: 0.14 | loss: 2.52
update:1130/2000, 耗时:0.01分/10.64分 | step: 578560 | performance: 5.3 | accuracy: 0.15 | loss: 4.06
update:1135/2000, 耗时:0.01分/10.68分 | step: 581120 | performance: 5.8 | accuracy: 0.17 | loss: 2.34
update:1140/2000, 耗时:0.01分/10.73分 | step: 583680 | performance: 10.0 | accuracy: 0.17 | loss: 2.50
update:1145/2000, 耗时:0.01分/10.77分 | step: 586240 | performance: 13.2 | accuracy: 0.17 | loss: 3.26
update:1150/2000, 耗时:0.01分/10.82分 | step: 588800 | performance: 7.3 | accuracy: 0.16 | loss: 2.39
update:1155/2000, 耗时:0.01分/10.87分 | step: 591360 | performance: 11.8 | accuracy: 0.16 | loss: 2.56
update:1160/2000, 耗时:0.01分/10.91分 | step: 593920 | performance: 16.2 | accuracy: 0.15 | loss: 2.15
update:1165/2000, 耗时:0.01分/10.96分 | step: 596480 | performance: 13.4 | accuracy: 0.14 | loss: 2.62
update:1170/2000, 耗时:0.01分/11.00分 | step: 599040 | performance: 5.6 | accuracy: 0.14 | loss: 1.17
update:1175/2000, 耗时:0.01分/11.05分 | step: 601600 | performance: 3.2 | accuracy: 0.13 | loss: 2.33
update:1180/2000, 耗时:0.01分/11.09分 | step: 604160 | performance: 0.6 | accuracy: 0.12 | loss: 3.35
update:1185/2000, 耗时:0.01分/11.14分 | step: 606720 | performance: 1.0 | accuracy: 0.00 | loss: 1.27
update:1190/2000, 耗时:0.01分/11.18分 | step: 609280 | performance: 2.5 | accuracy: 0.15 | loss: 2.15
update:1195/2000, 耗时:0.01分/11.23分 | step: 611840 | performance: 2.0 | accuracy: 0.14 | loss: 1.83
update:1200/2000, 耗时:0.01分/11.28分 | step: 614400 | performance: 4.6 | accuracy: 0.15 | loss: 3.02
update:1205/2000, 耗时:0.01分/11.32分 | step: 616960 | performance: 4.7 | accuracy: 0.14 | loss: 2.94
update:1210/2000, 耗时:0.01分/11.37分 | step: 619520 | performance: 3.0 | accuracy: 0.14 | loss: 2.02
update:1215/2000, 耗时:0.01分/11.41分 | step: 622080 | performance: 4.6 | accuracy: 0.15 | loss: 2.78
update:1220/2000, 耗时:0.01分/11.46分 | step: 624640 | performance: 14.3 | accuracy: 0.15 | loss: 4.36
update:1225/2000, 耗时:0.01分/11.50分 | step: 627200 | performance: 10.2 | accuracy: 0.15 | loss: 4.89
update:1230/2000, 耗时:0.01分/11.55分 | step: 629760 | performance: 8.4 | accuracy: 0.16 | loss: 5.65
update:1235/2000, 耗时:0.01分/11.60分 | step: 632320 | performance: 2.8 | accuracy: 0.15 | loss: 4.52
update:1240/2000, 耗时:0.01分/11.64分 | step: 634880 | performance: 3.1 | accuracy: 0.16 | loss: 8.11
update:1245/2000, 耗时:0.01分/11.69分 | step: 637440 | performance: 0.4 | accuracy: 0.20 | loss: 4.46
update:1250/2000, 耗时:0.01分/11.73分 | step: 640000 | performance: 0.6 | accuracy: 0.18 | loss: 2.93
update:1255/2000, 耗时:0.01分/11.78分 | step: 642560 | performance: 0.4 | accuracy: 0.17 | loss: 5.72
update:1260/2000, 耗时:0.01分/11.82分 | step: 645120 | performance: 1.0 | accuracy: 0.18 | loss: 3.57
update:1265/2000, 耗时:0.01分/11.87分 | step: 647680 | performance: 1.1 | accuracy: 0.17 | loss: 4.19
update:1270/2000, 耗时:0.01分/11.92分 | step: 650240 | performance: 0.6 | accuracy: 0.16 | loss: 2.04
update:1275/2000, 耗时:0.01分/11.96分 | step: 652800 | performance: 1.2 | accuracy: 0.17 | loss: 3.76
update:1280/2000, 耗时:0.01分/12.01分 | step: 655360 | performance: 3.3 | accuracy: 0.18 | loss: 4.19
update:1285/2000, 耗时:0.01分/12.05分 | step: 657920 | performance: 8.6 | accuracy: 0.18 | loss: 6.77
update:1290/2000, 耗时:0.01分/12.10分 | step: 660480 | performance: 8.1 | accuracy: 0.18 | loss: 4.15
update:1295/2000, 耗时:0.01分/12.14分 | step: 663040 | performance: 7.2 | accuracy: 0.18 | loss: 5.05
update:1300/2000, 耗时:0.01分/12.19分 | step: 665600 | performance: 2.0 | accuracy: 0.24 | loss: 4.84
update:1305/2000, 耗时:0.01分/12.23分 | step: 668160 | performance: 1.5 | accuracy: 0.20 | loss: 7.50
update:1310/2000, 耗时:0.01分/12.28分 | step: 670720 | performance: 1.0 | accuracy: 0.19 | loss: 3.84
update:1315/2000, 耗时:0.01分/12.33分 | step: 673280 | performance: 2.4 | accuracy: 0.19 | loss: 4.67
update:1320/2000, 耗时:0.01分/12.37分 | step: 675840 | performance: 1.9 | accuracy: 0.17 | loss: 2.62
update:1325/2000, 耗时:0.01分/12.42分 | step: 678400 | performance: 1.4 | accuracy: 0.16 | loss: 2.75
step: 680446 | worker_5@n_step_63: average total_reward after train data exhaustion : 18.9 | max total_reward: 218.2
update:1330/2000, 耗时:0.01分/12.46分 | step: 680960 | performance: 1.8 | accuracy: 0.16 | loss: 2.11
update:1335/2000, 耗时:0.01分/12.51分 | step: 683520 | performance: 6.0 | accuracy: 0.15 | loss: 1.52
update:1340/2000, 耗时:0.01分/12.56分 | step: 686080 | performance: 3.8 | accuracy: 0.15 | loss: 2.83
update:1345/2000, 耗时:0.01分/12.60分 | step: 688640 | performance: 2.0 | accuracy: 0.14 | loss: 3.40
update:1350/2000, 耗时:0.01分/12.65分 | step: 691200 | performance: 0.4 | accuracy: 0.14 | loss: 3.21
update:1355/2000, 耗时:0.01分/12.69分 | step: 693760 | performance: 0.4 | accuracy: 0.13 | loss: 1.93
update:1360/2000, 耗时:0.01分/12.74分 | step: 696320 | performance: 1.1 | accuracy: 0.12 | loss: 1.74
step: 698877 | worker_4@n_step_63: average total_reward after train data exhaustion : 8.7 | max total_reward: 218.2
update:1365/2000, 耗时:0.01分/12.78分 | step: 698880 | performance: 1.4 | accuracy: 0.31 | loss: 1.47
step: 699900 | worker_3@n_step_63: average total_reward after train data exhaustion : 10.1 | max total_reward: 218.2
update:1370/2000, 耗时:0.01分/12.83分 | step: 701440 | performance: 0.9 | accuracy: 0.12 | loss: 2.28
update:1375/2000, 耗时:0.01分/12.88分 | step: 704000 | performance: 1.0 | accuracy: 0.14 | loss: 1.70
step: 704511 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 218.2
update:1380/2000, 耗时:0.01分/12.92分 | step: 706560 | performance: 1.2 | accuracy: 0.12 | loss: 2.21
update:1385/2000, 耗时:0.01分/12.97分 | step: 709120 | performance: 1.6 | accuracy: 0.15 | loss: 1.03
step: 710144 | worker_7@n_step_63: average total_reward after train data exhaustion : 4.7 | max total_reward: 218.2
update:1390/2000, 耗时:0.01分/13.01分 | step: 711680 | performance: 1.1 | accuracy: 0.08 | loss: 2.21
update:1395/2000, 耗时:0.01分/13.06分 | step: 714240 | performance: 1.0 | accuracy: 0.00 | loss: 1.93
update:1400/2000, 耗时:0.01分/13.11分 | step: 716800 | performance: 1.0 | accuracy: 0.00 | loss: 1.23
update:1405/2000, 耗时:0.01分/13.15分 | step: 719360 | performance: 1.0 | accuracy: 0.12 | loss: 1.97
update:1410/2000, 耗时:0.01分/13.20分 | step: 721920 | performance: 1.0 | accuracy: 0.11 | loss: 2.47
update:1415/2000, 耗时:0.01分/13.24分 | step: 724480 | performance: 1.0 | accuracy: 0.12 | loss: 1.30
update:1420/2000, 耗时:0.01分/13.29分 | step: 727040 | performance: 1.3 | accuracy: 0.13 | loss: 2.60
update:1425/2000, 耗时:0.01分/13.33分 | step: 729600 | performance: 1.7 | accuracy: 0.13 | loss: 3.27
update:1430/2000, 耗时:0.01分/13.38分 | step: 732160 | performance: 1.8 | accuracy: 0.13 | loss: 6.82
update:1435/2000, 耗时:0.01分/13.43分 | step: 734720 | performance: 4.8 | accuracy: 0.15 | loss: 3.77
update:1440/2000, 耗时:0.01分/13.47分 | step: 737280 | performance: 42.5 | accuracy: 0.16 | loss: 4.80
update:1445/2000, 耗时:0.01分/13.52分 | step: 739840 | performance: 35.4 | accuracy: 0.15 | loss: 3.10
update:1450/2000, 耗时:0.01分/13.57分 | step: 742400 | performance: 105.1 | accuracy: 0.16 | loss: 4.53
update:1455/2000, 耗时:0.01分/13.62分 | step: 744960 | performance: 47.5 | accuracy: 0.15 | loss: 4.01
update:1460/2000, 耗时:0.01分/13.66分 | step: 747520 | performance: 47.1 | accuracy: 0.16 | loss: 3.42
update:1465/2000, 耗时:0.01分/13.71分 | step: 750080 | performance: 0.5 | accuracy: 0.14 | loss: 2.87
update:1470/2000, 耗时:0.01分/13.76分 | step: 752640 | performance: 0.6 | accuracy: 0.16 | loss: 3.88
update:1475/2000, 耗时:0.01分/13.81分 | step: 755200 | performance: 0.5 | accuracy: 0.17 | loss: 4.05
update:1480/2000, 耗时:0.01分/13.85分 | step: 757760 | performance: 1.6 | accuracy: 0.18 | loss: 4.81
update:1485/2000, 耗时:0.01分/13.90分 | step: 760320 | performance: 1.2 | accuracy: 0.17 | loss: 5.93
update:1490/2000, 耗时:0.01分/13.94分 | step: 762880 | performance: 0.8 | accuracy: 0.19 | loss: 4.96
update:1495/2000, 耗时:0.01分/13.99分 | step: 765440 | performance: 2.5 | accuracy: 0.21 | loss: 10.06
update:1500/2000, 耗时:0.01分/14.04分 | step: 768000 | performance: 23.7 | accuracy: 0.22 | loss: 8.57
update:1505/2000, 耗时:0.01分/14.08分 | step: 770560 | performance: 16.4 | accuracy: 0.22 | loss: 5.79
update:1510/2000, 耗时:0.01分/14.13分 | step: 773120 | performance: 7.1 | accuracy: 0.21 | loss: 1.37
update:1515/2000, 耗时:0.01分/14.18分 | step: 775680 | performance: 6.4 | accuracy: 0.20 | loss: 7.36
update:1520/2000, 耗时:0.01分/14.22分 | step: 778240 | performance: 1.1 | accuracy: 0.13 | loss: 3.09
update:1525/2000, 耗时:0.01分/14.27分 | step: 780800 | performance: 1.0 | accuracy: 0.12 | loss: 2.67
update:1530/2000, 耗时:0.01分/14.32分 | step: 783360 | performance: 0.9 | accuracy: 0.11 | loss: 1.46
update:1535/2000, 耗时:0.01分/14.36分 | step: 785920 | performance: 1.2 | accuracy: 0.12 | loss: 2.54
update:1540/2000, 耗时:0.01分/14.41分 | step: 788480 | performance: 1.5 | accuracy: 0.11 | loss: 2.88
update:1545/2000, 耗时:0.01分/14.46分 | step: 791040 | performance: 1.3 | accuracy: 0.12 | loss: 2.52
update:1550/2000, 耗时:0.01分/14.51分 | step: 793600 | performance: 1.8 | accuracy: 0.14 | loss: 5.06
update:1555/2000, 耗时:0.01分/14.56分 | step: 796160 | performance: 8.2 | accuracy: 0.14 | loss: 5.20
update:1560/2000, 耗时:0.01分/14.61分 | step: 798720 | performance: 11.2 | accuracy: 0.15 | loss: 4.22
update:1565/2000, 耗时:0.01分/14.66分 | step: 801280 | performance: 18.5 | accuracy: 0.15 | loss: 2.73
step: 802813 | worker_4@n_step_63: average total_reward after train data exhaustion : 18.6 | max total_reward: 218.2
update:1570/2000, 耗时:0.01分/14.71分 | step: 803840 | performance: 12.8 | accuracy: 0.15 | loss: 2.02
step: 804861 | worker_4@n_step_63: average total_reward after train data exhaustion : 15.1 | max total_reward: 218.2
update:1575/2000, 耗时:0.01分/14.76分 | step: 806400 | performance: 13.4 | accuracy: 0.14 | loss: 3.93
update:1580/2000, 耗时:0.01分/14.81分 | step: 808960 | performance: 1.2 | accuracy: 0.33 | loss: 3.13
update:1585/2000, 耗时:0.01分/14.86分 | step: 811520 | performance: 0.4 | accuracy: 0.11 | loss: 3.54
update:1590/2000, 耗时:0.01分/14.91分 | step: 814080 | performance: 0.4 | accuracy: 0.14 | loss: 3.29
update:1595/2000, 耗时:0.01分/14.95分 | step: 816640 | performance: 0.6 | accuracy: 0.17 | loss: 3.78
update:1600/2000, 耗时:0.01分/15.00分 | step: 819200 | performance: 1.2 | accuracy: 0.19 | loss: 4.86
update:1605/2000, 耗时:0.01分/15.05分 | step: 821760 | performance: 0.9 | accuracy: 0.19 | loss: 6.74
update:1610/2000, 耗时:0.01分/15.09分 | step: 824320 | performance: 2.9 | accuracy: 0.20 | loss: 4.91
update:1615/2000, 耗时:0.01分/15.14分 | step: 826880 | performance: 9.1 | accuracy: 0.21 | loss: 4.16
update:1620/2000, 耗时:0.01分/15.18分 | step: 829440 | performance: 6.5 | accuracy: 0.20 | loss: 3.74
step: 830460 | worker_3@n_step_63: average total_reward after train data exhaustion : 22.9 | max total_reward: 218.2
update:1625/2000, 耗时:0.01分/15.23分 | step: 832000 | performance: 15.5 | accuracy: 0.19 | loss: 4.62
update:1630/2000, 耗时:0.01分/15.28分 | step: 834560 | performance: 12.1 | accuracy: 0.18 | loss: 1.94
step: 835070 | worker_5@n_step_63: average total_reward after train data exhaustion : 28.1 | max total_reward: 218.2
update:1635/2000, 耗时:0.01分/15.32分 | step: 837120 | performance: 5.6 | accuracy: 0.17 | loss: 2.15
step: 838144 | worker_7@n_step_63: average total_reward after train data exhaustion : 25.1 | max total_reward: 218.2
step: 838651 | worker_2@n_step_63: average total_reward after train data exhaustion : 18.4 | max total_reward: 218.2
update:1640/2000, 耗时:0.01分/15.37分 | step: 839680 | performance: 1.2 | accuracy: 0.12 | loss: 3.36
update:1645/2000, 耗时:0.01分/15.42分 | step: 842240 | performance: 1.3 | accuracy: 0.11 | loss: 1.51
update:1650/2000, 耗时:0.01分/15.46分 | step: 844800 | performance: 1.1 | accuracy: 0.14 | loss: 1.75
update:1655/2000, 耗时:0.01分/15.51分 | step: 847360 | performance: 0.7 | accuracy: 0.11 | loss: 2.29
update:1660/2000, 耗时:0.01分/15.56分 | step: 849920 | performance: 1.0 | accuracy: 0.11 | loss: 2.50
update:1665/2000, 耗时:0.01分/15.60分 | step: 852480 | performance: 0.6 | accuracy: 0.13 | loss: 2.23
update:1670/2000, 耗时:0.01分/15.65分 | step: 855040 | performance: 0.5 | accuracy: 0.10 | loss: 1.49
update:1675/2000, 耗时:0.01分/15.70分 | step: 857600 | performance: 0.5 | accuracy: 0.11 | loss: 1.46
update:1680/2000, 耗时:0.01分/15.74分 | step: 860160 | performance: 0.8 | accuracy: 0.11 | loss: 2.24
update:1685/2000, 耗时:0.01分/15.79分 | step: 862720 | performance: 0.6 | accuracy: 0.11 | loss: 1.42
update:1690/2000, 耗时:0.01分/15.83分 | step: 865280 | performance: 1.1 | accuracy: 0.12 | loss: 4.55
update:1695/2000, 耗时:0.01分/15.88分 | step: 867840 | performance: 3.0 | accuracy: 0.14 | loss: 11.07
update:1700/2000, 耗时:0.01分/15.92分 | step: 870400 | performance: 16.4 | accuracy: 0.15 | loss: 11.21
update:1705/2000, 耗时:0.01分/15.97分 | step: 872960 | performance: 13.2 | accuracy: 0.16 | loss: 11.12
update:1710/2000, 耗时:0.01分/16.02分 | step: 875520 | performance: 3.7 | accuracy: 0.17 | loss: 4.22
update:1715/2000, 耗时:0.01分/16.06分 | step: 878080 | performance: 0.5 | accuracy: 0.17 | loss: 8.73
update:1720/2000, 耗时:0.01分/16.11分 | step: 880640 | performance: 0.5 | accuracy: 0.19 | loss: 8.09
update:1725/2000, 耗时:0.01分/16.15分 | step: 883200 | performance: 0.5 | accuracy: 0.25 | loss: 5.10
update:1730/2000, 耗时:0.01分/16.20分 | step: 885760 | performance: 0.4 | accuracy: 0.23 | loss: 6.39
update:1735/2000, 耗时:0.01分/16.24分 | step: 888320 | performance: 2.1 | accuracy: 0.26 | loss: 6.80
update:1740/2000, 耗时:0.01分/16.29分 | step: 890880 | performance: 1.9 | accuracy: 0.26 | loss: 6.37
update:1745/2000, 耗时:0.01分/16.34分 | step: 893440 | performance: 0.9 | accuracy: 0.26 | loss: 6.42
update:1750/2000, 耗时:0.01分/16.38分 | step: 896000 | performance: 2.5 | accuracy: 0.27 | loss: 9.85
update:1755/2000, 耗时:0.01分/16.43分 | step: 898560 | performance: 75.0 | accuracy: 0.28 | loss: 11.91
update:1760/2000, 耗时:0.01分/16.47分 | step: 901120 | performance: 28.2 | accuracy: 0.28 | loss: 13.83
update:1765/2000, 耗时:0.01分/16.52分 | step: 903680 | performance: 34.0 | accuracy: 0.28 | loss: 12.40
update:1770/2000, 耗时:0.01分/16.57分 | step: 906240 | performance: 4.3 | accuracy: 0.28 | loss: 14.06
update:1775/2000, 耗时:0.01分/16.61分 | step: 908800 | performance: 2.2 | accuracy: 0.27 | loss: 9.88
update:1780/2000, 耗时:0.01分/16.66分 | step: 911360 | performance: 0.2 | accuracy: 0.22 | loss: 5.11
update:1785/2000, 耗时:0.01分/16.71分 | step: 913920 | performance: 0.1 | accuracy: 0.20 | loss: 3.40
update:1790/2000, 耗时:0.01分/16.75分 | step: 916480 | performance: 0.0 | accuracy: 0.20 | loss: 4.28
update:1795/2000, 耗时:0.01分/16.80分 | step: 919040 | performance: 0.1 | accuracy: 0.21 | loss: 4.63
update:1800/2000, 耗时:0.01分/16.84分 | step: 921600 | performance: 0.1 | accuracy: 0.21 | loss: 5.39
update:1805/2000, 耗时:0.01分/16.89分 | step: 924160 | performance: 0.1 | accuracy: 0.21 | loss: 5.64
update:1810/2000, 耗时:0.01分/16.94分 | step: 926720 | performance: 0.2 | accuracy: 0.22 | loss: 7.67
update:1815/2000, 耗时:0.01分/16.98分 | step: 929280 | performance: 0.5 | accuracy: 0.23 | loss: 5.92
update:1820/2000, 耗时:0.01分/17.03分 | step: 931840 | performance: 0.7 | accuracy: 0.23 | loss: 10.23
update:1825/2000, 耗时:0.01分/17.07分 | step: 934400 | performance: 0.4 | accuracy: 0.23 | loss: 5.88
update:1830/2000, 耗时:0.01分/17.12分 | step: 936960 | performance: 0.1 | accuracy: 0.22 | loss: 7.47
update:1835/2000, 耗时:0.01分/17.17分 | step: 939520 | performance: 0.8 | accuracy: 0.23 | loss: 11.68
update:1840/2000, 耗时:0.01分/17.21分 | step: 942080 | performance: 0.3 | accuracy: 0.19 | loss: 5.63
update:1845/2000, 耗时:0.01分/17.26分 | step: 944640 | performance: 0.1 | accuracy: 0.18 | loss: 4.00
update:1850/2000, 耗时:0.01分/17.30分 | step: 947200 | performance: 0.4 | accuracy: 0.18 | loss: 6.70
update:1855/2000, 耗时:0.01分/17.35分 | step: 949760 | performance: 0.3 | accuracy: 0.16 | loss: 2.58
step: 951804 | worker_3@n_step_63: average total_reward after train data exhaustion : 46.8 | max total_reward: 218.2
update:1860/2000, 耗时:0.01分/17.40分 | step: 952320 | performance: 0.4 | accuracy: 0.15 | loss: 2.36
update:1865/2000, 耗时:0.01分/17.44分 | step: 954880 | performance: 0.3 | accuracy: 0.15 | loss: 2.72
update:1870/2000, 耗时:0.01分/17.49分 | step: 957440 | performance: 0.6 | accuracy: 0.15 | loss: 3.02
update:1875/2000, 耗时:0.01分/17.53分 | step: 960000 | performance: 0.7 | accuracy: 0.15 | loss: 5.54
update:1880/2000, 耗时:0.01分/17.58分 | step: 962560 | performance: 0.6 | accuracy: 0.15 | loss: 4.52
update:1885/2000, 耗时:0.01分/17.63分 | step: 965120 | performance: 0.1 | accuracy: 0.15 | loss: 3.35
update:1890/2000, 耗时:0.01分/17.67分 | step: 967680 | performance: 0.1 | accuracy: 0.15 | loss: 1.79
update:1895/2000, 耗时:0.01分/17.72分 | step: 970240 | performance: 1.1 | accuracy: 0.21 | loss: 3.01
update:1900/2000, 耗时:0.01分/17.76分 | step: 972800 | performance: 0.3 | accuracy: 0.12 | loss: 5.76
update:1905/2000, 耗时:0.01分/17.81分 | step: 975360 | performance: 0.2 | accuracy: 0.14 | loss: 4.56
update:1910/2000, 耗时:0.01分/17.86分 | step: 977920 | performance: 0.2 | accuracy: 0.14 | loss: 2.15
update:1915/2000, 耗时:0.01分/17.90分 | step: 980480 | performance: 0.3 | accuracy: 0.13 | loss: 1.88
update:1920/2000, 耗时:0.01分/17.95分 | step: 983040 | performance: 0.2 | accuracy: 0.12 | loss: 0.86
update:1925/2000, 耗时:0.01分/17.99分 | step: 985600 | performance: 0.2 | accuracy: 0.11 | loss: 1.09
update:1930/2000, 耗时:0.01分/18.04分 | step: 988160 | performance: 0.5 | accuracy: 0.11 | loss: 2.52
step: 990207 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 218.2
update:1935/2000, 耗时:0.01分/18.09分 | step: 990720 | performance: 0.6 | accuracy: 0.11 | loss: 0.70
step: 993276 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 218.2
update:1940/2000, 耗时:0.01分/18.13分 | step: 993280 | performance: 0.6 | accuracy: 0.10 | loss: 2.05
step: 995326 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 218.2
update:1945/2000, 耗时:0.01分/18.18分 | step: 995840 | performance: 0.5 | accuracy: 0.10 | loss: 0.75
step: 998400 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 218.2
update:1950/2000, 耗时:0.01分/18.22分 | step: 998400 | performance: 1.0 | accuracy: 0.00 | loss: 0.83
step: 1000442 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 218.2
step: 1000956 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 218.2
update:1955/2000, 耗时:0.01分/18.27分 | step: 1000960 | performance: 1.1 | accuracy: 0.33 | loss: 0.77
step: 1001465 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 218.2
step: 1001467 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 218.2
update:1960/2000, 耗时:0.01分/18.32分 | step: 1003520 | performance: 1.0 | accuracy: 0.15 | loss: 1.16
step: 1004538 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 218.2
step: 1004543 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 218.2
step: 1005563 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 218.2
update:1965/2000, 耗时:0.01分/18.36分 | step: 1006080 | performance: 1.1 | accuracy: 0.13 | loss: 1.52
step: 1008635 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 218.2
step: 1008639 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 218.2
update:1970/2000, 耗时:0.01分/18.41分 | step: 1008640 | performance: 0.8 | accuracy: 0.11 | loss: 2.67
update:1975/2000, 耗时:0.01分/18.46分 | step: 1011200 | performance: 2.2 | accuracy: 0.16 | loss: 1.72
step: 1013243 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 218.2
update:1980/2000, 耗时:0.01分/18.50分 | step: 1013760 | performance: 1.3 | accuracy: 0.10 | loss: 1.33
update:1985/2000, 耗时:0.01分/18.55分 | step: 1016320 | performance: 1.1 | accuracy: 0.25 | loss: 1.51
update:1990/2000, 耗时:0.01分/18.59分 | step: 1018880 | performance: 1.3 | accuracy: 0.23 | loss: 1.86
step: 1021436 | worker_3@n_step_63: average total_reward after train data exhaustion : -0.2 | max total_reward: 218.2
update:1995/2000, 耗时:0.01分/18.64分 | step: 1021440 | performance: 1.1 | accuracy: 0.09 | loss: 1.02
step: 1021952 | worker_7@n_step_63: average total_reward after train data exhaustion : -0.2 | max total_reward: 218.2
step: 1023482 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 218.2
step: 1023996 | worker_3@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 218.2
update:2000/2000, 耗时:0.01分/18.69分 | step: 1024000 | performance: 1.0 | accuracy: 0.00 | loss: 1.51
----------------------------------------finished----------------------------------------
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/397 [00:00<?, ?it/s]100%|| 397/397 [00:00<00:00, 99269.03it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1717.53
2023-07-24T12:00:00 | net performance [%] = 71.7531
2023-07-24T12:00:00 | number of trades [#] = 4
==================================================
Trial 22 Complete [00h 19m 07s]
net_wealth: 1719.2504621082335

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 03h 03m 21s

Search: Running Trial #23

Value             |Best Value So Far |Hyperparameter
1                 |1                 |horizon
365               |730               |lookback
True              |False             |MarketFactor
5                 |3                 |lags
0.92              |0.92              |gamma
32                |32                |batch_size
10                |1                 |n_step
0.8               |0.94              |gae_lambda
1                 |5                 |gradient_clip_norm
5                 |5                 |epochs
0.0001            |0.0001            |actor_lr
0.0001            |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4300.000000   4301.000000
mean      0.000435    20113.607657  ...   20173.020481  20169.373185
std       0.027833    16040.642334  ...   16078.674434  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7736.967529   7730.930176
50%       0.000642    11571.842969  ...   11753.029785  11751.469727
75%       0.011590    29894.706152  ...   30013.548340  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 01:06:44.265369: I tensorflow/cor22023-2023-07-28 01:06:44.265395: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-cer/it0pl0ical op2aerations:  AVX AVX2
To 3tefnab-orm/0lc7ep- 2them in 8u_fo etather operations, rebuild TensorFlow wur0e7-21it2h: 06:44.t8 0h2e 1:06:44.a265397: I tensorppropriate compiler f60540_lguaar2d.3c1c::gs1 42I]. -07 tThis
ensorflo TensorF2wf20l-22o/2w023l38 0-/co0-023-w binar17-07cor2ore0-828 01:0 /0p7l6-28a 1tfo:r0:06:44.4y21:04m./626586c581pu_ f2:: 0e96::4 6II t4en is.ea tsorflow/core/platftensorflow//c2oopr:644rm/cp.u5r285u_f3e/platform/cpu_feature_guard.c:e eatopIc:_gua rd.utecc:142n] Trso1e4_rfg2]ulow/a rhdcore/platfo6T5r5.its ccm07:T Ie/lhis aicTet tensorflow/conmfpiuz_eons:orF1rrfmdes42 wilteature_gua]ow binary /cpu_feature_ /phiTsr oorh ond.cptieAiPmIc:is Te142guardn.slatform/c zDcFlow binarcpoue_efr:1Fd wieth oneAe]p N elaurture_al Ne4TgtPIw ou2]o wThh Deepyaibi  srd.sisiN T eoptecrcurinsor :ak Llm iFlbraryoTensorFlow binawnary 142  b]Ni(onieDsnaryeNt Niwork Library)s   optiotormyi zptimized we  idiis z Ttwhi uhioneA os pPIste the followitn(g De ed with oneAPI Deep eh ononeDNCPN)NTensoeeUu ArFPrimal iNlow bIin etworsDteekr pi nNeuLibp Neurza ruyrraarc ael tito oud y i(sl NsNweitee tt hn wonteoArPkIhewoos p  iDfrtki mLioe izedberLn p i llarbywroNenoituhe DwiNarpe(orN)  oneAPItoan ny gueDNsle  (on tDeeDNN) ep Nh)N e NCPU inteurtalo wtor o usstNerkeu tshee   eLt wofrtffiobrraurcormay lhotnkc eLeli(lonl-owooneisiwnDiNnNbrc)r itoargg CPU y  C(PUi  fon e Dunssoiltltonse rtuictihntcraNeiwons pN followi)uinglcte iionn s tn og pin pCePo  pusreUr iaetrern sthfe fo rmffCoPorltUmaloworru inncanctions e-ccin performance-crer-itical opergcmariticiansal it itioCopPtructiUon snii:n stca ernactons in performanilsrAVX e-c o:Ace-VoXn r AcirVuc2t
pieticralstTioa ioca :eopenls i op t neAnVratio rXabnXs:  AVX AVXion Aations:   V2X
ApAerVfsl2TXo re
 V:AoVX TXo 22

Temtao enThenaobnce- a eAnabbVlme th cllreie tXm in otiheme  it her  itnAV nhoecemothpeerr on tiX2
hTnal  oati oopeo preart tiheanbalbeerare them i loopnneoeti onto ns,ss:, ro tr Ae arebutiblphuedhVeXrr ie a oToemn tpieonnrsin,satAiViooX orFn2
Tostl dl ,o re hwe rebuTwith eeilnable tnd Tethsr he buildnss aTppenosrooor,F ereobplmrpuiowr erir FldiatFawln  oetiTlen scomtooptioiwo whw ithte hn swir, Flhth eolwer flt thae r rowip ebuiproprtpherat iiappldroopartheh tnies,ea te c om pTaecilpapnrsooprpp rreoFeroiprabmtpel o uildcomflags.
pil rTensoiwlie rwarer flaaith thgFgles.
ste  . owc
appropriate compiler flags.
flags.
 with the appropriate compiler flags.
ompiler flags.
2023-07-28 01:06:44.880686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:06:44.886858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:06:44.895648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:06:44.899751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:06:44.911030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:06:44.916660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:06:44.920754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:06:44.937290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 1.2 | accuracy: 0.40 | loss: 0.99
update: 10/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 1.0 | accuracy: 0.36 | loss: 0.56
update: 15/2000, 耗时:0.00分/0.06分 | step:  1200 | performance: 1.1 | accuracy: 0.38 | loss: 1.07
update: 20/2000, 耗时:0.00分/0.08分 | step:  1600 | performance: 1.1 | accuracy: 0.39 | loss: 1.41
update: 25/2000, 耗时:0.00分/0.09分 | step:  2000 | performance: 0.9 | accuracy: 0.38 | loss: 0.57
update: 30/2000, 耗时:0.00分/0.11分 | step:  2400 | performance: 1.1 | accuracy: 0.37 | loss: 0.80
update: 35/2000, 耗时:0.00分/0.13分 | step:  2800 | performance: 0.9 | accuracy: 0.36 | loss: 0.40
update: 40/2000, 耗时:0.00分/0.14分 | step:  3200 | performance: 1.0 | accuracy: 0.36 | loss: 1.12
update: 45/2000, 耗时:0.00分/0.16分 | step:  3600 | performance: 1.1 | accuracy: 0.36 | loss: 0.71
update: 50/2000, 耗时:0.00分/0.18分 | step:  4000 | performance: 1.1 | accuracy: 0.36 | loss: 0.42
update: 55/2000, 耗时:0.00分/0.20分 | step:  4400 | performance: 1.7 | accuracy: 0.36 | loss: 0.77
update: 60/2000, 耗时:0.00分/0.21分 | step:  4800 | performance: 1.9 | accuracy: 0.36 | loss: 1.03
update: 65/2000, 耗时:0.00分/0.23分 | step:  5200 | performance: 1.9 | accuracy: 0.35 | loss: 0.58
update: 70/2000, 耗时:0.00分/0.25分 | step:  5600 | performance: 2.1 | accuracy: 0.35 | loss: 0.65
update: 75/2000, 耗时:0.00分/0.27分 | step:  6000 | performance: 1.9 | accuracy: 0.35 | loss: 0.56
update: 80/2000, 耗时:0.00分/0.29分 | step:  6400 | performance: 2.1 | accuracy: 0.35 | loss: 0.41
update: 85/2000, 耗时:0.00分/0.31分 | step:  6800 | performance: 1.9 | accuracy: 0.35 | loss: 0.52
update: 90/2000, 耗时:0.00分/0.32分 | step:  7200 | performance: 1.9 | accuracy: 0.35 | loss: 0.83
update: 95/2000, 耗时:0.00分/0.34分 | step:  7600 | performance: 2.0 | accuracy: 0.35 | loss: 1.14
update:100/2000, 耗时:0.00分/0.36分 | step:  8000 | performance: 1.8 | accuracy: 0.35 | loss: 0.54
update:105/2000, 耗时:0.00分/0.38分 | step:  8400 | performance: 1.6 | accuracy: 0.34 | loss: 0.82
update:110/2000, 耗时:0.00分/0.40分 | step:  8800 | performance: 1.5 | accuracy: 0.34 | loss: 0.31
update:115/2000, 耗时:0.00分/0.42分 | step:  9200 | performance: 1.5 | accuracy: 0.33 | loss: 0.18
update:120/2000, 耗时:0.00分/0.44分 | step:  9600 | performance: 1.6 | accuracy: 0.32 | loss: 0.51
update:125/2000, 耗时:0.00分/0.45分 | step: 10000 | performance: 1.5 | accuracy: 0.32 | loss: 0.25
update:130/2000, 耗时:0.00分/0.47分 | step: 10400 | performance: 1.5 | accuracy: 0.32 | loss: 0.16
update:135/2000, 耗时:0.00分/0.49分 | step: 10800 | performance: 1.5 | accuracy: 0.31 | loss: 0.47
update:140/2000, 耗时:0.00分/0.51分 | step: 11200 | performance: 1.6 | accuracy: 0.31 | loss: 0.50
update:145/2000, 耗时:0.00分/0.53分 | step: 11600 | performance: 1.4 | accuracy: 0.31 | loss: 0.28
update:150/2000, 耗时:0.00分/0.55分 | step: 12000 | performance: 1.5 | accuracy: 0.30 | loss: 0.47
update:155/2000, 耗时:0.00分/0.57分 | step: 12400 | performance: 1.4 | accuracy: 0.30 | loss: 0.25
update:160/2000, 耗时:0.00分/0.59分 | step: 12800 | performance: 1.5 | accuracy: 0.30 | loss: 0.41
update:165/2000, 耗时:0.00分/0.60分 | step: 13200 | performance: 1.6 | accuracy: 0.29 | loss: 0.28
update:170/2000, 耗时:0.00分/0.62分 | step: 13600 | performance: 1.6 | accuracy: 0.29 | loss: 0.20
update:175/2000, 耗时:0.00分/0.64分 | step: 14000 | performance: 1.7 | accuracy: 0.29 | loss: 0.45
update:180/2000, 耗时:0.00分/0.66分 | step: 14400 | performance: 1.7 | accuracy: 0.29 | loss: 0.39
update:185/2000, 耗时:0.00分/0.68分 | step: 14800 | performance: 1.8 | accuracy: 0.28 | loss: 0.39
update:190/2000, 耗时:0.00分/0.70分 | step: 15200 | performance: 1.8 | accuracy: 0.28 | loss: 0.32
update:195/2000, 耗时:0.00分/0.72分 | step: 15600 | performance: 2.1 | accuracy: 0.28 | loss: 0.44
update:200/2000, 耗时:0.00分/0.73分 | step: 16000 | performance: 2.1 | accuracy: 0.28 | loss: 0.34
update:205/2000, 耗时:0.00分/0.75分 | step: 16400 | performance: 2.0 | accuracy: 0.27 | loss: 0.60
update:210/2000, 耗时:0.00分/0.77分 | step: 16800 | performance: 2.6 | accuracy: 0.28 | loss: 1.01
update:215/2000, 耗时:0.00分/0.79分 | step: 17200 | performance: 2.6 | accuracy: 0.28 | loss: 0.57
update:220/2000, 耗时:0.00分/0.81分 | step: 17600 | performance: 2.2 | accuracy: 0.28 | loss: 0.32
update:225/2000, 耗时:0.00分/0.83分 | step: 18000 | performance: 2.3 | accuracy: 0.27 | loss: 0.20
update:230/2000, 耗时:0.00分/0.85分 | step: 18400 | performance: 1.9 | accuracy: 0.27 | loss: 0.14
update:235/2000, 耗时:0.00分/0.86分 | step: 18800 | performance: 1.8 | accuracy: 0.27 | loss: 0.18
update:240/2000, 耗时:0.00分/0.88分 | step: 19200 | performance: 1.6 | accuracy: 0.26 | loss: 0.15
update:245/2000, 耗时:0.00分/0.90分 | step: 19600 | performance: 1.5 | accuracy: 0.26 | loss: 0.14
update:250/2000, 耗时:0.00分/0.92分 | step: 20000 | performance: 1.5 | accuracy: 0.25 | loss: 0.05
update:255/2000, 耗时:0.00分/0.94分 | step: 20400 | performance: 1.4 | accuracy: 0.25 | loss: 0.01
update:260/2000, 耗时:0.00分/0.96分 | step: 20800 | performance: 1.4 | accuracy: 0.25 | loss: 0.04
update:265/2000, 耗时:0.00分/0.97分 | step: 21200 | performance: 1.5 | accuracy: 0.24 | loss: 0.30
update:270/2000, 耗时:0.00分/0.99分 | step: 21600 | performance: 1.5 | accuracy: 0.24 | loss: 0.18
update:275/2000, 耗时:0.00分/1.01分 | step: 22000 | performance: 1.5 | accuracy: 0.24 | loss: 0.01
update:280/2000, 耗时:0.00分/1.03分 | step: 22400 | performance: 1.4 | accuracy: 0.23 | loss: 0.06
update:285/2000, 耗时:0.00分/1.05分 | step: 22800 | performance: 1.4 | accuracy: 0.23 | loss: 0.13
update:290/2000, 耗时:0.00分/1.07分 | step: 23200 | performance: 1.4 | accuracy: 0.23 | loss: 0.01
update:295/2000, 耗时:0.00分/1.09分 | step: 23600 | performance: 1.4 | accuracy: 0.23 | loss: 0.08
update:300/2000, 耗时:0.00分/1.10分 | step: 24000 | performance: 1.4 | accuracy: 0.22 | loss: 0.01
update:305/2000, 耗时:0.00分/1.12分 | step: 24400 | performance: 1.4 | accuracy: 0.22 | loss: 0.01
update:310/2000, 耗时:0.00分/1.14分 | step: 24800 | performance: 1.5 | accuracy: 0.22 | loss: 0.02
update:315/2000, 耗时:0.00分/1.16分 | step: 25200 | performance: 1.4 | accuracy: 0.21 | loss: 0.00
update:320/2000, 耗时:0.00分/1.18分 | step: 25600 | performance: 1.4 | accuracy: 0.21 | loss: 0.05
update:325/2000, 耗时:0.00分/1.20分 | step: 26000 | performance: 1.5 | accuracy: 0.21 | loss: 0.12
update:330/2000, 耗时:0.00分/1.22分 | step: 26400 | performance: 1.5 | accuracy: 0.21 | loss: 0.23
update:335/2000, 耗时:0.00分/1.23分 | step: 26800 | performance: 1.4 | accuracy: 0.20 | loss: 0.12
update:340/2000, 耗时:0.00分/1.26分 | step: 27200 | performance: 1.4 | accuracy: 0.20 | loss: 0.07
update:345/2000, 耗时:0.00分/1.28分 | step: 27600 | performance: 1.4 | accuracy: 0.20 | loss: 0.05
update:350/2000, 耗时:0.00分/1.30分 | step: 28000 | performance: 1.4 | accuracy: 0.20 | loss: 0.07
Saving PPO weights in both H5 format and checkpoint @ update:353 
step: 28313 | worker_0@n_step_9: average total_reward after train data exhaustion : 154.6 | max total_reward: 234.0
step: 28314 | worker_1@n_step_9: average total_reward after train data exhaustion : 139.3 | max total_reward: 234.0
step: 28315 | worker_2@n_step_9: average total_reward after train data exhaustion : 126.7 | max total_reward: 234.0
step: 28316 | worker_3@n_step_9: average total_reward after train data exhaustion : 116.2 | max total_reward: 234.0
step: 28317 | worker_4@n_step_9: average total_reward after train data exhaustion : 107.4 | max total_reward: 234.0
step: 28318 | worker_5@n_step_9: average total_reward after train data exhaustion : 99.8 | max total_reward: 234.0
step: 28319 | worker_6@n_step_9: average total_reward after train data exhaustion : 93.2 | max total_reward: 234.0
step: 28320 | worker_7@n_step_9: average total_reward after train data exhaustion : 87.4 | max total_reward: 234.0
update:355/2000, 耗时:0.00分/1.32分 | step: 28400 | performance: 1.0 | accuracy: 0.10 | loss: 0.08
update:360/2000, 耗时:0.00分/1.34分 | step: 28800 | performance: 1.0 | accuracy: 0.08 | loss: 0.08
update:365/2000, 耗时:0.00分/1.36分 | step: 29200 | performance: 1.1 | accuracy: 0.11 | loss: 0.13
step: 29358 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 29360 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 29513 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:370/2000, 耗时:0.00分/1.38分 | step: 29600 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 29674 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 29675 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:375/2000, 耗时:0.00分/1.40分 | step: 30000 | performance: 1.1 | accuracy: 0.17 | loss: 0.08
step: 30397 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:380/2000, 耗时:0.00分/1.42分 | step: 30400 | performance: 1.1 | accuracy: 0.13 | loss: 0.10
step: 30553 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 30559 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 30715 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 30716 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:385/2000, 耗时:0.00分/1.44分 | step: 30800 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 30954 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:390/2000, 耗时:0.00分/1.45分 | step: 31200 | performance: 1.0 | accuracy: 0.12 | loss: 0.09
step: 31593 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:395/2000, 耗时:0.00分/1.47分 | step: 31600 | performance: 1.0 | accuracy: 0.11 | loss: 0.23
step: 31755 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
step: 31996 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
update:400/2000, 耗时:0.00分/1.49分 | step: 32000 | performance: 1.0 | accuracy: 0.12 | loss: 0.11
step: 32234 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:405/2000, 耗时:0.00分/1.51分 | step: 32400 | performance: 1.0 | accuracy: 0.12 | loss: 0.08
step: 32477 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
step: 32718 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
step: 32793 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:410/2000, 耗时:0.00分/1.53分 | step: 32800 | performance: 0.9 | accuracy: 0.11 | loss: 0.17
step: 33196 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 234.0
update:415/2000, 耗时:0.00分/1.55分 | step: 33200 | performance: 1.0 | accuracy: 0.09 | loss: 0.04
step: 33520 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 33599 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:420/2000, 耗时:0.00分/1.57分 | step: 33600 | performance: 1.0 | accuracy: 0.10 | loss: 0.08
step: 33677 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 33915 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 33993 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:425/2000, 耗时:0.00分/1.59分 | step: 34000 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 34078 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
step: 34396 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:430/2000, 耗时:0.00分/1.61分 | step: 34400 | performance: 1.0 | accuracy: 0.09 | loss: 0.07
step: 34720 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 34799 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:435/2000, 耗时:0.00分/1.63分 | step: 34800 | performance: 1.0 | accuracy: 0.10 | loss: 0.04
step: 35193 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 35195 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:440/2000, 耗时:0.00分/1.65分 | step: 35200 | performance: 1.0 | accuracy: 0.11 | loss: 0.06
step: 35278 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:445/2000, 耗时:0.00分/1.67分 | step: 35600 | performance: 1.0 | accuracy: 0.12 | loss: 0.04
step: 35754 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 35756 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:450/2000, 耗时:0.00分/1.69分 | step: 36000 | performance: 1.0 | accuracy: 0.14 | loss: 0.04
step: 36077 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 36313 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 36395 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:455/2000, 耗时:0.00分/1.71分 | step: 36400 | performance: 1.0 | accuracy: 0.11 | loss: 0.07
update:460/2000, 耗时:0.00分/1.73分 | step: 36800 | performance: 1.0 | accuracy: 0.12 | loss: 0.03
step: 36956 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:465/2000, 耗时:0.00分/1.75分 | step: 37200 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
step: 37280 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 37437 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 37513 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 37595 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 37598 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:470/2000, 耗时:0.00分/1.77分 | step: 37600 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
update:475/2000, 耗时:0.00分/1.78分 | step: 38000 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 38154 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 38236 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:480/2000, 耗时:0.00分/1.80分 | step: 38400 | performance: 1.0 | accuracy: 0.25 | loss: 0.04
step: 38559 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 38635 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 38640 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 38797 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 38798 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:485/2000, 耗时:0.00分/1.82分 | step: 38800 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 38873 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:490/2000, 耗时:0.00分/1.84分 | step: 39200 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 39596 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:495/2000, 耗时:0.00分/1.86分 | step: 39600 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 39837 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 39919 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 39995 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:500/2000, 耗时:0.00分/1.88分 | step: 40000 | performance: 1.0 | accuracy: 0.12 | loss: 0.06
step: 40078 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 40153 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:505/2000, 耗时:0.00分/1.89分 | step: 40400 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 40554 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 40796 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:510/2000, 耗时:0.00分/1.91分 | step: 40800 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 41035 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 41037 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 41039 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 41200 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:515/2000, 耗时:0.00分/1.93分 | step: 41200 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 41353 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 41438 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:520/2000, 耗时:0.00分/1.95分 | step: 41600 | performance: 1.0 | accuracy: 0.06 | loss: 0.08
step: 41754 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:525/2000, 耗时:0.00分/1.97分 | step: 42000 | performance: 1.1 | accuracy: 0.13 | loss: 0.08
step: 42079 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 42156 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 42235 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 42397 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 42400 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:530/2000, 耗时:0.00分/1.99分 | step: 42400 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 42638 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 42713 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:535/2000, 耗时:0.00分/2.01分 | step: 42800 | performance: 1.0 | accuracy: 0.06 | loss: 0.04
step: 42954 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:540/2000, 耗时:0.00分/2.02分 | step: 43200 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 43356 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 43435 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:545/2000, 耗时:0.00分/2.04分 | step: 43600 | performance: 1.0 | accuracy: 0.14 | loss: 0.06
step: 43680 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 43757 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 43838 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 43913 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:550/2000, 耗时:0.00分/2.06分 | step: 44000 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 44154 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:555/2000, 耗时:0.00分/2.08分 | step: 44400 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 44555 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 44556 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 44639 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:560/2000, 耗时:0.00分/2.10分 | step: 44800 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 45040 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 45117 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 234.0
step: 45198 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 234.0
update:565/2000, 耗时:0.00分/2.11分 | step: 45200 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 45273 | worker_0@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 234.0
update:570/2000, 耗时:0.00分/2.13分 | step: 45600 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 45839 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 45915 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 45916 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:575/2000, 耗时:0.00分/2.15分 | step: 46000 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 46313 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 46400 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:580/2000, 耗时:0.00分/2.17分 | step: 46400 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 46477 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 46558 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:585/2000, 耗时:0.00分/2.19分 | step: 46800 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 47199 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:590/2000, 耗时:0.00分/2.20分 | step: 47200 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 47275 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 47276 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 47513 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 47600 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:595/2000, 耗时:0.00分/2.22分 | step: 47600 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 47677 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 47758 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 47914 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:600/2000, 耗时:0.00分/2.24分 | step: 48000 | performance: 1.1 | accuracy: 0.12 | loss: 0.11
step: 48159 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
step: 48316 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:605/2000, 耗时:0.00分/2.26分 | step: 48400 | performance: 1.0 | accuracy: 0.12 | loss: 0.07
step: 48475 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
step: 48553 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
step: 48797 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:610/2000, 耗时:0.00分/2.28分 | step: 48800 | performance: 1.0 | accuracy: 0.17 | loss: 0.17
step: 49199 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:615/2000, 耗时:0.00分/2.30分 | step: 49200 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
step: 49438 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:620/2000, 耗时:0.00分/2.31分 | step: 49600 | performance: 1.0 | accuracy: 0.20 | loss: 0.07
step: 49676 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 49997 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:625/2000, 耗时:0.00分/2.33分 | step: 50000 | performance: 1.0 | accuracy: 0.25 | loss: 0.07
step: 50074 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 50240 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 50399 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:630/2000, 耗时:0.00分/2.35分 | step: 50400 | performance: 1.0 | accuracy: 0.33 | loss: 0.03
step: 50798 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:635/2000, 耗时:0.00分/2.37分 | step: 50800 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 50875 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 50953 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:640/2000, 耗时:0.00分/2.39分 | step: 51200 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 51274 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 51357 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 51439 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 51600 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:645/2000, 耗时:0.00分/2.40分 | step: 51600 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:650/2000, 耗时:0.00分/2.42分 | step: 52000 | performance: 1.0 | accuracy: 0.06 | loss: 0.06
step: 52076 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 52078 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 52153 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:655/2000, 耗时:0.00分/2.44分 | step: 52400 | performance: 1.0 | accuracy: 0.07 | loss: 0.11
step: 52479 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 52557 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:660/2000, 耗时:0.00分/2.46分 | step: 52800 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 52960 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:665/2000, 耗时:0.00分/2.47分 | step: 53200 | performance: 1.0 | accuracy: 0.08 | loss: 0.18
step: 53275 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 53356 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 53597 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:670/2000, 耗时:0.00分/2.49分 | step: 53600 | performance: 1.0 | accuracy: 0.08 | loss: 0.03
update:675/2000, 耗时:0.00分/2.51分 | step: 54000 | performance: 1.1 | accuracy: 0.27 | loss: 0.13
step: 54318 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:680/2000, 耗时:0.00分/2.53分 | step: 54400 | performance: 1.2 | accuracy: 0.13 | loss: 0.15
step: 54473 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
step: 54475 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
step: 54560 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
update:685/2000, 耗时:0.00分/2.55分 | step: 54800 | performance: 1.0 | accuracy: 0.08 | loss: 0.09
step: 55114 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:690/2000, 耗时:0.00分/2.56分 | step: 55200 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 55358 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
step: 55359 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
step: 55516 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:695/2000, 耗时:0.00分/2.58分 | step: 55600 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
step: 55753 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
update:700/2000, 耗时:0.00分/2.60分 | step: 56000 | performance: 1.1 | accuracy: 0.25 | loss: 0.25
step: 56239 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:705/2000, 耗时:0.00分/2.62分 | step: 56400 | performance: 1.2 | accuracy: 0.17 | loss: 0.21
update:710/2000, 耗时:0.00分/2.64分 | step: 56800 | performance: 1.2 | accuracy: 0.12 | loss: 0.07
step: 56875 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
step: 56953 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:715/2000, 耗时:0.00分/2.65分 | step: 57200 | performance: 1.0 | accuracy: 0.12 | loss: 0.20
step: 57519 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:720/2000, 耗时:0.00分/2.67分 | step: 57600 | performance: 1.0 | accuracy: 0.17 | loss: 0.10
update:725/2000, 耗时:0.00分/2.69分 | step: 58000 | performance: 1.0 | accuracy: 0.15 | loss: 0.15
step: 58396 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 234.0
update:730/2000, 耗时:0.00分/2.71分 | step: 58400 | performance: 1.0 | accuracy: 0.12 | loss: 0.18
step: 58479 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 234.0
update:735/2000, 耗时:0.00分/2.73分 | step: 58800 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
update:740/2000, 耗时:0.00分/2.75分 | step: 59200 | performance: 1.1 | accuracy: 0.17 | loss: 0.34
step: 59513 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.9 | max total_reward: 234.0
update:745/2000, 耗时:0.00分/2.76分 | step: 59600 | performance: 0.9 | accuracy: 0.12 | loss: 0.10
step: 59996 | worker_3@n_step_9: average total_reward after train data exhaustion : 2.0 | max total_reward: 234.0
update:750/2000, 耗时:0.00分/2.78分 | step: 60000 | performance: 1.0 | accuracy: 0.25 | loss: 0.08
update:755/2000, 耗时:0.00分/2.80分 | step: 60400 | performance: 1.0 | accuracy: 0.17 | loss: 0.12
step: 60553 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 234.0
update:760/2000, 耗时:0.00分/2.82分 | step: 60800 | performance: 1.0 | accuracy: 0.20 | loss: 0.06
step: 60877 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
update:765/2000, 耗时:0.00分/2.83分 | step: 61200 | performance: 1.0 | accuracy: 0.11 | loss: 0.12
step: 61276 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
step: 61514 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:770/2000, 耗时:0.00分/2.85分 | step: 61600 | performance: 1.1 | accuracy: 0.12 | loss: 0.10
step: 61917 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
step: 61995 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:775/2000, 耗时:0.00分/2.87分 | step: 62000 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 62400 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:780/2000, 耗时:0.00分/2.89分 | step: 62400 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 62476 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:785/2000, 耗时:0.00分/2.91分 | step: 62800 | performance: 1.0 | accuracy: 0.50 | loss: 0.06
step: 62957 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:790/2000, 耗时:0.00分/2.92分 | step: 63200 | performance: 1.1 | accuracy: 0.19 | loss: 0.14
step: 63436 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:795/2000, 耗时:0.00分/2.94分 | step: 63600 | performance: 1.2 | accuracy: 0.14 | loss: 0.25
step: 63753 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
step: 63920 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
update:800/2000, 耗时:0.00分/2.96分 | step: 64000 | performance: 1.0 | accuracy: 0.10 | loss: 0.08
step: 64078 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
step: 64237 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 234.0
update:805/2000, 耗时:0.00分/2.98分 | step: 64400 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
step: 64475 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
step: 64714 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
update:810/2000, 耗时:0.00分/3.00分 | step: 64800 | performance: 1.0 | accuracy: 0.12 | loss: 0.12
step: 65033 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
update:815/2000, 耗时:0.00分/3.01分 | step: 65200 | performance: 1.0 | accuracy: 0.11 | loss: 0.09
update:820/2000, 耗时:0.00分/3.03分 | step: 65600 | performance: 0.9 | accuracy: 0.12 | loss: 0.18
step: 65916 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
update:825/2000, 耗时:0.00分/3.05分 | step: 66000 | performance: 1.2 | accuracy: 0.19 | loss: 0.22
update:830/2000, 耗时:0.00分/3.07分 | step: 66400 | performance: 1.2 | accuracy: 0.15 | loss: 0.13
update:835/2000, 耗时:0.00分/3.08分 | step: 66800 | performance: 1.2 | accuracy: 0.11 | loss: 0.21
update:840/2000, 耗时:0.00分/3.10分 | step: 67200 | performance: 1.1 | accuracy: 0.14 | loss: 0.16
update:845/2000, 耗时:0.00分/3.12分 | step: 67600 | performance: 1.1 | accuracy: 0.13 | loss: 0.13
step: 67919 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:850/2000, 耗时:0.00分/3.14分 | step: 68000 | performance: 1.1 | accuracy: 0.13 | loss: 0.25
update:855/2000, 耗时:0.00分/3.15分 | step: 68400 | performance: 1.1 | accuracy: 0.13 | loss: 0.14
update:860/2000, 耗时:0.00分/3.17分 | step: 68800 | performance: 1.1 | accuracy: 0.13 | loss: 0.11
update:865/2000, 耗时:0.00分/3.19分 | step: 69200 | performance: 1.1 | accuracy: 0.13 | loss: 0.09
update:870/2000, 耗时:0.00分/3.21分 | step: 69600 | performance: 1.1 | accuracy: 0.13 | loss: 0.14
update:875/2000, 耗时:0.00分/3.22分 | step: 70000 | performance: 1.2 | accuracy: 0.12 | loss: 0.12
update:880/2000, 耗时:0.00分/3.24分 | step: 70400 | performance: 1.2 | accuracy: 0.12 | loss: 0.12
update:885/2000, 耗时:0.00分/3.26分 | step: 70800 | performance: 1.2 | accuracy: 0.12 | loss: 0.08
update:890/2000, 耗时:0.00分/3.28分 | step: 71200 | performance: 1.2 | accuracy: 0.12 | loss: 0.06
update:895/2000, 耗时:0.00分/3.30分 | step: 71600 | performance: 1.2 | accuracy: 0.12 | loss: 0.15
update:900/2000, 耗时:0.00分/3.32分 | step: 72000 | performance: 1.2 | accuracy: 0.12 | loss: 0.16
update:905/2000, 耗时:0.00分/3.33分 | step: 72400 | performance: 1.2 | accuracy: 0.11 | loss: 0.09
step: 72795 | worker_2@n_step_9: average total_reward after train data exhaustion : 2.6 | max total_reward: 234.0
update:910/2000, 耗时:0.00分/3.35分 | step: 72800 | performance: 1.2 | accuracy: 0.11 | loss: 0.07
update:915/2000, 耗时:0.00分/3.37分 | step: 73200 | performance: 1.3 | accuracy: 0.11 | loss: 0.10
step: 73353 | worker_0@n_step_9: average total_reward after train data exhaustion : 3.7 | max total_reward: 234.0
step: 73594 | worker_1@n_step_9: average total_reward after train data exhaustion : 3.7 | max total_reward: 234.0
update:920/2000, 耗时:0.00分/3.39分 | step: 73600 | performance: 1.3 | accuracy: 0.10 | loss: 0.09
step: 73995 | worker_2@n_step_9: average total_reward after train data exhaustion : 5.0 | max total_reward: 234.0
update:925/2000, 耗时:0.00分/3.41分 | step: 74000 | performance: 1.3 | accuracy: 0.10 | loss: 0.09
step: 74400 | worker_7@n_step_9: average total_reward after train data exhaustion : 7.5 | max total_reward: 234.0
update:930/2000, 耗时:0.00分/3.42分 | step: 74400 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 74713 | worker_0@n_step_9: average total_reward after train data exhaustion : 6.2 | max total_reward: 234.0
step: 74717 | worker_4@n_step_9: average total_reward after train data exhaustion : 6.2 | max total_reward: 234.0
update:935/2000, 耗时:0.00分/3.44分 | step: 74800 | performance: 1.0 | accuracy: 0.06 | loss: 0.09
update:940/2000, 耗时:0.00分/3.46分 | step: 75200 | performance: 1.0 | accuracy: 0.13 | loss: 0.07
step: 75278 | worker_5@n_step_9: average total_reward after train data exhaustion : 6.3 | max total_reward: 234.0
step: 75519 | worker_6@n_step_9: average total_reward after train data exhaustion : 3.8 | max total_reward: 234.0
update:945/2000, 耗时:0.00分/3.48分 | step: 75600 | performance: 0.9 | accuracy: 0.14 | loss: 0.16
step: 75674 | worker_1@n_step_9: average total_reward after train data exhaustion : 3.8 | max total_reward: 234.0
step: 75837 | worker_4@n_step_9: average total_reward after train data exhaustion : 4.0 | max total_reward: 234.0
step: 75993 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:950/2000, 耗时:0.00分/3.49分 | step: 76000 | performance: 1.0 | accuracy: 0.12 | loss: 0.11
step: 76076 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
update:955/2000, 耗时:0.00分/3.51分 | step: 76400 | performance: 0.9 | accuracy: 0.12 | loss: 0.18
step: 76638 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
step: 76794 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:960/2000, 耗时:0.00分/3.53分 | step: 76800 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:965/2000, 耗时:0.00分/3.55分 | step: 77200 | performance: 1.0 | accuracy: 0.12 | loss: 0.12
step: 77273 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
step: 77519 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 234.0
update:970/2000, 耗时:0.00分/3.57分 | step: 77600 | performance: 1.0 | accuracy: 0.14 | loss: 0.11
step: 77680 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
step: 77994 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 234.0
update:975/2000, 耗时:0.00分/3.58分 | step: 78000 | performance: 1.1 | accuracy: 0.12 | loss: 0.07
step: 78156 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 234.0
step: 78235 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 234.0
step: 78397 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 234.0
update:980/2000, 耗时:0.00分/3.60分 | step: 78400 | performance: 1.0 | accuracy: 0.12 | loss: 0.15
step: 78639 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:985/2000, 耗时:0.00分/3.62分 | step: 78800 | performance: 1.0 | accuracy: 0.14 | loss: 0.04
step: 78880 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 79114 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 79118 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:990/2000, 耗时:0.00分/3.64分 | step: 79200 | performance: 1.1 | accuracy: 0.12 | loss: 0.11
step: 79433 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 79597 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:995/2000, 耗时:0.00分/3.66分 | step: 79600 | performance: 1.1 | accuracy: 0.22 | loss: 0.14
update:1000/2000, 耗时:0.00分/3.68分 | step: 80000 | performance: 1.1 | accuracy: 0.12 | loss: 0.16
update:1005/2000, 耗时:0.00分/3.70分 | step: 80400 | performance: 1.0 | accuracy: 0.10 | loss: 0.19
update:1010/2000, 耗时:0.00分/3.71分 | step: 80800 | performance: 1.1 | accuracy: 0.13 | loss: 0.20
step: 81034 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
step: 81193 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 234.0
update:1015/2000, 耗时:0.00分/3.73分 | step: 81200 | performance: 1.2 | accuracy: 0.14 | loss: 0.14
update:1020/2000, 耗时:0.00分/3.75分 | step: 81600 | performance: 1.2 | accuracy: 0.10 | loss: 0.15
step: 81840 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 234.0
update:1025/2000, 耗时:0.00分/3.77分 | step: 82000 | performance: 1.1 | accuracy: 0.10 | loss: 0.16
step: 82233 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 234.0
step: 82317 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
update:1030/2000, 耗时:0.00分/3.79分 | step: 82400 | performance: 1.1 | accuracy: 0.20 | loss: 0.16
step: 82800 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:1035/2000, 耗时:0.00分/3.80分 | step: 82800 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 82959 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
step: 83198 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:1040/2000, 耗时:0.00分/3.82分 | step: 83200 | performance: 1.2 | accuracy: 0.14 | loss: 0.15
update:1045/2000, 耗时:0.00分/3.84分 | step: 83600 | performance: 1.0 | accuracy: 0.11 | loss: 0.09
step: 83673 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
update:1050/2000, 耗时:0.00分/3.86分 | step: 84000 | performance: 1.1 | accuracy: 0.12 | loss: 0.18
update:1055/2000, 耗时:0.00分/3.88分 | step: 84400 | performance: 1.1 | accuracy: 0.16 | loss: 0.10
step: 84478 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
step: 84559 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
update:1060/2000, 耗时:0.00分/3.90分 | step: 84800 | performance: 1.1 | accuracy: 0.15 | loss: 0.21
update:1065/2000, 耗时:0.00分/3.92分 | step: 85200 | performance: 1.3 | accuracy: 0.14 | loss: 0.22
update:1070/2000, 耗时:0.00分/3.94分 | step: 85600 | performance: 1.4 | accuracy: 0.16 | loss: 0.53
update:1075/2000, 耗时:0.00分/3.95分 | step: 86000 | performance: 1.4 | accuracy: 0.14 | loss: 0.26
update:1080/2000, 耗时:0.00分/3.97分 | step: 86400 | performance: 1.2 | accuracy: 0.14 | loss: 0.19
update:1085/2000, 耗时:0.00分/3.99分 | step: 86800 | performance: 1.2 | accuracy: 0.13 | loss: 0.11
update:1090/2000, 耗时:0.00分/4.01分 | step: 87200 | performance: 1.2 | accuracy: 0.12 | loss: 0.08
update:1095/2000, 耗时:0.00分/4.03分 | step: 87600 | performance: 1.2 | accuracy: 0.12 | loss: 0.06
update:1100/2000, 耗时:0.00分/4.05分 | step: 88000 | performance: 1.2 | accuracy: 0.13 | loss: 0.13
update:1105/2000, 耗时:0.00分/4.06分 | step: 88400 | performance: 1.3 | accuracy: 0.12 | loss: 0.07
update:1110/2000, 耗时:0.00分/4.08分 | step: 88800 | performance: 1.3 | accuracy: 0.11 | loss: 0.09
update:1115/2000, 耗时:0.00分/4.10分 | step: 89200 | performance: 1.3 | accuracy: 0.11 | loss: 0.06
update:1120/2000, 耗时:0.00分/4.12分 | step: 89600 | performance: 1.2 | accuracy: 0.11 | loss: 0.08
update:1125/2000, 耗时:0.00分/4.14分 | step: 90000 | performance: 1.2 | accuracy: 0.11 | loss: 0.08
step: 90078 | worker_5@n_step_9: average total_reward after train data exhaustion : 2.3 | max total_reward: 234.0
update:1130/2000, 耗时:0.00分/4.15分 | step: 90400 | performance: 1.2 | accuracy: 0.11 | loss: 0.09
update:1135/2000, 耗时:0.00分/4.17分 | step: 90800 | performance: 1.2 | accuracy: 0.11 | loss: 0.08
step: 90958 | worker_5@n_step_9: average total_reward after train data exhaustion : 2.4 | max total_reward: 234.0
update:1140/2000, 耗时:0.00分/4.19分 | step: 91200 | performance: 1.3 | accuracy: 0.10 | loss: 0.12
update:1145/2000, 耗时:0.00分/4.21分 | step: 91600 | performance: 1.3 | accuracy: 0.10 | loss: 0.07
update:1150/2000, 耗时:0.00分/4.23分 | step: 92000 | performance: 1.0 | accuracy: 0.06 | loss: 0.17
step: 92158 | worker_5@n_step_9: average total_reward after train data exhaustion : 4.7 | max total_reward: 234.0
update:1155/2000, 耗时:0.00分/4.25分 | step: 92400 | performance: 1.0 | accuracy: 0.12 | loss: 0.20
step: 92635 | worker_2@n_step_9: average total_reward after train data exhaustion : 4.5 | max total_reward: 234.0
update:1160/2000, 耗时:0.00分/4.26分 | step: 92800 | performance: 1.1 | accuracy: 0.17 | loss: 0.14
update:1165/2000, 耗时:0.00分/4.28分 | step: 93200 | performance: 1.0 | accuracy: 0.21 | loss: 0.17
update:1170/2000, 耗时:0.00分/4.30分 | step: 93600 | performance: 0.9 | accuracy: 0.16 | loss: 0.44
update:1175/2000, 耗时:0.00分/4.32分 | step: 94000 | performance: 0.9 | accuracy: 0.14 | loss: 0.22
update:1180/2000, 耗时:0.00分/4.34分 | step: 94400 | performance: 0.9 | accuracy: 0.14 | loss: 0.18
update:1185/2000, 耗时:0.00分/4.36分 | step: 94800 | performance: 0.9 | accuracy: 0.14 | loss: 0.09
update:1190/2000, 耗时:0.00分/4.38分 | step: 95200 | performance: 0.9 | accuracy: 0.14 | loss: 0.28
update:1195/2000, 耗时:0.00分/4.40分 | step: 95600 | performance: 0.9 | accuracy: 0.14 | loss: 0.31
update:1200/2000, 耗时:0.00分/4.41分 | step: 96000 | performance: 0.9 | accuracy: 0.14 | loss: 0.24
update:1205/2000, 耗时:0.00分/4.43分 | step: 96400 | performance: 0.9 | accuracy: 0.15 | loss: 0.24
update:1210/2000, 耗时:0.00分/4.45分 | step: 96800 | performance: 0.9 | accuracy: 0.15 | loss: 0.23
update:1215/2000, 耗时:0.00分/4.47分 | step: 97200 | performance: 0.9 | accuracy: 0.14 | loss: 0.41
update:1220/2000, 耗时:0.00分/4.49分 | step: 97600 | performance: 1.0 | accuracy: 0.15 | loss: 0.17
update:1225/2000, 耗时:0.00分/4.51分 | step: 98000 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:1230/2000, 耗时:0.00分/4.53分 | step: 98400 | performance: 0.9 | accuracy: 0.14 | loss: 0.17
update:1235/2000, 耗时:0.00分/4.55分 | step: 98800 | performance: 0.9 | accuracy: 0.14 | loss: 0.17
update:1240/2000, 耗时:0.00分/4.57分 | step: 99200 | performance: 0.9 | accuracy: 0.13 | loss: 0.07
update:1245/2000, 耗时:0.00分/4.59分 | step: 99600 | performance: 0.9 | accuracy: 0.13 | loss: 0.08
update:1250/2000, 耗时:0.00分/4.61分 | step: 100000 | performance: 0.9 | accuracy: 0.13 | loss: 0.05
update:1255/2000, 耗时:0.00分/4.63分 | step: 100400 | performance: 0.8 | accuracy: 0.12 | loss: 0.08
update:1260/2000, 耗时:0.00分/4.64分 | step: 100800 | performance: 0.8 | accuracy: 0.12 | loss: 0.06
step: 101116 | worker_3@n_step_9: average total_reward after train data exhaustion : 8.9 | max total_reward: 234.0
update:1265/2000, 耗时:0.00分/4.66分 | step: 101200 | performance: 0.9 | accuracy: 0.11 | loss: 0.08
update:1270/2000, 耗时:0.00分/4.68分 | step: 101600 | performance: 0.8 | accuracy: 0.11 | loss: 0.08
update:1275/2000, 耗时:0.00分/4.70分 | step: 102000 | performance: 0.8 | accuracy: 0.11 | loss: 0.08
step: 102396 | worker_3@n_step_9: average total_reward after train data exhaustion : 8.8 | max total_reward: 234.0
update:1280/2000, 耗时:0.00分/4.72分 | step: 102400 | performance: 0.8 | accuracy: 0.11 | loss: 0.07
update:1285/2000, 耗时:0.00分/4.74分 | step: 102800 | performance: 0.9 | accuracy: 0.11 | loss: 0.05
update:1290/2000, 耗时:0.00分/4.76分 | step: 103200 | performance: 0.9 | accuracy: 0.11 | loss: 0.06
step: 103596 | worker_3@n_step_9: average total_reward after train data exhaustion : 8.0 | max total_reward: 234.0
update:1295/2000, 耗时:0.00分/4.77分 | step: 103600 | performance: 0.9 | accuracy: 0.11 | loss: 0.23
update:1300/2000, 耗时:0.00分/4.79分 | step: 104000 | performance: 0.9 | accuracy: 0.11 | loss: 0.06
update:1305/2000, 耗时:0.00分/4.81分 | step: 104400 | performance: 0.9 | accuracy: 0.11 | loss: 0.18
update:1310/2000, 耗时:0.00分/4.83分 | step: 104800 | performance: 0.8 | accuracy: 0.11 | loss: 0.12
update:1315/2000, 耗时:0.00分/4.85分 | step: 105200 | performance: 0.9 | accuracy: 0.11 | loss: 0.17
step: 105273 | worker_0@n_step_9: average total_reward after train data exhaustion : 10.8 | max total_reward: 234.0
update:1320/2000, 耗时:0.00分/4.86分 | step: 105600 | performance: 0.9 | accuracy: 0.11 | loss: 0.10
update:1325/2000, 耗时:0.00分/4.88分 | step: 106000 | performance: 0.9 | accuracy: 0.11 | loss: 0.11
step: 106396 | worker_3@n_step_9: average total_reward after train data exhaustion : 8.3 | max total_reward: 234.0
update:1330/2000, 耗时:0.00分/4.90分 | step: 106400 | performance: 0.8 | accuracy: 0.11 | loss: 0.14
step: 106633 | worker_0@n_step_9: average total_reward after train data exhaustion : 7.1 | max total_reward: 234.0
step: 106637 | worker_4@n_step_9: average total_reward after train data exhaustion : 10.2 | max total_reward: 234.0
update:1335/2000, 耗时:0.00分/4.92分 | step: 106800 | performance: 0.8 | accuracy: 0.11 | loss: 0.16
update:1340/2000, 耗时:0.00分/4.93分 | step: 107200 | performance: 0.8 | accuracy: 0.11 | loss: 0.08
step: 107596 | worker_3@n_step_9: average total_reward after train data exhaustion : 6.9 | max total_reward: 234.0
update:1345/2000, 耗时:0.00分/4.95分 | step: 107600 | performance: 0.8 | accuracy: 0.11 | loss: 0.08
step: 107677 | worker_4@n_step_9: average total_reward after train data exhaustion : 6.9 | max total_reward: 234.0
step: 107993 | worker_0@n_step_9: average total_reward after train data exhaustion : 6.8 | max total_reward: 234.0
update:1350/2000, 耗时:0.00分/4.97分 | step: 108000 | performance: 0.8 | accuracy: 0.11 | loss: 0.03
update:1355/2000, 耗时:0.00分/4.99分 | step: 108400 | performance: 0.8 | accuracy: 0.11 | loss: 0.09
step: 108796 | worker_3@n_step_9: average total_reward after train data exhaustion : 7.7 | max total_reward: 234.0
update:1360/2000, 耗时:0.00分/5.01分 | step: 108800 | performance: 0.8 | accuracy: 0.11 | loss: 0.14
update:1365/2000, 耗时:0.00分/5.03分 | step: 109200 | performance: 0.8 | accuracy: 0.11 | loss: 0.09
update:1370/2000, 耗时:0.00分/5.04分 | step: 109600 | performance: 0.8 | accuracy: 0.10 | loss: 0.17
step: 109677 | worker_4@n_step_9: average total_reward after train data exhaustion : 4.7 | max total_reward: 234.0
update:1375/2000, 耗时:0.00分/5.06分 | step: 110000 | performance: 0.9 | accuracy: 0.10 | loss: 0.22
step: 110396 | worker_3@n_step_9: average total_reward after train data exhaustion : 4.9 | max total_reward: 234.0
update:1380/2000, 耗时:0.00分/5.08分 | step: 110400 | performance: 0.8 | accuracy: 0.10 | loss: 0.17
update:1385/2000, 耗时:0.00分/5.10分 | step: 110800 | performance: 0.9 | accuracy: 0.10 | loss: 0.04
update:1390/2000, 耗时:0.00分/5.12分 | step: 111200 | performance: 0.9 | accuracy: 0.10 | loss: 0.07
step: 111596 | worker_3@n_step_9: average total_reward after train data exhaustion : 5.1 | max total_reward: 234.0
update:1395/2000, 耗时:0.00分/5.13分 | step: 111600 | performance: 0.9 | accuracy: 0.10 | loss: 0.11
step: 111674 | worker_1@n_step_9: average total_reward after train data exhaustion : 5.2 | max total_reward: 234.0
update:1400/2000, 耗时:0.00分/5.15分 | step: 112000 | performance: 1.0 | accuracy: 0.17 | loss: 0.03
step: 112077 | worker_4@n_step_9: average total_reward after train data exhaustion : 4.4 | max total_reward: 234.0
step: 112393 | worker_0@n_step_9: average total_reward after train data exhaustion : 4.3 | max total_reward: 234.0
update:1405/2000, 耗时:0.00分/5.17分 | step: 112400 | performance: 1.1 | accuracy: 0.14 | loss: 0.06
update:1410/2000, 耗时:0.00分/5.19分 | step: 112800 | performance: 1.0 | accuracy: 0.13 | loss: 0.10
step: 112876 | worker_3@n_step_9: average total_reward after train data exhaustion : 7.4 | max total_reward: 234.0
update:1415/2000, 耗时:0.00分/5.21分 | step: 113200 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 113357 | worker_4@n_step_9: average total_reward after train data exhaustion : 7.3 | max total_reward: 234.0
step: 113600 | worker_7@n_step_9: average total_reward after train data exhaustion : 4.4 | max total_reward: 234.0
update:1420/2000, 耗时:0.00分/5.22分 | step: 113600 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 113919 | worker_6@n_step_9: average total_reward after train data exhaustion : 7.5 | max total_reward: 234.0
update:1425/2000, 耗时:0.00分/5.24分 | step: 114000 | performance: 1.0 | accuracy: 0.06 | loss: 0.04
step: 114076 | worker_3@n_step_9: average total_reward after train data exhaustion : 4.2 | max total_reward: 234.0
step: 114154 | worker_1@n_step_9: average total_reward after train data exhaustion : 7.7 | max total_reward: 234.0
step: 114155 | worker_2@n_step_9: average total_reward after train data exhaustion : 7.7 | max total_reward: 234.0
step: 114398 | worker_5@n_step_9: average total_reward after train data exhaustion : 7.6 | max total_reward: 234.0
update:1430/2000, 耗时:0.00分/5.26分 | step: 114400 | performance: 1.0 | accuracy: 0.07 | loss: 0.03
step: 114557 | worker_4@n_step_9: average total_reward after train data exhaustion : 7.7 | max total_reward: 234.0
step: 114800 | worker_7@n_step_9: average total_reward after train data exhaustion : 7.7 | max total_reward: 234.0
update:1435/2000, 耗时:0.00分/5.28分 | step: 114800 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
update:1440/2000, 耗时:0.00分/5.29分 | step: 115200 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 115274 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 115276 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 115355 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 115598 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 115599 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:1445/2000, 耗时:0.00分/5.31分 | step: 115600 | performance: 1.1 | accuracy: 0.11 | loss: 0.12
step: 115837 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 116000 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:1450/2000, 耗时:0.00分/5.33分 | step: 116000 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 116236 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:1455/2000, 耗时:0.00分/5.35分 | step: 116400 | performance: 1.0 | accuracy: 0.06 | loss: 0.07
step: 116478 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:1460/2000, 耗时:0.00分/5.37分 | step: 116800 | performance: 1.1 | accuracy: 0.13 | loss: 0.12
step: 116873 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
step: 117037 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
step: 117196 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:1465/2000, 耗时:0.00分/5.38分 | step: 117200 | performance: 1.0 | accuracy: 0.14 | loss: 0.12
step: 117280 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:1470/2000, 耗时:0.00分/5.40分 | step: 117600 | performance: 1.0 | accuracy: 0.17 | loss: 0.07
step: 117678 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 117754 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
step: 117755 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
step: 117993 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 117999 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 234.0
update:1475/2000, 耗时:0.00分/5.42分 | step: 118000 | performance: 1.1 | accuracy: 0.14 | loss: 0.05
update:1480/2000, 耗时:0.00分/5.44分 | step: 118400 | performance: 1.0 | accuracy: 0.21 | loss: 0.16
update:1485/2000, 耗时:0.00分/5.46分 | step: 118800 | performance: 1.1 | accuracy: 0.11 | loss: 0.12
update:1490/2000, 耗时:0.00分/5.47分 | step: 119200 | performance: 1.0 | accuracy: 0.25 | loss: 0.16
update:1495/2000, 耗时:0.00分/5.49分 | step: 119600 | performance: 0.9 | accuracy: 0.15 | loss: 0.45
update:1500/2000, 耗时:0.00分/5.51分 | step: 120000 | performance: 0.9 | accuracy: 0.10 | loss: 0.15
step: 120317 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:1505/2000, 耗时:0.00分/5.53分 | step: 120400 | performance: 1.0 | accuracy: 0.25 | loss: 0.12
step: 120640 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
update:1510/2000, 耗时:0.00分/5.55分 | step: 120800 | performance: 1.0 | accuracy: 0.33 | loss: 0.15
update:1515/2000, 耗时:0.00分/5.56分 | step: 121200 | performance: 1.0 | accuracy: 0.14 | loss: 0.28
update:1520/2000, 耗时:0.00分/5.58分 | step: 121600 | performance: 1.0 | accuracy: 0.18 | loss: 0.25
update:1525/2000, 耗时:0.00分/5.60分 | step: 122000 | performance: 1.1 | accuracy: 0.11 | loss: 0.18
step: 122400 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.8 | max total_reward: 234.0
update:1530/2000, 耗时:0.00分/5.61分 | step: 122400 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
update:1535/2000, 耗时:0.00分/5.63分 | step: 122800 | performance: 1.1 | accuracy: 0.19 | loss: 0.21
update:1540/2000, 耗时:0.00分/5.65分 | step: 123200 | performance: 1.2 | accuracy: 0.15 | loss: 0.18
update:1545/2000, 耗时:0.00分/5.67分 | step: 123600 | performance: 1.3 | accuracy: 0.14 | loss: 0.29
update:1550/2000, 耗时:0.00分/5.69分 | step: 124000 | performance: 1.3 | accuracy: 0.13 | loss: 0.12
update:1555/2000, 耗时:0.00分/5.70分 | step: 124400 | performance: 1.4 | accuracy: 0.12 | loss: 0.28
step: 124637 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:1560/2000, 耗时:0.00分/5.72分 | step: 124800 | performance: 1.4 | accuracy: 0.12 | loss: 0.09
update:1565/2000, 耗时:0.00分/5.74分 | step: 125200 | performance: 1.4 | accuracy: 0.12 | loss: 0.10
update:1570/2000, 耗时:0.00分/5.76分 | step: 125600 | performance: 1.4 | accuracy: 0.11 | loss: 0.04
update:1575/2000, 耗时:0.00分/5.78分 | step: 126000 | performance: 1.5 | accuracy: 0.12 | loss: 0.16
update:1580/2000, 耗时:0.00分/5.79分 | step: 126400 | performance: 1.5 | accuracy: 0.12 | loss: 0.17
step: 126797 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
update:1585/2000, 耗时:0.00分/5.81分 | step: 126800 | performance: 1.7 | accuracy: 0.12 | loss: 0.09
update:1590/2000, 耗时:0.00分/5.83分 | step: 127200 | performance: 1.7 | accuracy: 0.12 | loss: 0.11
update:1595/2000, 耗时:0.00分/5.85分 | step: 127600 | performance: 1.7 | accuracy: 0.11 | loss: 0.12
update:1600/2000, 耗时:0.00分/5.86分 | step: 128000 | performance: 1.7 | accuracy: 0.11 | loss: 0.07
update:1605/2000, 耗时:0.00分/5.88分 | step: 128400 | performance: 1.7 | accuracy: 0.11 | loss: 0.12
step: 128797 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:1610/2000, 耗时:0.00分/5.90分 | step: 128800 | performance: 1.7 | accuracy: 0.11 | loss: 0.10
step: 129033 | worker_0@n_step_9: average total_reward after train data exhaustion : 4.5 | max total_reward: 234.0
update:1615/2000, 耗时:0.00分/5.92分 | step: 129200 | performance: 1.7 | accuracy: 0.11 | loss: 0.08
step: 129275 | worker_2@n_step_9: average total_reward after train data exhaustion : 4.3 | max total_reward: 234.0
update:1620/2000, 耗时:0.00分/5.93分 | step: 129600 | performance: 1.7 | accuracy: 0.10 | loss: 0.22
update:1625/2000, 耗时:0.00分/5.95分 | step: 130000 | performance: 1.7 | accuracy: 0.10 | loss: 0.07
step: 130074 | worker_1@n_step_9: average total_reward after train data exhaustion : 4.5 | max total_reward: 234.0
step: 130077 | worker_4@n_step_9: average total_reward after train data exhaustion : 4.5 | max total_reward: 234.0
step: 130233 | worker_0@n_step_9: average total_reward after train data exhaustion : 4.4 | max total_reward: 234.0
update:1630/2000, 耗时:0.00分/5.97分 | step: 130400 | performance: 1.0 | accuracy: 0.20 | loss: 0.10
step: 130715 | worker_2@n_step_9: average total_reward after train data exhaustion : 6.1 | max total_reward: 234.0
update:1635/2000, 耗时:0.00分/5.98分 | step: 130800 | performance: 1.0 | accuracy: 0.25 | loss: 0.10
step: 131114 | worker_1@n_step_9: average total_reward after train data exhaustion : 2.9 | max total_reward: 234.0
step: 131197 | worker_4@n_step_9: average total_reward after train data exhaustion : 3.0 | max total_reward: 234.0
update:1640/2000, 耗时:0.00分/6.00分 | step: 131200 | performance: 1.0 | accuracy: 0.17 | loss: 0.07
step: 131513 | worker_0@n_step_9: average total_reward after train data exhaustion : 3.0 | max total_reward: 234.0
step: 131595 | worker_2@n_step_9: average total_reward after train data exhaustion : 3.0 | max total_reward: 234.0
update:1645/2000, 耗时:0.00分/6.02分 | step: 131600 | performance: 1.0 | accuracy: 0.20 | loss: 0.10
update:1650/2000, 耗时:0.00分/6.04分 | step: 132000 | performance: 1.0 | accuracy: 0.25 | loss: 0.13
step: 132237 | worker_4@n_step_9: average total_reward after train data exhaustion : 3.1 | max total_reward: 234.0
update:1655/2000, 耗时:0.00分/6.06分 | step: 132400 | performance: 1.1 | accuracy: 0.11 | loss: 0.19
update:1660/2000, 耗时:0.00分/6.07分 | step: 132800 | performance: 1.1 | accuracy: 0.17 | loss: 0.15
step: 132875 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.2 | max total_reward: 234.0
update:1665/2000, 耗时:0.00分/6.09分 | step: 133200 | performance: 1.1 | accuracy: 0.12 | loss: 0.16
step: 133360 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:1670/2000, 耗时:0.00分/6.11分 | step: 133600 | performance: 1.0 | accuracy: 0.17 | loss: 0.30
update:1675/2000, 耗时:0.00分/6.13分 | step: 134000 | performance: 1.1 | accuracy: 0.14 | loss: 0.27
update:1680/2000, 耗时:0.00分/6.14分 | step: 134400 | performance: 1.2 | accuracy: 0.14 | loss: 0.24
update:1685/2000, 耗时:0.00分/6.16分 | step: 134800 | performance: 1.2 | accuracy: 0.12 | loss: 0.13
update:1690/2000, 耗时:0.00分/6.18分 | step: 135200 | performance: 1.3 | accuracy: 0.10 | loss: 0.16
update:1695/2000, 耗时:0.00分/6.20分 | step: 135600 | performance: 1.1 | accuracy: 0.11 | loss: 0.21
update:1700/2000, 耗时:0.00分/6.21分 | step: 136000 | performance: 1.1 | accuracy: 0.11 | loss: 0.07
update:1705/2000, 耗时:0.00分/6.23分 | step: 136400 | performance: 1.1 | accuracy: 0.11 | loss: 0.11
update:1710/2000, 耗时:0.00分/6.25分 | step: 136800 | performance: 1.1 | accuracy: 0.10 | loss: 0.06
update:1715/2000, 耗时:0.00分/6.27分 | step: 137200 | performance: 1.1 | accuracy: 0.14 | loss: 0.09
update:1720/2000, 耗时:0.00分/6.29分 | step: 137600 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
step: 137680 | worker_7@n_step_9: average total_reward after train data exhaustion : 4.9 | max total_reward: 234.0
step: 137917 | worker_4@n_step_9: average total_reward after train data exhaustion : 4.8 | max total_reward: 234.0
update:1725/2000, 耗时:0.00分/6.31分 | step: 138000 | performance: 1.0 | accuracy: 0.17 | loss: 0.02
update:1730/2000, 耗时:0.00分/6.33分 | step: 138400 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 138558 | worker_5@n_step_9: average total_reward after train data exhaustion : 9.5 | max total_reward: 234.0
step: 138795 | worker_2@n_step_9: average total_reward after train data exhaustion : 10.3 | max total_reward: 234.0
update:1735/2000, 耗时:0.00分/6.35分 | step: 138800 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 139040 | worker_7@n_step_9: average total_reward after train data exhaustion : 6.8 | max total_reward: 234.0
step: 139117 | worker_4@n_step_9: average total_reward after train data exhaustion : 6.8 | max total_reward: 234.0
step: 139193 | worker_0@n_step_9: average total_reward after train data exhaustion : 6.9 | max total_reward: 234.0
update:1740/2000, 耗时:0.00分/6.37分 | step: 139200 | performance: 1.1 | accuracy: 0.15 | loss: 0.06
step: 139354 | worker_1@n_step_9: average total_reward after train data exhaustion : 6.9 | max total_reward: 234.0
step: 139519 | worker_6@n_step_9: average total_reward after train data exhaustion : 2.9 | max total_reward: 234.0
update:1745/2000, 耗时:0.00分/6.39分 | step: 139600 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 139758 | worker_5@n_step_9: average total_reward after train data exhaustion : 2.1 | max total_reward: 234.0
update:1750/2000, 耗时:0.00分/6.40分 | step: 140000 | performance: 1.0 | accuracy: 0.25 | loss: 0.10
step: 140157 | worker_4@n_step_9: average total_reward after train data exhaustion : 4.5 | max total_reward: 234.0
step: 140236 | worker_3@n_step_9: average total_reward after train data exhaustion : 4.4 | max total_reward: 234.0
step: 140240 | worker_7@n_step_9: average total_reward after train data exhaustion : 4.4 | max total_reward: 234.0
step: 140393 | worker_0@n_step_9: average total_reward after train data exhaustion : 4.3 | max total_reward: 234.0
update:1755/2000, 耗时:0.00分/6.42分 | step: 140400 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 140714 | worker_1@n_step_9: average total_reward after train data exhaustion : 4.2 | max total_reward: 234.0
update:1760/2000, 耗时:0.00分/6.44分 | step: 140800 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 140879 | worker_6@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 234.0
step: 141118 | worker_5@n_step_9: average total_reward after train data exhaustion : 0.9 | max total_reward: 234.0
update:1765/2000, 耗时:0.00分/6.46分 | step: 141200 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 141517 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 141596 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 141600 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1770/2000, 耗时:0.00分/6.48分 | step: 141600 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 141753 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1775/2000, 耗时:0.00分/6.50分 | step: 142000 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 142074 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 142239 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 142395 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1780/2000, 耗时:0.00分/6.52分 | step: 142400 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 142478 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1785/2000, 耗时:0.00分/6.53分 | step: 142800 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 142877 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 142956 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 142960 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 143113 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1790/2000, 耗时:0.00分/6.55分 | step: 143200 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 143434 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 143599 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1795/2000, 耗时:0.00分/6.57分 | step: 143600 | performance: 1.0 | accuracy: 0.08 | loss: 0.06
step: 143755 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 143838 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1800/2000, 耗时:0.00分/6.59分 | step: 144000 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 144237 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 144316 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 144320 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1805/2000, 耗时:0.00分/6.61分 | step: 144400 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 144473 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 144794 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1810/2000, 耗时:0.00分/6.63分 | step: 144800 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 144959 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 145115 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 145198 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1815/2000, 耗时:0.00分/6.65分 | step: 145200 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 145597 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1820/2000, 耗时:0.00分/6.67分 | step: 145600 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
step: 145676 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 145680 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 145833 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1825/2000, 耗时:0.00分/6.69分 | step: 146000 | performance: 1.0 | accuracy: 0.17 | loss: 0.06
step: 146154 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 146319 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1830/2000, 耗时:0.00分/6.70分 | step: 146400 | performance: 1.0 | accuracy: 0.20 | loss: 0.05
step: 146475 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 146558 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1835/2000, 耗时:0.00分/6.72分 | step: 146800 | performance: 1.0 | accuracy: 0.25 | loss: 0.06
step: 146957 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 147036 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 147040 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 147193 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1840/2000, 耗时:0.00分/6.74分 | step: 147200 | performance: 1.0 | accuracy: 0.33 | loss: 0.06
step: 147514 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1845/2000, 耗时:0.00分/6.76分 | step: 147600 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 147679 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 147835 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 147918 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1850/2000, 耗时:0.00分/6.78分 | step: 148000 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 148317 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 148396 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 148400 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1855/2000, 耗时:0.00分/6.80分 | step: 148400 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 148553 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1860/2000, 耗时:0.00分/6.82分 | step: 148800 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 148874 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 149039 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 149195 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1865/2000, 耗时:0.00分/6.84分 | step: 149200 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 149278 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1870/2000, 耗时:0.00分/6.85分 | step: 149600 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 149677 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 149756 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 149760 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 149913 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1875/2000, 耗时:0.00分/6.87分 | step: 150000 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 150234 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 150399 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1880/2000, 耗时:0.00分/6.89分 | step: 150400 | performance: 1.0 | accuracy: 0.08 | loss: 0.06
step: 150555 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 150638 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1885/2000, 耗时:0.00分/6.91分 | step: 150800 | performance: 1.0 | accuracy: 0.09 | loss: 0.06
step: 151037 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 151113 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 151116 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 151120 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:1890/2000, 耗时:0.00分/6.93分 | step: 151200 | performance: 1.0 | accuracy: 0.10 | loss: 0.06
step: 151594 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 151599 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1895/2000, 耗时:0.00分/6.95分 | step: 151600 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 151915 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 151998 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1900/2000, 耗时:0.00分/6.97分 | step: 152000 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 152397 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1905/2000, 耗时:0.00分/6.98分 | step: 152400 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
step: 152473 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 152476 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 152480 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1910/2000, 耗时:0.00分/7.00分 | step: 152800 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 152954 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 152959 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 153115 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1915/2000, 耗时:0.00分/7.02分 | step: 153200 | performance: 1.0 | accuracy: 0.20 | loss: 0.05
step: 153358 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1920/2000, 耗时:0.00分/7.04分 | step: 153600 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 153757 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 153833 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 153836 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 153840 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:1925/2000, 耗时:0.00分/7.06分 | step: 154000 | performance: 1.0 | accuracy: 0.33 | loss: 0.06
step: 154159 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 154314 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1930/2000, 耗时:0.00分/7.07分 | step: 154400 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 154475 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 154718 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1935/2000, 耗时:0.00分/7.09分 | step: 154800 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 154957 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 155040 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 155193 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 155196 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1940/2000, 耗时:0.00分/7.11分 | step: 155200 | performance: 1.0 | accuracy: 0.33 | loss: 0.06
step: 155519 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1945/2000, 耗时:0.00分/7.13分 | step: 155600 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 155675 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1950/2000, 耗时:0.00分/7.15分 | step: 156000 | performance: 1.1 | accuracy: 0.17 | loss: 0.08
step: 156078 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 156240 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 156316 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 156393 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1955/2000, 耗时:0.00分/7.17分 | step: 156400 | performance: 1.0 | accuracy: 0.33 | loss: 0.06
step: 156714 | worker_1@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
step: 156799 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:1960/2000, 耗时:0.00分/7.19分 | step: 156800 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 157035 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1965/2000, 耗时:0.00分/7.20分 | step: 157200 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 157438 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 157517 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 157600 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1970/2000, 耗时:0.00分/7.22分 | step: 157600 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 157676 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
step: 157753 | worker_0@n_step_9: average total_reward after train data exhaustion : 1.0 | max total_reward: 234.0
update:1975/2000, 耗时:0.00分/7.24分 | step: 158000 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 158159 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.1 | max total_reward: 234.0
update:1980/2000, 耗时:0.00分/7.26分 | step: 158400 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 158800 | worker_7@n_step_9: average total_reward after train data exhaustion : 1.3 | max total_reward: 234.0
update:1985/2000, 耗时:0.00分/7.28分 | step: 158800 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 158956 | worker_3@n_step_9: average total_reward after train data exhaustion : 1.4 | max total_reward: 234.0
step: 159117 | worker_4@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 234.0
step: 159199 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
update:1990/2000, 耗时:0.00分/7.30分 | step: 159200 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 159518 | worker_5@n_step_9: average total_reward after train data exhaustion : 1.5 | max total_reward: 234.0
update:1995/2000, 耗时:0.00分/7.32分 | step: 159600 | performance: 1.1 | accuracy: 0.25 | loss: 0.15
  0%|          | 0/406 [00:00<?, ?it/s]100%|| 406/406 [00:00<00:00, 101707.43it/s]
update:2000/2000, 耗时:0.00分/7.34分 | step: 160000 | performance: 1.0 | accuracy: 0.13 | loss: 0.05
----------------------------------------finished----------------------------------------
==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1000.00
2023-07-24T12:00:00 | net performance [%] = 0.0000
2023-07-24T12:00:00 | number of trades [#] = 0
==================================================
Trial 23 Complete [00h 07m 47s]
net_wealth: 1000.0

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 03h 11m 08s

Search: Running Trial #24

Value             |Best Value So Far |Hyperparameter
1                 |1                 |horizon
365               |730               |lookback
True              |False             |MarketFactor
5                 |3                 |lags
0.8               |0.92              |gamma
32                |32                |batch_size
32                |1                 |n_step
0.94              |0.94              |gae_lambda
0.1               |5                 |gradient_clip_norm
3                 |5                 |epochs
0.0005            |0.0001            |actor_lr
1e-05             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4300.000000   4301.000000
mean      0.000435    20113.607657  ...   20173.020481  20169.373185
std       0.027833    16040.642334  ...   16078.674434  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7736.967529   7730.930176
50%       0.000642    11571.842969  ...   11753.029785  11751.469727
75%       0.011590    29894.706152  ...   30013.548340  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 01:14:31.079882023-07-28 01:14:31.079907: I tensorflow/core/platform/cpu_featur2023-07-28 01:14:31.079943: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in28023:-0e _2I g7-28 01:14:31.0ua2t3-07-280r d08003.1:6cc1: I4::142] 31 tens.This 0o8Tensr0053fl:orFl oI ew/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the folotensorflow/corewl nsorflb/iowpnarliyatform/c npius opt_gif mized CewPaiUtt uhir e_ongnustrard operformwu20e23-07.-2/AcPI Doececpre/:a 1pnce-clatNeurrfi4caolr2ti m/cpNoetut]i_wn 8feso ca rki Ln laT hoibrarpery (oiations:  ApnsVer XeDNN TAftu)eVnX2so
orm20r0 to1T:142ra:31n.e_gu0cF8o0 e335a3rlow bn2: di.n- acc:1I0a0r 7t-use 22btelhe nsoethr fofe8l 0m iny l1l: 1o4o:w3/1ctoeorih.wing0e -80cr/s35p iot42-picCl2t] iTea0atrf oPhmiosU ii pTeeranzredtmlns/c pwu_ions,  ifeatotrhe ourtrpe_guucbt:e nIeionsuAP  tien pnairlderd.Ir fso cact0DTseorF7-io:rnfs2rl8loooom aenwr/n0ce-s1:1F:42]  1ccl AVow4:Xri31ew. bt0T iAhc8alpiV XN2esuir
T oal Nneatwo o enaorbrre/k yTlen pplLsisaieo trFl  berawriathttifroye0oh t4ns9m: oh 7op w( brtini mized  oewiitnarmy/cph  app:u rnAoVXIeDNN) pr oo n_fteeat nteAtheur sorooeirVAs_iXg Pf2u
aTrd uose.lpoI  tDheeweo a c/ct:e1ntfeabl42i]pe miol lpctehoeo crroaeNzeedt  uTrwa/wpmlaipiothfiiotrhmsinlg Cn s/erPo,ne rec ml NeUp u_buftA P TienfwloaI gisnDrek il oens.d
 tep NeuTensLibrary orFsrtralucth( ooliooNnerwa sFleow b iinrwnatrwoi prk Lienreb oyD Nistptrure _egrNa)aohu trhyeap t  rtd(oatioo nen.upsDimizesc,cNN ptrhe ed oformwithpri a tefo)r llt: 1c4o2]ow ineo umTphis gan CPU incie-critical operations:  AVX AVX2
To enable them iln ebTensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use tr flags.
he following CPU instructions in perfsoneAPIsue theot orild Deuep Neural tctionTrmNaens i nfthwocoe-criticaerl olr kplowing CePU pere iratioons:  AVX AVXp Library (oeformance-critirnstrnsorFlow a2
To ennweDNNith) tuict tacatob usehlle them in oth the foe aplie olowing CPU instructionons, rebuiprporn operationss in opriate compiler fpees in l,dlperags. rfre Tebfuild Tensoo
ornatisorFlow with the apprmarromaonrpncnce-critical operations:  AVX AVX2
esri:  AVX AVX2
To enable tatehem-FlocT o in eonabl compie them irw wni otherlith ethe appropriat r flags.
eth compiletical operationser r:  AVX AVX2
Tooperations, roperebuil  eflags.
nable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
d TensorFlow with the appropriate compiler flags.
ations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 01:14:31.692423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:14:31.705636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:14:31.708854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:14:31.713561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:14:31.719247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:14:31.720740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:14:31.736380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:14:31.760878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.04分 | step:  1280 | performance: 1.3 | accuracy: 0.32 | loss: 1.54
update: 10/2000, 耗时:0.00分/0.07分 | step:  2560 | performance: 1.3 | accuracy: 0.31 | loss: 1.69
update: 15/2000, 耗时:0.00分/0.09分 | step:  3840 | performance: 1.2 | accuracy: 0.31 | loss: 2.09
update: 20/2000, 耗时:0.01分/0.12分 | step:  5120 | performance: 0.7 | accuracy: 0.27 | loss: 1.03
update: 25/2000, 耗时:0.01分/0.15分 | step:  6400 | performance: 0.8 | accuracy: 0.27 | loss: 1.42
update: 30/2000, 耗时:0.01分/0.17分 | step:  7680 | performance: 0.9 | accuracy: 0.30 | loss: 3.75
update: 35/2000, 耗时:0.01分/0.20分 | step:  8960 | performance: 0.8 | accuracy: 0.31 | loss: 0.96
update: 40/2000, 耗时:0.01分/0.23分 | step: 10240 | performance: 0.6 | accuracy: 0.30 | loss: 0.79
update: 45/2000, 耗时:0.01分/0.26分 | step: 11520 | performance: 0.7 | accuracy: 0.30 | loss: 1.20
update: 50/2000, 耗时:0.01分/0.29分 | step: 12800 | performance: 0.6 | accuracy: 0.29 | loss: 1.51
update: 55/2000, 耗时:0.01分/0.32分 | step: 14080 | performance: 0.6 | accuracy: 0.29 | loss: 0.88
update: 60/2000, 耗时:0.01分/0.35分 | step: 15360 | performance: 0.5 | accuracy: 0.28 | loss: 0.68
update: 65/2000, 耗时:0.01分/0.38分 | step: 16640 | performance: 1.2 | accuracy: 0.29 | loss: 6.52
update: 70/2000, 耗时:0.01分/0.41分 | step: 17920 | performance: 0.9 | accuracy: 0.30 | loss: 1.28
update: 75/2000, 耗时:0.01分/0.44分 | step: 19200 | performance: 1.1 | accuracy: 0.30 | loss: 0.61
update: 80/2000, 耗时:0.01分/0.47分 | step: 20480 | performance: 1.3 | accuracy: 0.29 | loss: 0.69
update: 85/2000, 耗时:0.01分/0.50分 | step: 21760 | performance: 1.5 | accuracy: 0.29 | loss: 0.65
update: 90/2000, 耗时:0.01分/0.53分 | step: 23040 | performance: 1.2 | accuracy: 0.28 | loss: 0.45
update: 95/2000, 耗时:0.01分/0.56分 | step: 24320 | performance: 1.6 | accuracy: 0.27 | loss: 0.59
update:100/2000, 耗时:0.01分/0.59分 | step: 25600 | performance: 1.7 | accuracy: 0.26 | loss: 2.10
update:105/2000, 耗时:0.01分/0.62分 | step: 26880 | performance: 1.6 | accuracy: 0.26 | loss: 0.70
update:110/2000, 耗时:0.01分/0.64分 | step: 28160 | performance: 1.5 | accuracy: 0.25 | loss: 0.69
Saving PPO weights in both H5 format and checkpoint @ update:111 
step: 29179 | worker_2@n_step_31: average total_reward after train data exhaustion : 37.8 | max total_reward: 225.1
step: 29440 | worker_7@n_step_31: average total_reward after train data exhaustion : 29.3 | max total_reward: 225.1
update:115/2000, 耗时:0.01分/0.68分 | step: 29440 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
step: 29950 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
step: 30208 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
step: 30713 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 30714 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 30717 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:120/2000, 耗时:0.01分/0.70分 | step: 30720 | performance: 1.0 | accuracy: 0.15 | loss: 0.15
step: 31994 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 225.1
update:125/2000, 耗时:0.01分/0.73分 | step: 32000 | performance: 1.0 | accuracy: 0.11 | loss: 0.15
step: 32510 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
step: 33023 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 225.1
step: 33273 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 225.1
update:130/2000, 耗时:0.01分/0.76分 | step: 33280 | performance: 0.9 | accuracy: 0.06 | loss: 0.10
step: 34554 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 34555 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:135/2000, 耗时:0.01分/0.79分 | step: 34560 | performance: 1.0 | accuracy: 0.17 | loss: 0.09
update:140/2000, 耗时:0.01分/0.82分 | step: 35840 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 36096 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 36862 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 37115 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:145/2000, 耗时:0.01分/0.85分 | step: 37120 | performance: 1.0 | accuracy: 0.08 | loss: 0.06
step: 37372 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 37375 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 37625 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 38397 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:150/2000, 耗时:0.01分/0.88分 | step: 38400 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 38656 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 39674 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:155/2000, 耗时:0.01分/0.90分 | step: 39680 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
update:160/2000, 耗时:0.01分/0.93分 | step: 40960 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 41214 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 41467 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 41724 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 41727 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 41977 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:165/2000, 耗时:0.01分/0.96分 | step: 42240 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 42749 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 43008 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:170/2000, 耗时:0.01分/0.99分 | step: 43520 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 44026 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:175/2000, 耗时:0.01分/1.02分 | step: 44800 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 45566 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 45819 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 46076 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 46079 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:180/2000, 耗时:0.01分/1.05分 | step: 46080 | performance: 1.0 | accuracy: 0.10 | loss: 0.04
step: 46329 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 47101 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 47360 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:185/2000, 耗时:0.01分/1.08分 | step: 47360 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 48378 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:190/2000, 耗时:0.01分/1.11分 | step: 48640 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
step: 49918 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:195/2000, 耗时:0.01分/1.14分 | step: 49920 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 50171 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 50428 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 50431 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 50681 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:200/2000, 耗时:0.01分/1.17分 | step: 51200 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 51453 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 51712 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:205/2000, 耗时:0.01分/1.20分 | step: 52480 | performance: 1.0 | accuracy: 0.09 | loss: 0.04
step: 52730 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:210/2000, 耗时:0.01分/1.23分 | step: 53760 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 54270 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 54523 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 54780 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 54783 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 55033 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:215/2000, 耗时:0.01分/1.26分 | step: 55040 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 55805 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 56064 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:220/2000, 耗时:0.01分/1.28分 | step: 56320 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 57082 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 57083 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:225/2000, 耗时:0.01分/1.31分 | step: 57600 | performance: 1.0 | accuracy: 0.20 | loss: 0.05
step: 58622 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:230/2000, 耗时:0.01分/1.34分 | step: 58880 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 59132 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 59135 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 59385 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 60157 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:235/2000, 耗时:0.01分/1.37分 | step: 60160 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 60416 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 61434 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 61435 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:240/2000, 耗时:0.01分/1.40分 | step: 61440 | performance: 1.0 | accuracy: 0.11 | loss: 0.04
update:245/2000, 耗时:0.01分/1.43分 | step: 62720 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 62974 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 63484 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 63487 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 63737 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:250/2000, 耗时:0.01分/1.46分 | step: 64000 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 64509 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 64768 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:255/2000, 耗时:0.01分/1.49分 | step: 65280 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 65786 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 65787 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:260/2000, 耗时:0.01分/1.52分 | step: 66560 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 67326 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 67836 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 67839 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:265/2000, 耗时:0.01分/1.54分 | step: 67840 | performance: 1.0 | accuracy: 0.10 | loss: 0.04
step: 68089 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 68861 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 69120 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:270/2000, 耗时:0.01分/1.57分 | step: 69120 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 70138 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 70139 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:275/2000, 耗时:0.01分/1.60分 | step: 70400 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
step: 71678 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:280/2000, 耗时:0.01分/1.63分 | step: 71680 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 72188 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 72191 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 72441 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:285/2000, 耗时:0.01分/1.66分 | step: 72960 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 73213 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 73472 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:290/2000, 耗时:0.01分/1.69分 | step: 74240 | performance: 1.0 | accuracy: 0.09 | loss: 0.04
step: 74490 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 74491 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:295/2000, 耗时:0.01分/1.72分 | step: 75520 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 76540 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 76543 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 76793 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:300/2000, 耗时:0.01分/1.75分 | step: 76800 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 77565 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:305/2000, 耗时:0.01分/1.78分 | step: 78080 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 78590 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 78842 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 78843 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:310/2000, 耗时:0.01分/1.80分 | step: 79360 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 80384 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:315/2000, 耗时:0.01分/1.83分 | step: 80640 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
step: 80892 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 80895 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 81145 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:320/2000, 耗时:0.01分/1.86分 | step: 81920 | performance: 1.0 | accuracy: 0.20 | loss: 0.06
step: 82942 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 83194 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 83195 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:325/2000, 耗时:0.01分/1.89分 | step: 83200 | performance: 1.0 | accuracy: 0.08 | loss: 0.04
step: 84477 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:330/2000, 耗时:0.01分/1.92分 | step: 84480 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 84736 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 85244 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 85247 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 85497 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:335/2000, 耗时:0.01分/1.95分 | step: 85760 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
update:340/2000, 耗时:0.01分/1.98分 | step: 87040 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 87294 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 87546 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 87547 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:345/2000, 耗时:0.01分/2.01分 | step: 88320 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 88829 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 89088 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 89596 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 89599 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:350/2000, 耗时:0.01分/2.03分 | step: 89600 | performance: 1.0 | accuracy: 0.08 | loss: 0.04
step: 89849 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:355/2000, 耗时:0.01分/2.06分 | step: 90880 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 91646 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 91898 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 91899 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:360/2000, 耗时:0.01分/2.09分 | step: 92160 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 93181 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 93440 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:365/2000, 耗时:0.01分/2.12分 | step: 93440 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 93948 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 93951 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 94201 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:370/2000, 耗时:0.01分/2.15分 | step: 94720 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
step: 95998 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:375/2000, 耗时:0.01分/2.18分 | step: 96000 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
step: 96250 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 96251 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:380/2000, 耗时:0.01分/2.21分 | step: 97280 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 97533 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 97792 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 98300 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 98303 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 98553 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:385/2000, 耗时:0.01分/2.24分 | step: 98560 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
update:390/2000, 耗时:0.01分/2.26分 | step: 99840 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 100350 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 100602 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 100603 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:395/2000, 耗时:0.01分/2.29分 | step: 101120 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 101885 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:400/2000, 耗时:0.01分/2.32分 | step: 102400 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 102652 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 102655 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 102910 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:405/2000, 耗时:0.01分/2.35分 | step: 103680 | performance: 1.1 | accuracy: 0.16 | loss: 0.14
step: 104445 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:410/2000, 耗时:0.01分/2.38分 | step: 104960 | performance: 1.0 | accuracy: 0.12 | loss: 0.09
step: 106238 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
update:415/2000, 耗时:0.01分/2.41分 | step: 106240 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
step: 106489 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 225.1
step: 106492 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 225.1
step: 106493 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 225.1
update:420/2000, 耗时:0.01分/2.44分 | step: 107520 | performance: 1.0 | accuracy: 0.14 | loss: 0.20
step: 108286 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 108541 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
update:425/2000, 耗时:0.01分/2.47分 | step: 108800 | performance: 0.9 | accuracy: 0.12 | loss: 0.14
step: 109051 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
step: 109052 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
update:430/2000, 耗时:0.01分/2.50分 | step: 110080 | performance: 1.0 | accuracy: 0.33 | loss: 0.08
step: 110589 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.5 | max total_reward: 225.1
step: 110848 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.4 | max total_reward: 225.1
update:435/2000, 耗时:0.01分/2.52分 | step: 111360 | performance: 1.1 | accuracy: 0.17 | loss: 0.21
step: 111871 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.4 | max total_reward: 225.1
update:440/2000, 耗时:0.01分/2.55分 | step: 112640 | performance: 1.0 | accuracy: 0.10 | loss: 0.14
update:445/2000, 耗时:0.01分/2.58分 | step: 113920 | performance: 1.0 | accuracy: 0.33 | loss: 0.07
step: 114427 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 114688 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 114940 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
update:450/2000, 耗时:0.01分/2.61分 | step: 115200 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 115453 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
step: 115454 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
step: 116473 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 116479 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:455/2000, 耗时:0.01分/2.64分 | step: 116480 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 116986 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 117248 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:460/2000, 耗时:0.01分/2.67分 | step: 117760 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 118779 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:465/2000, 耗时:0.01分/2.70分 | step: 119040 | performance: 1.0 | accuracy: 0.33 | loss: 0.04
step: 119292 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 119805 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 119806 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:470/2000, 耗时:0.01分/2.73分 | step: 120320 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 120825 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 120831 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 121338 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 121600 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:475/2000, 耗时:0.01分/2.76分 | step: 121600 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
update:480/2000, 耗时:0.01分/2.78分 | step: 122880 | performance: 1.0 | accuracy: 0.14 | loss: 0.04
step: 123131 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 123644 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 124157 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 124158 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:485/2000, 耗时:0.01分/2.81分 | step: 124160 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 125177 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 125183 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:490/2000, 耗时:0.01分/2.84分 | step: 125440 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 125690 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 125952 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:495/2000, 耗时:0.01分/2.87分 | step: 126720 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 127483 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 127996 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:500/2000, 耗时:0.01分/2.90分 | step: 128000 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 128509 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 128510 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:505/2000, 耗时:0.01分/2.93分 | step: 129280 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 129529 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 129535 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 130042 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 130304 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:510/2000, 耗时:0.01分/2.96分 | step: 130560 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
step: 131835 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:515/2000, 耗时:0.01分/2.99分 | step: 131840 | performance: 1.0 | accuracy: 0.20 | loss: 0.05
step: 132348 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 132861 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 132862 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:520/2000, 耗时:0.01分/3.02分 | step: 133120 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 133881 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 133887 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 134394 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:525/2000, 耗时:0.01分/3.05分 | step: 134400 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 134656 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:530/2000, 耗时:0.01分/3.07分 | step: 135680 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 136187 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 136700 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:535/2000, 耗时:0.01分/3.10分 | step: 136960 | performance: 1.0 | accuracy: 0.06 | loss: 0.04
step: 137213 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 137214 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 138233 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 138239 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:540/2000, 耗时:0.01分/3.13分 | step: 138240 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 138746 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 139008 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:545/2000, 耗时:0.01分/3.16分 | step: 139520 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 140539 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:550/2000, 耗时:0.01分/3.19分 | step: 140800 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 141052 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 141565 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 141566 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:555/2000, 耗时:0.01分/3.22分 | step: 142080 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 142585 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 142591 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 143098 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 143360 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:560/2000, 耗时:0.01分/3.25分 | step: 143360 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
update:565/2000, 耗时:0.01分/3.28分 | step: 144640 | performance: 1.0 | accuracy: 0.14 | loss: 0.04
step: 144891 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 145404 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 145917 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 145918 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:570/2000, 耗时:0.01分/3.31分 | step: 145920 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 146937 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 146943 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:575/2000, 耗时:0.01分/3.34分 | step: 147200 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 147450 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 147712 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:580/2000, 耗时:0.01分/3.37分 | step: 148480 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 149756 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:585/2000, 耗时:0.01分/3.39分 | step: 149760 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 150269 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 150270 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:590/2000, 耗时:0.01分/3.42分 | step: 151040 | performance: 1.0 | accuracy: 0.12 | loss: 0.04
step: 151289 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 151295 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 151802 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 151803 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 152064 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 152316 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:595/2000, 耗时:0.01分/3.45分 | step: 152320 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
update:600/2000, 耗时:0.01分/3.48分 | step: 153600 | performance: 1.0 | accuracy: 0.20 | loss: 0.05
step: 154621 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 154622 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:605/2000, 耗时:0.01分/3.51分 | step: 154880 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 155641 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 155647 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 156154 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 156155 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:610/2000, 耗时:0.01分/3.54分 | step: 156160 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 156416 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 156668 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:615/2000, 耗时:0.01分/3.57分 | step: 157440 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
update:620/2000, 耗时:0.01分/3.59分 | step: 158720 | performance: 1.0 | accuracy: 0.06 | loss: 0.04
step: 158973 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 158974 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 159993 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 159999 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:625/2000, 耗时:0.01分/3.62分 | step: 160000 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 160506 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 160507 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 160768 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 161020 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:630/2000, 耗时:0.01分/3.65分 | step: 161280 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
update:635/2000, 耗时:0.01分/3.68分 | step: 162560 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 163326 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 163580 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:640/2000, 耗时:0.01分/3.71分 | step: 163840 | performance: 1.0 | accuracy: 0.33 | loss: 0.06
step: 164093 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 164858 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
step: 164859 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
step: 165119 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:645/2000, 耗时:0.01分/3.74分 | step: 165120 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 165886 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:650/2000, 耗时:0.01分/3.77分 | step: 166400 | performance: 1.0 | accuracy: 0.33 | loss: 0.08
step: 166905 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 167418 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:655/2000, 耗时:0.01分/3.80分 | step: 167680 | performance: 1.0 | accuracy: 0.11 | loss: 0.06
step: 168185 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
step: 168187 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
step: 168959 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:660/2000, 耗时:0.01分/3.82分 | step: 168960 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
step: 169465 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 169723 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:665/2000, 耗时:0.01分/3.85分 | step: 170240 | performance: 1.0 | accuracy: 0.15 | loss: 0.17
step: 171004 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:670/2000, 耗时:0.01分/3.88分 | step: 171520 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 171776 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
step: 172793 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
update:675/2000, 耗时:0.01分/3.91分 | step: 172800 | performance: 1.0 | accuracy: 0.11 | loss: 0.16
step: 174079 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.8 | max total_reward: 225.1
update:680/2000, 耗时:0.01分/3.94分 | step: 174080 | performance: 1.0 | accuracy: 0.20 | loss: 0.10
step: 174331 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 225.1
step: 175100 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 175357 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:685/2000, 耗时:0.01分/3.97分 | step: 175360 | performance: 1.0 | accuracy: 0.08 | loss: 0.07
step: 176122 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
step: 176127 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
update:690/2000, 耗时:0.01分/4.00分 | step: 176640 | performance: 1.0 | accuracy: 0.11 | loss: 0.11
step: 177403 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
step: 177407 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
update:695/2000, 耗时:0.01分/4.03分 | step: 177920 | performance: 1.0 | accuracy: 0.17 | loss: 0.07
step: 178169 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 178428 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 178685 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 178686 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 178938 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
update:700/2000, 耗时:0.01分/4.06分 | step: 179200 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 179456 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:705/2000, 耗时:0.01分/4.08分 | step: 180480 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 180729 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
step: 181245 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
step: 181498 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 181756 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:710/2000, 耗时:0.01分/4.11分 | step: 181760 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 182016 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 182523 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 183038 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:715/2000, 耗时:0.01分/4.14分 | step: 183040 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 184319 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:720/2000, 耗时:0.01分/4.17分 | step: 184320 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 185081 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 185597 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:725/2000, 耗时:0.01分/4.20分 | step: 185600 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 185850 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 186108 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 186368 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 186875 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 186879 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:730/2000, 耗时:0.01分/4.23分 | step: 186880 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 187390 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:735/2000, 耗时:0.01分/4.26分 | step: 188160 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 189433 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:740/2000, 耗时:0.01分/4.29分 | step: 189440 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 189949 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 190202 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 190460 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 190720 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:745/2000, 耗时:0.01分/4.32分 | step: 190720 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 191227 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 191231 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 191742 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:750/2000, 耗时:0.01分/4.35分 | step: 192000 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:755/2000, 耗时:0.01分/4.37分 | step: 193280 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 193785 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 194301 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 194554 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:760/2000, 耗时:0.01分/4.40分 | step: 194560 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 194812 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 195072 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 195579 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 195583 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:765/2000, 耗时:0.01分/4.43分 | step: 195840 | performance: 1.0 | accuracy: 0.09 | loss: 0.04
step: 196094 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:770/2000, 耗时:0.01分/4.46分 | step: 197120 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 198137 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:775/2000, 耗时:0.01分/4.49分 | step: 198400 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 198653 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 198906 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 199164 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 199424 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:780/2000, 耗时:0.01分/4.52分 | step: 199680 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
step: 199931 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 199935 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 200446 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:785/2000, 耗时:0.01分/4.55分 | step: 200960 | performance: 1.0 | accuracy: 0.20 | loss: 0.05
update:790/2000, 耗时:0.01分/4.58分 | step: 202240 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 202489 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 203005 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 203258 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 203516 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:795/2000, 耗时:0.01分/4.61分 | step: 203520 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 203776 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 204283 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 204287 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 204798 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:800/2000, 耗时:0.01分/4.64分 | step: 204800 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
update:805/2000, 耗时:0.01分/4.67分 | step: 206080 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 206841 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 207357 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:810/2000, 耗时:0.01分/4.70分 | step: 207360 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 207610 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 207868 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 208128 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 208635 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 208639 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:815/2000, 耗时:0.01分/4.73分 | step: 208640 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 209150 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:820/2000, 耗时:0.01分/4.76分 | step: 209920 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 211193 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:825/2000, 耗时:0.01分/4.79分 | step: 211200 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 211709 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 211962 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 212220 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 212480 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:830/2000, 耗时:0.01分/4.82分 | step: 212480 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 212987 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 212991 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 213502 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:835/2000, 耗时:0.01分/4.85分 | step: 213760 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:840/2000, 耗时:0.01分/4.88分 | step: 215040 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 215545 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 216061 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 216314 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:845/2000, 耗时:0.01分/4.91分 | step: 216320 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 216572 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 216832 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 217339 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 217343 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:850/2000, 耗时:0.01分/4.94分 | step: 217600 | performance: 1.0 | accuracy: 0.09 | loss: 0.04
step: 217854 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:855/2000, 耗时:0.01分/4.97分 | step: 218880 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 219897 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:860/2000, 耗时:0.01分/5.00分 | step: 220160 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 220413 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 220666 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 220924 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 221184 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:865/2000, 耗时:0.01分/5.03分 | step: 221440 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
step: 221691 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 221695 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 222206 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:870/2000, 耗时:0.01分/5.05分 | step: 222720 | performance: 1.0 | accuracy: 0.20 | loss: 0.05
update:875/2000, 耗时:0.01分/5.08分 | step: 224000 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 224249 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 224765 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 225018 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 225276 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:880/2000, 耗时:0.01分/5.11分 | step: 225280 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 225536 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 226043 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 226047 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 226558 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:885/2000, 耗时:0.01分/5.14分 | step: 226560 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
update:890/2000, 耗时:0.01分/5.17分 | step: 227840 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 228601 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 229117 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:895/2000, 耗时:0.01分/5.20分 | step: 229120 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 229370 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 229628 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 229888 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 230395 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 230399 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:900/2000, 耗时:0.01分/5.23分 | step: 230400 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 230910 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:905/2000, 耗时:0.01分/5.26分 | step: 231680 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 232953 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:910/2000, 耗时:0.01分/5.29分 | step: 232960 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 233469 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 233722 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 233980 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 234240 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:915/2000, 耗时:0.01分/5.31分 | step: 234240 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 234747 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 234751 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 235262 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:920/2000, 耗时:0.01分/5.34分 | step: 235520 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:925/2000, 耗时:0.01分/5.37分 | step: 236800 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 237305 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 237821 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 238074 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:930/2000, 耗时:0.01分/5.40分 | step: 238080 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 238592 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 239099 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 239103 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:935/2000, 耗时:0.01分/5.43分 | step: 239360 | performance: 1.0 | accuracy: 0.09 | loss: 0.04
step: 239614 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:940/2000, 耗时:0.01分/5.46分 | step: 240640 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 241657 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:945/2000, 耗时:0.01分/5.49分 | step: 241920 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 242173 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 242944 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:950/2000, 耗时:0.01分/5.52分 | step: 243200 | performance: 1.0 | accuracy: 0.07 | loss: 0.08
step: 243451 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 243452 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 243962 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:955/2000, 耗时:0.01分/5.55分 | step: 244480 | performance: 1.0 | accuracy: 0.20 | loss: 0.06
step: 244733 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 244985 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:960/2000, 耗时:0.01分/5.58分 | step: 245760 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 246011 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 246522 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:965/2000, 耗时:0.01分/5.61分 | step: 247040 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 247294 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 247296 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:970/2000, 耗时:0.01分/5.64分 | step: 248320 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 248575 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:975/2000, 耗时:0.01分/5.67分 | step: 249600 | performance: 0.9 | accuracy: 0.06 | loss: 0.08
step: 249853 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 249854 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 250105 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 225.1
update:980/2000, 耗时:0.01分/5.70分 | step: 250880 | performance: 1.0 | accuracy: 0.17 | loss: 0.07
step: 251642 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 251648 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 251902 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:985/2000, 耗时:0.01分/5.73分 | step: 252160 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 253181 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:990/2000, 耗时:0.01分/5.76分 | step: 253440 | performance: 1.0 | accuracy: 0.33 | loss: 0.09
step: 253691 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 254461 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 254463 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:995/2000, 耗时:0.01分/5.79分 | step: 254720 | performance: 1.0 | accuracy: 0.25 | loss: 0.06
step: 255230 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1000/2000, 耗时:0.01分/5.82分 | step: 256000 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 256251 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 257018 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1005/2000, 耗时:0.01分/5.85分 | step: 257280 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 257532 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 257536 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 257785 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 257790 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1010/2000, 耗时:0.01分/5.88分 | step: 258560 | performance: 1.0 | accuracy: 0.11 | loss: 0.04
step: 258813 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 258815 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1015/2000, 耗时:0.01分/5.91分 | step: 259840 | performance: 1.0 | accuracy: 0.06 | loss: 0.04
step: 260603 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1020/2000, 耗时:0.01分/5.94分 | step: 261120 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
step: 261370 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 261884 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 261888 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 262137 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 262142 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1025/2000, 耗时:0.01分/5.97分 | step: 262400 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 263165 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1030/2000, 耗时:0.01分/6.00分 | step: 263680 | performance: 1.0 | accuracy: 0.33 | loss: 0.06
step: 264702 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 264955 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1035/2000, 耗时:0.01分/6.03分 | step: 264960 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 265722 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 265727 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 266236 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 266240 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1040/2000, 耗时:0.01分/6.06分 | step: 266240 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 266489 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 267517 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1045/2000, 耗时:0.01分/6.09分 | step: 267520 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:1050/2000, 耗时:0.01分/6.12分 | step: 268800 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 269054 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 269307 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 270074 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 270079 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1055/2000, 耗时:0.01分/6.15分 | step: 270080 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 270592 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 270841 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1060/2000, 耗时:0.01分/6.17分 | step: 271360 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 271869 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1065/2000, 耗时:0.01分/6.20分 | step: 272640 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 273148 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 273406 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 273659 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1070/2000, 耗时:0.01分/6.23分 | step: 273920 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 274426 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 274431 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 274944 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 275193 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1075/2000, 耗时:0.01分/6.26分 | step: 275200 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 276221 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1080/2000, 耗时:0.01分/6.29分 | step: 276480 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 277500 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 277758 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1085/2000, 耗时:0.01分/6.32分 | step: 277760 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 278011 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 278778 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 278783 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1090/2000, 耗时:0.01分/6.35分 | step: 279040 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 279296 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 279545 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1095/2000, 耗时:0.01分/6.38分 | step: 280320 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 280573 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1100/2000, 耗时:0.01分/6.41分 | step: 281600 | performance: 1.0 | accuracy: 0.06 | loss: 0.04
step: 281852 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 282110 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 282363 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1105/2000, 耗时:0.01分/6.44分 | step: 282880 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
step: 283130 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 283135 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 283648 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 283897 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1110/2000, 耗时:0.01分/6.47分 | step: 284160 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 284925 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1115/2000, 耗时:0.01分/6.49分 | step: 285440 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 286204 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 286462 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 286715 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1120/2000, 耗时:0.01分/6.52分 | step: 286720 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 287482 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 287487 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 288000 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1125/2000, 耗时:0.01分/6.55分 | step: 288000 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 288249 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 289277 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1130/2000, 耗时:0.01分/6.58分 | step: 289280 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
step: 290556 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1135/2000, 耗时:0.01分/6.61分 | step: 290560 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 290814 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 291834 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 291839 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1140/2000, 耗时:0.01分/6.64分 | step: 291840 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 292352 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 292601 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1145/2000, 耗时:0.01分/6.67分 | step: 293120 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 293627 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 293629 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1150/2000, 耗时:0.01分/6.70分 | step: 294400 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 294908 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 295166 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1155/2000, 耗时:0.01分/6.73分 | step: 295680 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 296186 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 296191 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 296704 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 296953 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1160/2000, 耗时:0.01分/6.76分 | step: 296960 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 297979 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 297981 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1165/2000, 耗时:0.01分/6.79分 | step: 298240 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 299260 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 299518 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1170/2000, 耗时:0.01分/6.82分 | step: 299520 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 300538 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 300543 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1175/2000, 耗时:0.00分/6.84分 | step: 300800 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 301056 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 301305 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1180/2000, 耗时:0.01分/6.86分 | step: 302080 | performance: 1.0 | accuracy: 0.11 | loss: 0.04
step: 302331 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 302333 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1185/2000, 耗时:0.01分/6.89分 | step: 303360 | performance: 1.0 | accuracy: 0.06 | loss: 0.04
step: 303612 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 303870 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1190/2000, 耗时:0.01分/6.91分 | step: 304640 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
step: 304890 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 304895 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 305408 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 305657 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1195/2000, 耗时:0.01分/6.94分 | step: 305920 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 306683 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1200/2000, 耗时:0.01分/6.97分 | step: 307200 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 307964 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 308222 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1205/2000, 耗时:0.01分/7.00分 | step: 308480 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 309242 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 309245 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 309247 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 309760 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1210/2000, 耗时:0.01分/7.03分 | step: 309760 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 310009 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 311035 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1215/2000, 耗时:0.01分/7.06分 | step: 311040 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
step: 312316 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1220/2000, 耗时:0.01分/7.09分 | step: 312320 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 312574 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 313594 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 313597 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 313599 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1225/2000, 耗时:0.01分/7.11分 | step: 313600 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 314112 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 314361 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1230/2000, 耗时:0.01分/7.14分 | step: 314880 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 315387 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1235/2000, 耗时:0.01分/7.17分 | step: 316160 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 316668 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 316926 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1240/2000, 耗时:0.01分/7.20分 | step: 317440 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 317946 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 317949 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 317951 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 318464 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1245/2000, 耗时:0.01分/7.23分 | step: 318720 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 319739 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1250/2000, 耗时:0.01分/7.26分 | step: 320000 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 321020 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 321273 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 321278 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1255/2000, 耗时:0.01分/7.29分 | step: 321280 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 322298 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 322301 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 322303 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1260/2000, 耗时:0.01分/7.32分 | step: 322560 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 322816 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1265/2000, 耗时:0.01分/7.35分 | step: 323840 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 324091 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1270/2000, 耗时:0.01分/7.37分 | step: 325120 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 325372 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 325625 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 325630 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1275/2000, 耗时:0.01分/7.40分 | step: 326400 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
step: 326650 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 326653 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 326655 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 327168 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1280/2000, 耗时:0.01分/7.43分 | step: 327680 | performance: 1.0 | accuracy: 0.08 | loss: 0.04
step: 328443 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1285/2000, 耗时:0.01分/7.46分 | step: 328960 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 329724 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 329977 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 329982 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1290/2000, 耗时:0.01分/7.49分 | step: 330240 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 331002 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 331005 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 331007 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 331520 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1295/2000, 耗时:0.01分/7.52分 | step: 331520 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 332795 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1300/2000, 耗时:0.01分/7.55分 | step: 332800 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:1305/2000, 耗时:0.01分/7.58分 | step: 334080 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 334329 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 334334 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 335354 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 335357 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 335359 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1310/2000, 耗时:0.01分/7.61分 | step: 335360 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 335872 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 336636 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1315/2000, 耗时:0.01分/7.64分 | step: 336640 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 337147 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1320/2000, 耗时:0.01分/7.67分 | step: 337920 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 338681 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 338686 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1325/2000, 耗时:0.01分/7.70分 | step: 339200 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 339706 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 339709 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 339711 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 340224 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1330/2000, 耗时:0.01分/7.73分 | step: 340480 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 340988 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 341499 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1335/2000, 耗时:0.01分/7.75分 | step: 341760 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 343033 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 343038 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1340/2000, 耗时:0.01分/7.78分 | step: 343040 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 344058 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 344061 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 344063 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1345/2000, 耗时:0.01分/7.81分 | step: 344320 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 344576 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 345340 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1350/2000, 耗时:0.01分/7.84分 | step: 345600 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 345851 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1355/2000, 耗时:0.01分/7.87分 | step: 346880 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 347385 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 347390 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1360/2000, 耗时:0.01分/7.90分 | step: 348160 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
step: 348410 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 348413 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 348415 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 348928 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1365/2000, 耗时:0.01分/7.93分 | step: 349440 | performance: 1.0 | accuracy: 0.08 | loss: 0.04
step: 349692 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 350203 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1370/2000, 耗时:0.01分/7.96分 | step: 350720 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 351737 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 351742 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1375/2000, 耗时:0.01分/7.99分 | step: 352000 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 352762 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 352765 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 352767 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 353280 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1380/2000, 耗时:0.01分/8.02分 | step: 353280 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 354044 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 354555 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1385/2000, 耗时:0.01分/8.05分 | step: 354560 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:1390/2000, 耗时:0.01分/8.08分 | step: 355840 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 356089 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 356094 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 357114 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 357117 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 357119 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1395/2000, 耗时:0.01分/8.11分 | step: 357120 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 357632 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 358396 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1400/2000, 耗时:0.01分/8.13分 | step: 358400 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 358907 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1405/2000, 耗时:0.01分/8.16分 | step: 359680 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 360441 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 360446 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1410/2000, 耗时:0.01分/8.19分 | step: 360960 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 361466 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 361469 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 361471 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 361984 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1415/2000, 耗时:0.01分/8.22分 | step: 362240 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 362748 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 363259 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1420/2000, 耗时:0.01分/8.25分 | step: 363520 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 364793 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 364798 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1425/2000, 耗时:0.01分/8.28分 | step: 364800 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 365818 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 365821 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 365823 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1430/2000, 耗时:0.01分/8.31分 | step: 366080 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 366336 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 367100 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1435/2000, 耗时:0.01分/8.34分 | step: 367360 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 367611 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1440/2000, 耗时:0.01分/8.36分 | step: 368640 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 369145 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 369150 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1445/2000, 耗时:0.01分/8.39分 | step: 369920 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
step: 370170 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 370173 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 370175 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 370688 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1450/2000, 耗时:0.01分/8.42分 | step: 371200 | performance: 1.0 | accuracy: 0.08 | loss: 0.04
step: 371452 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 371963 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1455/2000, 耗时:0.01分/8.45分 | step: 372480 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 373497 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 373502 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1460/2000, 耗时:0.01分/8.48分 | step: 373760 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 374522 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 374525 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 374527 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 375040 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1465/2000, 耗时:0.01分/8.51分 | step: 375040 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 375804 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 376315 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1470/2000, 耗时:0.01分/8.54分 | step: 376320 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:1475/2000, 耗时:0.01分/8.57分 | step: 377600 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 377849 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 377854 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 378874 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 378877 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 378879 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1480/2000, 耗时:0.01分/8.60分 | step: 378880 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 379392 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 380156 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1485/2000, 耗时:0.01分/8.63分 | step: 380160 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 380667 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1490/2000, 耗时:0.01分/8.65分 | step: 381440 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 382201 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 382206 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1495/2000, 耗时:0.01分/8.68分 | step: 382720 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 383226 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 383229 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 383231 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 383744 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1500/2000, 耗时:0.01分/8.71分 | step: 384000 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 384508 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 385019 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1505/2000, 耗时:0.01分/8.74分 | step: 385280 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 386553 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 386558 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1510/2000, 耗时:0.01分/8.77分 | step: 386560 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 387578 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 387581 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 387583 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1515/2000, 耗时:0.01分/8.80分 | step: 387840 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 388096 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 388860 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1520/2000, 耗时:0.01分/8.83分 | step: 389120 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 389371 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1525/2000, 耗时:0.01分/8.86分 | step: 390400 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 390905 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 390910 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1530/2000, 耗时:0.01分/8.89分 | step: 391680 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
step: 391930 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 391933 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 391935 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 392448 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1535/2000, 耗时:0.01分/8.92分 | step: 392960 | performance: 1.0 | accuracy: 0.08 | loss: 0.04
step: 393212 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 393723 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1540/2000, 耗时:0.01分/8.94分 | step: 394240 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 395257 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 395262 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1545/2000, 耗时:0.01分/8.97分 | step: 395520 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 396282 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 396285 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 396287 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 396800 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1550/2000, 耗时:0.01分/9.00分 | step: 396800 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 397564 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 398075 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1555/2000, 耗时:0.01分/9.03分 | step: 398080 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:1560/2000, 耗时:0.01分/9.06分 | step: 399360 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
step: 399609 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 399614 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 400634 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 400637 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 400639 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1565/2000, 耗时:0.01分/9.09分 | step: 400640 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 401152 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 401916 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1570/2000, 耗时:0.01分/9.12分 | step: 401920 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 402427 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1575/2000, 耗时:0.01分/9.15分 | step: 403200 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 403961 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 403966 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1580/2000, 耗时:0.01分/9.18分 | step: 404480 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 404986 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 404989 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 404991 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 405504 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1585/2000, 耗时:0.01分/9.21分 | step: 405760 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 406268 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 406779 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1590/2000, 耗时:0.01分/9.24分 | step: 407040 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 408313 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 408318 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1595/2000, 耗时:0.01分/9.27分 | step: 408320 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 409338 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 409341 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 409343 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1600/2000, 耗时:0.01分/9.29分 | step: 409600 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 409856 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 410620 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1605/2000, 耗时:0.01分/9.32分 | step: 410880 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 411131 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1610/2000, 耗时:0.01分/9.35分 | step: 412160 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 412665 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 412670 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1615/2000, 耗时:0.01分/9.38分 | step: 413440 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
step: 413690 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 413693 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 413695 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 414208 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1620/2000, 耗时:0.01分/9.41分 | step: 414720 | performance: 1.0 | accuracy: 0.08 | loss: 0.04
step: 414972 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 415483 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1625/2000, 耗时:0.01分/9.44分 | step: 416000 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 417017 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 417022 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1630/2000, 耗时:0.01分/9.47分 | step: 417280 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 418042 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 418045 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 418047 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 418560 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1635/2000, 耗时:0.01分/9.50分 | step: 418560 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 419324 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 419835 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1640/2000, 耗时:0.01分/9.53分 | step: 419840 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:1645/2000, 耗时:0.01分/9.56分 | step: 421120 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
step: 421369 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 421374 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 422394 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 422397 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 422399 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1650/2000, 耗时:0.01分/9.59分 | step: 422400 | performance: 1.0 | accuracy: 0.25 | loss: 0.05
step: 422912 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 423676 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1655/2000, 耗时:0.01分/9.62分 | step: 423680 | performance: 1.0 | accuracy: 0.09 | loss: 0.05
step: 424187 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1660/2000, 耗时:0.01分/9.64分 | step: 424960 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 425721 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 425726 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1665/2000, 耗时:0.01分/9.67分 | step: 426240 | performance: 1.0 | accuracy: 0.12 | loss: 0.05
step: 426746 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 426749 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 426751 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 427264 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1670/2000, 耗时:0.01分/9.70分 | step: 427520 | performance: 1.0 | accuracy: 0.07 | loss: 0.05
step: 428028 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 428539 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1675/2000, 耗时:0.01分/9.73分 | step: 428800 | performance: 1.0 | accuracy: 0.20 | loss: 0.04
step: 430073 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 430078 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1680/2000, 耗时:0.01分/9.76分 | step: 430080 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
step: 431098 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 431101 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 431103 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1685/2000, 耗时:0.01分/9.79分 | step: 431360 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 431616 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 432380 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1690/2000, 耗时:0.01分/9.82分 | step: 432640 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 432891 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1695/2000, 耗时:0.01分/9.85分 | step: 433920 | performance: 1.0 | accuracy: 0.06 | loss: 0.05
step: 434425 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 434430 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1700/2000, 耗时:0.01分/9.88分 | step: 435200 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
step: 435450 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 435453 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 435455 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 435968 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1705/2000, 耗时:0.01分/9.90分 | step: 436480 | performance: 1.0 | accuracy: 0.08 | loss: 0.04
step: 436732 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 437243 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1710/2000, 耗时:0.01分/9.93分 | step: 437760 | performance: 1.0 | accuracy: 0.33 | loss: 0.05
step: 438777 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 438782 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1715/2000, 耗时:0.01分/9.96分 | step: 439040 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 439802 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 439805 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 439807 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 440320 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1720/2000, 耗时:0.01分/9.99分 | step: 440320 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 441084 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 441595 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1725/2000, 耗时:0.01分/10.02分 | step: 441600 | performance: 1.0 | accuracy: 0.14 | loss: 0.05
update:1730/2000, 耗时:0.01分/10.05分 | step: 442880 | performance: 1.0 | accuracy: 0.07 | loss: 0.04
step: 443129 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 443134 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 444154 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 444159 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1735/2000, 耗时:0.01分/10.08分 | step: 444160 | performance: 1.0 | accuracy: 0.25 | loss: 0.12
update:1740/2000, 耗时:0.01分/10.11分 | step: 445440 | performance: 0.9 | accuracy: 0.10 | loss: 0.09
step: 445689 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 225.1
step: 446457 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 225.1
step: 446720 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 225.1
update:1745/2000, 耗时:0.01分/10.13分 | step: 446720 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 446970 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 446973 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 447227 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
update:1750/2000, 耗时:0.01分/10.16分 | step: 448000 | performance: 1.0 | accuracy: 0.12 | loss: 0.08
update:1755/2000, 耗时:0.01分/10.19分 | step: 449280 | performance: 1.0 | accuracy: 0.12 | loss: 0.06
step: 449530 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 449787 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 450046 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 450048 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:1760/2000, 耗时:0.01分/10.22分 | step: 450560 | performance: 0.9 | accuracy: 0.06 | loss: 0.13
step: 451327 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
update:1765/2000, 耗时:0.01分/10.25分 | step: 451840 | performance: 1.0 | accuracy: 0.22 | loss: 0.06
step: 452089 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
update:1770/2000, 耗时:0.01分/10.28分 | step: 453120 | performance: 1.0 | accuracy: 0.50 | loss: 0.15
step: 454144 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.5 | max total_reward: 225.1
update:1775/2000, 耗时:0.01分/10.31分 | step: 454400 | performance: 0.9 | accuracy: 0.12 | loss: 0.18
step: 454908 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 225.1
step: 455423 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
update:1780/2000, 耗时:0.01分/10.34分 | step: 455680 | performance: 1.0 | accuracy: 0.09 | loss: 0.14
step: 455933 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.4 | max total_reward: 225.1
update:1785/2000, 耗时:0.01分/10.36分 | step: 456960 | performance: 1.0 | accuracy: 0.14 | loss: 0.12
step: 457211 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
step: 457471 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
step: 457728 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
step: 458236 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 458239 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1790/2000, 耗时:0.01分/10.39分 | step: 458240 | performance: 1.0 | accuracy: 0.13 | loss: 0.24
step: 459004 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
update:1795/2000, 耗时:0.01分/10.42分 | step: 459520 | performance: 1.2 | accuracy: 0.11 | loss: 0.22
step: 460284 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.6 | max total_reward: 225.1
update:1800/2000, 耗时:0.01分/10.45分 | step: 460800 | performance: 1.0 | accuracy: 0.25 | loss: 0.30
update:1805/2000, 耗时:0.01分/10.48分 | step: 462080 | performance: 1.1 | accuracy: 0.17 | loss: 0.21
update:1810/2000, 耗时:0.01分/10.51分 | step: 463360 | performance: 1.1 | accuracy: 0.11 | loss: 0.29
step: 464383 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.6 | max total_reward: 225.1
update:1815/2000, 耗时:0.01分/10.54分 | step: 464640 | performance: 1.0 | accuracy: 0.33 | loss: 0.23
step: 465662 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 465914 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:1820/2000, 耗时:0.01分/10.57分 | step: 465920 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 466688 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.4 | max total_reward: 225.1
step: 466941 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.4 | max total_reward: 225.1
step: 466942 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.4 | max total_reward: 225.1
update:1825/2000, 耗时:0.01分/10.60分 | step: 467200 | performance: 1.0 | accuracy: 0.12 | loss: 0.19
step: 467456 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.4 | max total_reward: 225.1
update:1830/2000, 耗时:0.01分/10.63分 | step: 468480 | performance: 1.1 | accuracy: 0.50 | loss: 0.21
update:1835/2000, 耗时:0.01分/10.66分 | step: 469760 | performance: 1.0 | accuracy: 0.20 | loss: 0.19
step: 470271 | worker_6@n_step_31: average total_reward after train data exhaustion : 2.0 | max total_reward: 225.1
update:1840/2000, 耗时:0.01分/10.69分 | step: 471040 | performance: 1.3 | accuracy: 0.14 | loss: 0.31
update:1845/2000, 耗时:0.01分/10.72分 | step: 472320 | performance: 1.5 | accuracy: 0.13 | loss: 0.32
update:1850/2000, 耗时:0.01分/10.75分 | step: 473600 | performance: 1.5 | accuracy: 0.13 | loss: 0.34
update:1855/2000, 耗时:0.01分/10.77分 | step: 474880 | performance: 1.7 | accuracy: 0.13 | loss: 0.46
step: 475132 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.9 | max total_reward: 225.1
update:1860/2000, 耗时:0.01分/10.80分 | step: 476160 | performance: 1.6 | accuracy: 0.13 | loss: 0.20
update:1865/2000, 耗时:0.01分/10.83分 | step: 477440 | performance: 1.6 | accuracy: 0.12 | loss: 0.21
update:1870/2000, 耗时:0.01分/10.86分 | step: 478720 | performance: 1.5 | accuracy: 0.11 | loss: 0.13
step: 478973 | worker_4@n_step_31: average total_reward after train data exhaustion : 6.8 | max total_reward: 225.1
step: 479482 | worker_1@n_step_31: average total_reward after train data exhaustion : 6.6 | max total_reward: 225.1
step: 479740 | worker_3@n_step_31: average total_reward after train data exhaustion : 7.6 | max total_reward: 225.1
update:1875/2000, 耗时:0.01分/10.89分 | step: 480000 | performance: 1.3 | accuracy: 0.11 | loss: 0.12
update:1880/2000, 耗时:0.01分/10.92分 | step: 481280 | performance: 1.3 | accuracy: 0.11 | loss: 0.09
step: 482046 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:1885/2000, 耗时:0.01分/10.95分 | step: 482560 | performance: 1.3 | accuracy: 0.10 | loss: 0.13
step: 483834 | worker_1@n_step_31: average total_reward after train data exhaustion : 3.2 | max total_reward: 225.1
update:1890/2000, 耗时:0.01分/10.98分 | step: 483840 | performance: 1.0 | accuracy: 0.20 | loss: 0.05
step: 484092 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 484093 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 484351 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 484601 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1895/2000, 耗时:0.01分/11.01分 | step: 485120 | performance: 1.0 | accuracy: 0.08 | loss: 0.07
step: 486394 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1900/2000, 耗时:0.01分/11.04分 | step: 486400 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 486656 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 487675 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1905/2000, 耗时:0.01分/11.07分 | step: 487680 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
step: 488445 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 488953 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
step: 488954 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:1910/2000, 耗时:0.01分/11.10分 | step: 488960 | performance: 1.0 | accuracy: 0.06 | loss: 0.07
step: 489725 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
step: 490235 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 225.1
update:1915/2000, 耗时:0.01分/11.13分 | step: 490240 | performance: 1.0 | accuracy: 0.17 | loss: 0.05
update:1920/2000, 耗时:0.01分/11.16分 | step: 491520 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
step: 491772 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
update:1925/2000, 耗时:0.01分/11.19分 | step: 492800 | performance: 1.1 | accuracy: 0.22 | loss: 0.07
step: 493053 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
step: 493563 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 225.1
step: 494080 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 225.1
update:1930/2000, 耗时:0.01分/11.22分 | step: 494080 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 495357 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.5 | max total_reward: 225.1
update:1935/2000, 耗时:0.01分/11.24分 | step: 495360 | performance: 1.2 | accuracy: 0.31 | loss: 0.16
step: 496634 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.5 | max total_reward: 225.1
update:1940/2000, 耗时:0.01分/11.27分 | step: 496640 | performance: 1.4 | accuracy: 0.16 | loss: 0.21
update:1945/2000, 耗时:0.01分/11.30分 | step: 497920 | performance: 1.5 | accuracy: 0.14 | loss: 0.14
update:1950/2000, 耗时:0.01分/11.33分 | step: 499200 | performance: 1.5 | accuracy: 0.13 | loss: 0.40
step: 500475 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.7 | max total_reward: 225.1
update:1955/2000, 耗时:0.01分/11.36分 | step: 500480 | performance: 1.4 | accuracy: 0.11 | loss: 0.21
update:1960/2000, 耗时:0.01分/11.39分 | step: 501760 | performance: 1.3 | accuracy: 0.11 | loss: 0.28
step: 502778 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
step: 502782 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
update:1965/2000, 耗时:0.01分/11.42分 | step: 503040 | performance: 1.3 | accuracy: 0.10 | loss: 0.11
step: 504319 | worker_6@n_step_31: average total_reward after train data exhaustion : 3.6 | max total_reward: 225.1
update:1970/2000, 耗时:0.01分/11.44分 | step: 504320 | performance: 1.0 | accuracy: 0.12 | loss: 0.11
step: 504576 | worker_7@n_step_31: average total_reward after train data exhaustion : 3.6 | max total_reward: 225.1
step: 504827 | worker_2@n_step_31: average total_reward after train data exhaustion : 3.6 | max total_reward: 225.1
step: 505087 | worker_6@n_step_31: average total_reward after train data exhaustion : 2.6 | max total_reward: 225.1
step: 505338 | worker_1@n_step_31: average total_reward after train data exhaustion : 2.6 | max total_reward: 225.1
update:1975/2000, 耗时:0.01分/11.47分 | step: 505600 | performance: 1.0 | accuracy: 0.11 | loss: 0.11
step: 506618 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
update:1980/2000, 耗时:0.01分/11.51分 | step: 506880 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 507136 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
step: 507387 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 225.1
step: 507902 | worker_5@n_step_31: average total_reward after train data exhaustion : 3.1 | max total_reward: 225.1
update:1985/2000, 耗时:0.01分/11.54分 | step: 508160 | performance: 1.0 | accuracy: 0.07 | loss: 0.12
update:1990/2000, 耗时:0.01分/11.57分 | step: 509440 | performance: 1.0 | accuracy: 0.12 | loss: 0.12
step: 510461 | worker_4@n_step_31: average total_reward after train data exhaustion : 3.9 | max total_reward: 225.1
step: 510715 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.0 | max total_reward: 225.1
update:1995/2000, 耗时:0.01分/11.60分 | step: 510720 | performance: 1.0 | accuracy: 0.25 | loss: 0.10
step: 511483 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.2 | max total_reward: 225.1
step: 511996 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.1 | max total_reward: 225.1
  0%|          | 0/406 [00:00<?, ?it/s]100%|| 406/406 [00:00<00:00, 101465.02it/s]
update:2000/2000, 耗时:0.01分/11.62分 | step: 512000 | performance: 1.1 | accuracy: 0.10 | loss: 0.22
----------------------------------------finished----------------------------------------
==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 992.35
2023-07-24T12:00:00 | net performance [%] = -0.7649
2023-07-24T12:00:00 | number of trades [#] = 6
==================================================
Trial 24 Complete [00h 12m 04s]
net_wealth: 992.3512110029355

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 03h 23m 12s

Search: Running Trial #25

Value             |Best Value So Far |Hyperparameter
4                 |1                 |horizon
365               |730               |lookback
True              |False             |MarketFactor
20                |3                 |lags
0.98              |0.92              |gamma
32                |32                |batch_size
10                |1                 |n_step
0.96              |0.94              |gae_lambda
0.2               |5                 |gradient_clip_norm
3                 |5                 |epochs
0.001             |0.0001            |actor_lr
1e-05             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4297.000000   4301.000000
mean      0.000435    20113.607657  ...   20184.134484  20169.373185
std       0.027833    16040.642334  ...   16078.780856  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7747.959961   7730.930176
50%       0.000642    11571.842969  ...   11755.309570  11751.469727
75%       0.011590    29894.706152  ...   30016.300781  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 01:26:35.20015899: I tensor2023-07-28 01:26:35.015931: I tensorflow/core/platform/cpu_feature_guard.cc22:1403-0223-]07- T27-28h8  20i01023-07:s 1:2T-e28 nsorFlow binary06:352 isflo w/.6c:o305r.1e5915: I /1o0p1:t20p2659t7:23: iemnsoliatfoI5 zerdft. lrewo0m1/winth cps/6cuo_nf0oore0e8A: eartPI ftlou2enIs/p3w/-rco 0e_guar7r-ed.D/2eep8 Nccpe 0u1l:atr2fo6:35:.12a20la2l0 Networok43-tforrmm/0c/pc7puu_r2f-_ef]efa0atult2u ow/8c2r 0oe_Trh1is 3e_gr:26-ugauaT :0rLibredn3sorr7-285..01Fary (cl 601o:ow nec2biD:14n4aNN) tr1d66:.oc use0335c.2 0th1e698] 8e/plat4ff06y: is : I  o:o I oprti:1l4l2tI t eTnhsootiws mrfliT]ensoens/cpumioro Twhis/c_zed withf erFloolnonwo eA/Pcore/pfesorflonaturerIe lwg/p CPaU iDT/tfneepw colo sNeuartfbtirnreunrarosrorem//cplaFy ctmpiusf/or_tionslgcpu__ofwmfeua bi/ncaateu rinala tu repr dorptimizNy .ceetwpis ecordk o_geuua _gp:_1rdrfofeatt.rw4uuim2i] arredm._zcTahnguc:142iath Leibirc]c cesa Tens:1o4nedTr2y] r(h ThAPois isInT -c rTe dDieew.ccnenstiep NeorFlowDur:sorFlotail Nowhc ao e14 Nbrtl2] ThFwobinariys  iTrk nNels Lien) toA ow bPuIseos oppbto Dinim etihernaraeep yrry NeuFrrairzedi fyoaa t sllloowi on(s:  l ois optwiinnew  NegA CPotwbork LiibiptimiraVX zed Ur instrwnya mtihzDr(iA oneAPoeud twh NoNny Ii sDViX)  oneD2e
cTpeNN)ttoeApt iton Peo use tnabl I Dehs iNep Neural e ttoe imizh ufn e do noehewNetpAeumi twsoPrIk Dlee e peirhL the iNreuraaln Nl  bformaNeoneAletwootncP wiwore-frolloowing rkcrikt LCnaicaliIb rDaegrthery  Lo PCUPiU  pi brarnry (oneDinsetNsNtpru(on opery (oc)tionsere rNeuarti in a DNNptitou)erfoon ornmanst,s cuaslo:n e  A use thrce-crtee bf Vioou ilXn sA ViXd2t he NeitiTDNNfcal opee)olrlowi
llennTaotowin  tensgor FClPt pU og iCnerions: Pfoo auwU nAsVX rmtarubo nse tlrckwh Ae t ctioeVhLiins- emb in wX2
Toc rie n pirfaoeerfoonsnatbillowicle thttrruyc eitraliothenrg  CmPm nanopce-ecsriroperaat iiho nttihce s(tiappaoln,o nrseb:uild eDNN) Tn perr ope tn s oin AVXUfoootperati hAer oprVX2 
uTos ee tnh oianbeonss: ie trfucrtialr aAtVieo lloFroteXolman winog CcPe nw tcAUnss,h -reweomm inbpcirliet  VX2
uilir icalTo eother ofple di n  iTnsrtantipoeabrfaructiognteoperlss.,nse nr oetbahs  utihld Tro
hieFrmaen performance-crtionloinmn s: wcien othesrte AVXoi w-rcri appF ticiroprth thca l al iAVX2loae
oTwo o appropppweiorteer rateions:  AVX AVX2
To enable them in other operations, rebuild Tenstations, rebuild Tenshn the appropriaite actoo ompraFrliopwFelb lrewr flaith toatlecompiewhie aplerpropriate  com with o f thgpntlsagcs.
:  AVXsoemp.il ilhee m in other oaper flaA
perpVX2
To enablrratopre  them in other operatiiiooans, te comprgnis.
s, rebuild Tensoeler flags.
rFlow with tbuiflags.
he appropld TensorFlow with the appropriate criate coompiler flags.m
piler flags.
2023-07-28 01:26:35.635244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:26:35.645224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:26:35.650268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:26:35.656241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:26:35.667798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:26:35.678876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:26:35.679347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:26:35.708944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 1.0 | accuracy: 0.44 | loss: 2.63
update: 10/2000, 耗时:0.00分/0.04分 | step:   800 | performance: 0.8 | accuracy: 0.37 | loss: 2.70
update: 15/2000, 耗时:0.00分/0.05分 | step:  1200 | performance: 0.9 | accuracy: 0.39 | loss: 3.17
update: 20/2000, 耗时:0.00分/0.07分 | step:  1600 | performance: 0.5 | accuracy: 0.40 | loss: 2.97
update: 25/2000, 耗时:0.00分/0.08分 | step:  2000 | performance: 0.5 | accuracy: 0.37 | loss: 2.37
update: 30/2000, 耗时:0.00分/0.09分 | step:  2400 | performance: 0.7 | accuracy: 0.37 | loss: 3.63
update: 35/2000, 耗时:0.00分/0.10分 | step:  2800 | performance: 0.9 | accuracy: 0.39 | loss: 2.94
update: 40/2000, 耗时:0.00分/0.11分 | step:  3200 | performance: 1.0 | accuracy: 0.40 | loss: 2.13
update: 45/2000, 耗时:0.00分/0.13分 | step:  3600 | performance: 1.1 | accuracy: 0.40 | loss: 2.68
update: 50/2000, 耗时:0.00分/0.14分 | step:  4000 | performance: 2.8 | accuracy: 0.40 | loss: 6.39
update: 55/2000, 耗时:0.00分/0.15分 | step:  4400 | performance: 2.5 | accuracy: 0.38 | loss: 1.27
update: 60/2000, 耗时:0.00分/0.17分 | step:  4800 | performance: 2.4 | accuracy: 0.35 | loss: 0.98
update: 65/2000, 耗时:0.00分/0.18分 | step:  5200 | performance: 3.4 | accuracy: 0.35 | loss: 2.71
update: 70/2000, 耗时:0.00分/0.20分 | step:  5600 | performance: 2.6 | accuracy: 0.34 | loss: 1.30
update: 75/2000, 耗时:0.00分/0.21分 | step:  6000 | performance: 2.5 | accuracy: 0.33 | loss: 0.59
update: 80/2000, 耗时:0.00分/0.23分 | step:  6400 | performance: 1.4 | accuracy: 0.32 | loss: 2.16
update: 85/2000, 耗时:0.00分/0.24分 | step:  6800 | performance: 4.1 | accuracy: 0.33 | loss: 23.77
update: 90/2000, 耗时:0.00分/0.26分 | step:  7200 | performance: 4.2 | accuracy: 0.34 | loss: 5.12
update: 95/2000, 耗时:0.00分/0.27分 | step:  7600 | performance: 14.7 | accuracy: 0.36 | loss: 5.12
update:100/2000, 耗时:0.00分/0.28分 | step:  8000 | performance: 7.6 | accuracy: 0.36 | loss: 6.46
update:105/2000, 耗时:0.00分/0.30分 | step:  8400 | performance: 10.4 | accuracy: 0.37 | loss: 3.23
update:110/2000, 耗时:0.00分/0.31分 | step:  8800 | performance: 11.8 | accuracy: 0.37 | loss: 1.68
update:115/2000, 耗时:0.00分/0.33分 | step:  9200 | performance: 8.1 | accuracy: 0.37 | loss: 2.55
update:120/2000, 耗时:0.00分/0.34分 | step:  9600 | performance: 10.0 | accuracy: 0.37 | loss: 2.06
update:125/2000, 耗时:0.00分/0.36分 | step: 10000 | performance: 12.3 | accuracy: 0.37 | loss: 17.39
update:130/2000, 耗时:0.00分/0.37分 | step: 10400 | performance: 14.6 | accuracy: 0.37 | loss: 2.03
update:135/2000, 耗时:0.00分/0.39分 | step: 10800 | performance: 8.2 | accuracy: 0.37 | loss: 1.39
update:140/2000, 耗时:0.00分/0.40分 | step: 11200 | performance: 7.8 | accuracy: 0.36 | loss: 1.84
update:145/2000, 耗时:0.00分/0.42分 | step: 11600 | performance: 5.1 | accuracy: 0.36 | loss: 3.47
update:150/2000, 耗时:0.00分/0.43分 | step: 12000 | performance: 12.2 | accuracy: 0.36 | loss: 11.83
update:155/2000, 耗时:0.00分/0.44分 | step: 12400 | performance: 8.6 | accuracy: 0.35 | loss: 0.86
update:160/2000, 耗时:0.00分/0.46分 | step: 12800 | performance: 14.4 | accuracy: 0.36 | loss: 2.37
update:165/2000, 耗时:0.00分/0.47分 | step: 13200 | performance: 12.2 | accuracy: 0.36 | loss: 1.79
update:170/2000, 耗时:0.00分/0.48分 | step: 13600 | performance: 10.1 | accuracy: 0.36 | loss: 2.30
update:175/2000, 耗时:0.00分/0.50分 | step: 14000 | performance: 8.2 | accuracy: 0.36 | loss: 3.62
update:180/2000, 耗时:0.00分/0.51分 | step: 14400 | performance: 9.5 | accuracy: 0.36 | loss: 2.95
update:185/2000, 耗时:0.00分/0.53分 | step: 14800 | performance: 8.9 | accuracy: 0.36 | loss: 2.27
update:190/2000, 耗时:0.00分/0.54分 | step: 15200 | performance: 9.1 | accuracy: 0.36 | loss: 5.83
update:195/2000, 耗时:0.00分/0.56分 | step: 15600 | performance: 20.3 | accuracy: 0.37 | loss: 4.99
update:200/2000, 耗时:0.00分/0.57分 | step: 16000 | performance: 24.9 | accuracy: 0.37 | loss: 4.82
update:205/2000, 耗时:0.00分/0.58分 | step: 16400 | performance: 152.1 | accuracy: 0.38 | loss: 27.69
update:210/2000, 耗时:0.00分/0.60分 | step: 16800 | performance: 141.6 | accuracy: 0.38 | loss: 2.84
update:215/2000, 耗时:0.00分/0.61分 | step: 17200 | performance: 430.5 | accuracy: 0.39 | loss: 7.99
update:220/2000, 耗时:0.00分/0.63分 | step: 17600 | performance: 339.2 | accuracy: 0.39 | loss: 3.28
update:225/2000, 耗时:0.00分/0.64分 | step: 18000 | performance: 400.1 | accuracy: 0.39 | loss: 4.95
update:230/2000, 耗时:0.00分/0.66分 | step: 18400 | performance: 142.1 | accuracy: 0.39 | loss: 2.89
update:235/2000, 耗时:0.00分/0.67分 | step: 18800 | performance: 248.8 | accuracy: 0.39 | loss: 3.18
update:240/2000, 耗时:0.00分/0.68分 | step: 19200 | performance: 147.0 | accuracy: 0.39 | loss: 2.92
update:245/2000, 耗时:0.00分/0.70分 | step: 19600 | performance: 202.7 | accuracy: 0.39 | loss: 3.06
update:250/2000, 耗时:0.00分/0.71分 | step: 20000 | performance: 147.7 | accuracy: 0.39 | loss: 2.37
update:255/2000, 耗时:0.00分/0.73分 | step: 20400 | performance: 119.6 | accuracy: 0.38 | loss: 5.09
update:260/2000, 耗时:0.00分/0.74分 | step: 20800 | performance: 155.6 | accuracy: 0.38 | loss: 1.92
update:265/2000, 耗时:0.00分/0.75分 | step: 21200 | performance: 177.7 | accuracy: 0.38 | loss: 2.68
update:270/2000, 耗时:0.00分/0.77分 | step: 21600 | performance: 213.2 | accuracy: 0.38 | loss: 3.32
update:275/2000, 耗时:0.00分/0.78分 | step: 22000 | performance: 221.2 | accuracy: 0.38 | loss: 2.02
update:280/2000, 耗时:0.00分/0.80分 | step: 22400 | performance: 231.1 | accuracy: 0.38 | loss: 2.40
update:285/2000, 耗时:0.00分/0.81分 | step: 22800 | performance: 342.9 | accuracy: 0.38 | loss: 0.92
update:290/2000, 耗时:0.00分/0.82分 | step: 23200 | performance: 324.9 | accuracy: 0.38 | loss: 1.74
update:295/2000, 耗时:0.00分/0.84分 | step: 23600 | performance: 350.3 | accuracy: 0.37 | loss: 0.27
update:300/2000, 耗时:0.00分/0.85分 | step: 24000 | performance: 390.9 | accuracy: 0.37 | loss: 0.72
update:305/2000, 耗时:0.00分/0.87分 | step: 24400 | performance: 723.1 | accuracy: 0.37 | loss: 3.65
update:310/2000, 耗时:0.00分/0.88分 | step: 24800 | performance: 811.5 | accuracy: 0.36 | loss: 0.36
update:315/2000, 耗时:0.00分/0.89分 | step: 25200 | performance: 848.2 | accuracy: 0.36 | loss: 2.96
update:320/2000, 耗时:0.00分/0.91分 | step: 25600 | performance: 830.9 | accuracy: 0.36 | loss: 1.17
update:325/2000, 耗时:0.00分/0.92分 | step: 26000 | performance: 827.5 | accuracy: 0.35 | loss: 0.47
update:330/2000, 耗时:0.00分/0.94分 | step: 26400 | performance: 896.5 | accuracy: 0.35 | loss: 3.19
update:335/2000, 耗时:0.00分/0.95分 | step: 26800 | performance: 965.5 | accuracy: 0.35 | loss: 0.84
update:340/2000, 耗时:0.00分/0.96分 | step: 27200 | performance: 958.4 | accuracy: 0.35 | loss: 0.09
update:345/2000, 耗时:0.00分/0.98分 | step: 27600 | performance: 977.5 | accuracy: 0.34 | loss: 0.31
update:350/2000, 耗时:0.00分/0.99分 | step: 28000 | performance: 973.7 | accuracy: 0.34 | loss: 0.12
Saving PPO weights in both H5 format and checkpoint @ update:351 
update:355/2000, 耗时:0.00分/1.01分 | step: 28400 | performance: 1.2 | accuracy: 0.17 | loss: 0.99
update:360/2000, 耗时:0.00分/1.02分 | step: 28800 | performance: 1.0 | accuracy: 0.00 | loss: 0.32
step: 29115 | worker_2@n_step_9: average total_reward after train data exhaustion : 29.3 | max total_reward: 181.4
step: 29120 | worker_7@n_step_9: average total_reward after train data exhaustion : 28.3 | max total_reward: 181.4
step: 29193 | worker_0@n_step_9: average total_reward after train data exhaustion : 26.4 | max total_reward: 181.4
update:365/2000, 耗时:0.00分/1.04分 | step: 29200 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
step: 29277 | worker_4@n_step_9: average total_reward after train data exhaustion : 22.9 | max total_reward: 181.4
update:370/2000, 耗时:0.00分/1.05分 | step: 29600 | performance: 1.9 | accuracy: 0.33 | loss: 6.70
update:375/2000, 耗时:0.00分/1.06分 | step: 30000 | performance: 1.5 | accuracy: 0.20 | loss: 0.44
update:380/2000, 耗时:0.00分/1.07分 | step: 30400 | performance: 1.7 | accuracy: 0.18 | loss: 0.82
update:385/2000, 耗时:0.00分/1.09分 | step: 30800 | performance: 2.0 | accuracy: 0.20 | loss: 1.51
update:390/2000, 耗时:0.00分/1.10分 | step: 31200 | performance: 2.0 | accuracy: 0.19 | loss: 0.56
update:395/2000, 耗时:0.00分/1.11分 | step: 31600 | performance: 1.9 | accuracy: 0.19 | loss: 2.85
update:400/2000, 耗时:0.00分/1.13分 | step: 32000 | performance: 1.6 | accuracy: 0.17 | loss: 1.06
update:405/2000, 耗时:0.00分/1.14分 | step: 32400 | performance: 2.1 | accuracy: 0.17 | loss: 0.68
update:410/2000, 耗时:0.00分/1.15分 | step: 32800 | performance: 2.3 | accuracy: 0.18 | loss: 2.71
update:415/2000, 耗时:0.00分/1.17分 | step: 33200 | performance: 3.5 | accuracy: 0.21 | loss: 5.51
update:420/2000, 耗时:0.00分/1.18分 | step: 33600 | performance: 23.3 | accuracy: 0.25 | loss: 7.96
update:425/2000, 耗时:0.00分/1.20分 | step: 34000 | performance: 15.9 | accuracy: 0.26 | loss: 2.87
update:430/2000, 耗时:0.00分/1.21分 | step: 34400 | performance: 24.4 | accuracy: 0.28 | loss: 4.25
update:435/2000, 耗时:0.00分/1.22分 | step: 34800 | performance: 14.7 | accuracy: 0.29 | loss: 5.68
update:440/2000, 耗时:0.00分/1.24分 | step: 35200 | performance: 14.4 | accuracy: 0.30 | loss: 2.91
update:445/2000, 耗时:0.00分/1.25分 | step: 35600 | performance: 5.9 | accuracy: 0.29 | loss: 6.01
update:450/2000, 耗时:0.00分/1.27分 | step: 36000 | performance: 2.4 | accuracy: 0.29 | loss: 13.75
update:455/2000, 耗时:0.00分/1.28分 | step: 36400 | performance: 1.1 | accuracy: 0.30 | loss: 7.99
update:460/2000, 耗时:0.00分/1.29分 | step: 36800 | performance: 0.2 | accuracy: 0.30 | loss: 10.37
update:465/2000, 耗时:0.00分/1.31分 | step: 37200 | performance: 0.5 | accuracy: 0.31 | loss: 9.49
update:470/2000, 耗时:0.00分/1.32分 | step: 37600 | performance: 0.5 | accuracy: 0.32 | loss: 4.18
update:475/2000, 耗时:0.00分/1.33分 | step: 38000 | performance: 0.6 | accuracy: 0.33 | loss: 4.10
update:480/2000, 耗时:0.00分/1.35分 | step: 38400 | performance: 1.5 | accuracy: 0.34 | loss: 7.28
update:485/2000, 耗时:0.00分/1.36分 | step: 38800 | performance: 0.9 | accuracy: 0.35 | loss: 6.41
update:490/2000, 耗时:0.00分/1.38分 | step: 39200 | performance: 2.7 | accuracy: 0.36 | loss: 9.23
update:495/2000, 耗时:0.00分/1.39分 | step: 39600 | performance: 2.8 | accuracy: 0.37 | loss: 5.31
update:500/2000, 耗时:0.00分/1.40分 | step: 40000 | performance: 1.3 | accuracy: 0.37 | loss: 10.78
update:505/2000, 耗时:0.00分/1.42分 | step: 40400 | performance: 0.8 | accuracy: 0.37 | loss: 10.70
update:510/2000, 耗时:0.00分/1.43分 | step: 40800 | performance: 1.3 | accuracy: 0.37 | loss: 7.15
update:515/2000, 耗时:0.00分/1.44分 | step: 41200 | performance: 5.9 | accuracy: 0.38 | loss: 6.68
update:520/2000, 耗时:0.00分/1.46分 | step: 41600 | performance: 3.0 | accuracy: 0.38 | loss: 9.45
update:525/2000, 耗时:0.00分/1.47分 | step: 42000 | performance: 1.1 | accuracy: 0.37 | loss: 6.76
update:530/2000, 耗时:0.00分/1.48分 | step: 42400 | performance: 1.3 | accuracy: 0.38 | loss: 3.13
update:535/2000, 耗时:0.00分/1.50分 | step: 42800 | performance: 1.4 | accuracy: 0.38 | loss: 7.63
update:540/2000, 耗时:0.00分/1.51分 | step: 43200 | performance: 0.7 | accuracy: 0.38 | loss: 6.04
update:545/2000, 耗时:0.00分/1.52分 | step: 43600 | performance: 0.7 | accuracy: 0.38 | loss: 6.62
update:550/2000, 耗时:0.00分/1.54分 | step: 44000 | performance: 1.3 | accuracy: 0.38 | loss: 5.77
update:555/2000, 耗时:0.00分/1.55分 | step: 44400 | performance: 1.2 | accuracy: 0.38 | loss: 2.62
update:560/2000, 耗时:0.00分/1.56分 | step: 44800 | performance: 3.4 | accuracy: 0.39 | loss: 5.99
update:565/2000, 耗时:0.00分/1.58分 | step: 45200 | performance: 7.5 | accuracy: 0.40 | loss: 5.35
update:570/2000, 耗时:0.00分/1.59分 | step: 45600 | performance: 32.3 | accuracy: 0.41 | loss: 13.50
update:575/2000, 耗时:0.00分/1.60分 | step: 46000 | performance: 54.4 | accuracy: 0.41 | loss: 4.96
update:580/2000, 耗时:0.00分/1.62分 | step: 46400 | performance: 374.8 | accuracy: 0.42 | loss: 9.28
update:585/2000, 耗时:0.00分/1.63分 | step: 46800 | performance: 500.5 | accuracy: 0.42 | loss: 8.86
update:590/2000, 耗时:0.00分/1.64分 | step: 47200 | performance: 558.2 | accuracy: 0.43 | loss: 7.12
update:595/2000, 耗时:0.00分/1.66分 | step: 47600 | performance: 417.2 | accuracy: 0.43 | loss: 7.30
update:600/2000, 耗时:0.00分/1.67分 | step: 48000 | performance: 66.8 | accuracy: 0.42 | loss: 8.22
update:605/2000, 耗时:0.00分/1.68分 | step: 48400 | performance: 50.3 | accuracy: 0.42 | loss: 4.96
update:610/2000, 耗时:0.00分/1.70分 | step: 48800 | performance: 37.9 | accuracy: 0.42 | loss: 7.21
update:615/2000, 耗时:0.00分/1.71分 | step: 49200 | performance: 140.5 | accuracy: 0.43 | loss: 4.35
update:620/2000, 耗时:0.00分/1.72分 | step: 49600 | performance: 191.1 | accuracy: 0.43 | loss: 4.70
update:625/2000, 耗时:0.00分/1.74分 | step: 50000 | performance: 121.6 | accuracy: 0.43 | loss: 8.15
update:630/2000, 耗时:0.00分/1.75分 | step: 50400 | performance: 292.0 | accuracy: 0.43 | loss: 4.85
update:635/2000, 耗时:0.00分/1.76分 | step: 50800 | performance: 206.0 | accuracy: 0.43 | loss: 3.49
update:640/2000, 耗时:0.00分/1.78分 | step: 51200 | performance: 81.6 | accuracy: 0.43 | loss: 3.04
update:645/2000, 耗时:0.00分/1.79分 | step: 51600 | performance: 114.9 | accuracy: 0.43 | loss: 1.66
update:650/2000, 耗时:0.00分/1.81分 | step: 52000 | performance: 150.0 | accuracy: 0.43 | loss: 2.31
update:655/2000, 耗时:0.00分/1.82分 | step: 52400 | performance: 135.4 | accuracy: 0.43 | loss: 1.91
update:660/2000, 耗时:0.00分/1.83分 | step: 52800 | performance: 120.8 | accuracy: 0.43 | loss: 1.94
update:665/2000, 耗时:0.00分/1.85分 | step: 53200 | performance: 115.3 | accuracy: 0.43 | loss: 3.40
update:670/2000, 耗时:0.00分/1.86分 | step: 53600 | performance: 327.9 | accuracy: 0.43 | loss: 5.92
update:675/2000, 耗时:0.00分/1.87分 | step: 54000 | performance: 275.5 | accuracy: 0.44 | loss: 4.84
update:680/2000, 耗时:0.00分/1.89分 | step: 54400 | performance: 1241.8 | accuracy: 0.44 | loss: 5.84
update:685/2000, 耗时:0.00分/1.90分 | step: 54800 | performance: 752.6 | accuracy: 0.44 | loss: 4.24
update:690/2000, 耗时:0.00分/1.92分 | step: 55200 | performance: 1178.7 | accuracy: 0.44 | loss: 3.76
update:695/2000, 耗时:0.00分/1.93分 | step: 55600 | performance: 2113.3 | accuracy: 0.44 | loss: 10.93
update:700/2000, 耗时:0.00分/1.94分 | step: 56000 | performance: 2553.5 | accuracy: 0.44 | loss: 6.74
update:705/2000, 耗时:0.00分/1.96分 | step: 56400 | performance: 1748.1 | accuracy: 0.44 | loss: 7.75
update:710/2000, 耗时:0.00分/1.97分 | step: 56800 | performance: 4627.6 | accuracy: 0.45 | loss: 1.83
update:715/2000, 耗时:0.00分/1.98分 | step: 57200 | performance: 4884.5 | accuracy: 0.45 | loss: 1.79
update:720/2000, 耗时:0.00分/2.00分 | step: 57600 | performance: 1.6 | accuracy: 0.66 | loss: 10.04
update:725/2000, 耗时:0.00分/2.01分 | step: 58000 | performance: 1.0 | accuracy: 0.46 | loss: 3.47
update:730/2000, 耗时:0.00分/2.02分 | step: 58400 | performance: 1.2 | accuracy: 0.47 | loss: 3.03
update:735/2000, 耗时:0.00分/2.04分 | step: 58800 | performance: 2.5 | accuracy: 0.46 | loss: 2.00
update:740/2000, 耗时:0.00分/2.05分 | step: 59200 | performance: 2.6 | accuracy: 0.45 | loss: 3.70
update:745/2000, 耗时:0.00分/2.06分 | step: 59600 | performance: 1.4 | accuracy: 0.43 | loss: 3.76
update:750/2000, 耗时:0.00分/2.08分 | step: 60000 | performance: 1.2 | accuracy: 0.41 | loss: 4.29
update:755/2000, 耗时:0.00分/2.09分 | step: 60400 | performance: 1.3 | accuracy: 0.39 | loss: 1.95
update:760/2000, 耗时:0.00分/2.10分 | step: 60800 | performance: 1.2 | accuracy: 0.36 | loss: 1.02
update:765/2000, 耗时:0.00分/2.12分 | step: 61200 | performance: 1.2 | accuracy: 0.34 | loss: 1.67
update:770/2000, 耗时:0.00分/2.13分 | step: 61600 | performance: 4.4 | accuracy: 0.36 | loss: 8.43
update:775/2000, 耗时:0.00分/2.14分 | step: 62000 | performance: 4.0 | accuracy: 0.37 | loss: 3.94
update:780/2000, 耗时:0.00分/2.16分 | step: 62400 | performance: 5.5 | accuracy: 0.37 | loss: 1.76
update:785/2000, 耗时:0.00分/2.17分 | step: 62800 | performance: 5.2 | accuracy: 0.37 | loss: 3.09
update:790/2000, 耗时:0.00分/2.18分 | step: 63200 | performance: 5.5 | accuracy: 0.36 | loss: 1.37
update:795/2000, 耗时:0.00分/2.20分 | step: 63600 | performance: 3.2 | accuracy: 0.36 | loss: 2.87
update:800/2000, 耗时:0.00分/2.21分 | step: 64000 | performance: 4.0 | accuracy: 0.36 | loss: 2.57
update:805/2000, 耗时:0.00分/2.22分 | step: 64400 | performance: 12.8 | accuracy: 0.37 | loss: 5.15
update:810/2000, 耗时:0.00分/2.24分 | step: 64800 | performance: 41.3 | accuracy: 0.39 | loss: 14.35
update:815/2000, 耗时:0.00分/2.25分 | step: 65200 | performance: 23.4 | accuracy: 0.39 | loss: 5.05
update:820/2000, 耗时:0.00分/2.26分 | step: 65600 | performance: 19.5 | accuracy: 0.39 | loss: 11.28
update:825/2000, 耗时:0.00分/2.28分 | step: 66000 | performance: 18.6 | accuracy: 0.40 | loss: 7.96
update:830/2000, 耗时:0.00分/2.29分 | step: 66400 | performance: 6.9 | accuracy: 0.40 | loss: 4.07
update:835/2000, 耗时:0.00分/2.30分 | step: 66800 | performance: 7.6 | accuracy: 0.40 | loss: 3.83
update:840/2000, 耗时:0.00分/2.32分 | step: 67200 | performance: 4.2 | accuracy: 0.39 | loss: 3.61
update:845/2000, 耗时:0.00分/2.33分 | step: 67600 | performance: 4.1 | accuracy: 0.39 | loss: 2.86
update:850/2000, 耗时:0.00分/2.34分 | step: 68000 | performance: 3.5 | accuracy: 0.38 | loss: 0.59
update:855/2000, 耗时:0.00分/2.36分 | step: 68400 | performance: 3.8 | accuracy: 0.38 | loss: 1.38
update:860/2000, 耗时:0.00分/2.37分 | step: 68800 | performance: 2.6 | accuracy: 0.37 | loss: 3.71
update:865/2000, 耗时:0.00分/2.38分 | step: 69200 | performance: 0.8 | accuracy: 0.37 | loss: 1.85
update:870/2000, 耗时:0.00分/2.40分 | step: 69600 | performance: 0.7 | accuracy: 0.36 | loss: 1.02
update:875/2000, 耗时:0.00分/2.41分 | step: 70000 | performance: 1.5 | accuracy: 0.36 | loss: 2.93
update:880/2000, 耗时:0.00分/2.42分 | step: 70400 | performance: 1.2 | accuracy: 0.36 | loss: 2.99
update:885/2000, 耗时:0.00分/2.44分 | step: 70800 | performance: 0.9 | accuracy: 0.35 | loss: 1.92
update:890/2000, 耗时:0.00分/2.45分 | step: 71200 | performance: 1.5 | accuracy: 0.36 | loss: 5.81
update:895/2000, 耗时:0.00分/2.46分 | step: 71600 | performance: 1.5 | accuracy: 0.35 | loss: 4.04
update:900/2000, 耗时:0.00分/2.48分 | step: 72000 | performance: 1.1 | accuracy: 0.35 | loss: 3.81
update:905/2000, 耗时:0.00分/2.49分 | step: 72400 | performance: 1.4 | accuracy: 0.35 | loss: 5.84
update:910/2000, 耗时:0.00分/2.51分 | step: 72800 | performance: 3.0 | accuracy: 0.36 | loss: 5.15
update:915/2000, 耗时:0.00分/2.52分 | step: 73200 | performance: 6.0 | accuracy: 0.36 | loss: 11.05
update:920/2000, 耗时:0.00分/2.53分 | step: 73600 | performance: 12.4 | accuracy: 0.37 | loss: 9.73
update:925/2000, 耗时:0.00分/2.55分 | step: 74000 | performance: 23.7 | accuracy: 0.37 | loss: 6.22
update:930/2000, 耗时:0.00分/2.56分 | step: 74400 | performance: 79.0 | accuracy: 0.38 | loss: 8.40
update:935/2000, 耗时:0.00分/2.57分 | step: 74800 | performance: 147.1 | accuracy: 0.38 | loss: 11.53
update:940/2000, 耗时:0.00分/2.59分 | step: 75200 | performance: 156.8 | accuracy: 0.38 | loss: 6.08
update:945/2000, 耗时:0.00分/2.60分 | step: 75600 | performance: 115.9 | accuracy: 0.38 | loss: 5.50
update:950/2000, 耗时:0.00分/2.61分 | step: 76000 | performance: 24.6 | accuracy: 0.38 | loss: 9.60
update:955/2000, 耗时:0.00分/2.63分 | step: 76400 | performance: 16.7 | accuracy: 0.38 | loss: 13.25
update:960/2000, 耗时:0.00分/2.64分 | step: 76800 | performance: 11.4 | accuracy: 0.39 | loss: 8.75
update:965/2000, 耗时:0.00分/2.65分 | step: 77200 | performance: 42.2 | accuracy: 0.39 | loss: 14.06
update:970/2000, 耗时:0.00分/2.67分 | step: 77600 | performance: 55.1 | accuracy: 0.39 | loss: 4.13
update:975/2000, 耗时:0.00分/2.68分 | step: 78000 | performance: 35.9 | accuracy: 0.39 | loss: 3.78
update:980/2000, 耗时:0.00分/2.69分 | step: 78400 | performance: 141.4 | accuracy: 0.40 | loss: 4.08
update:985/2000, 耗时:0.00分/2.71分 | step: 78800 | performance: 127.2 | accuracy: 0.40 | loss: 4.67
update:990/2000, 耗时:0.00分/2.72分 | step: 79200 | performance: 49.7 | accuracy: 0.40 | loss: 1.81
update:995/2000, 耗时:0.00分/2.74分 | step: 79600 | performance: 39.0 | accuracy: 0.40 | loss: 2.65
update:1000/2000, 耗时:0.00分/2.75分 | step: 80000 | performance: 21.9 | accuracy: 0.40 | loss: 3.20
update:1005/2000, 耗时:0.00分/2.76分 | step: 80400 | performance: 22.8 | accuracy: 0.40 | loss: 3.82
update:1010/2000, 耗时:0.00分/2.78分 | step: 80800 | performance: 24.6 | accuracy: 0.40 | loss: 1.79
update:1015/2000, 耗时:0.00分/2.79分 | step: 81200 | performance: 22.6 | accuracy: 0.40 | loss: 4.83
update:1020/2000, 耗时:0.00分/2.80分 | step: 81600 | performance: 12.6 | accuracy: 0.40 | loss: 6.46
update:1025/2000, 耗时:0.00分/2.82分 | step: 82000 | performance: 14.2 | accuracy: 0.40 | loss: 11.89
update:1030/2000, 耗时:0.00分/2.83分 | step: 82400 | performance: 39.5 | accuracy: 0.40 | loss: 7.67
update:1035/2000, 耗时:0.00分/2.84分 | step: 82800 | performance: 29.1 | accuracy: 0.41 | loss: 10.56
update:1040/2000, 耗时:0.00分/2.86分 | step: 83200 | performance: 24.7 | accuracy: 0.41 | loss: 2.13
update:1045/2000, 耗时:0.00分/2.87分 | step: 83600 | performance: 31.8 | accuracy: 0.41 | loss: 3.48
update:1050/2000, 耗时:0.00分/2.88分 | step: 84000 | performance: 36.0 | accuracy: 0.41 | loss: 2.04
update:1055/2000, 耗时:0.00分/2.90分 | step: 84400 | performance: 40.4 | accuracy: 0.41 | loss: 2.13
update:1060/2000, 耗时:0.00分/2.91分 | step: 84800 | performance: 14.5 | accuracy: 0.41 | loss: 1.77
update:1065/2000, 耗时:0.00分/2.92分 | step: 85200 | performance: 12.1 | accuracy: 0.41 | loss: 3.26
update:1070/2000, 耗时:0.00分/2.94分 | step: 85600 | performance: 0.8 | accuracy: 0.44 | loss: 6.24
update:1075/2000, 耗时:0.00分/2.95分 | step: 86000 | performance: 0.5 | accuracy: 0.45 | loss: 3.86
update:1080/2000, 耗时:0.00分/2.96分 | step: 86400 | performance: 0.8 | accuracy: 0.45 | loss: 2.59
update:1085/2000, 耗时:0.00分/2.98分 | step: 86800 | performance: 1.3 | accuracy: 0.48 | loss: 7.94
update:1090/2000, 耗时:0.00分/2.99分 | step: 87200 | performance: 1.6 | accuracy: 0.48 | loss: 3.34
update:1095/2000, 耗时:0.00分/3.00分 | step: 87600 | performance: 0.8 | accuracy: 0.47 | loss: 4.41
update:1100/2000, 耗时:0.00分/3.02分 | step: 88000 | performance: 0.9 | accuracy: 0.47 | loss: 5.58
update:1105/2000, 耗时:0.00分/3.03分 | step: 88400 | performance: 0.9 | accuracy: 0.46 | loss: 5.10
update:1110/2000, 耗时:0.00分/3.04分 | step: 88800 | performance: 1.1 | accuracy: 0.47 | loss: 3.31
update:1115/2000, 耗时:0.00分/3.06分 | step: 89200 | performance: 1.2 | accuracy: 0.47 | loss: 3.94
update:1120/2000, 耗时:0.00分/3.07分 | step: 89600 | performance: 5.5 | accuracy: 0.49 | loss: 6.94
update:1125/2000, 耗时:0.00分/3.08分 | step: 90000 | performance: 8.5 | accuracy: 0.49 | loss: 4.19
update:1130/2000, 耗时:0.00分/3.10分 | step: 90400 | performance: 8.5 | accuracy: 0.48 | loss: 3.14
update:1135/2000, 耗时:0.00分/3.11分 | step: 90800 | performance: 8.7 | accuracy: 0.47 | loss: 2.46
update:1140/2000, 耗时:0.00分/3.13分 | step: 91200 | performance: 6.3 | accuracy: 0.46 | loss: 1.06
update:1145/2000, 耗时:0.00分/3.14分 | step: 91600 | performance: 7.5 | accuracy: 0.46 | loss: 7.84
update:1150/2000, 耗时:0.00分/3.15分 | step: 92000 | performance: 10.5 | accuracy: 0.46 | loss: 7.17
update:1155/2000, 耗时:0.00分/3.17分 | step: 92400 | performance: 34.7 | accuracy: 0.46 | loss: 7.85
update:1160/2000, 耗时:0.00分/3.18分 | step: 92800 | performance: 59.5 | accuracy: 0.47 | loss: 11.62
update:1165/2000, 耗时:0.00分/3.19分 | step: 93200 | performance: 54.9 | accuracy: 0.47 | loss: 7.97
update:1170/2000, 耗时:0.00分/3.21分 | step: 93600 | performance: 58.8 | accuracy: 0.47 | loss: 4.69
update:1175/2000, 耗时:0.00分/3.22分 | step: 94000 | performance: 46.9 | accuracy: 0.46 | loss: 3.01
update:1180/2000, 耗时:0.00分/3.23分 | step: 94400 | performance: 45.0 | accuracy: 0.45 | loss: 1.13
update:1185/2000, 耗时:0.00分/3.25分 | step: 94800 | performance: 48.7 | accuracy: 0.45 | loss: 3.67
update:1190/2000, 耗时:0.00分/3.26分 | step: 95200 | performance: 25.1 | accuracy: 0.45 | loss: 2.21
update:1195/2000, 耗时:0.00分/3.27分 | step: 95600 | performance: 33.2 | accuracy: 0.44 | loss: 4.45
update:1200/2000, 耗时:0.00分/3.28分 | step: 96000 | performance: 25.8 | accuracy: 0.44 | loss: 9.74
update:1205/2000, 耗时:0.00分/3.30分 | step: 96400 | performance: 14.1 | accuracy: 0.44 | loss: 3.63
update:1210/2000, 耗时:0.00分/3.31分 | step: 96800 | performance: 13.0 | accuracy: 0.43 | loss: 1.46
update:1215/2000, 耗时:0.00分/3.32分 | step: 97200 | performance: 18.4 | accuracy: 0.42 | loss: 6.08
update:1220/2000, 耗时:0.00分/3.34分 | step: 97600 | performance: 8.9 | accuracy: 0.41 | loss: 2.30
update:1225/2000, 耗时:0.00分/3.35分 | step: 98000 | performance: 8.7 | accuracy: 0.40 | loss: 1.19
update:1230/2000, 耗时:0.00分/3.36分 | step: 98400 | performance: 8.4 | accuracy: 0.39 | loss: 0.05
update:1235/2000, 耗时:0.00分/3.38分 | step: 98800 | performance: 8.4 | accuracy: 0.38 | loss: 0.00
update:1240/2000, 耗时:0.00分/3.39分 | step: 99200 | performance: 8.4 | accuracy: 0.37 | loss: 0.07
update:1245/2000, 耗时:0.00分/3.40分 | step: 99600 | performance: 8.4 | accuracy: 0.36 | loss: 0.06
update:1250/2000, 耗时:0.00分/3.42分 | step: 100000 | performance: 8.4 | accuracy: 0.35 | loss: 0.01
update:1255/2000, 耗时:0.00分/3.43分 | step: 100400 | performance: 8.3 | accuracy: 0.35 | loss: 0.11
update:1260/2000, 耗时:0.00分/3.44分 | step: 100800 | performance: 8.3 | accuracy: 0.34 | loss: 0.01
update:1265/2000, 耗时:0.00分/3.46分 | step: 101200 | performance: 8.3 | accuracy: 0.33 | loss: 0.04
update:1270/2000, 耗时:0.00分/3.47分 | step: 101600 | performance: 8.3 | accuracy: 0.32 | loss: 0.03
update:1275/2000, 耗时:0.00分/3.48分 | step: 102000 | performance: 8.3 | accuracy: 0.31 | loss: 0.11
update:1280/2000, 耗时:0.00分/3.50分 | step: 102400 | performance: 8.3 | accuracy: 0.31 | loss: 0.04
update:1285/2000, 耗时:0.00分/3.51分 | step: 102800 | performance: 8.3 | accuracy: 0.30 | loss: 0.02
update:1290/2000, 耗时:0.00分/3.52分 | step: 103200 | performance: 8.3 | accuracy: 0.29 | loss: 0.12
update:1295/2000, 耗时:0.00分/3.54分 | step: 103600 | performance: 8.3 | accuracy: 0.29 | loss: 0.11
update:1300/2000, 耗时:0.00分/3.55分 | step: 104000 | performance: 8.3 | accuracy: 0.28 | loss: 0.05
update:1305/2000, 耗时:0.00分/3.57分 | step: 104400 | performance: 8.9 | accuracy: 0.28 | loss: 0.49
update:1310/2000, 耗时:0.00分/3.58分 | step: 104800 | performance: 10.0 | accuracy: 0.27 | loss: 2.06
update:1315/2000, 耗时:0.00分/3.59分 | step: 105200 | performance: 7.0 | accuracy: 0.27 | loss: 5.46
update:1320/2000, 耗时:0.00分/3.61分 | step: 105600 | performance: 3.9 | accuracy: 0.27 | loss: 2.27
update:1325/2000, 耗时:0.00分/3.62分 | step: 106000 | performance: 6.2 | accuracy: 0.28 | loss: 5.23
update:1330/2000, 耗时:0.00分/3.63分 | step: 106400 | performance: 1.6 | accuracy: 0.28 | loss: 6.38
update:1335/2000, 耗时:0.00分/3.65分 | step: 106800 | performance: 1.4 | accuracy: 0.28 | loss: 4.44
update:1340/2000, 耗时:0.00分/3.66分 | step: 107200 | performance: 3.9 | accuracy: 0.29 | loss: 5.17
update:1345/2000, 耗时:0.00分/3.67分 | step: 107600 | performance: 5.5 | accuracy: 0.29 | loss: 3.78
update:1350/2000, 耗时:0.00分/3.69分 | step: 108000 | performance: 14.8 | accuracy: 0.30 | loss: 8.50
update:1355/2000, 耗时:0.00分/3.70分 | step: 108400 | performance: 13.4 | accuracy: 0.30 | loss: 11.82
update:1360/2000, 耗时:0.00分/3.72分 | step: 108800 | performance: 11.2 | accuracy: 0.30 | loss: 7.86
update:1365/2000, 耗时:0.00分/3.73分 | step: 109200 | performance: 11.8 | accuracy: 0.31 | loss: 9.62
update:1370/2000, 耗时:0.00分/3.74分 | step: 109600 | performance: 20.3 | accuracy: 0.31 | loss: 7.67
update:1375/2000, 耗时:0.00分/3.76分 | step: 110000 | performance: 35.8 | accuracy: 0.32 | loss: 7.83
update:1380/2000, 耗时:0.00分/3.77分 | step: 110400 | performance: 180.4 | accuracy: 0.32 | loss: 8.66
update:1385/2000, 耗时:0.00分/3.78分 | step: 110800 | performance: 137.6 | accuracy: 0.32 | loss: 9.30
update:1390/2000, 耗时:0.00分/3.80分 | step: 111200 | performance: 120.1 | accuracy: 0.33 | loss: 3.38
update:1395/2000, 耗时:0.00分/3.81分 | step: 111600 | performance: 294.3 | accuracy: 0.33 | loss: 4.97
update:1400/2000, 耗时:0.00分/3.82分 | step: 112000 | performance: 324.8 | accuracy: 0.34 | loss: 2.86
update:1405/2000, 耗时:0.00分/3.83分 | step: 112400 | performance: 280.9 | accuracy: 0.34 | loss: 4.54
update:1410/2000, 耗时:0.00分/3.85分 | step: 112800 | performance: 771.2 | accuracy: 0.34 | loss: 4.22
update:1415/2000, 耗时:0.00分/3.86分 | step: 113200 | performance: 695.9 | accuracy: 0.34 | loss: 4.20
update:1420/2000, 耗时:0.00分/3.87分 | step: 113600 | performance: 0.9 | accuracy: 0.47 | loss: 2.85
update:1425/2000, 耗时:0.00分/3.89分 | step: 114000 | performance: 1.2 | accuracy: 0.52 | loss: 6.34
update:1430/2000, 耗时:0.00分/3.90分 | step: 114400 | performance: 1.0 | accuracy: 0.50 | loss: 6.28
update:1435/2000, 耗时:0.00分/3.91分 | step: 114800 | performance: 1.7 | accuracy: 0.51 | loss: 3.20
update:1440/2000, 耗时:0.00分/3.93分 | step: 115200 | performance: 3.4 | accuracy: 0.53 | loss: 7.38
update:1445/2000, 耗时:0.00分/3.94分 | step: 115600 | performance: 1.5 | accuracy: 0.50 | loss: 5.15
update:1450/2000, 耗时:0.00分/3.95分 | step: 116000 | performance: 3.8 | accuracy: 0.52 | loss: 2.95
update:1455/2000, 耗时:0.00分/3.97分 | step: 116400 | performance: 3.9 | accuracy: 0.50 | loss: 8.21
update:1460/2000, 耗时:0.00分/3.98分 | step: 116800 | performance: 4.0 | accuracy: 0.49 | loss: 3.10
update:1465/2000, 耗时:0.00分/3.99分 | step: 117200 | performance: 4.5 | accuracy: 0.50 | loss: 5.12
update:1470/2000, 耗时:0.00分/4.00分 | step: 117600 | performance: 25.1 | accuracy: 0.52 | loss: 6.00
update:1475/2000, 耗时:0.00分/4.02分 | step: 118000 | performance: 35.3 | accuracy: 0.52 | loss: 6.68
update:1480/2000, 耗时:0.00分/4.03分 | step: 118400 | performance: 51.9 | accuracy: 0.52 | loss: 7.86
update:1485/2000, 耗时:0.00分/4.04分 | step: 118800 | performance: 54.8 | accuracy: 0.52 | loss: 6.04
update:1490/2000, 耗时:0.00分/4.06分 | step: 119200 | performance: 42.6 | accuracy: 0.50 | loss: 6.76
update:1495/2000, 耗时:0.00分/4.07分 | step: 119600 | performance: 17.8 | accuracy: 0.50 | loss: 15.77
update:1500/2000, 耗时:0.00分/4.08分 | step: 120000 | performance: 13.8 | accuracy: 0.48 | loss: 4.73
update:1505/2000, 耗时:0.00分/4.10分 | step: 120400 | performance: 3.2 | accuracy: 0.47 | loss: 9.48
update:1510/2000, 耗时:0.00分/4.11分 | step: 120800 | performance: 1.7 | accuracy: 0.47 | loss: 11.48
update:1515/2000, 耗时:0.00分/4.12分 | step: 121200 | performance: 0.7 | accuracy: 0.46 | loss: 11.42
update:1520/2000, 耗时:0.00分/4.14分 | step: 121600 | performance: 0.7 | accuracy: 0.46 | loss: 9.71
update:1525/2000, 耗时:0.00分/4.15分 | step: 122000 | performance: 1.7 | accuracy: 0.47 | loss: 4.31
update:1530/2000, 耗时:0.00分/4.16分 | step: 122400 | performance: 3.0 | accuracy: 0.47 | loss: 15.78
update:1535/2000, 耗时:0.00分/4.18分 | step: 122800 | performance: 3.6 | accuracy: 0.48 | loss: 4.28
update:1540/2000, 耗时:0.00分/4.19分 | step: 123200 | performance: 2.9 | accuracy: 0.48 | loss: 7.76
update:1545/2000, 耗时:0.00分/4.20分 | step: 123600 | performance: 5.7 | accuracy: 0.49 | loss: 5.81
update:1550/2000, 耗时:0.00分/4.22分 | step: 124000 | performance: 6.5 | accuracy: 0.49 | loss: 4.08
update:1555/2000, 耗时:0.00分/4.23分 | step: 124400 | performance: 2.7 | accuracy: 0.48 | loss: 9.71
update:1560/2000, 耗时:0.00分/4.24分 | step: 124800 | performance: 2.3 | accuracy: 0.48 | loss: 3.97
update:1565/2000, 耗时:0.00分/4.26分 | step: 125200 | performance: 25.4 | accuracy: 0.48 | loss: 12.40
update:1570/2000, 耗时:0.00分/4.27分 | step: 125600 | performance: 10.0 | accuracy: 0.48 | loss: 7.07
update:1575/2000, 耗时:0.00分/4.28分 | step: 126000 | performance: 2.8 | accuracy: 0.47 | loss: 9.20
update:1580/2000, 耗时:0.00分/4.30分 | step: 126400 | performance: 2.6 | accuracy: 0.47 | loss: 6.00
update:1585/2000, 耗时:0.00分/4.31分 | step: 126800 | performance: 3.6 | accuracy: 0.47 | loss: 6.91
update:1590/2000, 耗时:0.00分/4.32分 | step: 127200 | performance: 3.6 | accuracy: 0.47 | loss: 5.12
update:1595/2000, 耗时:0.00分/4.34分 | step: 127600 | performance: 1.5 | accuracy: 0.47 | loss: 3.81
update:1600/2000, 耗时:0.00分/4.35分 | step: 128000 | performance: 2.7 | accuracy: 0.47 | loss: 5.15
update:1605/2000, 耗时:0.00分/4.36分 | step: 128400 | performance: 2.5 | accuracy: 0.46 | loss: 5.08
update:1610/2000, 耗时:0.00分/4.38分 | step: 128800 | performance: 1.1 | accuracy: 0.46 | loss: 6.09
update:1615/2000, 耗时:0.00分/4.39分 | step: 129200 | performance: 0.3 | accuracy: 0.46 | loss: 6.55
update:1620/2000, 耗时:0.00分/4.40分 | step: 129600 | performance: 0.1 | accuracy: 0.45 | loss: 14.45
update:1625/2000, 耗时:0.00分/4.42分 | step: 130000 | performance: 0.0 | accuracy: 0.45 | loss: 12.59
update:1630/2000, 耗时:0.00分/4.43分 | step: 130400 | performance: 0.0 | accuracy: 0.45 | loss: 12.78
update:1635/2000, 耗时:0.00分/4.45分 | step: 130800 | performance: 0.0 | accuracy: 0.45 | loss: 13.26
update:1640/2000, 耗时:0.00分/4.46分 | step: 131200 | performance: 0.0 | accuracy: 0.45 | loss: 8.52
update:1645/2000, 耗时:0.00分/4.47分 | step: 131600 | performance: 0.0 | accuracy: 0.45 | loss: 9.40
update:1650/2000, 耗时:0.00分/4.49分 | step: 132000 | performance: 0.0 | accuracy: 0.45 | loss: 14.88
update:1655/2000, 耗时:0.00分/4.50分 | step: 132400 | performance: 0.0 | accuracy: 0.45 | loss: 5.90
update:1660/2000, 耗时:0.00分/4.52分 | step: 132800 | performance: 0.0 | accuracy: 0.45 | loss: 4.56
update:1665/2000, 耗时:0.00分/4.53分 | step: 133200 | performance: 0.0 | accuracy: 0.45 | loss: 11.28
update:1670/2000, 耗时:0.00分/4.54分 | step: 133600 | performance: 0.0 | accuracy: 0.45 | loss: 3.37
update:1675/2000, 耗时:0.00分/4.56分 | step: 134000 | performance: 0.0 | accuracy: 0.45 | loss: 5.07
update:1680/2000, 耗时:0.00分/4.57分 | step: 134400 | performance: 0.0 | accuracy: 0.45 | loss: 6.86
update:1685/2000, 耗时:0.00分/4.58分 | step: 134800 | performance: 0.0 | accuracy: 0.45 | loss: 9.74
update:1690/2000, 耗时:0.00分/4.60分 | step: 135200 | performance: 0.0 | accuracy: 0.46 | loss: 7.37
update:1695/2000, 耗时:0.00分/4.61分 | step: 135600 | performance: 0.0 | accuracy: 0.46 | loss: 6.51
update:1700/2000, 耗时:0.00分/4.63分 | step: 136000 | performance: 0.0 | accuracy: 0.46 | loss: 12.22
update:1705/2000, 耗时:0.00分/4.64分 | step: 136400 | performance: 0.0 | accuracy: 0.46 | loss: 5.41
update:1710/2000, 耗时:0.00分/4.65分 | step: 136800 | performance: 0.0 | accuracy: 0.46 | loss: 5.29
update:1715/2000, 耗时:0.00分/4.67分 | step: 137200 | performance: 0.0 | accuracy: 0.46 | loss: 8.68
update:1720/2000, 耗时:0.00分/4.68分 | step: 137600 | performance: 0.0 | accuracy: 0.46 | loss: 6.14
update:1725/2000, 耗时:0.00分/4.70分 | step: 138000 | performance: 0.1 | accuracy: 0.47 | loss: 4.69
update:1730/2000, 耗时:0.00分/4.71分 | step: 138400 | performance: 0.6 | accuracy: 0.47 | loss: 7.64
update:1735/2000, 耗时:0.00分/4.72分 | step: 138800 | performance: 0.6 | accuracy: 0.47 | loss: 10.22
update:1740/2000, 耗时:0.00分/4.74分 | step: 139200 | performance: 0.4 | accuracy: 0.47 | loss: 4.24
update:1745/2000, 耗时:0.00分/4.75分 | step: 139600 | performance: 0.8 | accuracy: 0.47 | loss: 3.74
update:1750/2000, 耗时:0.00分/4.77分 | step: 140000 | performance: 0.9 | accuracy: 0.47 | loss: 4.66
step: 140314 | worker_1@n_step_9: average total_reward after train data exhaustion : 71.8 | max total_reward: 300.9
update:1755/2000, 耗时:0.00分/4.78分 | step: 140400 | performance: 1.0 | accuracy: 0.47 | loss: 6.72
update:1760/2000, 耗时:0.00分/4.79分 | step: 140800 | performance: 1.9 | accuracy: 0.47 | loss: 6.33
update:1765/2000, 耗时:0.00分/4.81分 | step: 141200 | performance: 1.6 | accuracy: 0.47 | loss: 3.43
update:1770/2000, 耗时:0.00分/4.82分 | step: 141600 | performance: 0.8 | accuracy: 0.45 | loss: 8.38
update:1775/2000, 耗时:0.00分/4.83分 | step: 142000 | performance: 1.2 | accuracy: 0.56 | loss: 13.26
update:1780/2000, 耗时:0.00分/4.85分 | step: 142400 | performance: 0.7 | accuracy: 0.48 | loss: 6.61
update:1785/2000, 耗时:0.00分/4.86分 | step: 142800 | performance: 1.7 | accuracy: 0.51 | loss: 7.72
update:1790/2000, 耗时:0.00分/4.88分 | step: 143200 | performance: 4.6 | accuracy: 0.54 | loss: 4.74
update:1795/2000, 耗时:0.00分/4.89分 | step: 143600 | performance: 1.7 | accuracy: 0.50 | loss: 9.97
update:1800/2000, 耗时:0.00分/4.90分 | step: 144000 | performance: 3.8 | accuracy: 0.52 | loss: 7.73
update:1805/2000, 耗时:0.00分/4.92分 | step: 144400 | performance: 4.4 | accuracy: 0.51 | loss: 5.03
update:1810/2000, 耗时:0.00分/4.93分 | step: 144800 | performance: 3.8 | accuracy: 0.49 | loss: 6.82
update:1815/2000, 耗时:0.00分/4.95分 | step: 145200 | performance: 4.7 | accuracy: 0.51 | loss: 5.46
update:1820/2000, 耗时:0.00分/4.96分 | step: 145600 | performance: 31.6 | accuracy: 0.52 | loss: 13.75
update:1825/2000, 耗时:0.00分/4.97分 | step: 146000 | performance: 35.9 | accuracy: 0.52 | loss: 13.70
update:1830/2000, 耗时:0.00分/4.99分 | step: 146400 | performance: 56.0 | accuracy: 0.52 | loss: 4.26
update:1835/2000, 耗时:0.00分/5.00分 | step: 146800 | performance: 59.9 | accuracy: 0.51 | loss: 5.23
update:1840/2000, 耗时:0.00分/5.02分 | step: 147200 | performance: 47.5 | accuracy: 0.51 | loss: 3.55
update:1845/2000, 耗时:0.00分/5.03分 | step: 147600 | performance: 36.4 | accuracy: 0.50 | loss: 7.13
update:1850/2000, 耗时:0.00分/5.04分 | step: 148000 | performance: 12.5 | accuracy: 0.48 | loss: 6.93
update:1855/2000, 耗时:0.00分/5.06分 | step: 148400 | performance: 3.1 | accuracy: 0.47 | loss: 9.29
update:1860/2000, 耗时:0.00分/5.07分 | step: 148800 | performance: 2.7 | accuracy: 0.47 | loss: 10.16
update:1865/2000, 耗时:0.00分/5.09分 | step: 149200 | performance: 0.6 | accuracy: 0.46 | loss: 6.97
update:1870/2000, 耗时:0.00分/5.10分 | step: 149600 | performance: 1.1 | accuracy: 0.46 | loss: 12.15
update:1875/2000, 耗时:0.00分/5.11分 | step: 150000 | performance: 1.3 | accuracy: 0.46 | loss: 4.76
update:1880/2000, 耗时:0.00分/5.13分 | step: 150400 | performance: 1.4 | accuracy: 0.47 | loss: 3.77
update:1885/2000, 耗时:0.00分/5.14分 | step: 150800 | performance: 3.6 | accuracy: 0.47 | loss: 7.85
update:1890/2000, 耗时:0.00分/5.16分 | step: 151200 | performance: 2.6 | accuracy: 0.48 | loss: 7.99
update:1895/2000, 耗时:0.00分/5.17分 | step: 151600 | performance: 5.9 | accuracy: 0.49 | loss: 6.67
update:1900/2000, 耗时:0.00分/5.18分 | step: 152000 | performance: 6.3 | accuracy: 0.49 | loss: 6.40
update:1905/2000, 耗时:0.00分/5.20分 | step: 152400 | performance: 3.9 | accuracy: 0.48 | loss: 5.74
update:1910/2000, 耗时:0.00分/5.21分 | step: 152800 | performance: 2.2 | accuracy: 0.48 | loss: 7.49
update:1915/2000, 耗时:0.00分/5.23分 | step: 153200 | performance: 23.6 | accuracy: 0.48 | loss: 12.78
update:1920/2000, 耗时:0.00分/5.24分 | step: 153600 | performance: 7.6 | accuracy: 0.47 | loss: 5.59
update:1925/2000, 耗时:0.00分/5.25分 | step: 154000 | performance: 4.7 | accuracy: 0.47 | loss: 4.82
update:1930/2000, 耗时:0.00分/5.27分 | step: 154400 | performance: 5.1 | accuracy: 0.45 | loss: 0.70
update:1935/2000, 耗时:0.00分/5.28分 | step: 154800 | performance: 4.5 | accuracy: 0.44 | loss: 0.45
update:1940/2000, 耗时:0.00分/5.30分 | step: 155200 | performance: 4.3 | accuracy: 0.43 | loss: 0.24
update:1945/2000, 耗时:0.00分/5.31分 | step: 155600 | performance: 4.2 | accuracy: 0.42 | loss: 0.31
update:1950/2000, 耗时:0.00分/5.32分 | step: 156000 | performance: 5.3 | accuracy: 0.42 | loss: 1.29
update:1955/2000, 耗时:0.00分/5.34分 | step: 156400 | performance: 5.2 | accuracy: 0.41 | loss: 0.21
update:1960/2000, 耗时:0.00分/5.35分 | step: 156800 | performance: 5.2 | accuracy: 0.40 | loss: 0.06
update:1965/2000, 耗时:0.00分/5.37分 | step: 157200 | performance: 5.2 | accuracy: 0.39 | loss: 0.76
update:1970/2000, 耗时:0.00分/5.38分 | step: 157600 | performance: 5.2 | accuracy: 0.38 | loss: 0.02
update:1975/2000, 耗时:0.00分/5.40分 | step: 158000 | performance: 5.2 | accuracy: 0.37 | loss: 0.04
update:1980/2000, 耗时:0.00分/5.41分 | step: 158400 | performance: 5.2 | accuracy: 0.36 | loss: 0.04
update:1985/2000, 耗时:0.00分/5.43分 | step: 158800 | performance: 5.2 | accuracy: 0.35 | loss: 0.01
update:1990/2000, 耗时:0.00分/5.44分 | step: 159200 | performance: 5.2 | accuracy: 0.34 | loss: 0.03
update:1995/2000, 耗时:0.00分/5.46分 | step: 159600 | performance: 5.2 | accuracy: 0.34 | loss: 0.01
  0%|          | 0/391 [00:00<?, ?it/s]100%|| 391/391 [00:00<00:00, 130249.61it/s]
update:2000/2000, 耗时:0.00分/5.47分 | step: 160000 | performance: 5.2 | accuracy: 0.33 | loss: 0.31
----------------------------------------finished----------------------------------------
==================================================
2023-01-10T12:00:00 | *** START BACKTEST ***
2023-01-10T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1000.00
2023-07-24T12:00:00 | net performance [%] = 0.0000
2023-07-24T12:00:00 | number of trades [#] = 0
==================================================
Trial 25 Complete [00h 05m 55s]
net_wealth: 1000.0

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 03h 29m 06s

Search: Running Trial #26

Value             |Best Value So Far |Hyperparameter
1                 |1                 |horizon
225               |730               |lookback
True              |False             |MarketFactor
10                |3                 |lags
0.8               |0.92              |gamma
16                |32                |batch_size
32                |1                 |n_step
0.99              |0.94              |gae_lambda
0.1               |5                 |gradient_clip_norm
5                 |5                 |epochs
5e-05             |0.0001            |actor_lr
0.0001            |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4300.000000   4301.000000
mean      0.000435    20113.607657  ...   20173.020481  20169.373185
std       0.027833    16040.642334  ...   16078.674434  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7736.967529   7730.930176
50%       0.000642    11571.842969  ...   11753.029785  11751.469727
75%       0.011590    29894.706152  ...   30013.548340  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 01:32:29.870195: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, 22023-07-202re3-07-28 012023-:b302uil:729.d T2ens0238--72o8 00rFl7-28 1:ow 32:290.330: 8I7 0tens1o08 rflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI De325: I tensorflow/core/platform/cpu_featur:eep _guard.cc:1420]32:29 1.T87:32h:290.870195:36 isI3: I   tTensoenrFlteonsw bsorfionrfloary lw/core/platfowrmi202i3-s/ copw/ou_f0ecore/7N-epla28 urtfoaptimilzrem/0 cNepud with on1t_e2tworfhA:P30a2ek I Deea2pt 3:2Ne9ur.ha8706 -5e l 07-2Net8wotr4 k 0:ure_g turuarLeL1Ii btd_ige:3r2.cc20:23-0n2a7sorafplpr-rbuaord.2o8w/yc 9( oc:n14021] ep:riDN3coreN).T8h7is20770 ate  :c I /rtpomp:lary Te:n(one1o4 t2De]nsorf2i9luse .lt 8T7heeow /NrN0s91)o folla2r:t towio flf ngIohr c aCiugsse.PUtsen 
m/csoFrlf pu tohwe Til_f enofobnselisowr/tarutctionrce/porFel/oallpaltfnosouwriea_ ingrtrn gpmeyr fiusaorfmr/dc.c oprmu_/ aonfcecp:t1imcC4iza2] ThPU instructions in performance-critical ootw binaris Tensorupeyp is opturFled_feaimeorw  wbiaithe-tcri zonendurt iticwioea_linthg op_argeuarAPera s:y  Ao isVX  ntieoptimizedI Deep NeuAAPVons:X d r 2w
AiVaXTulo tNaetwork Librd.c.c:1I r4h aryc (oneAPI Deeoc2en eD]D  :ATNepVhX2ie
1N42T]po   e NN)Thn etniaabloseble   u rtatThehlu Nemmetwose  ierutsk Lernh i ans otebiTenhrnasroy fo  olroFlrFotwhee(lrowo  Netwo binaropr binaryky ie rilsloats i w Liirn ooptimnsgbrar i,z opye r(aCrebuild TedP Uotnie einnssoootnpnweDNN) tDsNirFl,o reoNw t)i  burtmutizueihls eod  owdth cTtewn suioiriFthstoh  nns inone foleAlt epePrlI howf owwieA PIoartinpm prDoeperpg C iea ntahNPchUe einDteee ural Nt-sch rcomiee foll appptical operations:  AVX AVXep2 rtwork
oTo enable them in priaLNeural oilNet ower rinibrtflawtogg sCaurcrtPik.
ytonse Library (o coUm  iinhn npeest DNN)(onrile operatior to usuecentpersDi the fN, reboN uio) ltlfnsrofolwd o rmilnag aTnenssuce.osr -ceFl
performancir othe w with ten-g ChcriPtUiciatlf iicnalol eloope  sraoperawing CttppructiaionontionssPs::  r  iUn performance-critical operations:  AVX AVX2
To enable them in other operations instru oA, rpriate compiler flags.
ctions in performance-critical operations:eVX build TensorFlowAVX AVX2
To enable them in other operations with the appr, rebuild TensorFloAVX2
To enable them in other o  AVX AVX2
To enperaaoble ttionw witpriahteh tem in other operations, rebuild TensorFlow with the appropriate compiler s, rebuild TensorFlow with the appropriate compiler flags.
 compiler flags.
he appropriate compiler flags.
flags.
2023-07-28 01:32:30.491198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:32:30.509588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:32:30.513196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:32:30.515570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:32:30.522370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:32:30.527083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capabi2023-0lity: 7-28 01:32:308..6535
574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:32:30.539526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.05分 | step:  1280 | performance: 3.1 | accuracy: 0.45 | loss: 1.82
update: 10/2000, 耗时:0.01分/0.07分 | step:  2560 | performance: 3.7 | accuracy: 0.40 | loss: 1.10
update: 15/2000, 耗时:0.01分/0.10分 | step:  3840 | performance: 4.8 | accuracy: 0.40 | loss: 1.42
update: 20/2000, 耗时:0.01分/0.13分 | step:  5120 | performance: 4.9 | accuracy: 0.38 | loss: 0.56
update: 25/2000, 耗时:0.01分/0.16分 | step:  6400 | performance: 6.4 | accuracy: 0.36 | loss: 0.71
update: 30/2000, 耗时:0.01分/0.20分 | step:  7680 | performance: 7.8 | accuracy: 0.37 | loss: 1.63
update: 35/2000, 耗时:0.01分/0.23分 | step:  8960 | performance: 5.3 | accuracy: 0.37 | loss: 2.55
update: 40/2000, 耗时:0.01分/0.26分 | step: 10240 | performance: 6.2 | accuracy: 0.36 | loss: 1.21
update: 45/2000, 耗时:0.01分/0.30分 | step: 11520 | performance: 6.0 | accuracy: 0.35 | loss: 0.77
update: 50/2000, 耗时:0.01分/0.33分 | step: 12800 | performance: 6.1 | accuracy: 0.35 | loss: 1.00
update: 55/2000, 耗时:0.01分/0.36分 | step: 14080 | performance: 4.6 | accuracy: 0.35 | loss: 1.14
update: 60/2000, 耗时:0.01分/0.40分 | step: 15360 | performance: 5.5 | accuracy: 0.35 | loss: 0.92
update: 65/2000, 耗时:0.01分/0.43分 | step: 16640 | performance: 7.4 | accuracy: 0.35 | loss: 1.34
update: 70/2000, 耗时:0.01分/0.46分 | step: 17920 | performance: 15.9 | accuracy: 0.36 | loss: 1.68
update: 75/2000, 耗时:0.01分/0.50分 | step: 19200 | performance: 8.5 | accuracy: 0.36 | loss: 0.74
update: 80/2000, 耗时:0.01分/0.53分 | step: 20480 | performance: 7.6 | accuracy: 0.36 | loss: 1.00
update: 85/2000, 耗时:0.01分/0.56分 | step: 21760 | performance: 12.7 | accuracy: 0.35 | loss: 0.72
update: 90/2000, 耗时:0.01分/0.60分 | step: 23040 | performance: 16.5 | accuracy: 0.36 | loss: 0.88
update: 95/2000, 耗时:0.01分/0.63分 | step: 24320 | performance: 18.3 | accuracy: 0.35 | loss: 1.13
update:100/2000, 耗时:0.01分/0.67分 | step: 25600 | performance: 16.2 | accuracy: 0.35 | loss: 1.45
update:105/2000, 耗时:0.01分/0.70分 | step: 26880 | performance: 14.7 | accuracy: 0.35 | loss: 0.89
update:110/2000, 耗时:0.01分/0.73分 | step: 28160 | performance: 14.2 | accuracy: 0.35 | loss: 0.83
update:115/2000, 耗时:0.01分/0.77分 | step: 29440 | performance: 1.2 | accuracy: 0.45 | loss: 1.61
Saving PPO weights in both H5 format and checkpoint @ update:115 
update:120/2000, 耗时:0.01分/0.80分 | step: 30720 | performance: 1.6 | accuracy: 0.38 | loss: 1.08
update:125/2000, 耗时:0.01分/0.83分 | step: 32000 | performance: 1.0 | accuracy: 0.32 | loss: 0.79
update:130/2000, 耗时:0.01分/0.86分 | step: 33280 | performance: 1.0 | accuracy: 0.32 | loss: 0.73
update:135/2000, 耗时:0.01分/0.90分 | step: 34560 | performance: 1.1 | accuracy: 0.31 | loss: 0.63
update:140/2000, 耗时:0.01分/0.93分 | step: 35840 | performance: 1.1 | accuracy: 0.29 | loss: 0.56
update:145/2000, 耗时:0.01分/0.96分 | step: 37120 | performance: 1.3 | accuracy: 0.30 | loss: 1.40
update:150/2000, 耗时:0.01分/0.99分 | step: 38400 | performance: 1.1 | accuracy: 0.31 | loss: 1.41
update:155/2000, 耗时:0.01分/1.02分 | step: 39680 | performance: 1.0 | accuracy: 0.30 | loss: 0.51
update:160/2000, 耗时:0.01分/1.05分 | step: 40960 | performance: 1.1 | accuracy: 0.29 | loss: 0.57
update:165/2000, 耗时:0.01分/1.08分 | step: 42240 | performance: 0.9 | accuracy: 0.29 | loss: 1.11
update:170/2000, 耗时:0.01分/1.11分 | step: 43520 | performance: 0.9 | accuracy: 0.29 | loss: 0.56
update:175/2000, 耗时:0.01分/1.15分 | step: 44800 | performance: 1.0 | accuracy: 0.29 | loss: 0.71
update:180/2000, 耗时:0.01分/1.18分 | step: 46080 | performance: 0.9 | accuracy: 0.29 | loss: 0.84
update:185/2000, 耗时:0.01分/1.21分 | step: 47360 | performance: 1.7 | accuracy: 0.30 | loss: 1.13
update:190/2000, 耗时:0.01分/1.24分 | step: 48640 | performance: 1.6 | accuracy: 0.31 | loss: 0.91
update:195/2000, 耗时:0.01分/1.28分 | step: 49920 | performance: 1.6 | accuracy: 0.30 | loss: 0.71
update:200/2000, 耗时:0.01分/1.31分 | step: 51200 | performance: 1.3 | accuracy: 0.30 | loss: 0.92
update:205/2000, 耗时:0.01分/1.34分 | step: 52480 | performance: 1.2 | accuracy: 0.31 | loss: 0.95
update:210/2000, 耗时:0.01分/1.37分 | step: 53760 | performance: 1.0 | accuracy: 0.30 | loss: 0.74
update:215/2000, 耗时:0.01分/1.40分 | step: 55040 | performance: 0.8 | accuracy: 0.30 | loss: 0.47
update:220/2000, 耗时:0.01分/1.43分 | step: 56320 | performance: 0.8 | accuracy: 0.29 | loss: 0.47
update:225/2000, 耗时:0.01分/1.46分 | step: 57600 | performance: 0.6 | accuracy: 0.29 | loss: 0.24
Saving PPO weights in both H5 format and checkpoint @ update:229 
update:230/2000, 耗时:0.01分/1.50分 | step: 58880 | performance: 0.9 | accuracy: 0.18 | loss: 0.61
update:235/2000, 耗时:0.01分/1.53分 | step: 60160 | performance: 1.2 | accuracy: 0.14 | loss: 0.42
update:240/2000, 耗时:0.01分/1.57分 | step: 61440 | performance: 1.4 | accuracy: 0.14 | loss: 0.18
update:245/2000, 耗时:0.01分/1.60分 | step: 62720 | performance: 1.5 | accuracy: 0.14 | loss: 0.25
update:250/2000, 耗时:0.01分/1.63分 | step: 64000 | performance: 1.4 | accuracy: 0.14 | loss: 0.26
update:255/2000, 耗时:0.01分/1.66分 | step: 65280 | performance: 1.4 | accuracy: 0.13 | loss: 0.19
update:260/2000, 耗时:0.01分/1.70分 | step: 66560 | performance: 1.5 | accuracy: 0.14 | loss: 0.32
update:265/2000, 耗时:0.01分/1.73分 | step: 67840 | performance: 1.7 | accuracy: 0.14 | loss: 0.34
update:270/2000, 耗时:0.01分/1.76分 | step: 69120 | performance: 1.4 | accuracy: 0.14 | loss: 0.34
update:275/2000, 耗时:0.01分/1.79分 | step: 70400 | performance: 1.3 | accuracy: 0.14 | loss: 0.23
update:280/2000, 耗时:0.01分/1.83分 | step: 71680 | performance: 1.3 | accuracy: 0.14 | loss: 0.08
update:285/2000, 耗时:0.01分/1.86分 | step: 72960 | performance: 1.5 | accuracy: 0.13 | loss: 0.12
update:290/2000, 耗时:0.01分/1.89分 | step: 74240 | performance: 1.5 | accuracy: 0.13 | loss: 0.12
update:295/2000, 耗时:0.01分/1.92分 | step: 75520 | performance: 1.5 | accuracy: 0.13 | loss: 0.10
update:300/2000, 耗时:0.01分/1.95分 | step: 76800 | performance: 1.5 | accuracy: 0.13 | loss: 0.21
update:305/2000, 耗时:0.01分/1.98分 | step: 78080 | performance: 1.5 | accuracy: 0.12 | loss: 0.17
update:310/2000, 耗时:0.01分/2.02分 | step: 79360 | performance: 1.6 | accuracy: 0.12 | loss: 0.23
update:315/2000, 耗时:0.01分/2.05分 | step: 80640 | performance: 1.6 | accuracy: 0.11 | loss: 0.11
update:320/2000, 耗时:0.01分/2.08分 | step: 81920 | performance: 1.5 | accuracy: 0.11 | loss: 0.14
update:325/2000, 耗时:0.01分/2.11分 | step: 83200 | performance: 1.8 | accuracy: 0.11 | loss: 0.13
update:330/2000, 耗时:0.01分/2.14分 | step: 84480 | performance: 1.8 | accuracy: 0.11 | loss: 0.07
update:335/2000, 耗时:0.01分/2.17分 | step: 85760 | performance: 1.6 | accuracy: 0.10 | loss: 0.11
step: 86779 | worker_2@n_step_31: average total_reward after train data exhaustion : 11.2 | max total_reward: 227.2
update:340/2000, 耗时:0.01分/2.21分 | step: 87040 | performance: 1.7 | accuracy: 0.10 | loss: 0.16
step: 88062 | worker_5@n_step_31: average total_reward after train data exhaustion : 13.0 | max total_reward: 227.2
step: 88315 | worker_2@n_step_31: average total_reward after train data exhaustion : 13.1 | max total_reward: 227.2
update:345/2000, 耗时:0.01分/2.24分 | step: 88320 | performance: 1.1 | accuracy: 0.14 | loss: 0.11
update:350/2000, 耗时:0.01分/2.27分 | step: 89600 | performance: 1.0 | accuracy: 0.11 | loss: 0.31
step: 90363 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 227.2
update:355/2000, 耗时:0.01分/2.30分 | step: 90880 | performance: 1.0 | accuracy: 0.13 | loss: 0.20
step: 91642 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 227.2
update:360/2000, 耗时:0.01分/2.33分 | step: 92160 | performance: 1.0 | accuracy: 0.12 | loss: 0.22
update:365/2000, 耗时:0.01分/2.36分 | step: 93440 | performance: 1.3 | accuracy: 0.14 | loss: 0.26
step: 94202 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 227.2
update:370/2000, 耗时:0.01分/2.40分 | step: 94720 | performance: 1.4 | accuracy: 0.14 | loss: 0.21
step: 95230 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 227.2
step: 95482 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 227.2
update:375/2000, 耗时:0.01分/2.43分 | step: 96000 | performance: 1.3 | accuracy: 0.14 | loss: 0.22
step: 96250 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 227.2
update:380/2000, 耗时:0.01分/2.46分 | step: 97280 | performance: 1.2 | accuracy: 0.14 | loss: 0.48
update:385/2000, 耗时:0.01分/2.49分 | step: 98560 | performance: 1.2 | accuracy: 0.14 | loss: 0.39
update:390/2000, 耗时:0.01分/2.52分 | step: 99840 | performance: 1.2 | accuracy: 0.14 | loss: 0.36
update:395/2000, 耗时:0.01分/2.55分 | step: 101120 | performance: 1.1 | accuracy: 0.14 | loss: 0.25
update:400/2000, 耗时:0.01分/2.59分 | step: 102400 | performance: 1.0 | accuracy: 0.14 | loss: 0.25
update:405/2000, 耗时:0.01分/2.62分 | step: 103680 | performance: 0.8 | accuracy: 0.13 | loss: 0.22
update:410/2000, 耗时:0.01分/2.65分 | step: 104960 | performance: 0.8 | accuracy: 0.13 | loss: 0.19
update:415/2000, 耗时:0.01分/2.68分 | step: 106240 | performance: 0.7 | accuracy: 0.13 | loss: 0.30
update:420/2000, 耗时:0.01分/2.72分 | step: 107520 | performance: 0.8 | accuracy: 0.13 | loss: 0.29
update:425/2000, 耗时:0.01分/2.75分 | step: 108800 | performance: 0.8 | accuracy: 0.13 | loss: 0.24
update:430/2000, 耗时:0.01分/2.78分 | step: 110080 | performance: 0.9 | accuracy: 0.13 | loss: 0.22
update:435/2000, 耗时:0.01分/2.81分 | step: 111360 | performance: 1.0 | accuracy: 0.13 | loss: 0.10
update:440/2000, 耗时:0.01分/2.84分 | step: 112640 | performance: 1.1 | accuracy: 0.13 | loss: 0.20
update:445/2000, 耗时:0.01分/2.88分 | step: 113920 | performance: 1.1 | accuracy: 0.12 | loss: 0.18
update:450/2000, 耗时:0.01分/2.91分 | step: 115200 | performance: 1.2 | accuracy: 0.12 | loss: 0.26
update:455/2000, 耗时:0.01分/2.94分 | step: 116480 | performance: 0.9 | accuracy: 0.12 | loss: 0.34
update:460/2000, 耗时:0.01分/2.98分 | step: 117760 | performance: 0.9 | accuracy: 0.12 | loss: 0.44
update:465/2000, 耗时:0.01分/3.01分 | step: 119040 | performance: 0.8 | accuracy: 0.12 | loss: 0.33
update:470/2000, 耗时:0.01分/3.04分 | step: 120320 | performance: 1.0 | accuracy: 0.14 | loss: 0.31
step: 121593 | worker_0@n_step_31: average total_reward after train data exhaustion : 21.0 | max total_reward: 227.2
update:475/2000, 耗时:0.01分/3.07分 | step: 121600 | performance: 1.1 | accuracy: 0.14 | loss: 0.15
update:480/2000, 耗时:0.01分/3.10分 | step: 122880 | performance: 1.7 | accuracy: 0.14 | loss: 0.41
update:485/2000, 耗时:0.01分/3.14分 | step: 124160 | performance: 1.5 | accuracy: 0.13 | loss: 0.32
update:490/2000, 耗时:0.01分/3.17分 | step: 125440 | performance: 1.7 | accuracy: 0.14 | loss: 0.32
update:495/2000, 耗时:0.01分/3.20分 | step: 126720 | performance: 1.8 | accuracy: 0.14 | loss: 0.25
update:500/2000, 耗时:0.01分/3.23分 | step: 128000 | performance: 2.0 | accuracy: 0.14 | loss: 0.48
update:505/2000, 耗时:0.01分/3.27分 | step: 129280 | performance: 1.9 | accuracy: 0.15 | loss: 0.37
update:510/2000, 耗时:0.01分/3.30分 | step: 130560 | performance: 1.7 | accuracy: 0.15 | loss: 0.35
update:515/2000, 耗时:0.01分/3.33分 | step: 131840 | performance: 1.7 | accuracy: 0.14 | loss: 0.26
update:520/2000, 耗时:0.01分/3.36分 | step: 133120 | performance: 1.8 | accuracy: 0.14 | loss: 0.30
update:525/2000, 耗时:0.01分/3.40分 | step: 134400 | performance: 1.3 | accuracy: 0.14 | loss: 0.25
update:530/2000, 耗时:0.01分/3.43分 | step: 135680 | performance: 1.6 | accuracy: 0.14 | loss: 0.26
update:535/2000, 耗时:0.01分/3.46分 | step: 136960 | performance: 1.6 | accuracy: 0.15 | loss: 0.36
update:540/2000, 耗时:0.01分/3.49分 | step: 138240 | performance: 1.5 | accuracy: 0.15 | loss: 0.38
update:545/2000, 耗时:0.01分/3.53分 | step: 139520 | performance: 1.3 | accuracy: 0.15 | loss: 0.50
update:550/2000, 耗时:0.01分/3.56分 | step: 140800 | performance: 1.5 | accuracy: 0.15 | loss: 0.44
update:555/2000, 耗时:0.01分/3.59分 | step: 142080 | performance: 1.0 | accuracy: 0.15 | loss: 0.31
update:560/2000, 耗时:0.01分/3.63分 | step: 143360 | performance: 1.0 | accuracy: 0.15 | loss: 0.26
update:565/2000, 耗时:0.01分/3.66分 | step: 144640 | performance: 1.1 | accuracy: 0.15 | loss: 0.43
update:570/2000, 耗时:0.01分/3.69分 | step: 145920 | performance: 1.0 | accuracy: 0.15 | loss: 0.50
update:575/2000, 耗时:0.01分/3.72分 | step: 147200 | performance: 0.9 | accuracy: 0.15 | loss: 0.26
update:580/2000, 耗时:0.01分/3.76分 | step: 148480 | performance: 0.8 | accuracy: 0.14 | loss: 0.29
update:585/2000, 耗时:0.01分/3.79分 | step: 149760 | performance: 0.7 | accuracy: 0.14 | loss: 0.17
update:590/2000, 耗时:0.01分/3.82分 | step: 151040 | performance: 1.0 | accuracy: 0.20 | loss: 0.29
update:595/2000, 耗时:0.01分/3.85分 | step: 152320 | performance: 1.5 | accuracy: 0.16 | loss: 0.43
update:600/2000, 耗时:0.01分/3.88分 | step: 153600 | performance: 1.5 | accuracy: 0.16 | loss: 0.26
update:605/2000, 耗时:0.01分/3.91分 | step: 154880 | performance: 1.3 | accuracy: 0.14 | loss: 0.30
update:610/2000, 耗时:0.01分/3.94分 | step: 156160 | performance: 1.3 | accuracy: 0.14 | loss: 0.17
update:615/2000, 耗时:0.01分/3.97分 | step: 157440 | performance: 1.1 | accuracy: 0.13 | loss: 0.13
update:620/2000, 耗时:0.01分/4.00分 | step: 158720 | performance: 1.0 | accuracy: 0.13 | loss: 0.27
update:625/2000, 耗时:0.01分/4.04分 | step: 160000 | performance: 1.2 | accuracy: 0.14 | loss: 0.27
update:630/2000, 耗时:0.01分/4.07分 | step: 161280 | performance: 1.2 | accuracy: 0.13 | loss: 0.24
update:635/2000, 耗时:0.01分/4.10分 | step: 162560 | performance: 1.1 | accuracy: 0.14 | loss: 0.26
step: 163070 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 242.0
update:640/2000, 耗时:0.01分/4.14分 | step: 163840 | performance: 1.2 | accuracy: 0.14 | loss: 0.44
update:645/2000, 耗时:0.01分/4.17分 | step: 165120 | performance: 0.9 | accuracy: 0.14 | loss: 0.44
update:650/2000, 耗时:0.01分/4.20分 | step: 166400 | performance: 1.0 | accuracy: 0.14 | loss: 0.32
update:655/2000, 耗时:0.01分/4.24分 | step: 167680 | performance: 1.0 | accuracy: 0.14 | loss: 0.25
update:660/2000, 耗时:0.01分/4.27分 | step: 168960 | performance: 1.5 | accuracy: 0.15 | loss: 0.39
update:665/2000, 耗时:0.01分/4.30分 | step: 170240 | performance: 2.4 | accuracy: 0.15 | loss: 0.39
update:670/2000, 耗时:0.01分/4.33分 | step: 171520 | performance: 1.8 | accuracy: 0.15 | loss: 0.33
update:675/2000, 耗时:0.01分/4.36分 | step: 172800 | performance: 2.1 | accuracy: 0.14 | loss: 0.20
update:680/2000, 耗时:0.01分/4.40分 | step: 174080 | performance: 1.8 | accuracy: 0.14 | loss: 0.13
update:685/2000, 耗时:0.01分/4.43分 | step: 175360 | performance: 1.8 | accuracy: 0.14 | loss: 0.14
update:690/2000, 耗时:0.01分/4.46分 | step: 176640 | performance: 1.7 | accuracy: 0.13 | loss: 0.19
update:695/2000, 耗时:0.01分/4.49分 | step: 177920 | performance: 1.6 | accuracy: 0.13 | loss: 0.09
update:700/2000, 耗时:0.01分/4.52分 | step: 179200 | performance: 1.7 | accuracy: 0.13 | loss: 0.14
step: 180476 | worker_3@n_step_31: average total_reward after train data exhaustion : 19.3 | max total_reward: 246.4
update:705/2000, 耗时:0.01分/4.56分 | step: 180480 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 181245 | worker_4@n_step_31: average total_reward after train data exhaustion : 12.2 | max total_reward: 246.4
update:710/2000, 耗时:0.01分/4.59分 | step: 181760 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
update:715/2000, 耗时:0.01分/4.62分 | step: 183040 | performance: 1.3 | accuracy: 0.14 | loss: 0.32
step: 184061 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 246.4
update:720/2000, 耗时:0.01分/4.66分 | step: 184320 | performance: 1.0 | accuracy: 0.14 | loss: 0.19
step: 185337 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 246.4
update:725/2000, 耗时:0.01分/4.69分 | step: 185600 | performance: 1.2 | accuracy: 0.17 | loss: 0.24
step: 186364 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 246.4
update:730/2000, 耗时:0.01分/4.72分 | step: 186880 | performance: 1.3 | accuracy: 0.11 | loss: 0.21
update:735/2000, 耗时:0.01分/4.76分 | step: 188160 | performance: 1.1 | accuracy: 0.12 | loss: 0.28
update:740/2000, 耗时:0.01分/4.79分 | step: 189440 | performance: 1.1 | accuracy: 0.12 | loss: 0.16
update:745/2000, 耗时:0.01分/4.82分 | step: 190720 | performance: 1.1 | accuracy: 0.13 | loss: 0.20
step: 190972 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 246.4
update:750/2000, 耗时:0.01分/4.86分 | step: 192000 | performance: 1.1 | accuracy: 0.13 | loss: 0.41
step: 192249 | worker_0@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 246.4
step: 192506 | worker_1@n_step_31: average total_reward after train data exhaustion : 5.2 | max total_reward: 246.4
update:755/2000, 耗时:0.01分/4.89分 | step: 193280 | performance: 1.1 | accuracy: 0.13 | loss: 0.17
update:760/2000, 耗时:0.01分/4.92分 | step: 194560 | performance: 1.1 | accuracy: 0.12 | loss: 0.36
update:765/2000, 耗时:0.01分/4.96分 | step: 195840 | performance: 0.9 | accuracy: 0.12 | loss: 0.35
update:770/2000, 耗时:0.01分/4.99分 | step: 197120 | performance: 0.9 | accuracy: 0.13 | loss: 0.43
update:775/2000, 耗时:0.01分/5.02分 | step: 198400 | performance: 0.8 | accuracy: 0.13 | loss: 0.31
update:780/2000, 耗时:0.01分/5.06分 | step: 199680 | performance: 0.9 | accuracy: 0.13 | loss: 0.30
update:785/2000, 耗时:0.01分/5.09分 | step: 200960 | performance: 0.9 | accuracy: 0.13 | loss: 0.33
update:790/2000, 耗时:0.01分/5.12分 | step: 202240 | performance: 0.9 | accuracy: 0.13 | loss: 0.22
update:795/2000, 耗时:0.01分/5.16分 | step: 203520 | performance: 1.0 | accuracy: 0.13 | loss: 0.36
update:800/2000, 耗时:0.01分/5.19分 | step: 204800 | performance: 0.8 | accuracy: 0.13 | loss: 0.20
update:805/2000, 耗时:0.01分/5.22分 | step: 206080 | performance: 1.0 | accuracy: 0.13 | loss: 0.27
update:810/2000, 耗时:0.01分/5.26分 | step: 207360 | performance: 0.9 | accuracy: 0.12 | loss: 0.22
update:815/2000, 耗时:0.01分/5.29分 | step: 208640 | performance: 1.0 | accuracy: 0.12 | loss: 0.23
update:820/2000, 耗时:0.01分/5.32分 | step: 209920 | performance: 0.8 | accuracy: 0.12 | loss: 0.19
update:825/2000, 耗时:0.01分/5.36分 | step: 211200 | performance: 1.1 | accuracy: 0.12 | loss: 0.19
update:830/2000, 耗时:0.01分/5.39分 | step: 212480 | performance: 1.0 | accuracy: 0.12 | loss: 0.16
update:835/2000, 耗时:0.01分/5.42分 | step: 213760 | performance: 1.0 | accuracy: 0.11 | loss: 0.11
update:840/2000, 耗时:0.01分/5.45分 | step: 215040 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 216320 | worker_7@n_step_31: average total_reward after train data exhaustion : 11.4 | max total_reward: 246.4
update:845/2000, 耗时:0.01分/5.49分 | step: 216320 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
update:850/2000, 耗时:0.01分/5.52分 | step: 217600 | performance: 0.9 | accuracy: 0.00 | loss: 0.17
update:855/2000, 耗时:0.01分/5.56分 | step: 218880 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 219389 | worker_4@n_step_31: average total_reward after train data exhaustion : 9.1 | max total_reward: 246.4
step: 219391 | worker_6@n_step_31: average total_reward after train data exhaustion : 9.1 | max total_reward: 246.4
update:860/2000, 耗时:0.01分/5.59分 | step: 220160 | performance: 1.0 | accuracy: 0.08 | loss: 0.12
step: 221439 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 246.4
update:865/2000, 耗时:0.01分/5.63分 | step: 221440 | performance: 0.9 | accuracy: 0.10 | loss: 0.18
update:870/2000, 耗时:0.01分/5.66分 | step: 222720 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
step: 223228 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.9 | max total_reward: 246.4
step: 223488 | worker_7@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 246.4
step: 223743 | worker_6@n_step_31: average total_reward after train data exhaustion : 9.1 | max total_reward: 246.4
update:875/2000, 耗时:0.01分/5.70分 | step: 224000 | performance: 1.0 | accuracy: 0.06 | loss: 0.26
step: 225019 | worker_2@n_step_31: average total_reward after train data exhaustion : 8.4 | max total_reward: 246.4
update:880/2000, 耗时:0.01分/5.73分 | step: 225280 | performance: 1.0 | accuracy: 0.15 | loss: 0.21
step: 225791 | worker_6@n_step_31: average total_reward after train data exhaustion : 11.4 | max total_reward: 246.4
step: 226046 | worker_5@n_step_31: average total_reward after train data exhaustion : 11.3 | max total_reward: 246.4
update:885/2000, 耗时:0.01分/5.77分 | step: 226560 | performance: 1.1 | accuracy: 0.11 | loss: 0.28
update:890/2000, 耗时:0.01分/5.80分 | step: 227840 | performance: 1.1 | accuracy: 0.12 | loss: 0.25
update:895/2000, 耗时:0.01分/5.84分 | step: 229120 | performance: 1.0 | accuracy: 0.00 | loss: 0.34
step: 230143 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 246.4
update:900/2000, 耗时:0.01分/5.87分 | step: 230400 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:905/2000, 耗时:0.01分/5.91分 | step: 231680 | performance: 1.0 | accuracy: 0.29 | loss: 0.27
step: 232185 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 246.4
step: 232187 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 246.4
update:910/2000, 耗时:0.01分/5.94分 | step: 232960 | performance: 0.9 | accuracy: 0.07 | loss: 0.41
update:915/2000, 耗时:0.01分/5.98分 | step: 234240 | performance: 1.0 | accuracy: 0.00 | loss: 0.27
step: 235008 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 246.4
update:920/2000, 耗时:0.01分/6.01分 | step: 235520 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
step: 236027 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 246.4
update:925/2000, 耗时:0.01分/6.04分 | step: 236800 | performance: 1.1 | accuracy: 0.06 | loss: 0.12
step: 237305 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 246.4
update:930/2000, 耗时:0.01分/6.08分 | step: 238080 | performance: 1.7 | accuracy: 0.14 | loss: 0.33
step: 239353 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 246.4
update:935/2000, 耗时:0.01分/6.11分 | step: 239360 | performance: 1.6 | accuracy: 0.12 | loss: 0.25
update:940/2000, 耗时:0.01分/6.14分 | step: 240640 | performance: 1.4 | accuracy: 0.12 | loss: 0.25
update:945/2000, 耗时:0.01分/6.17分 | step: 241920 | performance: 1.2 | accuracy: 0.13 | loss: 0.30
update:950/2000, 耗时:0.01分/6.20分 | step: 243200 | performance: 1.0 | accuracy: 0.13 | loss: 0.20
update:955/2000, 耗时:0.01分/6.24分 | step: 244480 | performance: 1.0 | accuracy: 0.14 | loss: 0.29
update:960/2000, 耗时:0.01分/6.27分 | step: 245760 | performance: 1.0 | accuracy: 0.14 | loss: 0.19
update:965/2000, 耗时:0.01分/6.30分 | step: 247040 | performance: 1.3 | accuracy: 0.13 | loss: 0.40
update:970/2000, 耗时:0.01分/6.33分 | step: 248320 | performance: 1.1 | accuracy: 0.14 | loss: 0.37
update:975/2000, 耗时:0.01分/6.37分 | step: 249600 | performance: 1.0 | accuracy: 0.15 | loss: 0.48
update:980/2000, 耗时:0.01分/6.40分 | step: 250880 | performance: 1.2 | accuracy: 0.15 | loss: 0.51
update:985/2000, 耗时:0.01分/6.43分 | step: 252160 | performance: 1.1 | accuracy: 0.15 | loss: 0.22
update:990/2000, 耗时:0.01分/6.47分 | step: 253440 | performance: 1.2 | accuracy: 0.15 | loss: 0.28
update:995/2000, 耗时:0.01分/6.50分 | step: 254720 | performance: 1.3 | accuracy: 0.14 | loss: 0.29
update:1000/2000, 耗时:0.01分/6.53分 | step: 256000 | performance: 1.3 | accuracy: 0.14 | loss: 0.21
update:1005/2000, 耗时:0.01分/6.57分 | step: 257280 | performance: 1.3 | accuracy: 0.14 | loss: 0.22
update:1010/2000, 耗时:0.01分/6.60分 | step: 258560 | performance: 1.4 | accuracy: 0.13 | loss: 0.33
step: 259322 | worker_1@n_step_31: average total_reward after train data exhaustion : 13.3 | max total_reward: 246.4
update:1015/2000, 耗时:0.01分/6.63分 | step: 259840 | performance: 1.2 | accuracy: 0.13 | loss: 0.27
update:1020/2000, 耗时:0.01分/6.66分 | step: 261120 | performance: 1.1 | accuracy: 0.13 | loss: 0.14
update:1025/2000, 耗时:0.01分/6.70分 | step: 262400 | performance: 1.3 | accuracy: 0.13 | loss: 0.28
update:1030/2000, 耗时:0.01分/6.73分 | step: 263680 | performance: 1.0 | accuracy: 0.13 | loss: 0.29
update:1035/2000, 耗时:0.01分/6.76分 | step: 264960 | performance: 1.0 | accuracy: 0.13 | loss: 0.24
update:1040/2000, 耗时:0.01分/6.80分 | step: 266240 | performance: 0.9 | accuracy: 0.00 | loss: 0.22
update:1045/2000, 耗时:0.01分/6.83分 | step: 267520 | performance: 1.1 | accuracy: 0.13 | loss: 0.31
update:1050/2000, 耗时:0.01分/6.86分 | step: 268800 | performance: 0.9 | accuracy: 0.13 | loss: 0.37
update:1055/2000, 耗时:0.01分/6.90分 | step: 270080 | performance: 1.0 | accuracy: 0.11 | loss: 0.17
update:1060/2000, 耗时:0.01分/6.93分 | step: 271360 | performance: 1.0 | accuracy: 0.16 | loss: 0.24
step: 272128 | worker_7@n_step_31: average total_reward after train data exhaustion : 8.2 | max total_reward: 246.4
update:1065/2000, 耗时:0.01分/6.96分 | step: 272640 | performance: 1.0 | accuracy: 0.13 | loss: 0.25
update:1070/2000, 耗时:0.01分/7.00分 | step: 273920 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
step: 274176 | worker_7@n_step_31: average total_reward after train data exhaustion : 4.5 | max total_reward: 246.4
update:1075/2000, 耗时:0.01分/7.03分 | step: 275200 | performance: 1.2 | accuracy: 0.18 | loss: 0.18
update:1080/2000, 耗时:0.01分/7.06分 | step: 276480 | performance: 1.0 | accuracy: 0.06 | loss: 0.26
update:1085/2000, 耗时:0.01分/7.10分 | step: 277760 | performance: 0.9 | accuracy: 0.13 | loss: 0.33
update:1090/2000, 耗时:0.01分/7.13分 | step: 279040 | performance: 1.1 | accuracy: 0.15 | loss: 0.66
update:1095/2000, 耗时:0.01分/7.16分 | step: 280320 | performance: 1.0 | accuracy: 0.16 | loss: 0.53
update:1100/2000, 耗时:0.01分/7.19分 | step: 281600 | performance: 1.0 | accuracy: 0.18 | loss: 0.40
update:1105/2000, 耗时:0.01分/7.22分 | step: 282880 | performance: 1.0 | accuracy: 0.17 | loss: 0.28
update:1110/2000, 耗时:0.01分/7.26分 | step: 284160 | performance: 0.9 | accuracy: 0.18 | loss: 0.34
update:1115/2000, 耗时:0.01分/7.29分 | step: 285440 | performance: 0.8 | accuracy: 0.17 | loss: 0.33
update:1120/2000, 耗时:0.01分/7.32分 | step: 286720 | performance: 0.9 | accuracy: 0.18 | loss: 0.47
update:1125/2000, 耗时:0.01分/7.35分 | step: 288000 | performance: 0.7 | accuracy: 0.17 | loss: 0.36
update:1130/2000, 耗时:0.01分/7.39分 | step: 289280 | performance: 0.7 | accuracy: 0.16 | loss: 0.30
step: 290042 | worker_1@n_step_31: average total_reward after train data exhaustion : 12.1 | max total_reward: 246.4
update:1135/2000, 耗时:0.01分/7.42分 | step: 290560 | performance: 0.8 | accuracy: 0.16 | loss: 0.37
update:1140/2000, 耗时:0.01分/7.45分 | step: 291840 | performance: 1.0 | accuracy: 0.16 | loss: 0.32
update:1145/2000, 耗时:0.01分/7.48分 | step: 293120 | performance: 0.9 | accuracy: 0.16 | loss: 0.32
update:1150/2000, 耗时:0.01分/7.52分 | step: 294400 | performance: 1.0 | accuracy: 0.15 | loss: 0.36
update:1155/2000, 耗时:0.01分/7.55分 | step: 295680 | performance: 1.0 | accuracy: 0.16 | loss: 0.32
update:1160/2000, 耗时:0.01分/7.58分 | step: 296960 | performance: 1.1 | accuracy: 0.16 | loss: 0.46
update:1165/2000, 耗时:0.01分/7.62分 | step: 298240 | performance: 1.0 | accuracy: 0.16 | loss: 0.36
update:1170/2000, 耗时:0.01分/7.65分 | step: 299520 | performance: 0.7 | accuracy: 0.15 | loss: 0.26
update:1175/2000, 耗时:0.01分/7.68分 | step: 300800 | performance: 0.8 | accuracy: 0.15 | loss: 0.27
update:1180/2000, 耗时:0.01分/7.71分 | step: 302080 | performance: 0.8 | accuracy: 0.15 | loss: 0.27
update:1185/2000, 耗时:0.01分/7.74分 | step: 303360 | performance: 0.9 | accuracy: 0.15 | loss: 0.29
update:1190/2000, 耗时:0.01分/7.78分 | step: 304640 | performance: 0.7 | accuracy: 0.14 | loss: 0.19
update:1195/2000, 耗时:0.01分/7.81分 | step: 305920 | performance: 0.7 | accuracy: 0.14 | loss: 0.28
step: 307193 | worker_0@n_step_31: average total_reward after train data exhaustion : 12.5 | max total_reward: 246.4
update:1200/2000, 耗时:0.01分/7.84分 | step: 307200 | performance: 0.7 | accuracy: 0.14 | loss: 0.26
step: 307451 | worker_2@n_step_31: average total_reward after train data exhaustion : 12.5 | max total_reward: 246.4
update:1205/2000, 耗时:0.01分/7.88分 | step: 308480 | performance: 1.0 | accuracy: 0.17 | loss: 0.23
step: 309248 | worker_7@n_step_31: average total_reward after train data exhaustion : 16.7 | max total_reward: 246.4
update:1210/2000, 耗时:0.01分/7.91分 | step: 309760 | performance: 1.1 | accuracy: 0.12 | loss: 0.24
step: 310011 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.6 | max total_reward: 246.4
step: 310779 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.6 | max total_reward: 246.4
update:1215/2000, 耗时:0.01分/7.94分 | step: 311040 | performance: 1.0 | accuracy: 0.12 | loss: 0.26
update:1220/2000, 耗时:0.01分/7.97分 | step: 312320 | performance: 1.0 | accuracy: 0.13 | loss: 0.29
update:1225/2000, 耗时:0.01分/8.01分 | step: 313600 | performance: 1.0 | accuracy: 0.12 | loss: 0.27
step: 314363 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 246.4
update:1230/2000, 耗时:0.01分/8.04分 | step: 314880 | performance: 0.9 | accuracy: 0.12 | loss: 0.16
update:1235/2000, 耗时:0.01分/8.07分 | step: 316160 | performance: 0.9 | accuracy: 0.11 | loss: 0.16
update:1240/2000, 耗时:0.01分/8.10分 | step: 317440 | performance: 0.9 | accuracy: 0.11 | loss: 0.23
update:1245/2000, 耗时:0.01分/8.14分 | step: 318720 | performance: 1.0 | accuracy: 0.11 | loss: 0.26
step: 319227 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 246.4
update:1250/2000, 耗时:0.01分/8.17分 | step: 320000 | performance: 0.8 | accuracy: 0.12 | loss: 0.28
update:1255/2000, 耗时:0.01分/8.20分 | step: 321280 | performance: 0.8 | accuracy: 0.12 | loss: 0.24
update:1260/2000, 耗时:0.01分/8.24分 | step: 322560 | performance: 0.6 | accuracy: 0.12 | loss: 0.18
step: 323323 | worker_2@n_step_31: average total_reward after train data exhaustion : 13.2 | max total_reward: 246.4
step: 323582 | worker_5@n_step_31: average total_reward after train data exhaustion : 9.0 | max total_reward: 246.4
update:1265/2000, 耗时:0.01分/8.27分 | step: 323840 | performance: 0.5 | accuracy: 0.12 | loss: 0.23
step: 324347 | worker_2@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 246.4
update:1270/2000, 耗时:0.01分/8.30分 | step: 325120 | performance: 0.5 | accuracy: 0.12 | loss: 0.31
update:1275/2000, 耗时:0.01分/8.33分 | step: 326400 | performance: 0.5 | accuracy: 0.12 | loss: 0.30
update:1280/2000, 耗时:0.01分/8.36分 | step: 327680 | performance: 0.7 | accuracy: 0.12 | loss: 0.33
step: 328700 | worker_3@n_step_31: average total_reward after train data exhaustion : 8.1 | max total_reward: 246.4
update:1285/2000, 耗时:0.01分/8.40分 | step: 328960 | performance: 0.7 | accuracy: 0.12 | loss: 0.24
step: 330236 | worker_3@n_step_31: average total_reward after train data exhaustion : 8.0 | max total_reward: 246.4
update:1290/2000, 耗时:0.01分/8.43分 | step: 330240 | performance: 0.9 | accuracy: 0.12 | loss: 0.32
update:1295/2000, 耗时:0.01分/8.46分 | step: 331520 | performance: 0.9 | accuracy: 0.12 | loss: 0.26
update:1300/2000, 耗时:0.01分/8.49分 | step: 332800 | performance: 1.0 | accuracy: 0.12 | loss: 0.32
update:1305/2000, 耗时:0.01分/8.52分 | step: 334080 | performance: 1.1 | accuracy: 0.12 | loss: 0.43
update:1310/2000, 耗时:0.01分/8.55分 | step: 335360 | performance: 0.9 | accuracy: 0.12 | loss: 0.22
update:1315/2000, 耗时:0.01分/8.59分 | step: 336640 | performance: 0.9 | accuracy: 0.12 | loss: 0.23
update:1320/2000, 耗时:0.01分/8.62分 | step: 337920 | performance: 1.1 | accuracy: 0.12 | loss: 0.23
update:1325/2000, 耗时:0.01分/8.65分 | step: 339200 | performance: 1.1 | accuracy: 0.17 | loss: 0.23
update:1330/2000, 耗时:0.01分/8.69分 | step: 340480 | performance: 1.0 | accuracy: 0.00 | loss: 0.28
step: 341760 | worker_7@n_step_31: average total_reward after train data exhaustion : 8.0 | max total_reward: 246.4
update:1335/2000, 耗时:0.01分/8.72分 | step: 341760 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
update:1340/2000, 耗时:0.01分/8.75分 | step: 343040 | performance: 1.0 | accuracy: 0.15 | loss: 0.41
update:1345/2000, 耗时:0.01分/8.78分 | step: 344320 | performance: 1.2 | accuracy: 0.12 | loss: 0.28
update:1350/2000, 耗时:0.01分/8.82分 | step: 345600 | performance: 1.1 | accuracy: 0.12 | loss: 0.27
update:1355/2000, 耗时:0.01分/8.85分 | step: 346880 | performance: 1.1 | accuracy: 0.12 | loss: 0.22
update:1360/2000, 耗时:0.01分/8.88分 | step: 348160 | performance: 1.5 | accuracy: 0.13 | loss: 0.27
update:1365/2000, 耗时:0.01分/8.91分 | step: 349440 | performance: 1.6 | accuracy: 0.13 | loss: 0.18
update:1370/2000, 耗时:0.01分/8.94分 | step: 350720 | performance: 1.9 | accuracy: 0.13 | loss: 0.24
update:1375/2000, 耗时:0.01分/8.98分 | step: 352000 | performance: 2.1 | accuracy: 0.12 | loss: 0.20
update:1380/2000, 耗时:0.01分/9.01分 | step: 353280 | performance: 2.3 | accuracy: 0.12 | loss: 0.16
update:1385/2000, 耗时:0.01分/9.04分 | step: 354560 | performance: 2.2 | accuracy: 0.13 | loss: 0.17
step: 355326 | worker_5@n_step_31: average total_reward after train data exhaustion : 19.4 | max total_reward: 246.4
step: 355581 | worker_4@n_step_31: average total_reward after train data exhaustion : 19.6 | max total_reward: 246.4
update:1390/2000, 耗时:0.01分/9.07分 | step: 355840 | performance: 2.2 | accuracy: 0.12 | loss: 0.20
step: 357115 | worker_2@n_step_31: average total_reward after train data exhaustion : 19.6 | max total_reward: 246.4
update:1395/2000, 耗时:0.01分/9.10分 | step: 357120 | performance: 2.3 | accuracy: 0.13 | loss: 0.20
step: 357370 | worker_1@n_step_31: average total_reward after train data exhaustion : 8.5 | max total_reward: 246.4
step: 358397 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 246.4
update:1400/2000, 耗时:0.01分/9.13分 | step: 358400 | performance: 2.3 | accuracy: 0.12 | loss: 0.17
step: 358907 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 246.4
step: 358911 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 246.4
step: 359679 | worker_6@n_step_31: average total_reward after train data exhaustion : 4.9 | max total_reward: 246.4
update:1405/2000, 耗时:0.01分/9.16分 | step: 359680 | performance: 2.1 | accuracy: 0.12 | loss: 0.29
step: 360188 | worker_3@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 246.4
update:1410/2000, 耗时:0.01分/9.20分 | step: 360960 | performance: 2.4 | accuracy: 0.12 | loss: 0.27
update:1415/2000, 耗时:0.01分/9.23分 | step: 362240 | performance: 2.8 | accuracy: 0.12 | loss: 0.22
update:1420/2000, 耗时:0.01分/9.26分 | step: 363520 | performance: 3.3 | accuracy: 0.12 | loss: 0.18
step: 364538 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 246.4
update:1425/2000, 耗时:0.01分/9.29分 | step: 364800 | performance: 2.8 | accuracy: 0.12 | loss: 0.23
step: 365818 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 246.4
step: 365820 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 246.4
update:1430/2000, 耗时:0.01分/9.33分 | step: 366080 | performance: 2.6 | accuracy: 0.12 | loss: 0.21
update:1435/2000, 耗时:0.01分/9.36分 | step: 367360 | performance: 2.3 | accuracy: 0.11 | loss: 0.28
update:1440/2000, 耗时:0.01分/9.39分 | step: 368640 | performance: 2.1 | accuracy: 0.11 | loss: 0.19
step: 368895 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 246.4
step: 369660 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 246.4
step: 369914 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 246.4
update:1445/2000, 耗时:0.01分/9.42分 | step: 369920 | performance: 1.9 | accuracy: 0.11 | loss: 0.18
update:1450/2000, 耗时:0.01分/9.45分 | step: 371200 | performance: 1.6 | accuracy: 0.11 | loss: 0.42
update:1455/2000, 耗时:0.01分/9.48分 | step: 372480 | performance: 0.9 | accuracy: 0.15 | loss: 0.29
step: 373245 | worker_4@n_step_31: average total_reward after train data exhaustion : 8.3 | max total_reward: 246.4
update:1460/2000, 耗时:0.01分/9.51分 | step: 373760 | performance: 0.8 | accuracy: 0.11 | loss: 0.36
update:1465/2000, 耗时:0.01分/9.55分 | step: 375040 | performance: 0.8 | accuracy: 0.14 | loss: 0.51
update:1470/2000, 耗时:0.01分/9.58分 | step: 376320 | performance: 0.6 | accuracy: 0.13 | loss: 0.35
update:1475/2000, 耗时:0.01分/9.61分 | step: 377600 | performance: 0.6 | accuracy: 0.13 | loss: 0.26
update:1480/2000, 耗时:0.01分/9.64分 | step: 378880 | performance: 0.6 | accuracy: 0.14 | loss: 0.28
update:1485/2000, 耗时:0.01分/9.67分 | step: 380160 | performance: 0.6 | accuracy: 0.14 | loss: 0.38
update:1490/2000, 耗时:0.01分/9.70分 | step: 381440 | performance: 0.5 | accuracy: 0.14 | loss: 0.33
update:1495/2000, 耗时:0.01分/9.74分 | step: 382720 | performance: 0.5 | accuracy: 0.15 | loss: 0.39
update:1500/2000, 耗时:0.01分/9.77分 | step: 384000 | performance: 0.4 | accuracy: 0.15 | loss: 0.32
update:1505/2000, 耗时:0.01分/9.80分 | step: 385280 | performance: 0.6 | accuracy: 0.15 | loss: 0.30
update:1510/2000, 耗时:0.01分/9.83分 | step: 386560 | performance: 0.6 | accuracy: 0.15 | loss: 0.25
update:1515/2000, 耗时:0.01分/9.86分 | step: 387840 | performance: 0.5 | accuracy: 0.15 | loss: 0.31
update:1520/2000, 耗时:0.01分/9.89分 | step: 389120 | performance: 0.5 | accuracy: 0.16 | loss: 0.44
update:1525/2000, 耗时:0.01分/9.93分 | step: 390400 | performance: 0.6 | accuracy: 0.16 | loss: 0.80
update:1530/2000, 耗时:0.01分/9.96分 | step: 391680 | performance: 0.5 | accuracy: 0.17 | loss: 0.76
update:1535/2000, 耗时:0.01分/9.99分 | step: 392960 | performance: 0.7 | accuracy: 0.18 | loss: 1.08
update:1540/2000, 耗时:0.01分/10.02分 | step: 394240 | performance: 0.6 | accuracy: 0.18 | loss: 0.97
update:1545/2000, 耗时:0.01分/10.05分 | step: 395520 | performance: 0.5 | accuracy: 0.19 | loss: 0.41
update:1550/2000, 耗时:0.01分/10.08分 | step: 396800 | performance: 0.4 | accuracy: 0.19 | loss: 0.55
update:1555/2000, 耗时:0.01分/10.11分 | step: 398080 | performance: 0.3 | accuracy: 0.19 | loss: 0.38
update:1560/2000, 耗时:0.01分/10.14分 | step: 399360 | performance: 0.3 | accuracy: 0.19 | loss: 0.74
update:1565/2000, 耗时:0.01分/10.17分 | step: 400640 | performance: 0.3 | accuracy: 0.18 | loss: 0.28
update:1570/2000, 耗时:0.01分/10.21分 | step: 401920 | performance: 1.2 | accuracy: 0.18 | loss: 0.37
update:1575/2000, 耗时:0.01分/10.24分 | step: 403200 | performance: 0.9 | accuracy: 0.16 | loss: 0.41
update:1580/2000, 耗时:0.01分/10.27分 | step: 404480 | performance: 1.0 | accuracy: 0.15 | loss: 0.41
update:1585/2000, 耗时:0.01分/10.30分 | step: 405760 | performance: 1.1 | accuracy: 0.15 | loss: 0.23
update:1590/2000, 耗时:0.01分/10.33分 | step: 407040 | performance: 1.2 | accuracy: 0.14 | loss: 0.39
update:1595/2000, 耗时:0.01分/10.36分 | step: 408320 | performance: 1.1 | accuracy: 0.15 | loss: 0.34
update:1600/2000, 耗时:0.01分/10.39分 | step: 409600 | performance: 1.2 | accuracy: 0.15 | loss: 0.29
update:1605/2000, 耗时:0.01分/10.43分 | step: 410880 | performance: 1.2 | accuracy: 0.15 | loss: 0.23
update:1610/2000, 耗时:0.01分/10.46分 | step: 412160 | performance: 1.1 | accuracy: 0.15 | loss: 0.17
update:1615/2000, 耗时:0.01分/10.49分 | step: 413440 | performance: 1.1 | accuracy: 0.15 | loss: 0.16
step: 414462 | worker_5@n_step_31: average total_reward after train data exhaustion : 36.6 | max total_reward: 255.3
update:1620/2000, 耗时:0.01分/10.52分 | step: 414720 | performance: 1.1 | accuracy: 0.15 | loss: 0.18
update:1625/2000, 耗时:0.01分/10.56分 | step: 416000 | performance: 1.3 | accuracy: 0.14 | loss: 0.27
update:1630/2000, 耗时:0.01分/10.59分 | step: 417280 | performance: 1.3 | accuracy: 0.14 | loss: 0.22
step: 417790 | worker_5@n_step_31: average total_reward after train data exhaustion : 21.6 | max total_reward: 255.3
update:1635/2000, 耗时:0.01分/10.62分 | step: 418560 | performance: 1.3 | accuracy: 0.14 | loss: 0.22
update:1640/2000, 耗时:0.01分/10.66分 | step: 419840 | performance: 1.4 | accuracy: 0.14 | loss: 0.33
update:1645/2000, 耗时:0.01分/10.69分 | step: 421120 | performance: 1.5 | accuracy: 0.14 | loss: 0.26
update:1650/2000, 耗时:0.01分/10.72分 | step: 422400 | performance: 1.1 | accuracy: 0.13 | loss: 0.35
update:1655/2000, 耗时:0.01分/10.76分 | step: 423680 | performance: 1.0 | accuracy: 0.13 | loss: 0.28
update:1660/2000, 耗时:0.01分/10.79分 | step: 424960 | performance: 1.0 | accuracy: 0.13 | loss: 0.26
update:1665/2000, 耗时:0.01分/10.82分 | step: 426240 | performance: 1.1 | accuracy: 0.13 | loss: 0.15
update:1670/2000, 耗时:0.01分/10.86分 | step: 427520 | performance: 0.8 | accuracy: 0.13 | loss: 0.22
update:1675/2000, 耗时:0.01分/10.89分 | step: 428800 | performance: 0.7 | accuracy: 0.13 | loss: 0.08
update:1680/2000, 耗时:0.01分/10.92分 | step: 430080 | performance: 0.7 | accuracy: 0.12 | loss: 0.18
step: 431359 | worker_6@n_step_31: average total_reward after train data exhaustion : 12.7 | max total_reward: 255.3
step: 431360 | worker_7@n_step_31: average total_reward after train data exhaustion : 12.7 | max total_reward: 255.3
update:1685/2000, 耗时:0.01分/10.96分 | step: 431360 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 431609 | worker_0@n_step_31: average total_reward after train data exhaustion : 12.7 | max total_reward: 255.3
update:1690/2000, 耗时:0.01分/10.99分 | step: 432640 | performance: 1.0 | accuracy: 0.33 | loss: 0.19
step: 433661 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 255.3
update:1695/2000, 耗时:0.01分/11.02分 | step: 433920 | performance: 0.9 | accuracy: 0.17 | loss: 0.23
step: 434176 | worker_7@n_step_31: average total_reward after train data exhaustion : 3.8 | max total_reward: 255.3
step: 434943 | worker_6@n_step_31: average total_reward after train data exhaustion : 3.8 | max total_reward: 255.3
update:1700/2000, 耗时:0.01分/11.06分 | step: 435200 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
step: 435452 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 255.3
step: 435707 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 255.3
step: 435711 | worker_6@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 255.3
step: 435712 | worker_7@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 255.3
step: 436473 | worker_0@n_step_31: average total_reward after train data exhaustion : 4.1 | max total_reward: 255.3
update:1705/2000, 耗时:0.01分/11.09分 | step: 436480 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
update:1710/2000, 耗时:0.01分/11.12分 | step: 437760 | performance: 1.0 | accuracy: 0.12 | loss: 0.24
step: 438521 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 255.3
step: 438528 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 255.3
update:1715/2000, 耗时:0.01分/11.16分 | step: 439040 | performance: 0.8 | accuracy: 0.12 | loss: 0.45
step: 439293 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 255.3
update:1720/2000, 耗时:0.01分/11.19分 | step: 440320 | performance: 1.0 | accuracy: 0.14 | loss: 0.46
update:1725/2000, 耗时:0.01分/11.22分 | step: 441600 | performance: 0.9 | accuracy: 0.16 | loss: 0.38
update:1730/2000, 耗时:0.01分/11.26分 | step: 442880 | performance: 0.8 | accuracy: 0.15 | loss: 0.20
update:1735/2000, 耗时:0.01分/11.29分 | step: 444160 | performance: 0.7 | accuracy: 0.14 | loss: 0.17
update:1740/2000, 耗时:0.01分/11.32分 | step: 445440 | performance: 0.7 | accuracy: 0.14 | loss: 0.14
update:1745/2000, 耗时:0.01分/11.35分 | step: 446720 | performance: 0.7 | accuracy: 0.13 | loss: 0.16
update:1750/2000, 耗时:0.01分/11.39分 | step: 448000 | performance: 0.8 | accuracy: 0.12 | loss: 0.17
update:1755/2000, 耗时:0.01分/11.42分 | step: 449280 | performance: 0.8 | accuracy: 0.13 | loss: 0.23
update:1760/2000, 耗时:0.01分/11.46分 | step: 450560 | performance: 0.7 | accuracy: 0.13 | loss: 0.17
update:1765/2000, 耗时:0.01分/11.49分 | step: 451840 | performance: 0.8 | accuracy: 0.12 | loss: 0.12
update:1770/2000, 耗时:0.01分/11.53分 | step: 453120 | performance: 0.8 | accuracy: 0.12 | loss: 0.17
update:1775/2000, 耗时:0.01分/11.56分 | step: 454400 | performance: 0.8 | accuracy: 0.12 | loss: 0.16
step: 455166 | worker_5@n_step_31: average total_reward after train data exhaustion : 4.7 | max total_reward: 255.3
update:1780/2000, 耗时:0.01分/11.60分 | step: 455680 | performance: 1.0 | accuracy: 0.12 | loss: 0.29
step: 456702 | worker_5@n_step_31: average total_reward after train data exhaustion : 4.5 | max total_reward: 255.3
update:1785/2000, 耗时:0.01分/11.63分 | step: 456960 | performance: 1.1 | accuracy: 0.12 | loss: 0.23
update:1790/2000, 耗时:0.01分/11.67分 | step: 458240 | performance: 1.1 | accuracy: 0.12 | loss: 0.34
update:1795/2000, 耗时:0.01分/11.70分 | step: 459520 | performance: 0.9 | accuracy: 0.12 | loss: 0.27
update:1800/2000, 耗时:0.01分/11.74分 | step: 460800 | performance: 0.8 | accuracy: 0.11 | loss: 0.16
update:1805/2000, 耗时:0.01分/11.77分 | step: 462080 | performance: 0.7 | accuracy: 0.11 | loss: 0.18
update:1810/2000, 耗时:0.01分/11.80分 | step: 463360 | performance: 0.8 | accuracy: 0.11 | loss: 0.21
update:1815/2000, 耗时:0.01分/11.84分 | step: 464640 | performance: 0.6 | accuracy: 0.11 | loss: 0.20
update:1820/2000, 耗时:0.01分/11.87分 | step: 465920 | performance: 0.7 | accuracy: 0.11 | loss: 0.18
update:1825/2000, 耗时:0.01分/11.91分 | step: 467200 | performance: 0.8 | accuracy: 0.11 | loss: 0.18
step: 467450 | worker_1@n_step_31: average total_reward after train data exhaustion : 13.4 | max total_reward: 255.3
update:1830/2000, 耗时:0.01分/11.95分 | step: 468480 | performance: 1.1 | accuracy: 0.14 | loss: 0.12
update:1835/2000, 耗时:0.01分/11.98分 | step: 469760 | performance: 1.0 | accuracy: 0.12 | loss: 0.19
step: 470780 | worker_3@n_step_31: average total_reward after train data exhaustion : 8.1 | max total_reward: 255.3
update:1840/2000, 耗时:0.01分/12.01分 | step: 471040 | performance: 1.0 | accuracy: 0.11 | loss: 0.16
step: 471291 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.2 | max total_reward: 255.3
step: 472317 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 255.3
update:1845/2000, 耗时:0.01分/12.04分 | step: 472320 | performance: 1.1 | accuracy: 0.12 | loss: 0.26
step: 472827 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 255.3
step: 472832 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 255.3
step: 473343 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 255.3
update:1850/2000, 耗时:0.01分/12.08分 | step: 473600 | performance: 1.0 | accuracy: 0.07 | loss: 0.23
step: 474109 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 255.3
step: 474624 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 255.3
update:1855/2000, 耗时:0.01分/12.11分 | step: 474880 | performance: 1.1 | accuracy: 0.07 | loss: 0.27
step: 475903 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 255.3
update:1860/2000, 耗时:0.01分/12.15分 | step: 476160 | performance: 1.2 | accuracy: 0.12 | loss: 0.21
update:1865/2000, 耗时:0.01分/12.18分 | step: 477440 | performance: 1.2 | accuracy: 0.11 | loss: 0.39
step: 477952 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 255.3
update:1870/2000, 耗时:0.01分/12.21分 | step: 478720 | performance: 1.0 | accuracy: 0.00 | loss: 0.26
update:1875/2000, 耗时:0.01分/12.24分 | step: 480000 | performance: 0.8 | accuracy: 0.14 | loss: 0.80
update:1880/2000, 耗时:0.01分/12.28分 | step: 481280 | performance: 1.0 | accuracy: 0.13 | loss: 0.54
update:1885/2000, 耗时:0.01分/12.31分 | step: 482560 | performance: 1.0 | accuracy: 0.16 | loss: 0.29
update:1890/2000, 耗时:0.01分/12.34分 | step: 483840 | performance: 0.8 | accuracy: 0.14 | loss: 0.23
update:1895/2000, 耗时:0.01分/12.38分 | step: 485120 | performance: 0.9 | accuracy: 0.16 | loss: 0.29
update:1900/2000, 耗时:0.01分/12.41分 | step: 486400 | performance: 0.9 | accuracy: 0.17 | loss: 0.30
update:1905/2000, 耗时:0.01分/12.44分 | step: 487680 | performance: 0.8 | accuracy: 0.16 | loss: 0.36
update:1910/2000, 耗时:0.01分/12.47分 | step: 488960 | performance: 1.0 | accuracy: 0.15 | loss: 0.31
update:1915/2000, 耗时:0.01分/12.51分 | step: 490240 | performance: 1.2 | accuracy: 0.15 | loss: 0.33
update:1920/2000, 耗时:0.01分/12.54分 | step: 491520 | performance: 1.1 | accuracy: 0.16 | loss: 0.39
update:1925/2000, 耗时:0.01分/12.57分 | step: 492800 | performance: 0.9 | accuracy: 0.15 | loss: 0.36
update:1930/2000, 耗时:0.01分/12.60分 | step: 494080 | performance: 0.7 | accuracy: 0.15 | loss: 0.43
update:1935/2000, 耗时:0.01分/12.63分 | step: 495360 | performance: 0.7 | accuracy: 0.16 | loss: 0.59
update:1940/2000, 耗时:0.01分/12.67分 | step: 496640 | performance: 0.7 | accuracy: 0.16 | loss: 0.49
update:1945/2000, 耗时:0.01分/12.70分 | step: 497920 | performance: 0.6 | accuracy: 0.17 | loss: 0.41
update:1950/2000, 耗时:0.01分/12.73分 | step: 499200 | performance: 0.6 | accuracy: 0.17 | loss: 0.43
update:1955/2000, 耗时:0.01分/12.76分 | step: 500480 | performance: 0.6 | accuracy: 0.17 | loss: 0.56
update:1960/2000, 耗时:0.01分/12.80分 | step: 501760 | performance: 0.7 | accuracy: 0.17 | loss: 0.42
update:1965/2000, 耗时:0.01分/12.83分 | step: 503040 | performance: 0.7 | accuracy: 0.17 | loss: 0.55
update:1970/2000, 耗时:0.01分/12.86分 | step: 504320 | performance: 0.9 | accuracy: 0.16 | loss: 0.42
update:1975/2000, 耗时:0.01分/12.89分 | step: 505600 | performance: 0.7 | accuracy: 0.16 | loss: 0.31
update:1980/2000, 耗时:0.01分/12.92分 | step: 506880 | performance: 0.7 | accuracy: 0.16 | loss: 0.33
update:1985/2000, 耗时:0.01分/12.96分 | step: 508160 | performance: 0.5 | accuracy: 0.16 | loss: 0.34
update:1990/2000, 耗时:0.01分/12.99分 | step: 509440 | performance: 0.5 | accuracy: 0.15 | loss: 0.27
step: 509695 | worker_6@n_step_31: average total_reward after train data exhaustion : 29.3 | max total_reward: 255.3
update:1995/2000, 耗时:0.01分/13.02分 | step: 510720 | performance: 1.0 | accuracy: 0.33 | loss: 0.38
update:2000/2000, 耗时:0.01分/13.05分 | step: 512000 | performance: 0.8 | accuracy: 0.12 | loss: 0.32
----------------------------------------finished----------------------------------------
  0%|          | 0/401 [00:00<?, ?it/s]100%|| 401/401 [00:00<00:00, 133602.03it/s]
==================================================
2023-01-05T12:00:00 | *** START BACKTEST ***
2023-01-05T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1678.02
2023-07-24T12:00:00 | net performance [%] = 67.8020
2023-07-24T12:00:00 | number of trades [#] = 4
==================================================
Trial 26 Complete [00h 13m 29s]
net_wealth: 1679.7001409568088

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 03h 42m 36s

Search: Running Trial #27

Value             |Best Value So Far |Hyperparameter
1                 |1                 |horizon
365               |730               |lookback
True              |False             |MarketFactor
5                 |3                 |lags
0.85              |0.92              |gamma
16                |32                |batch_size
1                 |1                 |n_step
0.94              |0.94              |gae_lambda
10                |5                 |gradient_clip_norm
3                 |5                 |epochs
5e-05             |0.0001            |actor_lr
0.001             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4300.000000   4301.000000
mean      0.000435    20113.607657  ...   20173.020481  20169.373185
std       0.027833    16040.642334  ...   16078.674434  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7736.967529   7730.930176
50%       0.000642    11571.842969  ...   11753.029785  11751.469727
75%       0.011590    29894.706152  ...   30013.548340  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 01:45:59.148332: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized wit2023-07-28 01:45:59.148391: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow b2023-07-28 01:45:59.148443: I tensorflow/core/platform/cpu2023-07-28 01:45:59h_ 2fea0.23-07-28 0otn1ure_:45gua148472: I:r 59dt..cc:142] 1eT4nh8si3os T3re2: fnsorFlowlI o btinarwieAensn/yco arrisey/ o is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU inPpptimized wisotIh trfl oneAPIDeeorw Deep Neural Netwpuctions in performance-critical operlork Library (oaa/core/tnieDo nstNform/cpuN:_)fN to ee u autral NetworkAs2 eLibrar ure_thy (onepVX AVX2
lDaNe fotgTfN) toolrou ml22ao0 us00enabl/w2ing C3er2PcUdp2 u._fthce3 -07c-:ef 2oi1nl8lost 01:44wr5e tuctih:259o]nem.s   Tihi1n 4pe-8906: Ii i0ns ntge nrTf7so-eornsao2rm8 CP U foliothaw/cornceFrne-3/platfoscrriml-ot/twi0c alr co7upera-t2ibct8 i0na1p:45:5rons: y9io. A nV1X4 Ai8sVs8 Xi 0n5 2o0e
rp epTtoimi1ope:zer4 r5for:tatu:rdeimo5 9en .wab_Ia lu_intche o-ncfteenreieanss, gou aretAPtI Dbe1t4h8ueicealriup8 9oredr.m9c p_gufciledr T:e14ansordatn2]r.li F cocw:lootwhe  142]/rcwN eouproireal e/rplNtaaote Thtfwhot i:rokT nosin h:itrms/hc s eAV, p ruXa p_sfTeens eTbeuilpan dr soorrFFlowoTet pbinLiblrnsoIuoAwarrFlorw wi ytree_gnu sVaXaio2
rd.sitchcr: f tlo1p4tieT cth2omoe  ized wbe iiman]aryt hp ioppirs nn aaTeoloerbhlpetrAoPI pfriaty itlws/ caio rT e/emipzDgheesneledpms (aet.forio  
om /wriFtlnch  Npcoow booneuiumtern_phAaafiePlrelrI ne DoN DeapeerattiorN y) Nieteusfwnos  loptrikto rm iL,uesaze _rgeubeidapr dg.cuNbsr atiel.chural
ry (oneD: 14d Net TeNwwen2Nith one following CPU As] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable ork Librar)instru Pothem in other operations, rebuild TensorFlow with the appropriate compiler flags.
crFlow with the appropriate ctIiyt (ooons  mpi in ulsDeeep NepeoneDNN) toeurrform a the follonr flags.
wing CPcuse the following CPU instructions in al Network Library (oneDNN) to use the following CPU instructions in performance-crite-criticU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
ical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
al operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow wperformance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
ith the appropriate compiler flags.
2023-07-28 01:45:59.768688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:45:59.771535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:45:59.771684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:45:59.776437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:45:59.777962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:45:59.799181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:45:59.800052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:45:59.804438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.02分 | step:    40 | performance: 1.1 | accuracy: 0.60 | loss: 0.72
update: 10/2000, 耗时:0.00分/0.03分 | step:    80 | performance: 1.1 | accuracy: 0.40 | loss: 0.55
update: 15/2000, 耗时:0.00分/0.04分 | step:   120 | performance: 1.1 | accuracy: 0.47 | loss: 0.63
update: 20/2000, 耗时:0.00分/0.04分 | step:   160 | performance: 1.1 | accuracy: 0.40 | loss: 0.39
update: 25/2000, 耗时:0.00分/0.05分 | step:   200 | performance: 1.1 | accuracy: 0.44 | loss: 0.49
update: 30/2000, 耗时:0.00分/0.05分 | step:   240 | performance: 1.2 | accuracy: 0.50 | loss: 0.44
update: 35/2000, 耗时:0.00分/0.06分 | step:   280 | performance: 1.3 | accuracy: 0.46 | loss: 0.22
update: 40/2000, 耗时:0.00分/0.07分 | step:   320 | performance: 1.3 | accuracy: 0.45 | loss: 0.49
update: 45/2000, 耗时:0.00分/0.07分 | step:   360 | performance: 1.4 | accuracy: 0.47 | loss: 0.49
update: 50/2000, 耗时:0.00分/0.08分 | step:   400 | performance: 1.4 | accuracy: 0.48 | loss: 0.52
update: 55/2000, 耗时:0.00分/0.08分 | step:   440 | performance: 1.5 | accuracy: 0.47 | loss: 0.48
update: 60/2000, 耗时:0.00分/0.09分 | step:   480 | performance: 1.4 | accuracy: 0.47 | loss: 0.33
update: 65/2000, 耗时:0.00分/0.10分 | step:   520 | performance: 1.3 | accuracy: 0.46 | loss: 0.25
update: 70/2000, 耗时:0.00分/0.10分 | step:   560 | performance: 1.3 | accuracy: 0.44 | loss: 0.56
update: 75/2000, 耗时:0.00分/0.11分 | step:   600 | performance: 1.6 | accuracy: 0.47 | loss: 0.37
update: 80/2000, 耗时:0.00分/0.12分 | step:   640 | performance: 1.7 | accuracy: 0.46 | loss: 0.09
update: 85/2000, 耗时:0.00分/0.12分 | step:   680 | performance: 1.7 | accuracy: 0.45 | loss: 0.63
update: 90/2000, 耗时:0.00分/0.13分 | step:   720 | performance: 1.8 | accuracy: 0.46 | loss: 0.33
update: 95/2000, 耗时:0.00分/0.14分 | step:   760 | performance: 1.8 | accuracy: 0.44 | loss: 0.28
update:100/2000, 耗时:0.00分/0.14分 | step:   800 | performance: 1.7 | accuracy: 0.43 | loss: 0.56
update:105/2000, 耗时:0.00分/0.15分 | step:   840 | performance: 1.6 | accuracy: 0.42 | loss: 0.22
update:110/2000, 耗时:0.00分/0.16分 | step:   880 | performance: 1.7 | accuracy: 0.43 | loss: 0.43
update:115/2000, 耗时:0.00分/0.16分 | step:   920 | performance: 1.7 | accuracy: 0.42 | loss: 0.45
update:120/2000, 耗时:0.00分/0.17分 | step:   960 | performance: 1.7 | accuracy: 0.41 | loss: 0.30
update:125/2000, 耗时:0.00分/0.18分 | step:  1000 | performance: 1.7 | accuracy: 0.42 | loss: 0.29
update:130/2000, 耗时:0.00分/0.18分 | step:  1040 | performance: 1.7 | accuracy: 0.42 | loss: 0.56
update:135/2000, 耗时:0.00分/0.19分 | step:  1080 | performance: 1.7 | accuracy: 0.43 | loss: 0.48
update:140/2000, 耗时:0.00分/0.20分 | step:  1120 | performance: 1.7 | accuracy: 0.42 | loss: 0.41
update:145/2000, 耗时:0.00分/0.21分 | step:  1160 | performance: 1.7 | accuracy: 0.41 | loss: 0.16
update:150/2000, 耗时:0.00分/0.21分 | step:  1200 | performance: 1.7 | accuracy: 0.41 | loss: 0.29
update:155/2000, 耗时:0.00分/0.22分 | step:  1240 | performance: 1.6 | accuracy: 0.40 | loss: 0.51
update:160/2000, 耗时:0.00分/0.23分 | step:  1280 | performance: 1.7 | accuracy: 0.40 | loss: 0.14
update:165/2000, 耗时:0.00分/0.23分 | step:  1320 | performance: 1.7 | accuracy: 0.41 | loss: 0.42
update:170/2000, 耗时:0.00分/0.24分 | step:  1360 | performance: 1.9 | accuracy: 0.42 | loss: 0.39
update:175/2000, 耗时:0.00分/0.25分 | step:  1400 | performance: 1.9 | accuracy: 0.42 | loss: 0.29
update:180/2000, 耗时:0.00分/0.26分 | step:  1440 | performance: 1.8 | accuracy: 0.41 | loss: 0.39
update:185/2000, 耗时:0.00分/0.26分 | step:  1480 | performance: 1.9 | accuracy: 0.41 | loss: 0.39
update:190/2000, 耗时:0.00分/0.27分 | step:  1520 | performance: 1.9 | accuracy: 0.41 | loss: 0.33
update:195/2000, 耗时:0.00分/0.28分 | step:  1560 | performance: 1.7 | accuracy: 0.41 | loss: 0.52
update:200/2000, 耗时:0.00分/0.28分 | step:  1600 | performance: 1.7 | accuracy: 0.41 | loss: 0.41
update:205/2000, 耗时:0.00分/0.29分 | step:  1640 | performance: 1.8 | accuracy: 0.41 | loss: 0.39
update:210/2000, 耗时:0.00分/0.30分 | step:  1680 | performance: 1.8 | accuracy: 0.41 | loss: 0.11
update:215/2000, 耗时:0.00分/0.30分 | step:  1720 | performance: 1.8 | accuracy: 0.40 | loss: 0.14
update:220/2000, 耗时:0.00分/0.31分 | step:  1760 | performance: 1.7 | accuracy: 0.40 | loss: 0.63
update:225/2000, 耗时:0.00分/0.32分 | step:  1800 | performance: 1.7 | accuracy: 0.40 | loss: 0.33
update:230/2000, 耗时:0.00分/0.33分 | step:  1840 | performance: 1.6 | accuracy: 0.40 | loss: 0.40
update:235/2000, 耗时:0.00分/0.33分 | step:  1880 | performance: 1.7 | accuracy: 0.39 | loss: 0.14
update:240/2000, 耗时:0.00分/0.34分 | step:  1920 | performance: 1.7 | accuracy: 0.38 | loss: 0.07
update:245/2000, 耗时:0.00分/0.35分 | step:  1960 | performance: 1.7 | accuracy: 0.39 | loss: 0.32
update:250/2000, 耗时:0.00分/0.35分 | step:  2000 | performance: 1.7 | accuracy: 0.38 | loss: 0.19
update:255/2000, 耗时:0.00分/0.36分 | step:  2040 | performance: 1.7 | accuracy: 0.38 | loss: 0.39
update:260/2000, 耗时:0.00分/0.37分 | step:  2080 | performance: 1.7 | accuracy: 0.38 | loss: 0.37
update:265/2000, 耗时:0.00分/0.38分 | step:  2120 | performance: 1.8 | accuracy: 0.39 | loss: 0.19
update:270/2000, 耗时:0.00分/0.38分 | step:  2160 | performance: 1.8 | accuracy: 0.39 | loss: 0.06
update:275/2000, 耗时:0.00分/0.39分 | step:  2200 | performance: 1.9 | accuracy: 0.39 | loss: 0.27
update:280/2000, 耗时:0.00分/0.40分 | step:  2240 | performance: 1.8 | accuracy: 0.39 | loss: 0.29
update:285/2000, 耗时:0.00分/0.40分 | step:  2280 | performance: 1.8 | accuracy: 0.39 | loss: 0.22
update:290/2000, 耗时:0.00分/0.41分 | step:  2320 | performance: 1.8 | accuracy: 0.38 | loss: 0.35
update:295/2000, 耗时:0.00分/0.42分 | step:  2360 | performance: 1.7 | accuracy: 0.38 | loss: 0.59
update:300/2000, 耗时:0.00分/0.43分 | step:  2400 | performance: 1.7 | accuracy: 0.38 | loss: 0.51
update:305/2000, 耗时:0.00分/0.43分 | step:  2440 | performance: 1.6 | accuracy: 0.37 | loss: 0.45
update:310/2000, 耗时:0.00分/0.44分 | step:  2480 | performance: 1.8 | accuracy: 0.37 | loss: 0.51
update:315/2000, 耗时:0.00分/0.45分 | step:  2520 | performance: 1.8 | accuracy: 0.37 | loss: 0.25
update:320/2000, 耗时:0.00分/0.45分 | step:  2560 | performance: 1.7 | accuracy: 0.37 | loss: 0.32
update:325/2000, 耗时:0.00分/0.46分 | step:  2600 | performance: 1.7 | accuracy: 0.37 | loss: 0.10
update:330/2000, 耗时:0.00分/0.47分 | step:  2640 | performance: 1.8 | accuracy: 0.37 | loss: 0.12
update:335/2000, 耗时:0.00分/0.47分 | step:  2680 | performance: 1.7 | accuracy: 0.37 | loss: 0.36
update:340/2000, 耗时:0.00分/0.48分 | step:  2720 | performance: 1.6 | accuracy: 0.36 | loss: 1.09
update:345/2000, 耗时:0.00分/0.49分 | step:  2760 | performance: 1.6 | accuracy: 0.36 | loss: 0.11
update:350/2000, 耗时:0.00分/0.50分 | step:  2800 | performance: 1.7 | accuracy: 0.37 | loss: 0.23
update:355/2000, 耗时:0.00分/0.50分 | step:  2840 | performance: 1.7 | accuracy: 0.37 | loss: 0.49
update:360/2000, 耗时:0.00分/0.51分 | step:  2880 | performance: 1.8 | accuracy: 0.38 | loss: 0.08
update:365/2000, 耗时:0.00分/0.52分 | step:  2920 | performance: 1.6 | accuracy: 0.37 | loss: 0.42
update:370/2000, 耗时:0.00分/0.53分 | step:  2960 | performance: 1.5 | accuracy: 0.37 | loss: 0.62
update:375/2000, 耗时:0.00分/0.53分 | step:  3000 | performance: 1.4 | accuracy: 0.37 | loss: 0.22
update:380/2000, 耗时:0.00分/0.54分 | step:  3040 | performance: 1.4 | accuracy: 0.36 | loss: 0.36
update:385/2000, 耗时:0.00分/0.55分 | step:  3080 | performance: 1.5 | accuracy: 0.36 | loss: 0.30
update:390/2000, 耗时:0.00分/0.56分 | step:  3120 | performance: 1.5 | accuracy: 0.36 | loss: 0.52
update:395/2000, 耗时:0.00分/0.56分 | step:  3160 | performance: 1.5 | accuracy: 0.37 | loss: 0.08
update:400/2000, 耗时:0.00分/0.57分 | step:  3200 | performance: 1.6 | accuracy: 0.37 | loss: 0.06
update:405/2000, 耗时:0.00分/0.58分 | step:  3240 | performance: 1.6 | accuracy: 0.37 | loss: 0.33
update:410/2000, 耗时:0.00分/0.58分 | step:  3280 | performance: 1.7 | accuracy: 0.37 | loss: 0.40
update:415/2000, 耗时:0.00分/0.59分 | step:  3320 | performance: 1.6 | accuracy: 0.37 | loss: 0.24
update:420/2000, 耗时:0.00分/0.60分 | step:  3360 | performance: 1.6 | accuracy: 0.37 | loss: 0.23
update:425/2000, 耗时:0.00分/0.61分 | step:  3400 | performance: 1.7 | accuracy: 0.37 | loss: 0.40
update:430/2000, 耗时:0.00分/0.61分 | step:  3440 | performance: 1.7 | accuracy: 0.37 | loss: 0.00
update:435/2000, 耗时:0.00分/0.62分 | step:  3480 | performance: 1.7 | accuracy: 0.36 | loss: 0.21
update:440/2000, 耗时:0.00分/0.63分 | step:  3520 | performance: 1.6 | accuracy: 0.36 | loss: 0.25
update:445/2000, 耗时:0.00分/0.64分 | step:  3560 | performance: 1.7 | accuracy: 0.36 | loss: 0.51
update:450/2000, 耗时:0.00分/0.64分 | step:  3600 | performance: 1.6 | accuracy: 0.36 | loss: 0.01
update:455/2000, 耗时:0.00分/0.65分 | step:  3640 | performance: 1.6 | accuracy: 0.36 | loss: 0.37
update:460/2000, 耗时:0.00分/0.66分 | step:  3680 | performance: 1.6 | accuracy: 0.36 | loss: 0.37
update:465/2000, 耗时:0.00分/0.66分 | step:  3720 | performance: 1.6 | accuracy: 0.36 | loss: 0.26
update:470/2000, 耗时:0.00分/0.67分 | step:  3760 | performance: 1.7 | accuracy: 0.36 | loss: 0.20
update:475/2000, 耗时:0.00分/0.68分 | step:  3800 | performance: 1.7 | accuracy: 0.36 | loss: 0.05
update:480/2000, 耗时:0.00分/0.69分 | step:  3840 | performance: 1.7 | accuracy: 0.37 | loss: 0.11
update:485/2000, 耗时:0.00分/0.69分 | step:  3880 | performance: 1.7 | accuracy: 0.36 | loss: 0.05
update:490/2000, 耗时:0.00分/0.70分 | step:  3920 | performance: 1.7 | accuracy: 0.36 | loss: 0.05
update:495/2000, 耗时:0.00分/0.71分 | step:  3960 | performance: 1.6 | accuracy: 0.36 | loss: 0.12
update:500/2000, 耗时:0.00分/0.71分 | step:  4000 | performance: 1.7 | accuracy: 0.36 | loss: 0.14
update:505/2000, 耗时:0.00分/0.72分 | step:  4040 | performance: 1.7 | accuracy: 0.36 | loss: 0.21
update:510/2000, 耗时:0.00分/0.73分 | step:  4080 | performance: 1.7 | accuracy: 0.36 | loss: 0.19
update:515/2000, 耗时:0.00分/0.74分 | step:  4120 | performance: 1.9 | accuracy: 0.36 | loss: 0.17
update:520/2000, 耗时:0.00分/0.74分 | step:  4160 | performance: 1.7 | accuracy: 0.36 | loss: 0.46
update:525/2000, 耗时:0.00分/0.75分 | step:  4200 | performance: 1.6 | accuracy: 0.36 | loss: 0.55
update:530/2000, 耗时:0.00分/0.76分 | step:  4240 | performance: 1.6 | accuracy: 0.36 | loss: 0.39
update:535/2000, 耗时:0.00分/0.76分 | step:  4280 | performance: 1.9 | accuracy: 0.37 | loss: 0.27
update:540/2000, 耗时:0.00分/0.77分 | step:  4320 | performance: 1.9 | accuracy: 0.37 | loss: 0.13
update:545/2000, 耗时:0.00分/0.78分 | step:  4360 | performance: 2.0 | accuracy: 0.37 | loss: 0.33
update:550/2000, 耗时:0.00分/0.78分 | step:  4400 | performance: 1.9 | accuracy: 0.37 | loss: 1.03
update:555/2000, 耗时:0.00分/0.79分 | step:  4440 | performance: 1.8 | accuracy: 0.37 | loss: 0.41
update:560/2000, 耗时:0.00分/0.80分 | step:  4480 | performance: 1.9 | accuracy: 0.37 | loss: 0.04
update:565/2000, 耗时:0.00分/0.81分 | step:  4520 | performance: 1.8 | accuracy: 0.37 | loss: 0.13
update:570/2000, 耗时:0.00分/0.81分 | step:  4560 | performance: 1.8 | accuracy: 0.37 | loss: 0.40
update:575/2000, 耗时:0.00分/0.82分 | step:  4600 | performance: 2.1 | accuracy: 0.37 | loss: 0.24
update:580/2000, 耗时:0.00分/0.83分 | step:  4640 | performance: 2.0 | accuracy: 0.37 | loss: 0.44
update:585/2000, 耗时:0.00分/0.83分 | step:  4680 | performance: 1.9 | accuracy: 0.37 | loss: 0.41
update:590/2000, 耗时:0.00分/0.84分 | step:  4720 | performance: 1.7 | accuracy: 0.37 | loss: 0.53
update:595/2000, 耗时:0.00分/0.85分 | step:  4760 | performance: 1.6 | accuracy: 0.37 | loss: 0.40
update:600/2000, 耗时:0.00分/0.86分 | step:  4800 | performance: 1.6 | accuracy: 0.37 | loss: 0.52
update:605/2000, 耗时:0.00分/0.86分 | step:  4840 | performance: 1.7 | accuracy: 0.37 | loss: 0.41
update:610/2000, 耗时:0.00分/0.87分 | step:  4880 | performance: 1.7 | accuracy: 0.37 | loss: 0.26
update:615/2000, 耗时:0.00分/0.88分 | step:  4920 | performance: 1.8 | accuracy: 0.38 | loss: 0.41
update:620/2000, 耗时:0.00分/0.88分 | step:  4960 | performance: 1.8 | accuracy: 0.38 | loss: 0.48
update:625/2000, 耗时:0.00分/0.89分 | step:  5000 | performance: 1.8 | accuracy: 0.38 | loss: 0.34
update:630/2000, 耗时:0.00分/0.90分 | step:  5040 | performance: 1.8 | accuracy: 0.38 | loss: 0.26
update:635/2000, 耗时:0.00分/0.91分 | step:  5080 | performance: 1.8 | accuracy: 0.37 | loss: 0.35
update:640/2000, 耗时:0.00分/0.91分 | step:  5120 | performance: 1.8 | accuracy: 0.37 | loss: 0.39
update:645/2000, 耗时:0.00分/0.92分 | step:  5160 | performance: 1.8 | accuracy: 0.37 | loss: 0.38
update:650/2000, 耗时:0.00分/0.93分 | step:  5200 | performance: 1.8 | accuracy: 0.37 | loss: 0.45
update:655/2000, 耗时:0.00分/0.93分 | step:  5240 | performance: 1.7 | accuracy: 0.37 | loss: 0.32
update:660/2000, 耗时:0.00分/0.94分 | step:  5280 | performance: 1.7 | accuracy: 0.37 | loss: 0.32
update:665/2000, 耗时:0.00分/0.95分 | step:  5320 | performance: 1.7 | accuracy: 0.37 | loss: 0.23
update:670/2000, 耗时:0.00分/0.96分 | step:  5360 | performance: 1.7 | accuracy: 0.37 | loss: 0.24
update:675/2000, 耗时:0.00分/0.96分 | step:  5400 | performance: 1.7 | accuracy: 0.37 | loss: 0.09
update:680/2000, 耗时:0.00分/0.97分 | step:  5440 | performance: 1.7 | accuracy: 0.37 | loss: 0.18
update:685/2000, 耗时:0.00分/0.98分 | step:  5480 | performance: 1.7 | accuracy: 0.37 | loss: 0.32
update:690/2000, 耗时:0.00分/0.99分 | step:  5520 | performance: 1.7 | accuracy: 0.37 | loss: 0.22
update:695/2000, 耗时:0.00分/0.99分 | step:  5560 | performance: 1.7 | accuracy: 0.37 | loss: 0.30
update:700/2000, 耗时:0.00分/1.00分 | step:  5600 | performance: 1.7 | accuracy: 0.37 | loss: 0.06
update:705/2000, 耗时:0.00分/1.01分 | step:  5640 | performance: 1.7 | accuracy: 0.37 | loss: 0.18
update:710/2000, 耗时:0.00分/1.02分 | step:  5680 | performance: 1.8 | accuracy: 0.37 | loss: 0.13
update:715/2000, 耗时:0.00分/1.02分 | step:  5720 | performance: 1.8 | accuracy: 0.37 | loss: 0.82
update:720/2000, 耗时:0.00分/1.03分 | step:  5760 | performance: 1.8 | accuracy: 0.37 | loss: 0.38
update:725/2000, 耗时:0.00分/1.04分 | step:  5800 | performance: 1.9 | accuracy: 0.37 | loss: 0.43
update:730/2000, 耗时:0.00分/1.04分 | step:  5840 | performance: 1.9 | accuracy: 0.38 | loss: 0.21
update:735/2000, 耗时:0.00分/1.05分 | step:  5880 | performance: 1.9 | accuracy: 0.37 | loss: 0.26
update:740/2000, 耗时:0.00分/1.06分 | step:  5920 | performance: 1.9 | accuracy: 0.37 | loss: 0.16
update:745/2000, 耗时:0.00分/1.07分 | step:  5960 | performance: 1.9 | accuracy: 0.37 | loss: 0.45
update:750/2000, 耗时:0.00分/1.07分 | step:  6000 | performance: 1.9 | accuracy: 0.37 | loss: 0.07
update:755/2000, 耗时:0.00分/1.08分 | step:  6040 | performance: 1.9 | accuracy: 0.37 | loss: 0.38
update:760/2000, 耗时:0.00分/1.09分 | step:  6080 | performance: 1.9 | accuracy: 0.37 | loss: 0.13
update:765/2000, 耗时:0.00分/1.09分 | step:  6120 | performance: 1.9 | accuracy: 0.37 | loss: 0.06
update:770/2000, 耗时:0.00分/1.10分 | step:  6160 | performance: 1.9 | accuracy: 0.37 | loss: 0.31
update:775/2000, 耗时:0.00分/1.11分 | step:  6200 | performance: 1.9 | accuracy: 0.37 | loss: 0.15
update:780/2000, 耗时:0.00分/1.11分 | step:  6240 | performance: 1.9 | accuracy: 0.37 | loss: 0.13
update:785/2000, 耗时:0.00分/1.12分 | step:  6280 | performance: 1.9 | accuracy: 0.37 | loss: 0.02
update:790/2000, 耗时:0.00分/1.13分 | step:  6320 | performance: 1.9 | accuracy: 0.37 | loss: 0.11
update:795/2000, 耗时:0.00分/1.14分 | step:  6360 | performance: 1.9 | accuracy: 0.37 | loss: 0.42
update:800/2000, 耗时:0.00分/1.14分 | step:  6400 | performance: 2.0 | accuracy: 0.37 | loss: 0.06
update:805/2000, 耗时:0.00分/1.15分 | step:  6440 | performance: 1.8 | accuracy: 0.37 | loss: 0.45
update:810/2000, 耗时:0.00分/1.16分 | step:  6480 | performance: 1.8 | accuracy: 0.37 | loss: 0.19
update:815/2000, 耗时:0.00分/1.16分 | step:  6520 | performance: 1.9 | accuracy: 0.37 | loss: 0.14
update:820/2000, 耗时:0.00分/1.17分 | step:  6560 | performance: 1.9 | accuracy: 0.37 | loss: 0.06
update:825/2000, 耗时:0.00分/1.18分 | step:  6600 | performance: 1.9 | accuracy: 0.37 | loss: 0.44
update:830/2000, 耗时:0.00分/1.19分 | step:  6640 | performance: 1.9 | accuracy: 0.37 | loss: 0.25
update:835/2000, 耗时:0.00分/1.19分 | step:  6680 | performance: 1.9 | accuracy: 0.36 | loss: 0.21
update:840/2000, 耗时:0.00分/1.20分 | step:  6720 | performance: 1.9 | accuracy: 0.36 | loss: 0.25
update:845/2000, 耗时:0.00分/1.21分 | step:  6760 | performance: 1.9 | accuracy: 0.36 | loss: -0.00
update:850/2000, 耗时:0.00分/1.21分 | step:  6800 | performance: 1.9 | accuracy: 0.36 | loss: 0.16
update:855/2000, 耗时:0.00分/1.22分 | step:  6840 | performance: 1.9 | accuracy: 0.36 | loss: 0.14
update:860/2000, 耗时:0.00分/1.23分 | step:  6880 | performance: 1.9 | accuracy: 0.36 | loss: -0.01
update:865/2000, 耗时:0.00分/1.24分 | step:  6920 | performance: 1.9 | accuracy: 0.36 | loss: 0.30
update:870/2000, 耗时:0.00分/1.24分 | step:  6960 | performance: 2.0 | accuracy: 0.36 | loss: 0.08
update:875/2000, 耗时:0.00分/1.25分 | step:  7000 | performance: 2.0 | accuracy: 0.36 | loss: 1.21
update:880/2000, 耗时:0.00分/1.26分 | step:  7040 | performance: 2.1 | accuracy: 0.36 | loss: 0.07
update:885/2000, 耗时:0.00分/1.26分 | step:  7080 | performance: 2.1 | accuracy: 0.36 | loss: 0.34
update:890/2000, 耗时:0.00分/1.27分 | step:  7120 | performance: 2.0 | accuracy: 0.35 | loss: 0.18
update:895/2000, 耗时:0.00分/1.28分 | step:  7160 | performance: 2.0 | accuracy: 0.35 | loss: 0.31
update:900/2000, 耗时:0.00分/1.29分 | step:  7200 | performance: 2.1 | accuracy: 0.35 | loss: 0.65
update:905/2000, 耗时:0.00分/1.29分 | step:  7240 | performance: 2.1 | accuracy: 0.35 | loss: 0.02
update:910/2000, 耗时:0.00分/1.30分 | step:  7280 | performance: 2.2 | accuracy: 0.35 | loss: 0.60
update:915/2000, 耗时:0.00分/1.31分 | step:  7320 | performance: 2.1 | accuracy: 0.35 | loss: 0.19
update:920/2000, 耗时:0.00分/1.31分 | step:  7360 | performance: 2.2 | accuracy: 0.35 | loss: 0.42
update:925/2000, 耗时:0.00分/1.32分 | step:  7400 | performance: 2.2 | accuracy: 0.35 | loss: 0.12
update:930/2000, 耗时:0.00分/1.33分 | step:  7440 | performance: 2.2 | accuracy: 0.35 | loss: -0.00
update:935/2000, 耗时:0.00分/1.34分 | step:  7480 | performance: 2.2 | accuracy: 0.35 | loss: -0.00
update:940/2000, 耗时:0.00分/1.34分 | step:  7520 | performance: 2.2 | accuracy: 0.35 | loss: 0.08
update:945/2000, 耗时:0.00分/1.35分 | step:  7560 | performance: 2.3 | accuracy: 0.35 | loss: 0.39
update:950/2000, 耗时:0.00分/1.36分 | step:  7600 | performance: 2.3 | accuracy: 0.35 | loss: 0.04
update:955/2000, 耗时:0.00分/1.37分 | step:  7640 | performance: 2.4 | accuracy: 0.35 | loss: 1.00
update:960/2000, 耗时:0.00分/1.37分 | step:  7680 | performance: 2.4 | accuracy: 0.36 | loss: 0.28
update:965/2000, 耗时:0.00分/1.38分 | step:  7720 | performance: 2.3 | accuracy: 0.36 | loss: 0.81
update:970/2000, 耗时:0.00分/1.39分 | step:  7760 | performance: 2.1 | accuracy: 0.36 | loss: 0.08
update:975/2000, 耗时:0.00分/1.40分 | step:  7800 | performance: 2.1 | accuracy: 0.36 | loss: 0.05
update:980/2000, 耗时:0.00分/1.40分 | step:  7840 | performance: 2.3 | accuracy: 0.36 | loss: 0.51
update:985/2000, 耗时:0.00分/1.41分 | step:  7880 | performance: 2.1 | accuracy: 0.36 | loss: 0.22
update:990/2000, 耗时:0.00分/1.42分 | step:  7920 | performance: 2.2 | accuracy: 0.36 | loss: 0.58
update:995/2000, 耗时:0.00分/1.42分 | step:  7960 | performance: 2.4 | accuracy: 0.36 | loss: 0.56
update:1000/2000, 耗时:0.00分/1.43分 | step:  8000 | performance: 2.6 | accuracy: 0.36 | loss: -0.00
update:1005/2000, 耗时:0.00分/1.44分 | step:  8040 | performance: 2.6 | accuracy: 0.36 | loss: 0.23
update:1010/2000, 耗时:0.00分/1.45分 | step:  8080 | performance: 2.7 | accuracy: 0.36 | loss: 0.41
update:1015/2000, 耗时:0.00分/1.45分 | step:  8120 | performance: 2.8 | accuracy: 0.36 | loss: 0.51
update:1020/2000, 耗时:0.00分/1.46分 | step:  8160 | performance: 2.8 | accuracy: 0.36 | loss: 0.23
update:1025/2000, 耗时:0.00分/1.47分 | step:  8200 | performance: 2.8 | accuracy: 0.36 | loss: -0.01
update:1030/2000, 耗时:0.00分/1.48分 | step:  8240 | performance: 2.8 | accuracy: 0.36 | loss: 0.06
update:1035/2000, 耗时:0.00分/1.48分 | step:  8280 | performance: 3.0 | accuracy: 0.36 | loss: 0.01
update:1040/2000, 耗时:0.00分/1.49分 | step:  8320 | performance: 3.0 | accuracy: 0.36 | loss: 0.17
update:1045/2000, 耗时:0.00分/1.50分 | step:  8360 | performance: 2.9 | accuracy: 0.36 | loss: 0.41
update:1050/2000, 耗时:0.00分/1.51分 | step:  8400 | performance: 3.0 | accuracy: 0.36 | loss: 0.27
update:1055/2000, 耗时:0.00分/1.51分 | step:  8440 | performance: 3.1 | accuracy: 0.36 | loss: 0.54
update:1060/2000, 耗时:0.00分/1.52分 | step:  8480 | performance: 3.1 | accuracy: 0.36 | loss: 0.38
update:1065/2000, 耗时:0.00分/1.53分 | step:  8520 | performance: 3.1 | accuracy: 0.35 | loss: 0.20
update:1070/2000, 耗时:0.00分/1.54分 | step:  8560 | performance: 3.1 | accuracy: 0.35 | loss: 0.23
update:1075/2000, 耗时:0.00分/1.54分 | step:  8600 | performance: 3.2 | accuracy: 0.35 | loss: 0.12
update:1080/2000, 耗时:0.00分/1.55分 | step:  8640 | performance: 3.2 | accuracy: 0.35 | loss: 0.13
update:1085/2000, 耗时:0.00分/1.56分 | step:  8680 | performance: 3.3 | accuracy: 0.35 | loss: 0.08
update:1090/2000, 耗时:0.00分/1.56分 | step:  8720 | performance: 3.1 | accuracy: 0.35 | loss: 0.26
update:1095/2000, 耗时:0.00分/1.57分 | step:  8760 | performance: 3.1 | accuracy: 0.35 | loss: 0.23
update:1100/2000, 耗时:0.00分/1.58分 | step:  8800 | performance: 3.1 | accuracy: 0.35 | loss: 0.37
update:1105/2000, 耗时:0.00分/1.58分 | step:  8840 | performance: 3.2 | accuracy: 0.35 | loss: 0.18
update:1110/2000, 耗时:0.00分/1.59分 | step:  8880 | performance: 3.1 | accuracy: 0.35 | loss: 0.29
update:1115/2000, 耗时:0.00分/1.60分 | step:  8920 | performance: 3.1 | accuracy: 0.35 | loss: 0.05
update:1120/2000, 耗时:0.00分/1.61分 | step:  8960 | performance: 3.0 | accuracy: 0.35 | loss: 0.06
update:1125/2000, 耗时:0.00分/1.61分 | step:  9000 | performance: 3.2 | accuracy: 0.35 | loss: 0.51
update:1130/2000, 耗时:0.00分/1.62分 | step:  9040 | performance: 3.2 | accuracy: 0.35 | loss: 0.18
update:1135/2000, 耗时:0.00分/1.63分 | step:  9080 | performance: 2.9 | accuracy: 0.35 | loss: 0.04
update:1140/2000, 耗时:0.00分/1.64分 | step:  9120 | performance: 2.8 | accuracy: 0.35 | loss: 0.41
update:1145/2000, 耗时:0.00分/1.64分 | step:  9160 | performance: 2.9 | accuracy: 0.35 | loss: 0.30
update:1150/2000, 耗时:0.00分/1.65分 | step:  9200 | performance: 2.8 | accuracy: 0.35 | loss: -0.01
update:1155/2000, 耗时:0.00分/1.66分 | step:  9240 | performance: 2.8 | accuracy: 0.35 | loss: 0.20
update:1160/2000, 耗时:0.00分/1.66分 | step:  9280 | performance: 2.9 | accuracy: 0.35 | loss: 0.54
update:1165/2000, 耗时:0.00分/1.67分 | step:  9320 | performance: 2.9 | accuracy: 0.35 | loss: 0.05
update:1170/2000, 耗时:0.00分/1.68分 | step:  9360 | performance: 2.7 | accuracy: 0.35 | loss: 0.31
update:1175/2000, 耗时:0.00分/1.69分 | step:  9400 | performance: 2.7 | accuracy: 0.35 | loss: 0.22
update:1180/2000, 耗时:0.00分/1.69分 | step:  9440 | performance: 2.8 | accuracy: 0.35 | loss: 0.23
update:1185/2000, 耗时:0.00分/1.70分 | step:  9480 | performance: 2.8 | accuracy: 0.35 | loss: 0.34
update:1190/2000, 耗时:0.00分/1.71分 | step:  9520 | performance: 2.8 | accuracy: 0.35 | loss: 0.23
update:1195/2000, 耗时:0.00分/1.71分 | step:  9560 | performance: 2.6 | accuracy: 0.35 | loss: 0.58
update:1200/2000, 耗时:0.00分/1.72分 | step:  9600 | performance: 2.8 | accuracy: 0.35 | loss: 0.62
update:1205/2000, 耗时:0.00分/1.73分 | step:  9640 | performance: 2.9 | accuracy: 0.35 | loss: 0.17
update:1210/2000, 耗时:0.00分/1.74分 | step:  9680 | performance: 2.8 | accuracy: 0.35 | loss: 0.34
update:1215/2000, 耗时:0.00分/1.74分 | step:  9720 | performance: 2.8 | accuracy: 0.35 | loss: 0.39
update:1220/2000, 耗时:0.00分/1.75分 | step:  9760 | performance: 2.9 | accuracy: 0.35 | loss: 0.31
update:1225/2000, 耗时:0.00分/1.76分 | step:  9800 | performance: 2.8 | accuracy: 0.35 | loss: 0.30
update:1230/2000, 耗时:0.00分/1.77分 | step:  9840 | performance: 2.8 | accuracy: 0.35 | loss: 0.33
update:1235/2000, 耗时:0.00分/1.77分 | step:  9880 | performance: 2.8 | accuracy: 0.35 | loss: 0.11
update:1240/2000, 耗时:0.00分/1.78分 | step:  9920 | performance: 2.8 | accuracy: 0.35 | loss: 0.27
update:1245/2000, 耗时:0.00分/1.79分 | step:  9960 | performance: 2.8 | accuracy: 0.35 | loss: 0.06
update:1250/2000, 耗时:0.00分/1.79分 | step: 10000 | performance: 2.8 | accuracy: 0.35 | loss: -0.00
update:1255/2000, 耗时:0.00分/1.80分 | step: 10040 | performance: 2.7 | accuracy: 0.34 | loss: 0.14
update:1260/2000, 耗时:0.00分/1.81分 | step: 10080 | performance: 2.7 | accuracy: 0.34 | loss: 0.10
update:1265/2000, 耗时:0.00分/1.82分 | step: 10120 | performance: 2.7 | accuracy: 0.34 | loss: 0.05
update:1270/2000, 耗时:0.00分/1.82分 | step: 10160 | performance: 2.7 | accuracy: 0.34 | loss: -0.01
update:1275/2000, 耗时:0.00分/1.83分 | step: 10200 | performance: 2.7 | accuracy: 0.34 | loss: 0.24
update:1280/2000, 耗时:0.00分/1.84分 | step: 10240 | performance: 2.7 | accuracy: 0.34 | loss: -0.00
update:1285/2000, 耗时:0.00分/1.85分 | step: 10280 | performance: 2.7 | accuracy: 0.34 | loss: 0.10
update:1290/2000, 耗时:0.00分/1.85分 | step: 10320 | performance: 2.6 | accuracy: 0.34 | loss: 0.17
update:1295/2000, 耗时:0.00分/1.86分 | step: 10360 | performance: 2.6 | accuracy: 0.34 | loss: 0.06
update:1300/2000, 耗时:0.00分/1.87分 | step: 10400 | performance: 2.6 | accuracy: 0.34 | loss: -0.00
update:1305/2000, 耗时:0.00分/1.88分 | step: 10440 | performance: 2.5 | accuracy: 0.34 | loss: 0.54
update:1310/2000, 耗时:0.00分/1.88分 | step: 10480 | performance: 2.5 | accuracy: 0.34 | loss: 0.06
update:1315/2000, 耗时:0.00分/1.89分 | step: 10520 | performance: 2.6 | accuracy: 0.34 | loss: 0.11
update:1320/2000, 耗时:0.00分/1.90分 | step: 10560 | performance: 2.5 | accuracy: 0.34 | loss: 0.17
update:1325/2000, 耗时:0.00分/1.90分 | step: 10600 | performance: 2.5 | accuracy: 0.34 | loss: 0.09
update:1330/2000, 耗时:0.00分/1.91分 | step: 10640 | performance: 2.5 | accuracy: 0.34 | loss: 0.21
update:1335/2000, 耗时:0.00分/1.92分 | step: 10680 | performance: 2.5 | accuracy: 0.34 | loss: 0.09
update:1340/2000, 耗时:0.00分/1.93分 | step: 10720 | performance: 2.5 | accuracy: 0.34 | loss: 0.07
update:1345/2000, 耗时:0.00分/1.93分 | step: 10760 | performance: 2.7 | accuracy: 0.34 | loss: 0.22
update:1350/2000, 耗时:0.00分/1.94分 | step: 10800 | performance: 2.7 | accuracy: 0.34 | loss: 0.36
update:1355/2000, 耗时:0.00分/1.95分 | step: 10840 | performance: 2.6 | accuracy: 0.34 | loss: 0.14
update:1360/2000, 耗时:0.00分/1.95分 | step: 10880 | performance: 2.7 | accuracy: 0.34 | loss: 0.08
update:1365/2000, 耗时:0.00分/1.96分 | step: 10920 | performance: 2.7 | accuracy: 0.34 | loss: 0.17
update:1370/2000, 耗时:0.00分/1.97分 | step: 10960 | performance: 2.6 | accuracy: 0.34 | loss: 0.40
update:1375/2000, 耗时:0.00分/1.98分 | step: 11000 | performance: 2.7 | accuracy: 0.34 | loss: 0.49
update:1380/2000, 耗时:0.00分/1.98分 | step: 11040 | performance: 2.7 | accuracy: 0.34 | loss: 0.18
update:1385/2000, 耗时:0.00分/1.99分 | step: 11080 | performance: 2.7 | accuracy: 0.34 | loss: 0.05
update:1390/2000, 耗时:0.00分/2.00分 | step: 11120 | performance: 2.7 | accuracy: 0.34 | loss: 0.05
update:1395/2000, 耗时:0.00分/2.00分 | step: 11160 | performance: 2.7 | accuracy: 0.34 | loss: 0.09
update:1400/2000, 耗时:0.00分/2.01分 | step: 11200 | performance: 2.7 | accuracy: 0.34 | loss: 0.23
update:1405/2000, 耗时:0.00分/2.02分 | step: 11240 | performance: 2.7 | accuracy: 0.34 | loss: 0.12
update:1410/2000, 耗时:0.00分/2.03分 | step: 11280 | performance: 2.7 | accuracy: 0.34 | loss: 0.07
update:1415/2000, 耗时:0.00分/2.03分 | step: 11320 | performance: 2.9 | accuracy: 0.34 | loss: 0.19
update:1420/2000, 耗时:0.00分/2.04分 | step: 11360 | performance: 2.9 | accuracy: 0.34 | loss: 0.23
update:1425/2000, 耗时:0.00分/2.05分 | step: 11400 | performance: 2.8 | accuracy: 0.34 | loss: 0.70
update:1430/2000, 耗时:0.00分/2.05分 | step: 11440 | performance: 3.0 | accuracy: 0.34 | loss: 0.00
update:1435/2000, 耗时:0.00分/2.06分 | step: 11480 | performance: 2.9 | accuracy: 0.34 | loss: 0.35
update:1440/2000, 耗时:0.00分/2.07分 | step: 11520 | performance: 3.0 | accuracy: 0.34 | loss: 0.30
update:1445/2000, 耗时:0.00分/2.08分 | step: 11560 | performance: 3.0 | accuracy: 0.34 | loss: 0.23
update:1450/2000, 耗时:0.00分/2.08分 | step: 11600 | performance: 2.9 | accuracy: 0.34 | loss: 0.23
update:1455/2000, 耗时:0.00分/2.09分 | step: 11640 | performance: 2.7 | accuracy: 0.34 | loss: 0.26
update:1460/2000, 耗时:0.00分/2.10分 | step: 11680 | performance: 2.7 | accuracy: 0.34 | loss: 0.05
update:1465/2000, 耗时:0.00分/2.11分 | step: 11720 | performance: 2.7 | accuracy: 0.34 | loss: 0.26
update:1470/2000, 耗时:0.00分/2.11分 | step: 11760 | performance: 2.5 | accuracy: 0.34 | loss: 0.21
update:1475/2000, 耗时:0.00分/2.12分 | step: 11800 | performance: 3.8 | accuracy: 0.34 | loss: 1.79
update:1480/2000, 耗时:0.00分/2.13分 | step: 11840 | performance: 4.1 | accuracy: 0.34 | loss: 0.34
update:1485/2000, 耗时:0.00分/2.14分 | step: 11880 | performance: 4.7 | accuracy: 0.34 | loss: 0.48
update:1490/2000, 耗时:0.00分/2.14分 | step: 11920 | performance: 5.1 | accuracy: 0.34 | loss: 0.51
update:1495/2000, 耗时:0.00分/2.15分 | step: 11960 | performance: 4.8 | accuracy: 0.34 | loss: 0.01
update:1500/2000, 耗时:0.00分/2.16分 | step: 12000 | performance: 4.9 | accuracy: 0.34 | loss: 0.38
update:1505/2000, 耗时:0.00分/2.16分 | step: 12040 | performance: 4.7 | accuracy: 0.34 | loss: 0.30
update:1510/2000, 耗时:0.00分/2.17分 | step: 12080 | performance: 4.3 | accuracy: 0.34 | loss: 0.31
update:1515/2000, 耗时:0.00分/2.18分 | step: 12120 | performance: 4.3 | accuracy: 0.34 | loss: 0.17
update:1520/2000, 耗时:0.00分/2.18分 | step: 12160 | performance: 4.4 | accuracy: 0.34 | loss: 0.48
update:1525/2000, 耗时:0.00分/2.19分 | step: 12200 | performance: 4.6 | accuracy: 0.34 | loss: 0.10
update:1530/2000, 耗时:0.00分/2.20分 | step: 12240 | performance: 4.6 | accuracy: 0.34 | loss: 0.26
update:1535/2000, 耗时:0.00分/2.21分 | step: 12280 | performance: 4.5 | accuracy: 0.34 | loss: 0.28
update:1540/2000, 耗时:0.00分/2.21分 | step: 12320 | performance: 4.4 | accuracy: 0.34 | loss: 0.17
update:1545/2000, 耗时:0.00分/2.22分 | step: 12360 | performance: 4.4 | accuracy: 0.34 | loss: 0.21
update:1550/2000, 耗时:0.00分/2.23分 | step: 12400 | performance: 4.4 | accuracy: 0.34 | loss: 0.13
update:1555/2000, 耗时:0.00分/2.24分 | step: 12440 | performance: 4.4 | accuracy: 0.34 | loss: 0.20
update:1560/2000, 耗时:0.00分/2.24分 | step: 12480 | performance: 4.6 | accuracy: 0.34 | loss: 0.11
update:1565/2000, 耗时:0.00分/2.25分 | step: 12520 | performance: 4.7 | accuracy: 0.34 | loss: 0.16
update:1570/2000, 耗时:0.00分/2.26分 | step: 12560 | performance: 5.3 | accuracy: 0.34 | loss: 0.75
update:1575/2000, 耗时:0.00分/2.26分 | step: 12600 | performance: 5.5 | accuracy: 0.34 | loss: 0.00
update:1580/2000, 耗时:0.00分/2.27分 | step: 12640 | performance: 5.4 | accuracy: 0.34 | loss: 0.44
update:1585/2000, 耗时:0.00分/2.28分 | step: 12680 | performance: 5.6 | accuracy: 0.34 | loss: 0.31
update:1590/2000, 耗时:0.00分/2.29分 | step: 12720 | performance: 5.4 | accuracy: 0.34 | loss: 0.50
update:1595/2000, 耗时:0.00分/2.29分 | step: 12760 | performance: 5.4 | accuracy: 0.34 | loss: 0.12
update:1600/2000, 耗时:0.00分/2.30分 | step: 12800 | performance: 5.7 | accuracy: 0.34 | loss: 0.26
update:1605/2000, 耗时:0.00分/2.31分 | step: 12840 | performance: 5.7 | accuracy: 0.34 | loss: 0.23
update:1610/2000, 耗时:0.00分/2.31分 | step: 12880 | performance: 5.7 | accuracy: 0.34 | loss: 0.19
update:1615/2000, 耗时:0.00分/2.32分 | step: 12920 | performance: 5.3 | accuracy: 0.34 | loss: 0.27
update:1620/2000, 耗时:0.00分/2.33分 | step: 12960 | performance: 5.6 | accuracy: 0.34 | loss: 0.46
update:1625/2000, 耗时:0.00分/2.34分 | step: 13000 | performance: 5.6 | accuracy: 0.34 | loss: 0.36
update:1630/2000, 耗时:0.00分/2.34分 | step: 13040 | performance: 5.4 | accuracy: 0.34 | loss: 0.05
update:1635/2000, 耗时:0.00分/2.35分 | step: 13080 | performance: 5.5 | accuracy: 0.34 | loss: 0.26
update:1640/2000, 耗时:0.00分/2.36分 | step: 13120 | performance: 5.5 | accuracy: 0.34 | loss: 0.28
update:1645/2000, 耗时:0.00分/2.37分 | step: 13160 | performance: 5.5 | accuracy: 0.34 | loss: 0.44
update:1650/2000, 耗时:0.00分/2.37分 | step: 13200 | performance: 5.5 | accuracy: 0.34 | loss: 0.45
update:1655/2000, 耗时:0.00分/2.38分 | step: 13240 | performance: 5.4 | accuracy: 0.34 | loss: 0.38
update:1660/2000, 耗时:0.00分/2.39分 | step: 13280 | performance: 5.4 | accuracy: 0.34 | loss: 0.29
update:1665/2000, 耗时:0.00分/2.39分 | step: 13320 | performance: 5.6 | accuracy: 0.34 | loss: 0.50
update:1670/2000, 耗时:0.00分/2.40分 | step: 13360 | performance: 5.6 | accuracy: 0.34 | loss: 0.18
update:1675/2000, 耗时:0.00分/2.41分 | step: 13400 | performance: 5.6 | accuracy: 0.34 | loss: 0.26
update:1680/2000, 耗时:0.00分/2.41分 | step: 13440 | performance: 5.5 | accuracy: 0.34 | loss: 0.31
update:1685/2000, 耗时:0.00分/2.42分 | step: 13480 | performance: 5.4 | accuracy: 0.34 | loss: 0.36
update:1690/2000, 耗时:0.00分/2.43分 | step: 13520 | performance: 5.5 | accuracy: 0.34 | loss: 0.34
update:1695/2000, 耗时:0.00分/2.44分 | step: 13560 | performance: 5.5 | accuracy: 0.34 | loss: 0.27
update:1700/2000, 耗时:0.00分/2.44分 | step: 13600 | performance: 5.5 | accuracy: 0.33 | loss: 0.37
update:1705/2000, 耗时:0.00分/2.45分 | step: 13640 | performance: 5.4 | accuracy: 0.33 | loss: 0.41
update:1710/2000, 耗时:0.00分/2.46分 | step: 13680 | performance: 5.4 | accuracy: 0.33 | loss: 0.13
update:1715/2000, 耗时:0.00分/2.46分 | step: 13720 | performance: 5.6 | accuracy: 0.33 | loss: 0.32
update:1720/2000, 耗时:0.00分/2.47分 | step: 13760 | performance: 5.5 | accuracy: 0.33 | loss: 0.32
update:1725/2000, 耗时:0.00分/2.48分 | step: 13800 | performance: 5.5 | accuracy: 0.33 | loss: 0.33
update:1730/2000, 耗时:0.00分/2.48分 | step: 13840 | performance: 5.5 | accuracy: 0.33 | loss: 0.12
update:1735/2000, 耗时:0.00分/2.49分 | step: 13880 | performance: 5.6 | accuracy: 0.33 | loss: 0.29
update:1740/2000, 耗时:0.00分/2.50分 | step: 13920 | performance: 5.6 | accuracy: 0.33 | loss: 0.13
update:1745/2000, 耗时:0.00分/2.51分 | step: 13960 | performance: 5.5 | accuracy: 0.33 | loss: 0.28
update:1750/2000, 耗时:0.00分/2.51分 | step: 14000 | performance: 6.1 | accuracy: 0.33 | loss: 0.04
update:1755/2000, 耗时:0.00分/2.52分 | step: 14040 | performance: 6.2 | accuracy: 0.33 | loss: 0.11
update:1760/2000, 耗时:0.00分/2.53分 | step: 14080 | performance: 6.5 | accuracy: 0.33 | loss: 0.21
update:1765/2000, 耗时:0.00分/2.53分 | step: 14120 | performance: 6.5 | accuracy: 0.33 | loss: 0.10
update:1770/2000, 耗时:0.00分/2.54分 | step: 14160 | performance: 6.5 | accuracy: 0.33 | loss: 0.22
update:1775/2000, 耗时:0.00分/2.55分 | step: 14200 | performance: 6.4 | accuracy: 0.33 | loss: 0.24
update:1780/2000, 耗时:0.00分/2.55分 | step: 14240 | performance: 6.2 | accuracy: 0.33 | loss: 0.32
update:1785/2000, 耗时:0.00分/2.56分 | step: 14280 | performance: 6.1 | accuracy: 0.33 | loss: 0.34
update:1790/2000, 耗时:0.00分/2.57分 | step: 14320 | performance: 6.1 | accuracy: 0.33 | loss: 0.13
update:1795/2000, 耗时:0.00分/2.57分 | step: 14360 | performance: 6.0 | accuracy: 0.33 | loss: 0.12
update:1800/2000, 耗时:0.00分/2.58分 | step: 14400 | performance: 6.0 | accuracy: 0.33 | loss: 0.25
update:1805/2000, 耗时:0.00分/2.59分 | step: 14440 | performance: 5.9 | accuracy: 0.33 | loss: 0.05
update:1810/2000, 耗时:0.00分/2.60分 | step: 14480 | performance: 5.8 | accuracy: 0.33 | loss: 0.14
update:1815/2000, 耗时:0.00分/2.60分 | step: 14520 | performance: 5.8 | accuracy: 0.33 | loss: 0.11
update:1820/2000, 耗时:0.00分/2.61分 | step: 14560 | performance: 5.9 | accuracy: 0.33 | loss: 0.05
update:1825/2000, 耗时:0.00分/2.62分 | step: 14600 | performance: 5.8 | accuracy: 0.33 | loss: 0.26
update:1830/2000, 耗时:0.00分/2.62分 | step: 14640 | performance: 5.8 | accuracy: 0.33 | loss: 0.30
update:1835/2000, 耗时:0.00分/2.63分 | step: 14680 | performance: 5.7 | accuracy: 0.33 | loss: 0.44
update:1840/2000, 耗时:0.00分/2.64分 | step: 14720 | performance: 5.7 | accuracy: 0.33 | loss: 0.14
update:1845/2000, 耗时:0.00分/2.65分 | step: 14760 | performance: 5.7 | accuracy: 0.33 | loss: 0.08
update:1850/2000, 耗时:0.00分/2.65分 | step: 14800 | performance: 5.8 | accuracy: 0.33 | loss: 0.18
update:1855/2000, 耗时:0.00分/2.66分 | step: 14840 | performance: 5.7 | accuracy: 0.33 | loss: 0.14
update:1860/2000, 耗时:0.00分/2.67分 | step: 14880 | performance: 5.9 | accuracy: 0.33 | loss: 0.06
update:1865/2000, 耗时:0.00分/2.67分 | step: 14920 | performance: 5.8 | accuracy: 0.32 | loss: 0.29
update:1870/2000, 耗时:0.00分/2.68分 | step: 14960 | performance: 6.0 | accuracy: 0.33 | loss: -0.00
update:1875/2000, 耗时:0.00分/2.69分 | step: 15000 | performance: 6.0 | accuracy: 0.32 | loss: 0.07
update:1880/2000, 耗时:0.00分/2.69分 | step: 15040 | performance: 6.0 | accuracy: 0.32 | loss: 0.08
update:1885/2000, 耗时:0.00分/2.70分 | step: 15080 | performance: 6.1 | accuracy: 0.32 | loss: 0.00
update:1890/2000, 耗时:0.00分/2.70分 | step: 15120 | performance: 6.1 | accuracy: 0.32 | loss: 0.05
update:1895/2000, 耗时:0.00分/2.71分 | step: 15160 | performance: 6.2 | accuracy: 0.32 | loss: 0.21
update:1900/2000, 耗时:0.00分/2.72分 | step: 15200 | performance: 6.2 | accuracy: 0.32 | loss: 0.40
update:1905/2000, 耗时:0.00分/2.72分 | step: 15240 | performance: 6.2 | accuracy: 0.32 | loss: 0.12
update:1910/2000, 耗时:0.00分/2.73分 | step: 15280 | performance: 6.4 | accuracy: 0.32 | loss: -0.00
update:1915/2000, 耗时:0.00分/2.74分 | step: 15320 | performance: 6.3 | accuracy: 0.32 | loss: 0.11
update:1920/2000, 耗时:0.00分/2.74分 | step: 15360 | performance: 6.4 | accuracy: 0.32 | loss: 0.33
update:1925/2000, 耗时:0.00分/2.75分 | step: 15400 | performance: 6.4 | accuracy: 0.32 | loss: 0.00
update:1930/2000, 耗时:0.00分/2.76分 | step: 15440 | performance: 6.4 | accuracy: 0.32 | loss: 0.46
update:1935/2000, 耗时:0.00分/2.76分 | step: 15480 | performance: 6.3 | accuracy: 0.32 | loss: 0.67
update:1940/2000, 耗时:0.00分/2.77分 | step: 15520 | performance: 6.3 | accuracy: 0.32 | loss: 0.37
update:1945/2000, 耗时:0.00分/2.78分 | step: 15560 | performance: 6.1 | accuracy: 0.32 | loss: 0.28
update:1950/2000, 耗时:0.00分/2.78分 | step: 15600 | performance: 6.2 | accuracy: 0.32 | loss: 0.59
update:1955/2000, 耗时:0.00分/2.79分 | step: 15640 | performance: 6.1 | accuracy: 0.32 | loss: 0.18
update:1960/2000, 耗时:0.00分/2.80分 | step: 15680 | performance: 6.3 | accuracy: 0.32 | loss: 0.31
update:1965/2000, 耗时:0.00分/2.81分 | step: 15720 | performance: 6.1 | accuracy: 0.32 | loss: 0.41
update:1970/2000, 耗时:0.00分/2.81分 | step: 15760 | performance: 6.1 | accuracy: 0.32 | loss: 0.18
update:1975/2000, 耗时:0.00分/2.82分 | step: 15800 | performance: 6.2 | accuracy: 0.32 | loss: 0.45
update:1980/2000, 耗时:0.00分/2.83分 | step: 15840 | performance: 6.2 | accuracy: 0.32 | loss: 0.05
update:1985/2000, 耗时:0.00分/2.83分 | step: 15880 | performance: 6.2 | accuracy: 0.32 | loss: 0.30
update:1990/2000, 耗时:0.00分/2.84分 | step: 15920 | performance: 6.0 | accuracy: 0.32 | loss: 0.42
update:1995/2000, 耗时:0.00分/2.85分 | step: 15960 | performance: 5.3 | accuracy: 0.32 | loss: 0.10
update:2000/2000, 耗时:0.00分/2.85分 | step: 16000 | performance: 5.1 | accuracy: 0.32 | loss: 0.12
----------------------------------------finished----------------------------------------
  0%|          | 0/406 [00:00<?, ?it/s]==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
100%|| 406/406 [00:00<00:00, 55079.32it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1450.47
2023-07-24T12:00:00 | net performance [%] = 45.0466
2023-07-24T12:00:00 | number of trades [#] = 38
==================================================
Trial 27 Complete [00h 03m 17s]
net_wealth: 1451.9177508174423

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 03h 45m 53s

Search: Running Trial #28

Value             |Best Value So Far |Hyperparameter
4                 |1                 |horizon
225               |730               |lookback
True              |False             |MarketFactor
14                |3                 |lags
0.92              |0.92              |gamma
32                |32                |batch_size
7                 |1                 |n_step
0.94              |0.94              |gae_lambda
5                 |5                 |gradient_clip_norm
5                 |5                 |epochs
0.0005            |0.0001            |actor_lr
0.0005            |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4297.000000   4301.000000
mean      0.000435    20113.607657  ...   20184.134484  20169.373185
std       0.027833    16040.642334  ...   16078.780856  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7747.959961   7730.930176
50%       0.000642    11571.842969  ...   11755.309570  11751.469727
75%       0.011590    29894.706152  ...   30016.300781  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 01:49:17.117891: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binar22023-07023-07-28 01:49:17.117941: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (one2023-07-28 01:49:2y is optimized wDNN) toi-t28 h  u107osneAPI Deep Neur.a1le  1N1thee followint:wo49rg8:107.k Li1191 b: 7CIPU ir 947nas: I tenstoensortrucrtio0rfl23-07-28 0n1s:49:17oyw /( oneDNcN) in poto uerese tr/phe flafolorlomtwingan CPU inscet-rcfuctr.11l8ions in performaofnw028: I /ctoroeen2/sri0oti23-07-28 01cral oper:aftlip4l9o:atm/foro1m7.c11w/8c/cpu_fe202ao3-ceprns:tur eu_featu-07c/rp AVr-latf28X AVXiot2
To 0i1c2ael 02e_gua3:49:r-d op07-_1genable2 te.rations:  A3rccmu9a/78: cV.Xr dI Ahp1eVt1Xmu:e8ns4o_r 1feat8 0.c1cuf::42]1l4ow9: 4/T2rc1ore/]his7e_ pTh.is2118
gTo4 Tuea lTensina6 orerdt .forocFcn5am: bn/lcp:u_efso1r4F lethIeom attuenw2 tihn eroter sh_binar oelguar]o d.rTfhopr ope87: Ii sc Teylencw  ow/cribsinaste:t arns142i]o yration sooTonpo, reithis Tens, srifloowrbu/ilemirdebu/corFirF rleplzlo/latdsw bi foTeonwp oplabrread inys w Tensntiisthoafroyr mi/sctm  rpFul_ofoop/ticmpin imozue_ifweoatptiz rwFuermeiilowe wizatdd  wweAuPreiedtti_tghu ahr dtt_hhg  hw eI aouat.cnirhd .pperAePc aDeethp popc orneA:1cporpiraitaetN:I De1 4ecP4Ip 2]2]  Neo cDe eeuuraomprmapleTohnli lNeie pN eThsAiPNei elre sttwwr  Teork LfTluaroralnegIs .fkla iD
 LibrnbrgsNaertwork eseaopryLs.r yN
Floibrar y( e w( u(onoeobrDnneeDNiNDNN) NaN)t)loo  r ttoo usn  eN tetauFwlohre sue rthosw yeke Li bir f the follbfaorllioosowyllowwin gna(ri  yongo pist Cni opteniCPiUDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other opemPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
rations, rebuild TensorFlow wigm i instructions in performancth the appropriateCPU instructions in performance-critical operationze-critical operasized with oneAPI Deep Neural Netwoed with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critica:  AVX AVX2
To enable them in other opertiationrk comons:  As lV Xp, rebuild TensorFlow with the appropriatLo AVX2
To enableiperi ler flags.
tbraray (ohe comneemtpiler flags.
DNN) to use the following CPU instruc in other oiperaons: tions itions,  AVrX AebuVild TeX2
To enable them in other opnsorFlow with the appropriatee compiler flags.
rations, rebuild TensorFlnow with the appro priate compiler flags.
performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 01:49:17.699782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:49:17.721822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:49:17.731318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:49:17.736837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:49:17.739428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:49:17.743847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:49:17.750037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:49:17.753014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   280 | performance: 3.5 | accuracy: 0.57 | loss: 13.36
update: 10/2000, 耗时:0.00分/0.05分 | step:   560 | performance: 7.5 | accuracy: 0.53 | loss: 2.02
update: 15/2000, 耗时:0.00分/0.06分 | step:   840 | performance: 4.7 | accuracy: 0.42 | loss: 5.59
update: 20/2000, 耗时:0.00分/0.08分 | step:  1120 | performance: 4.5 | accuracy: 0.41 | loss: 1.44
update: 25/2000, 耗时:0.00分/0.09分 | step:  1400 | performance: 7.1 | accuracy: 0.41 | loss: 2.98
update: 30/2000, 耗时:0.00分/0.11分 | step:  1680 | performance: 6.8 | accuracy: 0.37 | loss: 0.89
update: 35/2000, 耗时:0.00分/0.12分 | step:  1960 | performance: 7.6 | accuracy: 0.37 | loss: 1.44
update: 40/2000, 耗时:0.00分/0.14分 | step:  2240 | performance: 4.5 | accuracy: 0.34 | loss: 3.29
update: 45/2000, 耗时:0.00分/0.15分 | step:  2520 | performance: 4.6 | accuracy: 0.32 | loss: 0.44
update: 50/2000, 耗时:0.00分/0.17分 | step:  2800 | performance: 4.3 | accuracy: 0.31 | loss: 0.46
update: 55/2000, 耗时:0.00分/0.19分 | step:  3080 | performance: 4.7 | accuracy: 0.32 | loss: 0.57
update: 60/2000, 耗时:0.00分/0.20分 | step:  3360 | performance: 3.5 | accuracy: 0.31 | loss: 0.91
update: 65/2000, 耗时:0.00分/0.22分 | step:  3640 | performance: 6.4 | accuracy: 0.33 | loss: 1.36
update: 70/2000, 耗时:0.00分/0.24分 | step:  3920 | performance: 8.0 | accuracy: 0.33 | loss: 2.19
update: 75/2000, 耗时:0.00分/0.25分 | step:  4200 | performance: 8.5 | accuracy: 0.33 | loss: 0.75
update: 80/2000, 耗时:0.00分/0.27分 | step:  4480 | performance: 7.2 | accuracy: 0.31 | loss: 0.71
update: 85/2000, 耗时:0.00分/0.29分 | step:  4760 | performance: 7.1 | accuracy: 0.30 | loss: 0.35
update: 90/2000, 耗时:0.00分/0.30分 | step:  5040 | performance: 7.2 | accuracy: 0.29 | loss: 0.02
update: 95/2000, 耗时:0.00分/0.32分 | step:  5320 | performance: 7.7 | accuracy: 0.28 | loss: 0.05
update:100/2000, 耗时:0.00分/0.34分 | step:  5600 | performance: 7.7 | accuracy: 0.26 | loss: 0.07
update:105/2000, 耗时:0.00分/0.35分 | step:  5880 | performance: 7.1 | accuracy: 0.26 | loss: 0.74
update:110/2000, 耗时:0.00分/0.37分 | step:  6160 | performance: 7.1 | accuracy: 0.26 | loss: 0.42
update:115/2000, 耗时:0.00分/0.39分 | step:  6440 | performance: 7.5 | accuracy: 0.26 | loss: 0.32
update:120/2000, 耗时:0.00分/0.40分 | step:  6720 | performance: 8.2 | accuracy: 0.26 | loss: 0.33
update:125/2000, 耗时:0.00分/0.42分 | step:  7000 | performance: 6.9 | accuracy: 0.25 | loss: 0.22
update:130/2000, 耗时:0.00分/0.44分 | step:  7280 | performance: 6.3 | accuracy: 0.25 | loss: 0.98
update:135/2000, 耗时:0.00分/0.45分 | step:  7560 | performance: 3.4 | accuracy: 0.25 | loss: 5.02
update:140/2000, 耗时:0.00分/0.47分 | step:  7840 | performance: 2.3 | accuracy: 0.25 | loss: 0.72
update:145/2000, 耗时:0.00分/0.48分 | step:  8120 | performance: 4.3 | accuracy: 0.25 | loss: 0.48
update:150/2000, 耗时:0.00分/0.50分 | step:  8400 | performance: 3.2 | accuracy: 0.25 | loss: 1.14
update:155/2000, 耗时:0.00分/0.52分 | step:  8680 | performance: 2.6 | accuracy: 0.25 | loss: 0.43
update:160/2000, 耗时:0.00分/0.53分 | step:  8960 | performance: 2.6 | accuracy: 0.24 | loss: 0.13
update:165/2000, 耗时:0.00分/0.55分 | step:  9240 | performance: 2.5 | accuracy: 0.24 | loss: 0.79
update:170/2000, 耗时:0.00分/0.57分 | step:  9520 | performance: 3.0 | accuracy: 0.24 | loss: 0.05
update:175/2000, 耗时:0.00分/0.58分 | step:  9800 | performance: 2.8 | accuracy: 0.23 | loss: 0.35
update:180/2000, 耗时:0.00分/0.60分 | step: 10080 | performance: 2.7 | accuracy: 0.23 | loss: 0.15
update:185/2000, 耗时:0.00分/0.62分 | step: 10360 | performance: 2.7 | accuracy: 0.22 | loss: 0.06
update:190/2000, 耗时:0.00分/0.63分 | step: 10640 | performance: 2.7 | accuracy: 0.22 | loss: 0.01
update:195/2000, 耗时:0.00分/0.65分 | step: 10920 | performance: 2.7 | accuracy: 0.21 | loss: 0.00
update:200/2000, 耗时:0.00分/0.67分 | step: 11200 | performance: 2.7 | accuracy: 0.21 | loss: 0.00
update:205/2000, 耗时:0.00分/0.68分 | step: 11480 | performance: 2.7 | accuracy: 0.20 | loss: 0.01
update:210/2000, 耗时:0.00分/0.70分 | step: 11760 | performance: 2.7 | accuracy: 0.20 | loss: 0.02
update:215/2000, 耗时:0.00分/0.72分 | step: 12040 | performance: 2.7 | accuracy: 0.20 | loss: 0.00
update:220/2000, 耗时:0.00分/0.74分 | step: 12320 | performance: 2.7 | accuracy: 0.19 | loss: 0.00
update:225/2000, 耗时:0.00分/0.75分 | step: 12600 | performance: 2.7 | accuracy: 0.19 | loss: 0.00
update:230/2000, 耗时:0.00分/0.77分 | step: 12880 | performance: 2.7 | accuracy: 0.19 | loss: 0.09
update:235/2000, 耗时:0.00分/0.79分 | step: 13160 | performance: 2.7 | accuracy: 0.18 | loss: 0.00
update:240/2000, 耗时:0.00分/0.81分 | step: 13440 | performance: 2.7 | accuracy: 0.18 | loss: 0.00
update:245/2000, 耗时:0.00分/0.82分 | step: 13720 | performance: 2.7 | accuracy: 0.17 | loss: 0.00
update:250/2000, 耗时:0.00分/0.84分 | step: 14000 | performance: 2.7 | accuracy: 0.17 | loss: 0.00
update:255/2000, 耗时:0.00分/0.86分 | step: 14280 | performance: 2.7 | accuracy: 0.17 | loss: 0.00
update:260/2000, 耗时:0.00分/0.87分 | step: 14560 | performance: 2.7 | accuracy: 0.17 | loss: 0.00
update:265/2000, 耗时:0.00分/0.89分 | step: 14840 | performance: 2.7 | accuracy: 0.16 | loss: 0.00
update:270/2000, 耗时:0.00分/0.91分 | step: 15120 | performance: 2.7 | accuracy: 0.16 | loss: 0.01
update:275/2000, 耗时:0.00分/0.93分 | step: 15400 | performance: 2.7 | accuracy: 0.16 | loss: 0.00
update:280/2000, 耗时:0.00分/0.94分 | step: 15680 | performance: 2.7 | accuracy: 0.16 | loss: 0.00
update:285/2000, 耗时:0.00分/0.96分 | step: 15960 | performance: 2.7 | accuracy: 0.15 | loss: 0.00
update:290/2000, 耗时:0.00分/0.98分 | step: 16240 | performance: 2.7 | accuracy: 0.15 | loss: 0.00
update:295/2000, 耗时:0.00分/0.99分 | step: 16520 | performance: 2.7 | accuracy: 0.15 | loss: 0.01
update:300/2000, 耗时:0.00分/1.01分 | step: 16800 | performance: 2.7 | accuracy: 0.15 | loss: 0.00
update:305/2000, 耗时:0.00分/1.03分 | step: 17080 | performance: 2.7 | accuracy: 0.15 | loss: 0.01
update:310/2000, 耗时:0.00分/1.05分 | step: 17360 | performance: 2.7 | accuracy: 0.14 | loss: 0.00
update:315/2000, 耗时:0.00分/1.06分 | step: 17640 | performance: 2.7 | accuracy: 0.14 | loss: 0.00
update:320/2000, 耗时:0.00分/1.08分 | step: 17920 | performance: 2.7 | accuracy: 0.14 | loss: 0.00
update:325/2000, 耗时:0.00分/1.10分 | step: 18200 | performance: 2.7 | accuracy: 0.14 | loss: 0.00
update:330/2000, 耗时:0.00分/1.12分 | step: 18480 | performance: 2.7 | accuracy: 0.13 | loss: 0.00
update:335/2000, 耗时:0.00分/1.14分 | step: 18760 | performance: 2.7 | accuracy: 0.13 | loss: 0.00
update:340/2000, 耗时:0.00分/1.15分 | step: 19040 | performance: 2.7 | accuracy: 0.13 | loss: 0.00
update:345/2000, 耗时:0.00分/1.17分 | step: 19320 | performance: 2.7 | accuracy: 0.13 | loss: 0.00
update:350/2000, 耗时:0.00分/1.19分 | step: 19600 | performance: 2.7 | accuracy: 0.13 | loss: 0.00
update:355/2000, 耗时:0.00分/1.21分 | step: 19880 | performance: 2.7 | accuracy: 0.13 | loss: 0.00
update:360/2000, 耗时:0.00分/1.22分 | step: 20160 | performance: 2.7 | accuracy: 0.12 | loss: 0.00
update:365/2000, 耗时:0.00分/1.24分 | step: 20440 | performance: 2.7 | accuracy: 0.12 | loss: 0.00
update:370/2000, 耗时:0.00分/1.26分 | step: 20720 | performance: 2.7 | accuracy: 0.12 | loss: 0.00
update:375/2000, 耗时:0.00分/1.27分 | step: 21000 | performance: 2.7 | accuracy: 0.12 | loss: 0.00
update:380/2000, 耗时:0.00分/1.29分 | step: 21280 | performance: 2.7 | accuracy: 0.12 | loss: 0.00
update:385/2000, 耗时:0.00分/1.31分 | step: 21560 | performance: 2.7 | accuracy: 0.12 | loss: 0.00
update:390/2000, 耗时:0.00分/1.33分 | step: 21840 | performance: 2.7 | accuracy: 0.12 | loss: 0.00
update:395/2000, 耗时:0.00分/1.34分 | step: 22120 | performance: 2.7 | accuracy: 0.11 | loss: 0.00
update:400/2000, 耗时:0.00分/1.36分 | step: 22400 | performance: 2.7 | accuracy: 0.11 | loss: 0.00
update:405/2000, 耗时:0.00分/1.38分 | step: 22680 | performance: 2.7 | accuracy: 0.11 | loss: 0.00
update:410/2000, 耗时:0.00分/1.39分 | step: 22960 | performance: 2.7 | accuracy: 0.11 | loss: 0.00
update:415/2000, 耗时:0.00分/1.41分 | step: 23240 | performance: 2.7 | accuracy: 0.11 | loss: 0.00
update:420/2000, 耗时:0.00分/1.43分 | step: 23520 | performance: 2.7 | accuracy: 0.11 | loss: 0.00
update:425/2000, 耗时:0.00分/1.45分 | step: 23800 | performance: 2.7 | accuracy: 0.11 | loss: 0.00
update:430/2000, 耗时:0.00分/1.46分 | step: 24080 | performance: 2.7 | accuracy: 0.11 | loss: 0.00
update:435/2000, 耗时:0.00分/1.48分 | step: 24360 | performance: 2.7 | accuracy: 0.10 | loss: 0.00
Saving PPO weights in both H5 format and checkpoint @ update:439 
update:440/2000, 耗时:0.00分/1.50分 | step: 24640 | performance: 2.7 | accuracy: 0.10 | loss: 0.01
update:445/2000, 耗时:0.00分/1.52分 | step: 24920 | performance: 2.7 | accuracy: 0.10 | loss: 0.00
step: 24971 | worker_2@n_step_6: average total_reward after train data exhaustion : 6.1 | max total_reward: 20.4
step: 24974 | worker_5@n_step_6: average total_reward after train data exhaustion : 5.5 | max total_reward: 20.4
update:450/2000, 耗时:0.00分/1.54分 | step: 25200 | performance: 2.7 | accuracy: 0.10 | loss: 0.00
step: 25361 | worker_0@n_step_6: average total_reward after train data exhaustion : 2.6 | max total_reward: 20.4
step: 25420 | worker_3@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 20.4
update:455/2000, 耗时:0.00分/1.56分 | step: 25480 | performance: 2.7 | accuracy: 0.10 | loss: 0.00
step: 25642 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.5 | max total_reward: 20.4
step: 25647 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.5 | max total_reward: 20.4
update:460/2000, 耗时:0.00分/1.57分 | step: 25760 | performance: 2.7 | accuracy: 0.10 | loss: 0.00
step: 25923 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.4 | max total_reward: 20.4
step: 25926 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.4 | max total_reward: 20.4
step: 26040 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.7 | max total_reward: 20.4
update:465/2000, 耗时:0.00分/1.59分 | step: 26040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 26313 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.7 | max total_reward: 21.0
update:470/2000, 耗时:0.00分/1.61分 | step: 26320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 26372 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.8 | max total_reward: 21.0
step: 26594 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.8 | max total_reward: 21.0
step: 26599 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.8 | max total_reward: 21.0
update:475/2000, 耗时:0.00分/1.62分 | step: 26600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 26653 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.4 | max total_reward: 21.0
step: 26875 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.4 | max total_reward: 21.0
step: 26878 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.4 | max total_reward: 21.0
update:480/2000, 耗时:0.00分/1.64分 | step: 26880 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 26992 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.4 | max total_reward: 21.0
update:485/2000, 耗时:0.00分/1.66分 | step: 27160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 27265 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 27324 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:490/2000, 耗时:0.00分/1.67分 | step: 27440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 27546 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 27551 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 27605 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:495/2000, 耗时:0.00分/1.69分 | step: 27720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 27827 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 27830 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 27944 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:500/2000, 耗时:0.00分/1.71分 | step: 28000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 28217 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 28276 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:505/2000, 耗时:0.00分/1.72分 | step: 28280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 28498 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 28503 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 28557 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:510/2000, 耗时:0.00分/1.74分 | step: 28560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 28779 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 28782 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:515/2000, 耗时:0.00分/1.75分 | step: 28840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 28896 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:520/2000, 耗时:0.00分/1.77分 | step: 29120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 29169 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 29228 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:525/2000, 耗时:0.00分/1.78分 | step: 29400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 29450 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 29455 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 29509 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:530/2000, 耗时:0.00分/1.80分 | step: 29680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 29731 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 29734 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 29848 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:535/2000, 耗时:0.00分/1.82分 | step: 29960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 30121 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 30180 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:540/2000, 耗时:0.00分/1.83分 | step: 30240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 30402 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 30407 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 30461 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:545/2000, 耗时:0.00分/1.85分 | step: 30520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 30683 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 30686 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 30800 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:550/2000, 耗时:0.00分/1.86分 | step: 30800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 31073 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:555/2000, 耗时:0.00分/1.88分 | step: 31080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 31132 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 31354 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 31359 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:560/2000, 耗时:0.00分/1.89分 | step: 31360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 31413 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 31635 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 31638 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:565/2000, 耗时:0.00分/1.91分 | step: 31640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 31752 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:570/2000, 耗时:0.00分/1.93分 | step: 31920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 32025 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 32084 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:575/2000, 耗时:0.00分/1.94分 | step: 32200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 32306 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 32311 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 32365 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:580/2000, 耗时:0.00分/1.96分 | step: 32480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 32587 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 32590 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 32704 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:585/2000, 耗时:0.00分/1.97分 | step: 32760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 32977 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 33036 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:590/2000, 耗时:0.00分/1.99分 | step: 33040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 33258 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 33263 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 33317 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:595/2000, 耗时:0.00分/2.00分 | step: 33320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 33539 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 33542 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:600/2000, 耗时:0.00分/2.02分 | step: 33600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 33656 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:605/2000, 耗时:0.00分/2.03分 | step: 33880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 33929 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 33988 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:610/2000, 耗时:0.00分/2.05分 | step: 34160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 34210 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 34215 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 34269 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:615/2000, 耗时:0.00分/2.06分 | step: 34440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 34491 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 34494 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 34608 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:620/2000, 耗时:0.00分/2.08分 | step: 34720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 34881 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 34940 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:625/2000, 耗时:0.00分/2.10分 | step: 35000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 35162 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 35167 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 35221 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:630/2000, 耗时:0.00分/2.11分 | step: 35280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 35443 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 35446 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 35560 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:635/2000, 耗时:0.00分/2.13分 | step: 35560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 35833 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:640/2000, 耗时:0.00分/2.14分 | step: 35840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 35892 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 36114 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 36119 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:645/2000, 耗时:0.00分/2.16分 | step: 36120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 36173 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 36395 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 36398 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:650/2000, 耗时:0.00分/2.18分 | step: 36400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 36512 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:655/2000, 耗时:0.00分/2.19分 | step: 36680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 36785 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 36844 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:660/2000, 耗时:0.00分/2.21分 | step: 36960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 37066 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 37071 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 37125 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:665/2000, 耗时:0.00分/2.22分 | step: 37240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 37347 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 37350 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 37464 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:670/2000, 耗时:0.00分/2.24分 | step: 37520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 37737 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 37796 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:675/2000, 耗时:0.00分/2.25分 | step: 37800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 38018 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 38023 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 38077 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:680/2000, 耗时:0.00分/2.27分 | step: 38080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 38299 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 38302 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:685/2000, 耗时:0.00分/2.29分 | step: 38360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 38416 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:690/2000, 耗时:0.00分/2.30分 | step: 38640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 38689 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 38748 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:695/2000, 耗时:0.00分/2.32分 | step: 38920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 38970 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 38975 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 39029 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:700/2000, 耗时:0.00分/2.34分 | step: 39200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 39251 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 39254 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 39368 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:705/2000, 耗时:0.00分/2.35分 | step: 39480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 39641 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 39700 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:710/2000, 耗时:0.00分/2.37分 | step: 39760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 39922 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 39927 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 39981 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:715/2000, 耗时:0.00分/2.38分 | step: 40040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 40203 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 40206 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 40320 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:720/2000, 耗时:0.00分/2.40分 | step: 40320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 40593 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:725/2000, 耗时:0.00分/2.42分 | step: 40600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 40652 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 40874 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 40879 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:730/2000, 耗时:0.00分/2.43分 | step: 40880 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 40933 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 41155 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 41158 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:735/2000, 耗时:0.00分/2.45分 | step: 41160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 41272 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:740/2000, 耗时:0.00分/2.46分 | step: 41440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 41545 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 41604 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:745/2000, 耗时:0.00分/2.48分 | step: 41720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 41826 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 41831 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 41885 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:750/2000, 耗时:0.00分/2.50分 | step: 42000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 42107 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 42110 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 42224 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:755/2000, 耗时:0.00分/2.51分 | step: 42280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 42497 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 42556 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:760/2000, 耗时:0.00分/2.53分 | step: 42560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 42778 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 42783 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 42837 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:765/2000, 耗时:0.00分/2.55分 | step: 42840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 43059 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 43062 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:770/2000, 耗时:0.00分/2.56分 | step: 43120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 43176 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:775/2000, 耗时:0.00分/2.58分 | step: 43400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 43449 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 43508 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:780/2000, 耗时:0.00分/2.59分 | step: 43680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 43730 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 43735 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 43789 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:785/2000, 耗时:0.00分/2.61分 | step: 43960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 44011 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 44014 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 44128 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:790/2000, 耗时:0.00分/2.63分 | step: 44240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 44401 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 44460 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:795/2000, 耗时:0.00分/2.64分 | step: 44520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 44682 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 44687 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 44741 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:800/2000, 耗时:0.00分/2.66分 | step: 44800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 44963 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 44966 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 45080 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:805/2000, 耗时:0.00分/2.68分 | step: 45080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 45353 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:810/2000, 耗时:0.00分/2.69分 | step: 45360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 45412 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 45634 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 45639 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:815/2000, 耗时:0.00分/2.71分 | step: 45640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 45693 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 45915 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 45918 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:820/2000, 耗时:0.00分/2.72分 | step: 45920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 46032 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:825/2000, 耗时:0.00分/2.74分 | step: 46200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 46305 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 46364 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:830/2000, 耗时:0.00分/2.76分 | step: 46480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 46586 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 46591 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 46645 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:835/2000, 耗时:0.00分/2.77分 | step: 46760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 46867 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 46870 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 46984 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:840/2000, 耗时:0.00分/2.79分 | step: 47040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 47257 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 47316 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:845/2000, 耗时:0.00分/2.80分 | step: 47320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 47538 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 47543 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 47597 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:850/2000, 耗时:0.00分/2.82分 | step: 47600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 47819 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 47822 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:855/2000, 耗时:0.00分/2.84分 | step: 47880 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 47936 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:860/2000, 耗时:0.00分/2.85分 | step: 48160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 48209 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 48268 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:865/2000, 耗时:0.00分/2.87分 | step: 48440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 48490 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 48495 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 48549 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:870/2000, 耗时:0.00分/2.89分 | step: 48720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 48771 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 48774 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 48888 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:875/2000, 耗时:0.00分/2.90分 | step: 49000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 49161 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 49220 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:880/2000, 耗时:0.00分/2.92分 | step: 49280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 49442 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 49447 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 49501 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:885/2000, 耗时:0.00分/2.93分 | step: 49560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 49723 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 49726 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 49840 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:890/2000, 耗时:0.00分/2.95分 | step: 49840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 50113 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:895/2000, 耗时:0.00分/2.97分 | step: 50120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 50172 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 50394 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 50399 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:900/2000, 耗时:0.00分/2.98分 | step: 50400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 50453 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 50675 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 50678 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:905/2000, 耗时:0.00分/3.00分 | step: 50680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 50792 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:910/2000, 耗时:0.00分/3.02分 | step: 50960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 51065 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 51124 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:915/2000, 耗时:0.00分/3.03分 | step: 51240 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 51346 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 51351 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 51405 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:920/2000, 耗时:0.00分/3.05分 | step: 51520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 51627 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 51630 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 51744 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:925/2000, 耗时:0.00分/3.06分 | step: 51800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 52017 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 52076 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:930/2000, 耗时:0.00分/3.08分 | step: 52080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 52298 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 52303 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 52357 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:935/2000, 耗时:0.00分/3.10分 | step: 52360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 52579 | worker_2@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 21.0
step: 52582 | worker_5@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 21.0
update:940/2000, 耗时:0.00分/3.11分 | step: 52640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 52696 | worker_7@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 21.0
update:945/2000, 耗时:0.00分/3.13分 | step: 52920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 52969 | worker_0@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 21.0
step: 53028 | worker_3@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 21.0
update:950/2000, 耗时:0.00分/3.14分 | step: 53200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 53250 | worker_1@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 21.0
step: 53255 | worker_6@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 21.0
step: 53309 | worker_4@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 21.0
update:955/2000, 耗时:0.00分/3.16分 | step: 53480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 53531 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 53534 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 53648 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:960/2000, 耗时:0.00分/3.18分 | step: 53760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 53921 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 53980 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:965/2000, 耗时:0.00分/3.19分 | step: 54040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 54202 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 54207 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 54261 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:970/2000, 耗时:0.00分/3.21分 | step: 54320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 54483 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 54486 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 54600 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:975/2000, 耗时:0.00分/3.23分 | step: 54600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 54873 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:980/2000, 耗时:0.00分/3.24分 | step: 54880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 54932 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 55154 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 55159 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:985/2000, 耗时:0.00分/3.26分 | step: 55160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 55213 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 55435 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 55438 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:990/2000, 耗时:0.00分/3.27分 | step: 55440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 55552 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:995/2000, 耗时:0.00分/3.29分 | step: 55720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 55825 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 55884 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1000/2000, 耗时:0.00分/3.30分 | step: 56000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 56106 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 56111 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 56165 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1005/2000, 耗时:0.00分/3.32分 | step: 56280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 56387 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 56390 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 56504 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1010/2000, 耗时:0.00分/3.34分 | step: 56560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 56777 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 56836 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1015/2000, 耗时:0.00分/3.35分 | step: 56840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 57058 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 57063 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 57117 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1020/2000, 耗时:0.00分/3.37分 | step: 57120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 57339 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 57342 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1025/2000, 耗时:0.00分/3.38分 | step: 57400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 57456 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1030/2000, 耗时:0.00分/3.40分 | step: 57680 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 57729 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 57788 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1035/2000, 耗时:0.00分/3.41分 | step: 57960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 58010 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 58015 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 58069 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1040/2000, 耗时:0.00分/3.43分 | step: 58240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 58291 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 58294 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 58408 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1045/2000, 耗时:0.00分/3.45分 | step: 58520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 58681 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 58740 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1050/2000, 耗时:0.00分/3.46分 | step: 58800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 58962 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 58967 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 59021 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1055/2000, 耗时:0.00分/3.48分 | step: 59080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 59243 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 59246 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 59360 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1060/2000, 耗时:0.00分/3.49分 | step: 59360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 59633 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1065/2000, 耗时:0.00分/3.51分 | step: 59640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 59692 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 59914 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 59919 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1070/2000, 耗时:0.00分/3.52分 | step: 59920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 59973 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 60195 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 60198 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1075/2000, 耗时:0.00分/3.54分 | step: 60200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 60312 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1080/2000, 耗时:0.00分/3.56分 | step: 60480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 60585 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 60644 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1085/2000, 耗时:0.00分/3.57分 | step: 60760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 60866 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 60871 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 60925 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1090/2000, 耗时:0.00分/3.59分 | step: 61040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 61147 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 61150 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 61264 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1095/2000, 耗时:0.00分/3.60分 | step: 61320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 61537 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 61596 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1100/2000, 耗时:0.00分/3.62分 | step: 61600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 61818 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 61823 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 61877 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1105/2000, 耗时:0.00分/3.63分 | step: 61880 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 62099 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 62102 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1110/2000, 耗时:0.00分/3.65分 | step: 62160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 62216 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1115/2000, 耗时:0.00分/3.67分 | step: 62440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 62489 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 62548 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1120/2000, 耗时:0.00分/3.68分 | step: 62720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 62770 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 62775 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 62829 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1125/2000, 耗时:0.00分/3.70分 | step: 63000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 63051 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 63054 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 63168 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1130/2000, 耗时:0.00分/3.71分 | step: 63280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 63441 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 63500 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1135/2000, 耗时:0.00分/3.73分 | step: 63560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 63722 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 63727 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 63781 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1140/2000, 耗时:0.00分/3.75分 | step: 63840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 64003 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 64006 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 64120 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1145/2000, 耗时:0.00分/3.76分 | step: 64120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 64393 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1150/2000, 耗时:0.00分/3.78分 | step: 64400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 64452 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 64674 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 64679 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1155/2000, 耗时:0.00分/3.79分 | step: 64680 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 64733 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 64955 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 64958 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1160/2000, 耗时:0.00分/3.81分 | step: 64960 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 65072 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1165/2000, 耗时:0.00分/3.82分 | step: 65240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 65345 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 65404 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1170/2000, 耗时:0.00分/3.84分 | step: 65520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 65626 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 65631 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 65685 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1175/2000, 耗时:0.00分/3.86分 | step: 65800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 65907 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 65910 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 66024 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1180/2000, 耗时:0.00分/3.87分 | step: 66080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 66297 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 66356 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1185/2000, 耗时:0.00分/3.89分 | step: 66360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 66578 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 66583 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 66637 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1190/2000, 耗时:0.00分/3.90分 | step: 66640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 66859 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 66862 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1195/2000, 耗时:0.00分/3.92分 | step: 66920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 66976 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1200/2000, 耗时:0.00分/3.94分 | step: 67200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 67249 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 67308 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1205/2000, 耗时:0.00分/3.95分 | step: 67480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 67530 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 67535 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 67589 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1210/2000, 耗时:0.00分/3.97分 | step: 67760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 67811 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 67814 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 67928 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1215/2000, 耗时:0.00分/3.98分 | step: 68040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 68201 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 68260 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1220/2000, 耗时:0.00分/4.00分 | step: 68320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 68482 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 68487 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 68541 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1225/2000, 耗时:0.00分/4.02分 | step: 68600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 68763 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 68766 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 68880 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1230/2000, 耗时:0.00分/4.03分 | step: 68880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 69153 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1235/2000, 耗时:0.00分/4.05分 | step: 69160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 69212 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 69434 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 69439 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1240/2000, 耗时:0.00分/4.06分 | step: 69440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 69493 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 69715 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 69718 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1245/2000, 耗时:0.00分/4.08分 | step: 69720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 69832 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1250/2000, 耗时:0.00分/4.09分 | step: 70000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 70105 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 70164 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1255/2000, 耗时:0.00分/4.11分 | step: 70280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 70386 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 70391 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 70445 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1260/2000, 耗时:0.00分/4.12分 | step: 70560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 70667 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 70670 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 70784 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1265/2000, 耗时:0.00分/4.14分 | step: 70840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 71057 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 71116 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1270/2000, 耗时:0.00分/4.16分 | step: 71120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 71338 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 71343 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 71397 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1275/2000, 耗时:0.00分/4.17分 | step: 71400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 71619 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 71622 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1280/2000, 耗时:0.00分/4.19分 | step: 71680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 71736 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1285/2000, 耗时:0.00分/4.20分 | step: 71960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 72009 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 72068 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1290/2000, 耗时:0.00分/4.22分 | step: 72240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 72290 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 72295 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 72349 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1295/2000, 耗时:0.00分/4.23分 | step: 72520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 72571 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 72574 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 72688 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1300/2000, 耗时:0.00分/4.25分 | step: 72800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 72961 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 73020 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1305/2000, 耗时:0.00分/4.26分 | step: 73080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 73242 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 73247 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 73301 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1310/2000, 耗时:0.00分/4.28分 | step: 73360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 73523 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 73526 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 73640 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1315/2000, 耗时:0.00分/4.30分 | step: 73640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 73913 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1320/2000, 耗时:0.00分/4.31分 | step: 73920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 73972 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 74194 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 74199 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1325/2000, 耗时:0.00分/4.33分 | step: 74200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 74253 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 74475 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 74478 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1330/2000, 耗时:0.00分/4.34分 | step: 74480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 74592 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1335/2000, 耗时:0.00分/4.36分 | step: 74760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 74865 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 74924 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1340/2000, 耗时:0.00分/4.38分 | step: 75040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 75146 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 75151 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 75205 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1345/2000, 耗时:0.00分/4.39分 | step: 75320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 75427 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 75430 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 75544 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1350/2000, 耗时:0.00分/4.41分 | step: 75600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 75817 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 75876 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1355/2000, 耗时:0.00分/4.42分 | step: 75880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 76098 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 76103 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 76157 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1360/2000, 耗时:0.00分/4.44分 | step: 76160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 76379 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 76382 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1365/2000, 耗时:0.00分/4.45分 | step: 76440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 76496 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1370/2000, 耗时:0.00分/4.47分 | step: 76720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 76769 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 76828 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1375/2000, 耗时:0.00分/4.49分 | step: 77000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 77050 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 77055 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 77109 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1380/2000, 耗时:0.00分/4.50分 | step: 77280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 77331 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 77334 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 77448 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1385/2000, 耗时:0.00分/4.52分 | step: 77560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 77721 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 77780 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1390/2000, 耗时:0.00分/4.53分 | step: 77840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 78002 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 78007 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 78061 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1395/2000, 耗时:0.00分/4.55分 | step: 78120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 78283 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 78286 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 78400 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1400/2000, 耗时:0.00分/4.57分 | step: 78400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 78673 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1405/2000, 耗时:0.00分/4.58分 | step: 78680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 78732 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 78954 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 78959 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1410/2000, 耗时:0.00分/4.60分 | step: 78960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 79013 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 79235 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 79238 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1415/2000, 耗时:0.00分/4.61分 | step: 79240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 79352 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1420/2000, 耗时:0.00分/4.63分 | step: 79520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 79625 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 79684 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1425/2000, 耗时:0.00分/4.64分 | step: 79800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 79906 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 79911 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 79965 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1430/2000, 耗时:0.00分/4.66分 | step: 80080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 80187 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 80190 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 80304 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1435/2000, 耗时:0.00分/4.68分 | step: 80360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 80577 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 80636 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1440/2000, 耗时:0.00分/4.69分 | step: 80640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 80858 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 80863 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 80917 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1445/2000, 耗时:0.00分/4.71分 | step: 80920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 81139 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 81142 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1450/2000, 耗时:0.00分/4.72分 | step: 81200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 81256 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1455/2000, 耗时:0.00分/4.74分 | step: 81480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 81529 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 81588 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1460/2000, 耗时:0.00分/4.76分 | step: 81760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 81810 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 81815 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 81869 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1465/2000, 耗时:0.00分/4.77分 | step: 82040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 82091 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 82094 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 82208 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1470/2000, 耗时:0.00分/4.79分 | step: 82320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 82481 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 82540 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1475/2000, 耗时:0.00分/4.80分 | step: 82600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 82762 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 82767 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 82821 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1480/2000, 耗时:0.00分/4.82分 | step: 82880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 83043 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 83046 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 83160 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1485/2000, 耗时:0.00分/4.84分 | step: 83160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 83433 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1490/2000, 耗时:0.00分/4.85分 | step: 83440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 83492 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 83714 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 83719 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1495/2000, 耗时:0.00分/4.87分 | step: 83720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 83773 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 83995 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 83998 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1500/2000, 耗时:0.00分/4.88分 | step: 84000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 84112 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1505/2000, 耗时:0.00分/4.90分 | step: 84280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 84385 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 84444 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1510/2000, 耗时:0.00分/4.91分 | step: 84560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 84666 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 84671 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 84725 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1515/2000, 耗时:0.00分/4.93分 | step: 84840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 84947 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 84950 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 85064 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1520/2000, 耗时:0.00分/4.94分 | step: 85120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 85337 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 85396 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1525/2000, 耗时:0.00分/4.96分 | step: 85400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 85618 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 85623 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 85677 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1530/2000, 耗时:0.00分/4.98分 | step: 85680 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 85899 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 85902 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1535/2000, 耗时:0.00分/4.99分 | step: 85960 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 86016 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1540/2000, 耗时:0.00分/5.01分 | step: 86240 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 86289 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 86348 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1545/2000, 耗时:0.00分/5.02分 | step: 86520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 86570 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 86575 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 86629 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1550/2000, 耗时:0.00分/5.04分 | step: 86800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 86851 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 86854 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 86968 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1555/2000, 耗时:0.00分/5.05分 | step: 87080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 87241 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 87300 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1560/2000, 耗时:0.00分/5.07分 | step: 87360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 87522 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 87527 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 87581 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1565/2000, 耗时:0.00分/5.08分 | step: 87640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 87803 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 87806 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 87920 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1570/2000, 耗时:0.00分/5.10分 | step: 87920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 88193 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1575/2000, 耗时:0.00分/5.11分 | step: 88200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 88252 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 88474 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 88479 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1580/2000, 耗时:0.00分/5.13分 | step: 88480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 88533 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 88755 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 88758 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1585/2000, 耗时:0.00分/5.14分 | step: 88760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 88872 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1590/2000, 耗时:0.00分/5.16分 | step: 89040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 89145 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 89204 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1595/2000, 耗时:0.00分/5.18分 | step: 89320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 89426 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 89431 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 89485 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1600/2000, 耗时:0.00分/5.19分 | step: 89600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 89707 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 89710 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 89824 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1605/2000, 耗时:0.00分/5.21分 | step: 89880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 90097 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 90156 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1610/2000, 耗时:0.00分/5.22分 | step: 90160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 90378 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 90383 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 90437 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1615/2000, 耗时:0.00分/5.24分 | step: 90440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 90659 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 90662 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1620/2000, 耗时:0.00分/5.25分 | step: 90720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 90776 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1625/2000, 耗时:0.00分/5.27分 | step: 91000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 91049 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 91108 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1630/2000, 耗时:0.00分/5.28分 | step: 91280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 91330 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 91335 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 91389 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1635/2000, 耗时:0.00分/5.30分 | step: 91560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 91611 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 91614 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 91728 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1640/2000, 耗时:0.00分/5.31分 | step: 91840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 92001 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 92060 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1645/2000, 耗时:0.00分/5.33分 | step: 92120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 92282 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 92287 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 92341 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1650/2000, 耗时:0.00分/5.34分 | step: 92400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 92563 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 92566 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 92680 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1655/2000, 耗时:0.00分/5.36分 | step: 92680 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 92953 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1660/2000, 耗时:0.00分/5.37分 | step: 92960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 93012 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 93234 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 93239 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1665/2000, 耗时:0.00分/5.39分 | step: 93240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 93293 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 93515 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 93518 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1670/2000, 耗时:0.00分/5.40分 | step: 93520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 93632 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1675/2000, 耗时:0.00分/5.42分 | step: 93800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 93905 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 93964 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1680/2000, 耗时:0.00分/5.43分 | step: 94080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 94186 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 94191 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 94245 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1685/2000, 耗时:0.00分/5.45分 | step: 94360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 94467 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 94470 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 94584 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1690/2000, 耗时:0.00分/5.46分 | step: 94640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 94857 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 94916 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1695/2000, 耗时:0.00分/5.48分 | step: 94920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 95138 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 95143 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 95197 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1700/2000, 耗时:0.00分/5.49分 | step: 95200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 95419 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 95422 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1705/2000, 耗时:0.00分/5.51分 | step: 95480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 95536 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1710/2000, 耗时:0.00分/5.53分 | step: 95760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 95809 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 95868 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1715/2000, 耗时:0.00分/5.54分 | step: 96040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 96090 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 96095 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 96149 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1720/2000, 耗时:0.00分/5.56分 | step: 96320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 96371 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 96374 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 96488 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1725/2000, 耗时:0.00分/5.57分 | step: 96600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 96761 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 96820 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1730/2000, 耗时:0.00分/5.59分 | step: 96880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 97042 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 97047 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 97101 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1735/2000, 耗时:0.00分/5.60分 | step: 97160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 97323 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 97326 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 97440 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1740/2000, 耗时:0.00分/5.62分 | step: 97440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 97713 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1745/2000, 耗时:0.00分/5.63分 | step: 97720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 97772 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 97994 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 97999 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1750/2000, 耗时:0.00分/5.65分 | step: 98000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 98053 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 98275 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 98278 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1755/2000, 耗时:0.00分/5.67分 | step: 98280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 98392 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1760/2000, 耗时:0.00分/5.68分 | step: 98560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 98665 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 98724 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1765/2000, 耗时:0.00分/5.70分 | step: 98840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 98946 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 98951 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 99005 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1770/2000, 耗时:0.00分/5.71分 | step: 99120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 99227 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 99230 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 99344 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1775/2000, 耗时:0.00分/5.73分 | step: 99400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 99617 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 99676 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1780/2000, 耗时:0.00分/5.75分 | step: 99680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 99898 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 99903 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 99957 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1785/2000, 耗时:0.00分/5.76分 | step: 99960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 100179 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 100182 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1790/2000, 耗时:0.00分/5.78分 | step: 100240 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 100296 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1795/2000, 耗时:0.00分/5.80分 | step: 100520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 100569 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 100628 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1800/2000, 耗时:0.00分/5.81分 | step: 100800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 100850 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 100855 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 100909 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1805/2000, 耗时:0.00分/5.83分 | step: 101080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 101131 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 101134 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 101248 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1810/2000, 耗时:0.00分/5.85分 | step: 101360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 101521 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 101580 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1815/2000, 耗时:0.00分/5.87分 | step: 101640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 101802 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 101807 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 101861 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1820/2000, 耗时:0.00分/5.88分 | step: 101920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 102083 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 102086 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 102200 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1825/2000, 耗时:0.00分/5.90分 | step: 102200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 102473 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1830/2000, 耗时:0.00分/5.92分 | step: 102480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 102532 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 102754 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 102759 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1835/2000, 耗时:0.00分/5.93分 | step: 102760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 102813 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 103035 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 103038 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1840/2000, 耗时:0.00分/5.95分 | step: 103040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 103152 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1845/2000, 耗时:0.00分/5.97分 | step: 103320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 103425 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 103484 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1850/2000, 耗时:0.00分/5.99分 | step: 103600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 103706 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 103711 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 103765 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1855/2000, 耗时:0.00分/6.00分 | step: 103880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 103987 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 103990 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 104104 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1860/2000, 耗时:0.00分/6.02分 | step: 104160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 104377 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 104436 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1865/2000, 耗时:0.00分/6.04分 | step: 104440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 104658 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 104663 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 104717 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1870/2000, 耗时:0.00分/6.05分 | step: 104720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 104939 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 104942 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1875/2000, 耗时:0.00分/6.07分 | step: 105000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 105056 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1880/2000, 耗时:0.00分/6.09分 | step: 105280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 105329 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 105388 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1885/2000, 耗时:0.00分/6.11分 | step: 105560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 105610 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 105615 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 105669 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1890/2000, 耗时:0.00分/6.12分 | step: 105840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 105891 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 105894 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 106008 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1895/2000, 耗时:0.00分/6.14分 | step: 106120 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 106281 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 106340 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1900/2000, 耗时:0.00分/6.16分 | step: 106400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 106562 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 106567 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 106621 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1905/2000, 耗时:0.00分/6.18分 | step: 106680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 106843 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 106846 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 106960 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1910/2000, 耗时:0.00分/6.19分 | step: 106960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 107233 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1915/2000, 耗时:0.00分/6.21分 | step: 107240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 107292 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 107514 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 107519 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1920/2000, 耗时:0.00分/6.23分 | step: 107520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 107573 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 107795 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 107798 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1925/2000, 耗时:0.00分/6.24分 | step: 107800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 107912 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1930/2000, 耗时:0.00分/6.26分 | step: 108080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 108185 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 108244 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1935/2000, 耗时:0.00分/6.28分 | step: 108360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 108466 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 108471 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 108525 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1940/2000, 耗时:0.00分/6.29分 | step: 108640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 108747 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 108750 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 108864 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1945/2000, 耗时:0.00分/6.31分 | step: 108920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 109137 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 109196 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1950/2000, 耗时:0.00分/6.33分 | step: 109200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 109418 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 109423 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 109477 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1955/2000, 耗时:0.00分/6.34分 | step: 109480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 109699 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 109702 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1960/2000, 耗时:0.00分/6.36分 | step: 109760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 109816 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1965/2000, 耗时:0.00分/6.38分 | step: 110040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 110089 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 110148 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1970/2000, 耗时:0.00分/6.39分 | step: 110320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 110370 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 110375 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 110429 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1975/2000, 耗时:0.00分/6.41分 | step: 110600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 110651 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 110654 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 110768 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1980/2000, 耗时:0.00分/6.43分 | step: 110880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 111041 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 111100 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1985/2000, 耗时:0.00分/6.45分 | step: 111160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 111322 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 111327 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 111381 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1990/2000, 耗时:0.00分/6.46分 | step: 111440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 111603 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 111606 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
step: 111720 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
update:1995/2000, 耗时:0.00分/6.48分 | step: 111720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 111993 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 21.0
  0%|          | 0/397 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/6.50分 | step: 112000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
----------------------------------------finished----------------------------------------
100%|| 397/397 [00:00<00:00, 99215.80it/s]
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1000.00
2023-07-24T12:00:00 | net performance [%] = 0.0000
2023-07-24T12:00:00 | number of trades [#] = 0
==================================================
Trial 28 Complete [00h 06m 56s]
net_wealth: 1000.0

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 03h 52m 50s

Search: Running Trial #29

Value             |Best Value So Far |Hyperparameter
6                 |1                 |horizon
365               |730               |lookback
True              |False             |MarketFactor
3                 |3                 |lags
0.8               |0.92              |gamma
32                |32                |batch_size
7                 |1                 |n_step
0.92              |0.94              |gae_lambda
5                 |5                 |gradient_clip_norm
5                 |5                 |epochs
0.001             |0.0001            |actor_lr
5e-05             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4295.000000   4301.000000
mean      0.000435    20113.607657  ...   20191.527960  20169.373185
std       0.027833    16040.642334  ...   16078.872271  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7755.915039   7730.930176
50%       0.000642    11571.842969  ...   11757.219727  11751.469727
75%       0.011590    29894.706152  ...   30018.430664  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 01:56:13.25492002202:3 -07-28 01:56I t:e1ns023o.2023-0753-04-92rflo30202w/cor7-2e5: I t2/2p33--07-28 0e1n8:8 5 01:l6:13a.56:130.1:56:t1form54921607-528/ sc401: 92:3orfloI5p.65:13. ten45w4u_f7/c9eat93s5: I2 1u2tens8roorfe: I_ gtensouoarrfe/plloloartdr.fw/ccwl0c:1foo04/crr:o2m/2cpu]_efow0eat urr0e2/I t/pe3_eg/c2o 3-pTlhartifso uelTaetnf-/npsl0orrm/mcpaaosotfrorur_frdl./Fco0cc:p7fue_af7eaw-t1242mu/rce/lcoow_ ]- T2hguardr.c8bi ncp:e1taurriy48/epl aits_sg Tfe 0u _nfoear0o12]m: Tu15:hstoupr6/tairmdrFliowse5. ccTce::i pnzseb1_4g26d]uina or1 aTrhriuw3yi .iF_:1slso5 3 w. T4t5h4b9 9ofpetaimie5t77iznarud:n Is 7tre_yg eoneuAairoPrdI. 6eFns D2.lcoce:ep1 4cwcs:Nodeu :2ptr1o42rw]flio]wa li /I b tth eiTNmcno rianrys zed ewoitehtihs n/epAP TIisl aw oeDnesooe oTrhrFilspt fookr m Nprow fTLlinobwbr/tceuraelAeianaryp/inm PNseucrIy o_ i(zo DroFisfeeedarl oonteew/pptD uwret_weol gpu NNiibairrka eLuirbnNdrmaira) tthotyafl  ory ius  rs (oozemd pNteio/nc.pcwuitmhi e_ef tehtoaDneetNn c:N)w ozfoeulAto AuserekPdI    lL1io4Dweiwei2r] eT_thhgpbtuPrI  NDaerehp Naeurndgy .(oices n e Tr aolDens ornceFAloCwNPNP)Ie uNreaUb intaot   Die:nsrtfeup1 wNoerske rlLy4 oiu2  ]N erTlloawlinhu Ntehtegs  fcioilClto wwtbirowsoorrkkian r  Lsy TLonpgt einbsoPCUir bPU iansr(rrFtlrio yuanowneiDmNiNi nz)ec  pe(rst otnorbyd  uiiowisteh t(foe thDNnN) tnnse  oooer frDuimaan cNtnr useonNcyil)le  tteo-pohAePIcero   frwfionnuDeoslietpg  CPlioNwer Ui sciuni rpmeeanngs  tthruaanercll o Ctfo ce-icPpir mfUN osnsoeins tructtloancerw oip-icrietrirni kp cal eoprferlotorticowiLmibraniingatiomn aCtaznce-rsa iscyr i(toenoiPlU  oiicnasnperalt r ds:  nptei:AeVDXN Nope uAonr)c ttios :r wfao  AiVXt AVXo ntironshus Vso iX2
ATn 2moan n:
 T cpeeoAeen- crAVX AiePrtabtlifV X enAIVeh ce fDoa XlV2
oetTXo2lreman
Toalbohc eeweinlmepn-   Nableen  e atciobphlermi inn oetet ho thutihetrhgeem ir c areCr PoUpatl oeron mo ppteraaioelnrstaht :i o atiAoneionisn: V AVs rotXhe r o,X nAVA poes rperaX,2 
rVaX2
Teo inbsTtiotuioilNrendo ens ,s Teeebn,a nbulield rTe sonrFltowwtrbu ilde nTtusawoiheemnsot ho rFl oblecitiworrFn wir lto thk hnems woeL  t htihe watheribepninb appprror opprai ortia tpreryfe iate (oron eDcNhuithm theocancee-mcriorl dopilerNp  fl) totToampi lue nsaoprpFreicaspeeor fle  ptrgarahel alrtiitiognsofooos,a snlsl,o.
.t
epera tri coonsww wimpith teilnehbuie apgreb:p rorl A pd TensV XfCPU luorrFia Aniglso.w
ld TensorFlow with the appropriate compiler flags.
iate compiler flags.
VX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
 withstructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
 the appropriate compiler flags.
2023-07-28 01:56:14.150854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:56:14.156816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:56:14.172015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:56:14.176513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:56:14.177155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:56:14.181932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:56:14.211198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 01:56:14.214312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   280 | performance: 1.3 | accuracy: 0.34 | loss: 0.66
update: 10/2000, 耗时:0.00分/0.05分 | step:   560 | performance: 4.0 | accuracy: 0.47 | loss: 1.24
update: 15/2000, 耗时:0.00分/0.06分 | step:   840 | performance: 0.9 | accuracy: 0.35 | loss: 0.93
update: 20/2000, 耗时:0.00分/0.07分 | step:  1120 | performance: 0.7 | accuracy: 0.37 | loss: 0.98
update: 25/2000, 耗时:0.00分/0.09分 | step:  1400 | performance: 1.4 | accuracy: 0.41 | loss: 1.89
update: 30/2000, 耗时:0.00分/0.10分 | step:  1680 | performance: 3.3 | accuracy: 0.45 | loss: 2.60
update: 35/2000, 耗时:0.00分/0.12分 | step:  1960 | performance: 3.8 | accuracy: 0.44 | loss: 0.73
update: 40/2000, 耗时:0.00分/0.13分 | step:  2240 | performance: 1.1 | accuracy: 0.42 | loss: 2.22
update: 45/2000, 耗时:0.00分/0.15分 | step:  2520 | performance: 5.9 | accuracy: 0.47 | loss: 3.21
update: 50/2000, 耗时:0.00分/0.17分 | step:  2800 | performance: 3.0 | accuracy: 0.44 | loss: 2.39
update: 55/2000, 耗时:0.00分/0.18分 | step:  3080 | performance: 5.3 | accuracy: 0.44 | loss: 3.50
update: 60/2000, 耗时:0.00分/0.20分 | step:  3360 | performance: 5.3 | accuracy: 0.46 | loss: 5.71
update: 65/2000, 耗时:0.00分/0.22分 | step:  3640 | performance: 5.3 | accuracy: 0.46 | loss: 5.68
update: 70/2000, 耗时:0.00分/0.24分 | step:  3920 | performance: 5.8 | accuracy: 0.46 | loss: 1.85
update: 75/2000, 耗时:0.00分/0.25分 | step:  4200 | performance: 86.1 | accuracy: 0.49 | loss: 4.32
update: 80/2000, 耗时:0.00分/0.27分 | step:  4480 | performance: 304.3 | accuracy: 0.50 | loss: 3.49
update: 85/2000, 耗时:0.00分/0.29分 | step:  4760 | performance: 176.8 | accuracy: 0.50 | loss: 0.87
update: 90/2000, 耗时:0.00分/0.30分 | step:  5040 | performance: 171.8 | accuracy: 0.49 | loss: 0.58
update: 95/2000, 耗时:0.00分/0.32分 | step:  5320 | performance: 218.5 | accuracy: 0.49 | loss: 2.42
update:100/2000, 耗时:0.00分/0.34分 | step:  5600 | performance: 107.7 | accuracy: 0.49 | loss: 3.73
update:105/2000, 耗时:0.00分/0.35分 | step:  5880 | performance: 115.4 | accuracy: 0.48 | loss: 5.41
update:110/2000, 耗时:0.00分/0.37分 | step:  6160 | performance: 106.4 | accuracy: 0.48 | loss: 0.98
update:115/2000, 耗时:0.00分/0.39分 | step:  6440 | performance: 26.3 | accuracy: 0.47 | loss: 1.55
update:120/2000, 耗时:0.00分/0.40分 | step:  6720 | performance: 19.6 | accuracy: 0.46 | loss: 3.35
update:125/2000, 耗时:0.00分/0.42分 | step:  7000 | performance: 2.6 | accuracy: 0.45 | loss: 1.44
update:130/2000, 耗时:0.00分/0.44分 | step:  7280 | performance: 2.1 | accuracy: 0.45 | loss: 1.47
update:135/2000, 耗时:0.00分/0.46分 | step:  7560 | performance: 0.4 | accuracy: 0.44 | loss: 11.68
update:140/2000, 耗时:0.00分/0.47分 | step:  7840 | performance: 0.2 | accuracy: 0.43 | loss: 12.07
update:145/2000, 耗时:0.00分/0.49分 | step:  8120 | performance: 0.7 | accuracy: 0.45 | loss: 1.35
update:150/2000, 耗时:0.00分/0.51分 | step:  8400 | performance: 0.4 | accuracy: 0.45 | loss: 4.08
update:155/2000, 耗时:0.00分/0.52分 | step:  8680 | performance: 0.7 | accuracy: 0.45 | loss: 1.71
update:160/2000, 耗时:0.00分/0.54分 | step:  8960 | performance: 0.6 | accuracy: 0.45 | loss: 3.32
update:165/2000, 耗时:0.00分/0.56分 | step:  9240 | performance: 2.3 | accuracy: 0.46 | loss: 3.42
update:170/2000, 耗时:0.00分/0.57分 | step:  9520 | performance: 2.7 | accuracy: 0.46 | loss: 1.82
update:175/2000, 耗时:0.00分/0.59分 | step:  9800 | performance: 1.4 | accuracy: 0.46 | loss: 6.04
update:180/2000, 耗时:0.00分/0.61分 | step: 10080 | performance: 4.7 | accuracy: 0.47 | loss: 1.25
update:185/2000, 耗时:0.00分/0.62分 | step: 10360 | performance: 5.3 | accuracy: 0.48 | loss: 3.85
update:190/2000, 耗时:0.00分/0.64分 | step: 10640 | performance: 5.3 | accuracy: 0.48 | loss: 5.34
update:195/2000, 耗时:0.00分/0.66分 | step: 10920 | performance: 1.6 | accuracy: 0.47 | loss: 1.29
update:200/2000, 耗时:0.00分/0.68分 | step: 11200 | performance: 1.2 | accuracy: 0.47 | loss: 1.34
update:205/2000, 耗时:0.00分/0.69分 | step: 11480 | performance: 1.0 | accuracy: 0.47 | loss: 1.27
update:210/2000, 耗时:0.00分/0.71分 | step: 11760 | performance: 4.5 | accuracy: 0.47 | loss: 8.51
update:215/2000, 耗时:0.00分/0.73分 | step: 12040 | performance: 15.0 | accuracy: 0.47 | loss: 10.17
update:220/2000, 耗时:0.00分/0.74分 | step: 12320 | performance: 8.3 | accuracy: 0.47 | loss: 3.47
update:225/2000, 耗时:0.00分/0.76分 | step: 12600 | performance: 1.7 | accuracy: 0.46 | loss: 3.68
update:230/2000, 耗时:0.00分/0.78分 | step: 12880 | performance: 1.1 | accuracy: 0.46 | loss: 2.35
update:235/2000, 耗时:0.00分/0.79分 | step: 13160 | performance: 1.1 | accuracy: 0.46 | loss: 1.10
update:240/2000, 耗时:0.00分/0.81分 | step: 13440 | performance: 1.3 | accuracy: 0.46 | loss: 1.63
update:245/2000, 耗时:0.00分/0.82分 | step: 13720 | performance: 1.6 | accuracy: 0.46 | loss: 1.04
update:250/2000, 耗时:0.00分/0.84分 | step: 14000 | performance: 0.6 | accuracy: 0.46 | loss: 7.27
update:255/2000, 耗时:0.00分/0.86分 | step: 14280 | performance: 0.4 | accuracy: 0.46 | loss: 5.21
update:260/2000, 耗时:0.00分/0.87分 | step: 14560 | performance: 0.5 | accuracy: 0.46 | loss: 1.77
update:265/2000, 耗时:0.00分/0.89分 | step: 14840 | performance: 0.6 | accuracy: 0.46 | loss: 2.30
update:270/2000, 耗时:0.00分/0.91分 | step: 15120 | performance: 0.8 | accuracy: 0.46 | loss: 1.30
update:275/2000, 耗时:0.00分/0.92分 | step: 15400 | performance: 0.3 | accuracy: 0.45 | loss: 2.44
update:280/2000, 耗时:0.00分/0.94分 | step: 15680 | performance: 0.1 | accuracy: 0.45 | loss: 0.83
update:285/2000, 耗时:0.00分/0.96分 | step: 15960 | performance: 0.0 | accuracy: 0.44 | loss: 3.18
update:290/2000, 耗时:0.00分/0.97分 | step: 16240 | performance: 0.0 | accuracy: 0.44 | loss: 8.77
update:295/2000, 耗时:0.00分/0.99分 | step: 16520 | performance: 0.0 | accuracy: 0.44 | loss: 7.71
update:300/2000, 耗时:0.00分/1.00分 | step: 16800 | performance: 0.0 | accuracy: 0.44 | loss: 2.51
update:305/2000, 耗时:0.00分/1.02分 | step: 17080 | performance: 0.0 | accuracy: 0.44 | loss: 3.25
update:310/2000, 耗时:0.00分/1.04分 | step: 17360 | performance: 0.0 | accuracy: 0.44 | loss: 5.92
update:315/2000, 耗时:0.00分/1.05分 | step: 17640 | performance: 0.0 | accuracy: 0.45 | loss: 5.95
update:320/2000, 耗时:0.00分/1.07分 | step: 17920 | performance: 0.0 | accuracy: 0.45 | loss: 2.99
update:325/2000, 耗时:0.00分/1.08分 | step: 18200 | performance: 0.0 | accuracy: 0.45 | loss: 4.29
update:330/2000, 耗时:0.00分/1.10分 | step: 18480 | performance: 0.0 | accuracy: 0.45 | loss: 1.62
update:335/2000, 耗时:0.00分/1.12分 | step: 18760 | performance: 0.0 | accuracy: 0.44 | loss: 3.33
update:340/2000, 耗时:0.00分/1.13分 | step: 19040 | performance: 0.0 | accuracy: 0.44 | loss: 1.33
update:345/2000, 耗时:0.00分/1.15分 | step: 19320 | performance: 0.0 | accuracy: 0.44 | loss: 1.23
update:350/2000, 耗时:0.00分/1.17分 | step: 19600 | performance: 0.0 | accuracy: 0.44 | loss: 2.27
update:355/2000, 耗时:0.00分/1.18分 | step: 19880 | performance: 0.0 | accuracy: 0.45 | loss: 10.28
update:360/2000, 耗时:0.00分/1.20分 | step: 20160 | performance: 0.0 | accuracy: 0.45 | loss: 0.98
update:365/2000, 耗时:0.00分/1.22分 | step: 20440 | performance: 0.0 | accuracy: 0.45 | loss: 5.86
update:370/2000, 耗时:0.00分/1.23分 | step: 20720 | performance: 0.0 | accuracy: 0.45 | loss: 4.88
update:375/2000, 耗时:0.00分/1.25分 | step: 21000 | performance: 0.0 | accuracy: 0.45 | loss: 4.92
update:380/2000, 耗时:0.00分/1.26分 | step: 21280 | performance: 0.0 | accuracy: 0.46 | loss: 2.01
update:385/2000, 耗时:0.00分/1.28分 | step: 21560 | performance: 0.0 | accuracy: 0.46 | loss: 2.57
update:390/2000, 耗时:0.00分/1.30分 | step: 21840 | performance: 0.0 | accuracy: 0.45 | loss: 2.90
update:395/2000, 耗时:0.00分/1.31分 | step: 22120 | performance: 0.0 | accuracy: 0.45 | loss: 3.04
update:400/2000, 耗时:0.00分/1.33分 | step: 22400 | performance: 0.0 | accuracy: 0.45 | loss: 1.69
update:405/2000, 耗时:0.00分/1.34分 | step: 22680 | performance: 0.0 | accuracy: 0.45 | loss: 2.28
update:410/2000, 耗时:0.00分/1.36分 | step: 22960 | performance: 0.0 | accuracy: 0.45 | loss: 8.37
update:415/2000, 耗时:0.00分/1.38分 | step: 23240 | performance: 0.0 | accuracy: 0.45 | loss: 2.34
update:420/2000, 耗时:0.00分/1.39分 | step: 23520 | performance: 0.0 | accuracy: 0.45 | loss: 2.07
update:425/2000, 耗时:0.00分/1.41分 | step: 23800 | performance: 0.0 | accuracy: 0.46 | loss: 1.41
update:430/2000, 耗时:0.00分/1.43分 | step: 24080 | performance: 0.0 | accuracy: 0.46 | loss: 5.35
update:435/2000, 耗时:0.00分/1.44分 | step: 24360 | performance: 0.0 | accuracy: 0.45 | loss: 5.12
update:440/2000, 耗时:0.00分/1.46分 | step: 24640 | performance: 0.0 | accuracy: 0.45 | loss: 0.50
update:445/2000, 耗时:0.00分/1.47分 | step: 24920 | performance: 0.0 | accuracy: 0.45 | loss: 1.83
update:450/2000, 耗时:0.00分/1.49分 | step: 25200 | performance: 0.0 | accuracy: 0.45 | loss: 2.57
update:455/2000, 耗时:0.00分/1.51分 | step: 25480 | performance: 0.0 | accuracy: 0.45 | loss: 12.05
update:460/2000, 耗时:0.00分/1.52分 | step: 25760 | performance: 0.0 | accuracy: 0.45 | loss: 1.95
update:465/2000, 耗时:0.00分/1.54分 | step: 26040 | performance: 0.0 | accuracy: 0.45 | loss: 5.28
update:470/2000, 耗时:0.00分/1.55分 | step: 26320 | performance: 0.0 | accuracy: 0.45 | loss: 1.47
update:475/2000, 耗时:0.00分/1.57分 | step: 26600 | performance: 0.0 | accuracy: 0.45 | loss: 0.41
update:480/2000, 耗时:0.00分/1.59分 | step: 26880 | performance: 0.0 | accuracy: 0.45 | loss: 1.67
update:485/2000, 耗时:0.00分/1.60分 | step: 27160 | performance: 0.0 | accuracy: 0.45 | loss: 6.90
update:490/2000, 耗时:0.00分/1.62分 | step: 27440 | performance: 0.0 | accuracy: 0.45 | loss: 0.86
update:495/2000, 耗时:0.00分/1.64分 | step: 27720 | performance: 0.0 | accuracy: 0.45 | loss: 2.27
update:500/2000, 耗时:0.00分/1.66分 | step: 28000 | performance: 0.0 | accuracy: 0.45 | loss: 3.52
Saving PPO weights in both H5 format and checkpoint @ update:504 
update:505/2000, 耗时:0.00分/1.68分 | step: 28280 | performance: 0.4 | accuracy: 0.20 | loss: 1.41
update:510/2000, 耗时:0.00分/1.69分 | step: 28560 | performance: 0.1 | accuracy: 0.24 | loss: 6.67
update:515/2000, 耗时:0.00分/1.71分 | step: 28840 | performance: 0.2 | accuracy: 0.39 | loss: 5.71
update:520/2000, 耗时:0.00分/1.72分 | step: 29120 | performance: 0.5 | accuracy: 0.48 | loss: 1.79
update:525/2000, 耗时:0.00分/1.74分 | step: 29400 | performance: 0.2 | accuracy: 0.43 | loss: 2.00
update:530/2000, 耗时:0.00分/1.75分 | step: 29680 | performance: 0.1 | accuracy: 0.43 | loss: 0.99
update:535/2000, 耗时:0.00分/1.77分 | step: 29960 | performance: 0.0 | accuracy: 0.40 | loss: 2.12
update:540/2000, 耗时:0.00分/1.79分 | step: 30240 | performance: 0.0 | accuracy: 0.43 | loss: 2.95
update:545/2000, 耗时:0.00分/1.80分 | step: 30520 | performance: 0.2 | accuracy: 0.46 | loss: 0.58
update:550/2000, 耗时:0.00分/1.82分 | step: 30800 | performance: 0.0 | accuracy: 0.43 | loss: 1.32
update:555/2000, 耗时:0.00分/1.84分 | step: 31080 | performance: 0.1 | accuracy: 0.46 | loss: 4.92
update:560/2000, 耗时:0.00分/1.85分 | step: 31360 | performance: 0.0 | accuracy: 0.46 | loss: 2.17
update:565/2000, 耗时:0.00分/1.87分 | step: 31640 | performance: 0.0 | accuracy: 0.46 | loss: 2.74
update:570/2000, 耗时:0.00分/1.88分 | step: 31920 | performance: 0.0 | accuracy: 0.46 | loss: 1.95
update:575/2000, 耗时:0.00分/1.90分 | step: 32200 | performance: 0.0 | accuracy: 0.46 | loss: 0.74
update:580/2000, 耗时:0.00分/1.91分 | step: 32480 | performance: 0.0 | accuracy: 0.44 | loss: 7.05
update:585/2000, 耗时:0.00分/1.93分 | step: 32760 | performance: 0.0 | accuracy: 0.43 | loss: 1.63
update:590/2000, 耗时:0.00分/1.95分 | step: 33040 | performance: 0.0 | accuracy: 0.44 | loss: 2.66
update:595/2000, 耗时:0.00分/1.96分 | step: 33320 | performance: 0.0 | accuracy: 0.44 | loss: 1.48
update:600/2000, 耗时:0.00分/1.98分 | step: 33600 | performance: 0.0 | accuracy: 0.44 | loss: 1.48
update:605/2000, 耗时:0.00分/1.99分 | step: 33880 | performance: 0.0 | accuracy: 0.45 | loss: 1.04
update:610/2000, 耗时:0.00分/2.01分 | step: 34160 | performance: 0.0 | accuracy: 0.45 | loss: 1.32
update:615/2000, 耗时:0.00分/2.03分 | step: 34440 | performance: 0.0 | accuracy: 0.46 | loss: 4.67
update:620/2000, 耗时:0.00分/2.04分 | step: 34720 | performance: 0.0 | accuracy: 0.47 | loss: 3.90
update:625/2000, 耗时:0.00分/2.06分 | step: 35000 | performance: 0.0 | accuracy: 0.48 | loss: 1.13
update:630/2000, 耗时:0.00分/2.07分 | step: 35280 | performance: 0.1 | accuracy: 0.49 | loss: 2.67
update:635/2000, 耗时:0.00分/2.09分 | step: 35560 | performance: 0.1 | accuracy: 0.49 | loss: 0.54
update:640/2000, 耗时:0.00分/2.11分 | step: 35840 | performance: 1.0 | accuracy: 0.51 | loss: 4.31
update:645/2000, 耗时:0.00分/2.12分 | step: 36120 | performance: 0.4 | accuracy: 0.51 | loss: 12.82
update:650/2000, 耗时:0.00分/2.14分 | step: 36400 | performance: 0.3 | accuracy: 0.50 | loss: 4.50
update:655/2000, 耗时:0.00分/2.15分 | step: 36680 | performance: 0.3 | accuracy: 0.50 | loss: 2.89
update:660/2000, 耗时:0.00分/2.17分 | step: 36960 | performance: 0.3 | accuracy: 0.50 | loss: 2.63
update:665/2000, 耗时:0.00分/2.18分 | step: 37240 | performance: 0.2 | accuracy: 0.49 | loss: 2.89
update:670/2000, 耗时:0.00分/2.20分 | step: 37520 | performance: 0.1 | accuracy: 0.49 | loss: 4.53
update:675/2000, 耗时:0.00分/2.22分 | step: 37800 | performance: 0.1 | accuracy: 0.49 | loss: 11.28
update:680/2000, 耗时:0.00分/2.23分 | step: 38080 | performance: 0.1 | accuracy: 0.49 | loss: 2.83
update:685/2000, 耗时:0.00分/2.25分 | step: 38360 | performance: 0.0 | accuracy: 0.48 | loss: 2.47
update:690/2000, 耗时:0.00分/2.26分 | step: 38640 | performance: 0.0 | accuracy: 0.48 | loss: 3.72
update:695/2000, 耗时:0.00分/2.28分 | step: 38920 | performance: 0.0 | accuracy: 0.48 | loss: 6.09
update:700/2000, 耗时:0.00分/2.29分 | step: 39200 | performance: 0.1 | accuracy: 0.48 | loss: 3.67
update:705/2000, 耗时:0.00分/2.31分 | step: 39480 | performance: 0.2 | accuracy: 0.49 | loss: 2.77
update:710/2000, 耗时:0.00分/2.33分 | step: 39760 | performance: 0.1 | accuracy: 0.49 | loss: 8.06
update:715/2000, 耗时:0.00分/2.34分 | step: 40040 | performance: 0.0 | accuracy: 0.48 | loss: 5.76
update:720/2000, 耗时:0.00分/2.36分 | step: 40320 | performance: 0.0 | accuracy: 0.49 | loss: 6.20
update:725/2000, 耗时:0.00分/2.37分 | step: 40600 | performance: 0.0 | accuracy: 0.49 | loss: 1.64
update:730/2000, 耗时:0.00分/2.39分 | step: 40880 | performance: 0.1 | accuracy: 0.50 | loss: 5.29
update:735/2000, 耗时:0.00分/2.41分 | step: 41160 | performance: 0.1 | accuracy: 0.50 | loss: 5.43
update:740/2000, 耗时:0.00分/2.42分 | step: 41440 | performance: 0.1 | accuracy: 0.50 | loss: 1.49
update:745/2000, 耗时:0.00分/2.44分 | step: 41720 | performance: 0.1 | accuracy: 0.50 | loss: 2.36
update:750/2000, 耗时:0.00分/2.45分 | step: 42000 | performance: 0.1 | accuracy: 0.50 | loss: 3.17
update:755/2000, 耗时:0.00分/2.47分 | step: 42280 | performance: 0.2 | accuracy: 0.50 | loss: 1.00
update:760/2000, 耗时:0.00分/2.48分 | step: 42560 | performance: 0.3 | accuracy: 0.50 | loss: 2.91
update:765/2000, 耗时:0.00分/2.50分 | step: 42840 | performance: 0.1 | accuracy: 0.50 | loss: 3.60
update:770/2000, 耗时:0.00分/2.51分 | step: 43120 | performance: 0.1 | accuracy: 0.50 | loss: 1.75
update:775/2000, 耗时:0.00分/2.53分 | step: 43400 | performance: 0.2 | accuracy: 0.51 | loss: 4.12
update:780/2000, 耗时:0.00分/2.54分 | step: 43680 | performance: 0.6 | accuracy: 0.51 | loss: 0.77
update:785/2000, 耗时:0.00分/2.56分 | step: 43960 | performance: 1.9 | accuracy: 0.51 | loss: 0.37
update:790/2000, 耗时:0.00分/2.58分 | step: 44240 | performance: 4.7 | accuracy: 0.52 | loss: 2.55
update:795/2000, 耗时:0.00分/2.59分 | step: 44520 | performance: 14.5 | accuracy: 0.52 | loss: 1.39
update:800/2000, 耗时:0.00分/2.61分 | step: 44800 | performance: 288.0 | accuracy: 0.53 | loss: 3.94
update:805/2000, 耗时:0.00分/2.62分 | step: 45080 | performance: 100.1 | accuracy: 0.52 | loss: 1.26
update:810/2000, 耗时:0.00分/2.64分 | step: 45360 | performance: 868.8 | accuracy: 0.53 | loss: 3.85
update:815/2000, 耗时:0.00分/2.65分 | step: 45640 | performance: 880.9 | accuracy: 0.53 | loss: 3.90
update:820/2000, 耗时:0.00分/2.67分 | step: 45920 | performance: 2891.4 | accuracy: 0.53 | loss: 1.38
update:825/2000, 耗时:0.00分/2.69分 | step: 46200 | performance: 2870.0 | accuracy: 0.53 | loss: 3.38
update:830/2000, 耗时:0.00分/2.70分 | step: 46480 | performance: 1551.9 | accuracy: 0.53 | loss: 8.49
update:835/2000, 耗时:0.00分/2.72分 | step: 46760 | performance: 2499.6 | accuracy: 0.53 | loss: 0.89
update:840/2000, 耗时:0.00分/2.73分 | step: 47040 | performance: 204.3 | accuracy: 0.53 | loss: 1.99
update:845/2000, 耗时:0.00分/2.75分 | step: 47320 | performance: 206.0 | accuracy: 0.53 | loss: 2.12
update:850/2000, 耗时:0.00分/2.76分 | step: 47600 | performance: 97.2 | accuracy: 0.52 | loss: 2.32
update:855/2000, 耗时:0.00分/2.78分 | step: 47880 | performance: 55.6 | accuracy: 0.52 | loss: 1.73
update:860/2000, 耗时:0.00分/2.79分 | step: 48160 | performance: 240.6 | accuracy: 0.52 | loss: 2.05
update:865/2000, 耗时:0.00分/2.81分 | step: 48440 | performance: 829.1 | accuracy: 0.53 | loss: 4.47
update:870/2000, 耗时:0.00分/2.83分 | step: 48720 | performance: 524.0 | accuracy: 0.53 | loss: 9.05
update:875/2000, 耗时:0.00分/2.84分 | step: 49000 | performance: 326.5 | accuracy: 0.52 | loss: 1.75
update:880/2000, 耗时:0.00分/2.86分 | step: 49280 | performance: 1971.3 | accuracy: 0.53 | loss: 1.10
update:885/2000, 耗时:0.00分/2.87分 | step: 49560 | performance: 2691.2 | accuracy: 0.53 | loss: 0.38
update:890/2000, 耗时:0.00分/2.89分 | step: 49840 | performance: 1954.7 | accuracy: 0.53 | loss: 8.30
update:895/2000, 耗时:0.00分/2.90分 | step: 50120 | performance: 695.5 | accuracy: 0.52 | loss: 8.16
update:900/2000, 耗时:0.00分/2.92分 | step: 50400 | performance: 675.4 | accuracy: 0.52 | loss: 4.90
update:905/2000, 耗时:0.00分/2.93分 | step: 50680 | performance: 228.1 | accuracy: 0.52 | loss: 1.92
update:910/2000, 耗时:0.00分/2.95分 | step: 50960 | performance: 108.9 | accuracy: 0.52 | loss: 7.18
update:915/2000, 耗时:0.00分/2.97分 | step: 51240 | performance: 239.4 | accuracy: 0.52 | loss: 2.20
update:920/2000, 耗时:0.00分/2.98分 | step: 51520 | performance: 224.9 | accuracy: 0.52 | loss: 3.12
update:925/2000, 耗时:0.00分/3.00分 | step: 51800 | performance: 196.5 | accuracy: 0.52 | loss: 1.49
update:930/2000, 耗时:0.00分/3.01分 | step: 52080 | performance: 242.7 | accuracy: 0.52 | loss: 5.68
update:935/2000, 耗时:0.00分/3.03分 | step: 52360 | performance: 136.3 | accuracy: 0.52 | loss: 2.10
update:940/2000, 耗时:0.00分/3.04分 | step: 52640 | performance: 22.9 | accuracy: 0.52 | loss: 5.47
update:945/2000, 耗时:0.00分/3.06分 | step: 52920 | performance: 25.0 | accuracy: 0.51 | loss: 3.79
update:950/2000, 耗时:0.00分/3.08分 | step: 53200 | performance: 2.8 | accuracy: 0.51 | loss: 8.17
update:955/2000, 耗时:0.00分/3.09分 | step: 53480 | performance: 1.7 | accuracy: 0.51 | loss: 1.83
update:960/2000, 耗时:0.00分/3.11分 | step: 53760 | performance: 4.5 | accuracy: 0.51 | loss: 4.32
update:965/2000, 耗时:0.00分/3.12分 | step: 54040 | performance: 4.6 | accuracy: 0.51 | loss: 3.13
update:970/2000, 耗时:0.00分/3.14分 | step: 54320 | performance: 2.5 | accuracy: 0.51 | loss: 0.56
update:975/2000, 耗时:0.00分/3.15分 | step: 54600 | performance: 3.0 | accuracy: 0.51 | loss: 7.42
update:980/2000, 耗时:0.00分/3.17分 | step: 54880 | performance: 1.3 | accuracy: 0.51 | loss: 1.12
update:985/2000, 耗时:0.00分/3.18分 | step: 55160 | performance: 1.3 | accuracy: 0.51 | loss: 0.58
update:990/2000, 耗时:0.00分/3.20分 | step: 55440 | performance: 1.7 | accuracy: 0.51 | loss: 1.50
update:995/2000, 耗时:0.00分/3.21分 | step: 55720 | performance: 0.4 | accuracy: 0.51 | loss: 2.99
update:1000/2000, 耗时:0.00分/3.23分 | step: 56000 | performance: 0.5 | accuracy: 0.51 | loss: 1.06
update:1005/2000, 耗时:0.00分/3.25分 | step: 56280 | performance: 0.5 | accuracy: 0.51 | loss: 0.58
Saving PPO weights in both H5 format and checkpoint @ update:1008 
update:1010/2000, 耗时:0.00分/3.26分 | step: 56560 | performance: 0.2 | accuracy: 0.15 | loss: 6.36
update:1015/2000, 耗时:0.00分/3.28分 | step: 56840 | performance: 0.1 | accuracy: 0.29 | loss: 2.64
update:1020/2000, 耗时:0.00分/3.29分 | step: 57120 | performance: 0.3 | accuracy: 0.42 | loss: 6.52
update:1025/2000, 耗时:0.00分/3.31分 | step: 57400 | performance: 0.4 | accuracy: 0.46 | loss: 4.88
update:1030/2000, 耗时:0.00分/3.33分 | step: 57680 | performance: 0.1 | accuracy: 0.41 | loss: 4.52
update:1035/2000, 耗时:0.00分/3.34分 | step: 57960 | performance: 0.0 | accuracy: 0.41 | loss: 6.82
update:1040/2000, 耗时:0.00分/3.36分 | step: 58240 | performance: 0.0 | accuracy: 0.41 | loss: 2.38
update:1045/2000, 耗时:0.00分/3.37分 | step: 58520 | performance: 0.1 | accuracy: 0.44 | loss: 9.24
update:1050/2000, 耗时:0.00分/3.39分 | step: 58800 | performance: 0.1 | accuracy: 0.45 | loss: 4.75
update:1055/2000, 耗时:0.00分/3.40分 | step: 59080 | performance: 0.0 | accuracy: 0.43 | loss: 0.55
update:1060/2000, 耗时:0.00分/3.42分 | step: 59360 | performance: 0.0 | accuracy: 0.45 | loss: 6.15
update:1065/2000, 耗时:0.00分/3.43分 | step: 59640 | performance: 0.0 | accuracy: 0.46 | loss: 3.08
update:1070/2000, 耗时:0.00分/3.45分 | step: 59920 | performance: 0.0 | accuracy: 0.46 | loss: 2.04
update:1075/2000, 耗时:0.00分/3.46分 | step: 60200 | performance: 0.0 | accuracy: 0.47 | loss: 4.91
update:1080/2000, 耗时:0.00分/3.48分 | step: 60480 | performance: 0.1 | accuracy: 0.46 | loss: 5.02
update:1085/2000, 耗时:0.00分/3.49分 | step: 60760 | performance: 0.1 | accuracy: 0.47 | loss: 4.15
update:1090/2000, 耗时:0.00分/3.51分 | step: 61040 | performance: 0.1 | accuracy: 0.48 | loss: 2.56
update:1095/2000, 耗时:0.00分/3.52分 | step: 61320 | performance: 0.1 | accuracy: 0.47 | loss: 2.71
update:1100/2000, 耗时:0.00分/3.54分 | step: 61600 | performance: 0.1 | accuracy: 0.47 | loss: 0.59
update:1105/2000, 耗时:0.00分/3.55分 | step: 61880 | performance: 0.1 | accuracy: 0.47 | loss: 1.63
update:1110/2000, 耗时:0.00分/3.57分 | step: 62160 | performance: 0.1 | accuracy: 0.47 | loss: 0.40
update:1115/2000, 耗时:0.00分/3.58分 | step: 62440 | performance: 0.1 | accuracy: 0.46 | loss: 1.58
update:1120/2000, 耗时:0.00分/3.60分 | step: 62720 | performance: 0.0 | accuracy: 0.46 | loss: 5.13
update:1125/2000, 耗时:0.00分/3.62分 | step: 63000 | performance: 0.0 | accuracy: 0.46 | loss: 2.05
update:1130/2000, 耗时:0.00分/3.63分 | step: 63280 | performance: 0.1 | accuracy: 0.47 | loss: 7.98
update:1135/2000, 耗时:0.00分/3.65分 | step: 63560 | performance: 0.6 | accuracy: 0.48 | loss: 5.46
update:1140/2000, 耗时:0.00分/3.66分 | step: 63840 | performance: 0.6 | accuracy: 0.48 | loss: 6.15
update:1145/2000, 耗时:0.00分/3.68分 | step: 64120 | performance: 2.4 | accuracy: 0.49 | loss: 7.04
update:1150/2000, 耗时:0.00分/3.69分 | step: 64400 | performance: 1.0 | accuracy: 0.49 | loss: 1.88
update:1155/2000, 耗时:0.00分/3.71分 | step: 64680 | performance: 1.7 | accuracy: 0.49 | loss: 6.82
update:1160/2000, 耗时:0.00分/3.72分 | step: 64960 | performance: 0.7 | accuracy: 0.48 | loss: 2.41
update:1165/2000, 耗时:0.00分/3.74分 | step: 65240 | performance: 0.7 | accuracy: 0.48 | loss: 3.00
update:1170/2000, 耗时:0.00分/3.75分 | step: 65520 | performance: 0.2 | accuracy: 0.47 | loss: 5.60
update:1175/2000, 耗时:0.00分/3.77分 | step: 65800 | performance: 0.2 | accuracy: 0.48 | loss: 1.68
update:1180/2000, 耗时:0.00分/3.78分 | step: 66080 | performance: 0.3 | accuracy: 0.48 | loss: 1.44
update:1185/2000, 耗时:0.00分/3.80分 | step: 66360 | performance: 0.3 | accuracy: 0.48 | loss: 4.67
update:1190/2000, 耗时:0.00分/3.82分 | step: 66640 | performance: 0.4 | accuracy: 0.48 | loss: 3.77
update:1195/2000, 耗时:0.00分/3.83分 | step: 66920 | performance: 0.5 | accuracy: 0.48 | loss: 2.43
update:1200/2000, 耗时:0.00分/3.85分 | step: 67200 | performance: 0.3 | accuracy: 0.47 | loss: 0.42
update:1205/2000, 耗时:0.00分/3.86分 | step: 67480 | performance: 0.2 | accuracy: 0.46 | loss: 0.49
update:1210/2000, 耗时:0.00分/3.88分 | step: 67760 | performance: 0.2 | accuracy: 0.46 | loss: 1.60
update:1215/2000, 耗时:0.00分/3.89分 | step: 68040 | performance: 0.1 | accuracy: 0.46 | loss: 2.11
update:1220/2000, 耗时:0.00分/3.91分 | step: 68320 | performance: 0.0 | accuracy: 0.46 | loss: 3.77
update:1225/2000, 耗时:0.00分/3.92分 | step: 68600 | performance: 0.0 | accuracy: 0.45 | loss: 3.37
update:1230/2000, 耗时:0.00分/3.94分 | step: 68880 | performance: 0.0 | accuracy: 0.45 | loss: 3.32
update:1235/2000, 耗时:0.00分/3.95分 | step: 69160 | performance: 0.1 | accuracy: 0.46 | loss: 3.46
update:1240/2000, 耗时:0.00分/3.97分 | step: 69440 | performance: 0.1 | accuracy: 0.46 | loss: 5.34
update:1245/2000, 耗时:0.00分/3.98分 | step: 69720 | performance: 0.1 | accuracy: 0.46 | loss: 1.33
update:1250/2000, 耗时:0.00分/4.00分 | step: 70000 | performance: 0.1 | accuracy: 0.46 | loss: 2.97
update:1255/2000, 耗时:0.00分/4.02分 | step: 70280 | performance: 0.1 | accuracy: 0.46 | loss: 2.40
update:1260/2000, 耗时:0.00分/4.03分 | step: 70560 | performance: 0.4 | accuracy: 0.47 | loss: 2.93
update:1265/2000, 耗时:0.00分/4.05分 | step: 70840 | performance: 0.3 | accuracy: 0.47 | loss: 0.99
update:1270/2000, 耗时:0.00分/4.06分 | step: 71120 | performance: 0.2 | accuracy: 0.47 | loss: 2.19
update:1275/2000, 耗时:0.00分/4.08分 | step: 71400 | performance: 0.2 | accuracy: 0.47 | loss: 1.38
update:1280/2000, 耗时:0.00分/4.09分 | step: 71680 | performance: 0.3 | accuracy: 0.47 | loss: 1.91
update:1285/2000, 耗时:0.00分/4.11分 | step: 71960 | performance: 0.8 | accuracy: 0.48 | loss: 0.44
update:1290/2000, 耗时:0.00分/4.13分 | step: 72240 | performance: 4.2 | accuracy: 0.49 | loss: 2.02
update:1295/2000, 耗时:0.00分/4.14分 | step: 72520 | performance: 4.5 | accuracy: 0.49 | loss: 4.64
update:1300/2000, 耗时:0.00分/4.16分 | step: 72800 | performance: 27.0 | accuracy: 0.49 | loss: 3.38
update:1305/2000, 耗时:0.00分/4.17分 | step: 73080 | performance: 187.0 | accuracy: 0.50 | loss: 19.43
update:1310/2000, 耗时:0.00分/4.19分 | step: 73360 | performance: 157.6 | accuracy: 0.49 | loss: 3.21
update:1315/2000, 耗时:0.00分/4.20分 | step: 73640 | performance: 1369.9 | accuracy: 0.50 | loss: 0.81
update:1320/2000, 耗时:0.00分/4.22分 | step: 73920 | performance: 1201.9 | accuracy: 0.50 | loss: 3.17
update:1325/2000, 耗时:0.00分/4.24分 | step: 74200 | performance: 2363.7 | accuracy: 0.50 | loss: 6.58
update:1330/2000, 耗时:0.00分/4.25分 | step: 74480 | performance: 3585.7 | accuracy: 0.50 | loss: 1.57
update:1335/2000, 耗时:0.00分/4.27分 | step: 74760 | performance: 2139.3 | accuracy: 0.50 | loss: 3.50
update:1340/2000, 耗时:0.00分/4.28分 | step: 75040 | performance: 1096.3 | accuracy: 0.50 | loss: 8.50
update:1345/2000, 耗时:0.00分/4.30分 | step: 75320 | performance: 180.2 | accuracy: 0.50 | loss: 1.82
update:1350/2000, 耗时:0.00分/4.31分 | step: 75600 | performance: 130.1 | accuracy: 0.50 | loss: 6.79
update:1355/2000, 耗时:0.00分/4.33分 | step: 75880 | performance: 108.6 | accuracy: 0.49 | loss: 0.16
update:1360/2000, 耗时:0.00分/4.34分 | step: 76160 | performance: 107.3 | accuracy: 0.49 | loss: 0.02
update:1365/2000, 耗时:0.00分/4.36分 | step: 76440 | performance: 108.1 | accuracy: 0.48 | loss: 1.17
update:1370/2000, 耗时:0.00分/4.37分 | step: 76720 | performance: 130.7 | accuracy: 0.48 | loss: 0.91
update:1375/2000, 耗时:0.00分/4.39分 | step: 77000 | performance: 98.7 | accuracy: 0.48 | loss: 1.83
update:1380/2000, 耗时:0.00分/4.40分 | step: 77280 | performance: 98.4 | accuracy: 0.48 | loss: 5.28
update:1385/2000, 耗时:0.00分/4.42分 | step: 77560 | performance: 554.0 | accuracy: 0.49 | loss: 2.43
update:1390/2000, 耗时:0.00分/4.43分 | step: 77840 | performance: 442.9 | accuracy: 0.49 | loss: 2.56
update:1395/2000, 耗时:0.00分/4.45分 | step: 78120 | performance: 273.1 | accuracy: 0.48 | loss: 2.99
update:1400/2000, 耗时:0.00分/4.46分 | step: 78400 | performance: 100.1 | accuracy: 0.48 | loss: 3.67
update:1405/2000, 耗时:0.00分/4.48分 | step: 78680 | performance: 89.5 | accuracy: 0.48 | loss: 4.79
update:1410/2000, 耗时:0.00分/4.49分 | step: 78960 | performance: 49.0 | accuracy: 0.48 | loss: 0.41
update:1415/2000, 耗时:0.00分/4.51分 | step: 79240 | performance: 72.8 | accuracy: 0.48 | loss: 1.69
update:1420/2000, 耗时:0.00分/4.52分 | step: 79520 | performance: 70.2 | accuracy: 0.48 | loss: 4.58
update:1425/2000, 耗时:0.00分/4.54分 | step: 79800 | performance: 66.1 | accuracy: 0.48 | loss: 2.68
update:1430/2000, 耗时:0.00分/4.55分 | step: 80080 | performance: 96.9 | accuracy: 0.48 | loss: 3.41
update:1435/2000, 耗时:0.00分/4.57分 | step: 80360 | performance: 52.5 | accuracy: 0.48 | loss: 4.38
update:1440/2000, 耗时:0.00分/4.58分 | step: 80640 | performance: 38.7 | accuracy: 0.47 | loss: 1.44
update:1445/2000, 耗时:0.00分/4.60分 | step: 80920 | performance: 8.1 | accuracy: 0.47 | loss: 1.28
update:1450/2000, 耗时:0.00分/4.62分 | step: 81200 | performance: 7.8 | accuracy: 0.47 | loss: 2.44
update:1455/2000, 耗时:0.00分/4.63分 | step: 81480 | performance: 0.8 | accuracy: 0.47 | loss: 3.16
update:1460/2000, 耗时:0.00分/4.65分 | step: 81760 | performance: 1.0 | accuracy: 0.47 | loss: 6.81
update:1465/2000, 耗时:0.00分/4.66分 | step: 82040 | performance: 1.0 | accuracy: 0.47 | loss: 3.47
update:1470/2000, 耗时:0.00分/4.68分 | step: 82320 | performance: 1.9 | accuracy: 0.47 | loss: 3.52
update:1475/2000, 耗时:0.00分/4.69分 | step: 82600 | performance: 0.6 | accuracy: 0.47 | loss: 1.23
update:1480/2000, 耗时:0.00分/4.71分 | step: 82880 | performance: 0.5 | accuracy: 0.47 | loss: 5.17
update:1485/2000, 耗时:0.00分/4.73分 | step: 83160 | performance: 0.5 | accuracy: 0.47 | loss: 2.92
update:1490/2000, 耗时:0.00分/4.74分 | step: 83440 | performance: 0.4 | accuracy: 0.47 | loss: 1.38
update:1495/2000, 耗时:0.00分/4.76分 | step: 83720 | performance: 0.3 | accuracy: 0.47 | loss: 5.56
update:1500/2000, 耗时:0.00分/4.77分 | step: 84000 | performance: 0.1 | accuracy: 0.47 | loss: 1.34
update:1505/2000, 耗时:0.00分/4.79分 | step: 84280 | performance: 0.2 | accuracy: 0.47 | loss: 2.38
update:1510/2000, 耗时:0.00分/4.81分 | step: 84560 | performance: 0.1 | accuracy: 0.47 | loss: 1.77
Saving PPO weights in both H5 format and checkpoint @ update:1511 
Saving PPO weights in both H5 format and checkpoint @ update:1514 
update:1515/2000, 耗时:0.00分/4.83分 | step: 84840 | performance: 0.2 | accuracy: 0.23 | loss: 1.03
Saving PPO weights in both H5 format and checkpoint @ update:1516 
Saving PPO weights in both H5 format and checkpoint @ update:1517 
step: 85004 | worker_3@n_step_6: average total_reward after train data exhaustion : -21.8 | max total_reward: 129.9
step: 85005 | worker_4@n_step_6: average total_reward after train data exhaustion : -21.4 | max total_reward: 129.9
step: 85007 | worker_6@n_step_6: average total_reward after train data exhaustion : -21.1 | max total_reward: 129.9
Saving PPO weights in both H5 format and checkpoint @ update:1518 
Saving PPO weights in both H5 format and checkpoint @ update:1519 
update:1520/2000, 耗时:0.00分/4.87分 | step: 85120 | performance: 0.1 | accuracy: 0.11 | loss: 0.03
step: 85171 | worker_2@n_step_6: average total_reward after train data exhaustion : -18.7 | max total_reward: 129.9
Saving PPO weights in both H5 format and checkpoint @ update:1521 
Saving PPO weights in both H5 format and checkpoint @ update:1522 
Saving PPO weights in both H5 format and checkpoint @ update:1523 
Saving PPO weights in both H5 format and checkpoint @ update:1524 
update:1525/2000, 耗时:0.00分/4.90分 | step: 85400 | performance: 0.2 | accuracy: 0.12 | loss: 0.18
Saving PPO weights in both H5 format and checkpoint @ update:1525 
Saving PPO weights in both H5 format and checkpoint @ update:1526 
Saving PPO weights in both H5 format and checkpoint @ update:1527 
step: 85568 | worker_7@n_step_6: average total_reward after train data exhaustion : 28.1 | max total_reward: 129.9
Saving PPO weights in both H5 format and checkpoint @ update:1528 
step: 85674 | worker_1@n_step_6: average total_reward after train data exhaustion : 20.3 | max total_reward: 129.9
update:1530/2000, 耗时:0.00分/4.94分 | step: 85680 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 85902 | worker_5@n_step_6: average total_reward after train data exhaustion : -4.2 | max total_reward: 129.9
step: 85956 | worker_3@n_step_6: average total_reward after train data exhaustion : -3.6 | max total_reward: 129.9
step: 85957 | worker_4@n_step_6: average total_reward after train data exhaustion : -3.2 | max total_reward: 129.9
step: 85959 | worker_6@n_step_6: average total_reward after train data exhaustion : -2.9 | max total_reward: 129.9
update:1535/2000, 耗时:0.00分/4.96分 | step: 85960 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 86121 | worker_0@n_step_6: average total_reward after train data exhaustion : -1.2 | max total_reward: 129.9
step: 86123 | worker_2@n_step_6: average total_reward after train data exhaustion : -1.2 | max total_reward: 129.9
update:1540/2000, 耗时:0.00分/4.97分 | step: 86240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 86520 | worker_7@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 129.9
update:1545/2000, 耗时:0.00分/4.99分 | step: 86520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 86626 | worker_1@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 129.9
update:1550/2000, 耗时:0.00分/5.01分 | step: 86800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 86854 | worker_5@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 129.9
step: 86908 | worker_3@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 129.9
step: 86909 | worker_4@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 129.9
step: 86911 | worker_6@n_step_6: average total_reward after train data exhaustion : -0.1 | max total_reward: 129.9
step: 87073 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 87075 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1555/2000, 耗时:0.00分/5.02分 | step: 87080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1560/2000, 耗时:0.00分/5.04分 | step: 87360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 87472 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 87578 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1565/2000, 耗时:0.00分/5.06分 | step: 87640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 87806 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 87860 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 87861 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 87863 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1570/2000, 耗时:0.00分/5.08分 | step: 87920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 88025 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 88027 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1575/2000, 耗时:0.00分/5.09分 | step: 88200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 88424 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1580/2000, 耗时:0.00分/5.11分 | step: 88480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 88530 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 88758 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1585/2000, 耗时:0.00分/5.13分 | step: 88760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 88812 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 88813 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 88815 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 88977 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 88979 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1590/2000, 耗时:0.00分/5.14分 | step: 89040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1595/2000, 耗时:0.00分/5.16分 | step: 89320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 89376 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 89482 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1600/2000, 耗时:0.00分/5.18分 | step: 89600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 89710 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 89764 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 89765 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 89767 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1605/2000, 耗时:0.00分/5.19分 | step: 89880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 89929 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 89931 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1610/2000, 耗时:0.00分/5.21分 | step: 90160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 90328 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 90434 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1615/2000, 耗时:0.00分/5.23分 | step: 90440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 90662 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 90716 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 90717 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 90719 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1620/2000, 耗时:0.00分/5.25分 | step: 90720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 90881 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 90883 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1625/2000, 耗时:0.00分/5.26分 | step: 91000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 91280 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1630/2000, 耗时:0.00分/5.28分 | step: 91280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 91386 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1635/2000, 耗时:0.00分/5.30分 | step: 91560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 91614 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 91668 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 91669 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 91671 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 91833 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 91835 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1640/2000, 耗时:0.00分/5.31分 | step: 91840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1645/2000, 耗时:0.00分/5.33分 | step: 92120 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 92232 | worker_7@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
step: 92338 | worker_1@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
update:1650/2000, 耗时:0.00分/5.35分 | step: 92400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 92566 | worker_5@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
step: 92620 | worker_3@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
step: 92621 | worker_4@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
step: 92623 | worker_6@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
update:1655/2000, 耗时:0.00分/5.36分 | step: 92680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 92785 | worker_0@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
step: 92787 | worker_2@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
update:1660/2000, 耗时:0.00分/5.38分 | step: 92960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 93184 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1665/2000, 耗时:0.00分/5.40分 | step: 93240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 93290 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 93518 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1670/2000, 耗时:0.00分/5.41分 | step: 93520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 93572 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 93573 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 93575 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 93737 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 93739 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1675/2000, 耗时:0.00分/5.43分 | step: 93800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1680/2000, 耗时:0.00分/5.45分 | step: 94080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 94136 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 94242 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1685/2000, 耗时:0.00分/5.46分 | step: 94360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 94470 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 94524 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 94525 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 94527 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1690/2000, 耗时:0.00分/5.48分 | step: 94640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 94689 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 94691 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1695/2000, 耗时:0.00分/5.50分 | step: 94920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 95088 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 95194 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1700/2000, 耗时:0.00分/5.51分 | step: 95200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 95422 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 95476 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 95477 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 95479 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1705/2000, 耗时:0.00分/5.53分 | step: 95480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 95641 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 95643 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1710/2000, 耗时:0.00分/5.55分 | step: 95760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 96040 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1715/2000, 耗时:0.00分/5.56分 | step: 96040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 96146 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1720/2000, 耗时:0.00分/5.58分 | step: 96320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 96374 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 96428 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 96429 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 96431 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 96593 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 96595 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1725/2000, 耗时:0.00分/5.60分 | step: 96600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1730/2000, 耗时:0.00分/5.62分 | step: 96880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 96992 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 97098 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1735/2000, 耗时:0.00分/5.63分 | step: 97160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 97326 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 97380 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 97381 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 97383 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1740/2000, 耗时:0.00分/5.65分 | step: 97440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 97545 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 97547 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1745/2000, 耗时:0.00分/5.67分 | step: 97720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 97944 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1750/2000, 耗时:0.00分/5.68分 | step: 98000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 98050 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 98278 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1755/2000, 耗时:0.00分/5.70分 | step: 98280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 98332 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 98333 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 98335 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 98497 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 98499 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1760/2000, 耗时:0.00分/5.72分 | step: 98560 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1765/2000, 耗时:0.00分/5.73分 | step: 98840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 98896 | worker_7@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
step: 99002 | worker_1@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
update:1770/2000, 耗时:0.00分/5.75分 | step: 99120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 99230 | worker_5@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
step: 99284 | worker_3@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
step: 99285 | worker_4@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
step: 99287 | worker_6@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
update:1775/2000, 耗时:0.00分/5.77分 | step: 99400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 99449 | worker_0@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
step: 99451 | worker_2@n_step_6: average total_reward after train data exhaustion : -0.0 | max total_reward: 129.9
update:1780/2000, 耗时:0.00分/5.78分 | step: 99680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 99848 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 99954 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1785/2000, 耗时:0.00分/5.80分 | step: 99960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 100182 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 100236 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 100237 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 100239 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1790/2000, 耗时:0.00分/5.82分 | step: 100240 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 100401 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 100403 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1795/2000, 耗时:0.00分/5.84分 | step: 100520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 100800 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1800/2000, 耗时:0.00分/5.85分 | step: 100800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 100906 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1805/2000, 耗时:0.00分/5.87分 | step: 101080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 101134 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 101188 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 101189 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 101191 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 101353 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 101355 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1810/2000, 耗时:0.00分/5.89分 | step: 101360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1815/2000, 耗时:0.00分/5.91分 | step: 101640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 101752 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 101858 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1820/2000, 耗时:0.00分/5.93分 | step: 101920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 102086 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 102140 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 102141 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 102143 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1825/2000, 耗时:0.00分/5.94分 | step: 102200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 102305 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 102307 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1830/2000, 耗时:0.00分/5.96分 | step: 102480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 102704 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1835/2000, 耗时:0.00分/5.98分 | step: 102760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 102810 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 103038 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1840/2000, 耗时:0.00分/6.00分 | step: 103040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 103092 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 103093 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 103095 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 103257 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 103259 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1845/2000, 耗时:0.00分/6.01分 | step: 103320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1850/2000, 耗时:0.00分/6.03分 | step: 103600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 103656 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 103762 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1855/2000, 耗时:0.00分/6.05分 | step: 103880 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 103990 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 104044 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 104045 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 104047 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1860/2000, 耗时:0.00分/6.06分 | step: 104160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 104209 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 104211 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1865/2000, 耗时:0.00分/6.08分 | step: 104440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 104608 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 104714 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1870/2000, 耗时:0.00分/6.10分 | step: 104720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 104942 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 104996 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 104997 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 104999 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1875/2000, 耗时:0.00分/6.12分 | step: 105000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 105161 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 105163 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1880/2000, 耗时:0.00分/6.13分 | step: 105280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 105560 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1885/2000, 耗时:0.00分/6.15分 | step: 105560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 105666 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1890/2000, 耗时:0.00分/6.17分 | step: 105840 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 105894 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 105948 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 105949 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 105951 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 106113 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 106115 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1895/2000, 耗时:0.00分/6.19分 | step: 106120 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1900/2000, 耗时:0.00分/6.20分 | step: 106400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 106512 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 106618 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1905/2000, 耗时:0.00分/6.22分 | step: 106680 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 106846 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 106900 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 106901 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 106903 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1910/2000, 耗时:0.00分/6.24分 | step: 106960 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 107065 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 107067 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1915/2000, 耗时:0.00分/6.26分 | step: 107240 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 107464 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1920/2000, 耗时:0.00分/6.27分 | step: 107520 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 107570 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 107798 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1925/2000, 耗时:0.00分/6.29分 | step: 107800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 107852 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 107853 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 107855 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 108017 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 108019 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1930/2000, 耗时:0.00分/6.31分 | step: 108080 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1935/2000, 耗时:0.00分/6.33分 | step: 108360 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 108416 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 108522 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1940/2000, 耗时:0.00分/6.34分 | step: 108640 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 108750 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 108804 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 108805 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 108807 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1945/2000, 耗时:0.00分/6.36分 | step: 108920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 108969 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 108971 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1950/2000, 耗时:0.00分/6.38分 | step: 109200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 109368 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 109474 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1955/2000, 耗时:0.00分/6.39分 | step: 109480 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 109702 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 109756 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 109757 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 109759 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1960/2000, 耗时:0.00分/6.41分 | step: 109760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 109921 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 109923 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1965/2000, 耗时:0.00分/6.43分 | step: 110040 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 110320 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1970/2000, 耗时:0.00分/6.44分 | step: 110320 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 110426 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1975/2000, 耗时:0.00分/6.46分 | step: 110600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 110654 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 110708 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 110709 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 110711 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 110873 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 110875 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1980/2000, 耗时:0.00分/6.48分 | step: 110880 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1985/2000, 耗时:0.00分/6.49分 | step: 111160 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 111272 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 111378 | worker_1@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1990/2000, 耗时:0.00分/6.51分 | step: 111440 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 111606 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 111660 | worker_3@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 111661 | worker_4@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 111663 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:1995/2000, 耗时:0.00分/6.53分 | step: 111720 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 111825 | worker_0@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
step: 111827 | worker_2@n_step_6: average total_reward after train data exhaustion : 0.0 | max total_reward: 129.9
update:2000/2000, 耗时:0.00分/6.54分 | step: 112000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
----------------------------------------finished----------------------------------------
==================================================
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/408 [00:00<?, ?it/s]100%|| 408/408 [00:00<00:00, 102171.83it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1026.50
2023-07-24T12:00:00 | net performance [%] = 2.6502
2023-07-24T12:00:00 | number of trades [#] = 2
==================================================
Trial 29 Complete [00h 06m 59s]
net_wealth: 1027.5296839717041

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 03h 59m 49s

Search: Running Trial #30

Value             |Best Value So Far |Hyperparameter
1                 |1                 |horizon
225               |730               |lookback
False             |False             |MarketFactor
20                |3                 |lags
0.9               |0.92              |gamma
32                |32                |batch_size
32                |1                 |n_step
0.96              |0.94              |gae_lambda
1                 |5                 |gradient_clip_norm
5                 |5                 |epochs
5e-05             |0.0001            |actor_lr
0.0001            |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4314.000000   4315.000000
mean      0.000441    20062.255222  ...   20122.295285  20118.633889
std       0.027818    16039.874230  ...   16077.162832  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7691.585083   7690.540039
50%       0.000642    11554.824463  ...   11724.320312  11715.610352
75%       0.011655    29873.081836  ...   29925.802734  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 02:03:12.736124: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow bina22023-07-28 02:03:12.736174: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neur2r023-y is op0a7t-l2i2 mi02z8Ne3t-ed wo w070i2020r3-07-2kt 2h 23-L8 ib:0037r:a02:o03:r-y (oneDNN1ne) At22PI .812.oDe ep Ne -28 7ural N3602:03:122.46: I 7eut3wsortenk L6isber1a the followori07y (r2:03:fng CPU instructions in performancelo-cw/ric12otrei/.8cal operations:  AVX AVX2
T173: 6p2I65: I tensorflow/core/loneDpa tlfto362ratfmNN/e92:2n0) 2to23cpos  u0u2_feature_guorarden3.f-sor m/cpelc0u_featuoIw cr-7te0:-/1core tha/ple fo2_atl8l4g2 7-for0u2] Toa2r8end.cwhi :nm/cpuisc sb_lfe:g oatrure_efClTgo14eunaP2]rwU/ cod. ccrsion:0strucTt reF/pt1h4is hlliaoTeo2tfow emrnms/0 icpb3ins2naryn  i:n p03:1ootehr Fisrelofw b2r opeo.i rrnmaanocpry7 etai3s669-imtc 5i:iou I t_ernitszn]iocrsaefldf olp opoewrta:, re/ectii1awtum o2.re7_o3Ti6gthuiasrhn b drs:e/uTe.ipzleatcocinlsod   TAefnosrom:d1 r/FVlXorc4withn A2wF loV69pu_feature_guard.cc:142] Thi3: I tensow]r  oflTonwewi/hcois Trense /oprFltowhlaeAPItXb2ina rf Doe
rmby is T/epoc epnAuPsI inopat_abfl e DtT eNnesuorrFeimihe thezep ral eyl owNemda  eatis w ortNpu eokbriwiunrpae_rti Lpitiopriabrarltegnmhi yo  uz (onaNeard.ccetery iD coNnotdsmNeA wit hower op:iP1Irplero4th  fDle)e poe2i]kp rNe  nLai autriabtmTgreAPI ihziesd  TlDeepswaroensoi  NN ytoenus.uhs eo n
retheFloral w, N ettwowbeinAo fo(oark LPnIlr r Dyerlkib ies bouileraeDNN)owinp dLib Tra  rNeguty o pt(iomCirezyPU use  insnneetdhrsat rwuictoirontDFe  s h l NetoneAPI(iwonlfoork ollown inDLe perwibrary with the appropriateNN) to use the following CPUeD insg tcomprep Neural  NNi(l) t ucCo use tthPU inser flags.
etruc ftions in performance-critical operations:  AVX AVX2oNefoion
To enable themlto isn lonewwororDmNink Li agn Cbrain perforNther op) tPmraoUneyr use the followice atio instns, rebuild Tensce-criticorF(-rconueDNNng CP)rit atol uiccaltl osieono thws  eU fiol oipenl npstructiopreartaitins  oiwneons oriwnith tgnhp :CPe as U  AVifornmappXnsctru e-crietcAr:itV X AVXocpr fAoVrXironamlaniatesc22

 Toco e e-critiinmpilerTcoal opn fae  ebratnion operalaagspt.belrformance-cions:  AVX AVre sl
e them in other ithetom in other opera: itcai onsApVelr oX, 2X
rTaotip  oeerbautAVXinlsd eionsn, reTea:b2
Tbuild o n sorAVX enab lAeFllo et theThVeXmm inw  o2w
tith her operations, rebuild TensorFlow with the appropriate compiler flags.
 tiTo enablensorFlow with the appropriate compiler flags.
hn other operations, rebuild TensoreFlow with the appropriate compi le appropriateethe rcm i nflagso other operations, rebumpiler.il
 flags.d Tensor
Flow with the appropriate compiler flags.
2023-07-28 02:03:13.356626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:03:13.374369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:03:13.375968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:03:13.381849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:03:13.392676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:03:13.400910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:03:13.406253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:03:13.419656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.05分 | step:  1280 | performance: 1.1 | accuracy: 0.36 | loss: 1.33
update: 10/2000, 耗时:0.01分/0.07分 | step:  2560 | performance: 0.9 | accuracy: 0.27 | loss: 0.67
update: 15/2000, 耗时:0.01分/0.10分 | step:  3840 | performance: 0.9 | accuracy: 0.25 | loss: 0.65
update: 20/2000, 耗时:0.01分/0.13分 | step:  5120 | performance: 0.8 | accuracy: 0.25 | loss: 0.99
update: 25/2000, 耗时:0.01分/0.17分 | step:  6400 | performance: 0.9 | accuracy: 0.22 | loss: 0.72
update: 30/2000, 耗时:0.01分/0.20分 | step:  7680 | performance: 0.7 | accuracy: 0.24 | loss: 1.89
update: 35/2000, 耗时:0.01分/0.23分 | step:  8960 | performance: 0.4 | accuracy: 0.26 | loss: 2.04
update: 40/2000, 耗时:0.01分/0.27分 | step: 10240 | performance: 0.5 | accuracy: 0.28 | loss: 0.99
update: 45/2000, 耗时:0.01分/0.30分 | step: 11520 | performance: 0.5 | accuracy: 0.27 | loss: 0.54
update: 50/2000, 耗时:0.01分/0.34分 | step: 12800 | performance: 0.5 | accuracy: 0.27 | loss: 1.60
update: 55/2000, 耗时:0.01分/0.37分 | step: 14080 | performance: 0.4 | accuracy: 0.27 | loss: 1.80
update: 60/2000, 耗时:0.01分/0.40分 | step: 15360 | performance: 0.5 | accuracy: 0.28 | loss: 1.63
update: 65/2000, 耗时:0.01分/0.44分 | step: 16640 | performance: 0.3 | accuracy: 0.29 | loss: 2.23
update: 70/2000, 耗时:0.01分/0.47分 | step: 17920 | performance: 0.2 | accuracy: 0.30 | loss: 2.83
update: 75/2000, 耗时:0.01分/0.50分 | step: 19200 | performance: 0.4 | accuracy: 0.31 | loss: 1.18
update: 80/2000, 耗时:0.01分/0.54分 | step: 20480 | performance: 0.4 | accuracy: 0.31 | loss: 0.29
update: 85/2000, 耗时:0.01分/0.57分 | step: 21760 | performance: 0.5 | accuracy: 0.31 | loss: 1.23
update: 90/2000, 耗时:0.01分/0.61分 | step: 23040 | performance: 0.4 | accuracy: 0.32 | loss: 1.83
update: 95/2000, 耗时:0.01分/0.64分 | step: 24320 | performance: 0.3 | accuracy: 0.31 | loss: 0.63
update:100/2000, 耗时:0.01分/0.67分 | step: 25600 | performance: 0.3 | accuracy: 0.31 | loss: 0.37
update:105/2000, 耗时:0.01分/0.71分 | step: 26880 | performance: 0.3 | accuracy: 0.30 | loss: 0.93
update:110/2000, 耗时:0.01分/0.74分 | step: 28160 | performance: 0.4 | accuracy: 0.29 | loss: 0.36
update:115/2000, 耗时:0.01分/0.78分 | step: 29440 | performance: 1.3 | accuracy: 0.67 | loss: 2.19
Saving PPO weights in both H5 format and checkpoint @ update:115 
update:120/2000, 耗时:0.01分/0.81分 | step: 30720 | performance: 0.9 | accuracy: 0.33 | loss: 0.65
update:125/2000, 耗时:0.01分/0.84分 | step: 32000 | performance: 1.0 | accuracy: 0.26 | loss: 0.54
update:130/2000, 耗时:0.01分/0.88分 | step: 33280 | performance: 1.0 | accuracy: 0.23 | loss: 0.61
update:135/2000, 耗时:0.01分/0.91分 | step: 34560 | performance: 1.1 | accuracy: 0.22 | loss: 0.38
update:140/2000, 耗时:0.01分/0.94分 | step: 35840 | performance: 1.1 | accuracy: 0.19 | loss: 0.37
update:145/2000, 耗时:0.01分/0.98分 | step: 37120 | performance: 1.0 | accuracy: 0.21 | loss: 1.77
update:150/2000, 耗时:0.01分/1.01分 | step: 38400 | performance: 1.4 | accuracy: 0.26 | loss: 2.83
update:155/2000, 耗时:0.01分/1.04分 | step: 39680 | performance: 1.3 | accuracy: 0.27 | loss: 0.66
update:160/2000, 耗时:0.01分/1.08分 | step: 40960 | performance: 1.4 | accuracy: 0.25 | loss: 0.22
update:165/2000, 耗时:0.01分/1.11分 | step: 42240 | performance: 0.7 | accuracy: 0.26 | loss: 1.83
update:170/2000, 耗时:0.01分/1.14分 | step: 43520 | performance: 0.7 | accuracy: 0.26 | loss: 1.60
update:175/2000, 耗时:0.01分/1.17分 | step: 44800 | performance: 0.7 | accuracy: 0.27 | loss: 1.24
update:180/2000, 耗时:0.01分/1.20分 | step: 46080 | performance: 0.6 | accuracy: 0.28 | loss: 2.10
update:185/2000, 耗时:0.01分/1.23分 | step: 47360 | performance: 1.2 | accuracy: 0.30 | loss: 2.34
update:190/2000, 耗时:0.01分/1.26分 | step: 48640 | performance: 1.0 | accuracy: 0.30 | loss: 1.45
update:195/2000, 耗时:0.01分/1.29分 | step: 49920 | performance: 1.0 | accuracy: 0.29 | loss: 0.15
update:200/2000, 耗时:0.01分/1.33分 | step: 51200 | performance: 1.6 | accuracy: 0.29 | loss: 1.66
update:205/2000, 耗时:0.01分/1.36分 | step: 52480 | performance: 1.7 | accuracy: 0.30 | loss: 1.81
update:210/2000, 耗时:0.01分/1.39分 | step: 53760 | performance: 1.7 | accuracy: 0.29 | loss: 0.31
update:215/2000, 耗时:0.01分/1.42分 | step: 55040 | performance: 1.7 | accuracy: 0.28 | loss: 0.21
update:220/2000, 耗时:0.01分/1.46分 | step: 56320 | performance: 1.6 | accuracy: 0.27 | loss: 0.25
update:225/2000, 耗时:0.01分/1.49分 | step: 57600 | performance: 1.7 | accuracy: 0.26 | loss: 0.21
Saving PPO weights in both H5 format and checkpoint @ update:229 
update:230/2000, 耗时:0.01分/1.53分 | step: 58880 | performance: 0.9 | accuracy: 0.36 | loss: 1.86
update:235/2000, 耗时:0.01分/1.56分 | step: 60160 | performance: 0.7 | accuracy: 0.19 | loss: 0.30
update:240/2000, 耗时:0.01分/1.59分 | step: 61440 | performance: 0.7 | accuracy: 0.16 | loss: 0.21
update:245/2000, 耗时:0.01分/1.63分 | step: 62720 | performance: 0.7 | accuracy: 0.14 | loss: 0.27
update:250/2000, 耗时:0.01分/1.66分 | step: 64000 | performance: 0.7 | accuracy: 0.13 | loss: 0.25
update:255/2000, 耗时:0.01分/1.69分 | step: 65280 | performance: 0.8 | accuracy: 0.13 | loss: 0.58
update:260/2000, 耗时:0.01分/1.72分 | step: 66560 | performance: 0.9 | accuracy: 0.16 | loss: 1.72
update:265/2000, 耗时:0.01分/1.76分 | step: 67840 | performance: 1.0 | accuracy: 0.21 | loss: 1.88
update:270/2000, 耗时:0.01分/1.79分 | step: 69120 | performance: 0.9 | accuracy: 0.21 | loss: 0.31
update:275/2000, 耗时:0.01分/1.82分 | step: 70400 | performance: 0.9 | accuracy: 0.20 | loss: 0.42
update:280/2000, 耗时:0.01分/1.86分 | step: 71680 | performance: 0.6 | accuracy: 0.21 | loss: 0.65
update:285/2000, 耗时:0.01分/1.89分 | step: 72960 | performance: 0.4 | accuracy: 0.21 | loss: 0.93
update:290/2000, 耗时:0.01分/1.92分 | step: 74240 | performance: 0.3 | accuracy: 0.21 | loss: 0.95
update:295/2000, 耗时:0.01分/1.95分 | step: 75520 | performance: 0.4 | accuracy: 0.22 | loss: 1.43
update:300/2000, 耗时:0.01分/1.99分 | step: 76800 | performance: 0.9 | accuracy: 0.24 | loss: 0.96
update:305/2000, 耗时:0.01分/2.02分 | step: 78080 | performance: 0.7 | accuracy: 0.25 | loss: 1.52
update:310/2000, 耗时:0.01分/2.05分 | step: 79360 | performance: 0.8 | accuracy: 0.24 | loss: 0.28
update:315/2000, 耗时:0.01分/2.08分 | step: 80640 | performance: 0.7 | accuracy: 0.24 | loss: 0.53
update:320/2000, 耗时:0.01分/2.12分 | step: 81920 | performance: 0.7 | accuracy: 0.23 | loss: 0.48
update:325/2000, 耗时:0.01分/2.15分 | step: 83200 | performance: 0.7 | accuracy: 0.23 | loss: 0.18
update:330/2000, 耗时:0.01分/2.18分 | step: 84480 | performance: 0.6 | accuracy: 0.22 | loss: 0.08
update:335/2000, 耗时:0.01分/2.21分 | step: 85760 | performance: 0.6 | accuracy: 0.21 | loss: 0.10
update:340/2000, 耗时:0.01分/2.25分 | step: 87040 | performance: 0.5 | accuracy: 0.20 | loss: 0.16
Saving PPO weights in both H5 format and checkpoint @ update:344 
update:345/2000, 耗时:0.01分/2.29分 | step: 88320 | performance: 0.9 | accuracy: 0.15 | loss: 0.70
update:350/2000, 耗时:0.01分/2.32分 | step: 89600 | performance: 1.0 | accuracy: 0.07 | loss: 0.32
step: 89851 | worker_2@n_step_31: average total_reward after train data exhaustion : 26.0 | max total_reward: 262.8
step: 90368 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:355/2000, 耗时:0.01分/2.35分 | step: 90880 | performance: 0.9 | accuracy: 0.23 | loss: 0.40
step: 91130 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
step: 91902 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:360/2000, 耗时:0.01分/2.38分 | step: 92160 | performance: 1.0 | accuracy: 0.00 | loss: 0.28
step: 92670 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
update:365/2000, 耗时:0.01分/2.42分 | step: 93440 | performance: 1.1 | accuracy: 0.10 | loss: 0.26
step: 93693 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:370/2000, 耗时:0.01分/2.45分 | step: 94720 | performance: 1.3 | accuracy: 0.12 | loss: 0.42
step: 95481 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:375/2000, 耗时:0.01分/2.48分 | step: 96000 | performance: 1.3 | accuracy: 0.11 | loss: 0.19
step: 96252 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
step: 96506 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:380/2000, 耗时:0.01分/2.52分 | step: 97280 | performance: 1.0 | accuracy: 0.00 | loss: 0.26
step: 98301 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 98555 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:385/2000, 耗时:0.01分/2.55分 | step: 98560 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
step: 98816 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 99581 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:390/2000, 耗时:0.01分/2.58分 | step: 99840 | performance: 1.0 | accuracy: 0.00 | loss: 0.34
step: 101117 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:395/2000, 耗时:0.01分/2.61分 | step: 101120 | performance: 1.2 | accuracy: 0.14 | loss: 0.24
step: 101375 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
step: 101883 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 262.8
update:400/2000, 耗时:0.01分/2.65分 | step: 102400 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
step: 103673 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 103678 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:405/2000, 耗时:0.01分/2.68分 | step: 103680 | performance: 1.0 | accuracy: 0.10 | loss: 0.20
step: 104699 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.4 | max total_reward: 262.8
update:410/2000, 耗时:0.01分/2.71分 | step: 104960 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
step: 105214 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 105725 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:415/2000, 耗时:0.01分/2.74分 | step: 106240 | performance: 1.0 | accuracy: 0.12 | loss: 0.27
step: 106489 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 262.8
step: 107257 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
step: 107515 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:420/2000, 耗时:0.01分/2.78分 | step: 107520 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 108287 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 108542 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:425/2000, 耗时:0.01分/2.81分 | step: 108800 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
step: 110073 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
update:430/2000, 耗时:0.01分/2.84分 | step: 110080 | performance: 1.0 | accuracy: 0.00 | loss: 0.28
step: 110848 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:435/2000, 耗时:0.01分/2.87分 | step: 111360 | performance: 1.0 | accuracy: 0.15 | loss: 0.24
step: 111609 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
step: 112128 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:440/2000, 耗时:0.01分/2.91分 | step: 112640 | performance: 1.1 | accuracy: 0.19 | loss: 0.40
step: 112889 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 113406 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
step: 113663 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 262.8
step: 113917 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 262.8
update:445/2000, 耗时:0.01分/2.94分 | step: 113920 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
step: 114684 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:450/2000, 耗时:0.01分/2.97分 | step: 115200 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 115710 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 262.8
step: 116217 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
step: 116224 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:455/2000, 耗时:0.01分/3.01分 | step: 116480 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 116991 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 117755 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.3 | max total_reward: 262.8
update:460/2000, 耗时:0.01分/3.04分 | step: 117760 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 118269 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
step: 118524 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 262.8
update:465/2000, 耗时:0.01分/3.07分 | step: 119040 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 119546 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 120057 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:470/2000, 耗时:0.01分/3.10分 | step: 120320 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 120576 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
step: 120831 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:475/2000, 耗时:0.01分/3.14分 | step: 121600 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 122874 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 122876 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 122879 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:480/2000, 耗时:0.01分/3.17分 | step: 122880 | performance: 1.0 | accuracy: 0.06 | loss: 0.14
step: 123643 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 123897 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 123904 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:485/2000, 耗时:0.01分/3.20分 | step: 124160 | performance: 1.0 | accuracy: 0.13 | loss: 0.26
step: 124415 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:490/2000, 耗时:0.01分/3.23分 | step: 125440 | performance: 0.8 | accuracy: 0.14 | loss: 0.60
step: 125948 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.6 | max total_reward: 262.8
update:495/2000, 耗时:0.01分/3.27分 | step: 126720 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 127228 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
step: 127232 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:500/2000, 耗时:0.01分/3.30分 | step: 128000 | performance: 1.0 | accuracy: 0.10 | loss: 0.17
step: 128505 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.3 | max total_reward: 262.8
update:505/2000, 耗时:0.01分/3.33分 | step: 129280 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 130300 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:510/2000, 耗时:0.01分/3.36分 | step: 130560 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
step: 130813 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 131070 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
update:515/2000, 耗时:0.01分/3.39分 | step: 131840 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 132347 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
step: 132349 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:520/2000, 耗时:0.01分/3.43分 | step: 133120 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
update:525/2000, 耗时:0.01分/3.46分 | step: 134400 | performance: 1.0 | accuracy: 0.00 | loss: 0.44
step: 134656 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:530/2000, 耗时:0.01分/3.49分 | step: 135680 | performance: 1.0 | accuracy: 0.00 | loss: 0.44
step: 135929 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 136448 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
update:535/2000, 耗时:0.01分/3.52分 | step: 136960 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 137210 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 262.8
update:540/2000, 耗时:0.01分/3.56分 | step: 138240 | performance: 0.9 | accuracy: 0.25 | loss: 0.41
step: 138490 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
step: 138749 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:545/2000, 耗时:0.01分/3.59分 | step: 139520 | performance: 1.0 | accuracy: 0.00 | loss: 0.33
step: 140542 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:550/2000, 耗时:0.01分/3.62分 | step: 140800 | performance: 1.1 | accuracy: 0.07 | loss: 0.36
step: 141312 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
update:555/2000, 耗时:0.01分/3.65分 | step: 142080 | performance: 1.0 | accuracy: 0.14 | loss: 0.43
step: 142329 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 262.8
step: 143103 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 262.8
update:560/2000, 耗时:0.01分/3.69分 | step: 143360 | performance: 1.0 | accuracy: 0.25 | loss: 0.25
step: 143614 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 262.8
step: 143866 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
step: 144383 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 144635 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:565/2000, 耗时:0.01分/3.72分 | step: 144640 | performance: 0.9 | accuracy: 0.00 | loss: 0.23
update:570/2000, 耗时:0.01分/3.75分 | step: 145920 | performance: 1.3 | accuracy: 0.13 | loss: 0.40
step: 147193 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:575/2000, 耗时:0.01分/3.78分 | step: 147200 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 147967 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:580/2000, 耗时:0.01分/3.82分 | step: 148480 | performance: 0.9 | accuracy: 0.11 | loss: 0.07
step: 149243 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 149753 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:585/2000, 耗时:0.01分/3.85分 | step: 149760 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
step: 151034 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 262.8
update:590/2000, 耗时:0.01分/3.89分 | step: 151040 | performance: 1.1 | accuracy: 0.15 | loss: 0.23
step: 152059 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:595/2000, 耗时:0.01分/3.92分 | step: 152320 | performance: 0.9 | accuracy: 0.00 | loss: 0.43
step: 152573 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 153595 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 262.8
update:600/2000, 耗时:0.01分/3.95分 | step: 153600 | performance: 1.0 | accuracy: 0.07 | loss: 0.34
step: 154365 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 262.8
update:605/2000, 耗时:0.01分/3.99分 | step: 154880 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
update:610/2000, 耗时:0.01分/4.02分 | step: 156160 | performance: 1.1 | accuracy: 0.12 | loss: 0.38
step: 157440 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:615/2000, 耗时:0.01分/4.05分 | step: 157440 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
step: 158720 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:620/2000, 耗时:0.01分/4.09分 | step: 158720 | performance: 1.0 | accuracy: 0.00 | loss: 0.48
update:625/2000, 耗时:0.01分/4.12分 | step: 160000 | performance: 1.0 | accuracy: 0.19 | loss: 0.34
step: 160256 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
update:630/2000, 耗时:0.01分/4.15分 | step: 161280 | performance: 0.9 | accuracy: 0.00 | loss: 0.37
update:635/2000, 耗时:0.01分/4.19分 | step: 162560 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
step: 163072 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 163579 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 163833 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:640/2000, 耗时:0.01分/4.22分 | step: 163840 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
update:645/2000, 耗时:0.01分/4.26分 | step: 165120 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
update:650/2000, 耗时:0.01分/4.29分 | step: 166400 | performance: 0.9 | accuracy: 0.00 | loss: 0.20
step: 166907 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
step: 167424 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:655/2000, 耗时:0.01分/4.32分 | step: 167680 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
step: 167933 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:660/2000, 耗时:0.01分/4.36分 | step: 168960 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
step: 170235 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
update:665/2000, 耗时:0.01分/4.39分 | step: 170240 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
step: 170752 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
update:670/2000, 耗时:0.01分/4.42分 | step: 171520 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 171773 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:675/2000, 耗时:0.01分/4.46分 | step: 172800 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 173056 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:680/2000, 耗时:0.01分/4.49分 | step: 174080 | performance: 1.0 | accuracy: 0.00 | loss: 0.30
step: 174332 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
step: 175353 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
update:685/2000, 耗时:0.01分/4.52分 | step: 175360 | performance: 1.1 | accuracy: 0.12 | loss: 0.47
step: 175869 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 262.8
step: 176121 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 262.8
update:690/2000, 耗时:0.01分/4.56分 | step: 176640 | performance: 1.0 | accuracy: 0.00 | loss: 0.25
step: 176891 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
step: 176892 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:695/2000, 耗时:0.01分/4.59分 | step: 177920 | performance: 1.0 | accuracy: 0.10 | loss: 0.25
step: 178172 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 178937 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 179200 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:700/2000, 耗时:0.01分/4.62分 | step: 179200 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
step: 179451 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 179968 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 180221 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:705/2000, 耗时:0.01分/4.66分 | step: 180480 | performance: 0.9 | accuracy: 0.23 | loss: 0.52
step: 181241 | worker_0@n_step_31: average total_reward after train data exhaustion : 8.0 | max total_reward: 262.8
update:710/2000, 耗时:0.01分/4.69分 | step: 181760 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
step: 182015 | worker_6@n_step_31: average total_reward after train data exhaustion : 8.1 | max total_reward: 262.8
step: 182522 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 182777 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:715/2000, 耗时:0.01分/4.72分 | step: 183040 | performance: 1.0 | accuracy: 0.17 | loss: 0.15
update:720/2000, 耗时:0.01分/4.76分 | step: 184320 | performance: 1.0 | accuracy: 0.00 | loss: 0.33
step: 184576 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:725/2000, 耗时:0.01分/4.79分 | step: 185600 | performance: 1.0 | accuracy: 0.00 | loss: 0.26
step: 185850 | worker_1@n_step_31: average total_reward after train data exhaustion : 4.1 | max total_reward: 262.8
update:730/2000, 耗时:0.01分/4.83分 | step: 186880 | performance: 0.8 | accuracy: 0.00 | loss: 0.58
update:735/2000, 耗时:0.01分/4.86分 | step: 188160 | performance: 1.0 | accuracy: 0.10 | loss: 0.19
update:740/2000, 耗时:0.01分/4.90分 | step: 189440 | performance: 1.0 | accuracy: 0.14 | loss: 0.43
update:745/2000, 耗时:0.01分/4.93分 | step: 190720 | performance: 1.0 | accuracy: 0.11 | loss: 0.41
update:750/2000, 耗时:0.01分/4.97分 | step: 192000 | performance: 1.1 | accuracy: 0.06 | loss: 0.36
step: 192510 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 262.8
update:755/2000, 耗时:0.01分/5.00分 | step: 193280 | performance: 1.0 | accuracy: 0.00 | loss: 0.32
update:760/2000, 耗时:0.01分/5.04分 | step: 194560 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
update:765/2000, 耗时:0.01分/5.07分 | step: 195840 | performance: 0.9 | accuracy: 0.14 | loss: 0.17
step: 196090 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:770/2000, 耗时:0.01分/5.11分 | step: 197120 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
update:775/2000, 耗时:0.01分/5.14分 | step: 198400 | performance: 1.0 | accuracy: 0.17 | loss: 0.30
step: 198649 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
step: 198910 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 262.8
step: 199680 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
update:780/2000, 耗时:0.01分/5.18分 | step: 199680 | performance: 1.0 | accuracy: 0.00 | loss: 0.34
step: 200185 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:785/2000, 耗时:0.01分/5.21分 | step: 200960 | performance: 0.9 | accuracy: 0.12 | loss: 0.26
update:790/2000, 耗时:0.01分/5.25分 | step: 202240 | performance: 0.7 | accuracy: 0.12 | loss: 0.35
update:795/2000, 耗时:0.01分/5.28分 | step: 203520 | performance: 0.7 | accuracy: 0.12 | loss: 0.24
update:800/2000, 耗时:0.01分/5.31分 | step: 204800 | performance: 0.7 | accuracy: 0.12 | loss: 0.47
step: 205310 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 262.8
update:805/2000, 耗时:0.01分/5.34分 | step: 206080 | performance: 0.7 | accuracy: 0.12 | loss: 0.34
update:810/2000, 耗时:0.01分/5.38分 | step: 207360 | performance: 0.7 | accuracy: 0.12 | loss: 0.49
update:815/2000, 耗时:0.01分/5.41分 | step: 208640 | performance: 0.8 | accuracy: 0.13 | loss: 0.36
update:820/2000, 耗时:0.01分/5.44分 | step: 209920 | performance: 0.8 | accuracy: 0.12 | loss: 0.17
update:825/2000, 耗时:0.01分/5.47分 | step: 211200 | performance: 0.8 | accuracy: 0.12 | loss: 0.24
update:830/2000, 耗时:0.01分/5.51分 | step: 212480 | performance: 0.7 | accuracy: 0.12 | loss: 0.25
update:835/2000, 耗时:0.01分/5.54分 | step: 213760 | performance: 0.7 | accuracy: 0.12 | loss: 0.39
update:840/2000, 耗时:0.01分/5.57分 | step: 215040 | performance: 0.7 | accuracy: 0.12 | loss: 0.37
step: 215293 | worker_4@n_step_31: average total_reward after train data exhaustion : 12.5 | max total_reward: 262.8
update:845/2000, 耗时:0.01分/5.61分 | step: 216320 | performance: 0.7 | accuracy: 0.13 | loss: 0.31
step: 217086 | worker_5@n_step_31: average total_reward after train data exhaustion : 7.5 | max total_reward: 262.8
update:850/2000, 耗时:0.01分/5.64分 | step: 217600 | performance: 0.8 | accuracy: 0.13 | loss: 0.39
update:855/2000, 耗时:0.01分/5.67分 | step: 218880 | performance: 1.0 | accuracy: 0.13 | loss: 0.43
update:860/2000, 耗时:0.01分/5.71分 | step: 220160 | performance: 1.0 | accuracy: 0.13 | loss: 0.34
update:865/2000, 耗时:0.01分/5.74分 | step: 221440 | performance: 0.8 | accuracy: 0.13 | loss: 0.19
update:870/2000, 耗时:0.01分/5.77分 | step: 222720 | performance: 0.7 | accuracy: 0.12 | loss: 0.32
update:875/2000, 耗时:0.01分/5.80分 | step: 224000 | performance: 0.8 | accuracy: 0.12 | loss: 0.51
update:880/2000, 耗时:0.01分/5.84分 | step: 225280 | performance: 0.7 | accuracy: 0.12 | loss: 0.34
update:885/2000, 耗时:0.01分/5.87分 | step: 226560 | performance: 0.6 | accuracy: 0.12 | loss: 0.34
update:890/2000, 耗时:0.01分/5.90分 | step: 227840 | performance: 0.6 | accuracy: 0.12 | loss: 0.37
update:895/2000, 耗时:0.01分/5.93分 | step: 229120 | performance: 0.6 | accuracy: 0.12 | loss: 0.44
update:900/2000, 耗时:0.01分/5.97分 | step: 230400 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 231168 | worker_7@n_step_31: average total_reward after train data exhaustion : 4.0 | max total_reward: 262.8
update:905/2000, 耗时:0.01分/6.00分 | step: 231680 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
update:910/2000, 耗时:0.01分/6.03分 | step: 232960 | performance: 1.0 | accuracy: 0.00 | loss: 0.30
step: 234240 | worker_7@n_step_31: average total_reward after train data exhaustion : 4.9 | max total_reward: 262.8
update:915/2000, 耗时:0.01分/6.06分 | step: 234240 | performance: 1.0 | accuracy: 0.00 | loss: 0.48
step: 235520 | worker_7@n_step_31: average total_reward after train data exhaustion : 8.7 | max total_reward: 262.8
update:920/2000, 耗时:0.01分/6.10分 | step: 235520 | performance: 1.0 | accuracy: 0.00 | loss: 0.49
update:925/2000, 耗时:0.01分/6.13分 | step: 236800 | performance: 1.2 | accuracy: 0.12 | loss: 0.27
update:930/2000, 耗时:0.01分/6.16分 | step: 238080 | performance: 1.3 | accuracy: 0.11 | loss: 0.25
step: 239357 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 262.8
update:935/2000, 耗时:0.01分/6.19分 | step: 239360 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
update:940/2000, 耗时:0.01分/6.23分 | step: 240640 | performance: 1.0 | accuracy: 0.12 | loss: 0.27
step: 241913 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 262.8
update:945/2000, 耗时:0.01分/6.26分 | step: 241920 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
step: 242173 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:950/2000, 耗时:0.01分/6.29分 | step: 243200 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
update:955/2000, 耗时:0.01分/6.33分 | step: 244480 | performance: 1.2 | accuracy: 0.12 | loss: 0.29
step: 245760 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 262.8
update:960/2000, 耗时:0.01分/6.36分 | step: 245760 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
update:965/2000, 耗时:0.01分/6.39分 | step: 247040 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
update:970/2000, 耗时:0.01分/6.42分 | step: 248320 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 248576 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
step: 248827 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
step: 249596 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.1 | max total_reward: 262.8
update:975/2000, 耗时:0.01分/6.46分 | step: 249600 | performance: 1.0 | accuracy: 0.12 | loss: 0.27
step: 249855 | worker_6@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 262.8
step: 250364 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 262.8
step: 250619 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 262.8
update:980/2000, 耗时:0.01分/6.49分 | step: 250880 | performance: 1.1 | accuracy: 0.13 | loss: 0.27
step: 251134 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 251641 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:985/2000, 耗时:0.01分/6.52分 | step: 252160 | performance: 1.0 | accuracy: 0.00 | loss: 0.40
step: 252668 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:990/2000, 耗时:0.01分/6.55分 | step: 253440 | performance: 1.0 | accuracy: 0.00 | loss: 0.29
update:995/2000, 耗时:0.01分/6.58分 | step: 254720 | performance: 0.8 | accuracy: 0.11 | loss: 0.38
update:1000/2000, 耗时:0.01分/6.62分 | step: 256000 | performance: 1.0 | accuracy: 0.00 | loss: 0.32
step: 257024 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:1005/2000, 耗时:0.01分/6.65分 | step: 257280 | performance: 1.2 | accuracy: 0.12 | loss: 0.54
step: 258304 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
update:1010/2000, 耗时:0.01分/6.68分 | step: 258560 | performance: 1.0 | accuracy: 0.07 | loss: 0.40
update:1015/2000, 耗时:0.01分/6.71分 | step: 259840 | performance: 1.0 | accuracy: 0.11 | loss: 0.44
step: 260608 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 262.8
update:1020/2000, 耗时:0.01分/6.75分 | step: 261120 | performance: 1.1 | accuracy: 0.14 | loss: 0.29
update:1025/2000, 耗时:0.01分/6.78分 | step: 262400 | performance: 0.9 | accuracy: 0.11 | loss: 0.41
update:1030/2000, 耗时:0.01分/6.81分 | step: 263680 | performance: 1.1 | accuracy: 0.13 | loss: 0.63
update:1035/2000, 耗时:0.01分/6.84分 | step: 264960 | performance: 0.9 | accuracy: 0.13 | loss: 0.62
update:1040/2000, 耗时:0.01分/6.87分 | step: 266240 | performance: 0.8 | accuracy: 0.13 | loss: 0.22
update:1045/2000, 耗时:0.01分/6.91分 | step: 267520 | performance: 0.7 | accuracy: 0.13 | loss: 0.38
update:1050/2000, 耗时:0.01分/6.94分 | step: 268800 | performance: 0.7 | accuracy: 0.13 | loss: 0.45
update:1055/2000, 耗时:0.01分/6.97分 | step: 270080 | performance: 0.7 | accuracy: 0.13 | loss: 0.30
update:1060/2000, 耗时:0.01分/7.00分 | step: 271360 | performance: 0.6 | accuracy: 0.13 | loss: 0.50
update:1065/2000, 耗时:0.01分/7.04分 | step: 272640 | performance: 0.6 | accuracy: 0.13 | loss: 0.39
update:1070/2000, 耗时:0.01分/7.07分 | step: 273920 | performance: 0.7 | accuracy: 0.13 | loss: 0.52
update:1075/2000, 耗时:0.01分/7.10分 | step: 275200 | performance: 0.8 | accuracy: 0.13 | loss: 0.48
update:1080/2000, 耗时:0.01分/7.13分 | step: 276480 | performance: 0.7 | accuracy: 0.14 | loss: 0.52
update:1085/2000, 耗时:0.01分/7.16分 | step: 277760 | performance: 0.8 | accuracy: 0.14 | loss: 0.42
update:1090/2000, 耗时:0.01分/7.20分 | step: 279040 | performance: 0.9 | accuracy: 0.14 | loss: 0.34
update:1095/2000, 耗时:0.01分/7.23分 | step: 280320 | performance: 0.8 | accuracy: 0.13 | loss: 0.20
update:1100/2000, 耗时:0.01分/7.26分 | step: 281600 | performance: 0.8 | accuracy: 0.13 | loss: 0.35
update:1105/2000, 耗时:0.01分/7.29分 | step: 282880 | performance: 0.9 | accuracy: 0.12 | loss: 0.20
update:1110/2000, 耗时:0.01分/7.33分 | step: 284160 | performance: 0.8 | accuracy: 0.12 | loss: 0.20
step: 284667 | worker_2@n_step_31: average total_reward after train data exhaustion : 16.9 | max total_reward: 262.8
update:1115/2000, 耗时:0.01分/7.36分 | step: 285440 | performance: 0.9 | accuracy: 0.12 | loss: 0.45
step: 285695 | worker_6@n_step_31: average total_reward after train data exhaustion : 8.1 | max total_reward: 262.8
update:1120/2000, 耗时:0.01分/7.39分 | step: 286720 | performance: 0.8 | accuracy: 0.12 | loss: 0.42
update:1125/2000, 耗时:0.01分/7.42分 | step: 288000 | performance: 0.8 | accuracy: 0.12 | loss: 0.27
step: 289022 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 262.8
step: 289276 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 262.8
update:1130/2000, 耗时:0.01分/7.45分 | step: 289280 | performance: 0.9 | accuracy: 0.12 | loss: 0.21
step: 289531 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 262.8
update:1135/2000, 耗时:0.01分/7.49分 | step: 290560 | performance: 0.9 | accuracy: 0.00 | loss: 0.36
step: 291836 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:1140/2000, 耗时:0.01分/7.52分 | step: 291840 | performance: 1.0 | accuracy: 0.14 | loss: 0.22
update:1145/2000, 耗时:0.01分/7.55分 | step: 293120 | performance: 1.1 | accuracy: 0.12 | loss: 0.32
update:1150/2000, 耗时:0.01分/7.59分 | step: 294400 | performance: 1.0 | accuracy: 0.08 | loss: 0.32
step: 294650 | worker_1@n_step_31: average total_reward after train data exhaustion : 4.2 | max total_reward: 262.8
step: 294907 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.2 | max total_reward: 262.8
update:1155/2000, 耗时:0.01分/7.62分 | step: 295680 | performance: 1.0 | accuracy: 0.00 | loss: 0.47
step: 296704 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:1160/2000, 耗时:0.01分/7.65分 | step: 296960 | performance: 1.0 | accuracy: 0.07 | loss: 0.16
step: 297465 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
step: 298236 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:1165/2000, 耗时:0.01分/7.69分 | step: 298240 | performance: 0.9 | accuracy: 0.11 | loss: 0.32
step: 298491 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
step: 299007 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
step: 299259 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 262.8
update:1170/2000, 耗时:0.01分/7.72分 | step: 299520 | performance: 0.9 | accuracy: 0.00 | loss: 0.47
step: 299770 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 262.8
update:1175/2000, 耗时:0.01分/7.75分 | step: 300800 | performance: 0.8 | accuracy: 0.00 | loss: 0.31
step: 301049 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:1180/2000, 耗时:0.01分/7.78分 | step: 302080 | performance: 0.9 | accuracy: 0.06 | loss: 0.39
step: 302586 | worker_1@n_step_31: average total_reward after train data exhaustion : 4.2 | max total_reward: 262.8
update:1185/2000, 耗时:0.01分/7.82分 | step: 303360 | performance: 1.0 | accuracy: 0.18 | loss: 0.24
update:1190/2000, 耗时:0.01分/7.85分 | step: 304640 | performance: 1.2 | accuracy: 0.15 | loss: 0.50
update:1195/2000, 耗时:0.01分/7.88分 | step: 305920 | performance: 1.2 | accuracy: 0.12 | loss: 0.37
step: 306938 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:1200/2000, 耗时:0.01分/7.92分 | step: 307200 | performance: 0.9 | accuracy: 0.12 | loss: 0.50
step: 308220 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 262.8
update:1205/2000, 耗时:0.01分/7.95分 | step: 308480 | performance: 0.9 | accuracy: 0.13 | loss: 0.39
step: 309242 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 262.8
update:1210/2000, 耗时:0.01分/7.98分 | step: 309760 | performance: 0.8 | accuracy: 0.12 | loss: 0.52
step: 311035 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 311036 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:1215/2000, 耗时:0.01分/8.01分 | step: 311040 | performance: 0.6 | accuracy: 0.13 | loss: 0.28
step: 311804 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:1220/2000, 耗时:0.01分/8.05分 | step: 312320 | performance: 0.6 | accuracy: 0.12 | loss: 0.47
update:1225/2000, 耗时:0.01分/8.08分 | step: 313600 | performance: 0.6 | accuracy: 0.12 | loss: 0.63
step: 314617 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
step: 314876 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
update:1230/2000, 耗时:0.01分/8.11分 | step: 314880 | performance: 0.5 | accuracy: 0.12 | loss: 0.32
step: 315643 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 315645 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
step: 316153 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:1235/2000, 耗时:0.01分/8.14分 | step: 316160 | performance: 0.5 | accuracy: 0.12 | loss: 0.23
update:1240/2000, 耗时:0.01分/8.18分 | step: 317440 | performance: 0.4 | accuracy: 0.12 | loss: 0.21
step: 317691 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
step: 317692 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 317693 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
step: 318458 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
update:1245/2000, 耗时:0.01分/8.21分 | step: 318720 | performance: 0.3 | accuracy: 0.12 | loss: 0.38
step: 318971 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 319229 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:1250/2000, 耗时:0.01分/8.24分 | step: 320000 | performance: 0.3 | accuracy: 0.12 | loss: 0.18
step: 320508 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:1255/2000, 耗时:0.01分/8.27分 | step: 321280 | performance: 0.3 | accuracy: 0.12 | loss: 0.40
update:1260/2000, 耗时:0.01分/8.31分 | step: 322560 | performance: 0.2 | accuracy: 0.12 | loss: 0.16
update:1265/2000, 耗时:0.01分/8.34分 | step: 323840 | performance: 0.2 | accuracy: 0.12 | loss: 0.19
update:1270/2000, 耗时:0.01分/8.37分 | step: 325120 | performance: 0.2 | accuracy: 0.11 | loss: 0.20
step: 325630 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:1275/2000, 耗时:0.01分/8.41分 | step: 326400 | performance: 0.2 | accuracy: 0.11 | loss: 0.37
step: 327675 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:1280/2000, 耗时:0.01分/8.44分 | step: 327680 | performance: 0.2 | accuracy: 0.11 | loss: 0.45
step: 327933 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:1285/2000, 耗时:0.01分/8.47分 | step: 328960 | performance: 0.2 | accuracy: 0.11 | loss: 0.32
update:1290/2000, 耗时:0.01分/8.50分 | step: 330240 | performance: 0.2 | accuracy: 0.11 | loss: 0.28
update:1295/2000, 耗时:0.01分/8.54分 | step: 331520 | performance: 0.2 | accuracy: 0.11 | loss: 0.44
step: 331774 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
update:1300/2000, 耗时:0.01分/8.57分 | step: 332800 | performance: 1.0 | accuracy: 0.12 | loss: 0.62
update:1305/2000, 耗时:0.01分/8.60分 | step: 334080 | performance: 1.0 | accuracy: 0.13 | loss: 0.51
update:1310/2000, 耗时:0.01分/8.63分 | step: 335360 | performance: 0.8 | accuracy: 0.11 | loss: 0.42
step: 336126 | worker_5@n_step_31: average total_reward after train data exhaustion : 8.2 | max total_reward: 262.8
update:1315/2000, 耗时:0.01分/8.67分 | step: 336640 | performance: 0.7 | accuracy: 0.13 | loss: 0.29
step: 336894 | worker_5@n_step_31: average total_reward after train data exhaustion : 8.3 | max total_reward: 262.8
update:1320/2000, 耗时:0.01分/8.70分 | step: 337920 | performance: 0.7 | accuracy: 0.13 | loss: 0.36
update:1325/2000, 耗时:0.01分/8.73分 | step: 339200 | performance: 0.6 | accuracy: 0.12 | loss: 0.33
update:1330/2000, 耗时:0.01分/8.77分 | step: 340480 | performance: 0.6 | accuracy: 0.13 | loss: 0.30
update:1335/2000, 耗时:0.01分/8.80分 | step: 341760 | performance: 0.6 | accuracy: 0.13 | loss: 0.31
step: 342526 | worker_5@n_step_31: average total_reward after train data exhaustion : 8.0 | max total_reward: 262.8
update:1340/2000, 耗时:0.01分/8.83分 | step: 343040 | performance: 0.7 | accuracy: 0.12 | loss: 0.21
update:1345/2000, 耗时:0.01分/8.86分 | step: 344320 | performance: 0.6 | accuracy: 0.12 | loss: 0.27
update:1350/2000, 耗时:0.01分/8.90分 | step: 345600 | performance: 0.6 | accuracy: 0.12 | loss: 0.27
update:1355/2000, 耗时:0.01分/8.93分 | step: 346880 | performance: 0.5 | accuracy: 0.12 | loss: 0.30
update:1360/2000, 耗时:0.01分/8.96分 | step: 348160 | performance: 0.6 | accuracy: 0.12 | loss: 0.34
update:1365/2000, 耗时:0.01分/8.99分 | step: 349440 | performance: 0.5 | accuracy: 0.12 | loss: 0.27
update:1370/2000, 耗时:0.01分/9.03分 | step: 350720 | performance: 0.5 | accuracy: 0.12 | loss: 0.24
step: 351742 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:1375/2000, 耗时:0.01分/9.06分 | step: 352000 | performance: 0.4 | accuracy: 0.11 | loss: 0.21
update:1380/2000, 耗时:0.01分/9.09分 | step: 353280 | performance: 0.5 | accuracy: 0.11 | loss: 0.20
update:1385/2000, 耗时:0.01分/9.13分 | step: 354560 | performance: 0.4 | accuracy: 0.10 | loss: 0.21
update:1390/2000, 耗时:0.01分/9.16分 | step: 355840 | performance: 0.4 | accuracy: 0.10 | loss: 0.25
update:1395/2000, 耗时:0.01分/9.19分 | step: 357120 | performance: 0.4 | accuracy: 0.10 | loss: 0.54
step: 357372 | worker_3@n_step_31: average total_reward after train data exhaustion : 18.5 | max total_reward: 262.8
step: 358138 | worker_1@n_step_31: average total_reward after train data exhaustion : 9.7 | max total_reward: 262.8
update:1400/2000, 耗时:0.01分/9.22分 | step: 358400 | performance: 0.4 | accuracy: 0.10 | loss: 0.48
step: 358654 | worker_5@n_step_31: average total_reward after train data exhaustion : 9.5 | max total_reward: 262.8
step: 358908 | worker_3@n_step_31: average total_reward after train data exhaustion : 9.2 | max total_reward: 262.8
update:1405/2000, 耗时:0.01分/9.26分 | step: 359680 | performance: 0.4 | accuracy: 0.10 | loss: 0.25
step: 360702 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:1410/2000, 耗时:0.01分/9.29分 | step: 360960 | performance: 0.4 | accuracy: 0.10 | loss: 0.40
step: 362233 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:1415/2000, 耗时:0.01分/9.32分 | step: 362240 | performance: 0.4 | accuracy: 0.10 | loss: 0.31
step: 362751 | worker_6@n_step_31: average total_reward after train data exhaustion : 7.7 | max total_reward: 262.8
update:1420/2000, 耗时:0.01分/9.36分 | step: 363520 | performance: 1.2 | accuracy: 0.13 | loss: 0.26
step: 364032 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 364281 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:1425/2000, 耗时:0.01分/9.39分 | step: 364800 | performance: 1.2 | accuracy: 0.12 | loss: 0.24
step: 365309 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
step: 365312 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
step: 365820 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:1430/2000, 耗时:0.01分/9.42分 | step: 366080 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
step: 366847 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 366848 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 367098 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 367356 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:1435/2000, 耗时:0.01分/9.45分 | step: 367360 | performance: 0.9 | accuracy: 0.11 | loss: 0.20
update:1440/2000, 耗时:0.01分/9.49分 | step: 368640 | performance: 1.0 | accuracy: 0.13 | loss: 0.25
step: 369145 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 369403 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 369918 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:1445/2000, 耗时:0.01分/9.52分 | step: 369920 | performance: 0.9 | accuracy: 0.10 | loss: 0.18
step: 370425 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 262.8
step: 370428 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 262.8
update:1450/2000, 耗时:0.01分/9.56分 | step: 371200 | performance: 0.9 | accuracy: 0.00 | loss: 0.22
step: 372477 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:1455/2000, 耗时:0.01分/9.59分 | step: 372480 | performance: 1.1 | accuracy: 0.12 | loss: 0.19
update:1460/2000, 耗时:0.01分/9.62分 | step: 373760 | performance: 1.0 | accuracy: 0.00 | loss: 0.26
step: 374265 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
step: 374784 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:1465/2000, 耗时:0.01分/9.66分 | step: 375040 | performance: 1.0 | accuracy: 0.13 | loss: 0.39
update:1470/2000, 耗时:0.01分/9.69分 | step: 376320 | performance: 0.6 | accuracy: 0.12 | loss: 0.65
step: 376825 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 262.8
update:1475/2000, 耗时:0.01分/9.72分 | step: 377600 | performance: 1.1 | accuracy: 0.12 | loss: 0.37
update:1480/2000, 耗时:0.01分/9.75分 | step: 378880 | performance: 1.1 | accuracy: 0.11 | loss: 0.49
update:1485/2000, 耗时:0.01分/9.79分 | step: 380160 | performance: 0.9 | accuracy: 0.12 | loss: 0.31
step: 380670 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.4 | max total_reward: 262.8
step: 381177 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.3 | max total_reward: 262.8
step: 381180 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.3 | max total_reward: 262.8
update:1490/2000, 耗时:0.01分/9.82分 | step: 381440 | performance: 0.9 | accuracy: 0.12 | loss: 0.31
update:1495/2000, 耗时:0.01分/9.85分 | step: 382720 | performance: 0.8 | accuracy: 0.12 | loss: 0.33
step: 383484 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:1500/2000, 耗时:0.01分/9.89分 | step: 384000 | performance: 0.8 | accuracy: 0.12 | loss: 0.34
step: 384508 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
step: 385276 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:1505/2000, 耗时:0.01分/9.92分 | step: 385280 | performance: 0.9 | accuracy: 0.12 | loss: 0.35
update:1510/2000, 耗时:0.01分/9.95分 | step: 386560 | performance: 0.7 | accuracy: 0.11 | loss: 0.28
update:1515/2000, 耗时:0.01分/9.99分 | step: 387840 | performance: 0.8 | accuracy: 0.12 | loss: 0.48
update:1520/2000, 耗时:0.01分/10.02分 | step: 389120 | performance: 0.7 | accuracy: 0.12 | loss: 0.26
step: 389626 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:1525/2000, 耗时:0.01分/10.05分 | step: 390400 | performance: 0.9 | accuracy: 0.12 | loss: 0.44
update:1530/2000, 耗时:0.01分/10.09分 | step: 391680 | performance: 0.9 | accuracy: 0.13 | loss: 0.52
update:1535/2000, 耗时:0.01分/10.12分 | step: 392960 | performance: 1.0 | accuracy: 0.13 | loss: 0.61
update:1540/2000, 耗时:0.01分/10.15分 | step: 394240 | performance: 1.0 | accuracy: 0.13 | loss: 0.46
update:1545/2000, 耗时:0.01分/10.19分 | step: 395520 | performance: 1.5 | accuracy: 0.14 | loss: 0.59
update:1550/2000, 耗时:0.01分/10.22分 | step: 396800 | performance: 1.3 | accuracy: 0.14 | loss: 0.53
update:1555/2000, 耗时:0.01分/10.26分 | step: 398080 | performance: 1.0 | accuracy: 0.13 | loss: 0.55
update:1560/2000, 耗时:0.01分/10.29分 | step: 399360 | performance: 1.0 | accuracy: 0.13 | loss: 0.50
update:1565/2000, 耗时:0.01分/10.32分 | step: 400640 | performance: 0.8 | accuracy: 0.13 | loss: 0.50
update:1570/2000, 耗时:0.01分/10.35分 | step: 401920 | performance: 0.8 | accuracy: 0.13 | loss: 0.38
update:1575/2000, 耗时:0.01分/10.39分 | step: 403200 | performance: 0.6 | accuracy: 0.13 | loss: 0.32
update:1580/2000, 耗时:0.01分/10.42分 | step: 404480 | performance: 0.5 | accuracy: 0.13 | loss: 0.45
update:1585/2000, 耗时:0.01分/10.45分 | step: 405760 | performance: 0.5 | accuracy: 0.13 | loss: 0.41
step: 406528 | worker_7@n_step_31: average total_reward after train data exhaustion : 11.3 | max total_reward: 262.8
update:1590/2000, 耗时:0.01分/10.49分 | step: 407040 | performance: 0.9 | accuracy: 0.00 | loss: 0.40
update:1595/2000, 耗时:0.01分/10.52分 | step: 408320 | performance: 0.8 | accuracy: 0.00 | loss: 0.56
update:1600/2000, 耗时:0.01分/10.56分 | step: 409600 | performance: 0.7 | accuracy: 0.11 | loss: 0.37
update:1605/2000, 耗时:0.01分/10.59分 | step: 410880 | performance: 0.8 | accuracy: 0.11 | loss: 0.37
update:1610/2000, 耗时:0.01分/10.62分 | step: 412160 | performance: 0.7 | accuracy: 0.12 | loss: 0.47
step: 412921 | worker_0@n_step_31: average total_reward after train data exhaustion : 9.0 | max total_reward: 262.8
update:1615/2000, 耗时:0.01分/10.65分 | step: 413440 | performance: 0.7 | accuracy: 0.11 | loss: 0.26
update:1620/2000, 耗时:0.01分/10.69分 | step: 414720 | performance: 0.6 | accuracy: 0.11 | loss: 0.15
update:1625/2000, 耗时:0.01分/10.72分 | step: 416000 | performance: 0.5 | accuracy: 0.11 | loss: 0.34
step: 416249 | worker_0@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 262.8
step: 416253 | worker_4@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 262.8
step: 416254 | worker_5@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 262.8
update:1630/2000, 耗时:0.01分/10.75分 | step: 417280 | performance: 0.5 | accuracy: 0.11 | loss: 0.26
step: 418044 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.1 | max total_reward: 262.8
update:1635/2000, 耗时:0.01分/10.79分 | step: 418560 | performance: 0.5 | accuracy: 0.11 | loss: 0.39
step: 419580 | worker_3@n_step_31: average total_reward after train data exhaustion : 8.2 | max total_reward: 262.8
update:1640/2000, 耗时:0.01分/10.83分 | step: 419840 | performance: 0.5 | accuracy: 0.11 | loss: 0.29
update:1645/2000, 耗时:0.01分/10.86分 | step: 421120 | performance: 0.5 | accuracy: 0.11 | loss: 0.30
update:1650/2000, 耗时:0.01分/10.90分 | step: 422400 | performance: 0.6 | accuracy: 0.11 | loss: 0.43
update:1655/2000, 耗时:0.01分/10.93分 | step: 423680 | performance: 0.7 | accuracy: 0.11 | loss: 0.35
step: 423934 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 424702 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:1660/2000, 耗时:0.01分/10.97分 | step: 424960 | performance: 0.7 | accuracy: 0.12 | loss: 0.39
update:1665/2000, 耗时:0.01分/11.00分 | step: 426240 | performance: 0.8 | accuracy: 0.12 | loss: 0.62
step: 426492 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
step: 427260 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:1670/2000, 耗时:0.01分/11.04分 | step: 427520 | performance: 1.0 | accuracy: 0.12 | loss: 0.53
update:1675/2000, 耗时:0.01分/11.07分 | step: 428800 | performance: 0.8 | accuracy: 0.12 | loss: 0.25
update:1680/2000, 耗时:0.01分/11.11分 | step: 430080 | performance: 0.9 | accuracy: 0.12 | loss: 0.26
update:1685/2000, 耗时:0.01分/11.14分 | step: 431360 | performance: 1.1 | accuracy: 0.12 | loss: 0.45
update:1690/2000, 耗时:0.01分/11.18分 | step: 432640 | performance: 0.9 | accuracy: 0.12 | loss: 0.47
step: 432892 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 262.8
update:1695/2000, 耗时:0.01分/11.21分 | step: 433920 | performance: 0.8 | accuracy: 0.12 | loss: 0.24
update:1700/2000, 耗时:0.01分/11.25分 | step: 435200 | performance: 0.8 | accuracy: 0.12 | loss: 0.48
update:1705/2000, 耗时:0.01分/11.28分 | step: 436480 | performance: 0.7 | accuracy: 0.12 | loss: 0.34
update:1710/2000, 耗时:0.01分/11.31分 | step: 437760 | performance: 0.7 | accuracy: 0.12 | loss: 0.36
step: 438784 | worker_7@n_step_31: average total_reward after train data exhaustion : 8.6 | max total_reward: 262.8
update:1715/2000, 耗时:0.01分/11.34分 | step: 439040 | performance: 1.0 | accuracy: 0.07 | loss: 0.24
update:1720/2000, 耗时:0.01分/11.38分 | step: 440320 | performance: 1.0 | accuracy: 0.00 | loss: 0.34
update:1725/2000, 耗时:0.01分/11.41分 | step: 441600 | performance: 1.2 | accuracy: 0.10 | loss: 0.39
step: 442364 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
step: 442624 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 442875 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:1730/2000, 耗时:0.01分/11.44分 | step: 442880 | performance: 1.0 | accuracy: 0.12 | loss: 0.49
step: 444155 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:1735/2000, 耗时:0.01分/11.48分 | step: 444160 | performance: 1.1 | accuracy: 0.12 | loss: 0.43
step: 445440 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:1740/2000, 耗时:0.01分/11.51分 | step: 445440 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
update:1745/2000, 耗时:0.01分/11.54分 | step: 446720 | performance: 1.1 | accuracy: 0.10 | loss: 0.25
update:1750/2000, 耗时:0.01分/11.58分 | step: 448000 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 448256 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:1755/2000, 耗时:0.01分/11.61分 | step: 449280 | performance: 1.2 | accuracy: 0.15 | loss: 0.40
step: 450043 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
step: 450560 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 262.8
update:1760/2000, 耗时:0.01分/11.64分 | step: 450560 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
step: 450811 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 262.8
step: 451584 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 262.8
update:1765/2000, 耗时:0.01分/11.67分 | step: 451840 | performance: 1.0 | accuracy: 0.12 | loss: 0.22
update:1770/2000, 耗时:0.01分/11.71分 | step: 453120 | performance: 1.2 | accuracy: 0.15 | loss: 0.52
update:1775/2000, 耗时:0.01分/11.74分 | step: 454400 | performance: 1.4 | accuracy: 0.14 | loss: 0.41
step: 454654 | worker_5@n_step_31: average total_reward after train data exhaustion : 8.3 | max total_reward: 262.8
update:1780/2000, 耗时:0.01分/11.77分 | step: 455680 | performance: 1.2 | accuracy: 0.13 | loss: 0.16
update:1785/2000, 耗时:0.01分/11.81分 | step: 456960 | performance: 1.1 | accuracy: 0.12 | loss: 0.19
step: 457214 | worker_5@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 262.8
step: 457981 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:1790/2000, 耗时:0.01分/11.84分 | step: 458240 | performance: 1.0 | accuracy: 0.12 | loss: 0.20
step: 458750 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:1795/2000, 耗时:0.01分/11.87分 | step: 459520 | performance: 1.1 | accuracy: 0.12 | loss: 0.23
step: 459773 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
step: 460028 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.0 | max total_reward: 262.8
step: 460799 | worker_6@n_step_31: average total_reward after train data exhaustion : 3.8 | max total_reward: 262.8
update:1800/2000, 耗时:0.01分/11.90分 | step: 460800 | performance: 1.2 | accuracy: 0.12 | loss: 0.21
step: 461310 | worker_5@n_step_31: average total_reward after train data exhaustion : 3.8 | max total_reward: 262.8
update:1805/2000, 耗时:0.01分/11.94分 | step: 462080 | performance: 1.0 | accuracy: 0.11 | loss: 0.27
update:1810/2000, 耗时:0.01分/11.97分 | step: 463360 | performance: 0.9 | accuracy: 0.12 | loss: 0.23
update:1815/2000, 耗时:0.01分/12.00分 | step: 464640 | performance: 0.8 | accuracy: 0.12 | loss: 0.31
step: 465402 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 262.8
update:1820/2000, 耗时:0.01分/12.04分 | step: 465920 | performance: 0.7 | accuracy: 0.12 | loss: 0.37
step: 466429 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
step: 466938 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
update:1825/2000, 耗时:0.01分/12.07分 | step: 467200 | performance: 0.7 | accuracy: 0.12 | loss: 0.20
step: 467708 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:1830/2000, 耗时:0.01分/12.10分 | step: 468480 | performance: 0.8 | accuracy: 0.12 | loss: 0.47
step: 469754 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:1835/2000, 耗时:0.01分/12.13分 | step: 469760 | performance: 0.8 | accuracy: 0.12 | loss: 0.23
update:1840/2000, 耗时:0.01分/12.17分 | step: 471040 | performance: 1.0 | accuracy: 0.12 | loss: 0.33
step: 471295 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 262.8
update:1845/2000, 耗时:0.01分/12.20分 | step: 472320 | performance: 0.7 | accuracy: 0.12 | loss: 0.23
update:1850/2000, 耗时:0.01分/12.23分 | step: 473600 | performance: 0.7 | accuracy: 0.12 | loss: 0.42
update:1855/2000, 耗时:0.01分/12.27分 | step: 474880 | performance: 0.6 | accuracy: 0.11 | loss: 0.44
update:1860/2000, 耗时:0.01分/12.30分 | step: 476160 | performance: 0.6 | accuracy: 0.11 | loss: 0.20
update:1865/2000, 耗时:0.01分/12.33分 | step: 477440 | performance: 0.6 | accuracy: 0.11 | loss: 0.26
step: 477945 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 262.8
update:1870/2000, 耗时:0.01分/12.36分 | step: 478720 | performance: 0.5 | accuracy: 0.11 | loss: 0.36
update:1875/2000, 耗时:0.01分/12.40分 | step: 480000 | performance: 0.4 | accuracy: 0.11 | loss: 0.25
update:1880/2000, 耗时:0.01分/12.43分 | step: 481280 | performance: 1.0 | accuracy: 0.00 | loss: 0.29
step: 482559 | worker_6@n_step_31: average total_reward after train data exhaustion : 4.7 | max total_reward: 262.8
update:1885/2000, 耗时:0.01分/12.46分 | step: 482560 | performance: 1.1 | accuracy: 0.25 | loss: 0.32
step: 482814 | worker_5@n_step_31: average total_reward after train data exhaustion : 4.8 | max total_reward: 262.8
step: 483839 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 262.8
update:1890/2000, 耗时:0.01分/12.49分 | step: 483840 | performance: 1.2 | accuracy: 0.14 | loss: 0.48
update:1895/2000, 耗时:0.01分/12.53分 | step: 485120 | performance: 1.1 | accuracy: 0.12 | loss: 0.26
update:1900/2000, 耗时:0.01分/12.56分 | step: 486400 | performance: 1.1 | accuracy: 0.13 | loss: 0.32
step: 487166 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
update:1905/2000, 耗时:0.01分/12.59分 | step: 487680 | performance: 1.2 | accuracy: 0.12 | loss: 0.17
step: 488441 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
step: 488959 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 262.8
update:1910/2000, 耗时:0.01分/12.62分 | step: 488960 | performance: 0.9 | accuracy: 0.12 | loss: 0.17
step: 489465 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 489470 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 262.8
update:1915/2000, 耗时:0.01分/12.66分 | step: 490240 | performance: 0.8 | accuracy: 0.12 | loss: 0.32
step: 490495 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 262.8
update:1920/2000, 耗时:0.01分/12.69分 | step: 491520 | performance: 0.9 | accuracy: 0.13 | loss: 0.33
update:1925/2000, 耗时:0.01分/12.72分 | step: 492800 | performance: 1.1 | accuracy: 0.13 | loss: 0.25
step: 493305 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 494078 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
update:1930/2000, 耗时:0.01分/12.75分 | step: 494080 | performance: 1.0 | accuracy: 0.13 | loss: 0.18
step: 495100 | worker_3@n_step_31: average total_reward after train data exhaustion : 2.9 | max total_reward: 262.8
step: 495358 | worker_5@n_step_31: average total_reward after train data exhaustion : 3.0 | max total_reward: 262.8
update:1935/2000, 耗时:0.01分/12.78分 | step: 495360 | performance: 1.0 | accuracy: 0.13 | loss: 0.22
step: 496121 | worker_0@n_step_31: average total_reward after train data exhaustion : 3.1 | max total_reward: 262.8
step: 496126 | worker_5@n_step_31: average total_reward after train data exhaustion : 3.1 | max total_reward: 262.8
update:1940/2000, 耗时:0.01分/12.82分 | step: 496640 | performance: 0.9 | accuracy: 0.12 | loss: 0.31
update:1945/2000, 耗时:0.01分/12.85分 | step: 497920 | performance: 1.0 | accuracy: 0.13 | loss: 0.32
step: 498173 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 262.8
update:1950/2000, 耗时:0.01分/12.88分 | step: 499200 | performance: 1.0 | accuracy: 0.12 | loss: 0.24
step: 499705 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 262.8
step: 500477 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 262.8
step: 500478 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 262.8
update:1955/2000, 耗时:0.01分/12.91分 | step: 500480 | performance: 1.0 | accuracy: 0.12 | loss: 0.19
update:1960/2000, 耗时:0.01分/12.95分 | step: 501760 | performance: 0.9 | accuracy: 0.12 | loss: 0.21
step: 502010 | worker_1@n_step_31: average total_reward after train data exhaustion : 4.4 | max total_reward: 262.8
step: 502014 | worker_5@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 262.8
step: 502015 | worker_6@n_step_31: average total_reward after train data exhaustion : 4.4 | max total_reward: 262.8
update:1965/2000, 耗时:0.01分/12.98分 | step: 503040 | performance: 1.2 | accuracy: 0.12 | loss: 0.46
update:1970/2000, 耗时:0.01分/13.01分 | step: 504320 | performance: 1.3 | accuracy: 0.12 | loss: 0.31
update:1975/2000, 耗时:0.01分/13.04分 | step: 505600 | performance: 1.2 | accuracy: 0.12 | loss: 0.55
update:1980/2000, 耗时:0.01分/13.08分 | step: 506880 | performance: 0.9 | accuracy: 0.12 | loss: 0.30
update:1985/2000, 耗时:0.01分/13.11分 | step: 508160 | performance: 1.1 | accuracy: 0.12 | loss: 0.48
update:1990/2000, 耗时:0.01分/13.14分 | step: 509440 | performance: 0.9 | accuracy: 0.12 | loss: 0.48
update:1995/2000, 耗时:0.01分/13.17分 | step: 510720 | performance: 0.7 | accuracy: 0.12 | loss: 0.44
  0%|          | 0/391 [00:00<?, ?it/s]100%|| 391/391 [00:00<00:00, 130291.00it/s]
update:2000/2000, 耗时:0.01分/13.21分 | step: 512000 | performance: 0.7 | accuracy: 0.12 | loss: 0.41
----------------------------------------finished----------------------------------------
==================================================
2023-01-10T12:00:00 | *** START BACKTEST ***
2023-01-10T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1457.36
2023-07-24T12:00:00 | net performance [%] = 45.7365
2023-07-24T12:00:00 | number of trades [#] = 2
==================================================
Trial 30 Complete [00h 13m 39s]
net_wealth: 1458.8234137872605

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 04h 13m 28s

Search: Running Trial #31

Value             |Best Value So Far |Hyperparameter
6                 |1                 |horizon
730               |730               |lookback
False             |False             |MarketFactor
5                 |3                 |lags
0.7               |0.92              |gamma
16                |32                |batch_size
1                 |1                 |n_step
0.92              |0.94              |gae_lambda
10                |5                 |gradient_clip_norm
3                 |5                 |epochs
5e-05             |0.0001            |actor_lr
0.0005            |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4309.000000   4315.000000
mean      0.000441    20062.255222  ...   20140.547965  20118.633889
std       0.027818    16039.874230  ...   16077.550480  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7699.189941   7690.540039
50%       0.000642    11554.824463  ...   11743.940430  11715.610352
75%       0.011655    29873.081836  ...   29950.949219  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-072023-07-28 02:16:51.372138: I tensorflow2202023-07-28 02:16:51.3-3722022168: 38- I02:16:510.7-237218- 0 2:t21607:8: I t52-1280eenso2./cor 3ne/plats-0roflrowfl/co7f0o-282ormw /cpu:r021/co_ef/6eatrure:51e._3g3/pplluaatrd.cc:7f2117:2412] 8T288: I tensorflo:ow/c1 I o6arh:tm5/c1ft.eipre/platuorf3m7o2_f21r1nsms:or e aftl/Iu terTcpueeo/_cfeap_ut_gfueuarnrasturew/core_o_nsgrogdF.crufaluco:r20231d2a0l2rd3w-/.-oc04.2c07w- 27c]b inar-28 Tcore0:y18/ 0phci:e2:4122]4latf2or:1s 6m/:]51/cplpu 16:5 1T_feaTtenfa Thih.ii3s7st2u6 6sor.T 0optei3eor_m:n sorFlow IrizedmguarF w7 bilow ittndb/ic2p642: I es Tnenash oneAntu._roy sroary ifsrPefI Deep Neural Network Library (olow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPIensorfi FDn loow/ptisa oeDNN) tpcticcmized:1m4 iwozrith e2ed ] o/wpitnlh oneeAATPI aPDehepI  DNelies eouraelpet  opwf NTtbi nNeuorree tNenuawussereo_ rtuork Lirahe famglu /cprary isN oeu_fdlp Nettewt.imaoFocitlrowlbwork Licbrr uzlary:1e4d2 ]w aTr yrhe_gk( ioowbning ietuaCLDibNrasiNnr) Pha ro nTy (roye (U nidns.toretAPe DnNcscN) :neDNo1ruFctiNI ts ooo u ptis4lDe)eus 2eot] Theihm itw  tbhopoinzsei n eNdfo l leou us wiweitThe nsralsoenogne infor  NAlePtIl t FpleorwfD eorma nbioCary iPwnarhye fsU  woeroklionptp lg iCmPi  iLibrarnUozweyNecureid ng- cwriats iC(Poihs ttU nolp  rNicaie insttucettionsrlw oDrno puersitrkuNomNc ncteatinLi)  perAttionifioioonso zn use sP bsth:Ii Drian eneep e folp Nplede  wrirofwtfoieuorralrhr mrman nNg ece-cCytan oAnV m(aPeoAnnwUX cPrIecDeN-critical opNeit ori-crit) enrDe kistructions in perfore amiAtpLtanceo uibrVX2
Toicaas-clr oer yt (o iNonnctailc ao hs:  Appee fel oeenable thuVX AVX2
To enable them in other operations, rebuild TensorrerFloDNN)olweral tlowipaoa twiie  mn gtrtaioonnsNt h the appruisne othere t sio:C  PU n:  AsV:X AVAo oX2 peVXinthewprA VfXo ArVaXllo AVi
orkwti2
X2
To To eniate structionnabonsaLnle,ibrars in brlebeT ue  poeyr  comp(fg CPU iort elnoihthem in otablmld Teneaemi innhncee oser-rcriotrinsetr u DoNpcN atecftiolh)ratiFololth o tew pennor opem iwags.s,nith s
 use the  ot erat in perebuifrforrationld osmTenhe:anctlhlowing Cie-crri ti e aoso pproprAVX AoPicnasVUpal,rX2
To inst F enablete rebuild TensorFlow with the appropriate compiler flags.
compiler flags.
e them in other operations, rebuild TensorFlow with the appropriate compiler flags.
low with the appropriate compiler flags.
rat ructions in peoperations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
ions, rebuild TensorFlow with the appropriate compiler flags.
rformance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 02:16:51.995707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:16:51.999148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:16:52.006007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:16:52.012560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:16:52.017182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:16:52.031531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:16:52.036563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:16:52.036899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.02分 | step:    40 | performance: 1.1 | accuracy: 0.60 | loss: 0.55
update: 10/2000, 耗时:0.00分/0.03分 | step:    80 | performance: 1.0 | accuracy: 0.40 | loss: 0.91
update: 15/2000, 耗时:0.00分/0.04分 | step:   120 | performance: 1.0 | accuracy: 0.47 | loss: 0.60
update: 20/2000, 耗时:0.00分/0.04分 | step:   160 | performance: 0.9 | accuracy: 0.40 | loss: 0.57
update: 25/2000, 耗时:0.00分/0.05分 | step:   200 | performance: 0.9 | accuracy: 0.40 | loss: 0.54
update: 30/2000, 耗时:0.00分/0.06分 | step:   240 | performance: 1.0 | accuracy: 0.43 | loss: 0.53
update: 35/2000, 耗时:0.00分/0.06分 | step:   280 | performance: 1.0 | accuracy: 0.49 | loss: 0.54
update: 40/2000, 耗时:0.00分/0.07分 | step:   320 | performance: 1.1 | accuracy: 0.47 | loss: 0.45
update: 45/2000, 耗时:0.00分/0.07分 | step:   360 | performance: 1.1 | accuracy: 0.44 | loss: 0.52
update: 50/2000, 耗时:0.00分/0.08分 | step:   400 | performance: 1.0 | accuracy: 0.42 | loss: 0.39
update: 55/2000, 耗时:0.00分/0.09分 | step:   440 | performance: 1.2 | accuracy: 0.47 | loss: 0.29
update: 60/2000, 耗时:0.00分/0.09分 | step:   480 | performance: 1.2 | accuracy: 0.47 | loss: 0.47
update: 65/2000, 耗时:0.00分/0.10分 | step:   520 | performance: 1.2 | accuracy: 0.46 | loss: 0.07
update: 70/2000, 耗时:0.00分/0.11分 | step:   560 | performance: 1.2 | accuracy: 0.44 | loss: 0.31
update: 75/2000, 耗时:0.00分/0.11分 | step:   600 | performance: 1.2 | accuracy: 0.43 | loss: 0.25
update: 80/2000, 耗时:0.00分/0.12分 | step:   640 | performance: 1.2 | accuracy: 0.45 | loss: 0.44
update: 85/2000, 耗时:0.00分/0.13分 | step:   680 | performance: 1.3 | accuracy: 0.45 | loss: 0.55
update: 90/2000, 耗时:0.00分/0.13分 | step:   720 | performance: 1.1 | accuracy: 0.43 | loss: 0.90
update: 95/2000, 耗时:0.00分/0.14分 | step:   760 | performance: 1.4 | accuracy: 0.46 | loss: 0.54
update:100/2000, 耗时:0.00分/0.14分 | step:   800 | performance: 1.3 | accuracy: 0.45 | loss: 0.46
update:105/2000, 耗时:0.00分/0.15分 | step:   840 | performance: 1.3 | accuracy: 0.43 | loss: 0.38
update:110/2000, 耗时:0.00分/0.16分 | step:   880 | performance: 1.3 | accuracy: 0.42 | loss: 0.45
update:115/2000, 耗时:0.00分/0.17分 | step:   920 | performance: 1.3 | accuracy: 0.41 | loss: 0.32
update:120/2000, 耗时:0.00分/0.17分 | step:   960 | performance: 1.2 | accuracy: 0.39 | loss: 0.40
update:125/2000, 耗时:0.00分/0.18分 | step:  1000 | performance: 1.2 | accuracy: 0.40 | loss: 0.27
update:130/2000, 耗时:0.00分/0.19分 | step:  1040 | performance: 1.2 | accuracy: 0.39 | loss: 0.41
update:135/2000, 耗时:0.00分/0.19分 | step:  1080 | performance: 1.3 | accuracy: 0.41 | loss: 0.30
update:140/2000, 耗时:0.00分/0.20分 | step:  1120 | performance: 1.3 | accuracy: 0.40 | loss: 0.58
update:145/2000, 耗时:0.00分/0.21分 | step:  1160 | performance: 1.2 | accuracy: 0.39 | loss: 0.24
update:150/2000, 耗时:0.00分/0.21分 | step:  1200 | performance: 1.1 | accuracy: 0.39 | loss: 0.90
update:155/2000, 耗时:0.00分/0.22分 | step:  1240 | performance: 1.0 | accuracy: 0.38 | loss: 0.72
update:160/2000, 耗时:0.00分/0.23分 | step:  1280 | performance: 1.2 | accuracy: 0.39 | loss: 0.88
update:165/2000, 耗时:0.00分/0.23分 | step:  1320 | performance: 0.7 | accuracy: 0.38 | loss: 0.81
update:170/2000, 耗时:0.00分/0.24分 | step:  1360 | performance: 0.8 | accuracy: 0.39 | loss: 1.55
update:175/2000, 耗时:0.00分/0.25分 | step:  1400 | performance: 0.6 | accuracy: 0.39 | loss: 1.47
update:180/2000, 耗时:0.00分/0.26分 | step:  1440 | performance: 0.6 | accuracy: 0.39 | loss: 1.36
update:185/2000, 耗时:0.00分/0.26分 | step:  1480 | performance: 0.6 | accuracy: 0.39 | loss: 0.36
update:190/2000, 耗时:0.00分/0.27分 | step:  1520 | performance: 0.6 | accuracy: 0.39 | loss: 0.90
update:195/2000, 耗时:0.00分/0.28分 | step:  1560 | performance: 0.6 | accuracy: 0.39 | loss: 0.84
update:200/2000, 耗时:0.00分/0.28分 | step:  1600 | performance: 0.5 | accuracy: 0.38 | loss: 0.23
update:205/2000, 耗时:0.00分/0.29分 | step:  1640 | performance: 0.5 | accuracy: 0.38 | loss: 0.30
update:210/2000, 耗时:0.00分/0.30分 | step:  1680 | performance: 0.5 | accuracy: 0.38 | loss: 0.33
update:215/2000, 耗时:0.00分/0.31分 | step:  1720 | performance: 0.5 | accuracy: 0.38 | loss: 0.17
update:220/2000, 耗时:0.00分/0.31分 | step:  1760 | performance: 0.4 | accuracy: 0.37 | loss: 0.94
update:225/2000, 耗时:0.00分/0.32分 | step:  1800 | performance: 0.3 | accuracy: 0.37 | loss: 0.63
update:230/2000, 耗时:0.00分/0.33分 | step:  1840 | performance: 0.3 | accuracy: 0.37 | loss: 0.11
update:235/2000, 耗时:0.00分/0.33分 | step:  1880 | performance: 0.3 | accuracy: 0.37 | loss: 0.79
update:240/2000, 耗时:0.00分/0.34分 | step:  1920 | performance: 0.3 | accuracy: 0.37 | loss: 0.21
update:245/2000, 耗时:0.00分/0.35分 | step:  1960 | performance: 0.3 | accuracy: 0.37 | loss: 0.64
update:250/2000, 耗时:0.00分/0.36分 | step:  2000 | performance: 0.3 | accuracy: 0.36 | loss: 0.43
update:255/2000, 耗时:0.00分/0.36分 | step:  2040 | performance: 0.3 | accuracy: 0.36 | loss: 0.43
update:260/2000, 耗时:0.00分/0.37分 | step:  2080 | performance: 0.3 | accuracy: 0.35 | loss: 0.30
update:265/2000, 耗时:0.00分/0.38分 | step:  2120 | performance: 0.3 | accuracy: 0.35 | loss: 0.90
update:270/2000, 耗时:0.00分/0.38分 | step:  2160 | performance: 0.3 | accuracy: 0.35 | loss: 0.31
update:275/2000, 耗时:0.00分/0.39分 | step:  2200 | performance: 0.3 | accuracy: 0.35 | loss: 0.20
update:280/2000, 耗时:0.00分/0.40分 | step:  2240 | performance: 0.3 | accuracy: 0.35 | loss: 0.37
update:285/2000, 耗时:0.00分/0.41分 | step:  2280 | performance: 0.3 | accuracy: 0.35 | loss: 0.50
update:290/2000, 耗时:0.00分/0.41分 | step:  2320 | performance: 0.2 | accuracy: 0.34 | loss: 0.19
update:295/2000, 耗时:0.00分/0.42分 | step:  2360 | performance: 0.3 | accuracy: 0.35 | loss: 0.43
update:300/2000, 耗时:0.00分/0.43分 | step:  2400 | performance: 0.3 | accuracy: 0.35 | loss: 0.60
update:305/2000, 耗时:0.00分/0.43分 | step:  2440 | performance: 0.3 | accuracy: 0.35 | loss: 0.04
update:310/2000, 耗时:0.00分/0.44分 | step:  2480 | performance: 0.3 | accuracy: 0.35 | loss: 0.38
update:315/2000, 耗时:0.00分/0.45分 | step:  2520 | performance: 0.3 | accuracy: 0.35 | loss: 0.30
update:320/2000, 耗时:0.00分/0.46分 | step:  2560 | performance: 0.3 | accuracy: 0.35 | loss: 0.23
update:325/2000, 耗时:0.00分/0.46分 | step:  2600 | performance: 0.3 | accuracy: 0.34 | loss: 0.75
update:330/2000, 耗时:0.00分/0.47分 | step:  2640 | performance: 0.3 | accuracy: 0.35 | loss: 0.42
update:335/2000, 耗时:0.00分/0.48分 | step:  2680 | performance: 0.3 | accuracy: 0.35 | loss: 0.10
update:340/2000, 耗时:0.00分/0.48分 | step:  2720 | performance: 0.3 | accuracy: 0.35 | loss: 0.50
update:345/2000, 耗时:0.00分/0.49分 | step:  2760 | performance: 0.3 | accuracy: 0.35 | loss: 0.38
update:350/2000, 耗时:0.00分/0.50分 | step:  2800 | performance: 0.3 | accuracy: 0.34 | loss: 0.25
update:355/2000, 耗时:0.00分/0.51分 | step:  2840 | performance: 0.3 | accuracy: 0.34 | loss: 0.36
update:360/2000, 耗时:0.00分/0.51分 | step:  2880 | performance: 0.3 | accuracy: 0.35 | loss: 0.49
update:365/2000, 耗时:0.00分/0.52分 | step:  2920 | performance: 0.3 | accuracy: 0.34 | loss: 0.37
update:370/2000, 耗时:0.00分/0.53分 | step:  2960 | performance: 0.3 | accuracy: 0.34 | loss: 0.35
update:375/2000, 耗时:0.00分/0.54分 | step:  3000 | performance: 0.4 | accuracy: 0.35 | loss: 0.61
update:380/2000, 耗时:0.00分/0.54分 | step:  3040 | performance: 0.4 | accuracy: 0.35 | loss: 0.55
update:385/2000, 耗时:0.00分/0.55分 | step:  3080 | performance: 0.4 | accuracy: 0.35 | loss: 0.32
update:390/2000, 耗时:0.00分/0.56分 | step:  3120 | performance: 0.4 | accuracy: 0.35 | loss: 0.18
update:395/2000, 耗时:0.00分/0.57分 | step:  3160 | performance: 0.4 | accuracy: 0.36 | loss: 0.50
update:400/2000, 耗时:0.00分/0.57分 | step:  3200 | performance: 0.4 | accuracy: 0.35 | loss: 0.37
update:405/2000, 耗时:0.00分/0.58分 | step:  3240 | performance: 0.4 | accuracy: 0.35 | loss: 0.19
update:410/2000, 耗时:0.00分/0.59分 | step:  3280 | performance: 0.4 | accuracy: 0.35 | loss: 0.31
update:415/2000, 耗时:0.00分/0.59分 | step:  3320 | performance: 0.4 | accuracy: 0.35 | loss: 0.33
update:420/2000, 耗时:0.00分/0.60分 | step:  3360 | performance: 0.4 | accuracy: 0.35 | loss: 0.17
update:425/2000, 耗时:0.00分/0.61分 | step:  3400 | performance: 0.4 | accuracy: 0.35 | loss: 0.24
update:430/2000, 耗时:0.00分/0.62分 | step:  3440 | performance: 0.4 | accuracy: 0.35 | loss: 0.92
update:435/2000, 耗时:0.00分/0.62分 | step:  3480 | performance: 0.5 | accuracy: 0.35 | loss: 0.45
update:440/2000, 耗时:0.00分/0.63分 | step:  3520 | performance: 0.4 | accuracy: 0.35 | loss: 0.15
update:445/2000, 耗时:0.00分/0.64分 | step:  3560 | performance: 0.4 | accuracy: 0.35 | loss: 0.38
update:450/2000, 耗时:0.00分/0.64分 | step:  3600 | performance: 0.5 | accuracy: 0.35 | loss: 0.50
update:455/2000, 耗时:0.00分/0.65分 | step:  3640 | performance: 0.5 | accuracy: 0.35 | loss: 0.30
update:460/2000, 耗时:0.00分/0.66分 | step:  3680 | performance: 0.5 | accuracy: 0.35 | loss: 0.45
update:465/2000, 耗时:0.00分/0.67分 | step:  3720 | performance: 0.5 | accuracy: 0.35 | loss: 0.21
update:470/2000, 耗时:0.00分/0.67分 | step:  3760 | performance: 0.5 | accuracy: 0.35 | loss: 0.25
update:475/2000, 耗时:0.00分/0.68分 | step:  3800 | performance: 0.5 | accuracy: 0.35 | loss: 0.24
update:480/2000, 耗时:0.00分/0.69分 | step:  3840 | performance: 0.5 | accuracy: 0.35 | loss: 0.45
update:485/2000, 耗时:0.00分/0.69分 | step:  3880 | performance: 0.5 | accuracy: 0.34 | loss: 0.46
update:490/2000, 耗时:0.00分/0.70分 | step:  3920 | performance: 0.5 | accuracy: 0.34 | loss: 0.61
update:495/2000, 耗时:0.00分/0.71分 | step:  3960 | performance: 0.4 | accuracy: 0.34 | loss: 0.34
update:500/2000, 耗时:0.00分/0.71分 | step:  4000 | performance: 0.4 | accuracy: 0.34 | loss: 0.51
update:505/2000, 耗时:0.00分/0.72分 | step:  4040 | performance: 0.5 | accuracy: 0.34 | loss: 0.49
update:510/2000, 耗时:0.00分/0.73分 | step:  4080 | performance: 0.4 | accuracy: 0.34 | loss: 0.72
update:515/2000, 耗时:0.00分/0.73分 | step:  4120 | performance: 0.5 | accuracy: 0.34 | loss: 0.26
update:520/2000, 耗时:0.00分/0.74分 | step:  4160 | performance: 0.5 | accuracy: 0.34 | loss: 0.17
update:525/2000, 耗时:0.00分/0.75分 | step:  4200 | performance: 0.5 | accuracy: 0.34 | loss: 0.01
update:530/2000, 耗时:0.00分/0.75分 | step:  4240 | performance: 0.5 | accuracy: 0.34 | loss: 0.02
update:535/2000, 耗时:0.00分/0.76分 | step:  4280 | performance: 0.5 | accuracy: 0.33 | loss: 0.43
update:540/2000, 耗时:0.00分/0.77分 | step:  4320 | performance: 0.5 | accuracy: 0.33 | loss: 0.75
update:545/2000, 耗时:0.00分/0.77分 | step:  4360 | performance: 0.5 | accuracy: 0.34 | loss: 0.31
update:550/2000, 耗时:0.00分/0.78分 | step:  4400 | performance: 0.5 | accuracy: 0.34 | loss: 0.57
update:555/2000, 耗时:0.00分/0.79分 | step:  4440 | performance: 0.6 | accuracy: 0.34 | loss: 0.83
update:560/2000, 耗时:0.00分/0.80分 | step:  4480 | performance: 0.7 | accuracy: 0.34 | loss: 0.31
update:565/2000, 耗时:0.00分/0.80分 | step:  4520 | performance: 0.7 | accuracy: 0.34 | loss: 0.43
update:570/2000, 耗时:0.00分/0.81分 | step:  4560 | performance: 0.6 | accuracy: 0.34 | loss: 0.60
update:575/2000, 耗时:0.00分/0.82分 | step:  4600 | performance: 0.7 | accuracy: 0.34 | loss: 0.57
update:580/2000, 耗时:0.00分/0.82分 | step:  4640 | performance: 0.7 | accuracy: 0.34 | loss: 0.67
update:585/2000, 耗时:0.00分/0.83分 | step:  4680 | performance: 0.8 | accuracy: 0.34 | loss: 0.25
update:590/2000, 耗时:0.00分/0.84分 | step:  4720 | performance: 0.9 | accuracy: 0.34 | loss: 0.68
update:595/2000, 耗时:0.00分/0.84分 | step:  4760 | performance: 0.8 | accuracy: 0.34 | loss: 0.20
update:600/2000, 耗时:0.00分/0.85分 | step:  4800 | performance: 0.6 | accuracy: 0.34 | loss: 0.25
update:605/2000, 耗时:0.00分/0.86分 | step:  4840 | performance: 0.6 | accuracy: 0.33 | loss: 0.19
update:610/2000, 耗时:0.00分/0.87分 | step:  4880 | performance: 0.8 | accuracy: 0.33 | loss: 0.13
update:615/2000, 耗时:0.00分/0.87分 | step:  4920 | performance: 0.7 | accuracy: 0.33 | loss: 0.39
update:620/2000, 耗时:0.00分/0.88分 | step:  4960 | performance: 0.7 | accuracy: 0.33 | loss: 0.46
update:625/2000, 耗时:0.00分/0.89分 | step:  5000 | performance: 1.1 | accuracy: 0.34 | loss: 1.18
update:630/2000, 耗时:0.00分/0.89分 | step:  5040 | performance: 0.9 | accuracy: 0.33 | loss: 0.46
update:635/2000, 耗时:0.00分/0.90分 | step:  5080 | performance: 0.9 | accuracy: 0.33 | loss: 1.35
update:640/2000, 耗时:0.00分/0.91分 | step:  5120 | performance: 0.9 | accuracy: 0.33 | loss: 0.33
update:645/2000, 耗时:0.00分/0.91分 | step:  5160 | performance: 0.8 | accuracy: 0.33 | loss: 0.02
update:650/2000, 耗时:0.00分/0.92分 | step:  5200 | performance: 0.8 | accuracy: 0.33 | loss: 0.40
update:655/2000, 耗时:0.00分/0.93分 | step:  5240 | performance: 0.9 | accuracy: 0.34 | loss: 0.66
update:660/2000, 耗时:0.00分/0.93分 | step:  5280 | performance: 0.9 | accuracy: 0.34 | loss: 0.57
update:665/2000, 耗时:0.00分/0.94分 | step:  5320 | performance: 0.9 | accuracy: 0.34 | loss: -0.02
update:670/2000, 耗时:0.00分/0.95分 | step:  5360 | performance: 0.9 | accuracy: 0.33 | loss: 1.08
update:675/2000, 耗时:0.00分/0.95分 | step:  5400 | performance: 0.9 | accuracy: 0.33 | loss: 0.53
update:680/2000, 耗时:0.00分/0.96分 | step:  5440 | performance: 0.7 | accuracy: 0.33 | loss: 0.62
update:685/2000, 耗时:0.00分/0.97分 | step:  5480 | performance: 0.8 | accuracy: 0.33 | loss: 0.55
update:690/2000, 耗时:0.00分/0.98分 | step:  5520 | performance: 0.8 | accuracy: 0.33 | loss: 0.12
update:695/2000, 耗时:0.00分/0.98分 | step:  5560 | performance: 0.9 | accuracy: 0.33 | loss: 0.47
update:700/2000, 耗时:0.00分/0.99分 | step:  5600 | performance: 0.8 | accuracy: 0.33 | loss: 0.54
update:705/2000, 耗时:0.00分/1.00分 | step:  5640 | performance: 0.8 | accuracy: 0.33 | loss: 0.79
update:710/2000, 耗时:0.00分/1.00分 | step:  5680 | performance: 0.8 | accuracy: 0.33 | loss: 0.41
update:715/2000, 耗时:0.00分/1.01分 | step:  5720 | performance: 0.7 | accuracy: 0.33 | loss: 0.33
update:720/2000, 耗时:0.00分/1.02分 | step:  5760 | performance: 0.7 | accuracy: 0.33 | loss: 0.38
update:725/2000, 耗时:0.00分/1.03分 | step:  5800 | performance: 0.8 | accuracy: 0.33 | loss: 0.69
update:730/2000, 耗时:0.00分/1.03分 | step:  5840 | performance: 0.7 | accuracy: 0.33 | loss: 0.35
update:735/2000, 耗时:0.00分/1.04分 | step:  5880 | performance: 0.7 | accuracy: 0.33 | loss: 0.61
update:740/2000, 耗时:0.00分/1.05分 | step:  5920 | performance: 0.9 | accuracy: 0.33 | loss: 0.34
update:745/2000, 耗时:0.00分/1.05分 | step:  5960 | performance: 0.9 | accuracy: 0.33 | loss: 0.37
update:750/2000, 耗时:0.00分/1.06分 | step:  6000 | performance: 1.0 | accuracy: 0.33 | loss: 0.45
update:755/2000, 耗时:0.00分/1.07分 | step:  6040 | performance: 1.0 | accuracy: 0.33 | loss: 0.31
update:760/2000, 耗时:0.00分/1.07分 | step:  6080 | performance: 1.0 | accuracy: 0.33 | loss: 0.54
update:765/2000, 耗时:0.00分/1.08分 | step:  6120 | performance: 0.9 | accuracy: 0.33 | loss: 0.28
update:770/2000, 耗时:0.00分/1.09分 | step:  6160 | performance: 1.0 | accuracy: 0.33 | loss: 0.41
update:775/2000, 耗时:0.00分/1.09分 | step:  6200 | performance: 1.0 | accuracy: 0.33 | loss: 0.31
update:780/2000, 耗时:0.00分/1.10分 | step:  6240 | performance: 1.0 | accuracy: 0.33 | loss: 1.28
update:785/2000, 耗时:0.00分/1.11分 | step:  6280 | performance: 0.8 | accuracy: 0.33 | loss: 0.12
update:790/2000, 耗时:0.00分/1.12分 | step:  6320 | performance: 0.8 | accuracy: 0.33 | loss: 0.41
update:795/2000, 耗时:0.00分/1.12分 | step:  6360 | performance: 0.8 | accuracy: 0.33 | loss: 0.42
update:800/2000, 耗时:0.00分/1.13分 | step:  6400 | performance: 0.8 | accuracy: 0.33 | loss: 0.55
update:805/2000, 耗时:0.00分/1.14分 | step:  6440 | performance: 0.8 | accuracy: 0.33 | loss: 0.48
update:810/2000, 耗时:0.00分/1.14分 | step:  6480 | performance: 0.9 | accuracy: 0.33 | loss: 0.46
update:815/2000, 耗时:0.00分/1.15分 | step:  6520 | performance: 0.9 | accuracy: 0.33 | loss: 0.45
update:820/2000, 耗时:0.00分/1.16分 | step:  6560 | performance: 1.0 | accuracy: 0.33 | loss: 0.34
update:825/2000, 耗时:0.00分/1.16分 | step:  6600 | performance: 0.9 | accuracy: 0.33 | loss: 0.24
update:830/2000, 耗时:0.00分/1.17分 | step:  6640 | performance: 1.0 | accuracy: 0.33 | loss: 0.29
update:835/2000, 耗时:0.00分/1.18分 | step:  6680 | performance: 1.0 | accuracy: 0.33 | loss: 0.24
update:840/2000, 耗时:0.00分/1.19分 | step:  6720 | performance: 0.9 | accuracy: 0.33 | loss: 0.46
update:845/2000, 耗时:0.00分/1.19分 | step:  6760 | performance: 0.7 | accuracy: 0.33 | loss: 1.80
update:850/2000, 耗时:0.00分/1.20分 | step:  6800 | performance: 0.7 | accuracy: 0.33 | loss: 0.58
update:855/2000, 耗时:0.00分/1.21分 | step:  6840 | performance: 0.8 | accuracy: 0.33 | loss: 0.24
update:860/2000, 耗时:0.00分/1.21分 | step:  6880 | performance: 0.8 | accuracy: 0.33 | loss: 0.31
update:865/2000, 耗时:0.00分/1.22分 | step:  6920 | performance: 0.8 | accuracy: 0.33 | loss: 0.22
update:870/2000, 耗时:0.00分/1.23分 | step:  6960 | performance: 0.7 | accuracy: 0.33 | loss: 0.51
update:875/2000, 耗时:0.00分/1.23分 | step:  7000 | performance: 0.7 | accuracy: 0.33 | loss: 0.11
update:880/2000, 耗时:0.00分/1.24分 | step:  7040 | performance: 0.7 | accuracy: 0.33 | loss: 0.34
update:885/2000, 耗时:0.00分/1.25分 | step:  7080 | performance: 0.8 | accuracy: 0.33 | loss: 0.41
update:890/2000, 耗时:0.00分/1.25分 | step:  7120 | performance: 0.7 | accuracy: 0.33 | loss: 0.36
update:895/2000, 耗时:0.00分/1.26分 | step:  7160 | performance: 0.6 | accuracy: 0.33 | loss: 0.69
update:900/2000, 耗时:0.00分/1.27分 | step:  7200 | performance: 0.6 | accuracy: 0.33 | loss: 0.70
update:905/2000, 耗时:0.00分/1.28分 | step:  7240 | performance: 0.6 | accuracy: 0.33 | loss: 0.33
update:910/2000, 耗时:0.00分/1.28分 | step:  7280 | performance: 0.6 | accuracy: 0.33 | loss: 0.73
update:915/2000, 耗时:0.00分/1.29分 | step:  7320 | performance: 0.6 | accuracy: 0.33 | loss: 0.56
update:920/2000, 耗时:0.00分/1.30分 | step:  7360 | performance: 0.6 | accuracy: 0.33 | loss: 0.32
update:925/2000, 耗时:0.00分/1.30分 | step:  7400 | performance: 0.6 | accuracy: 0.33 | loss: 0.34
update:930/2000, 耗时:0.00分/1.31分 | step:  7440 | performance: 0.6 | accuracy: 0.33 | loss: 0.09
update:935/2000, 耗时:0.00分/1.32分 | step:  7480 | performance: 0.5 | accuracy: 0.33 | loss: 0.34
update:940/2000, 耗时:0.00分/1.33分 | step:  7520 | performance: 0.5 | accuracy: 0.33 | loss: 0.45
update:945/2000, 耗时:0.00分/1.33分 | step:  7560 | performance: 0.5 | accuracy: 0.33 | loss: 0.26
update:950/2000, 耗时:0.00分/1.34分 | step:  7600 | performance: 0.4 | accuracy: 0.33 | loss: 0.49
update:955/2000, 耗时:0.00分/1.35分 | step:  7640 | performance: 0.5 | accuracy: 0.33 | loss: 0.30
update:960/2000, 耗时:0.00分/1.36分 | step:  7680 | performance: 0.5 | accuracy: 0.33 | loss: 0.34
update:965/2000, 耗时:0.00分/1.36分 | step:  7720 | performance: 0.5 | accuracy: 0.33 | loss: 0.23
update:970/2000, 耗时:0.00分/1.37分 | step:  7760 | performance: 0.6 | accuracy: 0.33 | loss: 0.35
update:975/2000, 耗时:0.00分/1.38分 | step:  7800 | performance: 0.5 | accuracy: 0.33 | loss: 0.40
update:980/2000, 耗时:0.00分/1.38分 | step:  7840 | performance: 0.5 | accuracy: 0.33 | loss: 0.37
update:985/2000, 耗时:0.00分/1.39分 | step:  7880 | performance: 0.5 | accuracy: 0.33 | loss: 0.07
update:990/2000, 耗时:0.00分/1.40分 | step:  7920 | performance: 0.6 | accuracy: 0.33 | loss: 0.77
update:995/2000, 耗时:0.00分/1.41分 | step:  7960 | performance: 0.6 | accuracy: 0.33 | loss: 0.57
update:1000/2000, 耗时:0.00分/1.41分 | step:  8000 | performance: 0.5 | accuracy: 0.33 | loss: 0.21
update:1005/2000, 耗时:0.00分/1.42分 | step:  8040 | performance: 0.4 | accuracy: 0.33 | loss: 0.71
update:1010/2000, 耗时:0.00分/1.43分 | step:  8080 | performance: 0.4 | accuracy: 0.33 | loss: 0.05
update:1015/2000, 耗时:0.00分/1.44分 | step:  8120 | performance: 0.4 | accuracy: 0.33 | loss: 0.38
update:1020/2000, 耗时:0.00分/1.44分 | step:  8160 | performance: 0.4 | accuracy: 0.33 | loss: 0.27
update:1025/2000, 耗时:0.00分/1.45分 | step:  8200 | performance: 0.4 | accuracy: 0.33 | loss: 0.25
update:1030/2000, 耗时:0.00分/1.46分 | step:  8240 | performance: 0.4 | accuracy: 0.33 | loss: 0.81
update:1035/2000, 耗时:0.00分/1.47分 | step:  8280 | performance: 0.4 | accuracy: 0.33 | loss: 0.61
update:1040/2000, 耗时:0.00分/1.47分 | step:  8320 | performance: 0.4 | accuracy: 0.33 | loss: 0.52
update:1045/2000, 耗时:0.00分/1.48分 | step:  8360 | performance: 0.4 | accuracy: 0.33 | loss: 0.12
update:1050/2000, 耗时:0.00分/1.49分 | step:  8400 | performance: 0.4 | accuracy: 0.32 | loss: 0.09
update:1055/2000, 耗时:0.00分/1.50分 | step:  8440 | performance: 0.4 | accuracy: 0.32 | loss: 0.25
update:1060/2000, 耗时:0.00分/1.50分 | step:  8480 | performance: 0.4 | accuracy: 0.32 | loss: 0.25
update:1065/2000, 耗时:0.00分/1.51分 | step:  8520 | performance: 0.4 | accuracy: 0.32 | loss: 0.41
update:1070/2000, 耗时:0.00分/1.52分 | step:  8560 | performance: 0.4 | accuracy: 0.32 | loss: 0.44
update:1075/2000, 耗时:0.00分/1.52分 | step:  8600 | performance: 0.5 | accuracy: 0.32 | loss: 0.49
update:1080/2000, 耗时:0.00分/1.53分 | step:  8640 | performance: 0.5 | accuracy: 0.33 | loss: 0.43
update:1085/2000, 耗时:0.00分/1.54分 | step:  8680 | performance: 0.5 | accuracy: 0.33 | loss: 0.11
update:1090/2000, 耗时:0.00分/1.55分 | step:  8720 | performance: 0.8 | accuracy: 0.33 | loss: 0.74
update:1095/2000, 耗时:0.00分/1.55分 | step:  8760 | performance: 0.8 | accuracy: 0.33 | loss: 0.40
update:1100/2000, 耗时:0.00分/1.56分 | step:  8800 | performance: 0.8 | accuracy: 0.33 | loss: 0.53
update:1105/2000, 耗时:0.00分/1.57分 | step:  8840 | performance: 0.9 | accuracy: 0.33 | loss: 0.40
update:1110/2000, 耗时:0.00分/1.58分 | step:  8880 | performance: 1.1 | accuracy: 0.33 | loss: 1.04
update:1115/2000, 耗时:0.00分/1.58分 | step:  8920 | performance: 1.0 | accuracy: 0.33 | loss: 0.60
update:1120/2000, 耗时:0.00分/1.59分 | step:  8960 | performance: 1.8 | accuracy: 0.33 | loss: 1.98
update:1125/2000, 耗时:0.00分/1.60分 | step:  9000 | performance: 2.0 | accuracy: 0.33 | loss: 0.23
update:1130/2000, 耗时:0.00分/1.60分 | step:  9040 | performance: 1.8 | accuracy: 0.33 | loss: 0.51
update:1135/2000, 耗时:0.00分/1.61分 | step:  9080 | performance: 3.5 | accuracy: 0.34 | loss: 1.28
update:1140/2000, 耗时:0.00分/1.62分 | step:  9120 | performance: 3.2 | accuracy: 0.34 | loss: 0.79
update:1145/2000, 耗时:0.00分/1.63分 | step:  9160 | performance: 4.8 | accuracy: 0.34 | loss: 0.47
update:1150/2000, 耗时:0.00分/1.63分 | step:  9200 | performance: 4.3 | accuracy: 0.34 | loss: 0.28
update:1155/2000, 耗时:0.00分/1.64分 | step:  9240 | performance: 3.8 | accuracy: 0.34 | loss: 0.12
update:1160/2000, 耗时:0.00分/1.65分 | step:  9280 | performance: 4.0 | accuracy: 0.34 | loss: 0.57
update:1165/2000, 耗时:0.00分/1.66分 | step:  9320 | performance: 3.7 | accuracy: 0.33 | loss: 0.30
update:1170/2000, 耗时:0.00分/1.66分 | step:  9360 | performance: 4.5 | accuracy: 0.34 | loss: 0.18
update:1175/2000, 耗时:0.00分/1.67分 | step:  9400 | performance: 4.9 | accuracy: 0.34 | loss: 0.68
update:1180/2000, 耗时:0.00分/1.68分 | step:  9440 | performance: 5.2 | accuracy: 0.34 | loss: 0.40
update:1185/2000, 耗时:0.00分/1.68分 | step:  9480 | performance: 5.1 | accuracy: 0.34 | loss: 0.32
update:1190/2000, 耗时:0.00分/1.69分 | step:  9520 | performance: 5.2 | accuracy: 0.34 | loss: 0.34
update:1195/2000, 耗时:0.00分/1.70分 | step:  9560 | performance: 5.0 | accuracy: 0.34 | loss: 0.47
update:1200/2000, 耗时:0.00分/1.71分 | step:  9600 | performance: 4.5 | accuracy: 0.33 | loss: 0.05
update:1205/2000, 耗时:0.00分/1.71分 | step:  9640 | performance: 4.7 | accuracy: 0.34 | loss: 0.58
update:1210/2000, 耗时:0.00分/1.72分 | step:  9680 | performance: 5.6 | accuracy: 0.34 | loss: 0.58
update:1215/2000, 耗时:0.00分/1.73分 | step:  9720 | performance: 5.5 | accuracy: 0.34 | loss: 0.85
update:1220/2000, 耗时:0.00分/1.74分 | step:  9760 | performance: 6.5 | accuracy: 0.34 | loss: 0.26
update:1225/2000, 耗时:0.00分/1.74分 | step:  9800 | performance: 6.7 | accuracy: 0.34 | loss: 0.35
update:1230/2000, 耗时:0.00分/1.75分 | step:  9840 | performance: 7.6 | accuracy: 0.34 | loss: 0.44
update:1235/2000, 耗时:0.00分/1.76分 | step:  9880 | performance: 8.1 | accuracy: 0.34 | loss: 0.40
update:1240/2000, 耗时:0.00分/1.76分 | step:  9920 | performance: 10.3 | accuracy: 0.34 | loss: -0.01
update:1245/2000, 耗时:0.00分/1.77分 | step:  9960 | performance: 8.7 | accuracy: 0.34 | loss: 0.19
update:1250/2000, 耗时:0.00分/1.78分 | step: 10000 | performance: 9.0 | accuracy: 0.34 | loss: 0.33
update:1255/2000, 耗时:0.00分/1.79分 | step: 10040 | performance: 8.8 | accuracy: 0.34 | loss: 0.36
update:1260/2000, 耗时:0.00分/1.79分 | step: 10080 | performance: 10.1 | accuracy: 0.34 | loss: 0.53
update:1265/2000, 耗时:0.00分/1.80分 | step: 10120 | performance: 9.7 | accuracy: 0.34 | loss: 0.36
update:1270/2000, 耗时:0.00分/1.81分 | step: 10160 | performance: 9.0 | accuracy: 0.34 | loss: 0.58
update:1275/2000, 耗时:0.00分/1.81分 | step: 10200 | performance: 9.5 | accuracy: 0.34 | loss: 0.25
update:1280/2000, 耗时:0.00分/1.82分 | step: 10240 | performance: 8.5 | accuracy: 0.34 | loss: 0.83
update:1285/2000, 耗时:0.00分/1.83分 | step: 10280 | performance: 8.1 | accuracy: 0.34 | loss: 0.19
update:1290/2000, 耗时:0.00分/1.84分 | step: 10320 | performance: 8.1 | accuracy: 0.33 | loss: 0.11
update:1295/2000, 耗时:0.00分/1.84分 | step: 10360 | performance: 8.3 | accuracy: 0.34 | loss: 0.19
update:1300/2000, 耗时:0.00分/1.85分 | step: 10400 | performance: 8.6 | accuracy: 0.34 | loss: 0.61
update:1305/2000, 耗时:0.00分/1.86分 | step: 10440 | performance: 8.6 | accuracy: 0.34 | loss: 0.37
update:1310/2000, 耗时:0.00分/1.86分 | step: 10480 | performance: 8.7 | accuracy: 0.34 | loss: 0.19
update:1315/2000, 耗时:0.00分/1.87分 | step: 10520 | performance: 8.2 | accuracy: 0.33 | loss: 0.52
update:1320/2000, 耗时:0.00分/1.88分 | step: 10560 | performance: 8.2 | accuracy: 0.33 | loss: 0.32
update:1325/2000, 耗时:0.00分/1.89分 | step: 10600 | performance: 8.1 | accuracy: 0.33 | loss: 0.38
update:1330/2000, 耗时:0.00分/1.89分 | step: 10640 | performance: 7.6 | accuracy: 0.33 | loss: 0.58
update:1335/2000, 耗时:0.00分/1.90分 | step: 10680 | performance: 7.8 | accuracy: 0.33 | loss: 0.26
update:1340/2000, 耗时:0.00分/1.91分 | step: 10720 | performance: 7.9 | accuracy: 0.33 | loss: 0.41
update:1345/2000, 耗时:0.00分/1.91分 | step: 10760 | performance: 8.1 | accuracy: 0.34 | loss: 0.34
update:1350/2000, 耗时:0.00分/1.92分 | step: 10800 | performance: 8.4 | accuracy: 0.34 | loss: 0.57
update:1355/2000, 耗时:0.00分/1.93分 | step: 10840 | performance: 7.9 | accuracy: 0.34 | loss: 0.36
update:1360/2000, 耗时:0.00分/1.94分 | step: 10880 | performance: 8.3 | accuracy: 0.34 | loss: 0.44
update:1365/2000, 耗时:0.00分/1.94分 | step: 10920 | performance: 8.3 | accuracy: 0.34 | loss: 0.34
update:1370/2000, 耗时:0.00分/1.95分 | step: 10960 | performance: 8.1 | accuracy: 0.34 | loss: 0.33
update:1375/2000, 耗时:0.00分/1.96分 | step: 11000 | performance: 8.2 | accuracy: 0.34 | loss: 0.29
update:1380/2000, 耗时:0.00分/1.96分 | step: 11040 | performance: 8.3 | accuracy: 0.34 | loss: 0.33
update:1385/2000, 耗时:0.00分/1.97分 | step: 11080 | performance: 7.6 | accuracy: 0.33 | loss: 0.38
update:1390/2000, 耗时:0.00分/1.98分 | step: 11120 | performance: 7.1 | accuracy: 0.33 | loss: 0.25
update:1395/2000, 耗时:0.00分/1.99分 | step: 11160 | performance: 7.6 | accuracy: 0.33 | loss: 0.73
update:1400/2000, 耗时:0.00分/1.99分 | step: 11200 | performance: 6.2 | accuracy: 0.33 | loss: 0.41
update:1405/2000, 耗时:0.00分/2.00分 | step: 11240 | performance: 6.1 | accuracy: 0.33 | loss: 0.27
update:1410/2000, 耗时:0.00分/2.01分 | step: 11280 | performance: 6.4 | accuracy: 0.33 | loss: -0.00
update:1415/2000, 耗时:0.00分/2.01分 | step: 11320 | performance: 6.4 | accuracy: 0.33 | loss: 0.12
update:1420/2000, 耗时:0.00分/2.02分 | step: 11360 | performance: 6.3 | accuracy: 0.33 | loss: 0.30
update:1425/2000, 耗时:0.00分/2.03分 | step: 11400 | performance: 6.6 | accuracy: 0.33 | loss: 0.39
update:1430/2000, 耗时:0.00分/2.04分 | step: 11440 | performance: 6.4 | accuracy: 0.33 | loss: 0.28
update:1435/2000, 耗时:0.00分/2.04分 | step: 11480 | performance: 5.9 | accuracy: 0.33 | loss: 0.21
update:1440/2000, 耗时:0.00分/2.05分 | step: 11520 | performance: 6.0 | accuracy: 0.33 | loss: 0.51
update:1445/2000, 耗时:0.00分/2.06分 | step: 11560 | performance: 6.4 | accuracy: 0.33 | loss: 0.25
update:1450/2000, 耗时:0.00分/2.06分 | step: 11600 | performance: 6.2 | accuracy: 0.33 | loss: 0.25
update:1455/2000, 耗时:0.00分/2.07分 | step: 11640 | performance: 6.7 | accuracy: 0.33 | loss: 0.14
update:1460/2000, 耗时:0.00分/2.08分 | step: 11680 | performance: 6.9 | accuracy: 0.33 | loss: 0.32
update:1465/2000, 耗时:0.00分/2.08分 | step: 11720 | performance: 6.9 | accuracy: 0.33 | loss: 0.38
update:1470/2000, 耗时:0.00分/2.09分 | step: 11760 | performance: 8.3 | accuracy: 0.33 | loss: 1.34
update:1475/2000, 耗时:0.00分/2.10分 | step: 11800 | performance: 9.3 | accuracy: 0.33 | loss: -0.00
update:1480/2000, 耗时:0.00分/2.11分 | step: 11840 | performance: 9.5 | accuracy: 0.33 | loss: 0.34
update:1485/2000, 耗时:0.00分/2.11分 | step: 11880 | performance: 9.0 | accuracy: 0.33 | loss: 0.40
update:1490/2000, 耗时:0.00分/2.12分 | step: 11920 | performance: 8.7 | accuracy: 0.33 | loss: 0.46
update:1495/2000, 耗时:0.00分/2.13分 | step: 11960 | performance: 8.6 | accuracy: 0.33 | loss: 0.68
update:1500/2000, 耗时:0.00分/2.13分 | step: 12000 | performance: 8.7 | accuracy: 0.33 | loss: 0.19
update:1505/2000, 耗时:0.00分/2.14分 | step: 12040 | performance: 9.0 | accuracy: 0.33 | loss: -0.01
update:1510/2000, 耗时:0.00分/2.15分 | step: 12080 | performance: 8.4 | accuracy: 0.33 | loss: 0.28
update:1515/2000, 耗时:0.00分/2.16分 | step: 12120 | performance: 7.8 | accuracy: 0.32 | loss: 0.27
update:1520/2000, 耗时:0.00分/2.17分 | step: 12160 | performance: 7.6 | accuracy: 0.32 | loss: 0.41
update:1525/2000, 耗时:0.00分/2.17分 | step: 12200 | performance: 7.5 | accuracy: 0.32 | loss: 0.32
update:1530/2000, 耗时:0.00分/2.18分 | step: 12240 | performance: 7.6 | accuracy: 0.32 | loss: 0.31
update:1535/2000, 耗时:0.00分/2.19分 | step: 12280 | performance: 7.4 | accuracy: 0.32 | loss: 0.22
update:1540/2000, 耗时:0.00分/2.20分 | step: 12320 | performance: 7.9 | accuracy: 0.32 | loss: 0.33
update:1545/2000, 耗时:0.00分/2.20分 | step: 12360 | performance: 6.4 | accuracy: 0.32 | loss: 0.27
update:1550/2000, 耗时:0.00分/2.21分 | step: 12400 | performance: 6.5 | accuracy: 0.32 | loss: 0.12
update:1555/2000, 耗时:0.00分/2.22分 | step: 12440 | performance: 6.6 | accuracy: 0.32 | loss: 0.18
update:1560/2000, 耗时:0.00分/2.23分 | step: 12480 | performance: 6.6 | accuracy: 0.32 | loss: 0.29
update:1565/2000, 耗时:0.00分/2.23分 | step: 12520 | performance: 6.1 | accuracy: 0.32 | loss: 0.18
update:1570/2000, 耗时:0.00分/2.24分 | step: 12560 | performance: 6.4 | accuracy: 0.32 | loss: 0.23
update:1575/2000, 耗时:0.00分/2.25分 | step: 12600 | performance: 6.4 | accuracy: 0.32 | loss: 0.01
update:1580/2000, 耗时:0.00分/2.26分 | step: 12640 | performance: 6.2 | accuracy: 0.32 | loss: 0.25
update:1585/2000, 耗时:0.00分/2.26分 | step: 12680 | performance: 6.1 | accuracy: 0.32 | loss: 0.11
update:1590/2000, 耗时:0.00分/2.27分 | step: 12720 | performance: 6.1 | accuracy: 0.32 | loss: 0.06
update:1595/2000, 耗时:0.00分/2.28分 | step: 12760 | performance: 7.1 | accuracy: 0.32 | loss: 0.69
update:1600/2000, 耗时:0.00分/2.29分 | step: 12800 | performance: 7.1 | accuracy: 0.32 | loss: 0.32
update:1605/2000, 耗时:0.00分/2.29分 | step: 12840 | performance: 7.1 | accuracy: 0.32 | loss: 0.00
update:1610/2000, 耗时:0.00分/2.30分 | step: 12880 | performance: 6.8 | accuracy: 0.31 | loss: 0.09
update:1615/2000, 耗时:0.00分/2.31分 | step: 12920 | performance: 6.8 | accuracy: 0.31 | loss: 0.36
update:1620/2000, 耗时:0.00分/2.32分 | step: 12960 | performance: 6.8 | accuracy: 0.31 | loss: 0.00
update:1625/2000, 耗时:0.00分/2.33分 | step: 13000 | performance: 6.8 | accuracy: 0.31 | loss: 0.07
update:1630/2000, 耗时:0.00分/2.33分 | step: 13040 | performance: 6.8 | accuracy: 0.31 | loss: -0.00
update:1635/2000, 耗时:0.00分/2.34分 | step: 13080 | performance: 6.8 | accuracy: 0.31 | loss: -0.00
update:1640/2000, 耗时:0.00分/2.35分 | step: 13120 | performance: 6.8 | accuracy: 0.31 | loss: -0.00
update:1645/2000, 耗时:0.00分/2.36分 | step: 13160 | performance: 6.8 | accuracy: 0.31 | loss: 0.00
update:1650/2000, 耗时:0.00分/2.36分 | step: 13200 | performance: 6.4 | accuracy: 0.31 | loss: 0.06
update:1655/2000, 耗时:0.00分/2.37分 | step: 13240 | performance: 6.4 | accuracy: 0.31 | loss: 0.27
update:1660/2000, 耗时:0.00分/2.38分 | step: 13280 | performance: 6.5 | accuracy: 0.31 | loss: 0.46
update:1665/2000, 耗时:0.00分/2.39分 | step: 13320 | performance: 7.5 | accuracy: 0.31 | loss: -0.00
update:1670/2000, 耗时:0.00分/2.39分 | step: 13360 | performance: 7.5 | accuracy: 0.31 | loss: 0.09
update:1675/2000, 耗时:0.00分/2.40分 | step: 13400 | performance: 7.2 | accuracy: 0.31 | loss: 0.21
update:1680/2000, 耗时:0.00分/2.41分 | step: 13440 | performance: 9.5 | accuracy: 0.31 | loss: -0.00
update:1685/2000, 耗时:0.00分/2.42分 | step: 13480 | performance: 9.8 | accuracy: 0.31 | loss: 0.20
update:1690/2000, 耗时:0.00分/2.43分 | step: 13520 | performance: 9.8 | accuracy: 0.31 | loss: 0.00
update:1695/2000, 耗时:0.00分/2.43分 | step: 13560 | performance: 9.8 | accuracy: 0.30 | loss: -0.00
update:1700/2000, 耗时:0.00分/2.44分 | step: 13600 | performance: 10.7 | accuracy: 0.30 | loss: 0.11
update:1705/2000, 耗时:0.00分/2.45分 | step: 13640 | performance: 10.7 | accuracy: 0.30 | loss: -0.00
update:1710/2000, 耗时:0.00分/2.46分 | step: 13680 | performance: 10.7 | accuracy: 0.30 | loss: 0.13
update:1715/2000, 耗时:0.00分/2.46分 | step: 13720 | performance: 10.7 | accuracy: 0.30 | loss: -0.00
update:1720/2000, 耗时:0.00分/2.47分 | step: 13760 | performance: 10.6 | accuracy: 0.30 | loss: 0.00
update:1725/2000, 耗时:0.00分/2.48分 | step: 13800 | performance: 10.6 | accuracy: 0.30 | loss: 0.10
update:1730/2000, 耗时:0.00分/2.49分 | step: 13840 | performance: 10.6 | accuracy: 0.30 | loss: -0.00
update:1735/2000, 耗时:0.00分/2.50分 | step: 13880 | performance: 10.6 | accuracy: 0.30 | loss: 0.00
update:1740/2000, 耗时:0.00分/2.50分 | step: 13920 | performance: 9.8 | accuracy: 0.30 | loss: -0.01
update:1745/2000, 耗时:0.00分/2.51分 | step: 13960 | performance: 10.0 | accuracy: 0.30 | loss: 0.17
update:1750/2000, 耗时:0.00分/2.52分 | step: 14000 | performance: 10.0 | accuracy: 0.30 | loss: 0.34
update:1755/2000, 耗时:0.00分/2.53分 | step: 14040 | performance: 10.0 | accuracy: 0.30 | loss: -0.00
update:1760/2000, 耗时:0.00分/2.53分 | step: 14080 | performance: 9.7 | accuracy: 0.29 | loss: 0.48
update:1765/2000, 耗时:0.00分/2.54分 | step: 14120 | performance: 10.6 | accuracy: 0.29 | loss: 0.66
update:1770/2000, 耗时:0.00分/2.55分 | step: 14160 | performance: 10.4 | accuracy: 0.29 | loss: 0.67
update:1775/2000, 耗时:0.00分/2.56分 | step: 14200 | performance: 11.0 | accuracy: 0.29 | loss: 0.11
update:1780/2000, 耗时:0.00分/2.57分 | step: 14240 | performance: 9.8 | accuracy: 0.29 | loss: 0.13
update:1785/2000, 耗时:0.00分/2.57分 | step: 14280 | performance: 11.9 | accuracy: 0.29 | loss: 0.29
update:1790/2000, 耗时:0.00分/2.58分 | step: 14320 | performance: 14.6 | accuracy: 0.29 | loss: 0.10
update:1795/2000, 耗时:0.00分/2.59分 | step: 14360 | performance: 14.5 | accuracy: 0.29 | loss: 0.02
update:1800/2000, 耗时:0.00分/2.60分 | step: 14400 | performance: 13.9 | accuracy: 0.29 | loss: 0.10
update:1805/2000, 耗时:0.00分/2.61分 | step: 14440 | performance: 13.9 | accuracy: 0.29 | loss: 0.20
update:1810/2000, 耗时:0.00分/2.61分 | step: 14480 | performance: 11.7 | accuracy: 0.29 | loss: 0.25
update:1815/2000, 耗时:0.00分/2.62分 | step: 14520 | performance: 8.1 | accuracy: 0.29 | loss: 0.30
update:1820/2000, 耗时:0.00分/2.63分 | step: 14560 | performance: 8.1 | accuracy: 0.29 | loss: -0.00
update:1825/2000, 耗时:0.00分/2.64分 | step: 14600 | performance: 8.6 | accuracy: 0.29 | loss: 0.18
update:1830/2000, 耗时:0.00分/2.64分 | step: 14640 | performance: 10.4 | accuracy: 0.29 | loss: 0.28
update:1835/2000, 耗时:0.00分/2.65分 | step: 14680 | performance: 10.0 | accuracy: 0.29 | loss: 0.49
update:1840/2000, 耗时:0.00分/2.66分 | step: 14720 | performance: 11.8 | accuracy: 0.29 | loss: 0.48
update:1845/2000, 耗时:0.00分/2.67分 | step: 14760 | performance: 12.8 | accuracy: 0.29 | loss: 0.69
update:1850/2000, 耗时:0.00分/2.67分 | step: 14800 | performance: 16.0 | accuracy: 0.29 | loss: 0.51
update:1855/2000, 耗时:0.00分/2.68分 | step: 14840 | performance: 14.8 | accuracy: 0.29 | loss: 0.59
update:1860/2000, 耗时:0.00分/2.69分 | step: 14880 | performance: 14.8 | accuracy: 0.29 | loss: 0.00
update:1865/2000, 耗时:0.00分/2.70分 | step: 14920 | performance: 13.2 | accuracy: 0.29 | loss: 0.56
update:1870/2000, 耗时:0.00分/2.70分 | step: 14960 | performance: 14.2 | accuracy: 0.29 | loss: 0.39
update:1875/2000, 耗时:0.00分/2.71分 | step: 15000 | performance: 13.5 | accuracy: 0.29 | loss: 0.14
update:1880/2000, 耗时:0.00分/2.72分 | step: 15040 | performance: 16.2 | accuracy: 0.29 | loss: 0.48
update:1885/2000, 耗时:0.00分/2.73分 | step: 15080 | performance: 17.0 | accuracy: 0.29 | loss: 0.30
update:1890/2000, 耗时:0.00分/2.73分 | step: 15120 | performance: 18.6 | accuracy: 0.29 | loss: 0.08
update:1895/2000, 耗时:0.00分/2.74分 | step: 15160 | performance: 18.3 | accuracy: 0.29 | loss: 0.37
update:1900/2000, 耗时:0.00分/2.75分 | step: 15200 | performance: 18.3 | accuracy: 0.29 | loss: 0.35
update:1905/2000, 耗时:0.00分/2.76分 | step: 15240 | performance: 20.2 | accuracy: 0.29 | loss: 0.25
update:1910/2000, 耗时:0.00分/2.77分 | step: 15280 | performance: 24.1 | accuracy: 0.30 | loss: 0.21
update:1915/2000, 耗时:0.00分/2.77分 | step: 15320 | performance: 28.8 | accuracy: 0.30 | loss: 0.11
update:1920/2000, 耗时:0.00分/2.78分 | step: 15360 | performance: 25.4 | accuracy: 0.30 | loss: 0.66
update:1925/2000, 耗时:0.00分/2.79分 | step: 15400 | performance: 23.0 | accuracy: 0.30 | loss: 0.55
update:1930/2000, 耗时:0.00分/2.80分 | step: 15440 | performance: 24.8 | accuracy: 0.30 | loss: 0.54
update:1935/2000, 耗时:0.00分/2.80分 | step: 15480 | performance: 15.0 | accuracy: 0.30 | loss: 0.85
update:1940/2000, 耗时:0.00分/2.81分 | step: 15520 | performance: 17.6 | accuracy: 0.30 | loss: 0.91
update:1945/2000, 耗时:0.00分/2.82分 | step: 15560 | performance: 21.4 | accuracy: 0.30 | loss: 0.70
update:1950/2000, 耗时:0.00分/2.83分 | step: 15600 | performance: 27.5 | accuracy: 0.30 | loss: 0.40
update:1955/2000, 耗时:0.00分/2.84分 | step: 15640 | performance: 25.3 | accuracy: 0.30 | loss: 0.64
update:1960/2000, 耗时:0.00分/2.84分 | step: 15680 | performance: 27.3 | accuracy: 0.30 | loss: 0.23
update:1965/2000, 耗时:0.00分/2.85分 | step: 15720 | performance: 28.1 | accuracy: 0.30 | loss: 0.40
update:1970/2000, 耗时:0.00分/2.86分 | step: 15760 | performance: 25.1 | accuracy: 0.30 | loss: 1.12
update:1975/2000, 耗时:0.00分/2.87分 | step: 15800 | performance: 22.9 | accuracy: 0.30 | loss: 1.05
update:1980/2000, 耗时:0.00分/2.87分 | step: 15840 | performance: 17.0 | accuracy: 0.30 | loss: 1.45
update:1985/2000, 耗时:0.00分/2.88分 | step: 15880 | performance: 13.7 | accuracy: 0.30 | loss: 1.23
update:1990/2000, 耗时:0.00分/2.89分 | step: 15920 | performance: 12.6 | accuracy: 0.30 | loss: 0.45
update:1995/2000, 耗时:0.00分/2.90分 | step: 15960 | performance: 10.3 | accuracy: 0.30 | loss: 0.71
  0%|          | 0/406 [00:00<?, ?it/s]100%|| 406/406 [00:00<00:00, 135278.63it/s]
update:2000/2000, 耗时:0.00分/2.90分 | step: 16000 | performance: 11.2 | accuracy: 0.30 | loss: 0.57
----------------------------------------finished----------------------------------------
==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1399.02
2023-07-24T12:00:00 | net performance [%] = 39.9022
2023-07-24T12:00:00 | number of trades [#] = 86
==================================================
Trial 31 Complete [00h 03m 20s]
net_wealth: 1399.0222572472442

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 04h 16m 49s

Search: Running Trial #32

Value             |Best Value So Far |Hyperparameter
4                 |1                 |horizon
365               |730               |lookback
False             |False             |MarketFactor
14                |3                 |lags
0.6               |0.92              |gamma
32                |32                |batch_size
10                |1                 |n_step
0.99              |0.94              |gae_lambda
2                 |5                 |gradient_clip_norm
3                 |5                 |epochs
5e-05             |0.0001            |actor_lr
0.001             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4311.000000   4315.000000
mean      0.000441    20062.255222  ...   20133.281642  20118.633889
std       0.027818    16039.874230  ...   16077.358923  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7695.614990   7690.540039
50%       0.000642    11554.824463  ...   11741.480469  11715.610352
75%       0.011655    29873.081836  ...   29939.474609  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 02:20:12.095414: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural2023-07-28 02:20:12.095483: I tensorflow/core/platform/cpu_feature_guard.cc:142] This2202023-07-3 Network Library (oneDNN) to use the following CPU ins22t-07-28 02:20:12.095417: I tensorflo8w/core/pla 0TensorFlowtf  2orm/cp3u_feature0_guard.cc:1422] Thiru-c07-28 02:ts Tenso22i:onrs0:12 02in3 .-binary is optimized with one07-209561p8e20 02:0r2:02fo3 :r1mI20:anc tee-n-2crit2s1oF0l2oAwPI.  2r30Dbefe-07ic7i0lal o-pera2on8t- apr Neu0yi28 02ro:20:1n is s.095862oal:p 29t:im2 N0:5e5tIizw 3w:/ed0  wit1coth  2:r2.eA VIX .Aeon00s/orpl99f5V9naet7f5XAPI olo6De2e
w: pI /cTo N9e2oe ork1urt e nable/rL:m/ cIntee nthspo itberusreanlsmfopl  ilowraN_eft/ocornee/aptlartwfulr fotlrotohfwofe_/rowrm/cm//ccopre/ouer oplre/gpa_cpuafpletfeartd.uraoroctcraamr/icopnty:142usrfk ]L eo_rmuT_hfi/sc pge, T(ounaea_ibrDNensrturdufoarreN_)g  y_ f(etFlouaro uea.oanteuDwtcrdcuser eebrN :u_1bNg) uaiinl4rtaor2dd. Tycce:n14]  u 2s]sTies th.eh of rTihiFso soeclcopw_ lwi:t1 4g Tlhe Ttehtoiwtihneu nfnogasrodlesr.miczc :oapl 1C4roFwlioneg 2PUFCwP bl]2]in Uo dini wT hbsn aTrt iphryr uicinaorsp rTieinsstys i opwstsi oonptrtisat uimieo tiin ccthmipomzreeizoends  w podi iFllernri n Tewnso th epoerrFfloorAownwmiath e bniflAPP angIc easroyn I.b DeeAePpI  Ni
s iopDe-teimefDenupci ozrmarreydaanc Nwl is eriep Neurai olpet-tutcNi rihreicalmttica owNe oniplo NezAedt wwoirke tLPtreaklIhi orne  oatwALibrary (o Dionebeop PrIp DeksraNrerateions: yu Li AVX AVX2
To enable them in other operations, rebuild TensorFlow witbrary (oneDNN) to use the following CPU instru h the appropriate compiler flags.
(oneDNN) to use the following CPU instructions in performance-critical operatep Nr:neDN ctions ien ail AV NetwXork L AVX2per
Nu)fooralr ibmNance Tents:o oentwork Libra-  useac AVX A tbhe folllrVXreo2ryary (itw
T iio(ca th l openg CPratiooneDNnUo ienDnss:eNnNabletructi the)  AVX AVm iem ino other opnNX2n oerations, rebs) to use the  in peto use the follrformaut
 Theonfoi ldwero ce-crling CPU instruct lTnable them in other operations, rebuild TensorFlow with the appropriate coempiler fioons in perilwntainformance-ggs.
opesorFlow wit CPU instructions in peiratchral of tormahe appropperraticrons, ince-aiitorebuite cnrs:itical opera i lAdccal operations:  AVX AVX2
To etVoXmp nAi TeoialenbVle them in other operations, rebsn:soXur2
i  AVXld Tenr TFlow o AsoeVnX2
To enable them in other opwitab flagshel. therea  thematp p
iriFn rolnow with sottheohpreri a, reot appropriate compiler flags.
build TenspeorFlow with the compiler flags.
rations, rebuild TensorFlow with the approe apprpriate compiloprier flagate compiler s.
flags.
2023-07-28 02:20:12.708473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:20:12.712682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:20:12.730642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:20:12.734071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:20:12.734586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:20:12.741708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:20:12.745961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:20:12.755869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 1.5 | accuracy: 0.38 | loss: 0.81
update: 10/2000, 耗时:0.00分/0.04分 | step:   800 | performance: 0.7 | accuracy: 0.28 | loss: 0.71
update: 15/2000, 耗时:0.00分/0.05分 | step:  1200 | performance: 0.9 | accuracy: 0.33 | loss: 0.43
update: 20/2000, 耗时:0.00分/0.07分 | step:  1600 | performance: 1.0 | accuracy: 0.35 | loss: 0.92
update: 25/2000, 耗时:0.00分/0.08分 | step:  2000 | performance: 0.7 | accuracy: 0.32 | loss: 0.50
update: 30/2000, 耗时:0.00分/0.09分 | step:  2400 | performance: 0.6 | accuracy: 0.31 | loss: 0.72
update: 35/2000, 耗时:0.00分/0.10分 | step:  2800 | performance: 0.4 | accuracy: 0.29 | loss: 0.97
update: 40/2000, 耗时:0.00分/0.12分 | step:  3200 | performance: 0.6 | accuracy: 0.29 | loss: 0.65
update: 45/2000, 耗时:0.00分/0.13分 | step:  3600 | performance: 0.5 | accuracy: 0.28 | loss: 0.42
update: 50/2000, 耗时:0.00分/0.15分 | step:  4000 | performance: 0.5 | accuracy: 0.29 | loss: 0.32
update: 55/2000, 耗时:0.00分/0.16分 | step:  4400 | performance: 0.5 | accuracy: 0.28 | loss: 1.26
update: 60/2000, 耗时:0.00分/0.18分 | step:  4800 | performance: 0.5 | accuracy: 0.27 | loss: 0.84
update: 65/2000, 耗时:0.00分/0.19分 | step:  5200 | performance: 0.6 | accuracy: 0.27 | loss: 0.51
update: 70/2000, 耗时:0.00分/0.21分 | step:  5600 | performance: 0.6 | accuracy: 0.27 | loss: 0.46
update: 75/2000, 耗时:0.00分/0.22分 | step:  6000 | performance: 0.7 | accuracy: 0.27 | loss: 0.61
update: 80/2000, 耗时:0.00分/0.24分 | step:  6400 | performance: 0.7 | accuracy: 0.27 | loss: 0.72
update: 85/2000, 耗时:0.00分/0.25分 | step:  6800 | performance: 0.9 | accuracy: 0.28 | loss: 0.64
update: 90/2000, 耗时:0.00分/0.27分 | step:  7200 | performance: 3.3 | accuracy: 0.29 | loss: 0.91
update: 95/2000, 耗时:0.00分/0.28分 | step:  7600 | performance: 5.1 | accuracy: 0.31 | loss: 1.34
update:100/2000, 耗时:0.00分/0.30分 | step:  8000 | performance: 2.6 | accuracy: 0.31 | loss: 4.23
update:105/2000, 耗时:0.00分/0.31分 | step:  8400 | performance: 3.8 | accuracy: 0.33 | loss: 2.18
update:110/2000, 耗时:0.00分/0.33分 | step:  8800 | performance: 4.4 | accuracy: 0.34 | loss: 1.14
update:115/2000, 耗时:0.00分/0.34分 | step:  9200 | performance: 2.3 | accuracy: 0.33 | loss: 0.68
update:120/2000, 耗时:0.00分/0.35分 | step:  9600 | performance: 2.1 | accuracy: 0.33 | loss: 0.72
update:125/2000, 耗时:0.00分/0.37分 | step: 10000 | performance: 2.3 | accuracy: 0.33 | loss: 0.40
update:130/2000, 耗时:0.00分/0.38分 | step: 10400 | performance: 2.8 | accuracy: 0.33 | loss: 0.44
update:135/2000, 耗时:0.00分/0.40分 | step: 10800 | performance: 2.6 | accuracy: 0.33 | loss: 0.49
update:140/2000, 耗时:0.00分/0.41分 | step: 11200 | performance: 2.0 | accuracy: 0.32 | loss: 0.45
update:145/2000, 耗时:0.00分/0.43分 | step: 11600 | performance: 1.0 | accuracy: 0.32 | loss: 1.75
update:150/2000, 耗时:0.00分/0.44分 | step: 12000 | performance: 0.4 | accuracy: 0.32 | loss: 2.22
update:155/2000, 耗时:0.00分/0.46分 | step: 12400 | performance: 0.4 | accuracy: 0.32 | loss: 0.35
update:160/2000, 耗时:0.00分/0.47分 | step: 12800 | performance: 0.4 | accuracy: 0.32 | loss: 1.04
update:165/2000, 耗时:0.00分/0.48分 | step: 13200 | performance: 0.3 | accuracy: 0.32 | loss: 0.66
update:170/2000, 耗时:0.00分/0.50分 | step: 13600 | performance: 0.3 | accuracy: 0.32 | loss: 0.56
update:175/2000, 耗时:0.00分/0.51分 | step: 14000 | performance: 0.3 | accuracy: 0.32 | loss: 0.87
update:180/2000, 耗时:0.00分/0.53分 | step: 14400 | performance: 0.3 | accuracy: 0.33 | loss: 1.05
update:185/2000, 耗时:0.00分/0.54分 | step: 14800 | performance: 0.3 | accuracy: 0.33 | loss: 0.78
update:190/2000, 耗时:0.00分/0.56分 | step: 15200 | performance: 0.3 | accuracy: 0.34 | loss: 0.74
update:195/2000, 耗时:0.00分/0.57分 | step: 15600 | performance: 0.4 | accuracy: 0.34 | loss: 0.86
update:200/2000, 耗时:0.00分/0.58分 | step: 16000 | performance: 0.9 | accuracy: 0.35 | loss: 2.72
update:205/2000, 耗时:0.00分/0.60分 | step: 16400 | performance: 2.4 | accuracy: 0.36 | loss: 0.85
update:210/2000, 耗时:0.00分/0.61分 | step: 16800 | performance: 11.5 | accuracy: 0.36 | loss: 4.61
update:215/2000, 耗时:0.00分/0.63分 | step: 17200 | performance: 32.4 | accuracy: 0.37 | loss: 1.22
update:220/2000, 耗时:0.00分/0.64分 | step: 17600 | performance: 48.8 | accuracy: 0.38 | loss: 1.51
update:225/2000, 耗时:0.00分/0.66分 | step: 18000 | performance: 70.1 | accuracy: 0.38 | loss: 0.58
update:230/2000, 耗时:0.00分/0.67分 | step: 18400 | performance: 47.5 | accuracy: 0.38 | loss: 1.58
update:235/2000, 耗时:0.00分/0.68分 | step: 18800 | performance: 24.9 | accuracy: 0.38 | loss: 1.45
update:240/2000, 耗时:0.00分/0.70分 | step: 19200 | performance: 49.7 | accuracy: 0.38 | loss: 0.32
update:245/2000, 耗时:0.00分/0.71分 | step: 19600 | performance: 45.6 | accuracy: 0.38 | loss: 0.43
update:250/2000, 耗时:0.00分/0.73分 | step: 20000 | performance: 50.7 | accuracy: 0.37 | loss: 0.30
update:255/2000, 耗时:0.00分/0.74分 | step: 20400 | performance: 61.8 | accuracy: 0.37 | loss: 0.54
update:260/2000, 耗时:0.00分/0.75分 | step: 20800 | performance: 56.8 | accuracy: 0.37 | loss: 0.71
update:265/2000, 耗时:0.00分/0.77分 | step: 21200 | performance: 134.9 | accuracy: 0.37 | loss: 0.99
update:270/2000, 耗时:0.00分/0.78分 | step: 21600 | performance: 153.8 | accuracy: 0.38 | loss: 2.18
update:275/2000, 耗时:0.00分/0.80分 | step: 22000 | performance: 47.3 | accuracy: 0.38 | loss: 0.91
update:280/2000, 耗时:0.00分/0.81分 | step: 22400 | performance: 36.7 | accuracy: 0.38 | loss: 0.50
update:285/2000, 耗时:0.00分/0.83分 | step: 22800 | performance: 32.1 | accuracy: 0.37 | loss: 0.30
update:290/2000, 耗时:0.00分/0.84分 | step: 23200 | performance: 39.1 | accuracy: 0.37 | loss: 0.32
update:295/2000, 耗时:0.00分/0.85分 | step: 23600 | performance: 40.8 | accuracy: 0.37 | loss: 0.46
update:300/2000, 耗时:0.00分/0.87分 | step: 24000 | performance: 39.2 | accuracy: 0.36 | loss: 0.32
update:305/2000, 耗时:0.00分/0.88分 | step: 24400 | performance: 38.3 | accuracy: 0.36 | loss: 0.44
update:310/2000, 耗时:0.00分/0.90分 | step: 24800 | performance: 38.3 | accuracy: 0.35 | loss: 0.07
update:315/2000, 耗时:0.00分/0.91分 | step: 25200 | performance: 45.8 | accuracy: 0.35 | loss: 0.26
update:320/2000, 耗时:0.00分/0.92分 | step: 25600 | performance: 49.9 | accuracy: 0.34 | loss: 0.13
update:325/2000, 耗时:0.00分/0.94分 | step: 26000 | performance: 45.8 | accuracy: 0.34 | loss: 0.17
update:330/2000, 耗时:0.00分/0.95分 | step: 26400 | performance: 52.1 | accuracy: 0.34 | loss: 0.29
update:335/2000, 耗时:0.00分/0.96分 | step: 26800 | performance: 60.8 | accuracy: 0.34 | loss: 0.39
update:340/2000, 耗时:0.00分/0.98分 | step: 27200 | performance: 50.4 | accuracy: 0.33 | loss: 0.32
update:345/2000, 耗时:0.00分/0.99分 | step: 27600 | performance: 73.1 | accuracy: 0.33 | loss: 0.61
update:350/2000, 耗时:0.00分/1.01分 | step: 28000 | performance: 79.6 | accuracy: 0.33 | loss: 0.27
Saving PPO weights in both H5 format and checkpoint @ update:353 
update:355/2000, 耗时:0.00分/1.02分 | step: 28400 | performance: 1.9 | accuracy: 0.45 | loss: 0.67
update:360/2000, 耗时:0.00分/1.04分 | step: 28800 | performance: 1.6 | accuracy: 0.25 | loss: 0.46
update:365/2000, 耗时:0.00分/1.05分 | step: 29200 | performance: 0.9 | accuracy: 0.20 | loss: 0.44
update:370/2000, 耗时:0.00分/1.06分 | step: 29600 | performance: 1.0 | accuracy: 0.17 | loss: 0.39
update:375/2000, 耗时:0.00分/1.08分 | step: 30000 | performance: 0.9 | accuracy: 0.15 | loss: 0.34
update:380/2000, 耗时:0.00分/1.09分 | step: 30400 | performance: 1.0 | accuracy: 0.15 | loss: 0.51
update:385/2000, 耗时:0.00分/1.10分 | step: 30800 | performance: 1.1 | accuracy: 0.16 | loss: 0.54
update:390/2000, 耗时:0.00分/1.12分 | step: 31200 | performance: 1.0 | accuracy: 0.16 | loss: 0.45
update:395/2000, 耗时:0.00分/1.13分 | step: 31600 | performance: 1.2 | accuracy: 0.16 | loss: 0.26
update:400/2000, 耗时:0.00分/1.14分 | step: 32000 | performance: 1.0 | accuracy: 0.17 | loss: 0.52
update:405/2000, 耗时:0.00分/1.15分 | step: 32400 | performance: 1.1 | accuracy: 0.17 | loss: 0.25
update:410/2000, 耗时:0.00分/1.16分 | step: 32800 | performance: 1.2 | accuracy: 0.17 | loss: 0.14
update:415/2000, 耗时:0.00分/1.17分 | step: 33200 | performance: 1.3 | accuracy: 0.17 | loss: 0.24
update:420/2000, 耗时:0.00分/1.19分 | step: 33600 | performance: 1.5 | accuracy: 0.17 | loss: 0.25
update:425/2000, 耗时:0.00分/1.20分 | step: 34000 | performance: 1.5 | accuracy: 0.16 | loss: 0.13
update:430/2000, 耗时:0.00分/1.21分 | step: 34400 | performance: 1.3 | accuracy: 0.16 | loss: 0.32
update:435/2000, 耗时:0.00分/1.22分 | step: 34800 | performance: 1.3 | accuracy: 0.17 | loss: 0.54
update:440/2000, 耗时:0.00分/1.23分 | step: 35200 | performance: 4.3 | accuracy: 0.19 | loss: 2.61
update:445/2000, 耗时:0.00分/1.25分 | step: 35600 | performance: 3.8 | accuracy: 0.20 | loss: 1.35
update:450/2000, 耗时:0.00分/1.26分 | step: 36000 | performance: 14.3 | accuracy: 0.23 | loss: 3.93
update:455/2000, 耗时:0.00分/1.27分 | step: 36400 | performance: 7.2 | accuracy: 0.24 | loss: 1.54
update:460/2000, 耗时:0.00分/1.29分 | step: 36800 | performance: 8.4 | accuracy: 0.25 | loss: 1.56
update:465/2000, 耗时:0.00分/1.30分 | step: 37200 | performance: 7.7 | accuracy: 0.26 | loss: 0.65
update:470/2000, 耗时:0.00分/1.31分 | step: 37600 | performance: 5.9 | accuracy: 0.26 | loss: 0.54
update:475/2000, 耗时:0.00分/1.32分 | step: 38000 | performance: 6.3 | accuracy: 0.26 | loss: 0.53
update:480/2000, 耗时:0.00分/1.34分 | step: 38400 | performance: 7.3 | accuracy: 0.26 | loss: 0.78
update:485/2000, 耗时:0.00分/1.35分 | step: 38800 | performance: 7.0 | accuracy: 0.26 | loss: 0.27
update:490/2000, 耗时:0.00分/1.36分 | step: 39200 | performance: 7.7 | accuracy: 0.25 | loss: 0.19
update:495/2000, 耗时:0.00分/1.38分 | step: 39600 | performance: 9.1 | accuracy: 0.25 | loss: 0.86
update:500/2000, 耗时:0.00分/1.39分 | step: 40000 | performance: 4.0 | accuracy: 0.26 | loss: 0.97
update:505/2000, 耗时:0.00分/1.40分 | step: 40400 | performance: 3.2 | accuracy: 0.25 | loss: 0.46
update:510/2000, 耗时:0.00分/1.42分 | step: 40800 | performance: 2.7 | accuracy: 0.25 | loss: 0.21
update:515/2000, 耗时:0.00分/1.43分 | step: 41200 | performance: 3.5 | accuracy: 0.26 | loss: 1.55
update:520/2000, 耗时:0.00分/1.44分 | step: 41600 | performance: 3.2 | accuracy: 0.26 | loss: 0.76
update:525/2000, 耗时:0.00分/1.46分 | step: 42000 | performance: 3.1 | accuracy: 0.26 | loss: 0.60
update:530/2000, 耗时:0.00分/1.47分 | step: 42400 | performance: 5.3 | accuracy: 0.27 | loss: 1.20
update:535/2000, 耗时:0.00分/1.48分 | step: 42800 | performance: 5.3 | accuracy: 0.28 | loss: 1.76
update:540/2000, 耗时:0.00分/1.50分 | step: 43200 | performance: 3.6 | accuracy: 0.28 | loss: 0.97
update:545/2000, 耗时:0.00分/1.51分 | step: 43600 | performance: 4.6 | accuracy: 0.29 | loss: 1.17
update:550/2000, 耗时:0.00分/1.52分 | step: 44000 | performance: 12.8 | accuracy: 0.30 | loss: 1.41
update:555/2000, 耗时:0.00分/1.53分 | step: 44400 | performance: 21.0 | accuracy: 0.31 | loss: 2.17
update:560/2000, 耗时:0.00分/1.55分 | step: 44800 | performance: 199.4 | accuracy: 0.32 | loss: 0.92
update:565/2000, 耗时:0.00分/1.56分 | step: 45200 | performance: 225.9 | accuracy: 0.32 | loss: 1.56
update:570/2000, 耗时:0.00分/1.57分 | step: 45600 | performance: 1081.6 | accuracy: 0.33 | loss: 3.23
update:575/2000, 耗时:0.00分/1.59分 | step: 46000 | performance: 1599.8 | accuracy: 0.34 | loss: 1.14
update:580/2000, 耗时:0.00分/1.60分 | step: 46400 | performance: 1963.7 | accuracy: 0.34 | loss: 1.10
update:585/2000, 耗时:0.00分/1.61分 | step: 46800 | performance: 2045.2 | accuracy: 0.35 | loss: 0.92
update:590/2000, 耗时:0.00分/1.62分 | step: 47200 | performance: 662.4 | accuracy: 0.34 | loss: 0.77
update:595/2000, 耗时:0.00分/1.64分 | step: 47600 | performance: 500.4 | accuracy: 0.34 | loss: 0.49
update:600/2000, 耗时:0.00分/1.65分 | step: 48000 | performance: 515.1 | accuracy: 0.34 | loss: 0.48
update:605/2000, 耗时:0.00分/1.66分 | step: 48400 | performance: 463.5 | accuracy: 0.33 | loss: 0.47
update:610/2000, 耗时:0.00分/1.68分 | step: 48800 | performance: 419.6 | accuracy: 0.33 | loss: 0.80
update:615/2000, 耗时:0.00分/1.69分 | step: 49200 | performance: 754.4 | accuracy: 0.34 | loss: 0.94
update:620/2000, 耗时:0.00分/1.70分 | step: 49600 | performance: 1121.3 | accuracy: 0.34 | loss: 1.29
update:625/2000, 耗时:0.00分/1.72分 | step: 50000 | performance: 898.4 | accuracy: 0.34 | loss: 1.15
update:630/2000, 耗时:0.00分/1.73分 | step: 50400 | performance: 383.6 | accuracy: 0.34 | loss: 0.62
update:635/2000, 耗时:0.00分/1.75分 | step: 50800 | performance: 443.5 | accuracy: 0.34 | loss: 0.48
update:640/2000, 耗时:0.00分/1.76分 | step: 51200 | performance: 519.2 | accuracy: 0.34 | loss: 0.69
update:645/2000, 耗时:0.00分/1.77分 | step: 51600 | performance: 437.0 | accuracy: 0.33 | loss: 0.26
update:650/2000, 耗时:0.00分/1.79分 | step: 52000 | performance: 488.0 | accuracy: 0.33 | loss: 0.18
update:655/2000, 耗时:0.00分/1.80分 | step: 52400 | performance: 534.9 | accuracy: 0.33 | loss: 0.41
update:660/2000, 耗时:0.00分/1.81分 | step: 52800 | performance: 671.9 | accuracy: 0.33 | loss: 0.25
update:665/2000, 耗时:0.00分/1.83分 | step: 53200 | performance: 640.4 | accuracy: 0.32 | loss: 0.36
update:670/2000, 耗时:0.00分/1.84分 | step: 53600 | performance: 800.1 | accuracy: 0.32 | loss: 0.41
update:675/2000, 耗时:0.00分/1.85分 | step: 54000 | performance: 699.6 | accuracy: 0.32 | loss: 0.21
update:680/2000, 耗时:0.00分/1.87分 | step: 54400 | performance: 561.3 | accuracy: 0.31 | loss: 0.37
update:685/2000, 耗时:0.00分/1.88分 | step: 54800 | performance: 554.9 | accuracy: 0.31 | loss: 0.52
update:690/2000, 耗时:0.00分/1.89分 | step: 55200 | performance: 501.6 | accuracy: 0.31 | loss: 0.35
update:695/2000, 耗时:0.00分/1.90分 | step: 55600 | performance: 575.6 | accuracy: 0.31 | loss: 0.53
update:700/2000, 耗时:0.00分/1.92分 | step: 56000 | performance: 588.4 | accuracy: 0.31 | loss: 0.30
update:705/2000, 耗时:0.00分/1.93分 | step: 56400 | performance: 636.0 | accuracy: 0.31 | loss: 0.31
Saving PPO weights in both H5 format and checkpoint @ update:706 
Saving PPO weights in both H5 format and checkpoint @ update:708 
update:710/2000, 耗时:0.00分/1.95分 | step: 56800 | performance: 1.0 | accuracy: 0.34 | loss: 0.87
update:715/2000, 耗时:0.00分/1.97分 | step: 57200 | performance: 0.9 | accuracy: 0.31 | loss: 0.64
update:720/2000, 耗时:0.00分/1.98分 | step: 57600 | performance: 0.7 | accuracy: 0.28 | loss: 0.59
update:725/2000, 耗时:0.00分/2.00分 | step: 58000 | performance: 0.9 | accuracy: 0.26 | loss: 0.51
update:730/2000, 耗时:0.00分/2.01分 | step: 58400 | performance: 1.1 | accuracy: 0.27 | loss: 0.37
update:735/2000, 耗时:0.00分/2.02分 | step: 58800 | performance: 0.9 | accuracy: 0.24 | loss: 0.48
update:740/2000, 耗时:0.00分/2.04分 | step: 59200 | performance: 0.9 | accuracy: 0.25 | loss: 0.45
update:745/2000, 耗时:0.00分/2.05分 | step: 59600 | performance: 0.9 | accuracy: 0.23 | loss: 0.35
update:750/2000, 耗时:0.00分/2.06分 | step: 60000 | performance: 0.9 | accuracy: 0.23 | loss: 0.44
update:755/2000, 耗时:0.00分/2.08分 | step: 60400 | performance: 0.8 | accuracy: 0.22 | loss: 0.27
update:760/2000, 耗时:0.00分/2.09分 | step: 60800 | performance: 1.4 | accuracy: 0.23 | loss: 1.16
update:765/2000, 耗时:0.00分/2.10分 | step: 61200 | performance: 1.1 | accuracy: 0.22 | loss: 0.26
update:770/2000, 耗时:0.00分/2.12分 | step: 61600 | performance: 1.1 | accuracy: 0.22 | loss: 0.28
update:775/2000, 耗时:0.00分/2.13分 | step: 62000 | performance: 1.1 | accuracy: 0.21 | loss: 0.16
update:780/2000, 耗时:0.00分/2.14分 | step: 62400 | performance: 1.1 | accuracy: 0.21 | loss: 0.32
update:785/2000, 耗时:0.00分/2.16分 | step: 62800 | performance: 1.0 | accuracy: 0.21 | loss: 0.70
update:790/2000, 耗时:0.00分/2.17分 | step: 63200 | performance: 1.2 | accuracy: 0.22 | loss: 0.55
update:795/2000, 耗时:0.00分/2.18分 | step: 63600 | performance: 5.4 | accuracy: 0.25 | loss: 1.89
update:800/2000, 耗时:0.00分/2.20分 | step: 64000 | performance: 8.1 | accuracy: 0.27 | loss: 0.84
update:805/2000, 耗时:0.00分/2.21分 | step: 64400 | performance: 12.5 | accuracy: 0.28 | loss: 5.10
update:810/2000, 耗时:0.00分/2.22分 | step: 64800 | performance: 17.7 | accuracy: 0.30 | loss: 1.17
update:815/2000, 耗时:0.00分/2.23分 | step: 65200 | performance: 10.5 | accuracy: 0.30 | loss: 0.62
update:820/2000, 耗时:0.00分/2.25分 | step: 65600 | performance: 5.6 | accuracy: 0.30 | loss: 1.10
update:825/2000, 耗时:0.00分/2.26分 | step: 66000 | performance: 6.3 | accuracy: 0.31 | loss: 0.38
update:830/2000, 耗时:0.00分/2.27分 | step: 66400 | performance: 8.0 | accuracy: 0.31 | loss: 0.64
update:835/2000, 耗时:0.00分/2.29分 | step: 66800 | performance: 11.0 | accuracy: 0.31 | loss: 0.39
update:840/2000, 耗时:0.00分/2.30分 | step: 67200 | performance: 10.7 | accuracy: 0.30 | loss: 0.45
update:845/2000, 耗时:0.00分/2.31分 | step: 67600 | performance: 8.3 | accuracy: 0.30 | loss: 0.47
update:850/2000, 耗时:0.00分/2.33分 | step: 68000 | performance: 8.3 | accuracy: 0.30 | loss: 0.93
update:855/2000, 耗时:0.00分/2.34分 | step: 68400 | performance: 11.4 | accuracy: 0.30 | loss: 3.73
update:860/2000, 耗时:0.00分/2.35分 | step: 68800 | performance: 10.9 | accuracy: 0.30 | loss: 0.29
update:865/2000, 耗时:0.00分/2.37分 | step: 69200 | performance: 8.8 | accuracy: 0.29 | loss: 1.71
update:870/2000, 耗时:0.00分/2.38分 | step: 69600 | performance: 11.2 | accuracy: 0.30 | loss: 0.93
update:875/2000, 耗时:0.00分/2.39分 | step: 70000 | performance: 9.5 | accuracy: 0.30 | loss: 0.53
update:880/2000, 耗时:0.00分/2.41分 | step: 70400 | performance: 11.2 | accuracy: 0.31 | loss: 0.53
update:885/2000, 耗时:0.00分/2.42分 | step: 70800 | performance: 17.6 | accuracy: 0.32 | loss: 1.34
update:890/2000, 耗时:0.00分/2.43分 | step: 71200 | performance: 8.8 | accuracy: 0.32 | loss: 0.87
update:895/2000, 耗时:0.00分/2.45分 | step: 71600 | performance: 8.0 | accuracy: 0.32 | loss: 0.66
update:900/2000, 耗时:0.00分/2.46分 | step: 72000 | performance: 12.5 | accuracy: 0.33 | loss: 1.08
update:905/2000, 耗时:0.00分/2.47分 | step: 72400 | performance: 34.8 | accuracy: 0.34 | loss: 1.59
update:910/2000, 耗时:0.00分/2.49分 | step: 72800 | performance: 54.2 | accuracy: 0.34 | loss: 2.22
update:915/2000, 耗时:0.00分/2.50分 | step: 73200 | performance: 381.9 | accuracy: 0.35 | loss: 3.33
update:920/2000, 耗时:0.00分/2.51分 | step: 73600 | performance: 829.7 | accuracy: 0.36 | loss: 1.74
update:925/2000, 耗时:0.00分/2.53分 | step: 74000 | performance: 1148.3 | accuracy: 0.36 | loss: 2.25
update:930/2000, 耗时:0.00分/2.54分 | step: 74400 | performance: 2547.4 | accuracy: 0.37 | loss: 1.64
update:935/2000, 耗时:0.00分/2.55分 | step: 74800 | performance: 1567.3 | accuracy: 0.37 | loss: 3.07
update:940/2000, 耗时:0.00分/2.57分 | step: 75200 | performance: 1078.5 | accuracy: 0.37 | loss: 1.28
update:945/2000, 耗时:0.00分/2.58分 | step: 75600 | performance: 687.9 | accuracy: 0.37 | loss: 0.62
update:950/2000, 耗时:0.00分/2.59分 | step: 76000 | performance: 627.2 | accuracy: 0.37 | loss: 0.32
update:955/2000, 耗时:0.00分/2.61分 | step: 76400 | performance: 483.9 | accuracy: 0.36 | loss: 0.37
update:960/2000, 耗时:0.00分/2.62分 | step: 76800 | performance: 360.3 | accuracy: 0.36 | loss: 0.71
update:965/2000, 耗时:0.00分/2.63分 | step: 77200 | performance: 237.2 | accuracy: 0.36 | loss: 1.02
update:970/2000, 耗时:0.00分/2.65分 | step: 77600 | performance: 172.8 | accuracy: 0.36 | loss: 1.46
update:975/2000, 耗时:0.00分/2.66分 | step: 78000 | performance: 208.2 | accuracy: 0.36 | loss: 1.62
update:980/2000, 耗时:0.00分/2.68分 | step: 78400 | performance: 183.8 | accuracy: 0.36 | loss: 1.50
update:985/2000, 耗时:0.00分/2.69分 | step: 78800 | performance: 170.9 | accuracy: 0.36 | loss: 0.53
update:990/2000, 耗时:0.00分/2.70分 | step: 79200 | performance: 242.0 | accuracy: 0.36 | loss: 0.82
update:995/2000, 耗时:0.00分/2.72分 | step: 79600 | performance: 246.0 | accuracy: 0.36 | loss: 0.25
update:1000/2000, 耗时:0.00分/2.73分 | step: 80000 | performance: 139.8 | accuracy: 0.35 | loss: 0.30
update:1005/2000, 耗时:0.00分/2.74分 | step: 80400 | performance: 114.1 | accuracy: 0.35 | loss: 0.43
update:1010/2000, 耗时:0.00分/2.76分 | step: 80800 | performance: 119.0 | accuracy: 0.34 | loss: 0.24
update:1015/2000, 耗时:0.00分/2.77分 | step: 81200 | performance: 175.3 | accuracy: 0.34 | loss: 0.16
update:1020/2000, 耗时:0.00分/2.78分 | step: 81600 | performance: 167.6 | accuracy: 0.34 | loss: 0.58
update:1025/2000, 耗时:0.00分/2.80分 | step: 82000 | performance: 202.4 | accuracy: 0.34 | loss: 0.10
update:1030/2000, 耗时:0.00分/2.81分 | step: 82400 | performance: 190.6 | accuracy: 0.33 | loss: 0.14
update:1035/2000, 耗时:0.00分/2.82分 | step: 82800 | performance: 227.7 | accuracy: 0.33 | loss: 0.29
update:1040/2000, 耗时:0.00分/2.84分 | step: 83200 | performance: 174.1 | accuracy: 0.33 | loss: 0.31
update:1045/2000, 耗时:0.00分/2.85分 | step: 83600 | performance: 178.4 | accuracy: 0.32 | loss: 0.58
update:1050/2000, 耗时:0.00分/2.86分 | step: 84000 | performance: 240.8 | accuracy: 0.32 | loss: 0.46
update:1055/2000, 耗时:0.00分/2.88分 | step: 84400 | performance: 188.0 | accuracy: 0.32 | loss: 0.39
Saving PPO weights in both H5 format and checkpoint @ update:1059 
update:1060/2000, 耗时:0.00分/2.90分 | step: 84800 | performance: 1.2 | accuracy: 0.44 | loss: 0.98
Saving PPO weights in both H5 format and checkpoint @ update:1061 
update:1065/2000, 耗时:0.00分/2.91分 | step: 85200 | performance: 1.4 | accuracy: 0.38 | loss: 0.86
update:1070/2000, 耗时:0.00分/2.93分 | step: 85600 | performance: 0.9 | accuracy: 0.26 | loss: 0.48
update:1075/2000, 耗时:0.00分/2.94分 | step: 86000 | performance: 1.6 | accuracy: 0.28 | loss: 0.68
update:1080/2000, 耗时:0.00分/2.96分 | step: 86400 | performance: 1.6 | accuracy: 0.26 | loss: 0.66
update:1085/2000, 耗时:0.00分/2.97分 | step: 86800 | performance: 1.7 | accuracy: 0.26 | loss: 0.41
update:1090/2000, 耗时:0.00分/2.98分 | step: 87200 | performance: 2.3 | accuracy: 0.26 | loss: 0.96
update:1095/2000, 耗时:0.00分/3.00分 | step: 87600 | performance: 1.9 | accuracy: 0.25 | loss: 0.34
update:1100/2000, 耗时:0.00分/3.01分 | step: 88000 | performance: 2.0 | accuracy: 0.25 | loss: 0.22
update:1105/2000, 耗时:0.00分/3.02分 | step: 88400 | performance: 1.7 | accuracy: 0.25 | loss: 0.42
update:1110/2000, 耗时:0.00分/3.04分 | step: 88800 | performance: 2.1 | accuracy: 0.25 | loss: 0.56
update:1115/2000, 耗时:0.00分/3.05分 | step: 89200 | performance: 2.0 | accuracy: 0.24 | loss: 0.28
update:1120/2000, 耗时:0.00分/3.06分 | step: 89600 | performance: 1.5 | accuracy: 0.23 | loss: 0.24
update:1125/2000, 耗时:0.00分/3.08分 | step: 90000 | performance: 1.7 | accuracy: 0.22 | loss: 0.26
update:1130/2000, 耗时:0.00分/3.09分 | step: 90400 | performance: 1.7 | accuracy: 0.22 | loss: 0.16
update:1135/2000, 耗时:0.00分/3.10分 | step: 90800 | performance: 1.6 | accuracy: 0.22 | loss: 0.33
update:1140/2000, 耗时:0.00分/3.12分 | step: 91200 | performance: 1.0 | accuracy: 0.22 | loss: 0.58
update:1145/2000, 耗时:0.00分/3.13分 | step: 91600 | performance: 1.8 | accuracy: 0.23 | loss: 2.16
update:1150/2000, 耗时:0.00分/3.15分 | step: 92000 | performance: 2.7 | accuracy: 0.25 | loss: 3.40
update:1155/2000, 耗时:0.00分/3.16分 | step: 92400 | performance: 10.1 | accuracy: 0.27 | loss: 4.35
update:1160/2000, 耗时:0.00分/3.17分 | step: 92800 | performance: 6.2 | accuracy: 0.28 | loss: 1.86
update:1165/2000, 耗时:0.00分/3.19分 | step: 93200 | performance: 6.0 | accuracy: 0.29 | loss: 1.10
update:1170/2000, 耗时:0.00分/3.20分 | step: 93600 | performance: 3.4 | accuracy: 0.29 | loss: 0.79
update:1175/2000, 耗时:0.00分/3.21分 | step: 94000 | performance: 2.8 | accuracy: 0.30 | loss: 0.87
update:1180/2000, 耗时:0.00分/3.23分 | step: 94400 | performance: 2.2 | accuracy: 0.30 | loss: 0.55
update:1185/2000, 耗时:0.00分/3.24分 | step: 94800 | performance: 2.3 | accuracy: 0.29 | loss: 0.79
update:1190/2000, 耗时:0.00分/3.25分 | step: 95200 | performance: 2.6 | accuracy: 0.29 | loss: 0.38
update:1195/2000, 耗时:0.00分/3.27分 | step: 95600 | performance: 2.4 | accuracy: 0.28 | loss: 0.22
update:1200/2000, 耗时:0.00分/3.28分 | step: 96000 | performance: 1.9 | accuracy: 0.28 | loss: 0.62
update:1205/2000, 耗时:0.00分/3.30分 | step: 96400 | performance: 1.0 | accuracy: 0.28 | loss: 0.73
update:1210/2000, 耗时:0.00分/3.31分 | step: 96800 | performance: 1.6 | accuracy: 0.28 | loss: 0.42
update:1215/2000, 耗时:0.00分/3.32分 | step: 97200 | performance: 1.3 | accuracy: 0.28 | loss: 0.54
update:1220/2000, 耗时:0.00分/3.34分 | step: 97600 | performance: 0.9 | accuracy: 0.28 | loss: 1.20
update:1225/2000, 耗时:0.00分/3.35分 | step: 98000 | performance: 0.7 | accuracy: 0.29 | loss: 1.30
update:1230/2000, 耗时:0.00分/3.36分 | step: 98400 | performance: 0.5 | accuracy: 0.29 | loss: 0.69
update:1235/2000, 耗时:0.00分/3.38分 | step: 98800 | performance: 0.5 | accuracy: 0.29 | loss: 1.06
update:1240/2000, 耗时:0.00分/3.39分 | step: 99200 | performance: 0.6 | accuracy: 0.30 | loss: 1.01
update:1245/2000, 耗时:0.00分/3.40分 | step: 99600 | performance: 0.3 | accuracy: 0.30 | loss: 1.05
update:1250/2000, 耗时:0.00分/3.42分 | step: 100000 | performance: 0.4 | accuracy: 0.31 | loss: 0.66
update:1255/2000, 耗时:0.00分/3.43分 | step: 100400 | performance: 1.3 | accuracy: 0.32 | loss: 0.82
update:1260/2000, 耗时:0.00分/3.44分 | step: 100800 | performance: 2.6 | accuracy: 0.33 | loss: 1.60
update:1265/2000, 耗时:0.00分/3.46分 | step: 101200 | performance: 13.3 | accuracy: 0.34 | loss: 0.82
update:1270/2000, 耗时:0.00分/3.47分 | step: 101600 | performance: 19.5 | accuracy: 0.34 | loss: 1.18
update:1275/2000, 耗时:0.00分/3.48分 | step: 102000 | performance: 155.6 | accuracy: 0.35 | loss: 0.95
update:1280/2000, 耗时:0.00分/3.50分 | step: 102400 | performance: 162.8 | accuracy: 0.36 | loss: 2.44
update:1285/2000, 耗时:0.00分/3.51分 | step: 102800 | performance: 195.5 | accuracy: 0.36 | loss: 1.76
update:1290/2000, 耗时:0.00分/3.52分 | step: 103200 | performance: 220.8 | accuracy: 0.36 | loss: 1.07
update:1295/2000, 耗时:0.00分/3.54分 | step: 103600 | performance: 157.2 | accuracy: 0.36 | loss: 1.38
update:1300/2000, 耗时:0.00分/3.55分 | step: 104000 | performance: 197.0 | accuracy: 0.36 | loss: 0.52
update:1305/2000, 耗时:0.00分/3.56分 | step: 104400 | performance: 246.9 | accuracy: 0.35 | loss: 0.18
update:1310/2000, 耗时:0.00分/3.58分 | step: 104800 | performance: 165.9 | accuracy: 0.35 | loss: 0.37
update:1315/2000, 耗时:0.00分/3.59分 | step: 105200 | performance: 211.7 | accuracy: 0.35 | loss: 0.75
update:1320/2000, 耗时:0.00分/3.61分 | step: 105600 | performance: 162.1 | accuracy: 0.35 | loss: 1.49
update:1325/2000, 耗时:0.00分/3.62分 | step: 106000 | performance: 196.9 | accuracy: 0.35 | loss: 1.15
update:1330/2000, 耗时:0.00分/3.63分 | step: 106400 | performance: 201.3 | accuracy: 0.35 | loss: 1.21
update:1335/2000, 耗时:0.00分/3.65分 | step: 106800 | performance: 123.5 | accuracy: 0.36 | loss: 0.91
update:1340/2000, 耗时:0.00分/3.66分 | step: 107200 | performance: 198.7 | accuracy: 0.36 | loss: 0.60
update:1345/2000, 耗时:0.00分/3.67分 | step: 107600 | performance: 152.7 | accuracy: 0.35 | loss: 0.24
update:1350/2000, 耗时:0.00分/3.69分 | step: 108000 | performance: 198.2 | accuracy: 0.35 | loss: 0.40
update:1355/2000, 耗时:0.00分/3.70分 | step: 108400 | performance: 156.6 | accuracy: 0.34 | loss: 0.16
update:1360/2000, 耗时:0.00分/3.71分 | step: 108800 | performance: 171.4 | accuracy: 0.34 | loss: 0.61
update:1365/2000, 耗时:0.00分/3.73分 | step: 109200 | performance: 243.3 | accuracy: 0.34 | loss: 0.31
update:1370/2000, 耗时:0.00分/3.74分 | step: 109600 | performance: 230.7 | accuracy: 0.34 | loss: 0.09
update:1375/2000, 耗时:0.00分/3.75分 | step: 110000 | performance: 325.0 | accuracy: 0.33 | loss: 0.30
update:1380/2000, 耗时:0.00分/3.76分 | step: 110400 | performance: 237.8 | accuracy: 0.33 | loss: 0.65
update:1385/2000, 耗时:0.00分/3.78分 | step: 110800 | performance: 233.0 | accuracy: 0.33 | loss: 0.36
update:1390/2000, 耗时:0.00分/3.79分 | step: 111200 | performance: 247.4 | accuracy: 0.32 | loss: 0.42
update:1395/2000, 耗时:0.00分/3.80分 | step: 111600 | performance: 236.5 | accuracy: 0.32 | loss: 0.46
update:1400/2000, 耗时:0.00分/3.82分 | step: 112000 | performance: 216.4 | accuracy: 0.32 | loss: 0.54
update:1405/2000, 耗时:0.00分/3.83分 | step: 112400 | performance: 339.3 | accuracy: 0.32 | loss: 0.50
update:1410/2000, 耗时:0.00分/3.84分 | step: 112800 | performance: 341.7 | accuracy: 0.32 | loss: 0.53
Saving PPO weights in both H5 format and checkpoint @ update:1412 
Saving PPO weights in both H5 format and checkpoint @ update:1413 
update:1415/2000, 耗时:0.00分/3.86分 | step: 113200 | performance: 0.8 | accuracy: 0.26 | loss: 1.17
update:1420/2000, 耗时:0.00分/3.88分 | step: 113600 | performance: 1.1 | accuracy: 0.33 | loss: 0.60
update:1425/2000, 耗时:0.00分/3.89分 | step: 114000 | performance: 1.2 | accuracy: 0.31 | loss: 0.88
update:1430/2000, 耗时:0.00分/3.90分 | step: 114400 | performance: 1.7 | accuracy: 0.31 | loss: 0.55
update:1435/2000, 耗时:0.00分/3.92分 | step: 114800 | performance: 2.2 | accuracy: 0.30 | loss: 0.49
update:1440/2000, 耗时:0.00分/3.93分 | step: 115200 | performance: 1.9 | accuracy: 0.29 | loss: 0.24
update:1445/2000, 耗时:0.00分/3.94分 | step: 115600 | performance: 3.6 | accuracy: 0.31 | loss: 0.71
update:1450/2000, 耗时:0.00分/3.96分 | step: 116000 | performance: 2.9 | accuracy: 0.28 | loss: 0.73
update:1455/2000, 耗时:0.00分/3.97分 | step: 116400 | performance: 2.9 | accuracy: 0.27 | loss: 0.32
update:1460/2000, 耗时:0.00分/3.98分 | step: 116800 | performance: 2.6 | accuracy: 0.26 | loss: 0.48
update:1465/2000, 耗时:0.00分/3.99分 | step: 117200 | performance: 7.9 | accuracy: 0.27 | loss: 0.81
update:1470/2000, 耗时:0.00分/4.01分 | step: 117600 | performance: 7.3 | accuracy: 0.26 | loss: 0.22
update:1475/2000, 耗时:0.00分/4.02分 | step: 118000 | performance: 7.8 | accuracy: 0.24 | loss: 0.14
update:1480/2000, 耗时:0.00分/4.03分 | step: 118400 | performance: 7.8 | accuracy: 0.23 | loss: 0.16
update:1485/2000, 耗时:0.00分/4.05分 | step: 118800 | performance: 7.5 | accuracy: 0.22 | loss: 0.30
update:1490/2000, 耗时:0.00分/4.06分 | step: 119200 | performance: 5.0 | accuracy: 0.22 | loss: 0.84
update:1495/2000, 耗时:0.00分/4.07分 | step: 119600 | performance: 5.5 | accuracy: 0.23 | loss: 1.20
update:1500/2000, 耗时:0.00分/4.09分 | step: 120000 | performance: 22.2 | accuracy: 0.25 | loss: 3.39
update:1505/2000, 耗时:0.00分/4.10分 | step: 120400 | performance: 41.2 | accuracy: 0.27 | loss: 2.28
update:1510/2000, 耗时:0.00分/4.11分 | step: 120800 | performance: 100.9 | accuracy: 0.29 | loss: 3.24
update:1515/2000, 耗时:0.00分/4.13分 | step: 121200 | performance: 69.5 | accuracy: 0.30 | loss: 1.37
update:1520/2000, 耗时:0.00分/4.14分 | step: 121600 | performance: 41.1 | accuracy: 0.30 | loss: 0.99
update:1525/2000, 耗时:0.00分/4.15分 | step: 122000 | performance: 59.3 | accuracy: 0.31 | loss: 1.35
update:1530/2000, 耗时:0.00分/4.16分 | step: 122400 | performance: 76.3 | accuracy: 0.31 | loss: 0.43
update:1535/2000, 耗时:0.00分/4.18分 | step: 122800 | performance: 52.9 | accuracy: 0.31 | loss: 0.55
update:1540/2000, 耗时:0.00分/4.19分 | step: 123200 | performance: 100.8 | accuracy: 0.31 | loss: 0.34
update:1545/2000, 耗时:0.00分/4.20分 | step: 123600 | performance: 96.5 | accuracy: 0.31 | loss: 0.18
update:1550/2000, 耗时:0.00分/4.22分 | step: 124000 | performance: 73.1 | accuracy: 0.30 | loss: 0.70
update:1555/2000, 耗时:0.00分/4.23分 | step: 124400 | performance: 59.6 | accuracy: 0.30 | loss: 0.85
update:1560/2000, 耗时:0.00分/4.24分 | step: 124800 | performance: 201.3 | accuracy: 0.30 | loss: 1.34
update:1565/2000, 耗时:0.00分/4.26分 | step: 125200 | performance: 124.6 | accuracy: 0.30 | loss: 0.23
update:1570/2000, 耗时:0.00分/4.27分 | step: 125600 | performance: 134.5 | accuracy: 0.29 | loss: 0.77
update:1575/2000, 耗时:0.00分/4.28分 | step: 126000 | performance: 139.8 | accuracy: 0.30 | loss: 0.98
update:1580/2000, 耗时:0.00分/4.29分 | step: 126400 | performance: 118.4 | accuracy: 0.31 | loss: 0.82
update:1585/2000, 耗时:0.00分/4.31分 | step: 126800 | performance: 124.5 | accuracy: 0.31 | loss: 0.56
update:1590/2000, 耗时:0.00分/4.32分 | step: 127200 | performance: 133.5 | accuracy: 0.32 | loss: 1.33
update:1595/2000, 耗时:0.00分/4.33分 | step: 127600 | performance: 90.4 | accuracy: 0.32 | loss: 1.04
update:1600/2000, 耗时:0.00分/4.35分 | step: 128000 | performance: 75.7 | accuracy: 0.32 | loss: 0.64
update:1605/2000, 耗时:0.00分/4.36分 | step: 128400 | performance: 92.2 | accuracy: 0.32 | loss: 0.82
update:1610/2000, 耗时:0.00分/4.37分 | step: 128800 | performance: 317.9 | accuracy: 0.33 | loss: 0.86
update:1615/2000, 耗时:0.00分/4.38分 | step: 129200 | performance: 739.0 | accuracy: 0.34 | loss: 3.19
update:1620/2000, 耗时:0.00分/4.40分 | step: 129600 | performance: 3746.8 | accuracy: 0.35 | loss: 7.71
update:1625/2000, 耗时:0.00分/4.41分 | step: 130000 | performance: 5267.6 | accuracy: 0.35 | loss: 3.17
update:1630/2000, 耗时:0.00分/4.42分 | step: 130400 | performance: 14715.0 | accuracy: 0.36 | loss: 1.95
update:1635/2000, 耗时:0.00分/4.44分 | step: 130800 | performance: 19787.2 | accuracy: 0.37 | loss: 1.93
update:1640/2000, 耗时:0.00分/4.45分 | step: 131200 | performance: 14767.2 | accuracy: 0.37 | loss: 1.69
update:1645/2000, 耗时:0.00分/4.46分 | step: 131600 | performance: 9028.4 | accuracy: 0.37 | loss: 1.17
update:1650/2000, 耗时:0.00分/4.48分 | step: 132000 | performance: 15986.5 | accuracy: 0.37 | loss: 0.79
update:1655/2000, 耗时:0.00分/4.49分 | step: 132400 | performance: 23170.0 | accuracy: 0.37 | loss: 0.40
update:1660/2000, 耗时:0.00分/4.50分 | step: 132800 | performance: 20937.1 | accuracy: 0.36 | loss: 0.41
update:1665/2000, 耗时:0.00分/4.52分 | step: 133200 | performance: 19820.8 | accuracy: 0.36 | loss: 0.38
update:1670/2000, 耗时:0.00分/4.53分 | step: 133600 | performance: 24494.2 | accuracy: 0.36 | loss: 0.72
update:1675/2000, 耗时:0.00分/4.54分 | step: 134000 | performance: 47733.6 | accuracy: 0.36 | loss: 0.96
update:1680/2000, 耗时:0.00分/4.56分 | step: 134400 | performance: 62942.6 | accuracy: 0.36 | loss: 1.87
update:1685/2000, 耗时:0.00分/4.57分 | step: 134800 | performance: 33418.6 | accuracy: 0.36 | loss: 1.11
update:1690/2000, 耗时:0.00分/4.58分 | step: 135200 | performance: 11008.6 | accuracy: 0.36 | loss: 0.84
update:1695/2000, 耗时:0.00分/4.59分 | step: 135600 | performance: 19110.2 | accuracy: 0.36 | loss: 0.83
update:1700/2000, 耗时:0.00分/4.61分 | step: 136000 | performance: 14500.1 | accuracy: 0.36 | loss: 0.08
update:1705/2000, 耗时:0.00分/4.62分 | step: 136400 | performance: 15393.2 | accuracy: 0.36 | loss: 0.29
update:1710/2000, 耗时:0.00分/4.63分 | step: 136800 | performance: 13431.0 | accuracy: 0.35 | loss: 0.42
update:1715/2000, 耗时:0.00分/4.65分 | step: 137200 | performance: 15079.5 | accuracy: 0.35 | loss: 0.37
update:1720/2000, 耗时:0.00分/4.66分 | step: 137600 | performance: 33927.5 | accuracy: 0.35 | loss: 0.13
update:1725/2000, 耗时:0.00分/4.67分 | step: 138000 | performance: 38692.3 | accuracy: 0.35 | loss: 0.73
update:1730/2000, 耗时:0.00分/4.69分 | step: 138400 | performance: 40618.1 | accuracy: 0.34 | loss: 0.16
update:1735/2000, 耗时:0.00分/4.70分 | step: 138800 | performance: 41826.9 | accuracy: 0.34 | loss: 0.20
update:1740/2000, 耗时:0.00分/4.71分 | step: 139200 | performance: 59634.1 | accuracy: 0.34 | loss: 0.38
update:1745/2000, 耗时:0.00分/4.72分 | step: 139600 | performance: 56353.3 | accuracy: 0.33 | loss: 0.43
update:1750/2000, 耗时:0.00分/4.74分 | step: 140000 | performance: 53228.8 | accuracy: 0.33 | loss: 0.50
update:1755/2000, 耗时:0.00分/4.75分 | step: 140400 | performance: 91144.8 | accuracy: 0.33 | loss: 0.65
update:1760/2000, 耗时:0.00分/4.76分 | step: 140800 | performance: 84270.9 | accuracy: 0.33 | loss: 0.50
step: 141113 | worker_0@n_step_9: average total_reward after train data exhaustion : 197.1 | max total_reward: 300.0
step: 141114 | worker_1@n_step_9: average total_reward after train data exhaustion : 197.2 | max total_reward: 300.0
step: 141115 | worker_2@n_step_9: average total_reward after train data exhaustion : 198.2 | max total_reward: 300.0
step: 141116 | worker_3@n_step_9: average total_reward after train data exhaustion : 200.4 | max total_reward: 300.0
step: 141117 | worker_4@n_step_9: average total_reward after train data exhaustion : 201.1 | max total_reward: 300.0
step: 141118 | worker_5@n_step_9: average total_reward after train data exhaustion : 203.6 | max total_reward: 300.0
step: 141120 | worker_7@n_step_9: average total_reward after train data exhaustion : 205.2 | max total_reward: 300.0
Saving PPO weights in both H5 format and checkpoint @ update:1764 
update:1765/2000, 耗时:0.00分/4.78分 | step: 141200 | performance: 1.5 | accuracy: 0.50 | loss: 1.54
Saving PPO weights in both H5 format and checkpoint @ update:1766 
update:1770/2000, 耗时:0.00分/4.80分 | step: 141600 | performance: 3.5 | accuracy: 0.52 | loss: 0.96
update:1775/2000, 耗时:0.00分/4.81分 | step: 142000 | performance: 1.7 | accuracy: 0.35 | loss: 0.39
update:1780/2000, 耗时:0.00分/4.83分 | step: 142400 | performance: 2.3 | accuracy: 0.36 | loss: 1.23
update:1785/2000, 耗时:0.00分/4.84分 | step: 142800 | performance: 3.0 | accuracy: 0.35 | loss: 0.46
update:1790/2000, 耗时:0.00分/4.86分 | step: 143200 | performance: 4.2 | accuracy: 0.34 | loss: 0.58
update:1795/2000, 耗时:0.00分/4.87分 | step: 143600 | performance: 4.0 | accuracy: 0.33 | loss: 0.69
update:1800/2000, 耗时:0.00分/4.88分 | step: 144000 | performance: 4.3 | accuracy: 0.33 | loss: 0.42
update:1805/2000, 耗时:0.00分/4.90分 | step: 144400 | performance: 4.6 | accuracy: 0.31 | loss: 0.84
update:1810/2000, 耗时:0.00分/4.91分 | step: 144800 | performance: 3.9 | accuracy: 0.30 | loss: 0.74
update:1815/2000, 耗时:0.00分/4.93分 | step: 145200 | performance: 5.0 | accuracy: 0.31 | loss: 0.47
update:1820/2000, 耗时:0.00分/4.94分 | step: 145600 | performance: 9.0 | accuracy: 0.30 | loss: 0.23
update:1825/2000, 耗时:0.00分/4.95分 | step: 146000 | performance: 7.4 | accuracy: 0.29 | loss: 0.14
update:1830/2000, 耗时:0.00分/4.97分 | step: 146400 | performance: 8.1 | accuracy: 0.28 | loss: 0.24
update:1835/2000, 耗时:0.00分/4.98分 | step: 146800 | performance: 7.1 | accuracy: 0.27 | loss: 0.33
update:1840/2000, 耗时:0.00分/5.00分 | step: 147200 | performance: 6.1 | accuracy: 0.26 | loss: 0.33
update:1845/2000, 耗时:0.00分/5.01分 | step: 147600 | performance: 4.5 | accuracy: 0.26 | loss: 0.85
update:1850/2000, 耗时:0.00分/5.02分 | step: 148000 | performance: 8.2 | accuracy: 0.28 | loss: 1.07
update:1855/2000, 耗时:0.00分/5.04分 | step: 148400 | performance: 30.4 | accuracy: 0.30 | loss: 2.27
update:1860/2000, 耗时:0.00分/5.05分 | step: 148800 | performance: 101.1 | accuracy: 0.32 | loss: 1.89
update:1865/2000, 耗时:0.00分/5.07分 | step: 149200 | performance: 42.3 | accuracy: 0.32 | loss: 1.90
update:1870/2000, 耗时:0.00分/5.08分 | step: 149600 | performance: 35.3 | accuracy: 0.33 | loss: 2.13
update:1875/2000, 耗时:0.00分/5.10分 | step: 150000 | performance: 40.0 | accuracy: 0.34 | loss: 0.85
update:1880/2000, 耗时:0.00分/5.11分 | step: 150400 | performance: 30.1 | accuracy: 0.34 | loss: 1.29
update:1885/2000, 耗时:0.00分/5.13分 | step: 150800 | performance: 34.4 | accuracy: 0.34 | loss: 0.56
update:1890/2000, 耗时:0.00分/5.14分 | step: 151200 | performance: 61.5 | accuracy: 0.34 | loss: 1.43
update:1895/2000, 耗时:0.00分/5.15分 | step: 151600 | performance: 56.9 | accuracy: 0.33 | loss: 0.46
update:1900/2000, 耗时:0.00分/5.17分 | step: 152000 | performance: 54.7 | accuracy: 0.33 | loss: 0.10
update:1905/2000, 耗时:0.00分/5.18分 | step: 152400 | performance: 50.3 | accuracy: 0.32 | loss: 0.64
update:1910/2000, 耗时:0.00分/5.20分 | step: 152800 | performance: 31.9 | accuracy: 0.32 | loss: 0.78
update:1915/2000, 耗时:0.00分/5.21分 | step: 153200 | performance: 47.7 | accuracy: 0.32 | loss: 0.66
update:1920/2000, 耗时:0.00分/5.22分 | step: 153600 | performance: 41.0 | accuracy: 0.31 | loss: 0.24
update:1925/2000, 耗时:0.00分/5.24分 | step: 154000 | performance: 24.8 | accuracy: 0.31 | loss: 1.16
update:1930/2000, 耗时:0.00分/5.25分 | step: 154400 | performance: 23.4 | accuracy: 0.32 | loss: 1.11
update:1935/2000, 耗时:0.00分/5.27分 | step: 154800 | performance: 22.6 | accuracy: 0.32 | loss: 0.71
update:1940/2000, 耗时:0.00分/5.28分 | step: 155200 | performance: 36.9 | accuracy: 0.33 | loss: 1.76
update:1945/2000, 耗时:0.00分/5.29分 | step: 155600 | performance: 36.5 | accuracy: 0.33 | loss: 1.16
update:1950/2000, 耗时:0.00分/5.31分 | step: 156000 | performance: 24.5 | accuracy: 0.34 | loss: 0.87
update:1955/2000, 耗时:0.00分/5.32分 | step: 156400 | performance: 23.0 | accuracy: 0.34 | loss: 0.68
update:1960/2000, 耗时:0.00分/5.34分 | step: 156800 | performance: 67.8 | accuracy: 0.35 | loss: 1.33
update:1965/2000, 耗时:0.00分/5.35分 | step: 157200 | performance: 150.2 | accuracy: 0.36 | loss: 1.36
update:1970/2000, 耗时:0.00分/5.36分 | step: 157600 | performance: 578.9 | accuracy: 0.36 | loss: 1.60
update:1975/2000, 耗时:0.00分/5.38分 | step: 158000 | performance: 1091.4 | accuracy: 0.37 | loss: 4.37
update:1980/2000, 耗时:0.00分/5.39分 | step: 158400 | performance: 4958.7 | accuracy: 0.38 | loss: 0.66
update:1985/2000, 耗时:0.00分/5.40分 | step: 158800 | performance: 7578.3 | accuracy: 0.38 | loss: 1.33
update:1990/2000, 耗时:0.00分/5.42分 | step: 159200 | performance: 6164.3 | accuracy: 0.39 | loss: 1.63
update:1995/2000, 耗时:0.00分/5.43分 | step: 159600 | performance: 6333.2 | accuracy: 0.39 | loss: 0.95
  0%|          | 0/397 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/5.45分 | step: 160000 | performance: 6500.9 | accuracy: 0.39 | loss: 2.05
----------------------------------------finished----------------------------------------
100%|| 397/397 [00:00<00:00, 99221.71it/s]
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1013.90
2023-07-24T12:00:00 | net performance [%] = 1.3901
2023-07-24T12:00:00 | number of trades [#] = 60
==================================================
Trial 32 Complete [00h 05m 53s]
net_wealth: 1014.9155472336918

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 04h 22m 42s

Search: Running Trial #33

Value             |Best Value So Far |Hyperparameter
6                 |1                 |horizon
365               |730               |lookback
False             |False             |MarketFactor
20                |3                 |lags
0.98              |0.92              |gamma
32                |32                |batch_size
3                 |1                 |n_step
0.92              |0.94              |gae_lambda
0.2               |5                 |gradient_clip_norm
5                 |5                 |epochs
0.0005            |0.0001            |actor_lr
0.0001            |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4309.000000   4315.000000
mean      0.000441    20062.255222  ...   20140.547965  20118.633889
std       0.027818    16039.874230  ...   16077.550480  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7699.189941   7690.540039
50%       0.000642    11554.824463  ...   11743.940430  11715.610352
75%       0.011655    29873.081836  ...   29950.949219  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 02:26:05.367465: I tensorflow/c2023-07-28 02:26:05.367497: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate com202202233ore/plap-0tform/cpu_feature_gi7uler fla-28 02:26:05.03674-07-28652023- gs02:2.
070-26:: aI23-2078r-23-07-22d.c8 c0: 2:28 6:0 0t201422]5:e 2Th62.:26:0:i0s05n35. Tens3o.sor6F06lrflow3756o7w/.7 36951: I769bc23-07-28 02:26:05.368095: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI De 83: I ti5ore/ple7t:eensanp96 0 :n aItsoofINo  etrflroum/ewn/ccore/psorptlflow/core/palatform/cpuue_featurrtflofrnroarlm /Nesew/co_gorfrloey/cupa w/cord.cc:14p_feature_gil2au] arThd.crste/plaitfo rmtufc:142osptimiw_or/ T]z This Tcomfeatur/cpu_feeprenka_gueardsorFlow binary is optimized with oneAPI Ded.ccns orL eewpibr uN_fFitheature_guard.l :o1e4wcc:14 bi2]a2u rnTrtoary iaylh] N usr ee(onoptim_ized i ThissegwutDNitawrorkdh N)  Te.cc: tT1e4 nLoi nnso2bsrnaeeoruoser API Deep AFtlhoPw] I D birnye (onepF loTahry is NeDNN) tNoeopwi bu rueuie fotralse thensa Tenr y  llowingaNet fCwPoUs instrorllowiorl Netwuctions in performance-critical operaoFikti olnrnss : goo AViX Ckw  LpPtiimLU i mbArVbiinaary (irzy is opotneDNN) to use tXizenhe fold2 with 
mTilbowingsoedi  etzreawryind ructit h (aobloneDon CPU eweNiNnonensstArPuI A in pD ith eeerpf oNrtomeurPIal Nha neeA)nectiP Ic DteDetowooermk  usns in pein other operations, rebuild TensorFlow  ep Nee-wriLe utpitbhrearyrf oal Nh etwork Nforthem e(l a aourLilnoacl e-wcirniNpprong CPU bcritical tpioprraerriyc eDNN) to use the f(nosnaolltoriaetatiuocns:tiwDileNN ) t ot onws ooprkeu Libr rsea taritiAnyon phee Vs:rf eoX (  cAVXrfmnol oglnoea CnA APVUXoVX 2inmstcwp2i
n
Tor eilngue-acbe r flagcsCTPro ei.ti
caUlneal in  obple them setrDtin ruoathcNthietiNones ) m toorn tiso:i usonnien ot p   heresr apterfoAoViXo pit hereArVX2 
fTan penolltsio, rns,oo enable them iwien bnuoigrforml Cand TensorFlow with the t hPrmacep-Ucaprireerbuil onoprptcde Tensi instruaiec-critreations,  orcrtaetliFclowibouiln operations:s in performance-critical operations:  Aad Tens  AVX AVX2
To enable them in other operations, c witlVX oohm A rpilrtebuildh eFr eolpVoX w af2T
eTolean penasogrs.
Flow with the apblwpietrpr otha tionthemrhpe approprriatoipras:eit ea   inc octe co AVommXmother operations, rebuild TensorFlow with the appropriate compiler flags.
piler flags.
pi AVX2
To enable them in other operations, lpiler flags.er flags.
r
ebuild TensorFlow with the appropriate compiler flags.
2023-07-28 02:26:05.970493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:26:05.976078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:26:05.982710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:26:06.008338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:26:06.015830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:26:06.020868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:26:06.032328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:26:06.036363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   120 | performance: 1.1 | accuracy: 0.40 | loss: 3.05
update: 10/2000, 耗时:0.00分/0.04分 | step:   240 | performance: 0.8 | accuracy: 0.37 | loss: 3.55
update: 15/2000, 耗时:0.00分/0.05分 | step:   360 | performance: 2.4 | accuracy: 0.51 | loss: 3.88
update: 20/2000, 耗时:0.00分/0.06分 | step:   480 | performance: 2.7 | accuracy: 0.50 | loss: 3.36
update: 25/2000, 耗时:0.00分/0.07分 | step:   600 | performance: 1.0 | accuracy: 0.45 | loss: 1.18
update: 30/2000, 耗时:0.00分/0.08分 | step:   720 | performance: 0.6 | accuracy: 0.41 | loss: 1.39
update: 35/2000, 耗时:0.00分/0.10分 | step:   840 | performance: 0.6 | accuracy: 0.38 | loss: 0.62
update: 40/2000, 耗时:0.00分/0.11分 | step:   960 | performance: 0.6 | accuracy: 0.35 | loss: 0.85
update: 45/2000, 耗时:0.00分/0.12分 | step:  1080 | performance: 0.9 | accuracy: 0.38 | loss: 0.46
update: 50/2000, 耗时:0.00分/0.13分 | step:  1200 | performance: 1.3 | accuracy: 0.41 | loss: 2.57
update: 55/2000, 耗时:0.00分/0.15分 | step:  1320 | performance: 2.3 | accuracy: 0.44 | loss: 1.74
update: 60/2000, 耗时:0.00分/0.16分 | step:  1440 | performance: 2.2 | accuracy: 0.40 | loss: 0.00
update: 65/2000, 耗时:0.00分/0.17分 | step:  1560 | performance: 2.2 | accuracy: 0.37 | loss: 0.01
update: 70/2000, 耗时:0.00分/0.19分 | step:  1680 | performance: 2.2 | accuracy: 0.34 | loss: 0.11
update: 75/2000, 耗时:0.00分/0.20分 | step:  1800 | performance: 2.2 | accuracy: 0.32 | loss: 0.03
update: 80/2000, 耗时:0.00分/0.21分 | step:  1920 | performance: 2.7 | accuracy: 0.33 | loss: 0.58
update: 85/2000, 耗时:0.00分/0.23分 | step:  2040 | performance: 1.8 | accuracy: 0.32 | loss: 0.37
update: 90/2000, 耗时:0.00分/0.24分 | step:  2160 | performance: 3.3 | accuracy: 0.33 | loss: 0.37
update: 95/2000, 耗时:0.00分/0.25分 | step:  2280 | performance: 5.9 | accuracy: 0.35 | loss: 0.50
update:100/2000, 耗时:0.00分/0.27分 | step:  2400 | performance: 3.7 | accuracy: 0.34 | loss: 0.64
update:105/2000, 耗时:0.00分/0.28分 | step:  2520 | performance: 5.7 | accuracy: 0.35 | loss: 1.10
update:110/2000, 耗时:0.00分/0.30分 | step:  2640 | performance: 5.0 | accuracy: 0.35 | loss: 0.71
update:115/2000, 耗时:0.00分/0.31分 | step:  2760 | performance: 3.5 | accuracy: 0.34 | loss: 1.35
update:120/2000, 耗时:0.00分/0.32分 | step:  2880 | performance: 3.7 | accuracy: 0.34 | loss: 1.42
update:125/2000, 耗时:0.00分/0.34分 | step:  3000 | performance: 7.2 | accuracy: 0.36 | loss: 0.93
update:130/2000, 耗时:0.00分/0.35分 | step:  3120 | performance: 7.0 | accuracy: 0.36 | loss: 0.46
update:135/2000, 耗时:0.00分/0.36分 | step:  3240 | performance: 6.0 | accuracy: 0.36 | loss: 0.91
update:140/2000, 耗时:0.00分/0.38分 | step:  3360 | performance: 5.9 | accuracy: 0.37 | loss: 0.82
update:145/2000, 耗时:0.00分/0.39分 | step:  3480 | performance: 7.4 | accuracy: 0.37 | loss: 3.20
update:150/2000, 耗时:0.00分/0.40分 | step:  3600 | performance: 5.9 | accuracy: 0.37 | loss: 0.64
update:155/2000, 耗时:0.00分/0.41分 | step:  3720 | performance: 6.2 | accuracy: 0.38 | loss: 0.64
update:160/2000, 耗时:0.00分/0.43分 | step:  3840 | performance: 6.6 | accuracy: 0.38 | loss: 1.88
update:165/2000, 耗时:0.00分/0.44分 | step:  3960 | performance: 6.6 | accuracy: 0.38 | loss: 0.37
update:170/2000, 耗时:0.00分/0.45分 | step:  4080 | performance: 11.6 | accuracy: 0.39 | loss: 3.01
update:175/2000, 耗时:0.00分/0.47分 | step:  4200 | performance: 61.3 | accuracy: 0.40 | loss: 2.80
update:180/2000, 耗时:0.00分/0.48分 | step:  4320 | performance: 33.8 | accuracy: 0.40 | loss: 3.53
update:185/2000, 耗时:0.00分/0.49分 | step:  4440 | performance: 15.9 | accuracy: 0.39 | loss: 1.41
update:190/2000, 耗时:0.00分/0.51分 | step:  4560 | performance: 16.1 | accuracy: 0.40 | loss: 1.53
update:195/2000, 耗时:0.00分/0.52分 | step:  4680 | performance: 12.2 | accuracy: 0.40 | loss: 1.75
update:200/2000, 耗时:0.00分/0.53分 | step:  4800 | performance: 10.0 | accuracy: 0.40 | loss: 0.57
update:205/2000, 耗时:0.00分/0.55分 | step:  4920 | performance: 9.8 | accuracy: 0.40 | loss: 2.46
update:210/2000, 耗时:0.00分/0.56分 | step:  5040 | performance: 7.8 | accuracy: 0.40 | loss: 0.83
update:215/2000, 耗时:0.00分/0.57分 | step:  5160 | performance: 7.7 | accuracy: 0.40 | loss: 0.44
update:220/2000, 耗时:0.00分/0.58分 | step:  5280 | performance: 8.5 | accuracy: 0.40 | loss: 1.72
update:225/2000, 耗时:0.00分/0.60分 | step:  5400 | performance: 7.1 | accuracy: 0.40 | loss: 2.73
update:230/2000, 耗时:0.00分/0.61分 | step:  5520 | performance: 6.7 | accuracy: 0.40 | loss: 1.73
update:235/2000, 耗时:0.00分/0.62分 | step:  5640 | performance: 3.8 | accuracy: 0.40 | loss: 0.76
update:240/2000, 耗时:0.00分/0.64分 | step:  5760 | performance: 4.6 | accuracy: 0.40 | loss: 0.53
update:245/2000, 耗时:0.00分/0.65分 | step:  5880 | performance: 3.9 | accuracy: 0.39 | loss: 0.94
update:250/2000, 耗时:0.00分/0.66分 | step:  6000 | performance: 3.5 | accuracy: 0.39 | loss: 0.31
update:255/2000, 耗时:0.00分/0.68分 | step:  6120 | performance: 3.6 | accuracy: 0.39 | loss: 0.39
update:260/2000, 耗时:0.00分/0.69分 | step:  6240 | performance: 3.1 | accuracy: 0.38 | loss: 0.71
update:265/2000, 耗时:0.00分/0.70分 | step:  6360 | performance: 3.2 | accuracy: 0.37 | loss: 0.01
update:270/2000, 耗时:0.00分/0.72分 | step:  6480 | performance: 3.0 | accuracy: 0.37 | loss: 0.26
update:275/2000, 耗时:0.00分/0.73分 | step:  6600 | performance: 2.8 | accuracy: 0.37 | loss: 0.55
update:280/2000, 耗时:0.00分/0.74分 | step:  6720 | performance: 2.8 | accuracy: 0.36 | loss: 0.08
update:285/2000, 耗时:0.00分/0.76分 | step:  6840 | performance: 2.6 | accuracy: 0.35 | loss: 0.00
update:290/2000, 耗时:0.00分/0.77分 | step:  6960 | performance: 2.6 | accuracy: 0.35 | loss: 0.03
update:295/2000, 耗时:0.00分/0.78分 | step:  7080 | performance: 2.6 | accuracy: 0.34 | loss: 0.00
update:300/2000, 耗时:0.00分/0.79分 | step:  7200 | performance: 2.8 | accuracy: 0.34 | loss: 0.37
update:305/2000, 耗时:0.00分/0.81分 | step:  7320 | performance: 2.8 | accuracy: 0.33 | loss: 0.00
update:310/2000, 耗时:0.00分/0.82分 | step:  7440 | performance: 2.7 | accuracy: 0.33 | loss: 0.21
update:315/2000, 耗时:0.00分/0.83分 | step:  7560 | performance: 2.7 | accuracy: 0.32 | loss: 0.02
update:320/2000, 耗时:0.00分/0.85分 | step:  7680 | performance: 2.7 | accuracy: 0.32 | loss: 0.02
update:325/2000, 耗时:0.00分/0.86分 | step:  7800 | performance: 4.9 | accuracy: 0.32 | loss: 3.77
update:330/2000, 耗时:0.00分/0.87分 | step:  7920 | performance: 1.9 | accuracy: 0.32 | loss: 1.24
update:335/2000, 耗时:0.00分/0.89分 | step:  8040 | performance: 2.0 | accuracy: 0.32 | loss: 2.35
update:340/2000, 耗时:0.00分/0.90分 | step:  8160 | performance: 2.1 | accuracy: 0.33 | loss: 3.45
update:345/2000, 耗时:0.00分/0.91分 | step:  8280 | performance: 1.1 | accuracy: 0.32 | loss: 0.19
update:350/2000, 耗时:0.00分/0.92分 | step:  8400 | performance: 1.1 | accuracy: 0.32 | loss: 0.06
update:355/2000, 耗时:0.00分/0.94分 | step:  8520 | performance: 1.1 | accuracy: 0.32 | loss: 0.18
update:360/2000, 耗时:0.00分/0.95分 | step:  8640 | performance: 1.2 | accuracy: 0.31 | loss: 1.01
update:365/2000, 耗时:0.00分/0.96分 | step:  8760 | performance: 1.3 | accuracy: 0.31 | loss: 0.36
update:370/2000, 耗时:0.00分/0.97分 | step:  8880 | performance: 1.4 | accuracy: 0.31 | loss: 0.51
update:375/2000, 耗时:0.00分/0.99分 | step:  9000 | performance: 1.4 | accuracy: 0.31 | loss: 0.04
update:380/2000, 耗时:0.00分/1.00分 | step:  9120 | performance: 1.8 | accuracy: 0.31 | loss: 1.00
update:385/2000, 耗时:0.00分/1.01分 | step:  9240 | performance: 1.9 | accuracy: 0.31 | loss: 1.11
update:390/2000, 耗时:0.00分/1.02分 | step:  9360 | performance: 1.6 | accuracy: 0.31 | loss: 0.44
update:395/2000, 耗时:0.00分/1.04分 | step:  9480 | performance: 1.8 | accuracy: 0.32 | loss: 1.79
update:400/2000, 耗时:0.00分/1.05分 | step:  9600 | performance: 0.9 | accuracy: 0.32 | loss: 1.26
update:405/2000, 耗时:0.00分/1.06分 | step:  9720 | performance: 1.0 | accuracy: 0.32 | loss: 0.47
update:410/2000, 耗时:0.00分/1.07分 | step:  9840 | performance: 0.9 | accuracy: 0.32 | loss: 0.62
update:415/2000, 耗时:0.00分/1.09分 | step:  9960 | performance: 1.8 | accuracy: 0.33 | loss: 3.69
update:420/2000, 耗时:0.00分/1.10分 | step: 10080 | performance: 2.4 | accuracy: 0.33 | loss: 4.17
update:425/2000, 耗时:0.00分/1.11分 | step: 10200 | performance: 3.0 | accuracy: 0.33 | loss: 0.81
update:430/2000, 耗时:0.00分/1.12分 | step: 10320 | performance: 3.2 | accuracy: 0.34 | loss: 0.65
update:435/2000, 耗时:0.00分/1.14分 | step: 10440 | performance: 3.2 | accuracy: 0.34 | loss: 0.61
update:440/2000, 耗时:0.00分/1.15分 | step: 10560 | performance: 2.3 | accuracy: 0.33 | loss: 0.57
update:445/2000, 耗时:0.00分/1.16分 | step: 10680 | performance: 2.5 | accuracy: 0.33 | loss: 0.28
update:450/2000, 耗时:0.00分/1.18分 | step: 10800 | performance: 2.9 | accuracy: 0.33 | loss: 0.29
update:455/2000, 耗时:0.00分/1.19分 | step: 10920 | performance: 3.5 | accuracy: 0.33 | loss: 2.13
update:460/2000, 耗时:0.00分/1.20分 | step: 11040 | performance: 3.7 | accuracy: 0.33 | loss: 0.87
update:465/2000, 耗时:0.00分/1.21分 | step: 11160 | performance: 4.2 | accuracy: 0.33 | loss: 0.46
update:470/2000, 耗时:0.00分/1.23分 | step: 11280 | performance: 5.6 | accuracy: 0.33 | loss: 1.33
update:475/2000, 耗时:0.00分/1.24分 | step: 11400 | performance: 4.8 | accuracy: 0.33 | loss: 0.59
update:480/2000, 耗时:0.00分/1.25分 | step: 11520 | performance: 7.7 | accuracy: 0.34 | loss: 2.12
update:485/2000, 耗时:0.00分/1.26分 | step: 11640 | performance: 8.7 | accuracy: 0.34 | loss: 3.10
update:490/2000, 耗时:0.00分/1.28分 | step: 11760 | performance: 73.2 | accuracy: 0.34 | loss: 17.13
update:495/2000, 耗时:0.00分/1.29分 | step: 11880 | performance: 85.7 | accuracy: 0.34 | loss: 22.29
update:500/2000, 耗时:0.00分/1.30分 | step: 12000 | performance: 68.4 | accuracy: 0.34 | loss: 1.53
update:505/2000, 耗时:0.00分/1.32分 | step: 12120 | performance: 105.8 | accuracy: 0.34 | loss: 2.14
update:510/2000, 耗时:0.00分/1.33分 | step: 12240 | performance: 110.5 | accuracy: 0.34 | loss: 2.73
update:515/2000, 耗时:0.00分/1.34分 | step: 12360 | performance: 132.4 | accuracy: 0.34 | loss: 0.40
update:520/2000, 耗时:0.00分/1.35分 | step: 12480 | performance: 180.8 | accuracy: 0.34 | loss: 1.73
update:525/2000, 耗时:0.00分/1.37分 | step: 12600 | performance: 436.1 | accuracy: 0.35 | loss: 0.39
update:530/2000, 耗时:0.00分/1.38分 | step: 12720 | performance: 395.0 | accuracy: 0.35 | loss: 3.34
update:535/2000, 耗时:0.00分/1.39分 | step: 12840 | performance: 450.6 | accuracy: 0.35 | loss: 0.96
update:540/2000, 耗时:0.00分/1.40分 | step: 12960 | performance: 694.6 | accuracy: 0.35 | loss: 0.65
update:545/2000, 耗时:0.00分/1.42分 | step: 13080 | performance: 436.5 | accuracy: 0.35 | loss: 1.74
update:550/2000, 耗时:0.00分/1.43分 | step: 13200 | performance: 469.0 | accuracy: 0.35 | loss: 0.39
update:555/2000, 耗时:0.00分/1.44分 | step: 13320 | performance: 529.9 | accuracy: 0.35 | loss: 1.07
update:560/2000, 耗时:0.00分/1.45分 | step: 13440 | performance: 611.1 | accuracy: 0.36 | loss: 2.98
update:565/2000, 耗时:0.00分/1.47分 | step: 13560 | performance: 658.2 | accuracy: 0.36 | loss: 1.97
update:570/2000, 耗时:0.00分/1.48分 | step: 13680 | performance: 613.1 | accuracy: 0.36 | loss: 0.81
update:575/2000, 耗时:0.00分/1.49分 | step: 13800 | performance: 666.9 | accuracy: 0.36 | loss: 0.37
update:580/2000, 耗时:0.00分/1.51分 | step: 13920 | performance: 560.2 | accuracy: 0.36 | loss: 0.89
update:585/2000, 耗时:0.00分/1.52分 | step: 14040 | performance: 1150.1 | accuracy: 0.37 | loss: 0.16
update:590/2000, 耗时:0.00分/1.53分 | step: 14160 | performance: 1387.8 | accuracy: 0.37 | loss: 0.36
update:595/2000, 耗时:0.00分/1.54分 | step: 14280 | performance: 1308.2 | accuracy: 0.37 | loss: 0.79
update:600/2000, 耗时:0.00分/1.56分 | step: 14400 | performance: 1380.1 | accuracy: 0.37 | loss: 0.76
update:605/2000, 耗时:0.00分/1.57分 | step: 14520 | performance: 1166.0 | accuracy: 0.37 | loss: 0.79
update:610/2000, 耗时:0.00分/1.58分 | step: 14640 | performance: 1613.3 | accuracy: 0.37 | loss: 1.20
update:615/2000, 耗时:0.00分/1.59分 | step: 14760 | performance: 1111.6 | accuracy: 0.36 | loss: 0.88
update:620/2000, 耗时:0.00分/1.61分 | step: 14880 | performance: 1045.4 | accuracy: 0.36 | loss: 0.82
update:625/2000, 耗时:0.00分/1.62分 | step: 15000 | performance: 1055.5 | accuracy: 0.36 | loss: 0.83
update:630/2000, 耗时:0.00分/1.63分 | step: 15120 | performance: 1040.2 | accuracy: 0.36 | loss: 0.10
update:635/2000, 耗时:0.00分/1.65分 | step: 15240 | performance: 1122.8 | accuracy: 0.36 | loss: 2.07
update:640/2000, 耗时:0.00分/1.66分 | step: 15360 | performance: 2449.0 | accuracy: 0.37 | loss: 2.40
update:645/2000, 耗时:0.00分/1.67分 | step: 15480 | performance: 3223.6 | accuracy: 0.37 | loss: 1.55
update:650/2000, 耗时:0.00分/1.68分 | step: 15600 | performance: 6489.4 | accuracy: 0.37 | loss: 0.46
update:655/2000, 耗时:0.00分/1.70分 | step: 15720 | performance: 7426.4 | accuracy: 0.37 | loss: 0.34
update:660/2000, 耗时:0.00分/1.71分 | step: 15840 | performance: 8905.2 | accuracy: 0.37 | loss: 0.67
update:665/2000, 耗时:0.00分/1.72分 | step: 15960 | performance: 9346.6 | accuracy: 0.37 | loss: 2.13
update:670/2000, 耗时:0.00分/1.73分 | step: 16080 | performance: 11666.2 | accuracy: 0.37 | loss: 1.31
update:675/2000, 耗时:0.00分/1.75分 | step: 16200 | performance: 10031.8 | accuracy: 0.37 | loss: 0.72
update:680/2000, 耗时:0.00分/1.76分 | step: 16320 | performance: 15403.3 | accuracy: 0.37 | loss: 1.34
update:685/2000, 耗时:0.00分/1.77分 | step: 16440 | performance: 43655.7 | accuracy: 0.38 | loss: 3.18
update:690/2000, 耗时:0.00分/1.78分 | step: 16560 | performance: 192069.0 | accuracy: 0.38 | loss: 6.19
update:695/2000, 耗时:0.00分/1.80分 | step: 16680 | performance: 213347.0 | accuracy: 0.38 | loss: 1.25
update:700/2000, 耗时:0.00分/1.81分 | step: 16800 | performance: 238832.9 | accuracy: 0.38 | loss: 0.94
update:705/2000, 耗时:0.00分/1.82分 | step: 16920 | performance: 185181.4 | accuracy: 0.38 | loss: 4.93
update:710/2000, 耗时:0.00分/1.84分 | step: 17040 | performance: 126498.4 | accuracy: 0.38 | loss: 1.28
update:715/2000, 耗时:0.00分/1.85分 | step: 17160 | performance: 78158.9 | accuracy: 0.38 | loss: 2.09
update:720/2000, 耗时:0.00分/1.86分 | step: 17280 | performance: 184253.6 | accuracy: 0.38 | loss: 1.52
update:725/2000, 耗时:0.00分/1.87分 | step: 17400 | performance: 58519.0 | accuracy: 0.38 | loss: 1.84
update:730/2000, 耗时:0.00分/1.89分 | step: 17520 | performance: 64195.0 | accuracy: 0.38 | loss: 0.00
update:735/2000, 耗时:0.00分/1.90分 | step: 17640 | performance: 59007.6 | accuracy: 0.38 | loss: 1.57
update:740/2000, 耗时:0.00分/1.91分 | step: 17760 | performance: 52967.3 | accuracy: 0.38 | loss: 2.31
update:745/2000, 耗时:0.00分/1.92分 | step: 17880 | performance: 48004.8 | accuracy: 0.37 | loss: 0.14
update:750/2000, 耗时:0.00分/1.94分 | step: 18000 | performance: 45208.3 | accuracy: 0.37 | loss: 0.42
update:755/2000, 耗时:0.00分/1.95分 | step: 18120 | performance: 75406.3 | accuracy: 0.37 | loss: 2.05
update:760/2000, 耗时:0.00分/1.96分 | step: 18240 | performance: 41520.2 | accuracy: 0.37 | loss: 1.51
update:765/2000, 耗时:0.00分/1.98分 | step: 18360 | performance: 44670.8 | accuracy: 0.37 | loss: 0.11
update:770/2000, 耗时:0.00分/1.99分 | step: 18480 | performance: 43489.6 | accuracy: 0.37 | loss: 0.58
update:775/2000, 耗时:0.00分/2.00分 | step: 18600 | performance: 32284.3 | accuracy: 0.37 | loss: 0.07
update:780/2000, 耗时:0.00分/2.01分 | step: 18720 | performance: 61092.5 | accuracy: 0.37 | loss: 0.72
update:785/2000, 耗时:0.00分/2.03分 | step: 18840 | performance: 103057.1 | accuracy: 0.37 | loss: 5.58
update:790/2000, 耗时:0.00分/2.04分 | step: 18960 | performance: 87212.5 | accuracy: 0.37 | loss: 0.67
update:795/2000, 耗时:0.00分/2.05分 | step: 19080 | performance: 103807.8 | accuracy: 0.37 | loss: 0.95
update:800/2000, 耗时:0.00分/2.06分 | step: 19200 | performance: 62015.2 | accuracy: 0.37 | loss: 4.39
update:805/2000, 耗时:0.00分/2.08分 | step: 19320 | performance: 60207.2 | accuracy: 0.37 | loss: 2.50
update:810/2000, 耗时:0.00分/2.09分 | step: 19440 | performance: 56653.8 | accuracy: 0.37 | loss: 1.15
update:815/2000, 耗时:0.00分/2.10分 | step: 19560 | performance: 49357.9 | accuracy: 0.37 | loss: 2.34
update:820/2000, 耗时:0.00分/2.11分 | step: 19680 | performance: 41991.3 | accuracy: 0.37 | loss: 0.32
update:825/2000, 耗时:0.00分/2.13分 | step: 19800 | performance: 108274.8 | accuracy: 0.37 | loss: 3.73
update:830/2000, 耗时:0.00分/2.14分 | step: 19920 | performance: 105029.6 | accuracy: 0.37 | loss: 0.54
update:835/2000, 耗时:0.00分/2.15分 | step: 20040 | performance: 212756.8 | accuracy: 0.37 | loss: 0.69
update:840/2000, 耗时:0.00分/2.17分 | step: 20160 | performance: 222314.5 | accuracy: 0.37 | loss: 2.25
update:845/2000, 耗时:0.00分/2.18分 | step: 20280 | performance: 278695.6 | accuracy: 0.37 | loss: 0.57
update:850/2000, 耗时:0.00分/2.19分 | step: 20400 | performance: 295677.7 | accuracy: 0.37 | loss: 0.82
update:855/2000, 耗时:0.00分/2.20分 | step: 20520 | performance: 188724.7 | accuracy: 0.38 | loss: 1.51
update:860/2000, 耗时:0.00分/2.22分 | step: 20640 | performance: 171585.9 | accuracy: 0.37 | loss: 0.52
update:865/2000, 耗时:0.00分/2.23分 | step: 20760 | performance: 172892.0 | accuracy: 0.37 | loss: 1.45
update:870/2000, 耗时:0.00分/2.24分 | step: 20880 | performance: 145987.9 | accuracy: 0.37 | loss: 0.22
update:875/2000, 耗时:0.00分/2.25分 | step: 21000 | performance: 180380.4 | accuracy: 0.37 | loss: 1.43
update:880/2000, 耗时:0.00分/2.27分 | step: 21120 | performance: 312161.7 | accuracy: 0.38 | loss: 1.24
update:885/2000, 耗时:0.00分/2.28分 | step: 21240 | performance: 307269.0 | accuracy: 0.38 | loss: 0.49
update:890/2000, 耗时:0.00分/2.29分 | step: 21360 | performance: 280206.7 | accuracy: 0.38 | loss: 3.00
update:895/2000, 耗时:0.00分/2.30分 | step: 21480 | performance: 196292.4 | accuracy: 0.38 | loss: 0.65
update:900/2000, 耗时:0.00分/2.32分 | step: 21600 | performance: 382027.5 | accuracy: 0.38 | loss: 2.72
update:905/2000, 耗时:0.00分/2.33分 | step: 21720 | performance: 510156.3 | accuracy: 0.38 | loss: 0.48
update:910/2000, 耗时:0.00分/2.34分 | step: 21840 | performance: 474693.9 | accuracy: 0.38 | loss: 0.00
update:915/2000, 耗时:0.00分/2.35分 | step: 21960 | performance: 521290.2 | accuracy: 0.38 | loss: 0.84
update:920/2000, 耗时:0.00分/2.37分 | step: 22080 | performance: 542700.0 | accuracy: 0.38 | loss: 1.11
update:925/2000, 耗时:0.00分/2.38分 | step: 22200 | performance: 466571.0 | accuracy: 0.38 | loss: 1.08
update:930/2000, 耗时:0.00分/2.39分 | step: 22320 | performance: 316448.9 | accuracy: 0.38 | loss: 0.39
update:935/2000, 耗时:0.00分/2.40分 | step: 22440 | performance: 277410.7 | accuracy: 0.38 | loss: 0.89
update:940/2000, 耗时:0.00分/2.42分 | step: 22560 | performance: 259515.4 | accuracy: 0.38 | loss: 0.27
update:945/2000, 耗时:0.00分/2.43分 | step: 22680 | performance: 415646.2 | accuracy: 0.38 | loss: 1.43
update:950/2000, 耗时:0.00分/2.44分 | step: 22800 | performance: 358867.4 | accuracy: 0.38 | loss: 0.44
update:955/2000, 耗时:0.00分/2.45分 | step: 22920 | performance: 740044.3 | accuracy: 0.38 | loss: 3.27
update:960/2000, 耗时:0.00分/2.47分 | step: 23040 | performance: 741917.4 | accuracy: 0.38 | loss: 1.30
update:965/2000, 耗时:0.00分/2.48分 | step: 23160 | performance: 404049.1 | accuracy: 0.38 | loss: 1.11
update:970/2000, 耗时:0.00分/2.49分 | step: 23280 | performance: 380943.6 | accuracy: 0.37 | loss: 0.78
update:975/2000, 耗时:0.00分/2.51分 | step: 23400 | performance: 350159.8 | accuracy: 0.37 | loss: -0.01
update:980/2000, 耗时:0.00分/2.52分 | step: 23520 | performance: 398418.5 | accuracy: 0.37 | loss: 0.40
update:985/2000, 耗时:0.00分/2.53分 | step: 23640 | performance: 442280.4 | accuracy: 0.37 | loss: 0.16
update:990/2000, 耗时:0.00分/2.54分 | step: 23760 | performance: 589753.1 | accuracy: 0.37 | loss: 2.37
update:995/2000, 耗时:0.00分/2.56分 | step: 23880 | performance: 427367.1 | accuracy: 0.37 | loss: 2.02
update:1000/2000, 耗时:0.00分/2.57分 | step: 24000 | performance: 563512.8 | accuracy: 0.37 | loss: 1.13
update:1005/2000, 耗时:0.00分/2.58分 | step: 24120 | performance: 603065.9 | accuracy: 0.37 | loss: 1.96
update:1010/2000, 耗时:0.00分/2.59分 | step: 24240 | performance: 602363.1 | accuracy: 0.37 | loss: 0.90
update:1015/2000, 耗时:0.00分/2.61分 | step: 24360 | performance: 1385580.7 | accuracy: 0.38 | loss: 3.67
update:1020/2000, 耗时:0.00分/2.62分 | step: 24480 | performance: 2379670.8 | accuracy: 0.38 | loss: 2.00
update:1025/2000, 耗时:0.00分/2.63分 | step: 24600 | performance: 2759612.6 | accuracy: 0.38 | loss: 0.58
update:1030/2000, 耗时:0.00分/2.64分 | step: 24720 | performance: 1784778.5 | accuracy: 0.38 | loss: 2.24
update:1035/2000, 耗时:0.00分/2.66分 | step: 24840 | performance: 2091841.1 | accuracy: 0.38 | loss: 0.51
update:1040/2000, 耗时:0.00分/2.67分 | step: 24960 | performance: 17081137.6 | accuracy: 0.38 | loss: 2.02
update:1045/2000, 耗时:0.00分/2.68分 | step: 25080 | performance: 22132514.3 | accuracy: 0.38 | loss: 0.93
update:1050/2000, 耗时:0.00分/2.69分 | step: 25200 | performance: 30879622.5 | accuracy: 0.38 | loss: 1.87
update:1055/2000, 耗时:0.00分/2.71分 | step: 25320 | performance: 19596558.4 | accuracy: 0.38 | loss: 3.44
update:1060/2000, 耗时:0.00分/2.72分 | step: 25440 | performance: 23610531.4 | accuracy: 0.38 | loss: 4.13
update:1065/2000, 耗时:0.00分/2.73分 | step: 25560 | performance: 13125702.8 | accuracy: 0.38 | loss: 0.50
update:1070/2000, 耗时:0.00分/2.74分 | step: 25680 | performance: 10547485.3 | accuracy: 0.38 | loss: 0.61
update:1075/2000, 耗时:0.00分/2.76分 | step: 25800 | performance: 11860076.6 | accuracy: 0.38 | loss: 2.17
update:1080/2000, 耗时:0.00分/2.77分 | step: 25920 | performance: 9313507.6 | accuracy: 0.38 | loss: 0.47
update:1085/2000, 耗时:0.00分/2.78分 | step: 26040 | performance: 20468441.9 | accuracy: 0.38 | loss: 1.86
update:1090/2000, 耗时:0.00分/2.80分 | step: 26160 | performance: 31172935.7 | accuracy: 0.38 | loss: 0.48
update:1095/2000, 耗时:0.00分/2.81分 | step: 26280 | performance: 36843916.5 | accuracy: 0.39 | loss: 0.92
update:1100/2000, 耗时:0.00分/2.82分 | step: 26400 | performance: 22020482.6 | accuracy: 0.39 | loss: 2.95
update:1105/2000, 耗时:0.00分/2.83分 | step: 26520 | performance: 43085440.8 | accuracy: 0.39 | loss: 1.40
update:1110/2000, 耗时:0.00分/2.85分 | step: 26640 | performance: 36602737.1 | accuracy: 0.39 | loss: 1.67
update:1115/2000, 耗时:0.00分/2.86分 | step: 26760 | performance: 27103081.9 | accuracy: 0.39 | loss: 2.19
update:1120/2000, 耗时:0.00分/2.87分 | step: 26880 | performance: 36527189.4 | accuracy: 0.39 | loss: 2.34
update:1125/2000, 耗时:0.00分/2.88分 | step: 27000 | performance: 38061212.9 | accuracy: 0.39 | loss: 1.26
update:1130/2000, 耗时:0.00分/2.90分 | step: 27120 | performance: 25117669.9 | accuracy: 0.39 | loss: 2.01
update:1135/2000, 耗时:0.00分/2.91分 | step: 27240 | performance: 22425926.4 | accuracy: 0.39 | loss: 3.82
update:1140/2000, 耗时:0.00分/2.92分 | step: 27360 | performance: 84951699.4 | accuracy: 0.39 | loss: 0.83
update:1145/2000, 耗时:0.00分/2.93分 | step: 27480 | performance: 90095419.5 | accuracy: 0.39 | loss: 1.88
update:1150/2000, 耗时:0.00分/2.95分 | step: 27600 | performance: 94378173.0 | accuracy: 0.39 | loss: 2.18
update:1155/2000, 耗时:0.00分/2.96分 | step: 27720 | performance: 76510370.4 | accuracy: 0.39 | loss: 0.28
update:1160/2000, 耗时:0.00分/2.97分 | step: 27840 | performance: 71318024.1 | accuracy: 0.39 | loss: 2.43
update:1165/2000, 耗时:0.00分/2.98分 | step: 27960 | performance: 87206112.9 | accuracy: 0.39 | loss: 2.71
update:1170/2000, 耗时:0.00分/3.00分 | step: 28080 | performance: 88260963.3 | accuracy: 0.39 | loss: 1.53
step: 28169 | worker_0@n_step_2: average total_reward after train data exhaustion : 296.7 | max total_reward: 296.7
step: 28170 | worker_1@n_step_2: average total_reward after train data exhaustion : 276.2 | max total_reward: 296.7
step: 28171 | worker_2@n_step_2: average total_reward after train data exhaustion : 264.1 | max total_reward: 296.7
step: 28172 | worker_3@n_step_2: average total_reward after train data exhaustion : 275.8 | max total_reward: 310.9
step: 28173 | worker_4@n_step_2: average total_reward after train data exhaustion : 274.4 | max total_reward: 310.9
step: 28174 | worker_5@n_step_2: average total_reward after train data exhaustion : 274.4 | max total_reward: 310.9
step: 28175 | worker_6@n_step_2: average total_reward after train data exhaustion : 270.4 | max total_reward: 310.9
step: 28176 | worker_7@n_step_2: average total_reward after train data exhaustion : 269.8 | max total_reward: 310.9
Saving PPO weights in both H5 format and checkpoint @ update:1174 
update:1175/2000, 耗时:0.00分/3.01分 | step: 28200 | performance: 1.2 | accuracy: 0.67 | loss: 1.56
update:1180/2000, 耗时:0.00分/3.02分 | step: 28320 | performance: 2.6 | accuracy: 0.78 | loss: 1.84
update:1185/2000, 耗时:0.00分/3.04分 | step: 28440 | performance: 1.9 | accuracy: 0.61 | loss: 2.32
update:1190/2000, 耗时:0.00分/3.05分 | step: 28560 | performance: 6.6 | accuracy: 0.69 | loss: 1.02
update:1195/2000, 耗时:0.00分/3.06分 | step: 28680 | performance: 7.1 | accuracy: 0.63 | loss: 0.55
update:1200/2000, 耗时:0.00分/3.07分 | step: 28800 | performance: 2.6 | accuracy: 0.56 | loss: 0.54
update:1205/2000, 耗时:0.00分/3.08分 | step: 28920 | performance: 1.3 | accuracy: 0.49 | loss: 2.97
update:1210/2000, 耗时:0.00分/3.10分 | step: 29040 | performance: 1.3 | accuracy: 0.49 | loss: 1.73
update:1215/2000, 耗时:0.00分/3.11分 | step: 29160 | performance: 1.3 | accuracy: 0.50 | loss: 0.61
update:1220/2000, 耗时:0.00分/3.12分 | step: 29280 | performance: 2.5 | accuracy: 0.53 | loss: 2.22
update:1225/2000, 耗时:0.00分/3.13分 | step: 29400 | performance: 4.5 | accuracy: 0.54 | loss: 3.51
update:1230/2000, 耗时:0.00分/3.15分 | step: 29520 | performance: 5.1 | accuracy: 0.55 | loss: 0.37
update:1235/2000, 耗时:0.00分/3.16分 | step: 29640 | performance: 4.5 | accuracy: 0.54 | loss: 0.28
update:1240/2000, 耗时:0.00分/3.17分 | step: 29760 | performance: 12.1 | accuracy: 0.56 | loss: 0.39
update:1245/2000, 耗时:0.00分/3.18分 | step: 29880 | performance: 16.1 | accuracy: 0.56 | loss: 4.10
update:1250/2000, 耗时:0.00分/3.19分 | step: 30000 | performance: 15.5 | accuracy: 0.55 | loss: 3.68
update:1255/2000, 耗时:0.00分/3.21分 | step: 30120 | performance: 10.7 | accuracy: 0.52 | loss: 2.23
update:1260/2000, 耗时:0.00分/3.22分 | step: 30240 | performance: 13.8 | accuracy: 0.53 | loss: 3.37
update:1265/2000, 耗时:0.00分/3.23分 | step: 30360 | performance: 4.9 | accuracy: 0.51 | loss: 3.80
update:1270/2000, 耗时:0.00分/3.24分 | step: 30480 | performance: 3.4 | accuracy: 0.50 | loss: 0.68
update:1275/2000, 耗时:0.00分/3.25分 | step: 30600 | performance: 7.6 | accuracy: 0.51 | loss: 2.05
update:1280/2000, 耗时:0.00分/3.27分 | step: 30720 | performance: 13.7 | accuracy: 0.53 | loss: 0.39
update:1285/2000, 耗时:0.00分/3.28分 | step: 30840 | performance: 10.9 | accuracy: 0.51 | loss: 0.43
update:1290/2000, 耗时:0.00分/3.29分 | step: 30960 | performance: 6.9 | accuracy: 0.49 | loss: 0.87
update:1295/2000, 耗时:0.00分/3.30分 | step: 31080 | performance: 7.2 | accuracy: 0.48 | loss: 3.00
update:1300/2000, 耗时:0.00分/3.32分 | step: 31200 | performance: 9.9 | accuracy: 0.49 | loss: 2.35
update:1305/2000, 耗时:0.00分/3.33分 | step: 31320 | performance: 9.3 | accuracy: 0.48 | loss: 2.39
update:1310/2000, 耗时:0.00分/3.34分 | step: 31440 | performance: 9.6 | accuracy: 0.48 | loss: 1.20
update:1315/2000, 耗时:0.00分/3.35分 | step: 31560 | performance: 9.5 | accuracy: 0.48 | loss: 0.50
update:1320/2000, 耗时:0.00分/3.37分 | step: 31680 | performance: 11.3 | accuracy: 0.47 | loss: 1.02
update:1325/2000, 耗时:0.00分/3.38分 | step: 31800 | performance: 8.6 | accuracy: 0.47 | loss: 0.49
update:1330/2000, 耗时:0.00分/3.39分 | step: 31920 | performance: 9.3 | accuracy: 0.46 | loss: 1.88
update:1335/2000, 耗时:0.00分/3.40分 | step: 32040 | performance: 9.6 | accuracy: 0.46 | loss: 2.22
update:1340/2000, 耗时:0.00分/3.42分 | step: 32160 | performance: 9.8 | accuracy: 0.46 | loss: 0.31
update:1345/2000, 耗时:0.00分/3.43分 | step: 32280 | performance: 50.3 | accuracy: 0.47 | loss: 5.12
update:1350/2000, 耗时:0.00分/3.44分 | step: 32400 | performance: 181.0 | accuracy: 0.48 | loss: 2.41
update:1355/2000, 耗时:0.00分/3.45分 | step: 32520 | performance: 213.2 | accuracy: 0.48 | loss: 1.90
update:1360/2000, 耗时:0.00分/3.47分 | step: 32640 | performance: 495.1 | accuracy: 0.49 | loss: 2.15
update:1365/2000, 耗时:0.00分/3.48分 | step: 32760 | performance: 231.1 | accuracy: 0.49 | loss: 4.31
update:1370/2000, 耗时:0.00分/3.49分 | step: 32880 | performance: 298.2 | accuracy: 0.49 | loss: 0.70
update:1375/2000, 耗时:0.00分/3.50分 | step: 33000 | performance: 280.2 | accuracy: 0.48 | loss: 0.31
update:1380/2000, 耗时:0.00分/3.51分 | step: 33120 | performance: 313.1 | accuracy: 0.47 | loss: 2.10
update:1385/2000, 耗时:0.00分/3.53分 | step: 33240 | performance: 301.4 | accuracy: 0.47 | loss: 0.80
update:1390/2000, 耗时:0.00分/3.54分 | step: 33360 | performance: 334.2 | accuracy: 0.47 | loss: 0.70
update:1395/2000, 耗时:0.00分/3.55分 | step: 33480 | performance: 397.7 | accuracy: 0.47 | loss: 0.44
update:1400/2000, 耗时:0.00分/3.56分 | step: 33600 | performance: 296.3 | accuracy: 0.47 | loss: 0.77
update:1405/2000, 耗时:0.00分/3.57分 | step: 33720 | performance: 259.9 | accuracy: 0.47 | loss: 3.30
update:1410/2000, 耗时:0.00分/3.59分 | step: 33840 | performance: 213.3 | accuracy: 0.47 | loss: 1.08
update:1415/2000, 耗时:0.00分/3.60分 | step: 33960 | performance: 241.3 | accuracy: 0.46 | loss: 0.88
update:1420/2000, 耗时:0.00分/3.61分 | step: 34080 | performance: 221.0 | accuracy: 0.46 | loss: 0.05
update:1425/2000, 耗时:0.00分/3.62分 | step: 34200 | performance: 196.9 | accuracy: 0.45 | loss: 0.63
update:1430/2000, 耗时:0.00分/3.64分 | step: 34320 | performance: 200.1 | accuracy: 0.45 | loss: 0.98
update:1435/2000, 耗时:0.00分/3.65分 | step: 34440 | performance: 174.0 | accuracy: 0.44 | loss: 0.11
update:1440/2000, 耗时:0.00分/3.66分 | step: 34560 | performance: 174.0 | accuracy: 0.43 | loss: 0.09
update:1445/2000, 耗时:0.00分/3.67分 | step: 34680 | performance: 197.6 | accuracy: 0.43 | loss: 2.02
update:1450/2000, 耗时:0.00分/3.69分 | step: 34800 | performance: 207.5 | accuracy: 0.43 | loss: 2.09
update:1455/2000, 耗时:0.00分/3.70分 | step: 34920 | performance: 272.1 | accuracy: 0.43 | loss: 2.73
update:1460/2000, 耗时:0.00分/3.71分 | step: 35040 | performance: 725.5 | accuracy: 0.44 | loss: 5.46
update:1465/2000, 耗时:0.00分/3.72分 | step: 35160 | performance: 1477.5 | accuracy: 0.45 | loss: 1.59
update:1470/2000, 耗时:0.00分/3.74分 | step: 35280 | performance: 2456.7 | accuracy: 0.45 | loss: 1.86
update:1475/2000, 耗时:0.00分/3.75分 | step: 35400 | performance: 2580.5 | accuracy: 0.45 | loss: 2.93
update:1480/2000, 耗时:0.00分/3.76分 | step: 35520 | performance: 1649.1 | accuracy: 0.45 | loss: 2.58
update:1485/2000, 耗时:0.00分/3.78分 | step: 35640 | performance: 4124.6 | accuracy: 0.46 | loss: 1.43
update:1490/2000, 耗时:0.00分/3.79分 | step: 35760 | performance: 18804.9 | accuracy: 0.47 | loss: 4.30
update:1495/2000, 耗时:0.00分/3.80分 | step: 35880 | performance: 12214.4 | accuracy: 0.47 | loss: 0.82
update:1500/2000, 耗时:0.00分/3.81分 | step: 36000 | performance: 21362.3 | accuracy: 0.47 | loss: 3.17
update:1505/2000, 耗时:0.00分/3.82分 | step: 36120 | performance: 5890.0 | accuracy: 0.46 | loss: 4.69
update:1510/2000, 耗时:0.00分/3.84分 | step: 36240 | performance: 5917.6 | accuracy: 0.46 | loss: 3.89
update:1515/2000, 耗时:0.00分/3.85分 | step: 36360 | performance: 7919.1 | accuracy: 0.46 | loss: 3.36
update:1520/2000, 耗时:0.00分/3.86分 | step: 36480 | performance: 14299.5 | accuracy: 0.47 | loss: 1.31
update:1525/2000, 耗时:0.00分/3.87分 | step: 36600 | performance: 10264.6 | accuracy: 0.46 | loss: 0.61
update:1530/2000, 耗时:0.00分/3.88分 | step: 36720 | performance: 9339.6 | accuracy: 0.46 | loss: 0.29
update:1535/2000, 耗时:0.00分/3.90分 | step: 36840 | performance: 6284.1 | accuracy: 0.46 | loss: 0.84
update:1540/2000, 耗时:0.00分/3.91分 | step: 36960 | performance: 10542.1 | accuracy: 0.46 | loss: 0.44
update:1545/2000, 耗时:0.00分/3.92分 | step: 37080 | performance: 11808.0 | accuracy: 0.47 | loss: 1.15
update:1550/2000, 耗时:0.00分/3.93分 | step: 37200 | performance: 15531.3 | accuracy: 0.47 | loss: 1.38
update:1555/2000, 耗时:0.00分/3.94分 | step: 37320 | performance: 44605.8 | accuracy: 0.47 | loss: 0.60
update:1560/2000, 耗时:0.00分/3.96分 | step: 37440 | performance: 39542.5 | accuracy: 0.47 | loss: 1.75
update:1565/2000, 耗时:0.00分/3.97分 | step: 37560 | performance: 41882.7 | accuracy: 0.47 | loss: 0.14
update:1570/2000, 耗时:0.00分/3.98分 | step: 37680 | performance: 52701.9 | accuracy: 0.46 | loss: 0.12
update:1575/2000, 耗时:0.00分/3.99分 | step: 37800 | performance: 22980.9 | accuracy: 0.46 | loss: 0.18
update:1580/2000, 耗时:0.00分/4.00分 | step: 37920 | performance: 24177.2 | accuracy: 0.45 | loss: 0.18
update:1585/2000, 耗时:0.00分/4.02分 | step: 38040 | performance: 24382.0 | accuracy: 0.45 | loss: 0.09
update:1590/2000, 耗时:0.00分/4.03分 | step: 38160 | performance: 43472.9 | accuracy: 0.45 | loss: 2.91
update:1595/2000, 耗时:0.00分/4.04分 | step: 38280 | performance: 41705.0 | accuracy: 0.45 | loss: 0.44
update:1600/2000, 耗时:0.00分/4.05分 | step: 38400 | performance: 39679.4 | accuracy: 0.45 | loss: 0.64
update:1605/2000, 耗时:0.00分/4.07分 | step: 38520 | performance: 48004.3 | accuracy: 0.45 | loss: 1.90
update:1610/2000, 耗时:0.00分/4.08分 | step: 38640 | performance: 46336.9 | accuracy: 0.45 | loss: 1.03
update:1615/2000, 耗时:0.00分/4.09分 | step: 38760 | performance: 46389.8 | accuracy: 0.44 | loss: 0.03
update:1620/2000, 耗时:0.00分/4.10分 | step: 38880 | performance: 35667.7 | accuracy: 0.44 | loss: 0.49
update:1625/2000, 耗时:0.00分/4.11分 | step: 39000 | performance: 34486.2 | accuracy: 0.43 | loss: 0.32
update:1630/2000, 耗时:0.00分/4.13分 | step: 39120 | performance: 35232.4 | accuracy: 0.43 | loss: -0.00
update:1635/2000, 耗时:0.00分/4.14分 | step: 39240 | performance: 29925.8 | accuracy: 0.42 | loss: 0.68
update:1640/2000, 耗时:0.00分/4.15分 | step: 39360 | performance: 30331.5 | accuracy: 0.42 | loss: 1.18
update:1645/2000, 耗时:0.00分/4.16分 | step: 39480 | performance: 25056.6 | accuracy: 0.42 | loss: 0.05
update:1650/2000, 耗时:0.00分/4.18分 | step: 39600 | performance: 25153.4 | accuracy: 0.41 | loss: 0.68
update:1655/2000, 耗时:0.00分/4.19分 | step: 39720 | performance: 16611.3 | accuracy: 0.41 | loss: 2.33
update:1660/2000, 耗时:0.00分/4.20分 | step: 39840 | performance: 14173.5 | accuracy: 0.41 | loss: 1.22
update:1665/2000, 耗时:0.00分/4.21分 | step: 39960 | performance: 67268.6 | accuracy: 0.41 | loss: 6.56
update:1670/2000, 耗时:0.00分/4.23分 | step: 40080 | performance: 274218.2 | accuracy: 0.42 | loss: 1.57
update:1675/2000, 耗时:0.00分/4.24分 | step: 40200 | performance: 346614.4 | accuracy: 0.42 | loss: 1.64
update:1680/2000, 耗时:0.00分/4.25分 | step: 40320 | performance: 345045.7 | accuracy: 0.41 | loss: 0.01
update:1685/2000, 耗时:0.00分/4.26分 | step: 40440 | performance: 345045.7 | accuracy: 0.41 | loss: 0.00
update:1690/2000, 耗时:0.00分/4.28分 | step: 40560 | performance: 329745.2 | accuracy: 0.41 | loss: 0.00
update:1695/2000, 耗时:0.00分/4.29分 | step: 40680 | performance: 311952.1 | accuracy: 0.40 | loss: 0.00
update:1700/2000, 耗时:0.00分/4.30分 | step: 40800 | performance: 311952.1 | accuracy: 0.40 | loss: 0.00
update:1705/2000, 耗时:0.00分/4.31分 | step: 40920 | performance: 311952.1 | accuracy: 0.39 | loss: 0.01
update:1710/2000, 耗时:0.00分/4.32分 | step: 41040 | performance: 306950.4 | accuracy: 0.39 | loss: 3.06
update:1715/2000, 耗时:0.00分/4.34分 | step: 41160 | performance: 226670.1 | accuracy: 0.39 | loss: 1.24
update:1720/2000, 耗时:0.00分/4.35分 | step: 41280 | performance: 196660.6 | accuracy: 0.39 | loss: 0.61
update:1725/2000, 耗时:0.00分/4.36分 | step: 41400 | performance: 177544.4 | accuracy: 0.39 | loss: 2.59
update:1730/2000, 耗时:0.00分/4.37分 | step: 41520 | performance: 155575.8 | accuracy: 0.39 | loss: 2.24
update:1735/2000, 耗时:0.00分/4.39分 | step: 41640 | performance: 121311.8 | accuracy: 0.39 | loss: 1.18
update:1740/2000, 耗时:0.00分/4.40分 | step: 41760 | performance: 123559.0 | accuracy: 0.39 | loss: 1.08
update:1745/2000, 耗时:0.00分/4.41分 | step: 41880 | performance: 115017.1 | accuracy: 0.39 | loss: 1.00
update:1750/2000, 耗时:0.00分/4.42分 | step: 42000 | performance: 121932.1 | accuracy: 0.40 | loss: 0.13
update:1755/2000, 耗时:0.00分/4.43分 | step: 42120 | performance: 127390.9 | accuracy: 0.40 | loss: 1.90
update:1760/2000, 耗时:0.00分/4.45分 | step: 42240 | performance: 202863.9 | accuracy: 0.40 | loss: 2.69
update:1765/2000, 耗时:0.00分/4.46分 | step: 42360 | performance: 258997.1 | accuracy: 0.40 | loss: 2.49
update:1770/2000, 耗时:0.00分/4.47分 | step: 42480 | performance: 302246.8 | accuracy: 0.40 | loss: 0.34
update:1775/2000, 耗时:0.00分/4.48分 | step: 42600 | performance: 229102.6 | accuracy: 0.40 | loss: 2.45
update:1780/2000, 耗时:0.00分/4.50分 | step: 42720 | performance: 206961.8 | accuracy: 0.40 | loss: 3.60
update:1785/2000, 耗时:0.00分/4.51分 | step: 42840 | performance: 112531.0 | accuracy: 0.40 | loss: 0.21
update:1790/2000, 耗时:0.00分/4.52分 | step: 42960 | performance: 163885.5 | accuracy: 0.41 | loss: 1.82
update:1795/2000, 耗时:0.00分/4.53分 | step: 43080 | performance: 138871.1 | accuracy: 0.41 | loss: 1.09
update:1800/2000, 耗时:0.00分/4.55分 | step: 43200 | performance: 139376.9 | accuracy: 0.41 | loss: 2.13
update:1805/2000, 耗时:0.00分/4.56分 | step: 43320 | performance: 180439.2 | accuracy: 0.41 | loss: 1.88
update:1810/2000, 耗时:0.00分/4.57分 | step: 43440 | performance: 198070.5 | accuracy: 0.41 | loss: 0.28
update:1815/2000, 耗时:0.00分/4.58分 | step: 43560 | performance: 437640.1 | accuracy: 0.41 | loss: 0.55
update:1820/2000, 耗时:0.00分/4.59分 | step: 43680 | performance: 581164.2 | accuracy: 0.42 | loss: 0.48
update:1825/2000, 耗时:0.00分/4.61分 | step: 43800 | performance: 1120967.3 | accuracy: 0.42 | loss: 2.02
update:1830/2000, 耗时:0.00分/4.62分 | step: 43920 | performance: 1778933.2 | accuracy: 0.42 | loss: 1.59
update:1835/2000, 耗时:0.00分/4.63分 | step: 44040 | performance: 3741621.3 | accuracy: 0.43 | loss: 1.17
update:1840/2000, 耗时:0.00分/4.64分 | step: 44160 | performance: 4087666.9 | accuracy: 0.43 | loss: 1.12
update:1845/2000, 耗时:0.00分/4.65分 | step: 44280 | performance: 3328560.2 | accuracy: 0.42 | loss: 4.08
update:1850/2000, 耗时:0.00分/4.67分 | step: 44400 | performance: 6624102.9 | accuracy: 0.43 | loss: 3.54
update:1855/2000, 耗时:0.00分/4.68分 | step: 44520 | performance: 13777545.7 | accuracy: 0.43 | loss: 0.92
update:1860/2000, 耗时:0.00分/4.69分 | step: 44640 | performance: 45460285.6 | accuracy: 0.43 | loss: 1.51
update:1865/2000, 耗时:0.00分/4.70分 | step: 44760 | performance: 289312465.9 | accuracy: 0.44 | loss: 4.21
update:1870/2000, 耗时:0.00分/4.72分 | step: 44880 | performance: 218001658.6 | accuracy: 0.44 | loss: 0.92
update:1875/2000, 耗时:0.00分/4.73分 | step: 45000 | performance: 80802247.4 | accuracy: 0.44 | loss: 3.05
update:1880/2000, 耗时:0.00分/4.74分 | step: 45120 | performance: 120422850.5 | accuracy: 0.44 | loss: 0.49
update:1885/2000, 耗时:0.00分/4.75分 | step: 45240 | performance: 263246717.8 | accuracy: 0.44 | loss: 1.32
update:1890/2000, 耗时:0.00分/4.76分 | step: 45360 | performance: 864115372.0 | accuracy: 0.44 | loss: 1.41
update:1895/2000, 耗时:0.00分/4.78分 | step: 45480 | performance: 1784153090.8 | accuracy: 0.45 | loss: 4.38
update:1900/2000, 耗时:0.00分/4.79分 | step: 45600 | performance: 800278441.8 | accuracy: 0.45 | loss: 0.42
update:1905/2000, 耗时:0.00分/4.80分 | step: 45720 | performance: 1517329026.2 | accuracy: 0.45 | loss: 1.50
update:1910/2000, 耗时:0.00分/4.81分 | step: 45840 | performance: 2162683856.9 | accuracy: 0.45 | loss: 3.77
update:1915/2000, 耗时:0.00分/4.82分 | step: 45960 | performance: 1645259569.5 | accuracy: 0.45 | loss: 3.84
update:1920/2000, 耗时:0.00分/4.84分 | step: 46080 | performance: 2689852827.0 | accuracy: 0.45 | loss: 0.44
update:1925/2000, 耗时:0.00分/4.85分 | step: 46200 | performance: 2275920013.3 | accuracy: 0.45 | loss: 2.18
update:1930/2000, 耗时:0.00分/4.86分 | step: 46320 | performance: 3821623258.6 | accuracy: 0.45 | loss: 2.10
update:1935/2000, 耗时:0.00分/4.87分 | step: 46440 | performance: 1206793540.7 | accuracy: 0.45 | loss: 7.14
update:1940/2000, 耗时:0.00分/4.88分 | step: 46560 | performance: 1887093864.6 | accuracy: 0.45 | loss: 0.76
update:1945/2000, 耗时:0.00分/4.90分 | step: 46680 | performance: 2529153902.5 | accuracy: 0.45 | loss: 0.55
update:1950/2000, 耗时:0.00分/4.91分 | step: 46800 | performance: 980105008.5 | accuracy: 0.45 | loss: 4.77
update:1955/2000, 耗时:0.00分/4.92分 | step: 46920 | performance: 2054267032.2 | accuracy: 0.45 | loss: 2.72
update:1960/2000, 耗时:0.00分/4.94分 | step: 47040 | performance: 2351788613.6 | accuracy: 0.45 | loss: 2.30
update:1965/2000, 耗时:0.00分/4.95分 | step: 47160 | performance: 2822752378.9 | accuracy: 0.45 | loss: 1.67
update:1970/2000, 耗时:0.00分/4.96分 | step: 47280 | performance: 2117327429.5 | accuracy: 0.45 | loss: 1.53
update:1975/2000, 耗时:0.00分/4.98分 | step: 47400 | performance: 2767451696.8 | accuracy: 0.45 | loss: 0.67
update:1980/2000, 耗时:0.00分/4.99分 | step: 47520 | performance: 1793101888.1 | accuracy: 0.45 | loss: 3.22
update:1985/2000, 耗时:0.00分/5.00分 | step: 47640 | performance: 2205569842.6 | accuracy: 0.45 | loss: 1.27
update:1990/2000, 耗时:0.00分/5.01分 | step: 47760 | performance: 2958638176.5 | accuracy: 0.45 | loss: 1.40
update:1995/2000, 耗时:0.00分/5.03分 | step: 47880 | performance: 3499358140.3 | accuracy: 0.45 | loss: 3.94
update:2000/2000, 耗时:0.00分/5.04分 | step: 48000 | performance: 842177431.6 | accuracy: 0.45 | loss: 1.70
----------------------------------------finished----------------------------------------
==================================================
2023-01-10T12:00:00 | *** START BACKTEST ***
2023-01-10T12:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/391 [00:00<?, ?it/s]100%|| 391/391 [00:00<00:00, 98002.44it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 923.67
2023-07-24T12:00:00 | net performance [%] = -7.6332
2023-07-24T12:00:00 | number of trades [#] = 28
==================================================
Trial 33 Complete [00h 05m 29s]
net_wealth: 924.5926517246286

Best net_wealth So Far: 1739.2646221209268
Total elapsed time: 04h 28m 11s

Search: Running Trial #34

Value             |Best Value So Far |Hyperparameter
7                 |1                 |horizon
730               |730               |lookback
False             |False             |MarketFactor
14                |3                 |lags
0.7               |0.92              |gamma
32                |32                |batch_size
32                |1                 |n_step
0.92              |0.94              |gae_lambda
0.1               |5                 |gradient_clip_norm
5                 |5                 |epochs
0.0001            |0.0001            |actor_lr
5e-05             |0.0005            |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4308.000000   4315.000000
mean      0.000441    20062.255222  ...   20144.178930  20118.633889
std       0.027818    16039.874230  ...   16077.649782  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7710.492310   7690.540039
50%       0.000642    11554.824463  ...   11744.425293  11715.610352
75%       0.011655    29873.081836  ...   29961.684570  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 02:31:34.42023-07-28 02:31:34.462728: I tensorflow/core/platform/cpu_feature_guard.cc:142] 2023-07-28 02:31:34.462765: I tensorflow/core/platform/cpu_feature_guard2023-07-28 02:31:34.46262711: I tensorflow/core/platform/cpu_feature_guard.cc:142.] Tchis Tcensor:Flow b1ina4ry is optimized with oneAPI Deep Neural Network Library (802: I 2o]Thntensorf This Telis TensoroeDNNnw/s) to use theoc rFlow binary is optfore/piomllilaztefFo2r02lmo/3-d0 w2co0with2p02 0223-3one2 ub_i03A7P-win-I0 -naf7D-2g8 0 re20:37a7-1:238CP2yt8 - 28u riseU_ i4 g.u0a2r:d3.no1ce463ecpstt::ipmi341.zr1u424] T edction6N 3w1 9shiit02: Ie s80 teni n 2ur::02 Ih:asT3l1 penoso3 Neerrf: o3tF1t:3ernn4sor.eAPflfwloroormawI lnk LiDoowbe4.464//ecpe-633raw b2icc1n9:ao rc1er/oprlry iie8I7:  tes aNe/npusIorat itcraltf lefn soolN ry oetw(prepoork m/tioLactpunrrflowi_efDeNa/tlfmizeodc urwoithwbroaraeNr)m _ tor/guniyo cep/tn(so:npol euuse eaa AD_ feAatt/tform/hcupVur_efXerN_N)gua Aa turer_VdX.2cguarPc
tTcod e.ocr:d14.ce/poc usen:2]e fo142  tlI] aThis che D TftoalblTlowing CPU insens:hieteructo1s ir4 fthemoremFl /l2pi nN elucTeponrotheowsa l] uN_eionrwi pe tnn ropewgso Tork Lihb formrancerFloia-iCsw nfPUbb Ttenerianai icnry (sonrtarytrituerDueary Nicotnis,_onsgcu iaars odl o.c crN): 1ie4bp perastito2]u isldooitn  n Thiss:uose   Teinpe p AmitzherfsoredVX AVXFr TormlFlwit2aotimie
hw ownsnoc eozed ww ibnTro ftih -eoniatchl  otnrlhnae eAobilteirPyI c theDweap is opteimFep pAPI Deer mizedpoplroia wiNain othw bin iNateenrg Ch urla oeperatiPUtyoor instunnsee col NArrm: e tAVpXw  ucile is tiPIr flags. DaoorA
el Nenk Litwoepp optNoimriVersateiokn  buLrzaeldii bn rp wrariaeNetwotrh onrfy (onrk LeAPeDXN2N)i bto usey r 
IT ormaaDre(nctoepoyeh  n (oen foeenable thD-ellNocwDNN) to use the following Cs, PU instructions in performance-critical operitNem rrations: iing Ceural Network Library (oneDNN) to uPN csal opee the followiAe)n gt rin otheoU insVrX AbC PU instoapre ruse the folloutions:  AViXldwu tructions in performance-critical operations:  ainct TensorFlow with the aiontsi oAVnis,gn VXpApVX2
p2erf T 
oTo ereCoPU in resnXamnabltbuiance- rAopld ructbelriate compiler fVcritical Tie X2
oensloaTtonsher Fino pem  low wi in other opepthemenrgeraforsath thr.tie a
ablompe them in other operations,  pinrnost, rebrebuiauiil otnd Tenpsriceate compilehld- crr oitirTFeflacal operelor opnasgeonortirawoss:.Flo
ns:  AVXtions, rebuild TensorFlow with the appr   w wA with the appropriate compiler flags.
oVX AVX2
Tith the appropriate compiler flags.
AVX2
To enable them in other opriate compiler flags.
o enable them in other operations, rebuild TensorFlow wperations, rebuild TensorFlow with the appropriate compiler flags.
ith the appropriate compiler flags.
2023-07-28 02:31:35.094310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:31:35.099894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:31:35.100793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:31:35.102398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:31:35.115888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:31:35.131795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:31:35.142700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:31:35.154107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
Saving PPO weights in both H5 format and checkpoint @ update:1 
update:  5/2000, 耗时:0.01分/0.05分 | step:  1280 | performance: 0.5 | accuracy: 0.21 | loss: 1.43
update: 10/2000, 耗时:0.01分/0.08分 | step:  2560 | performance: 0.5 | accuracy: 0.13 | loss: 0.51
update: 15/2000, 耗时:0.01分/0.11分 | step:  3840 | performance: 0.4 | accuracy: 0.13 | loss: 0.92
update: 20/2000, 耗时:0.01分/0.14分 | step:  5120 | performance: 4.6 | accuracy: 0.23 | loss: 4.94
update: 25/2000, 耗时:0.01分/0.17分 | step:  6400 | performance: 0.4 | accuracy: 0.26 | loss: 2.34
update: 30/2000, 耗时:0.01分/0.20分 | step:  7680 | performance: 0.4 | accuracy: 0.27 | loss: 0.89
update: 35/2000, 耗时:0.01分/0.24分 | step:  8960 | performance: 0.5 | accuracy: 0.29 | loss: 2.15
update: 40/2000, 耗时:0.01分/0.27分 | step: 10240 | performance: 0.2 | accuracy: 0.27 | loss: 1.03
update: 45/2000, 耗时:0.01分/0.30分 | step: 11520 | performance: 0.5 | accuracy: 0.29 | loss: 1.30
update: 50/2000, 耗时:0.01分/0.34分 | step: 12800 | performance: 1.4 | accuracy: 0.31 | loss: 3.22
update: 55/2000, 耗时:0.01分/0.37分 | step: 14080 | performance: 297.7 | accuracy: 0.35 | loss: 5.21
update: 60/2000, 耗时:0.01分/0.40分 | step: 15360 | performance: 21466.6 | accuracy: 0.37 | loss: 3.70
update: 65/2000, 耗时:0.01分/0.44分 | step: 16640 | performance: 1156.4 | accuracy: 0.37 | loss: 0.89
update: 70/2000, 耗时:0.01分/0.47分 | step: 17920 | performance: 2931.8 | accuracy: 0.37 | loss: 1.92
update: 75/2000, 耗时:0.01分/0.51分 | step: 19200 | performance: 2965.4 | accuracy: 0.37 | loss: 2.04
update: 80/2000, 耗时:0.01分/0.54分 | step: 20480 | performance: 1147.4 | accuracy: 0.36 | loss: 0.65
update: 85/2000, 耗时:0.01分/0.58分 | step: 21760 | performance: 968.0 | accuracy: 0.35 | loss: 0.38
update: 90/2000, 耗时:0.01分/0.61分 | step: 23040 | performance: 830.4 | accuracy: 0.33 | loss: 0.19
update: 95/2000, 耗时:0.01分/0.65分 | step: 24320 | performance: 650.4 | accuracy: 0.32 | loss: 0.21
Saving PPO weights in both H5 format and checkpoint @ update:99 
update:100/2000, 耗时:0.01分/0.69分 | step: 25600 | performance: 1.0 | accuracy: 0.00 | loss: 0.33
step: 26367 | worker_6@n_step_31: average total_reward after train data exhaustion : 43.7 | max total_reward: 177.1
update:105/2000, 耗时:0.01分/0.72分 | step: 26880 | performance: 0.8 | accuracy: 0.15 | loss: 0.40
update:110/2000, 耗时:0.01分/0.76分 | step: 28160 | performance: 2.2 | accuracy: 0.17 | loss: 0.54
update:115/2000, 耗时:0.01分/0.79分 | step: 29440 | performance: 1.8 | accuracy: 0.17 | loss: 0.89
update:120/2000, 耗时:0.01分/0.83分 | step: 30720 | performance: 28.3 | accuracy: 0.26 | loss: 3.68
update:125/2000, 耗时:0.01分/0.86分 | step: 32000 | performance: 13.2 | accuracy: 0.28 | loss: 1.64
update:130/2000, 耗时:0.01分/0.90分 | step: 33280 | performance: 2.1 | accuracy: 0.27 | loss: 0.94
update:135/2000, 耗时:0.01分/0.93分 | step: 34560 | performance: 5.4 | accuracy: 0.28 | loss: 1.44
update:140/2000, 耗时:0.01分/0.96分 | step: 35840 | performance: 1.2 | accuracy: 0.28 | loss: 0.80
update:145/2000, 耗时:0.01分/0.99分 | step: 37120 | performance: 1.7 | accuracy: 0.27 | loss: 0.85
update:150/2000, 耗时:0.01分/1.03分 | step: 38400 | performance: 1.4 | accuracy: 0.28 | loss: 1.70
update:155/2000, 耗时:0.01分/1.06分 | step: 39680 | performance: 562.6 | accuracy: 0.31 | loss: 3.54
update:160/2000, 耗时:0.01分/1.09分 | step: 40960 | performance: 13255.6 | accuracy: 0.34 | loss: 3.98
update:165/2000, 耗时:0.01分/1.12分 | step: 42240 | performance: 355.8 | accuracy: 0.34 | loss: 2.35
update:170/2000, 耗时:0.01分/1.16分 | step: 43520 | performance: 2605.9 | accuracy: 0.34 | loss: 1.99
update:175/2000, 耗时:0.01分/1.19分 | step: 44800 | performance: 4337.6 | accuracy: 0.34 | loss: 1.40
update:180/2000, 耗时:0.01分/1.22分 | step: 46080 | performance: 1653.7 | accuracy: 0.34 | loss: 1.27
update:185/2000, 耗时:0.01分/1.25分 | step: 47360 | performance: 407.3 | accuracy: 0.33 | loss: 1.36
update:190/2000, 耗时:0.01分/1.28分 | step: 48640 | performance: 153.7 | accuracy: 0.33 | loss: 0.75
update:195/2000, 耗时:0.01分/1.32分 | step: 49920 | performance: 205.5 | accuracy: 0.32 | loss: 0.54
update:200/2000, 耗时:0.01分/1.35分 | step: 51200 | performance: 197.6 | accuracy: 0.32 | loss: 0.45
update:205/2000, 耗时:0.01分/1.38分 | step: 52480 | performance: 0.9 | accuracy: 0.23 | loss: 0.64
update:210/2000, 耗时:0.01分/1.41分 | step: 53760 | performance: 0.5 | accuracy: 0.20 | loss: 0.38
update:215/2000, 耗时:0.01分/1.45分 | step: 55040 | performance: 0.6 | accuracy: 0.21 | loss: 1.19
update:220/2000, 耗时:0.01分/1.48分 | step: 56320 | performance: 8.3 | accuracy: 0.27 | loss: 2.61
update:225/2000, 耗时:0.01分/1.51分 | step: 57600 | performance: 2.7 | accuracy: 0.26 | loss: 1.04
update:230/2000, 耗时:0.01分/1.54分 | step: 58880 | performance: 1.6 | accuracy: 0.25 | loss: 1.06
update:235/2000, 耗时:0.01分/1.57分 | step: 60160 | performance: 0.4 | accuracy: 0.26 | loss: 1.67
update:240/2000, 耗时:0.01分/1.61分 | step: 61440 | performance: 1.4 | accuracy: 0.27 | loss: 1.19
update:245/2000, 耗时:0.01分/1.64分 | step: 62720 | performance: 2.6 | accuracy: 0.28 | loss: 1.43
update:250/2000, 耗时:0.01分/1.67分 | step: 64000 | performance: 16.4 | accuracy: 0.31 | loss: 2.62
update:255/2000, 耗时:0.01分/1.70分 | step: 65280 | performance: 2298.7 | accuracy: 0.34 | loss: 3.64
update:260/2000, 耗时:0.01分/1.74分 | step: 66560 | performance: 31732.2 | accuracy: 0.36 | loss: 4.39
update:265/2000, 耗时:0.01分/1.77分 | step: 67840 | performance: 3612.1 | accuracy: 0.36 | loss: 1.81
update:270/2000, 耗时:0.01分/1.80分 | step: 69120 | performance: 6477.0 | accuracy: 0.36 | loss: 2.00
update:275/2000, 耗时:0.01分/1.83分 | step: 70400 | performance: 8619.3 | accuracy: 0.36 | loss: 1.87
update:280/2000, 耗时:0.01分/1.87分 | step: 71680 | performance: 1885.2 | accuracy: 0.36 | loss: 1.72
update:285/2000, 耗时:0.01分/1.90分 | step: 72960 | performance: 590.0 | accuracy: 0.36 | loss: 1.04
update:290/2000, 耗时:0.01分/1.93分 | step: 74240 | performance: 463.9 | accuracy: 0.35 | loss: 0.59
update:295/2000, 耗时:0.01分/1.97分 | step: 75520 | performance: 311.5 | accuracy: 0.35 | loss: 0.67
update:300/2000, 耗时:0.01分/2.00分 | step: 76800 | performance: 1.0 | accuracy: 0.00 | loss: 0.47
update:305/2000, 耗时:0.01分/2.03分 | step: 78080 | performance: 0.7 | accuracy: 0.23 | loss: 0.52
update:310/2000, 耗时:0.01分/2.06分 | step: 79360 | performance: 1.5 | accuracy: 0.22 | loss: 0.38
update:315/2000, 耗时:0.01分/2.09分 | step: 80640 | performance: 2.1 | accuracy: 0.22 | loss: 1.51
update:320/2000, 耗时:0.01分/2.13分 | step: 81920 | performance: 3.8 | accuracy: 0.25 | loss: 1.84
update:325/2000, 耗时:0.01分/2.16分 | step: 83200 | performance: 1.1 | accuracy: 0.24 | loss: 1.15
update:330/2000, 耗时:0.01分/2.19分 | step: 84480 | performance: 0.7 | accuracy: 0.24 | loss: 0.62
update:335/2000, 耗时:0.01分/2.22分 | step: 85760 | performance: 0.6 | accuracy: 0.24 | loss: 0.90
update:340/2000, 耗时:0.01分/2.25分 | step: 87040 | performance: 3.1 | accuracy: 0.25 | loss: 1.04
update:345/2000, 耗时:0.01分/2.29分 | step: 88320 | performance: 6.0 | accuracy: 0.26 | loss: 0.90
update:350/2000, 耗时:0.01分/2.32分 | step: 89600 | performance: 56.7 | accuracy: 0.30 | loss: 2.83
update:355/2000, 耗时:0.01分/2.35分 | step: 90880 | performance: 7236.8 | accuracy: 0.33 | loss: 4.90
update:360/2000, 耗时:0.01分/2.38分 | step: 92160 | performance: 181030.5 | accuracy: 0.35 | loss: 4.33
update:365/2000, 耗时:0.01分/2.42分 | step: 93440 | performance: 9519.7 | accuracy: 0.35 | loss: 2.33
update:370/2000, 耗时:0.01分/2.45分 | step: 94720 | performance: 18034.9 | accuracy: 0.36 | loss: 2.64
update:375/2000, 耗时:0.01分/2.48分 | step: 96000 | performance: 29913.8 | accuracy: 0.36 | loss: 2.56
update:380/2000, 耗时:0.01分/2.52分 | step: 97280 | performance: 10942.8 | accuracy: 0.35 | loss: 1.53
update:385/2000, 耗时:0.01分/2.55分 | step: 98560 | performance: 4535.8 | accuracy: 0.35 | loss: 0.65
update:390/2000, 耗时:0.01分/2.58分 | step: 99840 | performance: 7675.7 | accuracy: 0.34 | loss: 0.62
update:395/2000, 耗时:0.01分/2.61分 | step: 101120 | performance: 7896.2 | accuracy: 0.34 | loss: 0.46
update:400/2000, 耗时:0.01分/2.65分 | step: 102400 | performance: 1.0 | accuracy: 0.23 | loss: 0.31
update:405/2000, 耗时:0.01分/2.68分 | step: 103680 | performance: 1.7 | accuracy: 0.24 | loss: 0.81
update:410/2000, 耗时:0.01分/2.71分 | step: 104960 | performance: 0.8 | accuracy: 0.21 | loss: 0.35
update:415/2000, 耗时:0.01分/2.74分 | step: 106240 | performance: 1.1 | accuracy: 0.21 | loss: 2.13
update:420/2000, 耗时:0.01分/2.77分 | step: 107520 | performance: 4.2 | accuracy: 0.27 | loss: 2.11
update:425/2000, 耗时:0.01分/2.81分 | step: 108800 | performance: 1.0 | accuracy: 0.26 | loss: 1.09
update:430/2000, 耗时:0.01分/2.84分 | step: 110080 | performance: 1.0 | accuracy: 0.26 | loss: 0.72
update:435/2000, 耗时:0.01分/2.87分 | step: 111360 | performance: 0.4 | accuracy: 0.25 | loss: 0.72
update:440/2000, 耗时:0.01分/2.90分 | step: 112640 | performance: 1.3 | accuracy: 0.26 | loss: 0.68
update:445/2000, 耗时:0.01分/2.93分 | step: 113920 | performance: 0.6 | accuracy: 0.26 | loss: 0.70
update:450/2000, 耗时:0.01分/2.97分 | step: 115200 | performance: 8.5 | accuracy: 0.28 | loss: 2.14
update:455/2000, 耗时:0.01分/3.00分 | step: 116480 | performance: 7507.8 | accuracy: 0.31 | loss: 2.97
update:460/2000, 耗时:0.01分/3.03分 | step: 117760 | performance: 17235.1 | accuracy: 0.33 | loss: 2.72
update:465/2000, 耗时:0.01分/3.06分 | step: 119040 | performance: 1081.7 | accuracy: 0.33 | loss: 1.91
update:470/2000, 耗时:0.01分/3.09分 | step: 120320 | performance: 4047.3 | accuracy: 0.34 | loss: 2.58
update:475/2000, 耗时:0.01分/3.13分 | step: 121600 | performance: 469.7 | accuracy: 0.34 | loss: 2.38
update:480/2000, 耗时:0.01分/3.16分 | step: 122880 | performance: 319.3 | accuracy: 0.34 | loss: 2.09
update:485/2000, 耗时:0.01分/3.19分 | step: 124160 | performance: 95.2 | accuracy: 0.34 | loss: 1.07
update:490/2000, 耗时:0.01分/3.22分 | step: 125440 | performance: 117.5 | accuracy: 0.34 | loss: 0.65
update:495/2000, 耗时:0.01分/3.25分 | step: 126720 | performance: 45.7 | accuracy: 0.33 | loss: 0.67
update:500/2000, 耗时:0.01分/3.29分 | step: 128000 | performance: 1.3 | accuracy: 0.30 | loss: 0.59
Saving PPO weights in both H5 format and checkpoint @ update:500 
Saving PPO weights in both H5 format and checkpoint @ update:501 
update:505/2000, 耗时:0.01分/3.33分 | step: 129280 | performance: 0.4 | accuracy: 0.27 | loss: 1.28
update:510/2000, 耗时:0.01分/3.36分 | step: 130560 | performance: 0.4 | accuracy: 0.27 | loss: 0.93
update:515/2000, 耗时:0.01分/3.39分 | step: 131840 | performance: 1.7 | accuracy: 0.30 | loss: 2.35
update:520/2000, 耗时:0.01分/3.42分 | step: 133120 | performance: 2.6 | accuracy: 0.33 | loss: 2.22
update:525/2000, 耗时:0.01分/3.45分 | step: 134400 | performance: 0.7 | accuracy: 0.32 | loss: 0.81
update:530/2000, 耗时:0.01分/3.49分 | step: 135680 | performance: 0.7 | accuracy: 0.31 | loss: 1.25
update:535/2000, 耗时:0.01分/3.52分 | step: 136960 | performance: 1.0 | accuracy: 0.31 | loss: 1.22
update:540/2000, 耗时:0.01分/3.55分 | step: 138240 | performance: 1.0 | accuracy: 0.31 | loss: 0.97
update:545/2000, 耗时:0.01分/3.58分 | step: 139520 | performance: 1.1 | accuracy: 0.32 | loss: 1.74
update:550/2000, 耗时:0.01分/3.61分 | step: 140800 | performance: 120.6 | accuracy: 0.35 | loss: 3.19
update:555/2000, 耗时:0.01分/3.65分 | step: 142080 | performance: 44549.7 | accuracy: 0.38 | loss: 4.21
update:560/2000, 耗时:0.01分/3.68分 | step: 143360 | performance: 2555.6 | accuracy: 0.38 | loss: 3.74
update:565/2000, 耗时:0.01分/3.71分 | step: 144640 | performance: 8427.2 | accuracy: 0.39 | loss: 2.53
update:570/2000, 耗时:0.01分/3.74分 | step: 145920 | performance: 34852.1 | accuracy: 0.40 | loss: 2.68
update:575/2000, 耗时:0.01分/3.77分 | step: 147200 | performance: 1471.0 | accuracy: 0.39 | loss: 2.71
update:580/2000, 耗时:0.01分/3.80分 | step: 148480 | performance: 2229.0 | accuracy: 0.39 | loss: 2.15
update:585/2000, 耗时:0.01分/3.84分 | step: 149760 | performance: 266.8 | accuracy: 0.39 | loss: 1.08
update:590/2000, 耗时:0.01分/3.87分 | step: 151040 | performance: 316.9 | accuracy: 0.38 | loss: 0.78
Saving PPO weights in both H5 format and checkpoint @ update:594 
update:595/2000, 耗时:0.01分/3.90分 | step: 152320 | performance: 158.4 | accuracy: 0.38 | loss: 0.64
Saving PPO weights in both H5 format and checkpoint @ update:597 
Saving PPO weights in both H5 format and checkpoint @ update:598 
update:600/2000, 耗时:0.01分/3.94分 | step: 153600 | performance: 0.8 | accuracy: 0.35 | loss: 0.73
Saving PPO weights in both H5 format and checkpoint @ update:600 
update:605/2000, 耗时:0.01分/3.98分 | step: 154880 | performance: 2.0 | accuracy: 0.33 | loss: 1.15
update:610/2000, 耗时:0.01分/4.01分 | step: 156160 | performance: 2.1 | accuracy: 0.33 | loss: 0.81
update:615/2000, 耗时:0.01分/4.05分 | step: 157440 | performance: 69.3 | accuracy: 0.38 | loss: 3.11
update:620/2000, 耗时:0.01分/4.08分 | step: 158720 | performance: 17.1 | accuracy: 0.37 | loss: 2.13
update:625/2000, 耗时:0.01分/4.11分 | step: 160000 | performance: 16.0 | accuracy: 0.36 | loss: 0.82
update:630/2000, 耗时:0.01分/4.14分 | step: 161280 | performance: 44.3 | accuracy: 0.37 | loss: 1.36
update:635/2000, 耗时:0.01分/4.17分 | step: 162560 | performance: 849.0 | accuracy: 0.39 | loss: 1.80
update:640/2000, 耗时:0.01分/4.20分 | step: 163840 | performance: 2483.7 | accuracy: 0.39 | loss: 1.28
update:645/2000, 耗时:0.01分/4.24分 | step: 165120 | performance: 3597.1 | accuracy: 0.39 | loss: 1.49
update:650/2000, 耗时:0.01分/4.27分 | step: 166400 | performance: 10446655.9 | accuracy: 0.43 | loss: 3.61
update:655/2000, 耗时:0.01分/4.30分 | step: 167680 | performance: 97556430.1 | accuracy: 0.44 | loss: 4.84
update:660/2000, 耗时:0.01分/4.33分 | step: 168960 | performance: 7408963.4 | accuracy: 0.44 | loss: 3.05
update:665/2000, 耗时:0.01分/4.36分 | step: 170240 | performance: 45845411.2 | accuracy: 0.45 | loss: 2.64
update:670/2000, 耗时:0.01分/4.40分 | step: 171520 | performance: 79180241.8 | accuracy: 0.45 | loss: 3.03
update:675/2000, 耗时:0.01分/4.43分 | step: 172800 | performance: 8932826.3 | accuracy: 0.44 | loss: 2.75
update:680/2000, 耗时:0.01分/4.46分 | step: 174080 | performance: 4244412.6 | accuracy: 0.44 | loss: 2.06
update:685/2000, 耗时:0.01分/4.49分 | step: 175360 | performance: 128553.0 | accuracy: 0.44 | loss: 1.36
update:690/2000, 耗时:0.01分/4.53分 | step: 176640 | performance: 64190.3 | accuracy: 0.43 | loss: 1.02
Saving PPO weights in both H5 format and checkpoint @ update:692 
update:695/2000, 耗时:0.01分/4.56分 | step: 177920 | performance: 42545.8 | accuracy: 0.42 | loss: 0.88
Saving PPO weights in both H5 format and checkpoint @ update:696 
Saving PPO weights in both H5 format and checkpoint @ update:697 
Saving PPO weights in both H5 format and checkpoint @ update:699 
update:700/2000, 耗时:0.01分/4.61分 | step: 179200 | performance: 0.5 | accuracy: 0.36 | loss: 1.04
update:705/2000, 耗时:0.01分/4.64分 | step: 180480 | performance: 2.6 | accuracy: 0.37 | loss: 1.05
update:710/2000, 耗时:0.01分/4.67分 | step: 181760 | performance: 1.0 | accuracy: 0.38 | loss: 1.26
update:715/2000, 耗时:0.01分/4.70分 | step: 183040 | performance: 15.4 | accuracy: 0.43 | loss: 3.50
update:720/2000, 耗时:0.01分/4.74分 | step: 184320 | performance: 4.9 | accuracy: 0.42 | loss: 3.09
update:725/2000, 耗时:0.01分/4.77分 | step: 185600 | performance: 2.7 | accuracy: 0.41 | loss: 1.90
update:730/2000, 耗时:0.01分/4.79分 | step: 186880 | performance: 1.0 | accuracy: 0.42 | loss: 2.37
update:735/2000, 耗时:0.01分/4.82分 | step: 188160 | performance: 4.2 | accuracy: 0.43 | loss: 2.41
update:740/2000, 耗时:0.01分/4.85分 | step: 189440 | performance: 9.8 | accuracy: 0.43 | loss: 1.52
update:745/2000, 耗时:0.01分/4.88分 | step: 190720 | performance: 49.7 | accuracy: 0.45 | loss: 2.87
update:750/2000, 耗时:0.01分/4.91分 | step: 192000 | performance: 6141.6 | accuracy: 0.47 | loss: 3.93
update:755/2000, 耗时:0.01分/4.94分 | step: 193280 | performance: 448143.2 | accuracy: 0.49 | loss: 4.48
update:760/2000, 耗时:0.01分/4.97分 | step: 194560 | performance: 4932.8 | accuracy: 0.48 | loss: 3.33
update:765/2000, 耗时:0.01分/5.01分 | step: 195840 | performance: 9896.5 | accuracy: 0.48 | loss: 2.99
update:770/2000, 耗时:0.01分/5.04分 | step: 197120 | performance: 11570.4 | accuracy: 0.48 | loss: 3.11
update:775/2000, 耗时:0.01分/5.07分 | step: 198400 | performance: 4702.1 | accuracy: 0.47 | loss: 2.72
update:780/2000, 耗时:0.01分/5.10分 | step: 199680 | performance: 321.3 | accuracy: 0.46 | loss: 1.96
update:785/2000, 耗时:0.01分/5.13分 | step: 200960 | performance: 344.8 | accuracy: 0.46 | loss: 0.95
update:790/2000, 耗时:0.01分/5.17分 | step: 202240 | performance: 277.1 | accuracy: 0.45 | loss: 0.73
Saving PPO weights in both H5 format and checkpoint @ update:792 
update:795/2000, 耗时:0.01分/5.20分 | step: 203520 | performance: 0.7 | accuracy: 0.33 | loss: 0.59
Saving PPO weights in both H5 format and checkpoint @ update:795 
update:800/2000, 耗时:0.01分/5.24分 | step: 204800 | performance: 6.4 | accuracy: 0.37 | loss: 1.34
update:805/2000, 耗时:0.01分/5.27分 | step: 206080 | performance: 4.2 | accuracy: 0.35 | loss: 1.44
update:810/2000, 耗时:0.01分/5.30分 | step: 207360 | performance: 3.4 | accuracy: 0.33 | loss: 2.14
update:815/2000, 耗时:0.01分/5.34分 | step: 208640 | performance: 11.0 | accuracy: 0.38 | loss: 2.69
update:820/2000, 耗时:0.01分/5.37分 | step: 209920 | performance: 1.5 | accuracy: 0.37 | loss: 1.52
update:825/2000, 耗时:0.01分/5.40分 | step: 211200 | performance: 1.2 | accuracy: 0.36 | loss: 1.10
update:830/2000, 耗时:0.01分/5.43分 | step: 212480 | performance: 0.6 | accuracy: 0.36 | loss: 1.47
update:835/2000, 耗时:0.01分/5.46分 | step: 213760 | performance: 0.6 | accuracy: 0.36 | loss: 1.09
update:840/2000, 耗时:0.01分/5.50分 | step: 215040 | performance: 1.0 | accuracy: 0.36 | loss: 1.54
update:845/2000, 耗时:0.01分/5.53分 | step: 216320 | performance: 43.2 | accuracy: 0.40 | loss: 2.91
update:850/2000, 耗时:0.01分/5.56分 | step: 217600 | performance: 25204.2 | accuracy: 0.43 | loss: 3.59
update:855/2000, 耗时:0.01分/5.60分 | step: 218880 | performance: 77168.8 | accuracy: 0.44 | loss: 4.98
update:860/2000, 耗时:0.01分/5.63分 | step: 220160 | performance: 2878.2 | accuracy: 0.43 | loss: 2.47
update:865/2000, 耗时:0.01分/5.66分 | step: 221440 | performance: 38851.6 | accuracy: 0.44 | loss: 2.67
update:870/2000, 耗时:0.01分/5.69分 | step: 222720 | performance: 12158.1 | accuracy: 0.43 | loss: 2.45
update:875/2000, 耗时:0.01分/5.73分 | step: 224000 | performance: 4347.1 | accuracy: 0.43 | loss: 2.32
update:880/2000, 耗时:0.01分/5.76分 | step: 225280 | performance: 968.7 | accuracy: 0.43 | loss: 0.97
update:885/2000, 耗时:0.01分/5.79分 | step: 226560 | performance: 280.4 | accuracy: 0.42 | loss: 0.80
update:890/2000, 耗时:0.01分/5.82分 | step: 227840 | performance: 256.8 | accuracy: 0.42 | loss: 0.71
step: 228608 | worker_7@n_step_31: average total_reward after train data exhaustion : 134.4 | max total_reward: 331.1
Saving PPO weights in both H5 format and checkpoint @ update:894 
update:895/2000, 耗时:0.01分/5.86分 | step: 229120 | performance: 1.0 | accuracy: 0.33 | loss: 0.72
Saving PPO weights in both H5 format and checkpoint @ update:895 
Saving PPO weights in both H5 format and checkpoint @ update:897 
update:900/2000, 耗时:0.01分/5.90分 | step: 230400 | performance: 2.0 | accuracy: 0.30 | loss: 0.70
update:905/2000, 耗时:0.01分/5.93分 | step: 231680 | performance: 2.5 | accuracy: 0.28 | loss: 0.69
update:910/2000, 耗时:0.01分/5.97分 | step: 232960 | performance: 12.4 | accuracy: 0.30 | loss: 1.96
update:915/2000, 耗时:0.01分/6.00分 | step: 234240 | performance: 33.2 | accuracy: 0.33 | loss: 2.35
update:920/2000, 耗时:0.01分/6.03分 | step: 235520 | performance: 16.2 | accuracy: 0.32 | loss: 0.98
update:925/2000, 耗时:0.01分/6.06分 | step: 236800 | performance: 35.2 | accuracy: 0.33 | loss: 1.11
update:930/2000, 耗时:0.01分/6.09分 | step: 238080 | performance: 12.4 | accuracy: 0.33 | loss: 1.78
update:935/2000, 耗时:0.01分/6.13分 | step: 239360 | performance: 27.4 | accuracy: 0.34 | loss: 2.15
update:940/2000, 耗时:0.01分/6.16分 | step: 240640 | performance: 58.6 | accuracy: 0.36 | loss: 2.19
update:945/2000, 耗时:0.01分/6.19分 | step: 241920 | performance: 2580.2 | accuracy: 0.39 | loss: 2.93
update:950/2000, 耗时:0.01分/6.22分 | step: 243200 | performance: 728108.9 | accuracy: 0.42 | loss: 4.47
update:955/2000, 耗时:0.01分/6.25分 | step: 244480 | performance: 68697.0 | accuracy: 0.42 | loss: 4.48
update:960/2000, 耗时:0.01分/6.29分 | step: 245760 | performance: 203815.1 | accuracy: 0.42 | loss: 3.14
update:965/2000, 耗时:0.01分/6.32分 | step: 247040 | performance: 840629.0 | accuracy: 0.43 | loss: 3.03
update:970/2000, 耗时:0.01分/6.35分 | step: 248320 | performance: 57211.1 | accuracy: 0.42 | loss: 2.33
update:975/2000, 耗时:0.01分/6.38分 | step: 249600 | performance: 36206.5 | accuracy: 0.42 | loss: 2.04
update:980/2000, 耗时:0.01分/6.41分 | step: 250880 | performance: 901.5 | accuracy: 0.41 | loss: 1.57
update:985/2000, 耗时:0.01分/6.45分 | step: 252160 | performance: 144.3 | accuracy: 0.40 | loss: 1.01
Saving PPO weights in both H5 format and checkpoint @ update:989 
update:990/2000, 耗时:0.01分/6.49分 | step: 253440 | performance: 59.4 | accuracy: 0.39 | loss: 0.71
Saving PPO weights in both H5 format and checkpoint @ update:990 
Saving PPO weights in both H5 format and checkpoint @ update:991 
step: 253945 | worker_0@n_step_31: average total_reward after train data exhaustion : 152.7 | max total_reward: 349.9
Saving PPO weights in both H5 format and checkpoint @ update:994 
update:995/2000, 耗时:0.01分/6.53分 | step: 254720 | performance: 1.0 | accuracy: 0.24 | loss: 0.66
Saving PPO weights in both H5 format and checkpoint @ update:995 
update:1000/2000, 耗时:0.01分/6.57分 | step: 256000 | performance: 1.9 | accuracy: 0.26 | loss: 0.64
update:1005/2000, 耗时:0.01分/6.61分 | step: 257280 | performance: 1.8 | accuracy: 0.26 | loss: 0.74
update:1010/2000, 耗时:0.01分/6.64分 | step: 258560 | performance: 13.5 | accuracy: 0.30 | loss: 2.16
update:1015/2000, 耗时:0.01分/6.68分 | step: 259840 | performance: 12.9 | accuracy: 0.31 | loss: 2.15
update:1020/2000, 耗时:0.01分/6.71分 | step: 261120 | performance: 8.1 | accuracy: 0.31 | loss: 1.08
update:1025/2000, 耗时:0.01分/6.75分 | step: 262400 | performance: 33.1 | accuracy: 0.32 | loss: 1.01
update:1030/2000, 耗时:0.01分/6.78分 | step: 263680 | performance: 30.3 | accuracy: 0.33 | loss: 1.63
update:1035/2000, 耗时:0.01分/6.81分 | step: 264960 | performance: 25.1 | accuracy: 0.33 | loss: 1.55
update:1040/2000, 耗时:0.01分/6.85分 | step: 266240 | performance: 82.5 | accuracy: 0.35 | loss: 1.67
update:1045/2000, 耗时:0.01分/6.88分 | step: 267520 | performance: 45523.1 | accuracy: 0.39 | loss: 3.43
update:1050/2000, 耗时:0.01分/6.91分 | step: 268800 | performance: 1652839.6 | accuracy: 0.41 | loss: 4.44
update:1055/2000, 耗时:0.01分/6.94分 | step: 270080 | performance: 52821.9 | accuracy: 0.41 | loss: 3.04
update:1060/2000, 耗时:0.01分/6.97分 | step: 271360 | performance: 279625.4 | accuracy: 0.41 | loss: 2.64
update:1065/2000, 耗时:0.01分/7.00分 | step: 272640 | performance: 1186463.1 | accuracy: 0.42 | loss: 2.70
update:1070/2000, 耗时:0.01分/7.04分 | step: 273920 | performance: 135610.8 | accuracy: 0.42 | loss: 2.69
update:1075/2000, 耗时:0.01分/7.07分 | step: 275200 | performance: 105056.3 | accuracy: 0.42 | loss: 1.72
update:1080/2000, 耗时:0.01分/7.10分 | step: 276480 | performance: 65194.8 | accuracy: 0.41 | loss: 0.76
update:1085/2000, 耗时:0.01分/7.13分 | step: 277760 | performance: 120238.4 | accuracy: 0.41 | loss: 0.59
Saving PPO weights in both H5 format and checkpoint @ update:1088 
step: 278778 | worker_1@n_step_31: average total_reward after train data exhaustion : 173.0 | max total_reward: 349.9
Saving PPO weights in both H5 format and checkpoint @ update:1089 
update:1090/2000, 耗时:0.01分/7.17分 | step: 279040 | performance: 145101.1 | accuracy: 0.41 | loss: 0.73
Saving PPO weights in both H5 format and checkpoint @ update:1090 
Saving PPO weights in both H5 format and checkpoint @ update:1091 
Saving PPO weights in both H5 format and checkpoint @ update:1093 
Saving PPO weights in both H5 format and checkpoint @ update:1094 
update:1095/2000, 耗时:0.01分/7.22分 | step: 280320 | performance: 0.9 | accuracy: 0.30 | loss: 1.07
update:1100/2000, 耗时:0.01分/7.26分 | step: 281600 | performance: 2.4 | accuracy: 0.33 | loss: 1.26
update:1105/2000, 耗时:0.01分/7.29分 | step: 282880 | performance: 0.6 | accuracy: 0.30 | loss: 1.16
update:1110/2000, 耗时:0.01分/7.32分 | step: 284160 | performance: 3.6 | accuracy: 0.34 | loss: 2.69
update:1115/2000, 耗时:0.01分/7.35分 | step: 285440 | performance: 0.3 | accuracy: 0.33 | loss: 1.35
update:1120/2000, 耗时:0.01分/7.38分 | step: 286720 | performance: 0.1 | accuracy: 0.33 | loss: 0.89
update:1125/2000, 耗时:0.01分/7.42分 | step: 288000 | performance: 0.3 | accuracy: 0.34 | loss: 1.16
update:1130/2000, 耗时:0.01分/7.45分 | step: 289280 | performance: 0.9 | accuracy: 0.35 | loss: 1.23
update:1135/2000, 耗时:0.01分/7.48分 | step: 290560 | performance: 4.2 | accuracy: 0.36 | loss: 1.40
update:1140/2000, 耗时:0.01分/7.51分 | step: 291840 | performance: 7.6 | accuracy: 0.38 | loss: 2.70
update:1145/2000, 耗时:0.01分/7.54分 | step: 293120 | performance: 2664.5 | accuracy: 0.41 | loss: 3.82
update:1150/2000, 耗时:0.01分/7.57分 | step: 294400 | performance: 92403.8 | accuracy: 0.42 | loss: 3.98
update:1155/2000, 耗时:0.01分/7.60分 | step: 295680 | performance: 1884.1 | accuracy: 0.42 | loss: 3.19
update:1160/2000, 耗时:0.01分/7.63分 | step: 296960 | performance: 10542.4 | accuracy: 0.43 | loss: 3.05
update:1165/2000, 耗时:0.01分/7.67分 | step: 298240 | performance: 14700.1 | accuracy: 0.43 | loss: 3.29
update:1170/2000, 耗时:0.01分/7.70分 | step: 299520 | performance: 2476.0 | accuracy: 0.43 | loss: 3.02
update:1175/2000, 耗时:0.01分/7.73分 | step: 300800 | performance: 692.1 | accuracy: 0.43 | loss: 2.90
update:1180/2000, 耗时:0.01分/7.76分 | step: 302080 | performance: 263.3 | accuracy: 0.43 | loss: 1.53
update:1185/2000, 耗时:0.01分/7.79分 | step: 303360 | performance: 81.3 | accuracy: 0.42 | loss: 0.85
update:1190/2000, 耗时:0.01分/7.83分 | step: 304640 | performance: 0.9 | accuracy: 0.20 | loss: 0.85
update:1195/2000, 耗时:0.01分/7.86分 | step: 305920 | performance: 2.7 | accuracy: 0.28 | loss: 0.94
update:1200/2000, 耗时:0.01分/7.89分 | step: 307200 | performance: 3.8 | accuracy: 0.30 | loss: 0.95
update:1205/2000, 耗时:0.01分/7.92分 | step: 308480 | performance: 9.3 | accuracy: 0.34 | loss: 1.69
update:1210/2000, 耗时:0.01分/7.95分 | step: 309760 | performance: 119.8 | accuracy: 0.37 | loss: 2.86
update:1215/2000, 耗时:0.01分/7.99分 | step: 311040 | performance: 53.8 | accuracy: 0.36 | loss: 1.33
update:1220/2000, 耗时:0.01分/8.02分 | step: 312320 | performance: 41.9 | accuracy: 0.34 | loss: 0.62
update:1225/2000, 耗时:0.01分/8.05分 | step: 313600 | performance: 176.3 | accuracy: 0.34 | loss: 1.87
update:1230/2000, 耗时:0.01分/8.08分 | step: 314880 | performance: 441.6 | accuracy: 0.35 | loss: 1.22
update:1235/2000, 耗时:0.01分/8.11分 | step: 316160 | performance: 989.3 | accuracy: 0.36 | loss: 1.31
update:1240/2000, 耗时:0.01分/8.14分 | step: 317440 | performance: 21853.4 | accuracy: 0.39 | loss: 3.11
update:1245/2000, 耗时:0.01分/8.18分 | step: 318720 | performance: 4777556.9 | accuracy: 0.42 | loss: 3.62
update:1250/2000, 耗时:0.01分/8.21分 | step: 320000 | performance: 24754779.4 | accuracy: 0.43 | loss: 4.68
update:1255/2000, 耗时:0.01分/8.24分 | step: 321280 | performance: 786048.1 | accuracy: 0.42 | loss: 3.24
update:1260/2000, 耗时:0.01分/8.28分 | step: 322560 | performance: 12700244.3 | accuracy: 0.43 | loss: 3.02
update:1265/2000, 耗时:0.01分/8.31分 | step: 323840 | performance: 6339737.7 | accuracy: 0.43 | loss: 2.74
update:1270/2000, 耗时:0.01分/8.34分 | step: 325120 | performance: 974722.1 | accuracy: 0.43 | loss: 3.15
update:1275/2000, 耗时:0.01分/8.37分 | step: 326400 | performance: 332043.8 | accuracy: 0.43 | loss: 1.89
update:1280/2000, 耗时:0.01分/8.40分 | step: 327680 | performance: 16914.8 | accuracy: 0.42 | loss: 0.96
update:1285/2000, 耗时:0.01分/8.44分 | step: 328960 | performance: 54950.7 | accuracy: 0.42 | loss: 0.80
update:1290/2000, 耗时:0.01分/8.47分 | step: 330240 | performance: 0.6 | accuracy: 0.19 | loss: 0.54
update:1295/2000, 耗时:0.01分/8.50分 | step: 331520 | performance: 1.7 | accuracy: 0.28 | loss: 0.80
update:1300/2000, 耗时:0.01分/8.53分 | step: 332800 | performance: 1.0 | accuracy: 0.26 | loss: 0.86
update:1305/2000, 耗时:0.01分/8.57分 | step: 334080 | performance: 0.6 | accuracy: 0.25 | loss: 2.68
update:1310/2000, 耗时:0.01分/8.60分 | step: 335360 | performance: 1.5 | accuracy: 0.30 | loss: 2.68
update:1315/2000, 耗时:0.01分/8.63分 | step: 336640 | performance: 0.3 | accuracy: 0.30 | loss: 1.10
update:1320/2000, 耗时:0.01分/8.66分 | step: 337920 | performance: 0.3 | accuracy: 0.30 | loss: 1.08
update:1325/2000, 耗时:0.01分/8.70分 | step: 339200 | performance: 0.8 | accuracy: 0.30 | loss: 0.90
update:1330/2000, 耗时:0.01分/8.73分 | step: 340480 | performance: 1.1 | accuracy: 0.30 | loss: 1.12
update:1335/2000, 耗时:0.01分/8.76分 | step: 341760 | performance: 1.6 | accuracy: 0.30 | loss: 0.98
update:1340/2000, 耗时:0.01分/8.79分 | step: 343040 | performance: 41.5 | accuracy: 0.33 | loss: 2.96
update:1345/2000, 耗时:0.01分/8.83分 | step: 344320 | performance: 10674.4 | accuracy: 0.36 | loss: 4.03
update:1350/2000, 耗时:0.01分/8.86分 | step: 345600 | performance: 7771.9 | accuracy: 0.37 | loss: 3.48
update:1355/2000, 耗时:0.01分/8.89分 | step: 346880 | performance: 4768.0 | accuracy: 0.37 | loss: 2.58
update:1360/2000, 耗时:0.01分/8.92分 | step: 348160 | performance: 54413.5 | accuracy: 0.39 | loss: 3.06
update:1365/2000, 耗时:0.01分/8.95分 | step: 349440 | performance: 5425.5 | accuracy: 0.38 | loss: 3.01
update:1370/2000, 耗时:0.01分/8.99分 | step: 350720 | performance: 6614.5 | accuracy: 0.39 | loss: 1.77
update:1375/2000, 耗时:0.01分/9.02分 | step: 352000 | performance: 758.9 | accuracy: 0.38 | loss: 0.71
update:1380/2000, 耗时:0.01分/9.05分 | step: 353280 | performance: 903.4 | accuracy: 0.37 | loss: 0.52
update:1385/2000, 耗时:0.01分/9.08分 | step: 354560 | performance: 801.8 | accuracy: 0.36 | loss: 0.45
update:1390/2000, 耗时:0.01分/9.11分 | step: 355840 | performance: 1.3 | accuracy: 0.24 | loss: 0.49
update:1395/2000, 耗时:0.01分/9.14分 | step: 357120 | performance: 7.7 | accuracy: 0.30 | loss: 1.29
update:1400/2000, 耗时:0.01分/9.17分 | step: 358400 | performance: 5.2 | accuracy: 0.30 | loss: 0.75
update:1405/2000, 耗时:0.01分/9.21分 | step: 359680 | performance: 5.5 | accuracy: 0.29 | loss: 1.96
update:1410/2000, 耗时:0.01分/9.24分 | step: 360960 | performance: 5.4 | accuracy: 0.31 | loss: 1.34
update:1415/2000, 耗时:0.01分/9.27分 | step: 362240 | performance: 5.0 | accuracy: 0.31 | loss: 0.73
update:1420/2000, 耗时:0.01分/9.30分 | step: 363520 | performance: 9.3 | accuracy: 0.31 | loss: 0.66
update:1425/2000, 耗时:0.01分/9.34分 | step: 364800 | performance: 3.9 | accuracy: 0.29 | loss: 0.77
update:1430/2000, 耗时:0.01分/9.37分 | step: 366080 | performance: 4.0 | accuracy: 0.29 | loss: 0.62
update:1435/2000, 耗时:0.01分/9.40分 | step: 367360 | performance: 4.6 | accuracy: 0.30 | loss: 1.09
update:1440/2000, 耗时:0.01分/9.44分 | step: 368640 | performance: 710.8 | accuracy: 0.33 | loss: 3.11
update:1445/2000, 耗时:0.01分/9.47分 | step: 369920 | performance: 106593.6 | accuracy: 0.36 | loss: 3.56
update:1450/2000, 耗时:0.01分/9.50分 | step: 371200 | performance: 6024.3 | accuracy: 0.36 | loss: 3.52
update:1455/2000, 耗时:0.01分/9.53分 | step: 372480 | performance: 11042.5 | accuracy: 0.36 | loss: 1.98
update:1460/2000, 耗时:0.01分/9.56分 | step: 373760 | performance: 27010.9 | accuracy: 0.37 | loss: 2.64
update:1465/2000, 耗时:0.01分/9.60分 | step: 375040 | performance: 628.2 | accuracy: 0.37 | loss: 2.41
update:1470/2000, 耗时:0.01分/9.63分 | step: 376320 | performance: 764.5 | accuracy: 0.37 | loss: 1.28
update:1475/2000, 耗时:0.01分/9.66分 | step: 377600 | performance: 98.3 | accuracy: 0.35 | loss: 0.68
update:1480/2000, 耗时:0.01分/9.69分 | step: 378880 | performance: 138.6 | accuracy: 0.35 | loss: 0.33
update:1485/2000, 耗时:0.01分/9.72分 | step: 380160 | performance: 141.7 | accuracy: 0.34 | loss: 0.40
update:1490/2000, 耗时:0.01分/9.75分 | step: 381440 | performance: 0.7 | accuracy: 0.16 | loss: 0.29
update:1495/2000, 耗时:0.01分/9.78分 | step: 382720 | performance: 3.6 | accuracy: 0.24 | loss: 0.94
update:1500/2000, 耗时:0.01分/9.82分 | step: 384000 | performance: 1.5 | accuracy: 0.22 | loss: 0.77
update:1505/2000, 耗时:0.01分/9.85分 | step: 385280 | performance: 7.9 | accuracy: 0.24 | loss: 1.98
update:1510/2000, 耗时:0.01分/9.88分 | step: 386560 | performance: 1.7 | accuracy: 0.24 | loss: 0.93
update:1515/2000, 耗时:0.01分/9.91分 | step: 387840 | performance: 0.8 | accuracy: 0.24 | loss: 0.49
update:1520/2000, 耗时:0.01分/9.94分 | step: 389120 | performance: 0.9 | accuracy: 0.24 | loss: 0.79
update:1525/2000, 耗时:0.01分/9.98分 | step: 390400 | performance: 9.8 | accuracy: 0.24 | loss: 0.78
update:1530/2000, 耗时:0.01分/10.01分 | step: 391680 | performance: 11.8 | accuracy: 0.25 | loss: 1.13
update:1535/2000, 耗时:0.01分/10.04分 | step: 392960 | performance: 24.2 | accuracy: 0.28 | loss: 2.52
update:1540/2000, 耗时:0.01分/10.07分 | step: 394240 | performance: 14835.6 | accuracy: 0.31 | loss: 3.59
update:1545/2000, 耗时:0.01分/10.10分 | step: 395520 | performance: 367217.1 | accuracy: 0.34 | loss: 5.32
update:1550/2000, 耗时:0.01分/10.13分 | step: 396800 | performance: 12334.3 | accuracy: 0.35 | loss: 4.62
update:1555/2000, 耗时:0.01分/10.17分 | step: 398080 | performance: 87093.9 | accuracy: 0.36 | loss: 3.29
update:1560/2000, 耗时:0.01分/10.20分 | step: 399360 | performance: 278991.8 | accuracy: 0.37 | loss: 3.06
update:1565/2000, 耗时:0.01分/10.23分 | step: 400640 | performance: 26084.2 | accuracy: 0.37 | loss: 3.51
update:1570/2000, 耗时:0.01分/10.26分 | step: 401920 | performance: 6570.0 | accuracy: 0.37 | loss: 2.87
update:1575/2000, 耗时:0.01分/10.30分 | step: 403200 | performance: 1277.7 | accuracy: 0.37 | loss: 1.61
update:1580/2000, 耗时:0.01分/10.33分 | step: 404480 | performance: 1305.8 | accuracy: 0.37 | loss: 0.92
update:1585/2000, 耗时:0.01分/10.36分 | step: 405760 | performance: 1.0 | accuracy: 0.33 | loss: 0.71
update:1590/2000, 耗时:0.01分/10.39分 | step: 407040 | performance: 0.6 | accuracy: 0.27 | loss: 0.83
update:1595/2000, 耗时:0.01分/10.42分 | step: 408320 | performance: 0.3 | accuracy: 0.28 | loss: 0.76
update:1600/2000, 耗时:0.01分/10.46分 | step: 409600 | performance: 0.2 | accuracy: 0.29 | loss: 1.23
update:1605/2000, 耗时:0.01分/10.49分 | step: 410880 | performance: 1.4 | accuracy: 0.33 | loss: 2.86
update:1610/2000, 耗时:0.01分/10.52分 | step: 412160 | performance: 0.3 | accuracy: 0.33 | loss: 2.24
update:1615/2000, 耗时:0.01分/10.55分 | step: 413440 | performance: 0.2 | accuracy: 0.34 | loss: 1.64
update:1620/2000, 耗时:0.01分/10.59分 | step: 414720 | performance: 0.1 | accuracy: 0.34 | loss: 1.91
update:1625/2000, 耗时:0.01分/10.62分 | step: 416000 | performance: 0.4 | accuracy: 0.35 | loss: 2.24
update:1630/2000, 耗时:0.01分/10.65分 | step: 417280 | performance: 1.2 | accuracy: 0.36 | loss: 2.10
update:1635/2000, 耗时:0.01分/10.68分 | step: 418560 | performance: 11.6 | accuracy: 0.39 | loss: 2.47
update:1640/2000, 耗时:0.01分/10.72分 | step: 419840 | performance: 1710.3 | accuracy: 0.42 | loss: 3.82
update:1645/2000, 耗时:0.01分/10.75分 | step: 421120 | performance: 25123.3 | accuracy: 0.43 | loss: 5.68
update:1650/2000, 耗时:0.01分/10.78分 | step: 422400 | performance: 821.2 | accuracy: 0.43 | loss: 3.49
update:1655/2000, 耗时:0.01分/10.81分 | step: 423680 | performance: 3147.9 | accuracy: 0.43 | loss: 2.49
update:1660/2000, 耗时:0.01分/10.84分 | step: 424960 | performance: 4844.2 | accuracy: 0.43 | loss: 2.68
update:1665/2000, 耗时:0.01分/10.88分 | step: 426240 | performance: 1919.8 | accuracy: 0.43 | loss: 2.74
update:1670/2000, 耗时:0.01分/10.91分 | step: 427520 | performance: 197.7 | accuracy: 0.43 | loss: 2.87
update:1675/2000, 耗时:0.01分/10.94分 | step: 428800 | performance: 94.2 | accuracy: 0.43 | loss: 1.87
update:1680/2000, 耗时:0.01分/10.97分 | step: 430080 | performance: 16.8 | accuracy: 0.42 | loss: 0.88
update:1685/2000, 耗时:0.01分/11.00分 | step: 431360 | performance: 0.7 | accuracy: 0.30 | loss: 0.73
update:1690/2000, 耗时:0.01分/11.04分 | step: 432640 | performance: 1.1 | accuracy: 0.25 | loss: 0.59
update:1695/2000, 耗时:0.01分/11.07分 | step: 433920 | performance: 1.1 | accuracy: 0.25 | loss: 0.61
update:1700/2000, 耗时:0.01分/11.10分 | step: 435200 | performance: 2.1 | accuracy: 0.27 | loss: 1.33
update:1705/2000, 耗时:0.01分/11.13分 | step: 436480 | performance: 29.4 | accuracy: 0.30 | loss: 1.86
update:1710/2000, 耗时:0.01分/11.16分 | step: 437760 | performance: 17.7 | accuracy: 0.31 | loss: 1.58
update:1715/2000, 耗时:0.01分/11.19分 | step: 439040 | performance: 32.4 | accuracy: 0.31 | loss: 0.71
update:1720/2000, 耗时:0.01分/11.22分 | step: 440320 | performance: 9.9 | accuracy: 0.30 | loss: 0.98
update:1725/2000, 耗时:0.01分/11.26分 | step: 441600 | performance: 15.1 | accuracy: 0.31 | loss: 1.40
update:1730/2000, 耗时:0.01分/11.29分 | step: 442880 | performance: 14.4 | accuracy: 0.32 | loss: 1.74
update:1735/2000, 耗时:0.01分/11.32分 | step: 444160 | performance: 547.0 | accuracy: 0.35 | loss: 3.34
update:1740/2000, 耗时:0.01分/11.35分 | step: 445440 | performance: 161885.2 | accuracy: 0.38 | loss: 3.82
update:1745/2000, 耗时:0.01分/11.38分 | step: 446720 | performance: 482433.6 | accuracy: 0.39 | loss: 4.10
update:1750/2000, 耗时:0.01分/11.42分 | step: 448000 | performance: 9034.6 | accuracy: 0.39 | loss: 2.14
update:1755/2000, 耗时:0.01分/11.45分 | step: 449280 | performance: 394394.2 | accuracy: 0.40 | loss: 2.55
update:1760/2000, 耗时:0.01分/11.48分 | step: 450560 | performance: 192571.1 | accuracy: 0.40 | loss: 3.02
update:1765/2000, 耗时:0.01分/11.51分 | step: 451840 | performance: 61873.8 | accuracy: 0.40 | loss: 2.56
update:1770/2000, 耗时:0.01分/11.55分 | step: 453120 | performance: 13100.4 | accuracy: 0.40 | loss: 1.32
update:1775/2000, 耗时:0.01分/11.58分 | step: 454400 | performance: 8066.6 | accuracy: 0.39 | loss: 0.72
update:1780/2000, 耗时:0.01分/11.61分 | step: 455680 | performance: 7354.6 | accuracy: 0.39 | loss: 0.58
update:1785/2000, 耗时:0.01分/11.64分 | step: 456960 | performance: 1.2 | accuracy: 0.30 | loss: 0.55
update:1790/2000, 耗时:0.01分/11.68分 | step: 458240 | performance: 1.9 | accuracy: 0.29 | loss: 0.88
update:1795/2000, 耗时:0.01分/11.71分 | step: 459520 | performance: 2.6 | accuracy: 0.28 | loss: 0.71
update:1800/2000, 耗时:0.01分/11.74分 | step: 460800 | performance: 6.6 | accuracy: 0.28 | loss: 2.20
update:1805/2000, 耗时:0.01分/11.77分 | step: 462080 | performance: 49.8 | accuracy: 0.32 | loss: 1.28
update:1810/2000, 耗时:0.01分/11.81分 | step: 463360 | performance: 25.1 | accuracy: 0.31 | loss: 0.87
update:1815/2000, 耗时:0.01分/11.84分 | step: 464640 | performance: 27.7 | accuracy: 0.30 | loss: 0.71
update:1820/2000, 耗时:0.01分/11.87分 | step: 465920 | performance: 21.0 | accuracy: 0.29 | loss: 0.91
update:1825/2000, 耗时:0.01分/11.90分 | step: 467200 | performance: 72.3 | accuracy: 0.30 | loss: 0.98
update:1830/2000, 耗时:0.01分/11.94分 | step: 468480 | performance: 117.1 | accuracy: 0.31 | loss: 2.01
update:1835/2000, 耗时:0.01分/11.97分 | step: 469760 | performance: 4012.5 | accuracy: 0.35 | loss: 3.42
update:1840/2000, 耗时:0.01分/12.00分 | step: 471040 | performance: 3135797.1 | accuracy: 0.38 | loss: 3.54
update:1845/2000, 耗时:0.01分/12.03分 | step: 472320 | performance: 708863.6 | accuracy: 0.39 | loss: 4.39
update:1850/2000, 耗时:0.01分/12.06分 | step: 473600 | performance: 1208858.3 | accuracy: 0.39 | loss: 3.33
update:1855/2000, 耗时:0.01分/12.10分 | step: 474880 | performance: 6458611.3 | accuracy: 0.40 | loss: 3.47
update:1860/2000, 耗时:0.01分/12.13分 | step: 476160 | performance: 827245.8 | accuracy: 0.40 | loss: 2.96
update:1865/2000, 耗时:0.01分/12.16分 | step: 477440 | performance: 1559437.2 | accuracy: 0.41 | loss: 3.03
update:1870/2000, 耗时:0.01分/12.20分 | step: 478720 | performance: 16069.4 | accuracy: 0.41 | loss: 3.17
update:1875/2000, 耗时:0.01分/12.23分 | step: 480000 | performance: 11627.4 | accuracy: 0.41 | loss: 2.31
update:1880/2000, 耗时:0.01分/12.26分 | step: 481280 | performance: 1591.5 | accuracy: 0.41 | loss: 2.07
update:1885/2000, 耗时:0.01分/12.29分 | step: 482560 | performance: 0.6 | accuracy: 0.39 | loss: 2.20
update:1890/2000, 耗时:0.01分/12.33分 | step: 483840 | performance: 0.1 | accuracy: 0.30 | loss: 0.60
update:1895/2000, 耗时:0.01分/12.36分 | step: 485120 | performance: 0.1 | accuracy: 0.29 | loss: 1.02
update:1900/2000, 耗时:0.01分/12.39分 | step: 486400 | performance: 3.6 | accuracy: 0.37 | loss: 4.06
update:1905/2000, 耗时:0.01分/12.42分 | step: 487680 | performance: 9.9 | accuracy: 0.38 | loss: 2.81
update:1910/2000, 耗时:0.01分/12.46分 | step: 488960 | performance: 3.8 | accuracy: 0.36 | loss: 1.03
update:1915/2000, 耗时:0.01分/12.49分 | step: 490240 | performance: 25.2 | accuracy: 0.38 | loss: 2.75
update:1920/2000, 耗时:0.01分/12.53分 | step: 491520 | performance: 20.1 | accuracy: 0.38 | loss: 1.80
update:1925/2000, 耗时:0.01分/12.56分 | step: 492800 | performance: 28.4 | accuracy: 0.38 | loss: 2.22
update:1930/2000, 耗时:0.01分/12.60分 | step: 494080 | performance: 85.7 | accuracy: 0.40 | loss: 2.36
update:1935/2000, 耗时:0.01分/12.63分 | step: 495360 | performance: 25557.3 | accuracy: 0.43 | loss: 3.45
update:1940/2000, 耗时:0.01分/12.67分 | step: 496640 | performance: 2486078.6 | accuracy: 0.45 | loss: 4.46
update:1945/2000, 耗时:0.01分/12.70分 | step: 497920 | performance: 105750.4 | accuracy: 0.44 | loss: 4.11
update:1950/2000, 耗时:0.01分/12.74分 | step: 499200 | performance: 714819.0 | accuracy: 0.45 | loss: 3.24
update:1955/2000, 耗时:0.01分/12.77分 | step: 500480 | performance: 4307133.9 | accuracy: 0.46 | loss: 2.80
update:1960/2000, 耗时:0.01分/12.81分 | step: 501760 | performance: 152669.3 | accuracy: 0.45 | loss: 3.49
update:1965/2000, 耗时:0.01分/12.84分 | step: 503040 | performance: 113384.4 | accuracy: 0.45 | loss: 2.42
update:1970/2000, 耗时:0.01分/12.88分 | step: 504320 | performance: 880.0 | accuracy: 0.44 | loss: 2.80
update:1975/2000, 耗时:0.01分/12.91分 | step: 505600 | performance: 824.2 | accuracy: 0.44 | loss: 1.07
step: 506622 | worker_5@n_step_31: average total_reward after train data exhaustion : 133.5 | max total_reward: 360.1
update:1980/2000, 耗时:0.01分/12.94分 | step: 506880 | performance: 746.0 | accuracy: 0.43 | loss: 0.86
update:1985/2000, 耗时:0.01分/12.97分 | step: 508160 | performance: 0.7 | accuracy: 0.28 | loss: 0.49
update:1990/2000, 耗时:0.01分/13.01分 | step: 509440 | performance: 0.5 | accuracy: 0.23 | loss: 0.33
update:1995/2000, 耗时:0.01分/13.04分 | step: 510720 | performance: 0.8 | accuracy: 0.23 | loss: 0.89
  0%|          | 0/397 [00:00<?, ?it/s]100%|| 397/397 [00:00<00:00, 119433.27it/s]
update:2000/2000, 耗时:0.01分/13.07分 | step: 512000 | performance: 23.8 | accuracy: 0.30 | loss: 2.61
----------------------------------------finished----------------------------------------
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1750.64
2023-07-24T12:00:00 | net performance [%] = 75.0636
2023-07-24T12:00:00 | number of trades [#] = 28
==================================================
Trial 34 Complete [00h 13m 31s]
net_wealth: 1752.3888145064732

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 04h 41m 42s

Search: Running Trial #35

Value             |Best Value So Far |Hyperparameter
6                 |7                 |horizon
730               |730               |lookback
False             |False             |MarketFactor
8                 |14                |lags
0.8               |0.7               |gamma
16                |32                |batch_size
1                 |32                |n_step
0.9               |0.92              |gae_lambda
0.2               |0.1               |gradient_clip_norm
3                 |5                 |epochs
5e-05             |0.0001            |actor_lr
5e-05             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4309.000000   4315.000000
mean      0.000441    20062.255222  ...   20140.547965  20118.633889
std       0.027818    16039.874230  ...   16077.550480  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7699.189941   7690.540039
50%       0.000642    11554.824463  ...   11743.940430  11715.610352
75%       0.011655    29873.081836  ...   29950.949219  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 02:45:05.112245: I tensorflow/core/2023-07-28 02:45:05.112271: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is202pla3-07-28  opttfi0m2ized with oneAPI Deep Neur2a0or2l N3etw-0ork Library (oneDNN) to use the following CPU instruction:7-284s  5202i3-07-0n22 :p84er5 f:0or02:45:05m.5.112325: I tensorfl:112om/cpuw_/f2c2023-07-28 02:0e23-04atuo7r-2a5e:r8 0en0_5g.ce1/up-crliaartd1225t.cicc:a0l:142 f54.] To5:05h.p1er1o12rm14569: I/a2 tt5cions:p20u: 3I2   06te: I _AtennsorensorffVsoflreolXowa AV/wtfXu2l8ri
6/:scToore/ceoo wp/_gu23-0lre/cpla7rd.ccoar:e /epnI tenasorflol-2atformw/cpt blefuoTrm/e/cc npsortour_e/plfeataFurehe_atg1t8fuolo4w fbionarrary_r m0/2 md.2]: cTc4i/hp5:ucsi s cpT:opt1m_f 4iu_fnee0aitun5mi.e 1orsaoe2z1_gu2]freadrd Ft7h.w eat2low bcuriTiheretnia4r y ics:_go ps Th: oeernasIpt14ttionu r2e]iomn s, re etiborFlow APIb Dezeuiinlaer_edy dnsor gTupT haiuarfis o wiedlrd.ccth ons TepAtPimi:nsor1oIN eDeepuwzFle/d  N.cccworo:i1t4h eew2uora/ ]npelaw TAitlh iensoPrIFtfNoleotwrhm /De  esbpitn a rNycprwohre 4Teknau_e ail sN fo2 Lisppute]o rTalproahbi etrFlopriworarsNaimiztreed  wiytekttwur  b iewc( n_LoioTaergoneDmbryk  uhansoisrrLdNp iolneNr Folpor)ib tetA .awrPifl mbyoIa iDn ccg (osa.ur
:se th1i4zenereaDrNyyN)e2 ]    feopT Nidh(eural N eto utiwonsweDNN)s tllso To oo puseen trwesohteimki tL hfo  itirFllowiobnreanzerg A PlbIinyC  da r(yPhwoi thi ownes  foipUo nienDsNtNr)uenAtoligDclmoiwt ieiePnCzeIg pD eed Cop   PnU instruNeurs in paPtctiwNeural Network LibrailUo use  instrtryuothh co Nne (tions onneseAPIDNt  DNwor) to use ektrie he fnoLe llow pin peiefpo Neillonebfwiurgf CPormaorUn ceramng CPUian s-cntrruilic erf-ccNrtirearnsticyiooarmanlt  (ooninpes iceraal opertDnti pNwork LibNoner)ary (ontre cteso:  AVXratu-ions c rA: Vfioticr uX2
To AVXal ocmDtNispe aenroanN)ttceen-critiashce al    oApVbefloXrea itolnisn pierl2t
Tooft ohem in othe:  AVr operatio renable use mns, trancebeX AVX2
Toh-ucil eoriticaenablemotl hn wtien folsl:o gin h e mA oiCtV Xw open hoetPhU inedr ArVi Tasr onoX2etpit
Toerrautoi engp Ceratiaocotnbns:  AVX AVX2sP,io
nTU  rsnso lie noe  instprhns, retmeebu nFaebrilirfornuctionbluelmod t  awnshoeti cTemld Te hnerswitei -io nh  tcrihnrpFelrsfotopioceo w araFelpowwpl  iwrmrtohnipriropethaa  oratattei nth ions,onsttcceher h:e-creit  appro  AVXa pAompiler flagV rXpseoppre.rbauriii
2
Toatcal tleions,   ecompiodpneler fla rTrebuild Taeboaplreigsteinn. ots
ate compiler flagnsorFls.hoorwem
s w:  F ith iAnV the alothpoperX AVwo priateXw2i
 compiletTo hr orena  thepble flags.
them in other operaerations, rebuild TensorFlow with the appropriate compiler flags.
 appropriate compiler flags.
tions, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 02:45:05.707133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:45:05.728227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:45:05.731089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:45:05.736906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:45:05.737074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:45:05.741548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:45:05.752318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:45:05.786152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:    40 | performance: 1.1 | accuracy: 0.40 | loss: 0.12
update: 10/2000, 耗时:0.00分/0.03分 | step:    80 | performance: 0.9 | accuracy: 0.20 | loss: 0.88
update: 15/2000, 耗时:0.00分/0.04分 | step:   120 | performance: 0.8 | accuracy: 0.13 | loss: 0.49
update: 20/2000, 耗时:0.00分/0.05分 | step:   160 | performance: 0.8 | accuracy: 0.10 | loss: 0.38
step: 164 | worker_3@n_step_0: average total_reward after train data exhaustion : -4.0 | max total_reward: -4.0
Saving PPO weights in both H5 format and checkpoint @ update:21 
update: 25/2000, 耗时:0.00分/0.06分 | step:   200 | performance: 0.8 | accuracy: 0.16 | loss: 0.40
update: 30/2000, 耗时:0.00分/0.06分 | step:   240 | performance: 0.8 | accuracy: 0.23 | loss: 0.68
update: 35/2000, 耗时:0.00分/0.07分 | step:   280 | performance: 0.8 | accuracy: 0.23 | loss: 0.34
update: 40/2000, 耗时:0.00分/0.08分 | step:   320 | performance: 0.9 | accuracy: 0.28 | loss: 0.39
update: 45/2000, 耗时:0.00分/0.08分 | step:   360 | performance: 0.9 | accuracy: 0.27 | loss: 0.52
update: 50/2000, 耗时:0.00分/0.09分 | step:   400 | performance: 0.7 | accuracy: 0.24 | loss: 0.49
update: 55/2000, 耗时:0.00分/0.10分 | step:   440 | performance: 0.7 | accuracy: 0.25 | loss: 0.39
update: 60/2000, 耗时:0.00分/0.10分 | step:   480 | performance: 0.7 | accuracy: 0.23 | loss: 0.35
update: 65/2000, 耗时:0.00分/0.11分 | step:   520 | performance: 0.7 | accuracy: 0.22 | loss: 0.23
update: 70/2000, 耗时:0.00分/0.12分 | step:   560 | performance: 0.7 | accuracy: 0.24 | loss: 0.42
update: 75/2000, 耗时:0.00分/0.12分 | step:   600 | performance: 0.7 | accuracy: 0.23 | loss: 0.24
update: 80/2000, 耗时:0.00分/0.13分 | step:   640 | performance: 0.7 | accuracy: 0.24 | loss: 0.36
update: 85/2000, 耗时:0.00分/0.14分 | step:   680 | performance: 0.8 | accuracy: 0.24 | loss: 0.23
update: 90/2000, 耗时:0.00分/0.14分 | step:   720 | performance: 0.9 | accuracy: 0.24 | loss: 0.47
update: 95/2000, 耗时:0.00分/0.15分 | step:   760 | performance: 0.9 | accuracy: 0.24 | loss: 0.16
update:100/2000, 耗时:0.00分/0.16分 | step:   800 | performance: 0.9 | accuracy: 0.23 | loss: 0.45
update:105/2000, 耗时:0.00分/0.16分 | step:   840 | performance: 0.9 | accuracy: 0.23 | loss: 0.46
update:110/2000, 耗时:0.00分/0.17分 | step:   880 | performance: 0.9 | accuracy: 0.23 | loss: 0.43
update:115/2000, 耗时:0.00分/0.18分 | step:   920 | performance: 0.9 | accuracy: 0.23 | loss: 0.21
update:120/2000, 耗时:0.00分/0.19分 | step:   960 | performance: 0.9 | accuracy: 0.23 | loss: 0.55
update:125/2000, 耗时:0.00分/0.19分 | step:  1000 | performance: 0.9 | accuracy: 0.25 | loss: 0.42
update:130/2000, 耗时:0.00分/0.20分 | step:  1040 | performance: 0.9 | accuracy: 0.26 | loss: 0.21
update:135/2000, 耗时:0.00分/0.21分 | step:  1080 | performance: 0.9 | accuracy: 0.28 | loss: 0.31
update:140/2000, 耗时:0.00分/0.21分 | step:  1120 | performance: 0.9 | accuracy: 0.27 | loss: 0.15
update:145/2000, 耗时:0.00分/0.22分 | step:  1160 | performance: 0.9 | accuracy: 0.26 | loss: 0.38
update:150/2000, 耗时:0.00分/0.23分 | step:  1200 | performance: 0.8 | accuracy: 0.25 | loss: 0.39
update:155/2000, 耗时:0.00分/0.24分 | step:  1240 | performance: 0.9 | accuracy: 0.25 | loss: 0.25
update:160/2000, 耗时:0.00分/0.24分 | step:  1280 | performance: 0.8 | accuracy: 0.24 | loss: 0.79
update:165/2000, 耗时:0.00分/0.25分 | step:  1320 | performance: 1.0 | accuracy: 0.25 | loss: 0.51
update:170/2000, 耗时:0.00分/0.26分 | step:  1360 | performance: 0.8 | accuracy: 0.25 | loss: 1.19
update:175/2000, 耗时:0.00分/0.27分 | step:  1400 | performance: 1.0 | accuracy: 0.25 | loss: 0.64
update:180/2000, 耗时:0.00分/0.27分 | step:  1440 | performance: 1.2 | accuracy: 0.26 | loss: 0.44
update:185/2000, 耗时:0.00分/0.28分 | step:  1480 | performance: 1.2 | accuracy: 0.26 | loss: 0.47
update:190/2000, 耗时:0.00分/0.29分 | step:  1520 | performance: 1.7 | accuracy: 0.28 | loss: 0.34
update:195/2000, 耗时:0.00分/0.30分 | step:  1560 | performance: 1.6 | accuracy: 0.28 | loss: 0.43
update:200/2000, 耗时:0.00分/0.30分 | step:  1600 | performance: 1.8 | accuracy: 0.28 | loss: 0.76
update:205/2000, 耗时:0.00分/0.31分 | step:  1640 | performance: 1.8 | accuracy: 0.28 | loss: 0.55
update:210/2000, 耗时:0.00分/0.32分 | step:  1680 | performance: 1.9 | accuracy: 0.29 | loss: 0.49
update:215/2000, 耗时:0.00分/0.33分 | step:  1720 | performance: 1.6 | accuracy: 0.28 | loss: 1.06
update:220/2000, 耗时:0.00分/0.33分 | step:  1760 | performance: 1.3 | accuracy: 0.28 | loss: 0.40
update:225/2000, 耗时:0.00分/0.34分 | step:  1800 | performance: 1.4 | accuracy: 0.28 | loss: 0.21
update:230/2000, 耗时:0.00分/0.35分 | step:  1840 | performance: 1.6 | accuracy: 0.28 | loss: 0.48
update:235/2000, 耗时:0.00分/0.35分 | step:  1880 | performance: 2.1 | accuracy: 0.29 | loss: 0.43
update:240/2000, 耗时:0.00分/0.36分 | step:  1920 | performance: 1.9 | accuracy: 0.29 | loss: 1.18
update:245/2000, 耗时:0.00分/0.37分 | step:  1960 | performance: 1.9 | accuracy: 0.29 | loss: 0.36
update:250/2000, 耗时:0.00分/0.38分 | step:  2000 | performance: 2.0 | accuracy: 0.29 | loss: 0.42
update:255/2000, 耗时:0.00分/0.38分 | step:  2040 | performance: 2.1 | accuracy: 0.30 | loss: 0.57
update:260/2000, 耗时:0.00分/0.39分 | step:  2080 | performance: 2.1 | accuracy: 0.30 | loss: 0.44
update:265/2000, 耗时:0.00分/0.40分 | step:  2120 | performance: 2.1 | accuracy: 0.29 | loss: 0.42
update:270/2000, 耗时:0.00分/0.41分 | step:  2160 | performance: 2.2 | accuracy: 0.30 | loss: 0.27
update:275/2000, 耗时:0.00分/0.41分 | step:  2200 | performance: 2.3 | accuracy: 0.30 | loss: 0.47
update:280/2000, 耗时:0.00分/0.42分 | step:  2240 | performance: 2.3 | accuracy: 0.31 | loss: 0.23
update:285/2000, 耗时:0.00分/0.43分 | step:  2280 | performance: 2.4 | accuracy: 0.31 | loss: 0.40
update:290/2000, 耗时:0.00分/0.44分 | step:  2320 | performance: 2.4 | accuracy: 0.31 | loss: 0.36
update:295/2000, 耗时:0.00分/0.44分 | step:  2360 | performance: 2.4 | accuracy: 0.31 | loss: 0.39
update:300/2000, 耗时:0.00分/0.45分 | step:  2400 | performance: 2.3 | accuracy: 0.31 | loss: 0.38
update:305/2000, 耗时:0.00分/0.46分 | step:  2440 | performance: 2.2 | accuracy: 0.30 | loss: 0.37
update:310/2000, 耗时:0.00分/0.47分 | step:  2480 | performance: 2.2 | accuracy: 0.30 | loss: 0.24
update:315/2000, 耗时:0.00分/0.47分 | step:  2520 | performance: 2.2 | accuracy: 0.30 | loss: 0.17
update:320/2000, 耗时:0.00分/0.48分 | step:  2560 | performance: 2.2 | accuracy: 0.29 | loss: 0.07
update:325/2000, 耗时:0.00分/0.49分 | step:  2600 | performance: 1.9 | accuracy: 0.29 | loss: 0.42
update:330/2000, 耗时:0.00分/0.50分 | step:  2640 | performance: 1.9 | accuracy: 0.28 | loss: 0.46
update:335/2000, 耗时:0.00分/0.50分 | step:  2680 | performance: 1.9 | accuracy: 0.29 | loss: 0.42
update:340/2000, 耗时:0.00分/0.51分 | step:  2720 | performance: 1.9 | accuracy: 0.29 | loss: 0.43
update:345/2000, 耗时:0.00分/0.52分 | step:  2760 | performance: 1.8 | accuracy: 0.28 | loss: 0.25
update:350/2000, 耗时:0.00分/0.52分 | step:  2800 | performance: 1.9 | accuracy: 0.29 | loss: 0.38
update:355/2000, 耗时:0.00分/0.53分 | step:  2840 | performance: 1.7 | accuracy: 0.28 | loss: 0.49
update:360/2000, 耗时:0.00分/0.54分 | step:  2880 | performance: 1.8 | accuracy: 0.29 | loss: 0.44
update:365/2000, 耗时:0.00分/0.55分 | step:  2920 | performance: 1.8 | accuracy: 0.28 | loss: 0.29
update:370/2000, 耗时:0.00分/0.55分 | step:  2960 | performance: 1.9 | accuracy: 0.29 | loss: 0.50
update:375/2000, 耗时:0.00分/0.56分 | step:  3000 | performance: 1.8 | accuracy: 0.29 | loss: 0.32
update:380/2000, 耗时:0.00分/0.57分 | step:  3040 | performance: 1.8 | accuracy: 0.29 | loss: 0.38
update:385/2000, 耗时:0.00分/0.58分 | step:  3080 | performance: 1.8 | accuracy: 0.28 | loss: 0.41
update:390/2000, 耗时:0.00分/0.58分 | step:  3120 | performance: 1.7 | accuracy: 0.28 | loss: 0.36
update:395/2000, 耗时:0.00分/0.59分 | step:  3160 | performance: 1.8 | accuracy: 0.28 | loss: 0.30
update:400/2000, 耗时:0.00分/0.60分 | step:  3200 | performance: 1.8 | accuracy: 0.28 | loss: 0.24
update:405/2000, 耗时:0.00分/0.61分 | step:  3240 | performance: 1.8 | accuracy: 0.28 | loss: 0.15
update:410/2000, 耗时:0.00分/0.61分 | step:  3280 | performance: 1.7 | accuracy: 0.28 | loss: 0.37
update:415/2000, 耗时:0.00分/0.62分 | step:  3320 | performance: 1.7 | accuracy: 0.28 | loss: 0.37
update:420/2000, 耗时:0.00分/0.63分 | step:  3360 | performance: 1.9 | accuracy: 0.28 | loss: 0.57
update:425/2000, 耗时:0.00分/0.64分 | step:  3400 | performance: 2.7 | accuracy: 0.29 | loss: 0.90
update:430/2000, 耗时:0.00分/0.64分 | step:  3440 | performance: 4.0 | accuracy: 0.29 | loss: 0.27
update:435/2000, 耗时:0.00分/0.65分 | step:  3480 | performance: 3.9 | accuracy: 0.29 | loss: 0.48
update:440/2000, 耗时:0.00分/0.66分 | step:  3520 | performance: 3.5 | accuracy: 0.29 | loss: 0.31
update:445/2000, 耗时:0.00分/0.66分 | step:  3560 | performance: 3.7 | accuracy: 0.29 | loss: 0.67
update:450/2000, 耗时:0.00分/0.67分 | step:  3600 | performance: 3.7 | accuracy: 0.30 | loss: 0.81
update:455/2000, 耗时:0.00分/0.68分 | step:  3640 | performance: 3.7 | accuracy: 0.29 | loss: 0.53
update:460/2000, 耗时:0.00分/0.69分 | step:  3680 | performance: 3.5 | accuracy: 0.29 | loss: 0.59
update:465/2000, 耗时:0.00分/0.69分 | step:  3720 | performance: 3.5 | accuracy: 0.30 | loss: 0.31
update:470/2000, 耗时:0.00分/0.70分 | step:  3760 | performance: 3.8 | accuracy: 0.30 | loss: 0.42
update:475/2000, 耗时:0.00分/0.71分 | step:  3800 | performance: 3.6 | accuracy: 0.30 | loss: 0.31
update:480/2000, 耗时:0.00分/0.72分 | step:  3840 | performance: 3.6 | accuracy: 0.30 | loss: 0.49
update:485/2000, 耗时:0.00分/0.72分 | step:  3880 | performance: 3.9 | accuracy: 0.31 | loss: 0.29
update:490/2000, 耗时:0.00分/0.73分 | step:  3920 | performance: 4.9 | accuracy: 0.31 | loss: 0.36
update:495/2000, 耗时:0.00分/0.74分 | step:  3960 | performance: 4.6 | accuracy: 0.31 | loss: 0.26
update:500/2000, 耗时:0.00分/0.74分 | step:  4000 | performance: 5.8 | accuracy: 0.31 | loss: 0.61
update:505/2000, 耗时:0.00分/0.75分 | step:  4040 | performance: 10.0 | accuracy: 0.32 | loss: 0.75
update:510/2000, 耗时:0.00分/0.76分 | step:  4080 | performance: 11.7 | accuracy: 0.32 | loss: 0.85
update:515/2000, 耗时:0.00分/0.77分 | step:  4120 | performance: 12.8 | accuracy: 0.32 | loss: 0.98
update:520/2000, 耗时:0.00分/0.77分 | step:  4160 | performance: 13.3 | accuracy: 0.32 | loss: 0.89
update:525/2000, 耗时:0.00分/0.78分 | step:  4200 | performance: 12.4 | accuracy: 0.32 | loss: 1.55
update:530/2000, 耗时:0.00分/0.79分 | step:  4240 | performance: 12.4 | accuracy: 0.32 | loss: 0.96
update:535/2000, 耗时:0.00分/0.79分 | step:  4280 | performance: 8.6 | accuracy: 0.31 | loss: 0.42
update:540/2000, 耗时:0.00分/0.80分 | step:  4320 | performance: 7.3 | accuracy: 0.31 | loss: 0.43
update:545/2000, 耗时:0.00分/0.81分 | step:  4360 | performance: 7.3 | accuracy: 0.31 | loss: 0.26
update:550/2000, 耗时:0.00分/0.82分 | step:  4400 | performance: 8.3 | accuracy: 0.32 | loss: 1.11
update:555/2000, 耗时:0.00分/0.82分 | step:  4440 | performance: 8.7 | accuracy: 0.32 | loss: 0.66
update:560/2000, 耗时:0.00分/0.83分 | step:  4480 | performance: 8.4 | accuracy: 0.31 | loss: 0.30
update:565/2000, 耗时:0.00分/0.84分 | step:  4520 | performance: 8.0 | accuracy: 0.32 | loss: 0.33
update:570/2000, 耗时:0.00分/0.85分 | step:  4560 | performance: 6.8 | accuracy: 0.31 | loss: 1.05
update:575/2000, 耗时:0.00分/0.85分 | step:  4600 | performance: 7.0 | accuracy: 0.31 | loss: 0.59
update:580/2000, 耗时:0.00分/0.86分 | step:  4640 | performance: 7.0 | accuracy: 0.32 | loss: 0.53
update:585/2000, 耗时:0.00分/0.87分 | step:  4680 | performance: 7.9 | accuracy: 0.32 | loss: 0.77
update:590/2000, 耗时:0.00分/0.87分 | step:  4720 | performance: 10.5 | accuracy: 0.32 | loss: 0.71
update:595/2000, 耗时:0.00分/0.88分 | step:  4760 | performance: 17.1 | accuracy: 0.32 | loss: 0.73
update:600/2000, 耗时:0.00分/0.89分 | step:  4800 | performance: 19.6 | accuracy: 0.33 | loss: 0.58
update:605/2000, 耗时:0.00分/0.89分 | step:  4840 | performance: 18.6 | accuracy: 0.33 | loss: 0.49
update:610/2000, 耗时:0.00分/0.90分 | step:  4880 | performance: 16.9 | accuracy: 0.32 | loss: 0.07
update:615/2000, 耗时:0.00分/0.91分 | step:  4920 | performance: 15.3 | accuracy: 0.32 | loss: 1.34
update:620/2000, 耗时:0.00分/0.91分 | step:  4960 | performance: 13.1 | accuracy: 0.32 | loss: 1.01
update:625/2000, 耗时:0.00分/0.92分 | step:  5000 | performance: 10.5 | accuracy: 0.32 | loss: 1.01
update:630/2000, 耗时:0.00分/0.93分 | step:  5040 | performance: 8.9 | accuracy: 0.32 | loss: 0.94
update:635/2000, 耗时:0.00分/0.94分 | step:  5080 | performance: 13.9 | accuracy: 0.32 | loss: 0.92
update:640/2000, 耗时:0.00分/0.94分 | step:  5120 | performance: 13.6 | accuracy: 0.32 | loss: 0.72
update:645/2000, 耗时:0.00分/0.95分 | step:  5160 | performance: 16.5 | accuracy: 0.32 | loss: 0.77
update:650/2000, 耗时:0.00分/0.96分 | step:  5200 | performance: 17.8 | accuracy: 0.32 | loss: 1.41
update:655/2000, 耗时:0.00分/0.96分 | step:  5240 | performance: 21.8 | accuracy: 0.33 | loss: 0.42
update:660/2000, 耗时:0.00分/0.97分 | step:  5280 | performance: 23.9 | accuracy: 0.33 | loss: 0.52
update:665/2000, 耗时:0.00分/0.98分 | step:  5320 | performance: 25.0 | accuracy: 0.33 | loss: 0.53
update:670/2000, 耗时:0.00分/0.98分 | step:  5360 | performance: 27.4 | accuracy: 0.33 | loss: 1.06
update:675/2000, 耗时:0.00分/0.99分 | step:  5400 | performance: 37.2 | accuracy: 0.33 | loss: 1.67
update:680/2000, 耗时:0.00分/1.00分 | step:  5440 | performance: 43.3 | accuracy: 0.33 | loss: 0.83
update:685/2000, 耗时:0.00分/1.00分 | step:  5480 | performance: 41.1 | accuracy: 0.33 | loss: 0.94
update:690/2000, 耗时:0.00分/1.01分 | step:  5520 | performance: 36.3 | accuracy: 0.33 | loss: 0.40
update:695/2000, 耗时:0.00分/1.02分 | step:  5560 | performance: 32.1 | accuracy: 0.33 | loss: 1.06
update:700/2000, 耗时:0.00分/1.02分 | step:  5600 | performance: 36.0 | accuracy: 0.33 | loss: 0.39
update:705/2000, 耗时:0.00分/1.03分 | step:  5640 | performance: 30.9 | accuracy: 0.33 | loss: 0.47
update:710/2000, 耗时:0.00分/1.04分 | step:  5680 | performance: 26.6 | accuracy: 0.32 | loss: 0.60
update:715/2000, 耗时:0.00分/1.05分 | step:  5720 | performance: 28.0 | accuracy: 0.32 | loss: 0.49
update:720/2000, 耗时:0.00分/1.05分 | step:  5760 | performance: 27.0 | accuracy: 0.32 | loss: 0.52
update:725/2000, 耗时:0.00分/1.06分 | step:  5800 | performance: 27.2 | accuracy: 0.32 | loss: 0.58
update:730/2000, 耗时:0.00分/1.07分 | step:  5840 | performance: 29.1 | accuracy: 0.33 | loss: 0.29
update:735/2000, 耗时:0.00分/1.07分 | step:  5880 | performance: 29.3 | accuracy: 0.33 | loss: 0.53
update:740/2000, 耗时:0.00分/1.08分 | step:  5920 | performance: 32.3 | accuracy: 0.33 | loss: 0.52
update:745/2000, 耗时:0.00分/1.09分 | step:  5960 | performance: 34.5 | accuracy: 0.33 | loss: 0.25
update:750/2000, 耗时:0.00分/1.10分 | step:  6000 | performance: 33.2 | accuracy: 0.33 | loss: 0.38
update:755/2000, 耗时:0.00分/1.10分 | step:  6040 | performance: 33.0 | accuracy: 0.33 | loss: 0.27
update:760/2000, 耗时:0.00分/1.11分 | step:  6080 | performance: 33.0 | accuracy: 0.33 | loss: 0.41
update:765/2000, 耗时:0.00分/1.12分 | step:  6120 | performance: 31.1 | accuracy: 0.33 | loss: 0.21
update:770/2000, 耗时:0.00分/1.12分 | step:  6160 | performance: 30.4 | accuracy: 0.32 | loss: 0.24
update:775/2000, 耗时:0.00分/1.13分 | step:  6200 | performance: 28.7 | accuracy: 0.32 | loss: 0.61
update:780/2000, 耗时:0.00分/1.14分 | step:  6240 | performance: 33.9 | accuracy: 0.32 | loss: 0.58
update:785/2000, 耗时:0.00分/1.15分 | step:  6280 | performance: 36.8 | accuracy: 0.32 | loss: 0.29
update:790/2000, 耗时:0.00分/1.15分 | step:  6320 | performance: 35.4 | accuracy: 0.32 | loss: 0.44
update:795/2000, 耗时:0.00分/1.16分 | step:  6360 | performance: 34.3 | accuracy: 0.32 | loss: 0.37
update:800/2000, 耗时:0.00分/1.17分 | step:  6400 | performance: 34.9 | accuracy: 0.32 | loss: 0.47
update:805/2000, 耗时:0.00分/1.17分 | step:  6440 | performance: 39.1 | accuracy: 0.32 | loss: 1.17
update:810/2000, 耗时:0.00分/1.18分 | step:  6480 | performance: 42.8 | accuracy: 0.32 | loss: 0.40
update:815/2000, 耗时:0.00分/1.19分 | step:  6520 | performance: 42.3 | accuracy: 0.32 | loss: 0.45
update:820/2000, 耗时:0.00分/1.20分 | step:  6560 | performance: 37.6 | accuracy: 0.32 | loss: 0.52
update:825/2000, 耗时:0.00分/1.20分 | step:  6600 | performance: 34.4 | accuracy: 0.32 | loss: 0.49
update:830/2000, 耗时:0.00分/1.21分 | step:  6640 | performance: 33.0 | accuracy: 0.32 | loss: 0.24
update:835/2000, 耗时:0.00分/1.22分 | step:  6680 | performance: 36.5 | accuracy: 0.32 | loss: 0.65
update:840/2000, 耗时:0.00分/1.22分 | step:  6720 | performance: 45.7 | accuracy: 0.32 | loss: 1.43
update:845/2000, 耗时:0.00分/1.23分 | step:  6760 | performance: 28.7 | accuracy: 0.32 | loss: 0.76
update:850/2000, 耗时:0.00分/1.24分 | step:  6800 | performance: 30.8 | accuracy: 0.32 | loss: 0.79
update:855/2000, 耗时:0.00分/1.25分 | step:  6840 | performance: 30.4 | accuracy: 0.32 | loss: 0.38
update:860/2000, 耗时:0.00分/1.25分 | step:  6880 | performance: 29.1 | accuracy: 0.32 | loss: 0.56
update:865/2000, 耗时:0.00分/1.26分 | step:  6920 | performance: 30.1 | accuracy: 0.32 | loss: 0.88
update:870/2000, 耗时:0.00分/1.27分 | step:  6960 | performance: 30.7 | accuracy: 0.32 | loss: 0.77
update:875/2000, 耗时:0.00分/1.27分 | step:  7000 | performance: 30.7 | accuracy: 0.32 | loss: 0.36
update:880/2000, 耗时:0.00分/1.28分 | step:  7040 | performance: 29.4 | accuracy: 0.32 | loss: 0.44
update:885/2000, 耗时:0.00分/1.29分 | step:  7080 | performance: 27.2 | accuracy: 0.32 | loss: 0.22
update:890/2000, 耗时:0.00分/1.30分 | step:  7120 | performance: 25.9 | accuracy: 0.32 | loss: 0.30
update:895/2000, 耗时:0.00分/1.30分 | step:  7160 | performance: 24.7 | accuracy: 0.32 | loss: 0.69
update:900/2000, 耗时:0.00分/1.31分 | step:  7200 | performance: 23.3 | accuracy: 0.32 | loss: 0.24
update:905/2000, 耗时:0.00分/1.32分 | step:  7240 | performance: 21.7 | accuracy: 0.32 | loss: 0.18
update:910/2000, 耗时:0.00分/1.32分 | step:  7280 | performance: 19.8 | accuracy: 0.32 | loss: 0.41
update:915/2000, 耗时:0.00分/1.33分 | step:  7320 | performance: 21.2 | accuracy: 0.32 | loss: 0.58
update:920/2000, 耗时:0.00分/1.34分 | step:  7360 | performance: 21.3 | accuracy: 0.32 | loss: 0.36
update:925/2000, 耗时:0.00分/1.34分 | step:  7400 | performance: 20.1 | accuracy: 0.32 | loss: 0.39
update:930/2000, 耗时:0.00分/1.35分 | step:  7440 | performance: 18.1 | accuracy: 0.32 | loss: 0.26
update:935/2000, 耗时:0.00分/1.36分 | step:  7480 | performance: 18.0 | accuracy: 0.31 | loss: 0.34
update:940/2000, 耗时:0.00分/1.36分 | step:  7520 | performance: 17.2 | accuracy: 0.31 | loss: 0.45
update:945/2000, 耗时:0.00分/1.37分 | step:  7560 | performance: 13.7 | accuracy: 0.31 | loss: 0.48
update:950/2000, 耗时:0.00分/1.38分 | step:  7600 | performance: 14.6 | accuracy: 0.31 | loss: 0.74
update:955/2000, 耗时:0.00分/1.39分 | step:  7640 | performance: 15.6 | accuracy: 0.31 | loss: 0.46
update:960/2000, 耗时:0.00分/1.39分 | step:  7680 | performance: 15.1 | accuracy: 0.31 | loss: 0.45
update:965/2000, 耗时:0.00分/1.40分 | step:  7720 | performance: 14.5 | accuracy: 0.31 | loss: 0.49
update:970/2000, 耗时:0.00分/1.41分 | step:  7760 | performance: 14.3 | accuracy: 0.31 | loss: 0.56
update:975/2000, 耗时:0.00分/1.41分 | step:  7800 | performance: 15.3 | accuracy: 0.31 | loss: 0.38
update:980/2000, 耗时:0.00分/1.42分 | step:  7840 | performance: 15.0 | accuracy: 0.31 | loss: 0.26
update:985/2000, 耗时:0.00分/1.43分 | step:  7880 | performance: 15.7 | accuracy: 0.31 | loss: 0.72
update:990/2000, 耗时:0.00分/1.44分 | step:  7920 | performance: 12.1 | accuracy: 0.31 | loss: 0.34
update:995/2000, 耗时:0.00分/1.44分 | step:  7960 | performance: 11.6 | accuracy: 0.31 | loss: 0.54
update:1000/2000, 耗时:0.00分/1.45分 | step:  8000 | performance: 11.8 | accuracy: 0.31 | loss: 0.60
update:1005/2000, 耗时:0.00分/1.46分 | step:  8040 | performance: 14.3 | accuracy: 0.31 | loss: 0.49
update:1010/2000, 耗时:0.00分/1.47分 | step:  8080 | performance: 14.4 | accuracy: 0.31 | loss: 0.30
update:1015/2000, 耗时:0.00分/1.47分 | step:  8120 | performance: 15.2 | accuracy: 0.31 | loss: 0.38
update:1020/2000, 耗时:0.00分/1.48分 | step:  8160 | performance: 16.4 | accuracy: 0.31 | loss: 0.44
update:1025/2000, 耗时:0.00分/1.49分 | step:  8200 | performance: 18.4 | accuracy: 0.32 | loss: 0.36
update:1030/2000, 耗时:0.00分/1.49分 | step:  8240 | performance: 18.6 | accuracy: 0.32 | loss: 0.50
update:1035/2000, 耗时:0.00分/1.50分 | step:  8280 | performance: 18.2 | accuracy: 0.32 | loss: 0.47
update:1040/2000, 耗时:0.00分/1.51分 | step:  8320 | performance: 18.1 | accuracy: 0.32 | loss: 0.32
update:1045/2000, 耗时:0.00分/1.51分 | step:  8360 | performance: 18.8 | accuracy: 0.32 | loss: 0.69
update:1050/2000, 耗时:0.00分/1.52分 | step:  8400 | performance: 20.4 | accuracy: 0.32 | loss: 0.71
update:1055/2000, 耗时:0.00分/1.53分 | step:  8440 | performance: 19.8 | accuracy: 0.32 | loss: 0.48
update:1060/2000, 耗时:0.00分/1.54分 | step:  8480 | performance: 19.4 | accuracy: 0.32 | loss: 0.37
update:1065/2000, 耗时:0.00分/1.54分 | step:  8520 | performance: 19.2 | accuracy: 0.32 | loss: 0.29
update:1070/2000, 耗时:0.00分/1.55分 | step:  8560 | performance: 19.6 | accuracy: 0.32 | loss: 0.28
update:1075/2000, 耗时:0.00分/1.56分 | step:  8600 | performance: 19.1 | accuracy: 0.32 | loss: 0.51
update:1080/2000, 耗时:0.00分/1.56分 | step:  8640 | performance: 19.9 | accuracy: 0.32 | loss: 0.64
update:1085/2000, 耗时:0.00分/1.57分 | step:  8680 | performance: 19.2 | accuracy: 0.32 | loss: 0.54
update:1090/2000, 耗时:0.00分/1.58分 | step:  8720 | performance: 21.8 | accuracy: 0.32 | loss: 0.72
update:1095/2000, 耗时:0.00分/1.59分 | step:  8760 | performance: 23.0 | accuracy: 0.32 | loss: 0.36
update:1100/2000, 耗时:0.00分/1.59分 | step:  8800 | performance: 24.9 | accuracy: 0.32 | loss: 0.45
update:1105/2000, 耗时:0.00分/1.60分 | step:  8840 | performance: 26.0 | accuracy: 0.32 | loss: 0.35
update:1110/2000, 耗时:0.00分/1.61分 | step:  8880 | performance: 20.0 | accuracy: 0.32 | loss: 0.63
update:1115/2000, 耗时:0.00分/1.61分 | step:  8920 | performance: 26.1 | accuracy: 0.32 | loss: 3.87
update:1120/2000, 耗时:0.00分/1.62分 | step:  8960 | performance: 56.8 | accuracy: 0.32 | loss: 1.47
update:1125/2000, 耗时:0.00分/1.63分 | step:  9000 | performance: 67.5 | accuracy: 0.32 | loss: 0.30
update:1130/2000, 耗时:0.00分/1.63分 | step:  9040 | performance: 37.3 | accuracy: 0.32 | loss: 2.23
update:1135/2000, 耗时:0.00分/1.64分 | step:  9080 | performance: 43.9 | accuracy: 0.32 | loss: 0.88
update:1140/2000, 耗时:0.00分/1.65分 | step:  9120 | performance: 38.0 | accuracy: 0.32 | loss: 1.07
update:1145/2000, 耗时:0.00分/1.65分 | step:  9160 | performance: 28.2 | accuracy: 0.32 | loss: 0.73
update:1150/2000, 耗时:0.00分/1.66分 | step:  9200 | performance: 25.7 | accuracy: 0.32 | loss: 0.76
update:1155/2000, 耗时:0.00分/1.67分 | step:  9240 | performance: 28.4 | accuracy: 0.32 | loss: 1.17
update:1160/2000, 耗时:0.00分/1.67分 | step:  9280 | performance: 34.8 | accuracy: 0.32 | loss: 0.83
update:1165/2000, 耗时:0.00分/1.68分 | step:  9320 | performance: 39.1 | accuracy: 0.32 | loss: 0.73
update:1170/2000, 耗时:0.00分/1.69分 | step:  9360 | performance: 39.1 | accuracy: 0.33 | loss: 0.60
update:1175/2000, 耗时:0.00分/1.70分 | step:  9400 | performance: 34.4 | accuracy: 0.32 | loss: 0.68
update:1180/2000, 耗时:0.00分/1.70分 | step:  9440 | performance: 31.4 | accuracy: 0.32 | loss: 0.26
update:1185/2000, 耗时:0.00分/1.71分 | step:  9480 | performance: 30.4 | accuracy: 0.32 | loss: 0.41
update:1190/2000, 耗时:0.00分/1.72分 | step:  9520 | performance: 34.2 | accuracy: 0.33 | loss: 0.61
update:1195/2000, 耗时:0.00分/1.72分 | step:  9560 | performance: 32.3 | accuracy: 0.33 | loss: 0.75
update:1200/2000, 耗时:0.00分/1.73分 | step:  9600 | performance: 38.7 | accuracy: 0.33 | loss: 0.87
update:1205/2000, 耗时:0.00分/1.74分 | step:  9640 | performance: 49.8 | accuracy: 0.33 | loss: 0.53
update:1210/2000, 耗时:0.00分/1.74分 | step:  9680 | performance: 48.5 | accuracy: 0.33 | loss: 0.86
update:1215/2000, 耗时:0.00分/1.75分 | step:  9720 | performance: 49.3 | accuracy: 0.33 | loss: 0.62
update:1220/2000, 耗时:0.00分/1.76分 | step:  9760 | performance: 55.5 | accuracy: 0.33 | loss: 0.79
update:1225/2000, 耗时:0.00分/1.76分 | step:  9800 | performance: 55.2 | accuracy: 0.33 | loss: 0.53
update:1230/2000, 耗时:0.00分/1.77分 | step:  9840 | performance: 54.1 | accuracy: 0.33 | loss: 0.43
update:1235/2000, 耗时:0.00分/1.78分 | step:  9880 | performance: 40.4 | accuracy: 0.33 | loss: 1.25
update:1240/2000, 耗时:0.00分/1.79分 | step:  9920 | performance: 40.6 | accuracy: 0.33 | loss: 0.60
update:1245/2000, 耗时:0.00分/1.79分 | step:  9960 | performance: 32.8 | accuracy: 0.33 | loss: 0.39
update:1250/2000, 耗时:0.00分/1.80分 | step: 10000 | performance: 31.4 | accuracy: 0.33 | loss: 0.46
update:1255/2000, 耗时:0.00分/1.81分 | step: 10040 | performance: 26.8 | accuracy: 0.33 | loss: 0.85
update:1260/2000, 耗时:0.00分/1.81分 | step: 10080 | performance: 27.0 | accuracy: 0.33 | loss: 0.50
update:1265/2000, 耗时:0.00分/1.82分 | step: 10120 | performance: 26.7 | accuracy: 0.33 | loss: 0.46
update:1270/2000, 耗时:0.00分/1.83分 | step: 10160 | performance: 26.8 | accuracy: 0.33 | loss: 0.58
update:1275/2000, 耗时:0.00分/1.83分 | step: 10200 | performance: 29.5 | accuracy: 0.33 | loss: 0.18
update:1280/2000, 耗时:0.00分/1.84分 | step: 10240 | performance: 28.2 | accuracy: 0.33 | loss: 0.31
update:1285/2000, 耗时:0.00分/1.85分 | step: 10280 | performance: 27.0 | accuracy: 0.33 | loss: 0.56
update:1290/2000, 耗时:0.00分/1.86分 | step: 10320 | performance: 26.7 | accuracy: 0.33 | loss: 0.44
update:1295/2000, 耗时:0.00分/1.86分 | step: 10360 | performance: 26.1 | accuracy: 0.33 | loss: 0.34
update:1300/2000, 耗时:0.00分/1.87分 | step: 10400 | performance: 25.2 | accuracy: 0.33 | loss: 0.29
update:1305/2000, 耗时:0.00分/1.88分 | step: 10440 | performance: 26.2 | accuracy: 0.33 | loss: 0.52
update:1310/2000, 耗时:0.00分/1.88分 | step: 10480 | performance: 27.2 | accuracy: 0.33 | loss: 0.27
update:1315/2000, 耗时:0.00分/1.89分 | step: 10520 | performance: 27.7 | accuracy: 0.33 | loss: 0.10
update:1320/2000, 耗时:0.00分/1.90分 | step: 10560 | performance: 25.3 | accuracy: 0.33 | loss: 0.42
update:1325/2000, 耗时:0.00分/1.90分 | step: 10600 | performance: 26.1 | accuracy: 0.33 | loss: 0.54
update:1330/2000, 耗时:0.00分/1.91分 | step: 10640 | performance: 24.9 | accuracy: 0.33 | loss: 0.38
update:1335/2000, 耗时:0.00分/1.92分 | step: 10680 | performance: 25.1 | accuracy: 0.33 | loss: 0.27
update:1340/2000, 耗时:0.00分/1.93分 | step: 10720 | performance: 24.4 | accuracy: 0.33 | loss: 0.32
update:1345/2000, 耗时:0.00分/1.93分 | step: 10760 | performance: 23.4 | accuracy: 0.33 | loss: 0.32
update:1350/2000, 耗时:0.00分/1.94分 | step: 10800 | performance: 23.0 | accuracy: 0.33 | loss: 0.47
update:1355/2000, 耗时:0.00分/1.95分 | step: 10840 | performance: 23.2 | accuracy: 0.33 | loss: 0.23
update:1360/2000, 耗时:0.00分/1.95分 | step: 10880 | performance: 24.1 | accuracy: 0.33 | loss: 0.28
update:1365/2000, 耗时:0.00分/1.96分 | step: 10920 | performance: 24.2 | accuracy: 0.33 | loss: 0.22
update:1370/2000, 耗时:0.00分/1.97分 | step: 10960 | performance: 24.1 | accuracy: 0.33 | loss: 0.40
update:1375/2000, 耗时:0.00分/1.97分 | step: 11000 | performance: 24.2 | accuracy: 0.33 | loss: 0.18
update:1380/2000, 耗时:0.00分/1.98分 | step: 11040 | performance: 25.1 | accuracy: 0.33 | loss: 0.35
update:1385/2000, 耗时:0.00分/1.99分 | step: 11080 | performance: 26.5 | accuracy: 0.33 | loss: 0.41
update:1390/2000, 耗时:0.00分/1.99分 | step: 11120 | performance: 24.5 | accuracy: 0.33 | loss: 1.02
update:1395/2000, 耗时:0.00分/2.00分 | step: 11160 | performance: 26.2 | accuracy: 0.33 | loss: 0.24
update:1400/2000, 耗时:0.00分/2.01分 | step: 11200 | performance: 27.2 | accuracy: 0.33 | loss: 0.47
update:1405/2000, 耗时:0.00分/2.02分 | step: 11240 | performance: 25.5 | accuracy: 0.33 | loss: 0.46
update:1410/2000, 耗时:0.00分/2.02分 | step: 11280 | performance: 26.0 | accuracy: 0.33 | loss: 0.82
update:1415/2000, 耗时:0.00分/2.03分 | step: 11320 | performance: 26.0 | accuracy: 0.33 | loss: 0.35
update:1420/2000, 耗时:0.00分/2.04分 | step: 11360 | performance: 26.7 | accuracy: 0.32 | loss: 0.39
update:1425/2000, 耗时:0.00分/2.04分 | step: 11400 | performance: 25.6 | accuracy: 0.32 | loss: 0.55
update:1430/2000, 耗时:0.00分/2.05分 | step: 11440 | performance: 24.8 | accuracy: 0.32 | loss: 0.32
update:1435/2000, 耗时:0.00分/2.06分 | step: 11480 | performance: 25.2 | accuracy: 0.32 | loss: 0.41
update:1440/2000, 耗时:0.00分/2.07分 | step: 11520 | performance: 25.0 | accuracy: 0.32 | loss: 0.25
update:1445/2000, 耗时:0.00分/2.07分 | step: 11560 | performance: 25.5 | accuracy: 0.32 | loss: 0.46
update:1450/2000, 耗时:0.00分/2.08分 | step: 11600 | performance: 26.8 | accuracy: 0.32 | loss: 0.35
update:1455/2000, 耗时:0.00分/2.09分 | step: 11640 | performance: 27.7 | accuracy: 0.32 | loss: 0.36
update:1460/2000, 耗时:0.00分/2.09分 | step: 11680 | performance: 29.0 | accuracy: 0.32 | loss: 0.33
update:1465/2000, 耗时:0.00分/2.10分 | step: 11720 | performance: 33.5 | accuracy: 0.33 | loss: 0.75
update:1470/2000, 耗时:0.00分/2.11分 | step: 11760 | performance: 34.3 | accuracy: 0.33 | loss: 0.38
update:1475/2000, 耗时:0.00分/2.12分 | step: 11800 | performance: 33.1 | accuracy: 0.32 | loss: 0.15
update:1480/2000, 耗时:0.00分/2.12分 | step: 11840 | performance: 32.2 | accuracy: 0.32 | loss: 0.46
update:1485/2000, 耗时:0.00分/2.13分 | step: 11880 | performance: 31.5 | accuracy: 0.32 | loss: 0.47
update:1490/2000, 耗时:0.00分/2.14分 | step: 11920 | performance: 30.5 | accuracy: 0.32 | loss: 0.39
update:1495/2000, 耗时:0.00分/2.14分 | step: 11960 | performance: 32.8 | accuracy: 0.32 | loss: 0.51
update:1500/2000, 耗时:0.00分/2.15分 | step: 12000 | performance: 31.4 | accuracy: 0.32 | loss: 0.50
update:1505/2000, 耗时:0.00分/2.16分 | step: 12040 | performance: 31.9 | accuracy: 0.32 | loss: 0.58
update:1510/2000, 耗时:0.00分/2.17分 | step: 12080 | performance: 31.9 | accuracy: 0.32 | loss: 0.37
update:1515/2000, 耗时:0.00分/2.17分 | step: 12120 | performance: 32.6 | accuracy: 0.32 | loss: 0.26
update:1520/2000, 耗时:0.00分/2.18分 | step: 12160 | performance: 32.7 | accuracy: 0.32 | loss: 0.17
update:1525/2000, 耗时:0.00分/2.19分 | step: 12200 | performance: 31.1 | accuracy: 0.32 | loss: 0.24
update:1530/2000, 耗时:0.00分/2.19分 | step: 12240 | performance: 30.7 | accuracy: 0.32 | loss: 0.50
update:1535/2000, 耗时:0.00分/2.20分 | step: 12280 | performance: 30.5 | accuracy: 0.32 | loss: 0.48
update:1540/2000, 耗时:0.00分/2.21分 | step: 12320 | performance: 31.9 | accuracy: 0.32 | loss: 0.66
update:1545/2000, 耗时:0.00分/2.22分 | step: 12360 | performance: 30.4 | accuracy: 0.32 | loss: 0.46
update:1550/2000, 耗时:0.00分/2.22分 | step: 12400 | performance: 30.6 | accuracy: 0.32 | loss: 0.30
update:1555/2000, 耗时:0.00分/2.23分 | step: 12440 | performance: 30.7 | accuracy: 0.32 | loss: 0.22
update:1560/2000, 耗时:0.00分/2.24分 | step: 12480 | performance: 31.9 | accuracy: 0.32 | loss: 0.54
update:1565/2000, 耗时:0.00分/2.25分 | step: 12520 | performance: 47.6 | accuracy: 0.32 | loss: 0.59
update:1570/2000, 耗时:0.00分/2.25分 | step: 12560 | performance: 48.8 | accuracy: 0.32 | loss: 0.33
update:1575/2000, 耗时:0.00分/2.26分 | step: 12600 | performance: 52.4 | accuracy: 0.32 | loss: 0.32
update:1580/2000, 耗时:0.00分/2.27分 | step: 12640 | performance: 52.7 | accuracy: 0.32 | loss: 0.56
update:1585/2000, 耗时:0.00分/2.27分 | step: 12680 | performance: 53.1 | accuracy: 0.32 | loss: 0.30
update:1590/2000, 耗时:0.00分/2.28分 | step: 12720 | performance: 54.0 | accuracy: 0.32 | loss: 0.73
update:1595/2000, 耗时:0.00分/2.29分 | step: 12760 | performance: 70.9 | accuracy: 0.33 | loss: 0.61
update:1600/2000, 耗时:0.00分/2.30分 | step: 12800 | performance: 71.0 | accuracy: 0.33 | loss: 0.32
update:1605/2000, 耗时:0.00分/2.30分 | step: 12840 | performance: 76.6 | accuracy: 0.33 | loss: 0.72
update:1610/2000, 耗时:0.00分/2.31分 | step: 12880 | performance: 84.1 | accuracy: 0.33 | loss: 0.27
update:1615/2000, 耗时:0.00分/2.32分 | step: 12920 | performance: 92.4 | accuracy: 0.33 | loss: 0.80
update:1620/2000, 耗时:0.00分/2.32分 | step: 12960 | performance: 128.5 | accuracy: 0.33 | loss: 0.69
update:1625/2000, 耗时:0.00分/2.33分 | step: 13000 | performance: 150.3 | accuracy: 0.33 | loss: 0.64
update:1630/2000, 耗时:0.00分/2.34分 | step: 13040 | performance: 168.9 | accuracy: 0.33 | loss: 0.46
update:1635/2000, 耗时:0.00分/2.35分 | step: 13080 | performance: 115.7 | accuracy: 0.33 | loss: 0.98
update:1640/2000, 耗时:0.00分/2.35分 | step: 13120 | performance: 108.9 | accuracy: 0.33 | loss: 0.44
update:1645/2000, 耗时:0.00分/2.36分 | step: 13160 | performance: 116.5 | accuracy: 0.33 | loss: 0.29
update:1650/2000, 耗时:0.00分/2.37分 | step: 13200 | performance: 110.2 | accuracy: 0.33 | loss: 0.75
update:1655/2000, 耗时:0.00分/2.38分 | step: 13240 | performance: 109.3 | accuracy: 0.33 | loss: 0.68
update:1660/2000, 耗时:0.00分/2.38分 | step: 13280 | performance: 103.0 | accuracy: 0.33 | loss: 0.44
update:1665/2000, 耗时:0.00分/2.39分 | step: 13320 | performance: 99.7 | accuracy: 0.33 | loss: 0.29
update:1670/2000, 耗时:0.00分/2.40分 | step: 13360 | performance: 116.3 | accuracy: 0.33 | loss: 0.62
update:1675/2000, 耗时:0.00分/2.40分 | step: 13400 | performance: 155.5 | accuracy: 0.33 | loss: 0.63
update:1680/2000, 耗时:0.00分/2.41分 | step: 13440 | performance: 212.7 | accuracy: 0.33 | loss: 0.40
update:1685/2000, 耗时:0.00分/2.42分 | step: 13480 | performance: 214.5 | accuracy: 0.33 | loss: 0.09
update:1690/2000, 耗时:0.00分/2.43分 | step: 13520 | performance: 200.3 | accuracy: 0.33 | loss: 0.55
update:1695/2000, 耗时:0.00分/2.43分 | step: 13560 | performance: 256.3 | accuracy: 0.33 | loss: 0.37
update:1700/2000, 耗时:0.00分/2.44分 | step: 13600 | performance: 312.5 | accuracy: 0.33 | loss: 0.33
update:1705/2000, 耗时:0.00分/2.45分 | step: 13640 | performance: 418.1 | accuracy: 0.34 | loss: 0.73
update:1710/2000, 耗时:0.00分/2.45分 | step: 13680 | performance: 533.5 | accuracy: 0.34 | loss: 0.35
update:1715/2000, 耗时:0.00分/2.46分 | step: 13720 | performance: 596.5 | accuracy: 0.34 | loss: 0.48
update:1720/2000, 耗时:0.00分/2.47分 | step: 13760 | performance: 1319.7 | accuracy: 0.34 | loss: 1.13
update:1725/2000, 耗时:0.00分/2.47分 | step: 13800 | performance: 1036.6 | accuracy: 0.34 | loss: 1.57
update:1730/2000, 耗时:0.00分/2.48分 | step: 13840 | performance: 672.2 | accuracy: 0.34 | loss: 0.78
update:1735/2000, 耗时:0.00分/2.49分 | step: 13880 | performance: 743.0 | accuracy: 0.34 | loss: 1.07
update:1740/2000, 耗时:0.00分/2.50分 | step: 13920 | performance: 725.7 | accuracy: 0.34 | loss: 0.93
update:1745/2000, 耗时:0.00分/2.50分 | step: 13960 | performance: 1002.2 | accuracy: 0.34 | loss: 1.17
update:1750/2000, 耗时:0.00分/2.51分 | step: 14000 | performance: 1168.8 | accuracy: 0.34 | loss: 0.93
update:1755/2000, 耗时:0.00分/2.52分 | step: 14040 | performance: 1172.3 | accuracy: 0.34 | loss: 0.46
update:1760/2000, 耗时:0.00分/2.52分 | step: 14080 | performance: 1373.4 | accuracy: 0.34 | loss: 1.28
update:1765/2000, 耗时:0.00分/2.53分 | step: 14120 | performance: 1608.0 | accuracy: 0.34 | loss: 0.69
update:1770/2000, 耗时:0.00分/2.54分 | step: 14160 | performance: 1640.8 | accuracy: 0.34 | loss: 0.68
update:1775/2000, 耗时:0.00分/2.54分 | step: 14200 | performance: 1221.2 | accuracy: 0.34 | loss: 0.76
update:1780/2000, 耗时:0.00分/2.55分 | step: 14240 | performance: 1489.0 | accuracy: 0.34 | loss: 0.46
update:1785/2000, 耗时:0.00分/2.56分 | step: 14280 | performance: 1439.9 | accuracy: 0.34 | loss: 0.53
update:1790/2000, 耗时:0.00分/2.57分 | step: 14320 | performance: 1767.7 | accuracy: 0.34 | loss: 0.17
update:1795/2000, 耗时:0.00分/2.57分 | step: 14360 | performance: 2016.8 | accuracy: 0.34 | loss: 0.28
update:1800/2000, 耗时:0.00分/2.58分 | step: 14400 | performance: 1949.4 | accuracy: 0.34 | loss: 0.46
update:1805/2000, 耗时:0.00分/2.59分 | step: 14440 | performance: 2608.7 | accuracy: 0.35 | loss: 0.81
update:1810/2000, 耗时:0.00分/2.59分 | step: 14480 | performance: 2654.0 | accuracy: 0.35 | loss: 2.04
update:1815/2000, 耗时:0.00分/2.60分 | step: 14520 | performance: 1531.4 | accuracy: 0.35 | loss: 1.42
update:1820/2000, 耗时:0.00分/2.61分 | step: 14560 | performance: 1207.7 | accuracy: 0.35 | loss: 1.31
update:1825/2000, 耗时:0.00分/2.61分 | step: 14600 | performance: 1217.2 | accuracy: 0.35 | loss: 0.78
update:1830/2000, 耗时:0.00分/2.62分 | step: 14640 | performance: 1220.4 | accuracy: 0.34 | loss: 0.58
update:1835/2000, 耗时:0.00分/2.63分 | step: 14680 | performance: 1073.3 | accuracy: 0.34 | loss: 0.57
update:1840/2000, 耗时:0.00分/2.64分 | step: 14720 | performance: 1669.6 | accuracy: 0.35 | loss: 0.73
update:1845/2000, 耗时:0.00分/2.64分 | step: 14760 | performance: 1946.1 | accuracy: 0.35 | loss: 0.26
update:1850/2000, 耗时:0.00分/2.65分 | step: 14800 | performance: 2518.8 | accuracy: 0.35 | loss: 0.62
update:1855/2000, 耗时:0.00分/2.66分 | step: 14840 | performance: 2224.0 | accuracy: 0.35 | loss: 0.10
update:1860/2000, 耗时:0.00分/2.66分 | step: 14880 | performance: 2573.7 | accuracy: 0.35 | loss: 0.47
update:1865/2000, 耗时:0.00分/2.67分 | step: 14920 | performance: 2469.7 | accuracy: 0.35 | loss: 0.25
update:1870/2000, 耗时:0.00分/2.68分 | step: 14960 | performance: 2047.5 | accuracy: 0.35 | loss: 1.13
update:1875/2000, 耗时:0.00分/2.69分 | step: 15000 | performance: 1980.2 | accuracy: 0.35 | loss: 0.53
update:1880/2000, 耗时:0.00分/2.69分 | step: 15040 | performance: 2639.3 | accuracy: 0.35 | loss: 0.64
update:1885/2000, 耗时:0.00分/2.70分 | step: 15080 | performance: 3068.8 | accuracy: 0.35 | loss: 0.41
update:1890/2000, 耗时:0.00分/2.71分 | step: 15120 | performance: 3045.6 | accuracy: 0.35 | loss: 0.52
update:1895/2000, 耗时:0.00分/2.71分 | step: 15160 | performance: 3156.5 | accuracy: 0.35 | loss: 0.43
update:1900/2000, 耗时:0.00分/2.72分 | step: 15200 | performance: 3038.6 | accuracy: 0.35 | loss: 0.16
update:1905/2000, 耗时:0.00分/2.73分 | step: 15240 | performance: 3087.6 | accuracy: 0.35 | loss: 0.46
update:1910/2000, 耗时:0.00分/2.74分 | step: 15280 | performance: 3780.7 | accuracy: 0.35 | loss: 0.68
update:1915/2000, 耗时:0.00分/2.74分 | step: 15320 | performance: 4021.7 | accuracy: 0.35 | loss: 0.81
update:1920/2000, 耗时:0.00分/2.75分 | step: 15360 | performance: 3433.9 | accuracy: 0.35 | loss: 0.71
update:1925/2000, 耗时:0.00分/2.76分 | step: 15400 | performance: 2849.3 | accuracy: 0.35 | loss: 0.42
update:1930/2000, 耗时:0.00分/2.76分 | step: 15440 | performance: 2393.5 | accuracy: 0.35 | loss: 0.75
update:1935/2000, 耗时:0.00分/2.77分 | step: 15480 | performance: 2309.2 | accuracy: 0.35 | loss: 0.43
update:1940/2000, 耗时:0.00分/2.78分 | step: 15520 | performance: 2519.3 | accuracy: 0.35 | loss: 0.64
update:1945/2000, 耗时:0.00分/2.78分 | step: 15560 | performance: 2581.7 | accuracy: 0.35 | loss: 0.76
update:1950/2000, 耗时:0.00分/2.79分 | step: 15600 | performance: 2294.1 | accuracy: 0.35 | loss: 0.66
update:1955/2000, 耗时:0.00分/2.80分 | step: 15640 | performance: 2152.9 | accuracy: 0.35 | loss: 0.33
update:1960/2000, 耗时:0.00分/2.81分 | step: 15680 | performance: 2232.3 | accuracy: 0.35 | loss: 0.29
update:1965/2000, 耗时:0.00分/2.81分 | step: 15720 | performance: 2228.8 | accuracy: 0.35 | loss: 0.65
update:1970/2000, 耗时:0.00分/2.82分 | step: 15760 | performance: 2533.8 | accuracy: 0.35 | loss: 0.40
update:1975/2000, 耗时:0.00分/2.83分 | step: 15800 | performance: 2926.3 | accuracy: 0.35 | loss: 0.76
update:1980/2000, 耗时:0.00分/2.83分 | step: 15840 | performance: 1929.9 | accuracy: 0.34 | loss: 1.96
update:1985/2000, 耗时:0.00分/2.84分 | step: 15880 | performance: 2256.6 | accuracy: 0.34 | loss: 1.34
update:1990/2000, 耗时:0.00分/2.85分 | step: 15920 | performance: 1650.7 | accuracy: 0.34 | loss: 1.12
update:1995/2000, 耗时:0.00分/2.86分 | step: 15960 | performance: 1246.4 | accuracy: 0.34 | loss: 0.94
  0%|          | 0/403 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/2.86分 | step: 16000 | performance: 1056.3 | accuracy: 0.34 | loss: 0.52
----------------------------------------finished----------------------------------------
==================================================
2023-01-04T12:00:00 | *** START BACKTEST ***
2023-01-04T12:00:00 | current balance = 1000.00
==================================================
100%|| 403/403 [00:00<00:00, 44772.72it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1371.81
2023-07-24T12:00:00 | net performance [%] = 37.1806
2023-07-24T12:00:00 | number of trades [#] = 98
==================================================
Trial 35 Complete [00h 03m 18s]
net_wealth: 1371.8059540474624

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 04h 45m 00s

Search: Running Trial #36

Value             |Best Value So Far |Hyperparameter
3                 |7                 |horizon
730               |730               |lookback
True              |False             |MarketFactor
20                |14                |lags
0.9               |0.7               |gamma
32                |32                |batch_size
7                 |32                |n_step
0.85              |0.92              |gae_lambda
1                 |0.1               |gradient_clip_norm
5                 |5                 |epochs
0.001             |0.0001            |actor_lr
0.0001            |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4298.000000   4301.000000
mean      0.000435    20113.607657  ...   20180.392273  20169.373185
std       0.027833    16040.642334  ...   16078.781641  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7741.750122   7730.930176
50%       0.000642    11571.842969  ...   11754.949707  11751.469727
75%       0.011590    29894.706152  ...   30015.383301  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 02:48:23.375566: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with on22eAPI Dee00p Neura2l3-0 2N3-077etw--22ork Librar20y (23-07-28 02:48:23.o8 2202023-07-n2e3D075711:8N  0I 2N:t)ensorflow/c42:48o:828:  t032.r2373oe/p 5use 3731: I tensor-the .lf07-23flow/co75r8 02:4eoal6t/lo8fo:23rm/.p59: Iw: i4tlenscporu_8:23.37ffeatulow/corere/pla_tfor5m/cpg65uu_fea35:7 atu5I tensorflr7eow/r_dcor3gua3.:ng CPU instructice/platform/cpu_ford.ns inceact  Ic:1u42performance-c]rr eiTht_iisgc:21 0a23Tenu4-sorFloarwd2a. tfol oc02tensopcr0] 2bf 7rierT-ha28 mn3isl arTye-ow0n0 2:is op7s4t/imizoedrc-8 owFil:o/twh cone2rAPeI  2D38.eep/ pp0u3760la2t9i:ob_tffon41s:4  rieatn Naeur:A2]m :yVr eTh4ui/cp _XIrsa lu _tefnsoo rN e8pAttifm:VeaXilowoitzedwrks  Luirb2r
2T/3coTrgeae.neursa 3w7i6y1o4rro9 tFl/opl:e d(aoh  .Icnwot tenascof_nbeAg lbei thoermnuaamrf nrd.cc/PeryD::in low/cNIN )oo1t 14 42toi su ]o r2]D epTse/plTchpehhepiaitfus T eestr _opnimifzeo rmNstor eed uwrrTFhiath eeeat/ucpl lrae_tginuards.uo_ofronnoee FNloasw, wAtPu b Ibiccina rn:ertfDoeweopr lraNrky e1e42]lLoi_bg uiilbd Teewruiannasrogry (r FulrodCoswnalP  yU i noipst set.io pwcNc:eD1Nrutwiotm tTr4N2) htoiki zL iucesd brhismei ]t twihzaeiton rTy  seThenissoh or Ftn Tflo lowe(nosnoreFlloweiAnP op werIf bioDDeN neNi)drmanpcb ig  ew-icrtNheC PUn airiyhuenr aonnteAoPIt   l iNa ryD escuaepppr oNpeiasle  etthoeuprerucatrsa ti tfwoolpltoiwmiinzge dCrlio nPat Nsete cioownrsUk i:s   oopmAViorkt L pnismitn pi iLXi lrzuediebwrcb rwitAaerr ahrryf i(l VtfioorymX2a
gs oTnos.tahn ee(
onnceDeNN-nDo) caNb ltrNit o nueAoi)nsiPcn eeeI alpAP D  tthheoI eteeep eDrmp  iNnoe u o ftoesper foeltlatruroawling C i NhmoePU nisnesNatt: r u nAcVeX-cwhfollerc oewiunrrittgio AaVlro  icka NoXp2eLeCtnw
sriaoT PtrokUbra   ioienable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
lin performance-critr y (oneoLnisinstrupb,cerra rDebuilary (ondti TNetions inoennsDNNs:  AVX AVXo 2)
 Ttperforo usmance-crriticaeo enable them in other  caNlFoper opllt e)r ahoe fpaotwol witherit thiaotiloonswto,no iuss :en ree aptnhg Ceb ufipProol lUl sA: d AVX AVXoV XT2p
rTiwe ioa ns oirFAVX2nsntg 
ertlCowneP wU iable ttTh huecim ctnhse appropriate compiler flags.
 inoottmipi ructions in peelneronrfs i oflags.
rmance-criticn peraablfl other operations eo,o rma rebuild TensorFlow with the appropriate compiler flags.
perations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
them in other operationnce-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
s, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 02:48:23.998071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:48:24.004385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:48:24.004541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:48:24.016293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:48:24.031226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:48:24.042988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:48:24.045769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:48:24.057494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   280 | performance: 0.8 | accuracy: 0.26 | loss: 0.80
update: 10/2000, 耗时:0.00分/0.05分 | step:   560 | performance: 0.8 | accuracy: 0.27 | loss: 1.07
update: 15/2000, 耗时:0.00分/0.06分 | step:   840 | performance: 0.8 | accuracy: 0.27 | loss: 0.38
update: 20/2000, 耗时:0.00分/0.08分 | step:  1120 | performance: 1.2 | accuracy: 0.26 | loss: 1.97
update: 25/2000, 耗时:0.00分/0.09分 | step:  1400 | performance: 2.4 | accuracy: 0.32 | loss: 1.88
update: 30/2000, 耗时:0.00分/0.11分 | step:  1680 | performance: 2.1 | accuracy: 0.34 | loss: 1.52
update: 35/2000, 耗时:0.00分/0.12分 | step:  1960 | performance: 1.6 | accuracy: 0.36 | loss: 2.25
update: 40/2000, 耗时:0.00分/0.14分 | step:  2240 | performance: 1.9 | accuracy: 0.38 | loss: 1.23
update: 45/2000, 耗时:0.00分/0.15分 | step:  2520 | performance: 1.6 | accuracy: 0.37 | loss: 4.10
update: 50/2000, 耗时:0.00分/0.17分 | step:  2800 | performance: 1.6 | accuracy: 0.36 | loss: 1.04
update: 55/2000, 耗时:0.00分/0.18分 | step:  3080 | performance: 1.6 | accuracy: 0.36 | loss: 0.67
update: 60/2000, 耗时:0.00分/0.20分 | step:  3360 | performance: 2.6 | accuracy: 0.36 | loss: 1.06
update: 65/2000, 耗时:0.00分/0.22分 | step:  3640 | performance: 3.4 | accuracy: 0.38 | loss: 1.01
update: 70/2000, 耗时:0.00分/0.23分 | step:  3920 | performance: 8.7 | accuracy: 0.41 | loss: 1.93
update: 75/2000, 耗时:0.00分/0.25分 | step:  4200 | performance: 7.3 | accuracy: 0.39 | loss: 0.20
update: 80/2000, 耗时:0.00分/0.26分 | step:  4480 | performance: 5.1 | accuracy: 0.37 | loss: 0.17
update: 85/2000, 耗时:0.00分/0.28分 | step:  4760 | performance: 7.1 | accuracy: 0.36 | loss: 0.30
update: 90/2000, 耗时:0.00分/0.29分 | step:  5040 | performance: 5.8 | accuracy: 0.34 | loss: 0.05
update: 95/2000, 耗时:0.00分/0.31分 | step:  5320 | performance: 5.8 | accuracy: 0.33 | loss: 0.01
update:100/2000, 耗时:0.00分/0.33分 | step:  5600 | performance: 5.8 | accuracy: 0.31 | loss: 0.01
update:105/2000, 耗时:0.00分/0.34分 | step:  5880 | performance: 5.8 | accuracy: 0.30 | loss: 0.10
update:110/2000, 耗时:0.00分/0.36分 | step:  6160 | performance: 5.8 | accuracy: 0.29 | loss: 0.13
update:115/2000, 耗时:0.00分/0.37分 | step:  6440 | performance: 5.8 | accuracy: 0.28 | loss: 0.19
update:120/2000, 耗时:0.00分/0.39分 | step:  6720 | performance: 5.8 | accuracy: 0.27 | loss: 0.33
update:125/2000, 耗时:0.00分/0.41分 | step:  7000 | performance: 5.8 | accuracy: 0.26 | loss: 0.00
update:130/2000, 耗时:0.00分/0.42分 | step:  7280 | performance: 5.8 | accuracy: 0.26 | loss: 0.06
update:135/2000, 耗时:0.00分/0.44分 | step:  7560 | performance: 6.1 | accuracy: 0.25 | loss: 0.72
update:140/2000, 耗时:0.00分/0.45分 | step:  7840 | performance: 8.6 | accuracy: 0.26 | loss: 1.01
update:145/2000, 耗时:0.00分/0.47分 | step:  8120 | performance: 7.9 | accuracy: 0.25 | loss: 0.23
update:150/2000, 耗时:0.00分/0.49分 | step:  8400 | performance: 8.7 | accuracy: 0.25 | loss: 0.00
update:155/2000, 耗时:0.00分/0.50分 | step:  8680 | performance: 8.7 | accuracy: 0.24 | loss: 0.03
update:160/2000, 耗时:0.00分/0.52分 | step:  8960 | performance: 4.7 | accuracy: 0.25 | loss: 1.90
update:165/2000, 耗时:0.00分/0.53分 | step:  9240 | performance: 6.5 | accuracy: 0.25 | loss: 2.75
update:170/2000, 耗时:0.00分/0.55分 | step:  9520 | performance: 13.1 | accuracy: 0.27 | loss: 3.77
update:175/2000, 耗时:0.00分/0.57分 | step:  9800 | performance: 14.9 | accuracy: 0.27 | loss: 1.09
update:180/2000, 耗时:0.00分/0.58分 | step: 10080 | performance: 13.3 | accuracy: 0.27 | loss: 0.26
update:185/2000, 耗时:0.00分/0.60分 | step: 10360 | performance: 13.4 | accuracy: 0.27 | loss: 0.00
update:190/2000, 耗时:0.00分/0.62分 | step: 10640 | performance: 13.3 | accuracy: 0.26 | loss: 0.38
update:195/2000, 耗时:0.00分/0.63分 | step: 10920 | performance: 14.2 | accuracy: 0.26 | loss: 0.27
update:200/2000, 耗时:0.00分/0.65分 | step: 11200 | performance: 17.0 | accuracy: 0.26 | loss: 0.01
update:205/2000, 耗时:0.00分/0.67分 | step: 11480 | performance: 17.0 | accuracy: 0.26 | loss: 0.19
update:210/2000, 耗时:0.00分/0.69分 | step: 11760 | performance: 16.7 | accuracy: 0.26 | loss: 0.00
update:215/2000, 耗时:0.00分/0.70分 | step: 12040 | performance: 16.7 | accuracy: 0.25 | loss: 0.00
update:220/2000, 耗时:0.00分/0.72分 | step: 12320 | performance: 16.7 | accuracy: 0.25 | loss: 0.00
update:225/2000, 耗时:0.00分/0.74分 | step: 12600 | performance: 16.8 | accuracy: 0.24 | loss: -0.00
update:230/2000, 耗时:0.00分/0.75分 | step: 12880 | performance: 16.6 | accuracy: 0.24 | loss: 0.00
update:235/2000, 耗时:0.00分/0.77分 | step: 13160 | performance: 16.6 | accuracy: 0.23 | loss: 0.00
update:240/2000, 耗时:0.00分/0.79分 | step: 13440 | performance: 16.6 | accuracy: 0.23 | loss: 0.01
update:245/2000, 耗时:0.00分/0.80分 | step: 13720 | performance: 16.6 | accuracy: 0.22 | loss: 0.00
update:250/2000, 耗时:0.00分/0.82分 | step: 14000 | performance: 13.8 | accuracy: 0.22 | loss: 0.47
update:255/2000, 耗时:0.00分/0.84分 | step: 14280 | performance: 13.8 | accuracy: 0.21 | loss: 0.00
update:260/2000, 耗时:0.00分/0.85分 | step: 14560 | performance: 13.8 | accuracy: 0.21 | loss: 0.00
update:265/2000, 耗时:0.00分/0.87分 | step: 14840 | performance: 13.8 | accuracy: 0.21 | loss: 0.00
update:270/2000, 耗时:0.00分/0.89分 | step: 15120 | performance: 13.8 | accuracy: 0.20 | loss: 0.09
update:275/2000, 耗时:0.00分/0.91分 | step: 15400 | performance: 13.8 | accuracy: 0.20 | loss: 0.03
update:280/2000, 耗时:0.00分/0.92分 | step: 15680 | performance: 20.8 | accuracy: 0.20 | loss: 2.89
update:285/2000, 耗时:0.00分/0.94分 | step: 15960 | performance: 21.2 | accuracy: 0.20 | loss: 0.01
update:290/2000, 耗时:0.00分/0.96分 | step: 16240 | performance: 20.2 | accuracy: 0.20 | loss: 0.09
update:295/2000, 耗时:0.00分/0.97分 | step: 16520 | performance: 19.2 | accuracy: 0.20 | loss: 0.69
update:300/2000, 耗时:0.00分/0.99分 | step: 16800 | performance: 13.5 | accuracy: 0.19 | loss: 0.56
update:305/2000, 耗时:0.00分/1.01分 | step: 17080 | performance: 19.4 | accuracy: 0.20 | loss: 1.55
update:310/2000, 耗时:0.00分/1.03分 | step: 17360 | performance: 20.7 | accuracy: 0.20 | loss: 0.59
update:315/2000, 耗时:0.00分/1.04分 | step: 17640 | performance: 16.6 | accuracy: 0.20 | loss: 0.11
update:320/2000, 耗时:0.00分/1.06分 | step: 17920 | performance: 18.9 | accuracy: 0.20 | loss: 0.46
update:325/2000, 耗时:0.00分/1.08分 | step: 18200 | performance: 26.0 | accuracy: 0.20 | loss: 3.30
update:330/2000, 耗时:0.00分/1.09分 | step: 18480 | performance: 29.1 | accuracy: 0.21 | loss: 1.83
update:335/2000, 耗时:0.00分/1.11分 | step: 18760 | performance: 19.8 | accuracy: 0.21 | loss: 0.58
update:340/2000, 耗时:0.00分/1.13分 | step: 19040 | performance: 18.8 | accuracy: 0.21 | loss: 0.05
update:345/2000, 耗时:0.00分/1.14分 | step: 19320 | performance: 14.1 | accuracy: 0.21 | loss: 0.94
update:350/2000, 耗时:0.00分/1.16分 | step: 19600 | performance: 14.2 | accuracy: 0.21 | loss: 3.51
update:355/2000, 耗时:0.00分/1.18分 | step: 19880 | performance: 15.5 | accuracy: 0.22 | loss: 2.46
update:360/2000, 耗时:0.00分/1.20分 | step: 20160 | performance: 12.2 | accuracy: 0.22 | loss: 1.02
update:365/2000, 耗时:0.00分/1.21分 | step: 20440 | performance: 3.4 | accuracy: 0.22 | loss: 2.11
update:370/2000, 耗时:0.00分/1.23分 | step: 20720 | performance: 4.4 | accuracy: 0.22 | loss: 1.38
update:375/2000, 耗时:0.00分/1.25分 | step: 21000 | performance: 3.8 | accuracy: 0.23 | loss: 0.89
update:380/2000, 耗时:0.00分/1.26分 | step: 21280 | performance: 3.2 | accuracy: 0.23 | loss: 1.00
update:385/2000, 耗时:0.00分/1.28分 | step: 21560 | performance: 3.7 | accuracy: 0.23 | loss: 0.34
update:390/2000, 耗时:0.00分/1.30分 | step: 21840 | performance: 3.7 | accuracy: 0.23 | loss: 0.56
update:395/2000, 耗时:0.00分/1.31分 | step: 22120 | performance: 5.5 | accuracy: 0.24 | loss: 2.87
update:400/2000, 耗时:0.00分/1.33分 | step: 22400 | performance: 6.1 | accuracy: 0.24 | loss: 1.72
update:405/2000, 耗时:0.00分/1.35分 | step: 22680 | performance: 4.0 | accuracy: 0.24 | loss: 0.85
update:410/2000, 耗时:0.00分/1.37分 | step: 22960 | performance: 4.2 | accuracy: 0.24 | loss: 4.21
update:415/2000, 耗时:0.00分/1.38分 | step: 23240 | performance: 7.1 | accuracy: 0.25 | loss: 1.24
update:420/2000, 耗时:0.00分/1.40分 | step: 23520 | performance: 8.3 | accuracy: 0.25 | loss: 0.68
update:425/2000, 耗时:0.00分/1.42分 | step: 23800 | performance: 8.1 | accuracy: 0.26 | loss: 3.02
update:430/2000, 耗时:0.00分/1.43分 | step: 24080 | performance: 7.0 | accuracy: 0.26 | loss: 1.69
update:435/2000, 耗时:0.00分/1.45分 | step: 24360 | performance: 13.9 | accuracy: 0.26 | loss: 2.84
update:440/2000, 耗时:0.00分/1.47分 | step: 24640 | performance: 13.2 | accuracy: 0.27 | loss: 3.95
update:445/2000, 耗时:0.00分/1.49分 | step: 24920 | performance: 14.5 | accuracy: 0.27 | loss: 0.97
step: 25137 | worker_0@n_step_6: average total_reward after train data exhaustion : 128.3 | max total_reward: 128.3
step: 25138 | worker_1@n_step_6: average total_reward after train data exhaustion : 136.9 | max total_reward: 145.5
step: 25139 | worker_2@n_step_6: average total_reward after train data exhaustion : 124.0 | max total_reward: 145.5
step: 25140 | worker_3@n_step_6: average total_reward after train data exhaustion : 111.9 | max total_reward: 145.5
step: 25141 | worker_4@n_step_6: average total_reward after train data exhaustion : 102.7 | max total_reward: 145.5
step: 25142 | worker_5@n_step_6: average total_reward after train data exhaustion : 101.4 | max total_reward: 145.5
step: 25143 | worker_6@n_step_6: average total_reward after train data exhaustion : 102.3 | max total_reward: 145.5
step: 25144 | worker_7@n_step_6: average total_reward after train data exhaustion : 103.7 | max total_reward: 145.5
Saving PPO weights in both H5 format and checkpoint @ update:449 
update:450/2000, 耗时:0.00分/1.51分 | step: 25200 | performance: 1.0 | accuracy: 0.29 | loss: 1.41
update:455/2000, 耗时:0.00分/1.52分 | step: 25480 | performance: 1.0 | accuracy: 0.48 | loss: 1.48
update:460/2000, 耗时:0.00分/1.54分 | step: 25760 | performance: 1.0 | accuracy: 0.47 | loss: 0.69
update:465/2000, 耗时:0.00分/1.56分 | step: 26040 | performance: 1.1 | accuracy: 0.50 | loss: 0.87
update:470/2000, 耗时:0.00分/1.57分 | step: 26320 | performance: 4.8 | accuracy: 0.54 | loss: 1.66
update:475/2000, 耗时:0.00分/1.59分 | step: 26600 | performance: 8.3 | accuracy: 0.55 | loss: 0.83
update:480/2000, 耗时:0.00分/1.61分 | step: 26880 | performance: 6.2 | accuracy: 0.53 | loss: 1.61
update:485/2000, 耗时:0.00分/1.63分 | step: 27160 | performance: 7.4 | accuracy: 0.53 | loss: 1.16
update:490/2000, 耗时:0.00分/1.64分 | step: 27440 | performance: 8.6 | accuracy: 0.52 | loss: 1.07
update:495/2000, 耗时:0.00分/1.66分 | step: 27720 | performance: 6.0 | accuracy: 0.50 | loss: 2.98
update:500/2000, 耗时:0.00分/1.68分 | step: 28000 | performance: 6.4 | accuracy: 0.48 | loss: 1.08
update:505/2000, 耗时:0.00分/1.70分 | step: 28280 | performance: 6.0 | accuracy: 0.48 | loss: 0.79
update:510/2000, 耗时:0.00分/1.71分 | step: 28560 | performance: 3.1 | accuracy: 0.46 | loss: 0.67
update:515/2000, 耗时:0.00分/1.73分 | step: 28840 | performance: 2.6 | accuracy: 0.45 | loss: 2.13
update:520/2000, 耗时:0.00分/1.75分 | step: 29120 | performance: 0.9 | accuracy: 0.44 | loss: 1.77
update:525/2000, 耗时:0.00分/1.77分 | step: 29400 | performance: 1.0 | accuracy: 0.44 | loss: 2.54
update:530/2000, 耗时:0.00分/1.79分 | step: 29680 | performance: 0.4 | accuracy: 0.43 | loss: 4.86
update:535/2000, 耗时:0.00分/1.80分 | step: 29960 | performance: 0.3 | accuracy: 0.43 | loss: 2.36
update:540/2000, 耗时:0.00分/1.82分 | step: 30240 | performance: 0.6 | accuracy: 0.43 | loss: 1.25
update:545/2000, 耗时:0.00分/1.84分 | step: 30520 | performance: 0.5 | accuracy: 0.43 | loss: 7.41
update:550/2000, 耗时:0.00分/1.86分 | step: 30800 | performance: 0.6 | accuracy: 0.43 | loss: 0.83
update:555/2000, 耗时:0.00分/1.87分 | step: 31080 | performance: 0.5 | accuracy: 0.44 | loss: 1.83
update:560/2000, 耗时:0.00分/1.89分 | step: 31360 | performance: 1.2 | accuracy: 0.45 | loss: 3.42
update:565/2000, 耗时:0.00分/1.91分 | step: 31640 | performance: 1.5 | accuracy: 0.46 | loss: 3.79
update:570/2000, 耗时:0.00分/1.93分 | step: 31920 | performance: 0.9 | accuracy: 0.46 | loss: 1.25
update:575/2000, 耗时:0.00分/1.95分 | step: 32200 | performance: 1.5 | accuracy: 0.46 | loss: 5.70
update:580/2000, 耗时:0.00分/1.96分 | step: 32480 | performance: 1.9 | accuracy: 0.47 | loss: 0.91
update:585/2000, 耗时:0.00分/1.98分 | step: 32760 | performance: 1.9 | accuracy: 0.47 | loss: 3.76
update:590/2000, 耗时:0.00分/2.00分 | step: 33040 | performance: 1.1 | accuracy: 0.46 | loss: 1.61
update:595/2000, 耗时:0.00分/2.02分 | step: 33320 | performance: 0.8 | accuracy: 0.46 | loss: 2.32
update:600/2000, 耗时:0.00分/2.03分 | step: 33600 | performance: 0.8 | accuracy: 0.46 | loss: 1.87
update:605/2000, 耗时:0.00分/2.05分 | step: 33880 | performance: 3.4 | accuracy: 0.47 | loss: 4.82
update:610/2000, 耗时:0.00分/2.07分 | step: 34160 | performance: 3.6 | accuracy: 0.47 | loss: 2.85
update:615/2000, 耗时:0.00分/2.09分 | step: 34440 | performance: 2.6 | accuracy: 0.47 | loss: 0.74
update:620/2000, 耗时:0.00分/2.10分 | step: 34720 | performance: 1.3 | accuracy: 0.47 | loss: 0.30
update:625/2000, 耗时:0.00分/2.12分 | step: 35000 | performance: 1.1 | accuracy: 0.46 | loss: 1.64
update:630/2000, 耗时:0.00分/2.13分 | step: 35280 | performance: 1.0 | accuracy: 0.46 | loss: 0.72
update:635/2000, 耗时:0.00分/2.15分 | step: 35560 | performance: 1.2 | accuracy: 0.47 | loss: 1.60
update:640/2000, 耗时:0.00分/2.17分 | step: 35840 | performance: 1.3 | accuracy: 0.47 | loss: 0.86
update:645/2000, 耗时:0.00分/2.18分 | step: 36120 | performance: 0.8 | accuracy: 0.46 | loss: 2.95
update:650/2000, 耗时:0.00分/2.20分 | step: 36400 | performance: 0.7 | accuracy: 0.46 | loss: 3.50
update:655/2000, 耗时:0.00分/2.22分 | step: 36680 | performance: 0.9 | accuracy: 0.46 | loss: 1.79
update:660/2000, 耗时:0.00分/2.23分 | step: 36960 | performance: 0.9 | accuracy: 0.45 | loss: 1.85
update:665/2000, 耗时:0.00分/2.25分 | step: 37240 | performance: 1.0 | accuracy: 0.46 | loss: 0.63
update:670/2000, 耗时:0.00分/2.27分 | step: 37520 | performance: 0.6 | accuracy: 0.45 | loss: 1.34
update:675/2000, 耗时:0.00分/2.28分 | step: 37800 | performance: 0.3 | accuracy: 0.45 | loss: 1.32
update:680/2000, 耗时:0.00分/2.30分 | step: 38080 | performance: 0.2 | accuracy: 0.44 | loss: 2.94
update:685/2000, 耗时:0.00分/2.32分 | step: 38360 | performance: 0.1 | accuracy: 0.44 | loss: 4.90
update:690/2000, 耗时:0.00分/2.33分 | step: 38640 | performance: 0.0 | accuracy: 0.44 | loss: 1.91
update:695/2000, 耗时:0.00分/2.35分 | step: 38920 | performance: 0.0 | accuracy: 0.44 | loss: 7.20
update:700/2000, 耗时:0.00分/2.37分 | step: 39200 | performance: 0.0 | accuracy: 0.44 | loss: 2.25
update:705/2000, 耗时:0.00分/2.38分 | step: 39480 | performance: 0.0 | accuracy: 0.44 | loss: 4.73
update:710/2000, 耗时:0.00分/2.40分 | step: 39760 | performance: 0.0 | accuracy: 0.43 | loss: 1.33
update:715/2000, 耗时:0.00分/2.42分 | step: 40040 | performance: 0.0 | accuracy: 0.44 | loss: 0.73
update:720/2000, 耗时:0.00分/2.43分 | step: 40320 | performance: 0.0 | accuracy: 0.44 | loss: 8.85
update:725/2000, 耗时:0.00分/2.45分 | step: 40600 | performance: 0.0 | accuracy: 0.44 | loss: 1.34
update:730/2000, 耗时:0.00分/2.47分 | step: 40880 | performance: 0.0 | accuracy: 0.44 | loss: 1.54
update:735/2000, 耗时:0.00分/2.48分 | step: 41160 | performance: 0.0 | accuracy: 0.44 | loss: 3.09
update:740/2000, 耗时:0.00分/2.50分 | step: 41440 | performance: 0.1 | accuracy: 0.45 | loss: 1.92
update:745/2000, 耗时:0.00分/2.52分 | step: 41720 | performance: 0.1 | accuracy: 0.45 | loss: 4.81
update:750/2000, 耗时:0.00分/2.53分 | step: 42000 | performance: 0.0 | accuracy: 0.45 | loss: 1.47
update:755/2000, 耗时:0.00分/2.55分 | step: 42280 | performance: 0.0 | accuracy: 0.44 | loss: 2.44
update:760/2000, 耗时:0.00分/2.57分 | step: 42560 | performance: 0.0 | accuracy: 0.44 | loss: 0.56
update:765/2000, 耗时:0.00分/2.58分 | step: 42840 | performance: 0.0 | accuracy: 0.45 | loss: 2.22
update:770/2000, 耗时:0.00分/2.60分 | step: 43120 | performance: 0.0 | accuracy: 0.44 | loss: 0.52
update:775/2000, 耗时:0.00分/2.61分 | step: 43400 | performance: 0.0 | accuracy: 0.44 | loss: 1.18
update:780/2000, 耗时:0.00分/2.63分 | step: 43680 | performance: 0.0 | accuracy: 0.44 | loss: 1.35
update:785/2000, 耗时:0.00分/2.65分 | step: 43960 | performance: 0.0 | accuracy: 0.44 | loss: 1.94
update:790/2000, 耗时:0.00分/2.66分 | step: 44240 | performance: 0.0 | accuracy: 0.45 | loss: 2.29
update:795/2000, 耗时:0.00分/2.68分 | step: 44520 | performance: 0.0 | accuracy: 0.45 | loss: 6.28
update:800/2000, 耗时:0.00分/2.70分 | step: 44800 | performance: 0.1 | accuracy: 0.45 | loss: 3.93
update:805/2000, 耗时:0.00分/2.71分 | step: 45080 | performance: 0.0 | accuracy: 0.45 | loss: 0.96
update:810/2000, 耗时:0.00分/2.73分 | step: 45360 | performance: 0.1 | accuracy: 0.45 | loss: 1.72
update:815/2000, 耗时:0.00分/2.74分 | step: 45640 | performance: 0.1 | accuracy: 0.45 | loss: 3.86
update:820/2000, 耗时:0.00分/2.76分 | step: 45920 | performance: 0.0 | accuracy: 0.45 | loss: 0.46
update:825/2000, 耗时:0.00分/2.77分 | step: 46200 | performance: 0.1 | accuracy: 0.45 | loss: 2.63
update:830/2000, 耗时:0.00分/2.79分 | step: 46480 | performance: 0.1 | accuracy: 0.46 | loss: 5.07
update:835/2000, 耗时:0.00分/2.80分 | step: 46760 | performance: 0.2 | accuracy: 0.46 | loss: 1.02
update:840/2000, 耗时:0.00分/2.82分 | step: 47040 | performance: 0.2 | accuracy: 0.46 | loss: 5.66
update:845/2000, 耗时:0.00分/2.84分 | step: 47320 | performance: 0.6 | accuracy: 0.47 | loss: 4.15
update:850/2000, 耗时:0.00分/2.85分 | step: 47600 | performance: 0.4 | accuracy: 0.46 | loss: 3.76
update:855/2000, 耗时:0.00分/2.87分 | step: 47880 | performance: 0.4 | accuracy: 0.46 | loss: 1.78
update:860/2000, 耗时:0.00分/2.88分 | step: 48160 | performance: 0.5 | accuracy: 0.47 | loss: 1.93
update:865/2000, 耗时:0.00分/2.90分 | step: 48440 | performance: 0.7 | accuracy: 0.47 | loss: 1.41
update:870/2000, 耗时:0.00分/2.91分 | step: 48720 | performance: 0.7 | accuracy: 0.47 | loss: 0.95
update:875/2000, 耗时:0.00分/2.93分 | step: 49000 | performance: 0.8 | accuracy: 0.47 | loss: 0.68
update:880/2000, 耗时:0.00分/2.95分 | step: 49280 | performance: 0.6 | accuracy: 0.47 | loss: 0.69
update:885/2000, 耗时:0.00分/2.96分 | step: 49560 | performance: 1.2 | accuracy: 0.47 | loss: 0.72
update:890/2000, 耗时:0.00分/2.97分 | step: 49840 | performance: 1.2 | accuracy: 0.47 | loss: 0.77
update:895/2000, 耗时:0.00分/2.99分 | step: 50120 | performance: 1.3 | accuracy: 0.47 | loss: 0.91
step: 50281 | worker_0@n_step_6: average total_reward after train data exhaustion : 84.9 | max total_reward: 145.5
step: 50282 | worker_1@n_step_6: average total_reward after train data exhaustion : 69.9 | max total_reward: 145.5
step: 50283 | worker_2@n_step_6: average total_reward after train data exhaustion : 57.6 | max total_reward: 145.5
step: 50284 | worker_3@n_step_6: average total_reward after train data exhaustion : 47.3 | max total_reward: 145.5
step: 50285 | worker_4@n_step_6: average total_reward after train data exhaustion : 38.6 | max total_reward: 145.5
step: 50286 | worker_5@n_step_6: average total_reward after train data exhaustion : 31.2 | max total_reward: 145.5
step: 50287 | worker_6@n_step_6: average total_reward after train data exhaustion : 24.8 | max total_reward: 145.5
step: 50288 | worker_7@n_step_6: average total_reward after train data exhaustion : 19.1 | max total_reward: 145.5
update:900/2000, 耗时:0.00分/3.00分 | step: 50400 | performance: 1.0 | accuracy: 0.36 | loss: 1.70
update:905/2000, 耗时:0.00分/3.02分 | step: 50680 | performance: 1.0 | accuracy: 0.45 | loss: 0.54
update:910/2000, 耗时:0.00分/3.04分 | step: 50960 | performance: 1.0 | accuracy: 0.49 | loss: 0.65
update:915/2000, 耗时:0.00分/3.05分 | step: 51240 | performance: 1.1 | accuracy: 0.50 | loss: 1.06
update:920/2000, 耗时:0.00分/3.07分 | step: 51520 | performance: 3.9 | accuracy: 0.54 | loss: 3.02
update:925/2000, 耗时:0.00分/3.08分 | step: 51800 | performance: 9.3 | accuracy: 0.56 | loss: 1.52
update:930/2000, 耗时:0.00分/3.10分 | step: 52080 | performance: 6.0 | accuracy: 0.53 | loss: 1.21
update:935/2000, 耗时:0.00分/3.12分 | step: 52360 | performance: 7.7 | accuracy: 0.53 | loss: 1.44
update:940/2000, 耗时:0.00分/3.13分 | step: 52640 | performance: 9.1 | accuracy: 0.52 | loss: 0.61
update:945/2000, 耗时:0.00分/3.15分 | step: 52920 | performance: 6.3 | accuracy: 0.50 | loss: 1.34
update:950/2000, 耗时:0.00分/3.16分 | step: 53200 | performance: 6.6 | accuracy: 0.49 | loss: 0.75
update:955/2000, 耗时:0.00分/3.18分 | step: 53480 | performance: 5.7 | accuracy: 0.48 | loss: 1.46
update:960/2000, 耗时:0.00分/3.19分 | step: 53760 | performance: 2.9 | accuracy: 0.46 | loss: 1.57
update:965/2000, 耗时:0.00分/3.21分 | step: 54040 | performance: 2.2 | accuracy: 0.45 | loss: 1.63
update:970/2000, 耗时:0.00分/3.22分 | step: 54320 | performance: 1.0 | accuracy: 0.44 | loss: 2.49
update:975/2000, 耗时:0.00分/3.24分 | step: 54600 | performance: 1.0 | accuracy: 0.44 | loss: 0.77
update:980/2000, 耗时:0.00分/3.25分 | step: 54880 | performance: 0.3 | accuracy: 0.42 | loss: 3.62
update:985/2000, 耗时:0.00分/3.27分 | step: 55160 | performance: 0.4 | accuracy: 0.43 | loss: 4.91
update:990/2000, 耗时:0.00分/3.29分 | step: 55440 | performance: 0.5 | accuracy: 0.43 | loss: 2.77
update:995/2000, 耗时:0.00分/3.30分 | step: 55720 | performance: 0.5 | accuracy: 0.43 | loss: 1.44
update:1000/2000, 耗时:0.00分/3.32分 | step: 56000 | performance: 0.5 | accuracy: 0.43 | loss: 2.39
update:1005/2000, 耗时:0.00分/3.33分 | step: 56280 | performance: 0.6 | accuracy: 0.44 | loss: 2.29
update:1010/2000, 耗时:0.00分/3.35分 | step: 56560 | performance: 0.9 | accuracy: 0.45 | loss: 3.91
update:1015/2000, 耗时:0.00分/3.36分 | step: 56840 | performance: 0.7 | accuracy: 0.45 | loss: 9.16
update:1020/2000, 耗时:0.00分/3.38分 | step: 57120 | performance: 1.0 | accuracy: 0.46 | loss: 0.73
update:1025/2000, 耗时:0.00分/3.39分 | step: 57400 | performance: 1.6 | accuracy: 0.46 | loss: 1.22
update:1030/2000, 耗时:0.00分/3.41分 | step: 57680 | performance: 1.8 | accuracy: 0.47 | loss: 1.93
update:1035/2000, 耗时:0.00分/3.43分 | step: 57960 | performance: 1.7 | accuracy: 0.47 | loss: 4.56
update:1040/2000, 耗时:0.00分/3.44分 | step: 58240 | performance: 1.2 | accuracy: 0.46 | loss: 0.62
update:1045/2000, 耗时:0.00分/3.46分 | step: 58520 | performance: 0.7 | accuracy: 0.46 | loss: 2.00
update:1050/2000, 耗时:0.00分/3.47分 | step: 58800 | performance: 1.1 | accuracy: 0.47 | loss: 4.59
update:1055/2000, 耗时:0.00分/3.49分 | step: 59080 | performance: 6.0 | accuracy: 0.47 | loss: 2.61
update:1060/2000, 耗时:0.00分/3.50分 | step: 59360 | performance: 2.7 | accuracy: 0.47 | loss: 3.01
update:1065/2000, 耗时:0.00分/3.52分 | step: 59640 | performance: 2.4 | accuracy: 0.47 | loss: 0.78
update:1070/2000, 耗时:0.00分/3.53分 | step: 59920 | performance: 1.0 | accuracy: 0.46 | loss: 1.84
update:1075/2000, 耗时:0.00分/3.55分 | step: 60200 | performance: 1.3 | accuracy: 0.47 | loss: 1.12
update:1080/2000, 耗时:0.00分/3.56分 | step: 60480 | performance: 1.1 | accuracy: 0.46 | loss: 0.32
update:1085/2000, 耗时:0.00分/3.58分 | step: 60760 | performance: 1.3 | accuracy: 0.47 | loss: 1.81
update:1090/2000, 耗时:0.00分/3.60分 | step: 61040 | performance: 1.3 | accuracy: 0.47 | loss: 3.38
update:1095/2000, 耗时:0.00分/3.61分 | step: 61320 | performance: 0.8 | accuracy: 0.46 | loss: 1.76
update:1100/2000, 耗时:0.00分/3.63分 | step: 61600 | performance: 0.7 | accuracy: 0.46 | loss: 1.06
update:1105/2000, 耗时:0.00分/3.64分 | step: 61880 | performance: 1.1 | accuracy: 0.46 | loss: 0.55
update:1110/2000, 耗时:0.00分/3.66分 | step: 62160 | performance: 1.0 | accuracy: 0.46 | loss: 0.87
update:1115/2000, 耗时:0.00分/3.67分 | step: 62440 | performance: 0.8 | accuracy: 0.45 | loss: 3.00
update:1120/2000, 耗时:0.00分/3.69分 | step: 62720 | performance: 0.5 | accuracy: 0.45 | loss: 0.88
update:1125/2000, 耗时:0.00分/3.71分 | step: 63000 | performance: 0.3 | accuracy: 0.45 | loss: 0.66
update:1130/2000, 耗时:0.00分/3.72分 | step: 63280 | performance: 0.2 | accuracy: 0.44 | loss: 0.78
update:1135/2000, 耗时:0.00分/3.74分 | step: 63560 | performance: 0.1 | accuracy: 0.44 | loss: 1.85
update:1140/2000, 耗时:0.00分/3.75分 | step: 63840 | performance: 0.0 | accuracy: 0.44 | loss: 2.41
update:1145/2000, 耗时:0.00分/3.77分 | step: 64120 | performance: 0.0 | accuracy: 0.44 | loss: 0.81
update:1150/2000, 耗时:0.00分/3.79分 | step: 64400 | performance: 0.0 | accuracy: 0.44 | loss: 1.76
update:1155/2000, 耗时:0.00分/3.80分 | step: 64680 | performance: 0.0 | accuracy: 0.44 | loss: 3.53
update:1160/2000, 耗时:0.00分/3.82分 | step: 64960 | performance: 0.0 | accuracy: 0.43 | loss: 1.25
update:1165/2000, 耗时:0.00分/3.83分 | step: 65240 | performance: 0.0 | accuracy: 0.44 | loss: 1.09
update:1170/2000, 耗时:0.00分/3.85分 | step: 65520 | performance: 0.0 | accuracy: 0.44 | loss: 4.37
update:1175/2000, 耗时:0.00分/3.87分 | step: 65800 | performance: 0.0 | accuracy: 0.44 | loss: 0.71
update:1180/2000, 耗时:0.00分/3.88分 | step: 66080 | performance: 0.0 | accuracy: 0.44 | loss: 5.36
update:1185/2000, 耗时:0.00分/3.90分 | step: 66360 | performance: 0.0 | accuracy: 0.44 | loss: 1.58
update:1190/2000, 耗时:0.00分/3.91分 | step: 66640 | performance: 0.1 | accuracy: 0.45 | loss: 1.58
update:1195/2000, 耗时:0.00分/3.93分 | step: 66920 | performance: 0.1 | accuracy: 0.45 | loss: 0.79
update:1200/2000, 耗时:0.00分/3.94分 | step: 67200 | performance: 0.0 | accuracy: 0.45 | loss: 1.55
update:1205/2000, 耗时:0.00分/3.96分 | step: 67480 | performance: 0.0 | accuracy: 0.44 | loss: 1.77
update:1210/2000, 耗时:0.00分/3.98分 | step: 67760 | performance: 0.0 | accuracy: 0.45 | loss: 5.05
update:1215/2000, 耗时:0.00分/3.99分 | step: 68040 | performance: 0.0 | accuracy: 0.45 | loss: 1.27
update:1220/2000, 耗时:0.00分/4.01分 | step: 68320 | performance: 0.0 | accuracy: 0.44 | loss: 0.80
update:1225/2000, 耗时:0.00分/4.02分 | step: 68600 | performance: 0.0 | accuracy: 0.44 | loss: 1.01
update:1230/2000, 耗时:0.00分/4.04分 | step: 68880 | performance: 0.0 | accuracy: 0.44 | loss: 7.23
update:1235/2000, 耗时:0.00分/4.06分 | step: 69160 | performance: 0.0 | accuracy: 0.45 | loss: 4.60
update:1240/2000, 耗时:0.00分/4.07分 | step: 69440 | performance: 0.0 | accuracy: 0.45 | loss: 0.80
update:1245/2000, 耗时:0.00分/4.09分 | step: 69720 | performance: 0.0 | accuracy: 0.45 | loss: 2.21
update:1250/2000, 耗时:0.00分/4.10分 | step: 70000 | performance: 0.1 | accuracy: 0.45 | loss: 1.93
update:1255/2000, 耗时:0.00分/4.12分 | step: 70280 | performance: 0.0 | accuracy: 0.45 | loss: 2.40
update:1260/2000, 耗时:0.00分/4.13分 | step: 70560 | performance: 0.0 | accuracy: 0.45 | loss: 2.65
update:1265/2000, 耗时:0.00分/4.15分 | step: 70840 | performance: 0.0 | accuracy: 0.46 | loss: 0.93
update:1270/2000, 耗时:0.00分/4.17分 | step: 71120 | performance: 0.0 | accuracy: 0.45 | loss: 3.71
update:1275/2000, 耗时:0.00分/4.18分 | step: 71400 | performance: 0.1 | accuracy: 0.46 | loss: 4.02
update:1280/2000, 耗时:0.00分/4.20分 | step: 71680 | performance: 0.2 | accuracy: 0.46 | loss: 3.56
update:1285/2000, 耗时:0.00分/4.21分 | step: 71960 | performance: 0.2 | accuracy: 0.46 | loss: 1.72
update:1290/2000, 耗时:0.00分/4.23分 | step: 72240 | performance: 0.4 | accuracy: 0.46 | loss: 3.56
update:1295/2000, 耗时:0.00分/4.24分 | step: 72520 | performance: 0.6 | accuracy: 0.46 | loss: 0.60
update:1300/2000, 耗时:0.00分/4.26分 | step: 72800 | performance: 0.4 | accuracy: 0.46 | loss: 1.90
update:1305/2000, 耗时:0.00分/4.28分 | step: 73080 | performance: 0.4 | accuracy: 0.46 | loss: 0.63
update:1310/2000, 耗时:0.00分/4.29分 | step: 73360 | performance: 0.5 | accuracy: 0.47 | loss: 0.60
update:1315/2000, 耗时:0.00分/4.31分 | step: 73640 | performance: 0.5 | accuracy: 0.47 | loss: 5.91
update:1320/2000, 耗时:0.00分/4.32分 | step: 73920 | performance: 0.7 | accuracy: 0.47 | loss: 1.09
update:1325/2000, 耗时:0.00分/4.34分 | step: 74200 | performance: 0.7 | accuracy: 0.47 | loss: 0.65
update:1330/2000, 耗时:0.00分/4.35分 | step: 74480 | performance: 0.7 | accuracy: 0.47 | loss: 3.22
update:1335/2000, 耗时:0.00分/4.37分 | step: 74760 | performance: 1.3 | accuracy: 0.47 | loss: 1.40
update:1340/2000, 耗时:0.00分/4.38分 | step: 75040 | performance: 1.2 | accuracy: 0.47 | loss: 1.17
update:1345/2000, 耗时:0.00分/4.40分 | step: 75320 | performance: 1.3 | accuracy: 0.47 | loss: 0.53
step: 75425 | worker_0@n_step_6: average total_reward after train data exhaustion : 14.1 | max total_reward: 145.5
step: 75426 | worker_1@n_step_6: average total_reward after train data exhaustion : 9.7 | max total_reward: 145.5
step: 75427 | worker_2@n_step_6: average total_reward after train data exhaustion : 5.8 | max total_reward: 145.5
step: 75428 | worker_3@n_step_6: average total_reward after train data exhaustion : 2.2 | max total_reward: 145.5
step: 75429 | worker_4@n_step_6: average total_reward after train data exhaustion : -1.0 | max total_reward: 145.5
step: 75430 | worker_5@n_step_6: average total_reward after train data exhaustion : -4.0 | max total_reward: 145.5
step: 75431 | worker_6@n_step_6: average total_reward after train data exhaustion : -6.6 | max total_reward: 145.5
step: 75432 | worker_7@n_step_6: average total_reward after train data exhaustion : -9.1 | max total_reward: 145.5
update:1350/2000, 耗时:0.00分/4.42分 | step: 75600 | performance: 0.9 | accuracy: 0.38 | loss: 0.80
update:1355/2000, 耗时:0.00分/4.43分 | step: 75880 | performance: 1.1 | accuracy: 0.46 | loss: 1.78
update:1360/2000, 耗时:0.00分/4.45分 | step: 76160 | performance: 1.1 | accuracy: 0.52 | loss: 1.65
update:1365/2000, 耗时:0.00分/4.46分 | step: 76440 | performance: 1.6 | accuracy: 0.52 | loss: 2.96
update:1370/2000, 耗时:0.00分/4.48分 | step: 76720 | performance: 4.5 | accuracy: 0.55 | loss: 0.83
update:1375/2000, 耗时:0.00分/4.49分 | step: 77000 | performance: 5.5 | accuracy: 0.54 | loss: 6.78
update:1380/2000, 耗时:0.00分/4.51分 | step: 77280 | performance: 5.6 | accuracy: 0.52 | loss: 2.35
update:1385/2000, 耗时:0.00分/4.52分 | step: 77560 | performance: 7.7 | accuracy: 0.53 | loss: 0.64
update:1390/2000, 耗时:0.00分/4.54分 | step: 77840 | performance: 7.4 | accuracy: 0.51 | loss: 2.04
update:1395/2000, 耗时:0.00分/4.55分 | step: 78120 | performance: 6.7 | accuracy: 0.49 | loss: 0.98
update:1400/2000, 耗时:0.00分/4.57分 | step: 78400 | performance: 6.1 | accuracy: 0.49 | loss: 1.71
update:1405/2000, 耗时:0.00分/4.59分 | step: 78680 | performance: 3.3 | accuracy: 0.47 | loss: 4.96
update:1410/2000, 耗时:0.00分/4.60分 | step: 78960 | performance: 2.9 | accuracy: 0.46 | loss: 1.34
update:1415/2000, 耗时:0.00分/4.62分 | step: 79240 | performance: 1.9 | accuracy: 0.45 | loss: 3.36
update:1420/2000, 耗时:0.00分/4.63分 | step: 79520 | performance: 0.7 | accuracy: 0.44 | loss: 1.26
update:1425/2000, 耗时:0.00分/4.65分 | step: 79800 | performance: 0.9 | accuracy: 0.44 | loss: 1.05
update:1430/2000, 耗时:0.00分/4.66分 | step: 80080 | performance: 0.3 | accuracy: 0.43 | loss: 4.27
update:1435/2000, 耗时:0.00分/4.68分 | step: 80360 | performance: 0.5 | accuracy: 0.43 | loss: 1.42
update:1440/2000, 耗时:0.00分/4.69分 | step: 80640 | performance: 0.4 | accuracy: 0.43 | loss: 3.98
update:1445/2000, 耗时:0.00分/4.71分 | step: 80920 | performance: 0.5 | accuracy: 0.43 | loss: 2.77
update:1450/2000, 耗时:0.00分/4.72分 | step: 81200 | performance: 0.5 | accuracy: 0.43 | loss: 1.74
update:1455/2000, 耗时:0.00分/4.74分 | step: 81480 | performance: 1.0 | accuracy: 0.45 | loss: 7.16
update:1460/2000, 耗时:0.00分/4.76分 | step: 81760 | performance: 1.0 | accuracy: 0.45 | loss: 1.07
update:1465/2000, 耗时:0.00分/4.77分 | step: 82040 | performance: 0.8 | accuracy: 0.45 | loss: 1.35
update:1470/2000, 耗时:0.00分/4.79分 | step: 82320 | performance: 1.0 | accuracy: 0.46 | loss: 0.85
update:1475/2000, 耗时:0.00分/4.80分 | step: 82600 | performance: 1.7 | accuracy: 0.46 | loss: 0.98
update:1480/2000, 耗时:0.00分/4.82分 | step: 82880 | performance: 1.7 | accuracy: 0.47 | loss: 0.58
update:1485/2000, 耗时:0.00分/4.83分 | step: 83160 | performance: 1.4 | accuracy: 0.47 | loss: 2.36
update:1490/2000, 耗时:0.00分/4.85分 | step: 83440 | performance: 1.1 | accuracy: 0.46 | loss: 0.90
update:1495/2000, 耗时:0.00分/4.87分 | step: 83720 | performance: 0.7 | accuracy: 0.46 | loss: 0.72
update:1500/2000, 耗时:0.00分/4.88分 | step: 84000 | performance: 1.2 | accuracy: 0.47 | loss: 1.96
update:1505/2000, 耗时:0.00分/4.90分 | step: 84280 | performance: 4.3 | accuracy: 0.47 | loss: 3.48
update:1510/2000, 耗时:0.00分/4.91分 | step: 84560 | performance: 2.6 | accuracy: 0.47 | loss: 0.60
update:1515/2000, 耗时:0.00分/4.93分 | step: 84840 | performance: 2.3 | accuracy: 0.47 | loss: 1.99
update:1520/2000, 耗时:0.00分/4.94分 | step: 85120 | performance: 1.3 | accuracy: 0.47 | loss: 5.13
update:1525/2000, 耗时:0.00分/4.96分 | step: 85400 | performance: 1.1 | accuracy: 0.46 | loss: 3.96
update:1530/2000, 耗时:0.00分/4.98分 | step: 85680 | performance: 1.2 | accuracy: 0.46 | loss: 2.22
update:1535/2000, 耗时:0.00分/4.99分 | step: 85960 | performance: 1.3 | accuracy: 0.47 | loss: 1.11
update:1540/2000, 耗时:0.00分/5.01分 | step: 86240 | performance: 1.3 | accuracy: 0.47 | loss: 0.59
update:1545/2000, 耗时:0.00分/5.02分 | step: 86520 | performance: 0.7 | accuracy: 0.46 | loss: 2.26
update:1550/2000, 耗时:0.00分/5.04分 | step: 86800 | performance: 0.7 | accuracy: 0.46 | loss: 1.09
update:1555/2000, 耗时:0.00分/5.05分 | step: 87080 | performance: 1.1 | accuracy: 0.46 | loss: 1.71
update:1560/2000, 耗时:0.00分/5.07分 | step: 87360 | performance: 0.9 | accuracy: 0.45 | loss: 0.93
update:1565/2000, 耗时:0.00分/5.09分 | step: 87640 | performance: 0.8 | accuracy: 0.45 | loss: 0.72
update:1570/2000, 耗时:0.00分/5.10分 | step: 87920 | performance: 0.5 | accuracy: 0.45 | loss: 1.53
update:1575/2000, 耗时:0.00分/5.12分 | step: 88200 | performance: 0.2 | accuracy: 0.45 | loss: 3.55
update:1580/2000, 耗时:0.00分/5.13分 | step: 88480 | performance: 0.2 | accuracy: 0.44 | loss: 0.80
update:1585/2000, 耗时:0.00分/5.15分 | step: 88760 | performance: 0.1 | accuracy: 0.44 | loss: 0.56
update:1590/2000, 耗时:0.00分/5.17分 | step: 89040 | performance: 0.0 | accuracy: 0.44 | loss: 4.22
update:1595/2000, 耗时:0.00分/5.18分 | step: 89320 | performance: 0.0 | accuracy: 0.44 | loss: 3.33
update:1600/2000, 耗时:0.00分/5.20分 | step: 89600 | performance: 0.0 | accuracy: 0.44 | loss: 0.64
update:1605/2000, 耗时:0.00分/5.21分 | step: 89880 | performance: 0.0 | accuracy: 0.44 | loss: 1.42
update:1610/2000, 耗时:0.00分/5.23分 | step: 90160 | performance: 0.0 | accuracy: 0.44 | loss: 4.98
update:1615/2000, 耗时:0.00分/5.24分 | step: 90440 | performance: 0.0 | accuracy: 0.44 | loss: 1.16
update:1620/2000, 耗时:0.00分/5.26分 | step: 90720 | performance: 0.0 | accuracy: 0.44 | loss: 2.03
update:1625/2000, 耗时:0.00分/5.28分 | step: 91000 | performance: 0.0 | accuracy: 0.44 | loss: 5.34
update:1630/2000, 耗时:0.00分/5.29分 | step: 91280 | performance: 0.0 | accuracy: 0.44 | loss: 2.54
update:1635/2000, 耗时:0.00分/5.31分 | step: 91560 | performance: 0.0 | accuracy: 0.44 | loss: 1.91
update:1640/2000, 耗时:0.00分/5.32分 | step: 91840 | performance: 0.0 | accuracy: 0.45 | loss: 2.35
update:1645/2000, 耗时:0.00分/5.34分 | step: 92120 | performance: 0.1 | accuracy: 0.45 | loss: 2.00
update:1650/2000, 耗时:0.00分/5.35分 | step: 92400 | performance: 0.0 | accuracy: 0.44 | loss: 3.54
update:1655/2000, 耗时:0.00分/5.37分 | step: 92680 | performance: 0.0 | accuracy: 0.44 | loss: 3.19
update:1660/2000, 耗时:0.00分/5.39分 | step: 92960 | performance: 0.0 | accuracy: 0.45 | loss: 0.81
update:1665/2000, 耗时:0.00分/5.40分 | step: 93240 | performance: 0.0 | accuracy: 0.45 | loss: 1.16
update:1670/2000, 耗时:0.00分/5.42分 | step: 93520 | performance: 0.0 | accuracy: 0.44 | loss: 1.09
update:1675/2000, 耗时:0.00分/5.43分 | step: 93800 | performance: 0.0 | accuracy: 0.44 | loss: 1.17
update:1680/2000, 耗时:0.00分/5.45分 | step: 94080 | performance: 0.0 | accuracy: 0.44 | loss: 0.71
update:1685/2000, 耗时:0.00分/5.47分 | step: 94360 | performance: 0.0 | accuracy: 0.45 | loss: 1.64
update:1690/2000, 耗时:0.00分/5.48分 | step: 94640 | performance: 0.0 | accuracy: 0.45 | loss: 0.71
update:1695/2000, 耗时:0.00分/5.50分 | step: 94920 | performance: 0.0 | accuracy: 0.45 | loss: 1.15
update:1700/2000, 耗时:0.00分/5.51分 | step: 95200 | performance: 0.1 | accuracy: 0.45 | loss: 1.49
update:1705/2000, 耗时:0.00分/5.53分 | step: 95480 | performance: 0.0 | accuracy: 0.45 | loss: 1.78
update:1710/2000, 耗时:0.00分/5.55分 | step: 95760 | performance: 0.1 | accuracy: 0.46 | loss: 5.42
update:1715/2000, 耗时:0.00分/5.56分 | step: 96040 | performance: 0.0 | accuracy: 0.45 | loss: 1.32
update:1720/2000, 耗时:0.00分/5.58分 | step: 96320 | performance: 0.0 | accuracy: 0.45 | loss: 1.50
update:1725/2000, 耗时:0.00分/5.59分 | step: 96600 | performance: 0.1 | accuracy: 0.46 | loss: 0.74
update:1730/2000, 耗时:0.00分/5.61分 | step: 96880 | performance: 0.1 | accuracy: 0.46 | loss: 1.53
update:1735/2000, 耗时:0.00分/5.63分 | step: 97160 | performance: 0.1 | accuracy: 0.46 | loss: 2.45
update:1740/2000, 耗时:0.00分/5.64分 | step: 97440 | performance: 0.5 | accuracy: 0.46 | loss: 2.44
update:1745/2000, 耗时:0.00分/5.66分 | step: 97720 | performance: 0.5 | accuracy: 0.46 | loss: 2.58
update:1750/2000, 耗时:0.00分/5.67分 | step: 98000 | performance: 0.4 | accuracy: 0.46 | loss: 1.26
update:1755/2000, 耗时:0.00分/5.69分 | step: 98280 | performance: 0.3 | accuracy: 0.46 | loss: 1.02
update:1760/2000, 耗时:0.00分/5.70分 | step: 98560 | performance: 0.6 | accuracy: 0.47 | loss: 5.25
update:1765/2000, 耗时:0.00分/5.72分 | step: 98840 | performance: 0.6 | accuracy: 0.47 | loss: 2.85
update:1770/2000, 耗时:0.00分/5.74分 | step: 99120 | performance: 0.7 | accuracy: 0.47 | loss: 2.21
update:1775/2000, 耗时:0.00分/5.75分 | step: 99400 | performance: 0.8 | accuracy: 0.47 | loss: 1.67
update:1780/2000, 耗时:0.00分/5.77分 | step: 99680 | performance: 0.6 | accuracy: 0.47 | loss: 1.97
update:1785/2000, 耗时:0.00分/5.78分 | step: 99960 | performance: 1.3 | accuracy: 0.47 | loss: 1.94
update:1790/2000, 耗时:0.00分/5.80分 | step: 100240 | performance: 1.2 | accuracy: 0.47 | loss: 0.56
update:1795/2000, 耗时:0.00分/5.81分 | step: 100520 | performance: 1.3 | accuracy: 0.47 | loss: 2.21
step: 100569 | worker_0@n_step_6: average total_reward after train data exhaustion : -11.3 | max total_reward: 145.5
step: 100570 | worker_1@n_step_6: average total_reward after train data exhaustion : -13.4 | max total_reward: 145.5
step: 100571 | worker_2@n_step_6: average total_reward after train data exhaustion : -15.3 | max total_reward: 145.5
step: 100572 | worker_3@n_step_6: average total_reward after train data exhaustion : -17.1 | max total_reward: 145.5
step: 100573 | worker_4@n_step_6: average total_reward after train data exhaustion : -18.8 | max total_reward: 145.5
step: 100574 | worker_5@n_step_6: average total_reward after train data exhaustion : -20.4 | max total_reward: 145.5
step: 100575 | worker_6@n_step_6: average total_reward after train data exhaustion : -21.8 | max total_reward: 145.5
step: 100576 | worker_7@n_step_6: average total_reward after train data exhaustion : -23.2 | max total_reward: 145.5
update:1800/2000, 耗时:0.00分/5.83分 | step: 100800 | performance: 1.0 | accuracy: 0.43 | loss: 1.41
update:1805/2000, 耗时:0.00分/5.85分 | step: 101080 | performance: 1.0 | accuracy: 0.43 | loss: 3.54
update:1810/2000, 耗时:0.00分/5.86分 | step: 101360 | performance: 1.1 | accuracy: 0.52 | loss: 1.27
update:1815/2000, 耗时:0.00分/5.88分 | step: 101640 | performance: 1.8 | accuracy: 0.53 | loss: 0.87
update:1820/2000, 耗时:0.00分/5.89分 | step: 101920 | performance: 6.2 | accuracy: 0.56 | loss: 1.57
update:1825/2000, 耗时:0.00分/5.91分 | step: 102200 | performance: 5.1 | accuracy: 0.53 | loss: 1.26
update:1830/2000, 耗时:0.00分/5.93分 | step: 102480 | performance: 6.4 | accuracy: 0.52 | loss: 1.76
update:1835/2000, 耗时:0.00分/5.94分 | step: 102760 | performance: 8.1 | accuracy: 0.53 | loss: 0.73
update:1840/2000, 耗时:0.00分/5.96分 | step: 103040 | performance: 7.8 | accuracy: 0.52 | loss: 0.73
update:1845/2000, 耗时:0.00分/5.97分 | step: 103320 | performance: 7.0 | accuracy: 0.50 | loss: 1.13
update:1850/2000, 耗时:0.00分/5.99分 | step: 103600 | performance: 6.0 | accuracy: 0.48 | loss: 1.78
update:1855/2000, 耗时:0.00分/6.01分 | step: 103880 | performance: 3.0 | accuracy: 0.46 | loss: 2.41
update:1860/2000, 耗时:0.00分/6.02分 | step: 104160 | performance: 2.7 | accuracy: 0.46 | loss: 1.47
update:1865/2000, 耗时:0.00分/6.04分 | step: 104440 | performance: 1.2 | accuracy: 0.44 | loss: 5.89
update:1870/2000, 耗时:0.00分/6.05分 | step: 104720 | performance: 0.7 | accuracy: 0.44 | loss: 0.86
update:1875/2000, 耗时:0.00分/6.07分 | step: 105000 | performance: 0.6 | accuracy: 0.43 | loss: 4.79
update:1880/2000, 耗时:0.00分/6.09分 | step: 105280 | performance: 0.3 | accuracy: 0.43 | loss: 1.41
update:1885/2000, 耗时:0.00分/6.10分 | step: 105560 | performance: 0.4 | accuracy: 0.43 | loss: 0.90
update:1890/2000, 耗时:0.00分/6.12分 | step: 105840 | performance: 0.3 | accuracy: 0.43 | loss: 0.86
update:1895/2000, 耗时:0.00分/6.13分 | step: 106120 | performance: 0.5 | accuracy: 0.43 | loss: 0.34
update:1900/2000, 耗时:0.00分/6.15分 | step: 106400 | performance: 0.5 | accuracy: 0.44 | loss: 1.84
update:1905/2000, 耗时:0.00分/6.17分 | step: 106680 | performance: 1.1 | accuracy: 0.45 | loss: 0.91
update:1910/2000, 耗时:0.00分/6.18分 | step: 106960 | performance: 1.1 | accuracy: 0.45 | loss: 1.06
update:1915/2000, 耗时:0.00分/6.20分 | step: 107240 | performance: 0.8 | accuracy: 0.45 | loss: 0.81
update:1920/2000, 耗时:0.00分/6.21分 | step: 107520 | performance: 1.3 | accuracy: 0.46 | loss: 2.03
update:1925/2000, 耗时:0.00分/6.23分 | step: 107800 | performance: 1.6 | accuracy: 0.46 | loss: 1.39
update:1930/2000, 耗时:0.00分/6.25分 | step: 108080 | performance: 1.8 | accuracy: 0.47 | loss: 2.45
update:1935/2000, 耗时:0.00分/6.26分 | step: 108360 | performance: 1.3 | accuracy: 0.47 | loss: 1.64
update:1940/2000, 耗时:0.00分/6.28分 | step: 108640 | performance: 0.9 | accuracy: 0.46 | loss: 2.52
update:1945/2000, 耗时:0.00分/6.29分 | step: 108920 | performance: 0.8 | accuracy: 0.46 | loss: 2.95
update:1950/2000, 耗时:0.00分/6.31分 | step: 109200 | performance: 1.1 | accuracy: 0.47 | loss: 0.75
update:1955/2000, 耗时:0.00分/6.32分 | step: 109480 | performance: 3.9 | accuracy: 0.47 | loss: 1.72
update:1960/2000, 耗时:0.00分/6.34分 | step: 109760 | performance: 2.2 | accuracy: 0.47 | loss: 1.47
update:1965/2000, 耗时:0.00分/6.36分 | step: 110040 | performance: 1.9 | accuracy: 0.47 | loss: 4.02
update:1970/2000, 耗时:0.00分/6.37分 | step: 110320 | performance: 1.0 | accuracy: 0.46 | loss: 2.05
update:1975/2000, 耗时:0.00分/6.39分 | step: 110600 | performance: 1.1 | accuracy: 0.46 | loss: 0.72
update:1980/2000, 耗时:0.00分/6.41分 | step: 110880 | performance: 1.2 | accuracy: 0.46 | loss: 1.06
update:1985/2000, 耗时:0.00分/6.42分 | step: 111160 | performance: 1.3 | accuracy: 0.47 | loss: 0.75
update:1990/2000, 耗时:0.00分/6.44分 | step: 111440 | performance: 1.2 | accuracy: 0.47 | loss: 4.18
update:1995/2000, 耗时:0.00分/6.45分 | step: 111720 | performance: 0.7 | accuracy: 0.46 | loss: 0.69
  0%|          | 0/391 [00:00<?, ?it/s]100%|| 391/391 [00:00<00:00, 97902.98it/s]
update:2000/2000, 耗时:0.00分/6.47分 | step: 112000 | performance: 0.8 | accuracy: 0.46 | loss: 1.86
----------------------------------------finished----------------------------------------
==================================================
2023-01-10T12:00:00 | *** START BACKTEST ***
2023-01-10T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1000.00
2023-07-24T12:00:00 | net performance [%] = 0.0000
2023-07-24T12:00:00 | number of trades [#] = 0
==================================================
Trial 36 Complete [00h 06m 54s]
net_wealth: 1000.0

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 04h 51m 54s

Search: Running Trial #37

Value             |Best Value So Far |Hyperparameter
4                 |7                 |horizon
365               |730               |lookback
False             |False             |MarketFactor
7                 |14                |lags
0.9               |0.7               |gamma
32                |32                |batch_size
7                 |32                |n_step
0.96              |0.92              |gae_lambda
5                 |0.1               |gradient_clip_norm
3                 |5                 |epochs
0.0005            |0.0001            |actor_lr
0.0001            |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4311.000000   4315.000000
mean      0.000441    20062.255222  ...   20133.281642  20118.633889
std       0.027818    16039.874230  ...   16077.358923  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7695.614990   7690.540039
50%       0.000642    11554.824463  ...   11741.480469  11715.610352
75%       0.011655    29873.081836  ...   29939.474609  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 02:55:18.196106: I tensorflow/core/pl2023-0atform/cpu_feature_guard.cc:142] This TensorFlo2023-07-27w8 02- 28: 0255b:5i:5:181.nary is196 8134: I tenso.orflow/c1p9tio6m1ri6e3zed w:/ ith pIo latform/ctnepu_featnesure_gAourPI falDro2wd.e/co0epr2e /pl3Ne-u0r7-atform2a/cpu_fel8  2a002Ntuertwork Librarye_2:553-gua07-:r1d8..cc: 214(on8 021] Te2DNhNis c96372c: T:5:Ie154:2182)2 023- n].t0 1Thisor7etno9Fsl -s 0To26ouw42r3-5s8 02:02e5 2b:70e-2n I stensor3orF2fl-olw/08o w  t02:55:178-28 02h:i.eb55f196l5o5::1ni8w/ac4r cfoooren/re/py 4.arlyl i1owis: op9 tIilaplati nttfeofns61orflm6rgiszo 5m/5cped8 u_fC wow/eaittu:r eo.pctrIh o _tgePUmiumanore//cpu_featurenird19e_g.p inslsao6z563c:ctteformA PII  rDurdftlenoa/so with ord.rwc/nfelowpcu/_:occAfeac14:u2rcP1I4]2 ]eot TuDeerep tehisions ie reTp/ pNe_Nheguar/ulatndraiuforpl.s  Tpm/a TercformpreeanasnocrlF Ntefcnsu_fea-corm/cpu_ettcuwor:fll Netweoaew 142_oorgtb] iTnhkuurraFrlykiar dsr ei.s  LirTei_guardo.pbonw scrcc:c14tio:rFbcl1tary iaml2i]4  onari2( opLziebonw y] eTrha tieDbdionTsNriani sN )wiar yT is oosp:  prthhtii e onenss mAity TiomrAFVX z(ilzoewdAVoePtnoeD n wXi2I
bied s ousnTaorrFN w tel N)yih ont teot he Ao PiInDabl Dus oneeAoPeeseeIptwp Neu   bep tthhe rDeimn Neiemaah fry li ipoils N en Neeul foztroawle othiNluloroweowing enraeCd PrptwUi iktwtogn s ir lCPULhm itoik N eLibrtuctbioporn eanerrArPwIoarryy  ((oosniezk  iDen eDNaDdL iwbirntNtahr onioye N() otons  useNen,p Nee e )r etbuoi uutrhepner Asald fTensfoolPeI trDlNsl Demano the NrN) to use ucteeowing CPU instrcrFlow wifollowing CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operaptiut hoections tfinNeuorna sweo-inlscr l  Nor,ple owiek Ltitwirihor trnfthgnbiocr rCkae  peapreybu ilLi arbflmpa noPpUerat iiorrd aTrooprrmnysce-teaincecarns-ort (ocr(Fe onrlcoowmniintsi:e Duwcitt Neipcailcl NhD opereNaNltio)n sA VatoprX AV Xfetra2o in ti liagosnt h
oupTsnes :.o a
pe: e)p rt r f soA VuXs eoneo r mtahAeAanbVpthlVcXe2-e X 
cTrei frtiheaftoiocatem  oel l lonlabAwcoling lV owioCeXpinmPU i2
Toen otphe themriler  ratg CPUeinn o niotnflsa is thnst:operear  AVX gAVX2blrueucrt itati
ons ihncTsoe me .i
o  pnetionnasr,s in pebforle them in other operations, rebuild TensorFlow withn r rformothea nebuild Tenscr ethe -critical operationsappropoperations, rebuild TensorFlow with the appropriate compiler flags.
opeomanrrFriatlcatioe-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
o:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the ape compiler flags.
ns, rebuild TensorFlow with the appropriate compiler flags.
propriate compiler flags.
w with the appropriate compiler flags.
2023-07-28 02:55:18.781449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:55:18.813612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:55:18.814764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:55:18.830657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:55:18.836832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:55:18.848620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:55:18.862673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 02:55:18.863966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   280 | performance: 1.7 | accuracy: 0.49 | loss: 1.09
update: 10/2000, 耗时:0.00分/0.04分 | step:   560 | performance: 3.0 | accuracy: 0.54 | loss: 2.60
update: 15/2000, 耗时:0.00分/0.05分 | step:   840 | performance: 1.9 | accuracy: 0.43 | loss: 0.47
update: 20/2000, 耗时:0.00分/0.06分 | step:  1120 | performance: 2.0 | accuracy: 0.38 | loss: 0.75
update: 25/2000, 耗时:0.00分/0.07分 | step:  1400 | performance: 3.4 | accuracy: 0.40 | loss: 2.72
update: 30/2000, 耗时:0.00分/0.08分 | step:  1680 | performance: 4.3 | accuracy: 0.40 | loss: 2.23
update: 35/2000, 耗时:0.00分/0.09分 | step:  1960 | performance: 4.8 | accuracy: 0.40 | loss: 3.16
update: 40/2000, 耗时:0.00分/0.10分 | step:  2240 | performance: 2.5 | accuracy: 0.38 | loss: 3.06
update: 45/2000, 耗时:0.00分/0.10分 | step:  2520 | performance: 3.7 | accuracy: 0.38 | loss: 0.86
update: 50/2000, 耗时:0.00分/0.12分 | step:  2800 | performance: 5.0 | accuracy: 0.39 | loss: 0.70
update: 55/2000, 耗时:0.00分/0.13分 | step:  3080 | performance: 4.2 | accuracy: 0.37 | loss: 0.80
update: 60/2000, 耗时:0.00分/0.14分 | step:  3360 | performance: 3.4 | accuracy: 0.37 | loss: 0.98
update: 65/2000, 耗时:0.00分/0.15分 | step:  3640 | performance: 3.6 | accuracy: 0.36 | loss: 3.37
update: 70/2000, 耗时:0.00分/0.16分 | step:  3920 | performance: 3.9 | accuracy: 0.35 | loss: 1.69
update: 75/2000, 耗时:0.00分/0.17分 | step:  4200 | performance: 5.7 | accuracy: 0.35 | loss: 1.59
update: 80/2000, 耗时:0.00分/0.18分 | step:  4480 | performance: 28.9 | accuracy: 0.38 | loss: 17.88
update: 85/2000, 耗时:0.00分/0.20分 | step:  4760 | performance: 22.1 | accuracy: 0.38 | loss: 0.82
update: 90/2000, 耗时:0.00分/0.21分 | step:  5040 | performance: 25.5 | accuracy: 0.38 | loss: 4.72
update: 95/2000, 耗时:0.00分/0.22分 | step:  5320 | performance: 31.7 | accuracy: 0.38 | loss: 1.75
update:100/2000, 耗时:0.00分/0.23分 | step:  5600 | performance: 30.7 | accuracy: 0.39 | loss: 4.91
update:105/2000, 耗时:0.00分/0.24分 | step:  5880 | performance: 24.6 | accuracy: 0.38 | loss: 2.12
update:110/2000, 耗时:0.00分/0.25分 | step:  6160 | performance: 20.2 | accuracy: 0.38 | loss: 0.81
update:115/2000, 耗时:0.00分/0.27分 | step:  6440 | performance: 15.2 | accuracy: 0.37 | loss: 0.82
update:120/2000, 耗时:0.00分/0.28分 | step:  6720 | performance: 14.3 | accuracy: 0.37 | loss: 1.42
update:125/2000, 耗时:0.00分/0.29分 | step:  7000 | performance: 40.7 | accuracy: 0.37 | loss: 7.78
update:130/2000, 耗时:0.00分/0.30分 | step:  7280 | performance: 72.2 | accuracy: 0.38 | loss: 6.04
update:135/2000, 耗时:0.00分/0.31分 | step:  7560 | performance: 94.6 | accuracy: 0.39 | loss: 7.01
update:140/2000, 耗时:0.00分/0.33分 | step:  7840 | performance: 226.3 | accuracy: 0.40 | loss: 2.24
update:145/2000, 耗时:0.00分/0.34分 | step:  8120 | performance: 142.1 | accuracy: 0.40 | loss: 1.88
update:150/2000, 耗时:0.00分/0.35分 | step:  8400 | performance: 178.1 | accuracy: 0.41 | loss: 0.98
update:155/2000, 耗时:0.00分/0.36分 | step:  8680 | performance: 92.6 | accuracy: 0.40 | loss: 1.03
update:160/2000, 耗时:0.00分/0.37分 | step:  8960 | performance: 89.7 | accuracy: 0.41 | loss: 1.67
update:165/2000, 耗时:0.00分/0.39分 | step:  9240 | performance: 50.7 | accuracy: 0.40 | loss: 1.41
update:170/2000, 耗时:0.00分/0.40分 | step:  9520 | performance: 51.7 | accuracy: 0.40 | loss: 1.02
update:175/2000, 耗时:0.00分/0.41分 | step:  9800 | performance: 31.6 | accuracy: 0.40 | loss: 0.87
update:180/2000, 耗时:0.00分/0.42分 | step: 10080 | performance: 52.9 | accuracy: 0.40 | loss: 5.05
update:185/2000, 耗时:0.00分/0.43分 | step: 10360 | performance: 54.8 | accuracy: 0.41 | loss: 1.38
update:190/2000, 耗时:0.00分/0.45分 | step: 10640 | performance: 64.1 | accuracy: 0.41 | loss: 5.78
update:195/2000, 耗时:0.00分/0.46分 | step: 10920 | performance: 40.2 | accuracy: 0.41 | loss: 2.16
update:200/2000, 耗时:0.00分/0.47分 | step: 11200 | performance: 22.8 | accuracy: 0.40 | loss: 1.35
update:205/2000, 耗时:0.00分/0.48分 | step: 11480 | performance: 18.6 | accuracy: 0.40 | loss: 3.26
update:210/2000, 耗时:0.00分/0.49分 | step: 11760 | performance: 11.8 | accuracy: 0.40 | loss: 1.90
update:215/2000, 耗时:0.00分/0.51分 | step: 12040 | performance: 3.4 | accuracy: 0.39 | loss: 1.29
update:220/2000, 耗时:0.00分/0.52分 | step: 12320 | performance: 1.8 | accuracy: 0.39 | loss: 1.50
update:225/2000, 耗时:0.00分/0.53分 | step: 12600 | performance: 1.5 | accuracy: 0.39 | loss: 3.26
update:230/2000, 耗时:0.00分/0.54分 | step: 12880 | performance: 1.8 | accuracy: 0.39 | loss: 5.76
update:235/2000, 耗时:0.00分/0.55分 | step: 13160 | performance: 1.7 | accuracy: 0.39 | loss: 1.39
update:240/2000, 耗时:0.00分/0.57分 | step: 13440 | performance: 1.4 | accuracy: 0.40 | loss: 1.42
update:245/2000, 耗时:0.00分/0.58分 | step: 13720 | performance: 1.2 | accuracy: 0.39 | loss: 1.56
update:250/2000, 耗时:0.00分/0.59分 | step: 14000 | performance: 1.2 | accuracy: 0.39 | loss: 1.32
update:255/2000, 耗时:0.00分/0.60分 | step: 14280 | performance: 2.5 | accuracy: 0.40 | loss: 0.25
update:260/2000, 耗时:0.00分/0.61分 | step: 14560 | performance: 2.1 | accuracy: 0.40 | loss: 1.80
update:265/2000, 耗时:0.00分/0.63分 | step: 14840 | performance: 1.5 | accuracy: 0.40 | loss: 1.62
update:270/2000, 耗时:0.00分/0.64分 | step: 15120 | performance: 1.5 | accuracy: 0.40 | loss: 1.07
update:275/2000, 耗时:0.00分/0.65分 | step: 15400 | performance: 1.9 | accuracy: 0.41 | loss: 2.08
update:280/2000, 耗时:0.00分/0.67分 | step: 15680 | performance: 5.3 | accuracy: 0.41 | loss: 5.69
update:285/2000, 耗时:0.00分/0.68分 | step: 15960 | performance: 11.3 | accuracy: 0.42 | loss: 1.43
update:290/2000, 耗时:0.00分/0.70分 | step: 16240 | performance: 10.6 | accuracy: 0.42 | loss: 11.35
update:295/2000, 耗时:0.00分/0.71分 | step: 16520 | performance: 49.6 | accuracy: 0.43 | loss: 7.67
update:300/2000, 耗时:0.00分/0.72分 | step: 16800 | performance: 194.2 | accuracy: 0.43 | loss: 2.63
update:305/2000, 耗时:0.00分/0.74分 | step: 17080 | performance: 111.5 | accuracy: 0.43 | loss: 1.29
update:310/2000, 耗时:0.00分/0.75分 | step: 17360 | performance: 616.4 | accuracy: 0.44 | loss: 3.52
update:315/2000, 耗时:0.00分/0.76分 | step: 17640 | performance: 559.1 | accuracy: 0.44 | loss: 2.39
update:320/2000, 耗时:0.00分/0.78分 | step: 17920 | performance: 582.6 | accuracy: 0.44 | loss: 12.70
update:325/2000, 耗时:0.00分/0.79分 | step: 18200 | performance: 986.0 | accuracy: 0.44 | loss: 1.96
update:330/2000, 耗时:0.00分/0.80分 | step: 18480 | performance: 637.0 | accuracy: 0.44 | loss: 1.67
update:335/2000, 耗时:0.00分/0.82分 | step: 18760 | performance: 322.0 | accuracy: 0.44 | loss: 7.62
update:340/2000, 耗时:0.00分/0.83分 | step: 19040 | performance: 301.6 | accuracy: 0.44 | loss: 1.80
update:345/2000, 耗时:0.00分/0.84分 | step: 19320 | performance: 364.3 | accuracy: 0.44 | loss: 5.72
update:350/2000, 耗时:0.00分/0.86分 | step: 19600 | performance: 382.6 | accuracy: 0.44 | loss: 2.02
update:355/2000, 耗时:0.00分/0.87分 | step: 19880 | performance: 301.8 | accuracy: 0.44 | loss: 7.72
update:360/2000, 耗时:0.00分/0.88分 | step: 20160 | performance: 135.6 | accuracy: 0.44 | loss: 0.86
update:365/2000, 耗时:0.00分/0.90分 | step: 20440 | performance: 95.1 | accuracy: 0.44 | loss: 1.53
update:370/2000, 耗时:0.00分/0.91分 | step: 20720 | performance: 87.3 | accuracy: 0.44 | loss: 1.43
update:375/2000, 耗时:0.00分/0.92分 | step: 21000 | performance: 58.1 | accuracy: 0.43 | loss: 2.75
update:380/2000, 耗时:0.00分/0.93分 | step: 21280 | performance: 94.8 | accuracy: 0.43 | loss: 1.50
update:385/2000, 耗时:0.00分/0.95分 | step: 21560 | performance: 94.8 | accuracy: 0.44 | loss: 3.62
update:390/2000, 耗时:0.00分/0.96分 | step: 21840 | performance: 55.0 | accuracy: 0.43 | loss: 0.81
update:395/2000, 耗时:0.00分/0.98分 | step: 22120 | performance: 32.8 | accuracy: 0.43 | loss: 1.28
update:400/2000, 耗时:0.00分/0.99分 | step: 22400 | performance: 33.5 | accuracy: 0.43 | loss: 0.66
update:405/2000, 耗时:0.00分/1.00分 | step: 22680 | performance: 44.2 | accuracy: 0.43 | loss: 1.28
update:410/2000, 耗时:0.00分/1.01分 | step: 22960 | performance: 69.0 | accuracy: 0.43 | loss: 3.80
update:415/2000, 耗时:0.00分/1.03分 | step: 23240 | performance: 55.8 | accuracy: 0.43 | loss: 6.75
update:420/2000, 耗时:0.00分/1.04分 | step: 23520 | performance: 34.4 | accuracy: 0.43 | loss: 3.26
update:425/2000, 耗时:0.00分/1.05分 | step: 23800 | performance: 21.0 | accuracy: 0.43 | loss: 3.39
update:430/2000, 耗时:0.00分/1.07分 | step: 24080 | performance: 26.4 | accuracy: 0.43 | loss: 0.90
update:435/2000, 耗时:0.00分/1.08分 | step: 24360 | performance: 34.1 | accuracy: 0.43 | loss: 2.98
update:440/2000, 耗时:0.00分/1.09分 | step: 24640 | performance: 98.0 | accuracy: 0.44 | loss: 3.37
update:445/2000, 耗时:0.00分/1.11分 | step: 24920 | performance: 90.6 | accuracy: 0.44 | loss: 1.67
update:450/2000, 耗时:0.00分/1.12分 | step: 25200 | performance: 446.3 | accuracy: 0.44 | loss: 0.75
update:455/2000, 耗时:0.00分/1.13分 | step: 25480 | performance: 469.1 | accuracy: 0.44 | loss: 4.58
update:460/2000, 耗时:0.00分/1.15分 | step: 25760 | performance: 294.0 | accuracy: 0.44 | loss: 4.75
update:465/2000, 耗时:0.00分/1.16分 | step: 26040 | performance: 273.7 | accuracy: 0.44 | loss: 0.98
update:470/2000, 耗时:0.00分/1.17分 | step: 26320 | performance: 602.9 | accuracy: 0.44 | loss: 0.71
update:475/2000, 耗时:0.00分/1.19分 | step: 26600 | performance: 744.1 | accuracy: 0.45 | loss: 1.34
update:480/2000, 耗时:0.00分/1.20分 | step: 26880 | performance: 667.8 | accuracy: 0.45 | loss: 2.31
update:485/2000, 耗时:0.00分/1.21分 | step: 27160 | performance: 813.3 | accuracy: 0.45 | loss: 4.38
update:490/2000, 耗时:0.00分/1.22分 | step: 27440 | performance: 1597.5 | accuracy: 0.45 | loss: 10.13
update:495/2000, 耗时:0.00分/1.23分 | step: 27720 | performance: 1884.7 | accuracy: 0.45 | loss: 1.85
update:500/2000, 耗时:0.00分/1.25分 | step: 28000 | performance: 1622.4 | accuracy: 0.45 | loss: 1.91
step: 28273 | worker_0@n_step_6: average total_reward after train data exhaustion : 173.2 | max total_reward: 173.2
step: 28274 | worker_1@n_step_6: average total_reward after train data exhaustion : 173.5 | max total_reward: 173.7
step: 28275 | worker_2@n_step_6: average total_reward after train data exhaustion : 174.8 | max total_reward: 177.4
step: 28276 | worker_3@n_step_6: average total_reward after train data exhaustion : 183.0 | max total_reward: 207.6
step: 28277 | worker_4@n_step_6: average total_reward after train data exhaustion : 193.0 | max total_reward: 232.9
step: 28278 | worker_5@n_step_6: average total_reward after train data exhaustion : 180.3 | max total_reward: 232.9
step: 28279 | worker_6@n_step_6: average total_reward after train data exhaustion : 182.7 | max total_reward: 232.9
step: 28280 | worker_7@n_step_6: average total_reward after train data exhaustion : 187.5 | max total_reward: 232.9
update:505/2000, 耗时:0.00分/1.26分 | step: 28280 | performance: 1.0 | accuracy: 0.00 | loss: 0.68
Saving PPO weights in both H5 format and checkpoint @ update:505 
update:510/2000, 耗时:0.00分/1.27分 | step: 28560 | performance: 1.0 | accuracy: 0.54 | loss: 1.07
update:515/2000, 耗时:0.00分/1.29分 | step: 28840 | performance: 2.1 | accuracy: 0.60 | loss: 3.30
update:520/2000, 耗时:0.00分/1.30分 | step: 29120 | performance: 0.9 | accuracy: 0.48 | loss: 2.86
update:525/2000, 耗时:0.00分/1.31分 | step: 29400 | performance: 1.0 | accuracy: 0.45 | loss: 2.36
update:530/2000, 耗时:0.00分/1.32分 | step: 29680 | performance: 2.5 | accuracy: 0.49 | loss: 3.55
update:535/2000, 耗时:0.00分/1.33分 | step: 29960 | performance: 3.8 | accuracy: 0.49 | loss: 2.39
update:540/2000, 耗时:0.00分/1.34分 | step: 30240 | performance: 4.3 | accuracy: 0.49 | loss: 4.06
update:545/2000, 耗时:0.00分/1.35分 | step: 30520 | performance: 2.9 | accuracy: 0.46 | loss: 8.67
update:550/2000, 耗时:0.00分/1.37分 | step: 30800 | performance: 3.6 | accuracy: 0.47 | loss: 3.90
update:555/2000, 耗时:0.00分/1.38分 | step: 31080 | performance: 5.1 | accuracy: 0.47 | loss: 0.44
update:560/2000, 耗时:0.00分/1.39分 | step: 31360 | performance: 5.4 | accuracy: 0.44 | loss: 0.40
update:565/2000, 耗时:0.00分/1.40分 | step: 31640 | performance: 4.8 | accuracy: 0.44 | loss: 1.46
update:570/2000, 耗时:0.00分/1.41分 | step: 31920 | performance: 5.1 | accuracy: 0.44 | loss: 5.40
update:575/2000, 耗时:0.00分/1.43分 | step: 32200 | performance: 5.2 | accuracy: 0.44 | loss: 2.13
update:580/2000, 耗时:0.00分/1.44分 | step: 32480 | performance: 10.9 | accuracy: 0.45 | loss: 2.14
update:585/2000, 耗时:0.00分/1.45分 | step: 32760 | performance: 50.9 | accuracy: 0.47 | loss: 9.93
update:590/2000, 耗时:0.00分/1.46分 | step: 33040 | performance: 35.0 | accuracy: 0.46 | loss: 1.63
update:595/2000, 耗时:0.00分/1.47分 | step: 33320 | performance: 49.7 | accuracy: 0.47 | loss: 4.30
update:600/2000, 耗时:0.00分/1.48分 | step: 33600 | performance: 66.4 | accuracy: 0.47 | loss: 1.70
update:605/2000, 耗时:0.00分/1.50分 | step: 33880 | performance: 60.4 | accuracy: 0.47 | loss: 4.55
update:610/2000, 耗时:0.00分/1.51分 | step: 34160 | performance: 48.1 | accuracy: 0.46 | loss: 0.90
update:615/2000, 耗时:0.00分/1.52分 | step: 34440 | performance: 36.3 | accuracy: 0.44 | loss: 1.00
update:620/2000, 耗时:0.00分/1.53分 | step: 34720 | performance: 19.8 | accuracy: 0.43 | loss: 1.18
update:625/2000, 耗时:0.00分/1.54分 | step: 35000 | performance: 22.5 | accuracy: 0.44 | loss: 1.55
update:630/2000, 耗时:0.00分/1.56分 | step: 35280 | performance: 74.4 | accuracy: 0.45 | loss: 10.76
update:635/2000, 耗时:0.00分/1.57分 | step: 35560 | performance: 132.2 | accuracy: 0.45 | loss: 5.25
update:640/2000, 耗时:0.00分/1.58分 | step: 35840 | performance: 173.2 | accuracy: 0.46 | loss: 8.16
update:645/2000, 耗时:0.00分/1.59分 | step: 36120 | performance: 414.4 | accuracy: 0.46 | loss: 2.87
update:650/2000, 耗时:0.00分/1.60分 | step: 36400 | performance: 282.1 | accuracy: 0.46 | loss: 1.87
update:655/2000, 耗时:0.00分/1.62分 | step: 36680 | performance: 442.8 | accuracy: 0.47 | loss: 1.15
update:660/2000, 耗时:0.00分/1.63分 | step: 36960 | performance: 252.3 | accuracy: 0.47 | loss: 1.24
update:665/2000, 耗时:0.00分/1.64分 | step: 37240 | performance: 244.3 | accuracy: 0.47 | loss: 2.21
update:670/2000, 耗时:0.00分/1.65分 | step: 37520 | performance: 162.9 | accuracy: 0.46 | loss: 1.31
update:675/2000, 耗时:0.00分/1.66分 | step: 37800 | performance: 174.9 | accuracy: 0.46 | loss: 3.48
update:680/2000, 耗时:0.00分/1.67分 | step: 38080 | performance: 100.0 | accuracy: 0.45 | loss: 0.45
update:685/2000, 耗时:0.00分/1.69分 | step: 38360 | performance: 180.0 | accuracy: 0.46 | loss: 7.32
update:690/2000, 耗时:0.00分/1.70分 | step: 38640 | performance: 189.5 | accuracy: 0.46 | loss: 1.43
update:695/2000, 耗时:0.00分/1.71分 | step: 38920 | performance: 212.8 | accuracy: 0.46 | loss: 2.31
update:700/2000, 耗时:0.00分/1.72分 | step: 39200 | performance: 133.3 | accuracy: 0.45 | loss: 0.95
update:705/2000, 耗时:0.00分/1.73分 | step: 39480 | performance: 76.3 | accuracy: 0.45 | loss: 3.22
update:710/2000, 耗时:0.00分/1.74分 | step: 39760 | performance: 82.8 | accuracy: 0.44 | loss: 4.80
update:715/2000, 耗时:0.00分/1.75分 | step: 40040 | performance: 54.1 | accuracy: 0.44 | loss: 1.35
update:720/2000, 耗时:0.00分/1.76分 | step: 40320 | performance: 73.3 | accuracy: 0.44 | loss: 1.05
update:725/2000, 耗时:0.00分/1.78分 | step: 40600 | performance: 45.1 | accuracy: 0.44 | loss: 0.63
update:730/2000, 耗时:0.00分/1.79分 | step: 40880 | performance: 37.9 | accuracy: 0.43 | loss: 0.45
update:735/2000, 耗时:0.00分/1.80分 | step: 41160 | performance: 47.8 | accuracy: 0.43 | loss: 8.46
update:740/2000, 耗时:0.00分/1.81分 | step: 41440 | performance: 45.8 | accuracy: 0.43 | loss: 2.07
update:745/2000, 耗时:0.00分/1.82分 | step: 41720 | performance: 39.5 | accuracy: 0.43 | loss: 1.47
update:750/2000, 耗时:0.00分/1.83分 | step: 42000 | performance: 33.9 | accuracy: 0.43 | loss: 1.45
update:755/2000, 耗时:0.00分/1.84分 | step: 42280 | performance: 33.5 | accuracy: 0.43 | loss: 1.16
update:760/2000, 耗时:0.00分/1.85分 | step: 42560 | performance: 57.7 | accuracy: 0.44 | loss: 0.23
update:765/2000, 耗时:0.00分/1.87分 | step: 42840 | performance: 49.3 | accuracy: 0.44 | loss: 1.61
update:770/2000, 耗时:0.00分/1.88分 | step: 43120 | performance: 33.7 | accuracy: 0.44 | loss: 2.18
update:775/2000, 耗时:0.00分/1.89分 | step: 43400 | performance: 35.8 | accuracy: 0.44 | loss: 1.06
update:780/2000, 耗时:0.00分/1.90分 | step: 43680 | performance: 47.6 | accuracy: 0.45 | loss: 2.27
update:785/2000, 耗时:0.00分/1.91分 | step: 43960 | performance: 131.2 | accuracy: 0.45 | loss: 5.94
update:790/2000, 耗时:0.00分/1.92分 | step: 44240 | performance: 281.9 | accuracy: 0.46 | loss: 1.29
update:795/2000, 耗时:0.00分/1.94分 | step: 44520 | performance: 263.3 | accuracy: 0.46 | loss: 10.64
update:800/2000, 耗时:0.00分/1.95分 | step: 44800 | performance: 1238.1 | accuracy: 0.46 | loss: 7.16
update:805/2000, 耗时:0.00分/1.96分 | step: 45080 | performance: 4844.4 | accuracy: 0.47 | loss: 2.59
update:810/2000, 耗时:0.00分/1.97分 | step: 45360 | performance: 2782.2 | accuracy: 0.47 | loss: 1.10
update:815/2000, 耗时:0.00分/1.98分 | step: 45640 | performance: 15381.3 | accuracy: 0.47 | loss: 3.42
update:820/2000, 耗时:0.00分/1.99分 | step: 45920 | performance: 13950.9 | accuracy: 0.47 | loss: 2.48
update:825/2000, 耗时:0.00分/2.00分 | step: 46200 | performance: 14537.7 | accuracy: 0.48 | loss: 12.35
update:830/2000, 耗时:0.00分/2.02分 | step: 46480 | performance: 24603.3 | accuracy: 0.48 | loss: 2.01
update:835/2000, 耗时:0.00分/2.03分 | step: 46760 | performance: 15894.2 | accuracy: 0.48 | loss: 1.81
update:840/2000, 耗时:0.00分/2.04分 | step: 47040 | performance: 7163.7 | accuracy: 0.48 | loss: 8.55
update:845/2000, 耗时:0.00分/2.05分 | step: 47320 | performance: 2941.4 | accuracy: 0.47 | loss: 1.05
update:850/2000, 耗时:0.00分/2.06分 | step: 47600 | performance: 1795.8 | accuracy: 0.47 | loss: 1.23
update:855/2000, 耗时:0.00分/2.07分 | step: 47880 | performance: 1623.3 | accuracy: 0.46 | loss: 1.03
update:860/2000, 耗时:0.00分/2.09分 | step: 48160 | performance: 981.0 | accuracy: 0.46 | loss: 6.02
update:865/2000, 耗时:0.00分/2.10分 | step: 48440 | performance: 648.1 | accuracy: 0.45 | loss: 0.86
update:870/2000, 耗时:0.00分/2.11分 | step: 48720 | performance: 412.5 | accuracy: 0.45 | loss: 0.82
update:875/2000, 耗时:0.00分/2.12分 | step: 49000 | performance: 413.9 | accuracy: 0.45 | loss: 1.55
update:880/2000, 耗时:0.00分/2.13分 | step: 49280 | performance: 217.4 | accuracy: 0.45 | loss: 0.89
update:885/2000, 耗时:0.00分/2.14分 | step: 49560 | performance: 390.5 | accuracy: 0.45 | loss: 1.50
update:890/2000, 耗时:0.00分/2.16分 | step: 49840 | performance: 390.6 | accuracy: 0.45 | loss: 3.99
update:895/2000, 耗时:0.00分/2.17分 | step: 50120 | performance: 226.5 | accuracy: 0.45 | loss: 0.77
update:900/2000, 耗时:0.00分/2.18分 | step: 50400 | performance: 108.5 | accuracy: 0.45 | loss: 1.05
update:905/2000, 耗时:0.00分/2.19分 | step: 50680 | performance: 77.2 | accuracy: 0.44 | loss: 1.90
update:910/2000, 耗时:0.00分/2.20分 | step: 50960 | performance: 96.9 | accuracy: 0.44 | loss: 0.71
update:915/2000, 耗时:0.00分/2.22分 | step: 51240 | performance: 173.5 | accuracy: 0.44 | loss: 0.35
update:920/2000, 耗时:0.00分/2.23分 | step: 51520 | performance: 183.1 | accuracy: 0.44 | loss: 0.24
update:925/2000, 耗时:0.00分/2.24分 | step: 51800 | performance: 184.4 | accuracy: 0.43 | loss: 0.00
update:930/2000, 耗时:0.00分/2.25分 | step: 52080 | performance: 182.1 | accuracy: 0.43 | loss: 0.18
update:935/2000, 耗时:0.00分/2.27分 | step: 52360 | performance: 206.2 | accuracy: 0.43 | loss: 0.97
update:940/2000, 耗时:0.00分/2.28分 | step: 52640 | performance: 220.9 | accuracy: 0.42 | loss: 0.07
update:945/2000, 耗时:0.00分/2.29分 | step: 52920 | performance: 219.7 | accuracy: 0.42 | loss: 0.02
update:950/2000, 耗时:0.00分/2.30分 | step: 53200 | performance: 219.7 | accuracy: 0.41 | loss: 0.12
update:955/2000, 耗时:0.00分/2.31分 | step: 53480 | performance: 297.9 | accuracy: 0.41 | loss: 0.13
update:960/2000, 耗时:0.00分/2.32分 | step: 53760 | performance: 249.5 | accuracy: 0.41 | loss: 0.41
update:965/2000, 耗时:0.00分/2.34分 | step: 54040 | performance: 209.5 | accuracy: 0.40 | loss: 0.39
update:970/2000, 耗时:0.00分/2.35分 | step: 54320 | performance: 184.2 | accuracy: 0.40 | loss: 0.25
update:975/2000, 耗时:0.00分/2.36分 | step: 54600 | performance: 285.3 | accuracy: 0.40 | loss: 0.75
update:980/2000, 耗时:0.00分/2.37分 | step: 54880 | performance: 272.5 | accuracy: 0.40 | loss: 0.15
update:985/2000, 耗时:0.00分/2.38分 | step: 55160 | performance: 253.6 | accuracy: 0.40 | loss: 0.93
update:990/2000, 耗时:0.00分/2.39分 | step: 55440 | performance: 283.3 | accuracy: 0.40 | loss: 3.43
update:995/2000, 耗时:0.00分/2.41分 | step: 55720 | performance: 492.4 | accuracy: 0.40 | loss: 10.90
update:1000/2000, 耗时:0.00分/2.42分 | step: 56000 | performance: 494.6 | accuracy: 0.40 | loss: 1.77
update:1005/2000, 耗时:0.00分/2.43分 | step: 56280 | performance: 453.2 | accuracy: 0.40 | loss: 1.79
step: 56553 | worker_0@n_step_6: average total_reward after train data exhaustion : 192.5 | max total_reward: 232.9
step: 56554 | worker_1@n_step_6: average total_reward after train data exhaustion : 192.0 | max total_reward: 232.9
step: 56555 | worker_2@n_step_6: average total_reward after train data exhaustion : 192.1 | max total_reward: 232.9
step: 56556 | worker_3@n_step_6: average total_reward after train data exhaustion : 192.0 | max total_reward: 232.9
step: 56557 | worker_4@n_step_6: average total_reward after train data exhaustion : 191.4 | max total_reward: 232.9
step: 56558 | worker_5@n_step_6: average total_reward after train data exhaustion : 192.0 | max total_reward: 232.9
step: 56559 | worker_6@n_step_6: average total_reward after train data exhaustion : 193.5 | max total_reward: 232.9
step: 56560 | worker_7@n_step_6: average total_reward after train data exhaustion : 193.2 | max total_reward: 232.9
update:1010/2000, 耗时:0.00分/2.44分 | step: 56560 | performance: 1.0 | accuracy: 0.00 | loss: 0.44
Saving PPO weights in both H5 format and checkpoint @ update:1010 
update:1015/2000, 耗时:0.00分/2.45分 | step: 56840 | performance: 0.9 | accuracy: 0.54 | loss: 1.31
update:1020/2000, 耗时:0.00分/2.47分 | step: 57120 | performance: 2.1 | accuracy: 0.59 | loss: 3.01
update:1025/2000, 耗时:0.00分/2.48分 | step: 57400 | performance: 0.9 | accuracy: 0.44 | loss: 2.19
update:1030/2000, 耗时:0.00分/2.49分 | step: 57680 | performance: 0.8 | accuracy: 0.44 | loss: 2.35
update:1035/2000, 耗时:0.00分/2.50分 | step: 57960 | performance: 1.7 | accuracy: 0.47 | loss: 3.63
update:1040/2000, 耗时:0.00分/2.52分 | step: 58240 | performance: 2.8 | accuracy: 0.48 | loss: 2.36
update:1045/2000, 耗时:0.00分/2.53分 | step: 58520 | performance: 3.2 | accuracy: 0.48 | loss: 4.37
update:1050/2000, 耗时:0.00分/2.54分 | step: 58800 | performance: 2.3 | accuracy: 0.46 | loss: 7.36
update:1055/2000, 耗时:0.00分/2.55分 | step: 59080 | performance: 3.1 | accuracy: 0.46 | loss: 4.36
update:1060/2000, 耗时:0.00分/2.56分 | step: 59360 | performance: 4.6 | accuracy: 0.47 | loss: 0.50
update:1065/2000, 耗时:0.00分/2.57分 | step: 59640 | performance: 5.3 | accuracy: 0.45 | loss: 0.48
update:1070/2000, 耗时:0.00分/2.59分 | step: 59920 | performance: 4.7 | accuracy: 0.44 | loss: 1.33
update:1075/2000, 耗时:0.00分/2.60分 | step: 60200 | performance: 5.4 | accuracy: 0.43 | loss: 4.67
update:1080/2000, 耗时:0.00分/2.61分 | step: 60480 | performance: 5.8 | accuracy: 0.43 | loss: 1.52
update:1085/2000, 耗时:0.00分/2.62分 | step: 60760 | performance: 10.2 | accuracy: 0.43 | loss: 0.70
update:1090/2000, 耗时:0.00分/2.63分 | step: 61040 | performance: 13.7 | accuracy: 0.41 | loss: 0.24
update:1095/2000, 耗时:0.00分/2.65分 | step: 61320 | performance: 11.0 | accuracy: 0.41 | loss: 0.35
update:1100/2000, 耗时:0.00分/2.66分 | step: 61600 | performance: 12.5 | accuracy: 0.40 | loss: 2.61
update:1105/2000, 耗时:0.00分/2.67分 | step: 61880 | performance: 15.1 | accuracy: 0.40 | loss: 1.15
update:1110/2000, 耗时:0.00分/2.68分 | step: 62160 | performance: 12.8 | accuracy: 0.39 | loss: 4.09
update:1115/2000, 耗时:0.00分/2.69分 | step: 62440 | performance: 10.1 | accuracy: 0.39 | loss: 0.76
update:1120/2000, 耗时:0.00分/2.70分 | step: 62720 | performance: 8.8 | accuracy: 0.38 | loss: 0.80
update:1125/2000, 耗时:0.00分/2.72分 | step: 63000 | performance: 6.8 | accuracy: 0.38 | loss: 4.04
update:1130/2000, 耗时:0.00分/2.73分 | step: 63280 | performance: 7.7 | accuracy: 0.39 | loss: 1.63
update:1135/2000, 耗时:0.00分/2.74分 | step: 63560 | performance: 25.5 | accuracy: 0.41 | loss: 10.57
update:1140/2000, 耗时:0.00分/2.75分 | step: 63840 | performance: 45.2 | accuracy: 0.41 | loss: 5.64
update:1145/2000, 耗时:0.00分/2.76分 | step: 64120 | performance: 59.2 | accuracy: 0.42 | loss: 7.93
update:1150/2000, 耗时:0.00分/2.77分 | step: 64400 | performance: 141.7 | accuracy: 0.43 | loss: 2.93
update:1155/2000, 耗时:0.00分/2.79分 | step: 64680 | performance: 96.5 | accuracy: 0.43 | loss: 1.77
update:1160/2000, 耗时:0.00分/2.80分 | step: 64960 | performance: 151.5 | accuracy: 0.43 | loss: 1.09
update:1165/2000, 耗时:0.00分/2.81分 | step: 65240 | performance: 81.2 | accuracy: 0.43 | loss: 1.19
update:1170/2000, 耗时:0.00分/2.82分 | step: 65520 | performance: 82.1 | accuracy: 0.43 | loss: 2.37
update:1175/2000, 耗时:0.00分/2.83分 | step: 65800 | performance: 34.3 | accuracy: 0.43 | loss: 0.85
update:1180/2000, 耗时:0.00分/2.84分 | step: 66080 | performance: 34.7 | accuracy: 0.43 | loss: 2.66
update:1185/2000, 耗时:0.00分/2.86分 | step: 66360 | performance: 16.2 | accuracy: 0.42 | loss: 0.31
update:1190/2000, 耗时:0.00分/2.87分 | step: 66640 | performance: 30.5 | accuracy: 0.43 | loss: 5.95
update:1195/2000, 耗时:0.00分/2.88分 | step: 66920 | performance: 35.3 | accuracy: 0.43 | loss: 1.06
update:1200/2000, 耗时:0.00分/2.89分 | step: 67200 | performance: 38.5 | accuracy: 0.43 | loss: 2.65
update:1205/2000, 耗时:0.00分/2.90分 | step: 67480 | performance: 26.6 | accuracy: 0.42 | loss: 1.78
update:1210/2000, 耗时:0.00分/2.91分 | step: 67760 | performance: 16.7 | accuracy: 0.42 | loss: 2.92
update:1215/2000, 耗时:0.00分/2.93分 | step: 68040 | performance: 18.5 | accuracy: 0.42 | loss: 5.07
update:1220/2000, 耗时:0.00分/2.94分 | step: 68320 | performance: 11.0 | accuracy: 0.42 | loss: 1.78
update:1225/2000, 耗时:0.00分/2.95分 | step: 68600 | performance: 19.7 | accuracy: 0.41 | loss: 0.09
update:1230/2000, 耗时:0.00分/2.96分 | step: 68880 | performance: 17.1 | accuracy: 0.41 | loss: 0.37
update:1235/2000, 耗时:0.00分/2.97分 | step: 69160 | performance: 12.3 | accuracy: 0.40 | loss: 2.01
update:1240/2000, 耗时:0.00分/2.99分 | step: 69440 | performance: 12.3 | accuracy: 0.41 | loss: 8.17
update:1245/2000, 耗时:0.00分/3.00分 | step: 69720 | performance: 12.3 | accuracy: 0.41 | loss: 2.59
update:1250/2000, 耗时:0.00分/3.01分 | step: 70000 | performance: 10.7 | accuracy: 0.41 | loss: 1.45
update:1255/2000, 耗时:0.00分/3.02分 | step: 70280 | performance: 9.4 | accuracy: 0.41 | loss: 1.49
update:1260/2000, 耗时:0.00分/3.03分 | step: 70560 | performance: 9.6 | accuracy: 0.41 | loss: 2.19
update:1265/2000, 耗时:0.00分/3.05分 | step: 70840 | performance: 21.2 | accuracy: 0.42 | loss: 0.22
update:1270/2000, 耗时:0.00分/3.06分 | step: 71120 | performance: 18.1 | accuracy: 0.42 | loss: 1.64
update:1275/2000, 耗时:0.00分/3.07分 | step: 71400 | performance: 12.4 | accuracy: 0.42 | loss: 2.11
update:1280/2000, 耗时:0.00分/3.08分 | step: 71680 | performance: 13.3 | accuracy: 0.42 | loss: 0.66
update:1285/2000, 耗时:0.00分/3.09分 | step: 71960 | performance: 18.9 | accuracy: 0.43 | loss: 2.21
update:1290/2000, 耗时:0.00分/3.10分 | step: 72240 | performance: 52.1 | accuracy: 0.44 | loss: 5.61
update:1295/2000, 耗时:0.00分/3.12分 | step: 72520 | performance: 111.9 | accuracy: 0.44 | loss: 1.36
update:1300/2000, 耗时:0.00分/3.13分 | step: 72800 | performance: 104.5 | accuracy: 0.44 | loss: 10.70
update:1305/2000, 耗时:0.00分/3.14分 | step: 73080 | performance: 491.6 | accuracy: 0.45 | loss: 6.98
update:1310/2000, 耗时:0.00分/3.15分 | step: 73360 | performance: 1923.7 | accuracy: 0.45 | loss: 2.64
update:1315/2000, 耗时:0.00分/3.16分 | step: 73640 | performance: 1104.8 | accuracy: 0.45 | loss: 1.10
update:1320/2000, 耗时:0.00分/3.17分 | step: 73920 | performance: 6107.8 | accuracy: 0.46 | loss: 3.30
update:1325/2000, 耗时:0.00分/3.18分 | step: 74200 | performance: 5539.8 | accuracy: 0.46 | loss: 2.46
update:1330/2000, 耗时:0.00分/3.20分 | step: 74480 | performance: 5772.8 | accuracy: 0.46 | loss: 12.58
update:1335/2000, 耗时:0.00分/3.21分 | step: 74760 | performance: 9769.8 | accuracy: 0.46 | loss: 1.92
update:1340/2000, 耗时:0.00分/3.22分 | step: 75040 | performance: 6311.5 | accuracy: 0.46 | loss: 1.81
update:1345/2000, 耗时:0.00分/3.23分 | step: 75320 | performance: 3190.4 | accuracy: 0.46 | loss: 6.86
update:1350/2000, 耗时:0.00分/3.24分 | step: 75600 | performance: 2632.3 | accuracy: 0.46 | loss: 0.52
update:1355/2000, 耗时:0.00分/3.25分 | step: 75880 | performance: 2464.0 | accuracy: 0.45 | loss: 1.01
update:1360/2000, 耗时:0.00分/3.27分 | step: 76160 | performance: 1926.4 | accuracy: 0.45 | loss: 1.10
update:1365/2000, 耗时:0.00分/3.28分 | step: 76440 | performance: 1561.6 | accuracy: 0.45 | loss: 4.99
update:1370/2000, 耗时:0.00分/3.29分 | step: 76720 | performance: 1373.6 | accuracy: 0.44 | loss: 0.17
update:1375/2000, 耗时:0.00分/3.30分 | step: 77000 | performance: 839.0 | accuracy: 0.44 | loss: 0.59
update:1380/2000, 耗时:0.00分/3.31分 | step: 77280 | performance: 605.8 | accuracy: 0.43 | loss: 1.06
update:1385/2000, 耗时:0.00分/3.32分 | step: 77560 | performance: 512.5 | accuracy: 0.43 | loss: 0.49
update:1390/2000, 耗时:0.00分/3.33分 | step: 77840 | performance: 1078.9 | accuracy: 0.43 | loss: 1.52
update:1395/2000, 耗时:0.00分/3.34分 | step: 78120 | performance: 1079.1 | accuracy: 0.44 | loss: 3.98
update:1400/2000, 耗时:0.00分/3.36分 | step: 78400 | performance: 625.9 | accuracy: 0.43 | loss: 0.76
update:1405/2000, 耗时:0.00分/3.37分 | step: 78680 | performance: 278.4 | accuracy: 0.43 | loss: 0.33
update:1410/2000, 耗时:0.00分/3.38分 | step: 78960 | performance: 271.6 | accuracy: 0.43 | loss: 0.46
update:1415/2000, 耗时:0.00分/3.39分 | step: 79240 | performance: 336.2 | accuracy: 0.43 | loss: 0.74
update:1420/2000, 耗时:0.00分/3.40分 | step: 79520 | performance: 474.8 | accuracy: 0.42 | loss: 0.01
update:1425/2000, 耗时:0.00分/3.41分 | step: 79800 | performance: 569.0 | accuracy: 0.42 | loss: 0.44
update:1430/2000, 耗时:0.00分/3.42分 | step: 80080 | performance: 569.0 | accuracy: 0.41 | loss: 0.05
update:1435/2000, 耗时:0.00分/3.43分 | step: 80360 | performance: 554.7 | accuracy: 0.41 | loss: 0.16
update:1440/2000, 耗时:0.00分/3.45分 | step: 80640 | performance: 689.8 | accuracy: 0.41 | loss: 0.80
update:1445/2000, 耗时:0.00分/3.46分 | step: 80920 | performance: 624.1 | accuracy: 0.40 | loss: 0.24
update:1450/2000, 耗时:0.00分/3.47分 | step: 81200 | performance: 744.4 | accuracy: 0.40 | loss: 0.09
update:1455/2000, 耗时:0.00分/3.48分 | step: 81480 | performance: 576.4 | accuracy: 0.40 | loss: 1.44
update:1460/2000, 耗时:0.00分/3.49分 | step: 81760 | performance: 2479.2 | accuracy: 0.40 | loss: 0.77
update:1465/2000, 耗时:0.00分/3.50分 | step: 82040 | performance: 2650.5 | accuracy: 0.40 | loss: 3.60
update:1470/2000, 耗时:0.00分/3.51分 | step: 82320 | performance: 1768.9 | accuracy: 0.41 | loss: 4.55
update:1475/2000, 耗时:0.00分/3.53分 | step: 82600 | performance: 1588.6 | accuracy: 0.41 | loss: 0.96
update:1480/2000, 耗时:0.00分/3.54分 | step: 82880 | performance: 3499.3 | accuracy: 0.41 | loss: 0.64
update:1485/2000, 耗时:0.00分/3.55分 | step: 83160 | performance: 3446.5 | accuracy: 0.41 | loss: 0.60
update:1490/2000, 耗时:0.00分/3.56分 | step: 83440 | performance: 2953.6 | accuracy: 0.41 | loss: 2.50
update:1495/2000, 耗时:0.00分/3.57分 | step: 83720 | performance: 3541.7 | accuracy: 0.41 | loss: 4.45
update:1500/2000, 耗时:0.00分/3.58分 | step: 84000 | performance: 6477.6 | accuracy: 0.41 | loss: 13.66
update:1505/2000, 耗时:0.00分/3.60分 | step: 84280 | performance: 7359.2 | accuracy: 0.41 | loss: 1.73
update:1510/2000, 耗时:0.00分/3.61分 | step: 84560 | performance: 5841.4 | accuracy: 0.41 | loss: 2.27
step: 84833 | worker_0@n_step_6: average total_reward after train data exhaustion : 197.8 | max total_reward: 270.9
step: 84834 | worker_1@n_step_6: average total_reward after train data exhaustion : 200.9 | max total_reward: 270.9
step: 84835 | worker_2@n_step_6: average total_reward after train data exhaustion : 204.2 | max total_reward: 270.9
step: 84836 | worker_3@n_step_6: average total_reward after train data exhaustion : 206.7 | max total_reward: 270.9
step: 84837 | worker_4@n_step_6: average total_reward after train data exhaustion : 208.8 | max total_reward: 270.9
step: 84838 | worker_5@n_step_6: average total_reward after train data exhaustion : 211.7 | max total_reward: 271.0
step: 84839 | worker_6@n_step_6: average total_reward after train data exhaustion : 211.4 | max total_reward: 271.0
step: 84840 | worker_7@n_step_6: average total_reward after train data exhaustion : 214.6 | max total_reward: 288.5
update:1515/2000, 耗时:0.00分/3.62分 | step: 84840 | performance: 1.0 | accuracy: 0.00 | loss: 0.76
Saving PPO weights in both H5 format and checkpoint @ update:1515 
update:1520/2000, 耗时:0.00分/3.64分 | step: 85120 | performance: 1.1 | accuracy: 0.46 | loss: 1.33
update:1525/2000, 耗时:0.00分/3.65分 | step: 85400 | performance: 2.8 | accuracy: 0.57 | loss: 3.45
update:1530/2000, 耗时:0.00分/3.66分 | step: 85680 | performance: 1.0 | accuracy: 0.46 | loss: 3.97
update:1535/2000, 耗时:0.00分/3.67分 | step: 85960 | performance: 0.9 | accuracy: 0.47 | loss: 3.03
update:1540/2000, 耗时:0.00分/3.68分 | step: 86240 | performance: 2.3 | accuracy: 0.51 | loss: 4.18
update:1545/2000, 耗时:0.00分/3.69分 | step: 86520 | performance: 3.6 | accuracy: 0.51 | loss: 2.27
update:1550/2000, 耗时:0.00分/3.71分 | step: 86800 | performance: 3.9 | accuracy: 0.51 | loss: 4.55
update:1555/2000, 耗时:0.00分/3.72分 | step: 87080 | performance: 2.2 | accuracy: 0.49 | loss: 9.77
update:1560/2000, 耗时:0.00分/3.73分 | step: 87360 | performance: 3.0 | accuracy: 0.51 | loss: 6.93
update:1565/2000, 耗时:0.00分/3.74分 | step: 87640 | performance: 4.3 | accuracy: 0.51 | loss: 0.53
update:1570/2000, 耗时:0.00分/3.75分 | step: 87920 | performance: 4.8 | accuracy: 0.50 | loss: 0.36
update:1575/2000, 耗时:0.00分/3.76分 | step: 88200 | performance: 4.2 | accuracy: 0.49 | loss: 1.58
update:1580/2000, 耗时:0.00分/3.77分 | step: 88480 | performance: 4.3 | accuracy: 0.48 | loss: 5.67
update:1585/2000, 耗时:0.00分/3.78分 | step: 88760 | performance: 5.1 | accuracy: 0.50 | loss: 1.94
update:1590/2000, 耗时:0.00分/3.80分 | step: 89040 | performance: 10.6 | accuracy: 0.50 | loss: 1.78
update:1595/2000, 耗时:0.00分/3.81分 | step: 89320 | performance: 53.3 | accuracy: 0.52 | loss: 8.31
update:1600/2000, 耗时:0.00分/3.82分 | step: 89600 | performance: 36.6 | accuracy: 0.51 | loss: 1.97
update:1605/2000, 耗时:0.00分/3.83分 | step: 89880 | performance: 51.3 | accuracy: 0.51 | loss: 4.61
update:1610/2000, 耗时:0.00分/3.84分 | step: 90160 | performance: 68.5 | accuracy: 0.51 | loss: 1.75
update:1615/2000, 耗时:0.00分/3.85分 | step: 90440 | performance: 62.8 | accuracy: 0.51 | loss: 5.48
update:1620/2000, 耗时:0.00分/3.86分 | step: 90720 | performance: 54.4 | accuracy: 0.50 | loss: 2.08
update:1625/2000, 耗时:0.00分/3.88分 | step: 91000 | performance: 43.4 | accuracy: 0.50 | loss: 1.28
update:1630/2000, 耗时:0.00分/3.89分 | step: 91280 | performance: 21.8 | accuracy: 0.49 | loss: 1.73
update:1635/2000, 耗时:0.00分/3.90分 | step: 91560 | performance: 24.7 | accuracy: 0.50 | loss: 1.59
update:1640/2000, 耗时:0.00分/3.91分 | step: 91840 | performance: 81.9 | accuracy: 0.51 | loss: 10.66
update:1645/2000, 耗时:0.00分/3.92分 | step: 92120 | performance: 145.5 | accuracy: 0.51 | loss: 5.40
update:1650/2000, 耗时:0.00分/3.93分 | step: 92400 | performance: 190.6 | accuracy: 0.51 | loss: 7.93
update:1655/2000, 耗时:0.00分/3.94分 | step: 92680 | performance: 456.1 | accuracy: 0.52 | loss: 2.71
update:1660/2000, 耗时:0.00分/3.95分 | step: 92960 | performance: 310.5 | accuracy: 0.51 | loss: 1.70
update:1665/2000, 耗时:0.00分/3.97分 | step: 93240 | performance: 486.1 | accuracy: 0.52 | loss: 1.20
update:1670/2000, 耗时:0.00分/3.98分 | step: 93520 | performance: 260.8 | accuracy: 0.51 | loss: 1.44
update:1675/2000, 耗时:0.00分/3.99分 | step: 93800 | performance: 182.9 | accuracy: 0.51 | loss: 2.17
update:1680/2000, 耗时:0.00分/4.00分 | step: 94080 | performance: 183.2 | accuracy: 0.51 | loss: 0.41
update:1685/2000, 耗时:0.00分/4.01分 | step: 94360 | performance: 212.7 | accuracy: 0.51 | loss: 6.80
update:1690/2000, 耗时:0.00分/4.02分 | step: 94640 | performance: 119.8 | accuracy: 0.51 | loss: 1.04
update:1695/2000, 耗时:0.00分/4.03分 | step: 94920 | performance: 270.1 | accuracy: 0.52 | loss: 8.34
update:1700/2000, 耗时:0.00分/4.04分 | step: 95200 | performance: 312.2 | accuracy: 0.52 | loss: 1.45
update:1705/2000, 耗时:0.00分/4.06分 | step: 95480 | performance: 376.1 | accuracy: 0.52 | loss: 5.35
update:1710/2000, 耗时:0.00分/4.07分 | step: 95760 | performance: 238.3 | accuracy: 0.52 | loss: 3.36
update:1715/2000, 耗时:0.00分/4.08分 | step: 96040 | performance: 141.8 | accuracy: 0.51 | loss: 7.47
update:1720/2000, 耗时:0.00分/4.09分 | step: 96320 | performance: 138.8 | accuracy: 0.51 | loss: 4.99
update:1725/2000, 耗时:0.00分/4.10分 | step: 96600 | performance: 84.6 | accuracy: 0.51 | loss: 1.44
update:1730/2000, 耗时:0.00分/4.11分 | step: 96880 | performance: 145.6 | accuracy: 0.50 | loss: 1.09
update:1735/2000, 耗时:0.00分/4.12分 | step: 97160 | performance: 93.7 | accuracy: 0.50 | loss: 1.45
update:1740/2000, 耗时:0.00分/4.13分 | step: 97440 | performance: 67.9 | accuracy: 0.50 | loss: 6.66
update:1745/2000, 耗时:0.00分/4.15分 | step: 97720 | performance: 54.5 | accuracy: 0.50 | loss: 7.73
update:1750/2000, 耗时:0.00分/4.16分 | step: 98000 | performance: 54.6 | accuracy: 0.50 | loss: 3.01
update:1755/2000, 耗时:0.00分/4.17分 | step: 98280 | performance: 47.2 | accuracy: 0.50 | loss: 1.45
update:1760/2000, 耗时:0.00分/4.18分 | step: 98560 | performance: 36.5 | accuracy: 0.49 | loss: 1.83
update:1765/2000, 耗时:0.00分/4.19分 | step: 98840 | performance: 31.7 | accuracy: 0.49 | loss: 0.97
update:1770/2000, 耗时:0.00分/4.20分 | step: 99120 | performance: 70.4 | accuracy: 0.50 | loss: 0.21
update:1775/2000, 耗时:0.00分/4.21分 | step: 99400 | performance: 60.1 | accuracy: 0.50 | loss: 1.52
update:1780/2000, 耗时:0.00分/4.22分 | step: 99680 | performance: 41.0 | accuracy: 0.50 | loss: 2.20
update:1785/2000, 耗时:0.00分/4.24分 | step: 99960 | performance: 41.2 | accuracy: 0.50 | loss: 0.76
update:1790/2000, 耗时:0.00分/4.25分 | step: 100240 | performance: 46.8 | accuracy: 0.50 | loss: 2.31
update:1795/2000, 耗时:0.00分/4.26分 | step: 100520 | performance: 129.0 | accuracy: 0.50 | loss: 5.83
update:1800/2000, 耗时:0.00分/4.27分 | step: 100800 | performance: 277.2 | accuracy: 0.51 | loss: 1.23
update:1805/2000, 耗时:0.00分/4.28分 | step: 101080 | performance: 258.8 | accuracy: 0.51 | loss: 10.58
update:1810/2000, 耗时:0.00分/4.29分 | step: 101360 | performance: 1217.3 | accuracy: 0.51 | loss: 6.91
update:1815/2000, 耗时:0.00分/4.31分 | step: 101640 | performance: 4763.2 | accuracy: 0.52 | loss: 2.42
update:1820/2000, 耗时:0.00分/4.32分 | step: 101920 | performance: 2735.6 | accuracy: 0.51 | loss: 1.02
update:1825/2000, 耗时:0.00分/4.33分 | step: 102200 | performance: 15123.3 | accuracy: 0.52 | loss: 3.28
update:1830/2000, 耗时:0.00分/4.34分 | step: 102480 | performance: 13716.9 | accuracy: 0.52 | loss: 2.39
update:1835/2000, 耗时:0.00分/4.35分 | step: 102760 | performance: 14293.8 | accuracy: 0.52 | loss: 12.17
update:1840/2000, 耗时:0.00分/4.36分 | step: 103040 | performance: 24190.5 | accuracy: 0.52 | loss: 2.12
update:1845/2000, 耗时:0.00分/4.37分 | step: 103320 | performance: 15627.6 | accuracy: 0.52 | loss: 1.81
update:1850/2000, 耗时:0.00分/4.39分 | step: 103600 | performance: 9122.2 | accuracy: 0.52 | loss: 4.09
update:1855/2000, 耗时:0.00分/4.40分 | step: 103880 | performance: 8454.3 | accuracy: 0.52 | loss: 1.83
update:1860/2000, 耗时:0.00分/4.41分 | step: 104160 | performance: 12477.3 | accuracy: 0.52 | loss: 8.89
update:1865/2000, 耗时:0.00分/4.42分 | step: 104440 | performance: 13427.9 | accuracy: 0.52 | loss: 2.31
update:1870/2000, 耗时:0.00分/4.43分 | step: 104720 | performance: 9511.2 | accuracy: 0.52 | loss: 8.32
update:1875/2000, 耗时:0.00分/4.44分 | step: 105000 | performance: 3875.8 | accuracy: 0.51 | loss: 1.16
update:1880/2000, 耗时:0.00分/4.45分 | step: 105280 | performance: 1863.4 | accuracy: 0.51 | loss: 2.77
update:1885/2000, 耗时:0.00分/4.46分 | step: 105560 | performance: 1379.2 | accuracy: 0.51 | loss: 1.64
update:1890/2000, 耗时:0.00分/4.48分 | step: 105840 | performance: 1319.7 | accuracy: 0.51 | loss: 1.30
update:1895/2000, 耗时:0.00分/4.49分 | step: 106120 | performance: 3971.9 | accuracy: 0.51 | loss: 1.57
update:1900/2000, 耗时:0.00分/4.50分 | step: 106400 | performance: 3972.4 | accuracy: 0.51 | loss: 4.04
update:1905/2000, 耗时:0.00分/4.51分 | step: 106680 | performance: 2304.0 | accuracy: 0.51 | loss: 0.77
update:1910/2000, 耗时:0.00分/4.52分 | step: 106960 | performance: 960.4 | accuracy: 0.50 | loss: 0.48
update:1915/2000, 耗时:0.00分/4.53分 | step: 107240 | performance: 922.5 | accuracy: 0.50 | loss: 1.27
update:1920/2000, 耗时:0.00分/4.54分 | step: 107520 | performance: 1234.6 | accuracy: 0.50 | loss: 0.96
update:1925/2000, 耗时:0.00分/4.55分 | step: 107800 | performance: 2213.5 | accuracy: 0.50 | loss: 2.48
update:1930/2000, 耗时:0.00分/4.57分 | step: 108080 | performance: 2398.1 | accuracy: 0.50 | loss: 8.18
update:1935/2000, 耗时:0.00分/4.58分 | step: 108360 | performance: 1471.6 | accuracy: 0.50 | loss: 1.95
update:1940/2000, 耗时:0.00分/4.59分 | step: 108640 | performance: 833.9 | accuracy: 0.49 | loss: 5.52
update:1945/2000, 耗时:0.00分/4.60分 | step: 108920 | performance: 1302.0 | accuracy: 0.50 | loss: 0.84
update:1950/2000, 耗时:0.00分/4.61分 | step: 109200 | performance: 1683.9 | accuracy: 0.50 | loss: 3.40
update:1955/2000, 耗时:0.00分/4.62分 | step: 109480 | performance: 4841.9 | accuracy: 0.50 | loss: 2.82
update:1960/2000, 耗时:0.00分/4.63分 | step: 109760 | performance: 4472.0 | accuracy: 0.50 | loss: 1.74
update:1965/2000, 耗时:0.00分/4.64分 | step: 110040 | performance: 17414.4 | accuracy: 0.50 | loss: 0.71
update:1970/2000, 耗时:0.00分/4.66分 | step: 110320 | performance: 18305.7 | accuracy: 0.50 | loss: 4.29
update:1975/2000, 耗时:0.00分/4.67分 | step: 110600 | performance: 11471.1 | accuracy: 0.50 | loss: 5.23
update:1980/2000, 耗时:0.00分/4.68分 | step: 110880 | performance: 10301.9 | accuracy: 0.50 | loss: 1.05
update:1985/2000, 耗时:0.00分/4.69分 | step: 111160 | performance: 22692.5 | accuracy: 0.50 | loss: 0.68
update:1990/2000, 耗时:0.00分/4.70分 | step: 111440 | performance: 27097.7 | accuracy: 0.50 | loss: 1.15
update:1995/2000, 耗时:0.00分/4.71分 | step: 111720 | performance: 24321.6 | accuracy: 0.50 | loss: 2.43
  0%|          | 0/404 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/4.72分 | step: 112000 | performance: 29164.8 | accuracy: 0.50 | loss: 4.19
----------------------------------------finished----------------------------------------
100%|| 404/404 [00:00<00:00, 134998.31it/s]
==================================================
2023-01-04T00:00:00 | *** START BACKTEST ***
2023-01-04T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1228.21
2023-07-24T12:00:00 | net performance [%] = 22.8211
2023-07-24T12:00:00 | number of trades [#] = 14
==================================================
Trial 37 Complete [00h 05m 10s]
net_wealth: 1229.440887145482

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 04h 57m 05s

Search: Running Trial #38

Value             |Best Value So Far |Hyperparameter
3                 |7                 |horizon
365               |730               |lookback
False             |False             |MarketFactor
3                 |14                |lags
0.85              |0.7               |gamma
32                |32                |batch_size
3                 |32                |n_step
0.99              |0.92              |gae_lambda
0.1               |0.1               |gradient_clip_norm
5                 |5                 |epochs
5e-05             |0.0001            |actor_lr
5e-05             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4312.000000   4315.000000
mean      0.000441    20062.255222  ...   20129.629835  20118.633889
std       0.027818    16039.874230  ...   16077.282571  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7694.525024   7690.540039
50%       0.000642    11554.824463  ...   11737.255371  11715.610352
75%       0.011655    29873.081836  ...   29933.737305  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 03:00:282023-07-28 03:00:28.129775: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operat2023-07-28 03:00:28.129890: I t2.1023-07ie-2onso8nr sflow/c:0 o3 :00rA:VX2e /A8VX2
To .platfore1na2mbl/9ec9 p09ut:_h feIem a2 0t23-07i-28 03:00:28.130012: I t2uretensorflow/core_/pn ot976hg5u: ardeI t.nsorflowec/ncc:so14rorelatfor/pflow/colm2/cratform/cp]e/plpu atform/cu_Tp_fhuifeature_gs _feaTuetureeaa_nerd.rsorFlow binary is optit ourguepmiea_zrr2ga023utae-rio0dn7s,-28dd .  cc0wir:e1b4t.ccu2i3l:h]142 ]o nT d eAThis TensorF2hiTensol0:00roFw lob2i3n2-0P023-wa0 77cc:w--228 03:8142i]t 03:Isr y: 0 D20 T:28.ensor130e38iFs o7lo9w: Ie te. bnp130s inaryNo2e8urfr1al: I o0ten0w:28hT is.p1hs ito/cportisiore/3flmoiw/cm041z1leipzlaed  witNeto :tforrmeTdwh/  onpo reeA/PcklatfoIIrn pws DeorF ut_ feaem/cLetuirbe_nlpogtra Nwhue  sreuaarorbinry a(apdr.coyfnelDocw:l1 42NN it] TNetwo)r kth  Lih/oncbrariepu_ofye APIoi(on upsrsee/ DapNropritalN)s ae ttte  furt orDmeTeo /usohe ncsepo NreFceupul_ofopmpifeo_ra ellowiltatun Netlreer_g fgtwuholaerw rkg Cfaollowu PbU  aginLibrd.cings.i
miinarydzes CPU .d wititnrsc:14rary is oth cucti2 cornusct:] p(oneo it142] n pDnThis NThiieTN) to eeis mizrAfToensroeons umandce wnrFlow-in performance-critical operations:  AVX AVX2
To enable them in other operations, res cseb obinarrPuilIth y is optimDe following CPU instructions in perfoieepzed with oFlow binarneAPiriIt dty icNeural Network Library (oneDNN) th is opti Deaooepr ln eopeArm auNeur ations:  AVTncesamnXPI l Network Lib Deep Neural Network Library (oneDNN)rareAVX2
To enable them ie the foll to osiorn yzeF-cwinriticalus lotherg (oe o od pwiteratih oneA CPU ipPenetDonnI DeepNs:ratio ostrheN) to uswu with Nns, rebueiulrae t fthe approprol Net  AchetliiateVdXl co nws Aowo mfTensoro iinnVlX2pFi ollpg rokwing CP Library (oneDNN
To enab) Uow with theClPeto  elU instructa rethem iinstroppropi use the followinr flags.
uctions ir nnformangi CPUothe in psrcnste -oerup errcritical operataatiincetions peorformance-crit, comnics rebuild TensorFlow with the appropriate compiler flap:falgos. r
 tioilnom aAVX s inAVX2
To ena ncperfer flags.
ormance-critical operations:  AVX AVX2
To enable them in other ope-cripereratble ttihatieical mooperatio ns, onns:  rs: AVX AVX2
To ena AVX AVX2
To enable them iiebuild TensorFlow winn other operations, rethbuild TensorFlow with the appropriate compiler flags.
 the  other operations, rebuild TensorFlow with the appropriate compiler flags.
appropriate compiler flags.
ble them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 03:00:28.738853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:00:28.765709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:00:28.765966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:00:28.766702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:00:28.777508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:00:28.777959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:00:28.779605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:00:28.820537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   120 | performance: 1.2 | accuracy: 0.47 | loss: 1.19
update: 10/2000, 耗时:0.00分/0.04分 | step:   240 | performance: 0.7 | accuracy: 0.33 | loss: 2.18
update: 15/2000, 耗时:0.00分/0.05分 | step:   360 | performance: 0.7 | accuracy: 0.31 | loss: 0.67
update: 20/2000, 耗时:0.00分/0.06分 | step:   480 | performance: 1.1 | accuracy: 0.40 | loss: 2.06
update: 25/2000, 耗时:0.00分/0.07分 | step:   600 | performance: 1.3 | accuracy: 0.40 | loss: 1.03
update: 30/2000, 耗时:0.00分/0.09分 | step:   720 | performance: 0.7 | accuracy: 0.37 | loss: 4.32
update: 35/2000, 耗时:0.00分/0.10分 | step:   840 | performance: 0.6 | accuracy: 0.36 | loss: 3.56
update: 40/2000, 耗时:0.00分/0.11分 | step:   960 | performance: 0.5 | accuracy: 0.34 | loss: 0.34
update: 45/2000, 耗时:0.00分/0.12分 | step:  1080 | performance: 0.4 | accuracy: 0.33 | loss: 0.78
update: 50/2000, 耗时:0.00分/0.13分 | step:  1200 | performance: 0.5 | accuracy: 0.36 | loss: 1.05
update: 55/2000, 耗时:0.00分/0.14分 | step:  1320 | performance: 0.5 | accuracy: 0.36 | loss: 1.69
update: 60/2000, 耗时:0.00分/0.16分 | step:  1440 | performance: 0.8 | accuracy: 0.40 | loss: 1.34
update: 65/2000, 耗时:0.00分/0.17分 | step:  1560 | performance: 0.9 | accuracy: 0.42 | loss: 1.66
update: 70/2000, 耗时:0.00分/0.18分 | step:  1680 | performance: 1.3 | accuracy: 0.43 | loss: 0.95
update: 75/2000, 耗时:0.00分/0.19分 | step:  1800 | performance: 1.3 | accuracy: 0.43 | loss: 0.73
update: 80/2000, 耗时:0.00分/0.21分 | step:  1920 | performance: 1.8 | accuracy: 0.44 | loss: 1.41
update: 85/2000, 耗时:0.00分/0.22分 | step:  2040 | performance: 1.4 | accuracy: 0.43 | loss: 1.58
update: 90/2000, 耗时:0.00分/0.23分 | step:  2160 | performance: 1.6 | accuracy: 0.44 | loss: 0.68
update: 95/2000, 耗时:0.00分/0.24分 | step:  2280 | performance: 1.0 | accuracy: 0.42 | loss: 2.20
update:100/2000, 耗时:0.00分/0.26分 | step:  2400 | performance: 0.8 | accuracy: 0.43 | loss: 0.92
update:105/2000, 耗时:0.00分/0.27分 | step:  2520 | performance: 0.9 | accuracy: 0.43 | loss: 1.00
update:110/2000, 耗时:0.00分/0.28分 | step:  2640 | performance: 0.8 | accuracy: 0.42 | loss: 1.58
update:115/2000, 耗时:0.00分/0.30分 | step:  2760 | performance: 0.8 | accuracy: 0.42 | loss: 1.06
update:120/2000, 耗时:0.00分/0.31分 | step:  2880 | performance: 0.7 | accuracy: 0.42 | loss: 1.07
update:125/2000, 耗时:0.00分/0.32分 | step:  3000 | performance: 0.6 | accuracy: 0.42 | loss: 2.59
update:130/2000, 耗时:0.00分/0.33分 | step:  3120 | performance: 0.9 | accuracy: 0.43 | loss: 0.79
update:135/2000, 耗时:0.00分/0.35分 | step:  3240 | performance: 0.8 | accuracy: 0.42 | loss: 1.48
update:140/2000, 耗时:0.00分/0.36分 | step:  3360 | performance: 0.8 | accuracy: 0.43 | loss: 0.72
update:145/2000, 耗时:0.00分/0.37分 | step:  3480 | performance: 0.8 | accuracy: 0.43 | loss: 1.42
update:150/2000, 耗时:0.00分/0.39分 | step:  3600 | performance: 0.8 | accuracy: 0.43 | loss: 0.69
update:155/2000, 耗时:0.00分/0.40分 | step:  3720 | performance: 0.7 | accuracy: 0.42 | loss: 0.62
update:160/2000, 耗时:0.00分/0.41分 | step:  3840 | performance: 0.7 | accuracy: 0.42 | loss: 0.56
update:165/2000, 耗时:0.00分/0.42分 | step:  3960 | performance: 0.7 | accuracy: 0.43 | loss: 1.86
update:170/2000, 耗时:0.00分/0.44分 | step:  4080 | performance: 0.8 | accuracy: 0.43 | loss: 1.54
update:175/2000, 耗时:0.00分/0.45分 | step:  4200 | performance: 1.0 | accuracy: 0.43 | loss: 0.93
update:180/2000, 耗时:0.00分/0.46分 | step:  4320 | performance: 1.7 | accuracy: 0.44 | loss: 1.30
update:185/2000, 耗时:0.00分/0.48分 | step:  4440 | performance: 2.0 | accuracy: 0.44 | loss: 2.34
update:190/2000, 耗时:0.00分/0.49分 | step:  4560 | performance: 3.5 | accuracy: 0.45 | loss: 3.46
update:195/2000, 耗时:0.00分/0.50分 | step:  4680 | performance: 4.3 | accuracy: 0.45 | loss: 2.91
update:200/2000, 耗时:0.00分/0.51分 | step:  4800 | performance: 2.3 | accuracy: 0.44 | loss: 3.57
update:205/2000, 耗时:0.00分/0.53分 | step:  4920 | performance: 2.8 | accuracy: 0.44 | loss: 1.06
update:210/2000, 耗时:0.00分/0.54分 | step:  5040 | performance: 2.3 | accuracy: 0.44 | loss: 0.70
update:215/2000, 耗时:0.00分/0.55分 | step:  5160 | performance: 3.3 | accuracy: 0.44 | loss: 0.91
update:220/2000, 耗时:0.00分/0.57分 | step:  5280 | performance: 3.3 | accuracy: 0.44 | loss: 2.72
update:225/2000, 耗时:0.00分/0.58分 | step:  5400 | performance: 3.3 | accuracy: 0.44 | loss: 1.59
update:230/2000, 耗时:0.00分/0.59分 | step:  5520 | performance: 3.5 | accuracy: 0.44 | loss: 0.56
update:235/2000, 耗时:0.00分/0.61分 | step:  5640 | performance: 3.0 | accuracy: 0.44 | loss: 0.32
update:240/2000, 耗时:0.00分/0.62分 | step:  5760 | performance: 2.4 | accuracy: 0.43 | loss: 0.46
update:245/2000, 耗时:0.00分/0.63分 | step:  5880 | performance: 2.0 | accuracy: 0.43 | loss: 0.49
update:250/2000, 耗时:0.00分/0.65分 | step:  6000 | performance: 2.1 | accuracy: 0.43 | loss: 1.35
update:255/2000, 耗时:0.00分/0.66分 | step:  6120 | performance: 2.0 | accuracy: 0.43 | loss: 2.39
update:260/2000, 耗时:0.00分/0.67分 | step:  6240 | performance: 2.0 | accuracy: 0.43 | loss: 0.54
update:265/2000, 耗时:0.00分/0.69分 | step:  6360 | performance: 1.9 | accuracy: 0.43 | loss: 1.51
update:270/2000, 耗时:0.00分/0.70分 | step:  6480 | performance: 1.7 | accuracy: 0.42 | loss: 0.39
update:275/2000, 耗时:0.00分/0.71分 | step:  6600 | performance: 1.8 | accuracy: 0.42 | loss: 0.13
update:280/2000, 耗时:0.00分/0.72分 | step:  6720 | performance: 1.9 | accuracy: 0.42 | loss: 1.09
update:285/2000, 耗时:0.00分/0.74分 | step:  6840 | performance: 1.9 | accuracy: 0.41 | loss: 0.61
update:290/2000, 耗时:0.00分/0.75分 | step:  6960 | performance: 2.2 | accuracy: 0.41 | loss: 0.32
update:295/2000, 耗时:0.00分/0.76分 | step:  7080 | performance: 3.0 | accuracy: 0.41 | loss: 0.17
update:300/2000, 耗时:0.00分/0.78分 | step:  7200 | performance: 2.4 | accuracy: 0.40 | loss: 0.17
update:305/2000, 耗时:0.00分/0.79分 | step:  7320 | performance: 2.7 | accuracy: 0.40 | loss: 0.12
update:310/2000, 耗时:0.00分/0.81分 | step:  7440 | performance: 2.6 | accuracy: 0.39 | loss: 0.93
update:315/2000, 耗时:0.00分/0.82分 | step:  7560 | performance: 3.0 | accuracy: 0.40 | loss: 1.56
update:320/2000, 耗时:0.00分/0.83分 | step:  7680 | performance: 3.0 | accuracy: 0.39 | loss: 0.61
update:325/2000, 耗时:0.00分/0.85分 | step:  7800 | performance: 3.0 | accuracy: 0.39 | loss: 0.22
update:330/2000, 耗时:0.00分/0.86分 | step:  7920 | performance: 2.7 | accuracy: 0.38 | loss: 0.63
update:335/2000, 耗时:0.00分/0.87分 | step:  8040 | performance: 2.7 | accuracy: 0.38 | loss: 0.84
update:340/2000, 耗时:0.00分/0.89分 | step:  8160 | performance: 2.8 | accuracy: 0.38 | loss: 0.33
update:345/2000, 耗时:0.00分/0.90分 | step:  8280 | performance: 2.6 | accuracy: 0.37 | loss: 0.47
update:350/2000, 耗时:0.00分/0.91分 | step:  8400 | performance: 4.5 | accuracy: 0.38 | loss: 0.92
update:355/2000, 耗时:0.00分/0.93分 | step:  8520 | performance: 3.8 | accuracy: 0.37 | loss: 1.07
update:360/2000, 耗时:0.00分/0.94分 | step:  8640 | performance: 3.7 | accuracy: 0.37 | loss: 1.07
update:365/2000, 耗时:0.00分/0.95分 | step:  8760 | performance: 3.6 | accuracy: 0.37 | loss: 0.87
update:370/2000, 耗时:0.00分/0.97分 | step:  8880 | performance: 4.3 | accuracy: 0.37 | loss: 0.20
update:375/2000, 耗时:0.00分/0.98分 | step:  9000 | performance: 4.1 | accuracy: 0.37 | loss: 0.96
update:380/2000, 耗时:0.00分/0.99分 | step:  9120 | performance: 4.0 | accuracy: 0.37 | loss: 0.73
update:385/2000, 耗时:0.00分/1.01分 | step:  9240 | performance: 2.4 | accuracy: 0.37 | loss: 0.57
update:390/2000, 耗时:0.00分/1.02分 | step:  9360 | performance: 2.4 | accuracy: 0.36 | loss: 0.43
update:395/2000, 耗时:0.00分/1.04分 | step:  9480 | performance: 2.2 | accuracy: 0.36 | loss: 0.77
update:400/2000, 耗时:0.00分/1.05分 | step:  9600 | performance: 2.3 | accuracy: 0.36 | loss: 0.53
update:405/2000, 耗时:0.00分/1.06分 | step:  9720 | performance: 2.0 | accuracy: 0.36 | loss: 0.50
update:410/2000, 耗时:0.00分/1.08分 | step:  9840 | performance: 2.0 | accuracy: 0.36 | loss: 0.47
update:415/2000, 耗时:0.00分/1.09分 | step:  9960 | performance: 2.2 | accuracy: 0.36 | loss: 0.90
update:420/2000, 耗时:0.00分/1.11分 | step: 10080 | performance: 2.2 | accuracy: 0.36 | loss: 0.91
update:425/2000, 耗时:0.00分/1.12分 | step: 10200 | performance: 2.6 | accuracy: 0.37 | loss: 1.09
update:430/2000, 耗时:0.00分/1.13分 | step: 10320 | performance: 2.8 | accuracy: 0.37 | loss: 0.83
update:435/2000, 耗时:0.00分/1.15分 | step: 10440 | performance: 2.9 | accuracy: 0.37 | loss: 1.56
update:440/2000, 耗时:0.00分/1.16分 | step: 10560 | performance: 3.5 | accuracy: 0.37 | loss: 2.59
update:445/2000, 耗时:0.00分/1.17分 | step: 10680 | performance: 3.5 | accuracy: 0.38 | loss: 0.89
update:450/2000, 耗时:0.00分/1.19分 | step: 10800 | performance: 3.4 | accuracy: 0.37 | loss: 1.33
update:455/2000, 耗时:0.00分/1.20分 | step: 10920 | performance: 2.6 | accuracy: 0.37 | loss: 0.92
update:460/2000, 耗时:0.00分/1.22分 | step: 11040 | performance: 1.9 | accuracy: 0.37 | loss: 1.22
update:465/2000, 耗时:0.00分/1.23分 | step: 11160 | performance: 1.9 | accuracy: 0.37 | loss: 0.51
update:470/2000, 耗时:0.00分/1.24分 | step: 11280 | performance: 1.6 | accuracy: 0.37 | loss: 0.51
update:475/2000, 耗时:0.00分/1.26分 | step: 11400 | performance: 1.7 | accuracy: 0.37 | loss: 0.52
update:480/2000, 耗时:0.00分/1.27分 | step: 11520 | performance: 1.5 | accuracy: 0.37 | loss: 0.48
update:485/2000, 耗时:0.00分/1.28分 | step: 11640 | performance: 1.6 | accuracy: 0.36 | loss: 0.50
update:490/2000, 耗时:0.00分/1.30分 | step: 11760 | performance: 1.5 | accuracy: 0.36 | loss: 1.10
update:495/2000, 耗时:0.00分/1.31分 | step: 11880 | performance: 1.7 | accuracy: 0.36 | loss: 0.59
update:500/2000, 耗时:0.00分/1.32分 | step: 12000 | performance: 2.6 | accuracy: 0.36 | loss: 0.69
update:505/2000, 耗时:0.00分/1.34分 | step: 12120 | performance: 2.6 | accuracy: 0.36 | loss: 0.53
update:510/2000, 耗时:0.00分/1.35分 | step: 12240 | performance: 2.5 | accuracy: 0.36 | loss: 1.88
update:515/2000, 耗时:0.00分/1.36分 | step: 12360 | performance: 2.4 | accuracy: 0.36 | loss: 0.88
update:520/2000, 耗时:0.00分/1.38分 | step: 12480 | performance: 2.4 | accuracy: 0.36 | loss: 0.75
update:525/2000, 耗时:0.00分/1.39分 | step: 12600 | performance: 2.2 | accuracy: 0.35 | loss: 1.40
update:530/2000, 耗时:0.00分/1.40分 | step: 12720 | performance: 2.4 | accuracy: 0.35 | loss: 0.37
update:535/2000, 耗时:0.00分/1.42分 | step: 12840 | performance: 2.5 | accuracy: 0.35 | loss: 0.40
update:540/2000, 耗时:0.00分/1.43分 | step: 12960 | performance: 2.3 | accuracy: 0.35 | loss: 0.60
update:545/2000, 耗时:0.00分/1.44分 | step: 13080 | performance: 1.9 | accuracy: 0.35 | loss: 0.80
update:550/2000, 耗时:0.00分/1.46分 | step: 13200 | performance: 2.1 | accuracy: 0.35 | loss: 0.55
update:555/2000, 耗时:0.00分/1.47分 | step: 13320 | performance: 2.0 | accuracy: 0.35 | loss: 0.22
update:560/2000, 耗时:0.00分/1.49分 | step: 13440 | performance: 1.9 | accuracy: 0.34 | loss: 0.52
update:565/2000, 耗时:0.00分/1.50分 | step: 13560 | performance: 1.9 | accuracy: 0.34 | loss: 0.45
update:570/2000, 耗时:0.00分/1.51分 | step: 13680 | performance: 1.9 | accuracy: 0.34 | loss: 0.68
update:575/2000, 耗时:0.00分/1.53分 | step: 13800 | performance: 1.7 | accuracy: 0.34 | loss: 0.44
update:580/2000, 耗时:0.00分/1.54分 | step: 13920 | performance: 1.7 | accuracy: 0.34 | loss: 0.42
update:585/2000, 耗时:0.00分/1.55分 | step: 14040 | performance: 1.7 | accuracy: 0.34 | loss: 0.26
update:590/2000, 耗时:0.00分/1.57分 | step: 14160 | performance: 2.2 | accuracy: 0.34 | loss: 0.22
update:595/2000, 耗时:0.00分/1.58分 | step: 14280 | performance: 2.4 | accuracy: 0.34 | loss: 0.56
update:600/2000, 耗时:0.00分/1.60分 | step: 14400 | performance: 2.6 | accuracy: 0.34 | loss: 0.70
update:605/2000, 耗时:0.00分/1.61分 | step: 14520 | performance: 2.5 | accuracy: 0.34 | loss: 0.43
update:610/2000, 耗时:0.00分/1.62分 | step: 14640 | performance: 2.6 | accuracy: 0.34 | loss: 0.43
update:615/2000, 耗时:0.00分/1.64分 | step: 14760 | performance: 2.2 | accuracy: 0.34 | loss: 0.26
update:620/2000, 耗时:0.00分/1.65分 | step: 14880 | performance: 2.2 | accuracy: 0.34 | loss: 0.39
update:625/2000, 耗时:0.00分/1.67分 | step: 15000 | performance: 2.0 | accuracy: 0.34 | loss: 0.76
update:630/2000, 耗时:0.00分/1.68分 | step: 15120 | performance: 2.1 | accuracy: 0.34 | loss: 0.39
update:635/2000, 耗时:0.00分/1.69分 | step: 15240 | performance: 2.0 | accuracy: 0.34 | loss: 0.66
update:640/2000, 耗时:0.00分/1.71分 | step: 15360 | performance: 2.3 | accuracy: 0.34 | loss: 0.45
update:645/2000, 耗时:0.00分/1.72分 | step: 15480 | performance: 2.6 | accuracy: 0.34 | loss: 0.64
update:650/2000, 耗时:0.00分/1.74分 | step: 15600 | performance: 3.0 | accuracy: 0.34 | loss: 0.40
update:655/2000, 耗时:0.00分/1.75分 | step: 15720 | performance: 4.0 | accuracy: 0.34 | loss: 1.00
update:660/2000, 耗时:0.00分/1.76分 | step: 15840 | performance: 4.2 | accuracy: 0.34 | loss: 0.35
update:665/2000, 耗时:0.00分/1.78分 | step: 15960 | performance: 4.8 | accuracy: 0.34 | loss: 0.60
update:670/2000, 耗时:0.00分/1.79分 | step: 16080 | performance: 4.7 | accuracy: 0.34 | loss: 0.23
update:675/2000, 耗时:0.00分/1.81分 | step: 16200 | performance: 5.6 | accuracy: 0.34 | loss: 0.35
update:680/2000, 耗时:0.00分/1.82分 | step: 16320 | performance: 6.3 | accuracy: 0.34 | loss: 1.73
update:685/2000, 耗时:0.00分/1.83分 | step: 16440 | performance: 8.7 | accuracy: 0.34 | loss: 0.15
update:690/2000, 耗时:0.00分/1.85分 | step: 16560 | performance: 10.6 | accuracy: 0.34 | loss: 0.37
update:695/2000, 耗时:0.00分/1.86分 | step: 16680 | performance: 12.3 | accuracy: 0.34 | loss: 1.79
update:700/2000, 耗时:0.00分/1.88分 | step: 16800 | performance: 13.3 | accuracy: 0.34 | loss: 1.45
update:705/2000, 耗时:0.00分/1.89分 | step: 16920 | performance: 14.5 | accuracy: 0.34 | loss: 1.18
update:710/2000, 耗时:0.00分/1.90分 | step: 17040 | performance: 11.3 | accuracy: 0.34 | loss: 1.32
update:715/2000, 耗时:0.00分/1.92分 | step: 17160 | performance: 13.6 | accuracy: 0.34 | loss: 0.99
update:720/2000, 耗时:0.00分/1.93分 | step: 17280 | performance: 21.6 | accuracy: 0.34 | loss: 1.07
update:725/2000, 耗时:0.00分/1.94分 | step: 17400 | performance: 25.7 | accuracy: 0.34 | loss: 0.30
update:730/2000, 耗时:0.00分/1.96分 | step: 17520 | performance: 19.3 | accuracy: 0.34 | loss: 2.75
update:735/2000, 耗时:0.00分/1.97分 | step: 17640 | performance: 18.9 | accuracy: 0.34 | loss: 0.87
update:740/2000, 耗时:0.00分/1.99分 | step: 17760 | performance: 33.2 | accuracy: 0.35 | loss: 1.25
update:745/2000, 耗时:0.00分/2.00分 | step: 17880 | performance: 30.6 | accuracy: 0.35 | loss: 1.25
update:750/2000, 耗时:0.00分/2.01分 | step: 18000 | performance: 30.1 | accuracy: 0.35 | loss: 1.56
update:755/2000, 耗时:0.00分/2.03分 | step: 18120 | performance: 33.6 | accuracy: 0.35 | loss: 0.61
update:760/2000, 耗时:0.00分/2.04分 | step: 18240 | performance: 35.9 | accuracy: 0.35 | loss: 0.44
update:765/2000, 耗时:0.00分/2.05分 | step: 18360 | performance: 27.2 | accuracy: 0.35 | loss: 0.45
update:770/2000, 耗时:0.00分/2.07分 | step: 18480 | performance: 21.9 | accuracy: 0.35 | loss: 2.27
update:775/2000, 耗时:0.00分/2.08分 | step: 18600 | performance: 26.3 | accuracy: 0.35 | loss: 1.81
update:780/2000, 耗时:0.00分/2.09分 | step: 18720 | performance: 30.0 | accuracy: 0.35 | loss: 0.83
update:785/2000, 耗时:0.00分/2.11分 | step: 18840 | performance: 12.3 | accuracy: 0.35 | loss: 2.35
update:790/2000, 耗时:0.00分/2.12分 | step: 18960 | performance: 10.4 | accuracy: 0.35 | loss: 0.39
update:795/2000, 耗时:0.00分/2.13分 | step: 19080 | performance: 10.9 | accuracy: 0.35 | loss: 0.83
update:800/2000, 耗时:0.00分/2.15分 | step: 19200 | performance: 14.7 | accuracy: 0.35 | loss: 0.78
update:805/2000, 耗时:0.00分/2.16分 | step: 19320 | performance: 19.3 | accuracy: 0.35 | loss: 1.08
update:810/2000, 耗时:0.00分/2.17分 | step: 19440 | performance: 22.1 | accuracy: 0.35 | loss: 0.71
update:815/2000, 耗时:0.00分/2.18分 | step: 19560 | performance: 18.5 | accuracy: 0.35 | loss: 1.64
update:820/2000, 耗时:0.00分/2.20分 | step: 19680 | performance: 21.8 | accuracy: 0.35 | loss: 0.75
update:825/2000, 耗时:0.00分/2.21分 | step: 19800 | performance: 20.9 | accuracy: 0.35 | loss: 0.70
update:830/2000, 耗时:0.00分/2.22分 | step: 19920 | performance: 13.7 | accuracy: 0.35 | loss: 2.98
update:835/2000, 耗时:0.00分/2.24分 | step: 20040 | performance: 11.0 | accuracy: 0.35 | loss: 0.88
update:840/2000, 耗时:0.00分/2.25分 | step: 20160 | performance: 11.5 | accuracy: 0.35 | loss: 0.57
update:845/2000, 耗时:0.00分/2.27分 | step: 20280 | performance: 11.1 | accuracy: 0.35 | loss: 1.06
update:850/2000, 耗时:0.00分/2.28分 | step: 20400 | performance: 11.9 | accuracy: 0.35 | loss: 1.00
update:855/2000, 耗时:0.00分/2.29分 | step: 20520 | performance: 11.7 | accuracy: 0.35 | loss: 1.21
update:860/2000, 耗时:0.00分/2.31分 | step: 20640 | performance: 14.6 | accuracy: 0.35 | loss: 0.87
update:865/2000, 耗时:0.00分/2.32分 | step: 20760 | performance: 17.7 | accuracy: 0.35 | loss: 0.46
update:870/2000, 耗时:0.00分/2.34分 | step: 20880 | performance: 19.8 | accuracy: 0.35 | loss: 0.69
update:875/2000, 耗时:0.00分/2.35分 | step: 21000 | performance: 20.4 | accuracy: 0.35 | loss: 1.25
update:880/2000, 耗时:0.00分/2.36分 | step: 21120 | performance: 23.5 | accuracy: 0.35 | loss: 0.65
update:885/2000, 耗时:0.00分/2.38分 | step: 21240 | performance: 30.3 | accuracy: 0.35 | loss: 0.61
update:890/2000, 耗时:0.00分/2.39分 | step: 21360 | performance: 32.1 | accuracy: 0.35 | loss: 1.62
update:895/2000, 耗时:0.00分/2.40分 | step: 21480 | performance: 34.3 | accuracy: 0.35 | loss: 0.96
update:900/2000, 耗时:0.00分/2.42分 | step: 21600 | performance: 33.7 | accuracy: 0.35 | loss: 1.82
update:905/2000, 耗时:0.00分/2.43分 | step: 21720 | performance: 31.2 | accuracy: 0.35 | loss: 1.33
update:910/2000, 耗时:0.00分/2.45分 | step: 21840 | performance: 25.2 | accuracy: 0.35 | loss: 0.68
update:915/2000, 耗时:0.00分/2.46分 | step: 21960 | performance: 24.6 | accuracy: 0.35 | loss: 0.37
update:920/2000, 耗时:0.00分/2.47分 | step: 22080 | performance: 16.5 | accuracy: 0.35 | loss: 0.42
update:925/2000, 耗时:0.00分/2.49分 | step: 22200 | performance: 16.8 | accuracy: 0.35 | loss: 0.36
update:930/2000, 耗时:0.00分/2.50分 | step: 22320 | performance: 15.9 | accuracy: 0.35 | loss: 0.51
update:935/2000, 耗时:0.00分/2.51分 | step: 22440 | performance: 18.6 | accuracy: 0.35 | loss: 0.34
update:940/2000, 耗时:0.00分/2.53分 | step: 22560 | performance: 20.3 | accuracy: 0.35 | loss: 0.80
update:945/2000, 耗时:0.00分/2.54分 | step: 22680 | performance: 22.1 | accuracy: 0.35 | loss: 0.64
update:950/2000, 耗时:0.00分/2.55分 | step: 22800 | performance: 27.3 | accuracy: 0.35 | loss: 1.50
update:955/2000, 耗时:0.00分/2.57分 | step: 22920 | performance: 25.4 | accuracy: 0.35 | loss: 0.30
update:960/2000, 耗时:0.00分/2.58分 | step: 23040 | performance: 23.2 | accuracy: 0.35 | loss: 0.54
update:965/2000, 耗时:0.00分/2.59分 | step: 23160 | performance: 25.0 | accuracy: 0.35 | loss: 0.62
update:970/2000, 耗时:0.00分/2.61分 | step: 23280 | performance: 26.8 | accuracy: 0.35 | loss: 1.19
update:975/2000, 耗时:0.00分/2.62分 | step: 23400 | performance: 28.5 | accuracy: 0.35 | loss: 1.25
update:980/2000, 耗时:0.00分/2.63分 | step: 23520 | performance: 30.0 | accuracy: 0.35 | loss: 0.40
update:985/2000, 耗时:0.00分/2.65分 | step: 23640 | performance: 25.9 | accuracy: 0.35 | loss: 0.36
update:990/2000, 耗时:0.00分/2.66分 | step: 23760 | performance: 29.8 | accuracy: 0.35 | loss: 1.15
update:995/2000, 耗时:0.00分/2.67分 | step: 23880 | performance: 27.1 | accuracy: 0.35 | loss: 0.93
update:1000/2000, 耗时:0.00分/2.68分 | step: 24000 | performance: 31.9 | accuracy: 0.35 | loss: 0.85
update:1005/2000, 耗时:0.00分/2.70分 | step: 24120 | performance: 32.5 | accuracy: 0.35 | loss: 0.72
update:1010/2000, 耗时:0.00分/2.71分 | step: 24240 | performance: 35.0 | accuracy: 0.36 | loss: 0.73
update:1015/2000, 耗时:0.00分/2.72分 | step: 24360 | performance: 36.4 | accuracy: 0.36 | loss: 1.01
update:1020/2000, 耗时:0.00分/2.74分 | step: 24480 | performance: 47.2 | accuracy: 0.36 | loss: 0.54
update:1025/2000, 耗时:0.00分/2.75分 | step: 24600 | performance: 51.2 | accuracy: 0.36 | loss: 0.70
update:1030/2000, 耗时:0.00分/2.76分 | step: 24720 | performance: 48.9 | accuracy: 0.36 | loss: 0.80
update:1035/2000, 耗时:0.00分/2.78分 | step: 24840 | performance: 47.7 | accuracy: 0.36 | loss: 2.05
update:1040/2000, 耗时:0.00分/2.79分 | step: 24960 | performance: 42.2 | accuracy: 0.36 | loss: 2.13
update:1045/2000, 耗时:0.00分/2.80分 | step: 25080 | performance: 87.9 | accuracy: 0.36 | loss: 5.07
update:1050/2000, 耗时:0.00分/2.82分 | step: 25200 | performance: 89.5 | accuracy: 0.36 | loss: 0.33
update:1055/2000, 耗时:0.00分/2.83分 | step: 25320 | performance: 101.0 | accuracy: 0.36 | loss: 2.08
update:1060/2000, 耗时:0.00分/2.84分 | step: 25440 | performance: 108.1 | accuracy: 0.36 | loss: 0.70
update:1065/2000, 耗时:0.00分/2.86分 | step: 25560 | performance: 107.2 | accuracy: 0.36 | loss: 0.93
update:1070/2000, 耗时:0.00分/2.87分 | step: 25680 | performance: 86.2 | accuracy: 0.36 | loss: 0.79
update:1075/2000, 耗时:0.00分/2.88分 | step: 25800 | performance: 89.2 | accuracy: 0.36 | loss: 1.65
update:1080/2000, 耗时:0.00分/2.89分 | step: 25920 | performance: 96.7 | accuracy: 0.36 | loss: 0.76
update:1085/2000, 耗时:0.00分/2.91分 | step: 26040 | performance: 99.3 | accuracy: 0.36 | loss: 0.50
update:1090/2000, 耗时:0.00分/2.92分 | step: 26160 | performance: 119.0 | accuracy: 0.36 | loss: 1.42
update:1095/2000, 耗时:0.00分/2.93分 | step: 26280 | performance: 142.0 | accuracy: 0.36 | loss: 1.73
update:1100/2000, 耗时:0.00分/2.95分 | step: 26400 | performance: 148.3 | accuracy: 0.36 | loss: 0.38
update:1105/2000, 耗时:0.00分/2.96分 | step: 26520 | performance: 110.6 | accuracy: 0.36 | loss: 1.62
update:1110/2000, 耗时:0.00分/2.97分 | step: 26640 | performance: 102.0 | accuracy: 0.36 | loss: 0.35
update:1115/2000, 耗时:0.00分/2.99分 | step: 26760 | performance: 103.3 | accuracy: 0.36 | loss: 1.12
update:1120/2000, 耗时:0.00分/3.00分 | step: 26880 | performance: 105.8 | accuracy: 0.36 | loss: 1.43
update:1125/2000, 耗时:0.00分/3.01分 | step: 27000 | performance: 117.3 | accuracy: 0.36 | loss: 0.60
update:1130/2000, 耗时:0.00分/3.03分 | step: 27120 | performance: 116.8 | accuracy: 0.36 | loss: 1.35
update:1135/2000, 耗时:0.00分/3.04分 | step: 27240 | performance: 110.1 | accuracy: 0.36 | loss: 2.10
update:1140/2000, 耗时:0.00分/3.05分 | step: 27360 | performance: 120.4 | accuracy: 0.37 | loss: 1.37
update:1145/2000, 耗时:0.00分/3.06分 | step: 27480 | performance: 225.5 | accuracy: 0.37 | loss: 1.29
update:1150/2000, 耗时:0.00分/3.08分 | step: 27600 | performance: 228.3 | accuracy: 0.37 | loss: 0.42
update:1155/2000, 耗时:0.00分/3.09分 | step: 27720 | performance: 222.5 | accuracy: 0.37 | loss: 1.36
update:1160/2000, 耗时:0.00分/3.10分 | step: 27840 | performance: 209.1 | accuracy: 0.37 | loss: 0.80
update:1165/2000, 耗时:0.00分/3.12分 | step: 27960 | performance: 215.7 | accuracy: 0.37 | loss: 0.37
update:1170/2000, 耗时:0.00分/3.13分 | step: 28080 | performance: 243.7 | accuracy: 0.37 | loss: 0.78
update:1175/2000, 耗时:0.00分/3.14分 | step: 28200 | performance: 242.8 | accuracy: 0.37 | loss: 0.80
update:1180/2000, 耗时:0.00分/3.16分 | step: 28320 | performance: 1.0 | accuracy: 1.00 | loss: 0.73
Saving PPO weights in both H5 format and checkpoint @ update:1180 
update:1185/2000, 耗时:0.00分/3.17分 | step: 28440 | performance: 0.9 | accuracy: 0.31 | loss: 2.08
update:1190/2000, 耗时:0.00分/3.19分 | step: 28560 | performance: 0.4 | accuracy: 0.19 | loss: 1.51
update:1195/2000, 耗时:0.00分/3.20分 | step: 28680 | performance: 0.5 | accuracy: 0.28 | loss: 0.69
update:1200/2000, 耗时:0.00分/3.21分 | step: 28800 | performance: 0.5 | accuracy: 0.30 | loss: 1.65
update:1205/2000, 耗时:0.00分/3.22分 | step: 28920 | performance: 0.4 | accuracy: 0.32 | loss: 1.06
update:1210/2000, 耗时:0.00分/3.24分 | step: 29040 | performance: 0.2 | accuracy: 0.30 | loss: 1.53
update:1215/2000, 耗时:0.00分/3.25分 | step: 29160 | performance: 0.2 | accuracy: 0.29 | loss: 1.83
update:1220/2000, 耗时:0.00分/3.26分 | step: 29280 | performance: 0.2 | accuracy: 0.30 | loss: 0.87
update:1225/2000, 耗时:0.00分/3.28分 | step: 29400 | performance: 0.2 | accuracy: 0.32 | loss: 0.51
update:1230/2000, 耗时:0.00分/3.29分 | step: 29520 | performance: 0.2 | accuracy: 0.32 | loss: 0.52
update:1235/2000, 耗时:0.00分/3.30分 | step: 29640 | performance: 0.2 | accuracy: 0.33 | loss: 1.20
update:1240/2000, 耗时:0.00分/3.31分 | step: 29760 | performance: 0.2 | accuracy: 0.35 | loss: 0.53
update:1245/2000, 耗时:0.00分/3.33分 | step: 29880 | performance: 0.2 | accuracy: 0.34 | loss: 0.82
update:1250/2000, 耗时:0.00分/3.34分 | step: 30000 | performance: 0.3 | accuracy: 0.36 | loss: 0.78
update:1255/2000, 耗时:0.00分/3.35分 | step: 30120 | performance: 0.3 | accuracy: 0.35 | loss: 0.71
update:1260/2000, 耗时:0.00分/3.36分 | step: 30240 | performance: 0.3 | accuracy: 0.36 | loss: 0.71
update:1265/2000, 耗时:0.00分/3.38分 | step: 30360 | performance: 0.3 | accuracy: 0.36 | loss: 0.60
update:1270/2000, 耗时:0.00分/3.39分 | step: 30480 | performance: 0.3 | accuracy: 0.38 | loss: 1.25
update:1275/2000, 耗时:0.00分/3.40分 | step: 30600 | performance: 0.3 | accuracy: 0.38 | loss: 0.56
update:1280/2000, 耗时:0.00分/3.41分 | step: 30720 | performance: 0.3 | accuracy: 0.39 | loss: 0.57
update:1285/2000, 耗时:0.00分/3.43分 | step: 30840 | performance: 0.3 | accuracy: 0.39 | loss: 0.53
update:1290/2000, 耗时:0.00分/3.44分 | step: 30960 | performance: 0.4 | accuracy: 0.40 | loss: 0.53
update:1295/2000, 耗时:0.00分/3.45分 | step: 31080 | performance: 0.4 | accuracy: 0.39 | loss: 1.23
update:1300/2000, 耗时:0.00分/3.46分 | step: 31200 | performance: 0.3 | accuracy: 0.39 | loss: 0.28
update:1305/2000, 耗时:0.00分/3.48分 | step: 31320 | performance: 0.3 | accuracy: 0.38 | loss: 1.60
update:1310/2000, 耗时:0.00分/3.49分 | step: 31440 | performance: 0.4 | accuracy: 0.39 | loss: 0.80
update:1315/2000, 耗时:0.00分/3.50分 | step: 31560 | performance: 0.5 | accuracy: 0.39 | loss: 1.79
update:1320/2000, 耗时:0.00分/3.51分 | step: 31680 | performance: 0.5 | accuracy: 0.40 | loss: 1.76
update:1325/2000, 耗时:0.00分/3.52分 | step: 31800 | performance: 0.5 | accuracy: 0.40 | loss: 1.57
update:1330/2000, 耗时:0.00分/3.54分 | step: 31920 | performance: 0.5 | accuracy: 0.40 | loss: 1.91
update:1335/2000, 耗时:0.00分/3.55分 | step: 32040 | performance: 0.5 | accuracy: 0.39 | loss: 0.36
update:1340/2000, 耗时:0.00分/3.56分 | step: 32160 | performance: 0.5 | accuracy: 0.39 | loss: 0.37
update:1345/2000, 耗时:0.00分/3.57分 | step: 32280 | performance: 0.5 | accuracy: 0.40 | loss: 1.90
update:1350/2000, 耗时:0.00分/3.59分 | step: 32400 | performance: 0.5 | accuracy: 0.40 | loss: 1.45
update:1355/2000, 耗时:0.00分/3.60分 | step: 32520 | performance: 0.8 | accuracy: 0.40 | loss: 0.43
update:1360/2000, 耗时:0.00分/3.61分 | step: 32640 | performance: 1.2 | accuracy: 0.40 | loss: 2.65
update:1365/2000, 耗时:0.00分/3.62分 | step: 32760 | performance: 1.4 | accuracy: 0.41 | loss: 0.45
update:1370/2000, 耗时:0.00分/3.64分 | step: 32880 | performance: 2.3 | accuracy: 0.41 | loss: 2.09
update:1375/2000, 耗时:0.00分/3.65分 | step: 33000 | performance: 2.5 | accuracy: 0.41 | loss: 2.37
update:1380/2000, 耗时:0.00分/3.66分 | step: 33120 | performance: 1.7 | accuracy: 0.41 | loss: 0.79
update:1385/2000, 耗时:0.00分/3.67分 | step: 33240 | performance: 2.2 | accuracy: 0.41 | loss: 0.34
update:1390/2000, 耗时:0.00分/3.69分 | step: 33360 | performance: 1.9 | accuracy: 0.41 | loss: 0.22
update:1395/2000, 耗时:0.00分/3.70分 | step: 33480 | performance: 2.4 | accuracy: 0.42 | loss: 0.50
update:1400/2000, 耗时:0.00分/3.71分 | step: 33600 | performance: 2.5 | accuracy: 0.42 | loss: 0.42
update:1405/2000, 耗时:0.00分/3.72分 | step: 33720 | performance: 2.9 | accuracy: 0.42 | loss: 1.86
update:1410/2000, 耗时:0.00分/3.73分 | step: 33840 | performance: 2.9 | accuracy: 0.42 | loss: 0.33
update:1415/2000, 耗时:0.00分/3.75分 | step: 33960 | performance: 2.4 | accuracy: 0.42 | loss: 0.39
update:1420/2000, 耗时:0.00分/3.76分 | step: 34080 | performance: 2.0 | accuracy: 0.41 | loss: 1.01
update:1425/2000, 耗时:0.00分/3.77分 | step: 34200 | performance: 2.2 | accuracy: 0.41 | loss: 0.46
update:1430/2000, 耗时:0.00分/3.78分 | step: 34320 | performance: 2.1 | accuracy: 0.41 | loss: 0.80
update:1435/2000, 耗时:0.00分/3.79分 | step: 34440 | performance: 2.0 | accuracy: 0.41 | loss: 0.50
update:1440/2000, 耗时:0.00分/3.81分 | step: 34560 | performance: 2.0 | accuracy: 0.41 | loss: 0.75
update:1445/2000, 耗时:0.00分/3.82分 | step: 34680 | performance: 1.9 | accuracy: 0.40 | loss: 0.68
update:1450/2000, 耗时:0.00分/3.83分 | step: 34800 | performance: 1.2 | accuracy: 0.40 | loss: 0.38
update:1455/2000, 耗时:0.00分/3.84分 | step: 34920 | performance: 1.2 | accuracy: 0.40 | loss: 0.36
update:1460/2000, 耗时:0.00分/3.85分 | step: 35040 | performance: 1.3 | accuracy: 0.39 | loss: 1.01
update:1465/2000, 耗时:0.00分/3.87分 | step: 35160 | performance: 1.2 | accuracy: 0.39 | loss: 0.73
update:1470/2000, 耗时:0.00分/3.88分 | step: 35280 | performance: 1.7 | accuracy: 0.40 | loss: 0.66
update:1475/2000, 耗时:0.00分/3.89分 | step: 35400 | performance: 3.4 | accuracy: 0.41 | loss: 1.05
update:1480/2000, 耗时:0.00分/3.90分 | step: 35520 | performance: 3.1 | accuracy: 0.41 | loss: 0.43
update:1485/2000, 耗时:0.00分/3.92分 | step: 35640 | performance: 3.9 | accuracy: 0.41 | loss: 2.94
update:1490/2000, 耗时:0.00分/3.93分 | step: 35760 | performance: 3.5 | accuracy: 0.41 | loss: 1.09
update:1495/2000, 耗时:0.00分/3.94分 | step: 35880 | performance: 4.5 | accuracy: 0.41 | loss: 1.51
update:1500/2000, 耗时:0.00分/3.95分 | step: 36000 | performance: 7.4 | accuracy: 0.42 | loss: 2.06
update:1505/2000, 耗时:0.00分/3.96分 | step: 36120 | performance: 7.7 | accuracy: 0.42 | loss: 3.64
update:1510/2000, 耗时:0.00分/3.98分 | step: 36240 | performance: 7.0 | accuracy: 0.42 | loss: 0.78
update:1515/2000, 耗时:0.00分/3.99分 | step: 36360 | performance: 5.5 | accuracy: 0.42 | loss: 0.90
update:1520/2000, 耗时:0.00分/4.00分 | step: 36480 | performance: 4.3 | accuracy: 0.41 | loss: 1.84
update:1525/2000, 耗时:0.00分/4.01分 | step: 36600 | performance: 3.7 | accuracy: 0.41 | loss: 0.31
update:1530/2000, 耗时:0.00分/4.03分 | step: 36720 | performance: 5.9 | accuracy: 0.42 | loss: 0.91
update:1535/2000, 耗时:0.00分/4.04分 | step: 36840 | performance: 5.4 | accuracy: 0.41 | loss: 2.90
update:1540/2000, 耗时:0.00分/4.05分 | step: 36960 | performance: 4.7 | accuracy: 0.42 | loss: 2.63
update:1545/2000, 耗时:0.00分/4.06分 | step: 37080 | performance: 4.3 | accuracy: 0.41 | loss: 1.94
update:1550/2000, 耗时:0.00分/4.07分 | step: 37200 | performance: 5.3 | accuracy: 0.42 | loss: 0.42
update:1555/2000, 耗时:0.00分/4.09分 | step: 37320 | performance: 4.9 | accuracy: 0.41 | loss: 0.51
update:1560/2000, 耗时:0.00分/4.10分 | step: 37440 | performance: 4.6 | accuracy: 0.41 | loss: 0.53
update:1565/2000, 耗时:0.00分/4.11分 | step: 37560 | performance: 4.8 | accuracy: 0.41 | loss: 0.27
update:1570/2000, 耗时:0.00分/4.12分 | step: 37680 | performance: 4.8 | accuracy: 0.40 | loss: 0.49
update:1575/2000, 耗时:0.00分/4.13分 | step: 37800 | performance: 4.9 | accuracy: 0.40 | loss: 0.36
update:1580/2000, 耗时:0.00分/4.15分 | step: 37920 | performance: 4.9 | accuracy: 0.40 | loss: 0.59
update:1585/2000, 耗时:0.00分/4.16分 | step: 38040 | performance: 3.4 | accuracy: 0.40 | loss: 0.21
update:1590/2000, 耗时:0.00分/4.17分 | step: 38160 | performance: 3.5 | accuracy: 0.40 | loss: 0.16
update:1595/2000, 耗时:0.00分/4.18分 | step: 38280 | performance: 3.6 | accuracy: 0.39 | loss: 0.58
update:1600/2000, 耗时:0.00分/4.19分 | step: 38400 | performance: 3.7 | accuracy: 0.39 | loss: 1.11
update:1605/2000, 耗时:0.00分/4.21分 | step: 38520 | performance: 5.5 | accuracy: 0.39 | loss: 1.22
update:1610/2000, 耗时:0.00分/4.22分 | step: 38640 | performance: 6.0 | accuracy: 0.40 | loss: 0.49
update:1615/2000, 耗时:0.00分/4.23分 | step: 38760 | performance: 5.8 | accuracy: 0.40 | loss: 1.86
update:1620/2000, 耗时:0.00分/4.24分 | step: 38880 | performance: 6.0 | accuracy: 0.40 | loss: 0.60
update:1625/2000, 耗时:0.00分/4.26分 | step: 39000 | performance: 5.5 | accuracy: 0.40 | loss: 0.52
update:1630/2000, 耗时:0.00分/4.27分 | step: 39120 | performance: 5.4 | accuracy: 0.40 | loss: 2.08
update:1635/2000, 耗时:0.00分/4.28分 | step: 39240 | performance: 4.4 | accuracy: 0.40 | loss: 1.31
update:1640/2000, 耗时:0.00分/4.29分 | step: 39360 | performance: 3.9 | accuracy: 0.40 | loss: 0.36
update:1645/2000, 耗时:0.00分/4.30分 | step: 39480 | performance: 4.2 | accuracy: 0.40 | loss: 0.68
update:1650/2000, 耗时:0.00分/4.32分 | step: 39600 | performance: 3.9 | accuracy: 0.40 | loss: 0.39
update:1655/2000, 耗时:0.00分/4.33分 | step: 39720 | performance: 3.8 | accuracy: 0.39 | loss: 0.64
update:1660/2000, 耗时:0.00分/4.34分 | step: 39840 | performance: 3.1 | accuracy: 0.39 | loss: 1.39
update:1665/2000, 耗时:0.00分/4.35分 | step: 39960 | performance: 3.0 | accuracy: 0.39 | loss: 1.51
update:1670/2000, 耗时:0.00分/4.37分 | step: 40080 | performance: 2.5 | accuracy: 0.39 | loss: 0.22
update:1675/2000, 耗时:0.00分/4.38分 | step: 40200 | performance: 2.8 | accuracy: 0.39 | loss: 0.20
update:1680/2000, 耗时:0.00分/4.39分 | step: 40320 | performance: 2.8 | accuracy: 0.38 | loss: 0.15
update:1685/2000, 耗时:0.00分/4.40分 | step: 40440 | performance: 2.3 | accuracy: 0.38 | loss: 0.36
update:1690/2000, 耗时:0.00分/4.42分 | step: 40560 | performance: 2.6 | accuracy: 0.38 | loss: 1.03
update:1695/2000, 耗时:0.00分/4.43分 | step: 40680 | performance: 2.3 | accuracy: 0.38 | loss: 0.96
update:1700/2000, 耗时:0.00分/4.44分 | step: 40800 | performance: 2.7 | accuracy: 0.38 | loss: 0.23
update:1705/2000, 耗时:0.00分/4.45分 | step: 40920 | performance: 2.7 | accuracy: 0.38 | loss: 0.49
update:1710/2000, 耗时:0.00分/4.47分 | step: 41040 | performance: 2.2 | accuracy: 0.38 | loss: 0.44
update:1715/2000, 耗时:0.00分/4.48分 | step: 41160 | performance: 2.0 | accuracy: 0.38 | loss: 1.09
update:1720/2000, 耗时:0.00分/4.49分 | step: 41280 | performance: 2.1 | accuracy: 0.38 | loss: 0.49
update:1725/2000, 耗时:0.00分/4.50分 | step: 41400 | performance: 1.7 | accuracy: 0.38 | loss: 1.31
update:1730/2000, 耗时:0.00分/4.52分 | step: 41520 | performance: 2.0 | accuracy: 0.38 | loss: 0.57
update:1735/2000, 耗时:0.00分/4.53分 | step: 41640 | performance: 1.8 | accuracy: 0.38 | loss: 0.54
update:1740/2000, 耗时:0.00分/4.54分 | step: 41760 | performance: 1.8 | accuracy: 0.38 | loss: 0.82
update:1745/2000, 耗时:0.00分/4.56分 | step: 41880 | performance: 1.7 | accuracy: 0.37 | loss: 1.12
update:1750/2000, 耗时:0.00分/4.57分 | step: 42000 | performance: 1.6 | accuracy: 0.37 | loss: 0.55
update:1755/2000, 耗时:0.00分/4.58分 | step: 42120 | performance: 1.6 | accuracy: 0.37 | loss: 0.79
update:1760/2000, 耗时:0.00分/4.59分 | step: 42240 | performance: 1.5 | accuracy: 0.37 | loss: 0.93
update:1765/2000, 耗时:0.00分/4.61分 | step: 42360 | performance: 1.6 | accuracy: 0.37 | loss: 0.62
update:1770/2000, 耗时:0.00分/4.62分 | step: 42480 | performance: 1.5 | accuracy: 0.37 | loss: 0.49
update:1775/2000, 耗时:0.00分/4.63分 | step: 42600 | performance: 1.6 | accuracy: 0.37 | loss: 0.25
update:1780/2000, 耗时:0.00分/4.64分 | step: 42720 | performance: 1.6 | accuracy: 0.37 | loss: 0.64
update:1785/2000, 耗时:0.00分/4.66分 | step: 42840 | performance: 1.6 | accuracy: 0.37 | loss: 0.34
update:1790/2000, 耗时:0.00分/4.67分 | step: 42960 | performance: 1.5 | accuracy: 0.37 | loss: 0.84
update:1795/2000, 耗时:0.00分/4.68分 | step: 43080 | performance: 1.1 | accuracy: 0.37 | loss: 0.31
update:1800/2000, 耗时:0.00分/4.69分 | step: 43200 | performance: 1.1 | accuracy: 0.37 | loss: 0.45
update:1805/2000, 耗时:0.00分/4.71分 | step: 43320 | performance: 1.0 | accuracy: 0.37 | loss: 1.65
update:1810/2000, 耗时:0.00分/4.72分 | step: 43440 | performance: 1.0 | accuracy: 0.37 | loss: 0.91
update:1815/2000, 耗时:0.00分/4.73分 | step: 43560 | performance: 1.0 | accuracy: 0.37 | loss: 0.90
update:1820/2000, 耗时:0.00分/4.75分 | step: 43680 | performance: 1.2 | accuracy: 0.37 | loss: 1.05
update:1825/2000, 耗时:0.00分/4.76分 | step: 43800 | performance: 1.6 | accuracy: 0.37 | loss: 2.46
update:1830/2000, 耗时:0.00分/4.77分 | step: 43920 | performance: 1.7 | accuracy: 0.38 | loss: 0.50
update:1835/2000, 耗时:0.00分/4.79分 | step: 44040 | performance: 2.7 | accuracy: 0.38 | loss: 2.49
update:1840/2000, 耗时:0.00分/4.80分 | step: 44160 | performance: 3.1 | accuracy: 0.38 | loss: 0.46
update:1845/2000, 耗时:0.00分/4.81分 | step: 44280 | performance: 4.7 | accuracy: 0.38 | loss: 0.96
update:1850/2000, 耗时:0.00分/4.83分 | step: 44400 | performance: 4.0 | accuracy: 0.38 | loss: 0.55
update:1855/2000, 耗时:0.00分/4.84分 | step: 44520 | performance: 4.6 | accuracy: 0.38 | loss: 0.88
update:1860/2000, 耗时:0.00分/4.85分 | step: 44640 | performance: 4.6 | accuracy: 0.39 | loss: 1.55
update:1865/2000, 耗时:0.00分/4.86分 | step: 44760 | performance: 7.5 | accuracy: 0.39 | loss: 1.85
update:1870/2000, 耗时:0.00分/4.88分 | step: 44880 | performance: 12.5 | accuracy: 0.39 | loss: 0.31
update:1875/2000, 耗时:0.00分/4.89分 | step: 45000 | performance: 21.8 | accuracy: 0.39 | loss: 1.01
update:1880/2000, 耗时:0.00分/4.90分 | step: 45120 | performance: 30.3 | accuracy: 0.39 | loss: 3.47
update:1885/2000, 耗时:0.00分/4.92分 | step: 45240 | performance: 32.8 | accuracy: 0.39 | loss: 3.91
update:1890/2000, 耗时:0.00分/4.93分 | step: 45360 | performance: 22.5 | accuracy: 0.39 | loss: 2.50
update:1895/2000, 耗时:0.00分/4.94分 | step: 45480 | performance: 38.8 | accuracy: 0.39 | loss: 1.39
update:1900/2000, 耗时:0.00分/4.96分 | step: 45600 | performance: 67.3 | accuracy: 0.40 | loss: 0.53
update:1905/2000, 耗时:0.00分/4.97分 | step: 45720 | performance: 93.0 | accuracy: 0.40 | loss: 1.02
update:1910/2000, 耗时:0.00分/4.98分 | step: 45840 | performance: 61.0 | accuracy: 0.40 | loss: 1.62
update:1915/2000, 耗时:0.00分/5.00分 | step: 45960 | performance: 65.7 | accuracy: 0.40 | loss: 0.72
update:1920/2000, 耗时:0.00分/5.01分 | step: 46080 | performance: 97.5 | accuracy: 0.40 | loss: 1.46
update:1925/2000, 耗时:0.00分/5.02分 | step: 46200 | performance: 81.5 | accuracy: 0.40 | loss: 3.56
update:1930/2000, 耗时:0.00分/5.03分 | step: 46320 | performance: 72.9 | accuracy: 0.40 | loss: 1.11
update:1935/2000, 耗时:0.00分/5.05分 | step: 46440 | performance: 73.8 | accuracy: 0.40 | loss: 0.53
update:1940/2000, 耗时:0.00分/5.06分 | step: 46560 | performance: 78.1 | accuracy: 0.40 | loss: 1.24
update:1945/2000, 耗时:0.00分/5.07分 | step: 46680 | performance: 62.0 | accuracy: 0.40 | loss: 0.43
update:1950/2000, 耗时:0.00分/5.08分 | step: 46800 | performance: 61.8 | accuracy: 0.40 | loss: 1.49
update:1955/2000, 耗时:0.00分/5.10分 | step: 46920 | performance: 62.0 | accuracy: 0.40 | loss: 0.78
update:1960/2000, 耗时:0.00分/5.11分 | step: 47040 | performance: 50.5 | accuracy: 0.40 | loss: 1.45
update:1965/2000, 耗时:0.00分/5.12分 | step: 47160 | performance: 26.7 | accuracy: 0.40 | loss: 0.63
update:1970/2000, 耗时:0.00分/5.14分 | step: 47280 | performance: 25.8 | accuracy: 0.40 | loss: 0.51
update:1975/2000, 耗时:0.00分/5.15分 | step: 47400 | performance: 24.0 | accuracy: 0.40 | loss: 0.57
update:1980/2000, 耗时:0.00分/5.16分 | step: 47520 | performance: 20.9 | accuracy: 0.39 | loss: 0.32
update:1985/2000, 耗时:0.00分/5.18分 | step: 47640 | performance: 25.3 | accuracy: 0.39 | loss: 0.71
update:1990/2000, 耗时:0.00分/5.19分 | step: 47760 | performance: 23.3 | accuracy: 0.39 | loss: 0.76
update:1995/2000, 耗时:0.00分/5.20分 | step: 47880 | performance: 21.3 | accuracy: 0.39 | loss: 1.16
  0%|          | 0/408 [00:00<?, ?it/s]100%|| 408/408 [00:00<00:00, 102165.73it/s]
update:2000/2000, 耗时:0.00分/5.22分 | step: 48000 | performance: 21.8 | accuracy: 0.39 | loss: 0.21
----------------------------------------finished----------------------------------------
==================================================
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1192.82
2023-07-24T12:00:00 | net performance [%] = 19.2815
2023-07-24T12:00:00 | number of trades [#] = 26
==================================================
Trial 38 Complete [00h 05m 40s]
net_wealth: 1194.0094484048498

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 05h 02m 44s

Search: Running Trial #39

Value             |Best Value So Far |Hyperparameter
1                 |7                 |horizon
730               |730               |lookback
True              |False             |MarketFactor
10                |14                |lags
0.9               |0.7               |gamma
16                |32                |batch_size
7                 |32                |n_step
0.98              |0.92              |gae_lambda
5                 |0.1               |gradient_clip_norm
5                 |5                 |epochs
0.001             |0.0001            |actor_lr
0.0001            |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4300.000000   4301.000000
mean      0.000435    20113.607657  ...   20173.020481  20169.373185
std       0.027833    16040.642334  ...   16078.674434  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7736.967529   7730.930176
50%       0.000642    11571.842969  ...   11753.029785  11751.469727
75%       0.011590    29894.706152  ...   30013.548340  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-22023-07-28 03:06:07.2023-07-28 03:06:07.860488: I 28 03:06t8:07e6.04720223-07-28 :n I03:08so66r:f0 low/core/plate023t2f02430-o-07-20778 0-n28 .086033:06:07s:5026rm:0o7./cpu_featur8655:rflow/.04core/ple6a_3: guar8d.6cc04: It :tensorform/c6142]I flo This1  1IT wttenpu_f: I tensoeens/encore/platform/cpu_feature_guard.cc:142] Thi2so0s23-07-28 0oat3o2:u0rrrFlow binaf6re_frlyo wl:rifso0/ colwp/coorw7stimizegu/ ed wTpol.atfe8inosrrea/tomrFlow 600bh 9oi02/3n/anr2ecp-lcyA07opurart ifd-s optoi:P.mi_c2cf :eIe/8 03aIrpm: z/c142t ed wilatf] ThittDeenues0s r6hp NeuroaTernsfe_ogrull NeF: aonrd0twoo.crlo7.m/8o60wecpu/crwk pboirnue_9/_f26:c pelarayt aI: 1 tufre4_gteis2uaLeA] tiunbs oorflptaifrrroarryd.c cTe_guardm/cpu_feature_guard.cc:142] Th(mow/core/platform/cpu_feature_guard.cc:PIized with oneAPI Deep:h 1D414 22e] TeN]hip sNeu reuralTah  lTiNeet.c cNws: 1e4toTweon2nioneDNrk r]k LLN)  Ts isobhis rTeiaTsriy (onbrary nosorFerelso F(ornDeNDTenFlnowws obrtNs)oilnoN rFFolw  Nbaina)lo ub ionws ebintor yu is asa rwy  oitrpys  hetoeiispt bii onarypmt is optimized i rmttzoedi zuwf oye di wwisihsl tohp iitmhize do nweiAtoe eht noieAPt IlmPoIithwih ng nCezed  PwUo e fointeAiDlnslotwPI  h onDeADeireeepfeoup n NPgc CtIi PDNeelpleouwinge p ConrNae PNeuuuralsraUl r a U instl iNnNr ucNeettwwoeile Network LibAPI Dn stpertkrefrouwc tLooririk Libktrborr Liraryi b(rarmoanoeans in ans iperyyDnne   ((NrNyp) or f(ocpe-c onetrofn unerNseeDooermaeuDrDnce-iNmNaNcr athNeN rtl)nN )i)fcal o itto usooptcl leo-wiiucese ntg   aNetcrtt oehhee flo rwaoCPtio pueioUl stirn sfole: ikcal r o wLithnlloaet fnolstAVg ClPiwXii oUo bowpr urAenrcitiVga nisnatCiPU:n Xryos tArVuXc  nos tAi o(go nCeinnisP2VnX 2
DU
 T:pnesr iin nsTtrucsftor oA VNuN oX  erc)mteAt itoon pseirofusnaanblnen iVn co s ein etaXp ert-c2pfeorrfmr
hhbleamTeen rai toiotmfcalnccee -o cori ti-pcerhin oircaatltherions:lrtliecma    o pAeVromol Xwpaernactein iAoVnX2anoea-bpls
tcer ,To giitnh emo  in ie teCircaorPtUh aionl oepethenrsti res:otnrsu:c t iAnVaXbaoob l urinApVeX 2 Aoeltdr apse TteV iXn Art
i hVaXt2
pToiTinesrfooooemr Fionn orm so:enlan  nsotns,c ereb-ucw  ,rhietwieAVrica naabilethrb  lt eleopel dthX  tAhV Xeroehm ien ab2mT einti
o sapoent honprroesrpatthF,l ruoiil odw  Toonweirp rrebpeuriatsiaoipoentl:dT o  AeertaetnnsoVX isoanbrleT theF s e,A nVsXl2omhr ewo  ,c rwFit
bourlohtielbdwm heiTuoi len  w dt hepTienalae rinths bfl a otTeo rtFhleopethel agmwnhaepr sp prsw.pip rooppe
rn otheooriirpri otrapterFatoph rthe apiloaetrwata e  ioccwtieinspt omcoonsropriaoh m,p,ilpiete  rebcmom rebuiltd pilrhlpTielee ra  ffpnsolagers er flafplagr.Fglu
ild rops.Towsl.
er
iate compiler flags.
 with the appropriate compiler flags.
nsoags.
rFlow with the appropriate compiler flags.
2023-07-28 03:06:08.463901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:06:08.471420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:06:08.488044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:06:08.493334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:06:08.497653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:06:08.508028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:06:08.509301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3072023-070, pci bus i-2d: 08 03:06:008.515358: I tenso00:01rflow/c:00.o0, compute cre/common_runtime/gpu/gpu_device.cc:1510]a Createpabilityd device /j: 8.6
ob:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   280 | performance: 0.9 | accuracy: 0.37 | loss: 1.40
update: 10/2000, 耗时:0.00分/0.05分 | step:   560 | performance: 0.9 | accuracy: 0.41 | loss: 1.45
update: 15/2000, 耗时:0.00分/0.06分 | step:   840 | performance: 0.9 | accuracy: 0.38 | loss: 1.46
update: 20/2000, 耗时:0.00分/0.07分 | step:  1120 | performance: 0.9 | accuracy: 0.36 | loss: 1.18
update: 25/2000, 耗时:0.00分/0.09分 | step:  1400 | performance: 0.9 | accuracy: 0.33 | loss: 2.03
update: 30/2000, 耗时:0.00分/0.10分 | step:  1680 | performance: 0.8 | accuracy: 0.30 | loss: 0.91
update: 35/2000, 耗时:0.00分/0.12分 | step:  1960 | performance: 0.8 | accuracy: 0.29 | loss: 0.42
update: 40/2000, 耗时:0.00分/0.13分 | step:  2240 | performance: 0.9 | accuracy: 0.27 | loss: 0.36
update: 45/2000, 耗时:0.00分/0.15分 | step:  2520 | performance: 0.9 | accuracy: 0.27 | loss: 0.29
update: 50/2000, 耗时:0.00分/0.16分 | step:  2800 | performance: 0.9 | accuracy: 0.25 | loss: 0.62
update: 55/2000, 耗时:0.00分/0.18分 | step:  3080 | performance: 0.9 | accuracy: 0.25 | loss: 0.13
update: 60/2000, 耗时:0.00分/0.19分 | step:  3360 | performance: 0.9 | accuracy: 0.24 | loss: 0.15
update: 65/2000, 耗时:0.00分/0.21分 | step:  3640 | performance: 0.9 | accuracy: 0.22 | loss: 0.04
update: 70/2000, 耗时:0.00分/0.22分 | step:  3920 | performance: 0.9 | accuracy: 0.21 | loss: 0.01
update: 75/2000, 耗时:0.00分/0.24分 | step:  4200 | performance: 0.9 | accuracy: 0.20 | loss: 0.21
update: 80/2000, 耗时:0.00分/0.25分 | step:  4480 | performance: 1.0 | accuracy: 0.20 | loss: 0.73
update: 85/2000, 耗时:0.00分/0.27分 | step:  4760 | performance: 1.0 | accuracy: 0.21 | loss: 4.51
update: 90/2000, 耗时:0.00分/0.28分 | step:  5040 | performance: 0.8 | accuracy: 0.23 | loss: 1.70
update: 95/2000, 耗时:0.00分/0.30分 | step:  5320 | performance: 0.9 | accuracy: 0.23 | loss: 0.54
update:100/2000, 耗时:0.00分/0.32分 | step:  5600 | performance: 0.8 | accuracy: 0.23 | loss: 1.41
update:105/2000, 耗时:0.00分/0.33分 | step:  5880 | performance: 0.8 | accuracy: 0.24 | loss: 0.47
update:110/2000, 耗时:0.00分/0.35分 | step:  6160 | performance: 0.6 | accuracy: 0.24 | loss: 0.49
update:115/2000, 耗时:0.00分/0.37分 | step:  6440 | performance: 0.6 | accuracy: 0.24 | loss: 0.17
update:120/2000, 耗时:0.00分/0.38分 | step:  6720 | performance: 0.6 | accuracy: 0.24 | loss: 0.44
update:125/2000, 耗时:0.00分/0.40分 | step:  7000 | performance: 0.6 | accuracy: 0.23 | loss: 0.07
update:130/2000, 耗时:0.00分/0.41分 | step:  7280 | performance: 0.6 | accuracy: 0.23 | loss: 0.21
update:135/2000, 耗时:0.00分/0.43分 | step:  7560 | performance: 0.6 | accuracy: 0.23 | loss: 0.19
update:140/2000, 耗时:0.00分/0.45分 | step:  7840 | performance: 0.6 | accuracy: 0.22 | loss: 0.08
update:145/2000, 耗时:0.00分/0.46分 | step:  8120 | performance: 0.6 | accuracy: 0.22 | loss: 0.39
update:150/2000, 耗时:0.00分/0.48分 | step:  8400 | performance: 0.6 | accuracy: 0.22 | loss: 0.63
update:155/2000, 耗时:0.00分/0.50分 | step:  8680 | performance: 0.6 | accuracy: 0.22 | loss: 0.88
update:160/2000, 耗时:0.00分/0.51分 | step:  8960 | performance: 0.8 | accuracy: 0.22 | loss: 2.31
update:165/2000, 耗时:0.00分/0.53分 | step:  9240 | performance: 0.7 | accuracy: 0.22 | loss: 0.10
update:170/2000, 耗时:0.00分/0.54分 | step:  9520 | performance: 0.7 | accuracy: 0.21 | loss: 0.01
update:175/2000, 耗时:0.00分/0.56分 | step:  9800 | performance: 0.7 | accuracy: 0.21 | loss: 0.01
update:180/2000, 耗时:0.00分/0.58分 | step: 10080 | performance: 0.8 | accuracy: 0.21 | loss: 0.28
update:185/2000, 耗时:0.00分/0.59分 | step: 10360 | performance: 0.8 | accuracy: 0.20 | loss: 0.02
update:190/2000, 耗时:0.00分/0.61分 | step: 10640 | performance: 0.7 | accuracy: 0.20 | loss: 0.58
update:195/2000, 耗时:0.00分/0.63分 | step: 10920 | performance: 0.8 | accuracy: 0.20 | loss: 0.06
update:200/2000, 耗时:0.00分/0.64分 | step: 11200 | performance: 0.8 | accuracy: 0.21 | loss: 0.50
update:205/2000, 耗时:0.00分/0.66分 | step: 11480 | performance: 0.8 | accuracy: 0.21 | loss: 0.67
update:210/2000, 耗时:0.00分/0.68分 | step: 11760 | performance: 0.6 | accuracy: 0.21 | loss: 0.98
update:215/2000, 耗时:0.00分/0.69分 | step: 12040 | performance: 0.7 | accuracy: 0.21 | loss: 0.74
update:220/2000, 耗时:0.00分/0.71分 | step: 12320 | performance: 0.7 | accuracy: 0.22 | loss: 0.52
update:225/2000, 耗时:0.00分/0.72分 | step: 12600 | performance: 0.7 | accuracy: 0.22 | loss: 0.71
update:230/2000, 耗时:0.00分/0.74分 | step: 12880 | performance: 1.0 | accuracy: 0.23 | loss: 0.97
update:235/2000, 耗时:0.00分/0.76分 | step: 13160 | performance: 1.0 | accuracy: 0.24 | loss: 0.40
update:240/2000, 耗时:0.00分/0.77分 | step: 13440 | performance: 1.2 | accuracy: 0.25 | loss: 1.52
update:245/2000, 耗时:0.00分/0.79分 | step: 13720 | performance: 1.7 | accuracy: 0.25 | loss: 4.53
update:250/2000, 耗时:0.00分/0.81分 | step: 14000 | performance: 1.5 | accuracy: 0.26 | loss: 2.12
update:255/2000, 耗时:0.00分/0.82分 | step: 14280 | performance: 1.8 | accuracy: 0.26 | loss: 0.43
update:260/2000, 耗时:0.00分/0.84分 | step: 14560 | performance: 1.6 | accuracy: 0.27 | loss: 0.79
update:265/2000, 耗时:0.00分/0.86分 | step: 14840 | performance: 1.5 | accuracy: 0.27 | loss: 0.50
update:270/2000, 耗时:0.00分/0.87分 | step: 15120 | performance: 1.5 | accuracy: 0.28 | loss: 0.80
update:275/2000, 耗时:0.00分/0.89分 | step: 15400 | performance: 1.2 | accuracy: 0.28 | loss: 1.49
update:280/2000, 耗时:0.00分/0.91分 | step: 15680 | performance: 1.2 | accuracy: 0.28 | loss: 0.71
update:285/2000, 耗时:0.00分/0.92分 | step: 15960 | performance: 1.2 | accuracy: 0.28 | loss: 0.67
update:290/2000, 耗时:0.00分/0.94分 | step: 16240 | performance: 1.1 | accuracy: 0.28 | loss: 0.71
update:295/2000, 耗时:0.00分/0.96分 | step: 16520 | performance: 1.2 | accuracy: 0.28 | loss: 0.16
update:300/2000, 耗时:0.00分/0.97分 | step: 16800 | performance: 1.2 | accuracy: 0.28 | loss: 0.39
update:305/2000, 耗时:0.00分/0.99分 | step: 17080 | performance: 1.4 | accuracy: 0.27 | loss: 0.37
update:310/2000, 耗时:0.00分/1.01分 | step: 17360 | performance: 1.4 | accuracy: 0.27 | loss: 0.36
update:315/2000, 耗时:0.00分/1.02分 | step: 17640 | performance: 1.3 | accuracy: 0.27 | loss: 0.14
update:320/2000, 耗时:0.00分/1.04分 | step: 17920 | performance: 1.3 | accuracy: 0.27 | loss: 0.03
update:325/2000, 耗时:0.00分/1.06分 | step: 18200 | performance: 1.3 | accuracy: 0.26 | loss: 0.00
update:330/2000, 耗时:0.00分/1.08分 | step: 18480 | performance: 1.3 | accuracy: 0.26 | loss: 0.09
update:335/2000, 耗时:0.00分/1.09分 | step: 18760 | performance: 1.3 | accuracy: 0.25 | loss: 0.00
update:340/2000, 耗时:0.00分/1.11分 | step: 19040 | performance: 1.3 | accuracy: 0.25 | loss: 0.00
update:345/2000, 耗时:0.00分/1.13分 | step: 19320 | performance: 1.3 | accuracy: 0.25 | loss: 0.10
update:350/2000, 耗时:0.00分/1.14分 | step: 19600 | performance: 1.3 | accuracy: 0.25 | loss: 0.02
update:355/2000, 耗时:0.00分/1.16分 | step: 19880 | performance: 1.3 | accuracy: 0.24 | loss: 0.06
update:360/2000, 耗时:0.00分/1.18分 | step: 20160 | performance: 1.3 | accuracy: 0.24 | loss: 0.01
update:365/2000, 耗时:0.00分/1.19分 | step: 20440 | performance: 1.3 | accuracy: 0.24 | loss: 0.07
update:370/2000, 耗时:0.00分/1.21分 | step: 20720 | performance: 1.3 | accuracy: 0.23 | loss: 0.01
update:375/2000, 耗时:0.00分/1.23分 | step: 21000 | performance: 1.3 | accuracy: 0.23 | loss: 0.01
update:380/2000, 耗时:0.00分/1.24分 | step: 21280 | performance: 1.3 | accuracy: 0.23 | loss: 0.00
update:385/2000, 耗时:0.00分/1.26分 | step: 21560 | performance: 1.3 | accuracy: 0.23 | loss: 0.00
update:390/2000, 耗时:0.00分/1.28分 | step: 21840 | performance: 1.3 | accuracy: 0.22 | loss: 0.00
update:395/2000, 耗时:0.00分/1.29分 | step: 22120 | performance: 1.3 | accuracy: 0.22 | loss: 0.12
update:400/2000, 耗时:0.00分/1.31分 | step: 22400 | performance: 1.3 | accuracy: 0.22 | loss: 0.30
update:405/2000, 耗时:0.00分/1.33分 | step: 22680 | performance: 1.3 | accuracy: 0.22 | loss: 0.01
update:410/2000, 耗时:0.00分/1.35分 | step: 22960 | performance: 1.3 | accuracy: 0.21 | loss: 0.00
update:415/2000, 耗时:0.00分/1.36分 | step: 23240 | performance: 1.3 | accuracy: 0.21 | loss: 0.12
update:420/2000, 耗时:0.00分/1.38分 | step: 23520 | performance: 1.3 | accuracy: 0.21 | loss: 0.11
update:425/2000, 耗时:0.00分/1.40分 | step: 23800 | performance: 1.3 | accuracy: 0.21 | loss: 0.09
update:430/2000, 耗时:0.00分/1.41分 | step: 24080 | performance: 1.3 | accuracy: 0.21 | loss: 0.01
update:435/2000, 耗时:0.00分/1.43分 | step: 24360 | performance: 1.3 | accuracy: 0.21 | loss: 0.00
update:440/2000, 耗时:0.00分/1.45分 | step: 24640 | performance: 1.3 | accuracy: 0.20 | loss: 0.12
update:445/2000, 耗时:0.00分/1.46分 | step: 24920 | performance: 1.3 | accuracy: 0.20 | loss: 0.01
update:450/2000, 耗时:0.00分/1.48分 | step: 25200 | performance: 1.3 | accuracy: 0.20 | loss: 0.04
Saving PPO weights in both H5 format and checkpoint @ update:451 
update:455/2000, 耗时:0.00分/1.50分 | step: 25480 | performance: 1.0 | accuracy: 0.07 | loss: 0.03
update:460/2000, 耗时:0.00分/1.52分 | step: 25760 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 26033 | worker_0@n_step_6: average total_reward after train data exhaustion : 30.1 | max total_reward: 207.4
step: 26034 | worker_1@n_step_6: average total_reward after train data exhaustion : 29.5 | max total_reward: 207.4
step: 26035 | worker_2@n_step_6: average total_reward after train data exhaustion : 25.7 | max total_reward: 207.4
step: 26036 | worker_3@n_step_6: average total_reward after train data exhaustion : 21.6 | max total_reward: 207.4
step: 26037 | worker_4@n_step_6: average total_reward after train data exhaustion : 17.7 | max total_reward: 207.4
step: 26038 | worker_5@n_step_6: average total_reward after train data exhaustion : 13.7 | max total_reward: 207.4
step: 26039 | worker_6@n_step_6: average total_reward after train data exhaustion : 9.8 | max total_reward: 207.4
step: 26040 | worker_7@n_step_6: average total_reward after train data exhaustion : 6.5 | max total_reward: 207.4
update:465/2000, 耗时:0.00分/1.54分 | step: 26040 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:470/2000, 耗时:0.00分/1.55分 | step: 26320 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:475/2000, 耗时:0.00分/1.57分 | step: 26600 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:480/2000, 耗时:0.00分/1.59分 | step: 26880 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 26985 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 26986 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 26987 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 26988 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 26989 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 26990 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 26991 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 26992 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:485/2000, 耗时:0.00分/1.60分 | step: 27160 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:490/2000, 耗时:0.00分/1.62分 | step: 27440 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:495/2000, 耗时:0.00分/1.64分 | step: 27720 | performance: 1.0 | accuracy: 0.17 | loss: 0.15
step: 27937 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 27938 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 27939 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 27940 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 27941 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 27942 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 27943 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 27944 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:500/2000, 耗时:0.00分/1.65分 | step: 28000 | performance: 1.0 | accuracy: 0.14 | loss: 0.07
update:505/2000, 耗时:0.00分/1.67分 | step: 28280 | performance: 1.0 | accuracy: 0.12 | loss: 0.09
update:510/2000, 耗时:0.00分/1.69分 | step: 28560 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:515/2000, 耗时:0.00分/1.70分 | step: 28840 | performance: 1.0 | accuracy: 0.10 | loss: 0.10
step: 28889 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 28890 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 28891 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 28892 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 28893 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 28894 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 28895 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 28896 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:520/2000, 耗时:0.00分/1.72分 | step: 29120 | performance: 1.0 | accuracy: 0.09 | loss: 0.11
update:525/2000, 耗时:0.00分/1.74分 | step: 29400 | performance: 1.0 | accuracy: 0.08 | loss: 0.07
update:530/2000, 耗时:0.00分/1.75分 | step: 29680 | performance: 1.0 | accuracy: 0.08 | loss: 0.03
step: 29841 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 29842 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 29843 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 29844 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 29845 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 29846 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 29847 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 29848 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:535/2000, 耗时:0.00分/1.77分 | step: 29960 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:540/2000, 耗时:0.00分/1.79分 | step: 30240 | performance: 1.0 | accuracy: 0.07 | loss: 0.00
update:545/2000, 耗时:0.00分/1.80分 | step: 30520 | performance: 1.0 | accuracy: 0.06 | loss: 0.00
step: 30793 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 30794 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 30795 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 30796 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 30797 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 30798 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 30799 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 30800 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:550/2000, 耗时:0.00分/1.82分 | step: 30800 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:555/2000, 耗时:0.00分/1.84分 | step: 31080 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:560/2000, 耗时:0.00分/1.85分 | step: 31360 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:565/2000, 耗时:0.00分/1.87分 | step: 31640 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 31745 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 31746 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 31747 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 31748 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 31749 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 31750 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 31751 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 31752 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:570/2000, 耗时:0.00分/1.89分 | step: 31920 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:575/2000, 耗时:0.00分/1.91分 | step: 32200 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:580/2000, 耗时:0.00分/1.92分 | step: 32480 | performance: 1.0 | accuracy: 0.17 | loss: 0.15
step: 32697 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 32698 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 32699 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 32700 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 32701 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 32702 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 32703 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 32704 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:585/2000, 耗时:0.00分/1.94分 | step: 32760 | performance: 1.0 | accuracy: 0.14 | loss: 0.07
update:590/2000, 耗时:0.00分/1.96分 | step: 33040 | performance: 1.0 | accuracy: 0.12 | loss: 0.09
update:595/2000, 耗时:0.00分/1.97分 | step: 33320 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:600/2000, 耗时:0.00分/1.99分 | step: 33600 | performance: 1.0 | accuracy: 0.10 | loss: 0.10
step: 33649 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 33650 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 33651 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 33652 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 33653 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 33654 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 33655 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 33656 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:605/2000, 耗时:0.00分/2.01分 | step: 33880 | performance: 1.0 | accuracy: 0.09 | loss: 0.10
update:610/2000, 耗时:0.00分/2.03分 | step: 34160 | performance: 1.0 | accuracy: 0.08 | loss: 0.07
update:615/2000, 耗时:0.00分/2.04分 | step: 34440 | performance: 1.0 | accuracy: 0.08 | loss: 0.03
step: 34601 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 34602 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 34603 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 34604 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 34605 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 34606 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 34607 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 34608 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:620/2000, 耗时:0.00分/2.06分 | step: 34720 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:625/2000, 耗时:0.00分/2.08分 | step: 35000 | performance: 1.0 | accuracy: 0.07 | loss: 0.00
update:630/2000, 耗时:0.00分/2.10分 | step: 35280 | performance: 1.0 | accuracy: 0.06 | loss: 0.00
step: 35553 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 35554 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 35555 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 35556 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 35557 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 35558 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 35559 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 35560 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:635/2000, 耗时:0.00分/2.11分 | step: 35560 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:640/2000, 耗时:0.00分/2.13分 | step: 35840 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:645/2000, 耗时:0.00分/2.15分 | step: 36120 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:650/2000, 耗时:0.00分/2.17分 | step: 36400 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 36505 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 36506 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 36507 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 36508 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 36509 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 36510 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 36511 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 36512 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:655/2000, 耗时:0.00分/2.18分 | step: 36680 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:660/2000, 耗时:0.00分/2.20分 | step: 36960 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
update:665/2000, 耗时:0.00分/2.22分 | step: 37240 | performance: 1.0 | accuracy: 0.17 | loss: 0.15
step: 37457 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 37458 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 37459 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 37460 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 37461 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 37462 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 37463 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 37464 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:670/2000, 耗时:0.00分/2.24分 | step: 37520 | performance: 1.0 | accuracy: 0.14 | loss: 0.07
update:675/2000, 耗时:0.00分/2.25分 | step: 37800 | performance: 1.0 | accuracy: 0.12 | loss: 0.08
update:680/2000, 耗时:0.00分/2.27分 | step: 38080 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:685/2000, 耗时:0.00分/2.29分 | step: 38360 | performance: 1.0 | accuracy: 0.10 | loss: 0.10
step: 38409 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 38410 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 38411 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 38412 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 38413 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 38414 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 38415 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 38416 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:690/2000, 耗时:0.00分/2.31分 | step: 38640 | performance: 1.0 | accuracy: 0.09 | loss: 0.11
update:695/2000, 耗时:0.00分/2.32分 | step: 38920 | performance: 1.0 | accuracy: 0.08 | loss: 0.07
update:700/2000, 耗时:0.00分/2.34分 | step: 39200 | performance: 1.0 | accuracy: 0.08 | loss: 0.03
step: 39361 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 39362 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 39363 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 39364 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 39365 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 39366 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 39367 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 39368 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:705/2000, 耗时:0.00分/2.36分 | step: 39480 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:710/2000, 耗时:0.00分/2.37分 | step: 39760 | performance: 1.0 | accuracy: 0.07 | loss: 0.00
update:715/2000, 耗时:0.00分/2.39分 | step: 40040 | performance: 1.0 | accuracy: 0.06 | loss: 0.00
step: 40313 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 40314 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 40315 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 40316 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 40317 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 40318 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 40319 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 40320 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:720/2000, 耗时:0.00分/2.41分 | step: 40320 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:725/2000, 耗时:0.00分/2.43分 | step: 40600 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:730/2000, 耗时:0.00分/2.44分 | step: 40880 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:735/2000, 耗时:0.00分/2.46分 | step: 41160 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 41265 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 41266 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 41267 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 41268 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 41269 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 41270 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 41271 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 41272 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:740/2000, 耗时:0.00分/2.48分 | step: 41440 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:745/2000, 耗时:0.00分/2.49分 | step: 41720 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:750/2000, 耗时:0.00分/2.51分 | step: 42000 | performance: 1.0 | accuracy: 0.17 | loss: 0.13
step: 42218 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.1 | max total_reward: 207.4
step: 42220 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.1 | max total_reward: 207.4
step: 42221 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.1 | max total_reward: 207.4
step: 42222 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.1 | max total_reward: 207.4
step: 42223 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.1 | max total_reward: 207.4
step: 42224 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.1 | max total_reward: 207.4
update:755/2000, 耗时:0.00分/2.53分 | step: 42280 | performance: 1.0 | accuracy: 0.14 | loss: 0.09
step: 42329 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.1 | max total_reward: 207.4
step: 42331 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.1 | max total_reward: 207.4
update:760/2000, 耗时:0.00分/2.54分 | step: 42560 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:765/2000, 耗时:0.00分/2.56分 | step: 42840 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:770/2000, 耗时:0.00分/2.58分 | step: 43120 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 43170 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 43172 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 43173 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 43174 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 43175 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 43176 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 43281 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 43283 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:775/2000, 耗时:0.00分/2.59分 | step: 43400 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:780/2000, 耗时:0.00分/2.61分 | step: 43680 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
update:785/2000, 耗时:0.00分/2.63分 | step: 43960 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 44122 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 44124 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 44125 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 44126 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 44127 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 44128 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 44233 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 44235 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:790/2000, 耗时:0.00分/2.64分 | step: 44240 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:795/2000, 耗时:0.00分/2.66分 | step: 44520 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:800/2000, 耗时:0.00分/2.68分 | step: 44800 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 45074 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 45076 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 45077 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 45078 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 45079 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 45080 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:805/2000, 耗时:0.00分/2.70分 | step: 45080 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 45185 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 45187 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:810/2000, 耗时:0.00分/2.71分 | step: 45360 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:815/2000, 耗时:0.00分/2.73分 | step: 45640 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:820/2000, 耗时:0.00分/2.75分 | step: 45920 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 46026 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46028 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46029 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46030 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46031 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46032 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46137 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46139 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:825/2000, 耗时:0.00分/2.76分 | step: 46200 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
update:830/2000, 耗时:0.00分/2.78分 | step: 46480 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:835/2000, 耗时:0.00分/2.80分 | step: 46760 | performance: 1.0 | accuracy: 0.17 | loss: 0.13
step: 46978 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46980 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46981 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46982 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46983 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 46984 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:840/2000, 耗时:0.00分/2.81分 | step: 47040 | performance: 1.0 | accuracy: 0.14 | loss: 0.09
step: 47089 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 47091 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:845/2000, 耗时:0.00分/2.83分 | step: 47320 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:850/2000, 耗时:0.00分/2.85分 | step: 47600 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:855/2000, 耗时:0.00分/2.86分 | step: 47880 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 47930 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 47932 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 47933 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 47934 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 47935 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 47936 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 48041 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 48043 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:860/2000, 耗时:0.00分/2.88分 | step: 48160 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:865/2000, 耗时:0.00分/2.89分 | step: 48440 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
update:870/2000, 耗时:0.00分/2.91分 | step: 48720 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 48882 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 48884 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 48885 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 48886 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 48887 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 48888 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 48993 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 48995 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:875/2000, 耗时:0.00分/2.93分 | step: 49000 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
update:880/2000, 耗时:0.00分/2.94分 | step: 49280 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:885/2000, 耗时:0.00分/2.96分 | step: 49560 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 49834 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 49836 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 49837 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 49838 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 49839 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 49840 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:890/2000, 耗时:0.00分/2.97分 | step: 49840 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 49945 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 49947 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:895/2000, 耗时:0.00分/2.99分 | step: 50120 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:900/2000, 耗时:0.00分/3.00分 | step: 50400 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:905/2000, 耗时:0.00分/3.02分 | step: 50680 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 50786 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 50788 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 50789 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 50790 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 50791 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 50792 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 50897 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 50899 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:910/2000, 耗时:0.00分/3.04分 | step: 50960 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:915/2000, 耗时:0.00分/3.05分 | step: 51240 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:920/2000, 耗时:0.00分/3.07分 | step: 51520 | performance: 1.0 | accuracy: 0.17 | loss: 0.14
step: 51738 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 51740 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 51741 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 51742 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 51743 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 51744 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:925/2000, 耗时:0.00分/3.08分 | step: 51800 | performance: 1.0 | accuracy: 0.14 | loss: 0.09
step: 51849 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 51851 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:930/2000, 耗时:0.00分/3.10分 | step: 52080 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:935/2000, 耗时:0.00分/3.11分 | step: 52360 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:940/2000, 耗时:0.00分/3.13分 | step: 52640 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 52690 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 52692 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 52693 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 52694 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 52695 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 52696 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 52801 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 52803 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:945/2000, 耗时:0.00分/3.15分 | step: 52920 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:950/2000, 耗时:0.00分/3.16分 | step: 53200 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
update:955/2000, 耗时:0.00分/3.18分 | step: 53480 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 53642 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 53644 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 53645 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 53646 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 53647 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 53648 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 53753 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 53755 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:960/2000, 耗时:0.00分/3.19分 | step: 53760 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
update:965/2000, 耗时:0.00分/3.21分 | step: 54040 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:970/2000, 耗时:0.00分/3.22分 | step: 54320 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 54594 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 54596 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 54597 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 54598 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 54599 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 54600 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:975/2000, 耗时:0.00分/3.24分 | step: 54600 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 54705 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 54707 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:980/2000, 耗时:0.00分/3.26分 | step: 54880 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:985/2000, 耗时:0.00分/3.27分 | step: 55160 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:990/2000, 耗时:0.00分/3.29分 | step: 55440 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 55546 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 55548 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 55549 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 55550 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 55551 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 55552 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 55657 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 55659 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:995/2000, 耗时:0.00分/3.30分 | step: 55720 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
update:1000/2000, 耗时:0.00分/3.32分 | step: 56000 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:1005/2000, 耗时:0.00分/3.33分 | step: 56280 | performance: 1.0 | accuracy: 0.17 | loss: 0.14
step: 56498 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 56500 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 56501 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 56502 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 56503 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 56504 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1010/2000, 耗时:0.00分/3.35分 | step: 56560 | performance: 1.0 | accuracy: 0.14 | loss: 0.09
step: 56609 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 56611 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1015/2000, 耗时:0.00分/3.37分 | step: 56840 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:1020/2000, 耗时:0.00分/3.38分 | step: 57120 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:1025/2000, 耗时:0.00分/3.40分 | step: 57400 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 57450 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 57452 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 57453 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 57454 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 57455 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 57456 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 57561 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 57563 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1030/2000, 耗时:0.00分/3.41分 | step: 57680 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:1035/2000, 耗时:0.00分/3.43分 | step: 57960 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
update:1040/2000, 耗时:0.00分/3.45分 | step: 58240 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 58402 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 58404 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 58405 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 58406 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 58407 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 58408 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 58513 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 58515 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1045/2000, 耗时:0.00分/3.46分 | step: 58520 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
update:1050/2000, 耗时:0.00分/3.48分 | step: 58800 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:1055/2000, 耗时:0.00分/3.50分 | step: 59080 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 59354 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 59356 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 59357 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 59358 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 59359 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 59360 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1060/2000, 耗时:0.00分/3.51分 | step: 59360 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 59465 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 59467 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1065/2000, 耗时:0.00分/3.53分 | step: 59640 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1070/2000, 耗时:0.00分/3.54分 | step: 59920 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:1075/2000, 耗时:0.00分/3.56分 | step: 60200 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 60306 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 60308 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 60309 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 60310 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 60311 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 60312 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 60417 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 60419 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1080/2000, 耗时:0.00分/3.58分 | step: 60480 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
update:1085/2000, 耗时:0.00分/3.59分 | step: 60760 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:1090/2000, 耗时:0.00分/3.61分 | step: 61040 | performance: 1.0 | accuracy: 0.17 | loss: 0.14
step: 61258 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 61260 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 61261 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 61262 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 61263 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 61264 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1095/2000, 耗时:0.00分/3.62分 | step: 61320 | performance: 1.0 | accuracy: 0.14 | loss: 0.09
step: 61369 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 61371 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1100/2000, 耗时:0.00分/3.64分 | step: 61600 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:1105/2000, 耗时:0.00分/3.66分 | step: 61880 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:1110/2000, 耗时:0.00分/3.67分 | step: 62160 | performance: 1.0 | accuracy: 0.10 | loss: 0.08
step: 62210 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 62212 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 62213 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 62214 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 62215 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 62216 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 62321 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 62323 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1115/2000, 耗时:0.00分/3.69分 | step: 62440 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:1120/2000, 耗时:0.00分/3.71分 | step: 62720 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
update:1125/2000, 耗时:0.00分/3.72分 | step: 63000 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 63162 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 63164 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 63165 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 63166 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 63167 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 63168 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 63273 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 63275 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1130/2000, 耗时:0.00分/3.74分 | step: 63280 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
update:1135/2000, 耗时:0.00分/3.75分 | step: 63560 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:1140/2000, 耗时:0.00分/3.77分 | step: 63840 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 64114 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 64116 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 64117 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 64118 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 64119 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 64120 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1145/2000, 耗时:0.00分/3.79分 | step: 64120 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 64225 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 64227 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1150/2000, 耗时:0.00分/3.80分 | step: 64400 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1155/2000, 耗时:0.00分/3.82分 | step: 64680 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:1160/2000, 耗时:0.00分/3.84分 | step: 64960 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 65066 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 65068 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 65069 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 65070 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 65071 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 65072 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 65177 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 65179 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1165/2000, 耗时:0.00分/3.85分 | step: 65240 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
update:1170/2000, 耗时:0.00分/3.87分 | step: 65520 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:1175/2000, 耗时:0.00分/3.88分 | step: 65800 | performance: 1.0 | accuracy: 0.17 | loss: 0.14
step: 66018 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66020 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66021 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66022 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66023 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66024 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1180/2000, 耗时:0.00分/3.90分 | step: 66080 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
step: 66129 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66131 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1185/2000, 耗时:0.00分/3.91分 | step: 66360 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:1190/2000, 耗时:0.00分/3.93分 | step: 66640 | performance: 1.0 | accuracy: 0.11 | loss: 0.11
update:1195/2000, 耗时:0.00分/3.95分 | step: 66920 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 66970 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66972 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66973 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66974 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66975 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 66976 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 67081 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 67083 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1200/2000, 耗时:0.00分/3.96分 | step: 67200 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:1205/2000, 耗时:0.00分/3.98分 | step: 67480 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
update:1210/2000, 耗时:0.00分/3.99分 | step: 67760 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 67922 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 67924 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 67925 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 67926 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 67927 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 67928 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 68033 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 68035 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1215/2000, 耗时:0.00分/4.01分 | step: 68040 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
update:1220/2000, 耗时:0.00分/4.02分 | step: 68320 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:1225/2000, 耗时:0.00分/4.04分 | step: 68600 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 68874 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 68876 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 68877 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 68878 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 68879 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 68880 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1230/2000, 耗时:0.00分/4.06分 | step: 68880 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 68985 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 68987 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1235/2000, 耗时:0.00分/4.07分 | step: 69160 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1240/2000, 耗时:0.00分/4.09分 | step: 69440 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
update:1245/2000, 耗时:0.00分/4.11分 | step: 69720 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 69826 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 69828 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 69829 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 69830 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 69831 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 69832 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 69937 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 69939 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1250/2000, 耗时:0.00分/4.12分 | step: 70000 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
update:1255/2000, 耗时:0.00分/4.14分 | step: 70280 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:1260/2000, 耗时:0.00分/4.15分 | step: 70560 | performance: 1.0 | accuracy: 0.17 | loss: 0.14
step: 70778 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 70780 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 70781 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 70782 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 70783 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 70784 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1265/2000, 耗时:0.00分/4.17分 | step: 70840 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
step: 70889 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 70891 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1270/2000, 耗时:0.00分/4.19分 | step: 71120 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:1275/2000, 耗时:0.00分/4.20分 | step: 71400 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:1280/2000, 耗时:0.00分/4.22分 | step: 71680 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 71730 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 71732 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 71733 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 71734 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 71735 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 71736 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 71841 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 71843 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1285/2000, 耗时:0.00分/4.24分 | step: 71960 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:1290/2000, 耗时:0.00分/4.25分 | step: 72240 | performance: 1.0 | accuracy: 0.08 | loss: 0.05
update:1295/2000, 耗时:0.00分/4.27分 | step: 72520 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 72682 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 72684 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 72685 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 72686 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 72687 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 72688 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 72793 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 72795 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1300/2000, 耗时:0.00分/4.28分 | step: 72800 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
update:1305/2000, 耗时:0.00分/4.30分 | step: 73080 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:1310/2000, 耗时:0.00分/4.31分 | step: 73360 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 73634 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 73636 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 73637 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 73638 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 73639 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 73640 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1315/2000, 耗时:0.00分/4.33分 | step: 73640 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 73745 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 73747 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1320/2000, 耗时:0.00分/4.34分 | step: 73920 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1325/2000, 耗时:0.00分/4.36分 | step: 74200 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1330/2000, 耗时:0.00分/4.38分 | step: 74480 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 74586 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 74588 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 74589 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 74590 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 74591 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 74592 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 74697 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 74699 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1335/2000, 耗时:0.00分/4.39分 | step: 74760 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:1340/2000, 耗时:0.00分/4.41分 | step: 75040 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:1345/2000, 耗时:0.00分/4.42分 | step: 75320 | performance: 1.0 | accuracy: 0.17 | loss: 0.14
step: 75538 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 75540 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 75541 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 75542 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 75543 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 75544 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1350/2000, 耗时:0.00分/4.44分 | step: 75600 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
step: 75649 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 75651 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1355/2000, 耗时:0.00分/4.46分 | step: 75880 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:1360/2000, 耗时:0.00分/4.47分 | step: 76160 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:1365/2000, 耗时:0.00分/4.49分 | step: 76440 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 76490 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 76492 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 76493 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 76494 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 76495 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 76496 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 76601 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 76603 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1370/2000, 耗时:0.00分/4.50分 | step: 76720 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:1375/2000, 耗时:0.00分/4.52分 | step: 77000 | performance: 1.0 | accuracy: 0.08 | loss: 0.06
update:1380/2000, 耗时:0.00分/4.54分 | step: 77280 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 77442 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 77444 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 77445 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 77446 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 77447 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 77448 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 77553 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 77555 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1385/2000, 耗时:0.00分/4.55分 | step: 77560 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
update:1390/2000, 耗时:0.00分/4.57分 | step: 77840 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:1395/2000, 耗时:0.00分/4.58分 | step: 78120 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 78394 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 78396 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 78397 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 78398 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 78399 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 78400 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1400/2000, 耗时:0.00分/4.60分 | step: 78400 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 78505 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 78507 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1405/2000, 耗时:0.00分/4.61分 | step: 78680 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1410/2000, 耗时:0.00分/4.63分 | step: 78960 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1415/2000, 耗时:0.00分/4.65分 | step: 79240 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 79346 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 79348 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 79349 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 79350 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 79351 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 79352 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 79457 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 79459 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1420/2000, 耗时:0.00分/4.66分 | step: 79520 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:1425/2000, 耗时:0.00分/4.68分 | step: 79800 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:1430/2000, 耗时:0.00分/4.69分 | step: 80080 | performance: 1.0 | accuracy: 0.17 | loss: 0.14
step: 80298 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 80300 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 80301 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 80302 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 80303 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 80304 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1435/2000, 耗时:0.00分/4.71分 | step: 80360 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
step: 80409 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 80411 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1440/2000, 耗时:0.00分/4.72分 | step: 80640 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:1445/2000, 耗时:0.00分/4.74分 | step: 80920 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:1450/2000, 耗时:0.00分/4.76分 | step: 81200 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 81250 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 81252 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 81253 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 81254 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 81255 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 81256 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 81361 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 81363 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1455/2000, 耗时:0.00分/4.77分 | step: 81480 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:1460/2000, 耗时:0.00分/4.79分 | step: 81760 | performance: 1.0 | accuracy: 0.08 | loss: 0.06
update:1465/2000, 耗时:0.00分/4.80分 | step: 82040 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 82202 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 82204 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 82205 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 82206 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 82207 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 82208 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 82313 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 82315 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1470/2000, 耗时:0.00分/4.82分 | step: 82320 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
update:1475/2000, 耗时:0.00分/4.83分 | step: 82600 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:1480/2000, 耗时:0.00分/4.85分 | step: 82880 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 83154 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 83156 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 83157 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 83158 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 83159 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 83160 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1485/2000, 耗时:0.00分/4.87分 | step: 83160 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 83265 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 83267 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1490/2000, 耗时:0.00分/4.88分 | step: 83440 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1495/2000, 耗时:0.00分/4.90分 | step: 83720 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1500/2000, 耗时:0.00分/4.92分 | step: 84000 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 84106 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 84108 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 84109 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 84110 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 84111 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 84112 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 84217 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 84219 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1505/2000, 耗时:0.00分/4.93分 | step: 84280 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:1510/2000, 耗时:0.00分/4.95分 | step: 84560 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:1515/2000, 耗时:0.00分/4.96分 | step: 84840 | performance: 1.0 | accuracy: 0.17 | loss: 0.13
step: 85058 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 85060 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 85061 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 85062 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 85063 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 85064 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1520/2000, 耗时:0.00分/4.98分 | step: 85120 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
step: 85169 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 85171 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1525/2000, 耗时:0.00分/4.99分 | step: 85400 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:1530/2000, 耗时:0.00分/5.01分 | step: 85680 | performance: 1.0 | accuracy: 0.11 | loss: 0.11
update:1535/2000, 耗时:0.00分/5.02分 | step: 85960 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 86010 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86012 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86013 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86014 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86015 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86016 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86121 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86123 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1540/2000, 耗时:0.00分/5.04分 | step: 86240 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:1545/2000, 耗时:0.00分/5.05分 | step: 86520 | performance: 1.0 | accuracy: 0.08 | loss: 0.06
update:1550/2000, 耗时:0.00分/5.07分 | step: 86800 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 86962 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86964 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86965 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86966 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86967 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 86968 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 87073 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 87075 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1555/2000, 耗时:0.00分/5.09分 | step: 87080 | performance: 1.0 | accuracy: 0.07 | loss: 0.02
update:1560/2000, 耗时:0.00分/5.10分 | step: 87360 | performance: 1.0 | accuracy: 0.07 | loss: 0.01
update:1565/2000, 耗时:0.00分/5.12分 | step: 87640 | performance: 1.0 | accuracy: 0.06 | loss: 0.01
step: 87914 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 87916 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 87917 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 87918 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 87919 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 87920 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1570/2000, 耗时:0.00分/5.13分 | step: 87920 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 88025 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 88027 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1575/2000, 耗时:0.00分/5.15分 | step: 88200 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1580/2000, 耗时:0.00分/5.16分 | step: 88480 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:1585/2000, 耗时:0.00分/5.18分 | step: 88760 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 88866 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 88868 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 88869 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 88870 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 88871 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 88872 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 88977 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 88979 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1590/2000, 耗时:0.00分/5.19分 | step: 89040 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
update:1595/2000, 耗时:0.00分/5.21分 | step: 89320 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:1600/2000, 耗时:0.00分/5.22分 | step: 89600 | performance: 1.0 | accuracy: 0.17 | loss: 0.14
step: 89818 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 89820 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 89821 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 89822 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 89823 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 89824 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1605/2000, 耗时:0.00分/5.24分 | step: 89880 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
step: 89929 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 89931 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1610/2000, 耗时:0.00分/5.25分 | step: 90160 | performance: 1.0 | accuracy: 0.12 | loss: 0.10
update:1615/2000, 耗时:0.00分/5.27分 | step: 90440 | performance: 1.0 | accuracy: 0.11 | loss: 0.10
update:1620/2000, 耗时:0.00分/5.29分 | step: 90720 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 90770 | worker_1@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 90772 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 90773 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 90774 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 90775 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 90776 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 90881 | worker_0@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 90883 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1625/2000, 耗时:0.00分/5.30分 | step: 91000 | performance: 1.0 | accuracy: 0.09 | loss: 0.08
update:1630/2000, 耗时:0.00分/5.32分 | step: 91280 | performance: 1.0 | accuracy: 0.08 | loss: 0.06
update:1635/2000, 耗时:0.00分/5.33分 | step: 91560 | performance: 1.0 | accuracy: 0.08 | loss: 0.02
step: 91726 | worker_5@n_step_6: average total_reward after train data exhaustion : 0.9 | max total_reward: 207.4
step: 91727 | worker_6@n_step_6: average total_reward after train data exhaustion : 0.9 | max total_reward: 207.4
step: 91728 | worker_7@n_step_6: average total_reward after train data exhaustion : 0.9 | max total_reward: 207.4
step: 91837 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1640/2000, 耗时:0.00分/5.35分 | step: 91840 | performance: 1.0 | accuracy: 0.14 | loss: 0.22
step: 91894 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
step: 91947 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.0 | max total_reward: 207.4
update:1645/2000, 耗时:0.00分/5.36分 | step: 92120 | performance: 1.0 | accuracy: 0.17 | loss: 0.22
update:1650/2000, 耗时:0.00分/5.38分 | step: 92400 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 92567 | worker_6@n_step_6: average total_reward after train data exhaustion : 1.1 | max total_reward: 207.4
step: 92676 | worker_3@n_step_6: average total_reward after train data exhaustion : 1.1 | max total_reward: 207.4
update:1655/2000, 耗时:0.00分/5.39分 | step: 92680 | performance: 1.0 | accuracy: 0.17 | loss: 0.11
step: 92899 | worker_2@n_step_6: average total_reward after train data exhaustion : 1.2 | max total_reward: 207.4
step: 92904 | worker_7@n_step_6: average total_reward after train data exhaustion : 1.2 | max total_reward: 207.4
step: 92958 | worker_5@n_step_6: average total_reward after train data exhaustion : 1.2 | max total_reward: 207.4
update:1660/2000, 耗时:0.00分/5.41分 | step: 92960 | performance: 1.0 | accuracy: 0.14 | loss: 0.07
step: 93013 | worker_4@n_step_6: average total_reward after train data exhaustion : 1.2 | max total_reward: 207.4
update:1665/2000, 耗时:0.00分/5.42分 | step: 93240 | performance: 1.0 | accuracy: 0.25 | loss: 0.26
update:1670/2000, 耗时:0.00分/5.44分 | step: 93520 | performance: 1.0 | accuracy: 0.16 | loss: 0.30
update:1675/2000, 耗时:0.00分/5.45分 | step: 93800 | performance: 1.0 | accuracy: 0.19 | loss: 0.15
update:1680/2000, 耗时:0.00分/5.47分 | step: 94080 | performance: 1.0 | accuracy: 0.18 | loss: 0.17
update:1685/2000, 耗时:0.00分/5.48分 | step: 94360 | performance: 1.0 | accuracy: 0.16 | loss: 0.21
update:1690/2000, 耗时:0.00分/5.50分 | step: 94640 | performance: 1.0 | accuracy: 0.13 | loss: 0.06
step: 94858 | worker_1@n_step_6: average total_reward after train data exhaustion : 2.0 | max total_reward: 207.4
update:1695/2000, 耗时:0.00分/5.52分 | step: 94920 | performance: 1.0 | accuracy: 0.12 | loss: 0.06
update:1700/2000, 耗时:0.00分/5.53分 | step: 95200 | performance: 1.0 | accuracy: 0.11 | loss: 0.06
update:1705/2000, 耗时:0.00分/5.55分 | step: 95480 | performance: 1.0 | accuracy: 0.10 | loss: 0.05
step: 95590 | worker_5@n_step_6: average total_reward after train data exhaustion : 3.6 | max total_reward: 207.4
step: 95757 | worker_4@n_step_6: average total_reward after train data exhaustion : 3.7 | max total_reward: 207.4
update:1710/2000, 耗时:0.00分/5.56分 | step: 95760 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 95810 | worker_1@n_step_6: average total_reward after train data exhaustion : 3.7 | max total_reward: 207.4
update:1715/2000, 耗时:0.00分/5.58分 | step: 96040 | performance: 1.0 | accuracy: 0.16 | loss: 0.27
update:1720/2000, 耗时:0.00分/5.59分 | step: 96320 | performance: 1.0 | accuracy: 0.20 | loss: 0.32
update:1725/2000, 耗时:0.00分/5.61分 | step: 96600 | performance: 1.0 | accuracy: 0.16 | loss: 0.60
update:1730/2000, 耗时:0.00分/5.62分 | step: 96880 | performance: 1.0 | accuracy: 0.19 | loss: 0.47
update:1735/2000, 耗时:0.00分/5.64分 | step: 97160 | performance: 0.9 | accuracy: 0.19 | loss: 0.97
update:1740/2000, 耗时:0.00分/5.65分 | step: 97440 | performance: 1.1 | accuracy: 0.23 | loss: 0.23
update:1745/2000, 耗时:0.00分/5.67分 | step: 97720 | performance: 1.2 | accuracy: 0.23 | loss: 0.60
update:1750/2000, 耗时:0.00分/5.68分 | step: 98000 | performance: 1.2 | accuracy: 0.23 | loss: 0.76
update:1755/2000, 耗时:0.00分/5.70分 | step: 98280 | performance: 1.2 | accuracy: 0.23 | loss: 1.56
update:1760/2000, 耗时:0.00分/5.72分 | step: 98560 | performance: 1.3 | accuracy: 0.25 | loss: 1.60
update:1765/2000, 耗时:0.00分/5.73分 | step: 98840 | performance: 1.2 | accuracy: 0.27 | loss: 1.05
update:1770/2000, 耗时:0.00分/5.75分 | step: 99120 | performance: 1.2 | accuracy: 0.28 | loss: 2.00
update:1775/2000, 耗时:0.00分/5.76分 | step: 99400 | performance: 1.4 | accuracy: 0.29 | loss: 0.94
update:1780/2000, 耗时:0.00分/5.78分 | step: 99680 | performance: 1.5 | accuracy: 0.31 | loss: 1.87
update:1785/2000, 耗时:0.00分/5.79分 | step: 99960 | performance: 2.1 | accuracy: 0.33 | loss: 1.01
update:1790/2000, 耗时:0.00分/5.81分 | step: 100240 | performance: 2.0 | accuracy: 0.34 | loss: 2.03
update:1795/2000, 耗时:0.00分/5.82分 | step: 100520 | performance: 2.7 | accuracy: 0.36 | loss: 2.38
update:1800/2000, 耗时:0.00分/5.84分 | step: 100800 | performance: 2.7 | accuracy: 0.37 | loss: 1.89
update:1805/2000, 耗时:0.00分/5.85分 | step: 101080 | performance: 2.2 | accuracy: 0.37 | loss: 1.45
update:1810/2000, 耗时:0.00分/5.87分 | step: 101360 | performance: 2.3 | accuracy: 0.39 | loss: 1.28
update:1815/2000, 耗时:0.00分/5.89分 | step: 101640 | performance: 2.1 | accuracy: 0.39 | loss: 0.71
update:1820/2000, 耗时:0.00分/5.90分 | step: 101920 | performance: 2.1 | accuracy: 0.40 | loss: 2.00
update:1825/2000, 耗时:0.00分/5.92分 | step: 102200 | performance: 1.6 | accuracy: 0.39 | loss: 1.59
update:1830/2000, 耗时:0.00分/5.93分 | step: 102480 | performance: 1.4 | accuracy: 0.39 | loss: 1.56
update:1835/2000, 耗时:0.00分/5.95分 | step: 102760 | performance: 1.6 | accuracy: 0.40 | loss: 1.43
update:1840/2000, 耗时:0.00分/5.96分 | step: 103040 | performance: 1.3 | accuracy: 0.40 | loss: 1.18
update:1845/2000, 耗时:0.00分/5.98分 | step: 103320 | performance: 1.2 | accuracy: 0.39 | loss: 0.88
update:1850/2000, 耗时:0.00分/5.99分 | step: 103600 | performance: 1.2 | accuracy: 0.39 | loss: 1.45
update:1855/2000, 耗时:0.00分/6.01分 | step: 103880 | performance: 1.4 | accuracy: 0.40 | loss: 1.82
update:1860/2000, 耗时:0.00分/6.02分 | step: 104160 | performance: 1.5 | accuracy: 0.41 | loss: 0.83
update:1865/2000, 耗时:0.00分/6.04分 | step: 104440 | performance: 1.5 | accuracy: 0.41 | loss: 0.59
update:1870/2000, 耗时:0.00分/6.05分 | step: 104720 | performance: 0.7 | accuracy: 0.41 | loss: 2.77
update:1875/2000, 耗时:0.00分/6.07分 | step: 105000 | performance: 0.9 | accuracy: 0.41 | loss: 1.99
update:1880/2000, 耗时:0.00分/6.09分 | step: 105280 | performance: 1.0 | accuracy: 0.42 | loss: 2.80
update:1885/2000, 耗时:0.00分/6.10分 | step: 105560 | performance: 1.1 | accuracy: 0.42 | loss: 1.98
update:1890/2000, 耗时:0.00分/6.12分 | step: 105840 | performance: 1.1 | accuracy: 0.42 | loss: 1.44
update:1895/2000, 耗时:0.00分/6.13分 | step: 106120 | performance: 1.2 | accuracy: 0.42 | loss: 1.64
update:1900/2000, 耗时:0.00分/6.15分 | step: 106400 | performance: 1.1 | accuracy: 0.42 | loss: 1.55
update:1905/2000, 耗时:0.00分/6.16分 | step: 106680 | performance: 1.0 | accuracy: 0.42 | loss: 0.76
update:1910/2000, 耗时:0.00分/6.18分 | step: 106960 | performance: 1.2 | accuracy: 0.42 | loss: 1.06
update:1915/2000, 耗时:0.00分/6.19分 | step: 107240 | performance: 1.2 | accuracy: 0.43 | loss: 0.62
update:1920/2000, 耗时:0.00分/6.21分 | step: 107520 | performance: 1.0 | accuracy: 0.43 | loss: 1.47
update:1925/2000, 耗时:0.00分/6.22分 | step: 107800 | performance: 1.0 | accuracy: 0.43 | loss: 1.46
update:1930/2000, 耗时:0.00分/6.24分 | step: 108080 | performance: 1.0 | accuracy: 0.43 | loss: 0.90
update:1935/2000, 耗时:0.00分/6.25分 | step: 108360 | performance: 1.2 | accuracy: 0.44 | loss: 0.86
update:1940/2000, 耗时:0.00分/6.27分 | step: 108640 | performance: 1.4 | accuracy: 0.44 | loss: 1.14
update:1945/2000, 耗时:0.00分/6.29分 | step: 108920 | performance: 1.6 | accuracy: 0.44 | loss: 2.15
update:1950/2000, 耗时:0.00分/6.30分 | step: 109200 | performance: 1.8 | accuracy: 0.45 | loss: 1.78
update:1955/2000, 耗时:0.00分/6.32分 | step: 109480 | performance: 2.4 | accuracy: 0.45 | loss: 2.44
update:1960/2000, 耗时:0.00分/6.33分 | step: 109760 | performance: 2.3 | accuracy: 0.45 | loss: 1.55
update:1965/2000, 耗时:0.00分/6.35分 | step: 110040 | performance: 2.9 | accuracy: 0.45 | loss: 1.19
update:1970/2000, 耗时:0.00分/6.36分 | step: 110320 | performance: 3.3 | accuracy: 0.46 | loss: 1.44
update:1975/2000, 耗时:0.00分/6.38分 | step: 110600 | performance: 3.8 | accuracy: 0.46 | loss: 1.01
update:1980/2000, 耗时:0.00分/6.39分 | step: 110880 | performance: 3.8 | accuracy: 0.46 | loss: 0.99
update:1985/2000, 耗时:0.00分/6.41分 | step: 111160 | performance: 3.6 | accuracy: 0.46 | loss: 1.26
update:1990/2000, 耗时:0.00分/6.42分 | step: 111440 | performance: 3.4 | accuracy: 0.46 | loss: 1.21
update:1995/2000, 耗时:0.00分/6.44分 | step: 111720 | performance: 2.2 | accuracy: 0.46 | loss: 1.78
  0%|          | 0/401 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/6.45分 | step: 112000 | performance: 2.1 | accuracy: 0.46 | loss: 1.35
----------------------------------------finished----------------------------------------
==================================================
2023-01-05T12:00:00 | *** START BACKTEST ***
2023-01-05T12:00:00 | current balance = 1000.00
==================================================
100%|| 401/401 [00:00<00:00, 47697.69it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1725.61
2023-07-24T12:00:00 | net performance [%] = 72.5615
2023-07-24T12:00:00 | number of trades [#] = 2
==================================================
Trial 39 Complete [00h 06m 54s]
net_wealth: 1727.3420349333471

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 05h 09m 38s

Search: Running Trial #40

Value             |Best Value So Far |Hyperparameter
2                 |7                 |horizon
365               |730               |lookback
False             |False             |MarketFactor
10                |14                |lags
0.85              |0.7               |gamma
16                |32                |batch_size
1                 |32                |n_step
0.85              |0.92              |gae_lambda
0.1               |0.1               |gradient_clip_norm
5                 |5                 |epochs
5e-05             |0.0001            |actor_lr
0.0001            |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4313.000000   4315.000000
mean      0.000441    20062.255222  ...   20125.961477  20118.633889
std       0.027818    16039.874230  ...   16077.223335  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7693.100098   7690.540039
50%       0.000642    11554.824463  ...   11733.030273  11715.610352
75%       0.011655    29873.081836  ...   29928.000000  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 03:13:01.2787579: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to2023-07-28 03:13:01.787663: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI 22D0eep Neu0ra223-l Network07 3Li buse the rafo-ry (-2l8onl 0eo07Dw3-:13:012.NN) to 7i88n7g7 u3 0s3:13:0e the023-07- 28 0folCPU ins2t: lIo 3:13:01.t7ensorr1uctio8n7flow/.core/platform/cpu_fea78ture_guar75d.9722cc:: 142I8: s]  te 2ITi0w23-07-h ti2ennss8norflow/ ocrf0o3 ps Tensoere/p:lrio13:01w./cor788elr048: I tena/platF2form/0tlowcpform/c2u_fp3-0snugeorfl2_0feaaow/2 3-t0urf7b -Core_PgmtcuiruornUa riyneaerd_ ainssgc/ optuep-.iamrlctrucact:forri142m] itcThzd2t.8i ic7-2c8eid0s3 /:142] :cwi1p tThh3ui on_f:ons Tsensin  Tpeeaenso01tAuProcarer.lF78e8_2 lI 14: ooF gIDrp0efr3at: eweoi1oten bn3s::piun a0 srd.orflow1 AVX lca.rAcoyw bN/ci7VeXu2r
T8 8:o17rno aen2rira:m al sabnNIeytc  toewelnorsko Lr-ecrfilti  ibproitshawc/aclot imoi remeope/zer y e(/pdpl in tapl1iwtitoo4n2mhf eDoN]Ntha oiezrrtfeodr wTmhnr)i tahtiism / t/T ooeoocppernnnseasuc: Atorion_uPIpu_ fse f DAFse atVhXee lee,A r efpo aVtXoNweueur2 rAalle
TPI lb_gbi outuuarroDe_Nwnideinlg C.e pe Ncd PngeuuaraTUcena brle :l1e4 2t]h edt.cTmsNoec:iwonhtr 1rias Tin4k2 Lenst]r uTihbisoFsc wto rrorthFaiTrlyo iesrkron wo pby s  einai reantrny oLpi(olibrary opser f(oornmentiiwasn omniezDeNNcDeNNdo o-cs)r wip)t Ftorii,  wt htmrithu oliozsoneAPIet ewb  Diucsutieeaeldhled  Te  bep o ai n NpetuhntsoreF faweprparl rirhlyat iisoNoetheow onprl  ws: tiloiow afteolplowwing totniniom reC Pckgi zCePAoAd  LPiI wUVbDritXh A eae VmrpyoiXp2 
NeunirlTeon Us tire rA h ntuhfesalc (eo PaNlettrunantewDorpNgckapIions N L Dinblisbtei roraroenps  ipyep.N
eenr)   (ur fiarpoenteaDottlN N)r foeN rtoeut morwcao soer ushnkc Lmep ilmiabntreeactehre -crh-flameiecrritical op fto icgsal fel opeionl .yrlolwoiwnga t
r (oneDNoinaitonstCions:  hAerN )o pt:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the age CPUrations, rebuild TensorFlow with the appropriate compiler flags.
PU instructions in performance-crppriVX AVto use the following CPU instructions in performa instructions in performanical operations:  AVX AVXncopXriate compiler flags.
2
To enable them in other operations, rebue-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate cc2
e-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
ild TensorFloTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
ompiler flags.
w with the appropriate compiler flags.
2023-07-28 03:13:02.419537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:13:02.427206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:13:02.429913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:13:02.446338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:13:02.449158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:13:02.464707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:13:02.466747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:13:02.484032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:    40 | performance: 1.0 | accuracy: 0.20 | loss: 0.55
update: 10/2000, 耗时:0.00分/0.04分 | step:    80 | performance: 0.8 | accuracy: 0.10 | loss: 0.78
update: 15/2000, 耗时:0.00分/0.05分 | step:   120 | performance: 0.7 | accuracy: 0.20 | loss: 1.30
update: 20/2000, 耗时:0.00分/0.06分 | step:   160 | performance: 0.6 | accuracy: 0.15 | loss: 0.61
update: 25/2000, 耗时:0.00分/0.07分 | step:   200 | performance: 0.7 | accuracy: 0.24 | loss: 0.38
update: 30/2000, 耗时:0.00分/0.08分 | step:   240 | performance: 0.8 | accuracy: 0.27 | loss: 0.88
update: 35/2000, 耗时:0.00分/0.09分 | step:   280 | performance: 0.7 | accuracy: 0.29 | loss: 0.36
update: 40/2000, 耗时:0.00分/0.10分 | step:   320 | performance: 0.8 | accuracy: 0.38 | loss: 0.29
update: 45/2000, 耗时:0.00分/0.11分 | step:   360 | performance: 0.9 | accuracy: 0.38 | loss: 0.34
update: 50/2000, 耗时:0.00分/0.12分 | step:   400 | performance: 0.9 | accuracy: 0.36 | loss: 0.36
update: 55/2000, 耗时:0.00分/0.13分 | step:   440 | performance: 1.0 | accuracy: 0.35 | loss: 0.37
update: 60/2000, 耗时:0.00分/0.15分 | step:   480 | performance: 1.1 | accuracy: 0.35 | loss: 0.49
update: 65/2000, 耗时:0.00分/0.16分 | step:   520 | performance: 0.9 | accuracy: 0.32 | loss: 0.71
update: 70/2000, 耗时:0.00分/0.17分 | step:   560 | performance: 0.9 | accuracy: 0.33 | loss: 0.61
update: 75/2000, 耗时:0.00分/0.18分 | step:   600 | performance: 0.8 | accuracy: 0.32 | loss: 0.49
update: 80/2000, 耗时:0.00分/0.19分 | step:   640 | performance: 0.8 | accuracy: 0.31 | loss: 0.23
update: 85/2000, 耗时:0.00分/0.20分 | step:   680 | performance: 0.9 | accuracy: 0.31 | loss: 0.38
update: 90/2000, 耗时:0.00分/0.21分 | step:   720 | performance: 0.8 | accuracy: 0.30 | loss: 0.16
update: 95/2000, 耗时:0.00分/0.23分 | step:   760 | performance: 0.8 | accuracy: 0.31 | loss: 0.20
update:100/2000, 耗时:0.00分/0.24分 | step:   800 | performance: 0.9 | accuracy: 0.30 | loss: 0.15
update:105/2000, 耗时:0.00分/0.25分 | step:   840 | performance: 0.8 | accuracy: 0.30 | loss: 0.07
update:110/2000, 耗时:0.00分/0.26分 | step:   880 | performance: 1.0 | accuracy: 0.31 | loss: 0.39
update:115/2000, 耗时:0.00分/0.27分 | step:   920 | performance: 1.0 | accuracy: 0.33 | loss: 0.23
update:120/2000, 耗时:0.00分/0.29分 | step:   960 | performance: 1.0 | accuracy: 0.33 | loss: 0.14
update:125/2000, 耗时:0.00分/0.30分 | step:  1000 | performance: 1.0 | accuracy: 0.34 | loss: 0.41
update:130/2000, 耗时:0.00分/0.31分 | step:  1040 | performance: 1.0 | accuracy: 0.32 | loss: 0.37
update:135/2000, 耗时:0.00分/0.32分 | step:  1080 | performance: 0.9 | accuracy: 0.31 | loss: 0.37
update:140/2000, 耗时:0.00分/0.33分 | step:  1120 | performance: 0.9 | accuracy: 0.30 | loss: 0.43
update:145/2000, 耗时:0.00分/0.35分 | step:  1160 | performance: 0.9 | accuracy: 0.29 | loss: 0.46
update:150/2000, 耗时:0.00分/0.36分 | step:  1200 | performance: 0.8 | accuracy: 0.29 | loss: 0.29
update:155/2000, 耗时:0.00分/0.37分 | step:  1240 | performance: 0.9 | accuracy: 0.30 | loss: 0.70
update:160/2000, 耗时:0.00分/0.38分 | step:  1280 | performance: 0.9 | accuracy: 0.30 | loss: 0.12
update:165/2000, 耗时:0.00分/0.40分 | step:  1320 | performance: 1.1 | accuracy: 0.32 | loss: 0.45
update:170/2000, 耗时:0.00分/0.41分 | step:  1360 | performance: 1.1 | accuracy: 0.32 | loss: 0.23
update:175/2000, 耗时:0.00分/0.42分 | step:  1400 | performance: 1.0 | accuracy: 0.32 | loss: 0.52
update:180/2000, 耗时:0.00分/0.43分 | step:  1440 | performance: 0.9 | accuracy: 0.32 | loss: 0.37
update:185/2000, 耗时:0.00分/0.44分 | step:  1480 | performance: 0.9 | accuracy: 0.32 | loss: 0.28
update:190/2000, 耗时:0.00分/0.46分 | step:  1520 | performance: 0.9 | accuracy: 0.32 | loss: 0.25
update:195/2000, 耗时:0.00分/0.47分 | step:  1560 | performance: 0.9 | accuracy: 0.31 | loss: 0.44
update:200/2000, 耗时:0.00分/0.48分 | step:  1600 | performance: 0.9 | accuracy: 0.30 | loss: 0.42
update:205/2000, 耗时:0.00分/0.49分 | step:  1640 | performance: 0.9 | accuracy: 0.30 | loss: 0.58
update:210/2000, 耗时:0.00分/0.51分 | step:  1680 | performance: 0.9 | accuracy: 0.31 | loss: 0.41
update:215/2000, 耗时:0.00分/0.52分 | step:  1720 | performance: 0.9 | accuracy: 0.31 | loss: 0.47
update:220/2000, 耗时:0.00分/0.53分 | step:  1760 | performance: 0.8 | accuracy: 0.30 | loss: 0.43
update:225/2000, 耗时:0.00分/0.54分 | step:  1800 | performance: 0.8 | accuracy: 0.30 | loss: 0.32
update:230/2000, 耗时:0.00分/0.55分 | step:  1840 | performance: 0.8 | accuracy: 0.30 | loss: 0.37
update:235/2000, 耗时:0.00分/0.57分 | step:  1880 | performance: 0.7 | accuracy: 0.29 | loss: 0.08
update:240/2000, 耗时:0.00分/0.58分 | step:  1920 | performance: 0.8 | accuracy: 0.30 | loss: 0.51
update:245/2000, 耗时:0.00分/0.59分 | step:  1960 | performance: 0.9 | accuracy: 0.30 | loss: 0.30
update:250/2000, 耗时:0.00分/0.60分 | step:  2000 | performance: 0.9 | accuracy: 0.30 | loss: 0.23
update:255/2000, 耗时:0.00分/0.62分 | step:  2040 | performance: 0.9 | accuracy: 0.29 | loss: 0.17
update:260/2000, 耗时:0.00分/0.63分 | step:  2080 | performance: 0.8 | accuracy: 0.29 | loss: 0.13
update:265/2000, 耗时:0.00分/0.64分 | step:  2120 | performance: 0.8 | accuracy: 0.28 | loss: 0.20
update:270/2000, 耗时:0.00分/0.65分 | step:  2160 | performance: 0.8 | accuracy: 0.28 | loss: 0.48
update:275/2000, 耗时:0.00分/0.67分 | step:  2200 | performance: 0.8 | accuracy: 0.28 | loss: 0.98
update:280/2000, 耗时:0.00分/0.68分 | step:  2240 | performance: 0.8 | accuracy: 0.29 | loss: 0.31
update:285/2000, 耗时:0.00分/0.69分 | step:  2280 | performance: 0.8 | accuracy: 0.29 | loss: 0.26
update:290/2000, 耗时:0.00分/0.70分 | step:  2320 | performance: 0.9 | accuracy: 0.29 | loss: 0.06
update:295/2000, 耗时:0.00分/0.71分 | step:  2360 | performance: 0.8 | accuracy: 0.28 | loss: 0.15
update:300/2000, 耗时:0.00分/0.73分 | step:  2400 | performance: 0.8 | accuracy: 0.28 | loss: 0.22
update:305/2000, 耗时:0.00分/0.74分 | step:  2440 | performance: 0.9 | accuracy: 0.29 | loss: 0.13
update:310/2000, 耗时:0.00分/0.75分 | step:  2480 | performance: 1.0 | accuracy: 0.29 | loss: 0.16
update:315/2000, 耗时:0.00分/0.76分 | step:  2520 | performance: 1.0 | accuracy: 0.29 | loss: 0.33
update:320/2000, 耗时:0.00分/0.78分 | step:  2560 | performance: 1.1 | accuracy: 0.29 | loss: 0.78
update:325/2000, 耗时:0.00分/0.79分 | step:  2600 | performance: 1.1 | accuracy: 0.29 | loss: 0.49
update:330/2000, 耗时:0.00分/0.80分 | step:  2640 | performance: 1.1 | accuracy: 0.29 | loss: 0.43
update:335/2000, 耗时:0.00分/0.81分 | step:  2680 | performance: 1.1 | accuracy: 0.29 | loss: 0.32
update:340/2000, 耗时:0.00分/0.82分 | step:  2720 | performance: 1.1 | accuracy: 0.29 | loss: 0.33
update:345/2000, 耗时:0.00分/0.84分 | step:  2760 | performance: 1.1 | accuracy: 0.30 | loss: 0.88
update:350/2000, 耗时:0.00分/0.85分 | step:  2800 | performance: 1.1 | accuracy: 0.30 | loss: 0.34
update:355/2000, 耗时:0.00分/0.86分 | step:  2840 | performance: 1.1 | accuracy: 0.30 | loss: 0.12
update:360/2000, 耗时:0.00分/0.87分 | step:  2880 | performance: 1.2 | accuracy: 0.31 | loss: 0.13
update:365/2000, 耗时:0.00分/0.88分 | step:  2920 | performance: 1.2 | accuracy: 0.31 | loss: 0.10
update:370/2000, 耗时:0.00分/0.89分 | step:  2960 | performance: 1.2 | accuracy: 0.31 | loss: 0.23
update:375/2000, 耗时:0.00分/0.91分 | step:  3000 | performance: 1.1 | accuracy: 0.31 | loss: 0.95
update:380/2000, 耗时:0.00分/0.92分 | step:  3040 | performance: 1.0 | accuracy: 0.31 | loss: 0.29
update:385/2000, 耗时:0.00分/0.93分 | step:  3080 | performance: 1.0 | accuracy: 0.30 | loss: 0.45
update:390/2000, 耗时:0.00分/0.94分 | step:  3120 | performance: 1.0 | accuracy: 0.30 | loss: 0.51
update:395/2000, 耗时:0.00分/0.95分 | step:  3160 | performance: 1.0 | accuracy: 0.30 | loss: 0.41
update:400/2000, 耗时:0.00分/0.97分 | step:  3200 | performance: 1.0 | accuracy: 0.30 | loss: 0.45
update:405/2000, 耗时:0.00分/0.98分 | step:  3240 | performance: 1.0 | accuracy: 0.30 | loss: 0.54
update:410/2000, 耗时:0.00分/0.99分 | step:  3280 | performance: 1.1 | accuracy: 0.30 | loss: 0.54
update:415/2000, 耗时:0.00分/1.00分 | step:  3320 | performance: 1.0 | accuracy: 0.30 | loss: 0.32
update:420/2000, 耗时:0.00分/1.01分 | step:  3360 | performance: 0.9 | accuracy: 0.30 | loss: 0.24
update:425/2000, 耗时:0.00分/1.03分 | step:  3400 | performance: 1.0 | accuracy: 0.30 | loss: 0.29
update:430/2000, 耗时:0.00分/1.04分 | step:  3440 | performance: 1.0 | accuracy: 0.30 | loss: 0.24
update:435/2000, 耗时:0.00分/1.05分 | step:  3480 | performance: 1.0 | accuracy: 0.31 | loss: 0.19
update:440/2000, 耗时:0.00分/1.06分 | step:  3520 | performance: 1.0 | accuracy: 0.31 | loss: 0.42
update:445/2000, 耗时:0.00分/1.07分 | step:  3560 | performance: 1.0 | accuracy: 0.31 | loss: 0.54
update:450/2000, 耗时:0.00分/1.08分 | step:  3600 | performance: 1.0 | accuracy: 0.31 | loss: 0.23
update:455/2000, 耗时:0.00分/1.10分 | step:  3640 | performance: 1.0 | accuracy: 0.31 | loss: 0.46
update:460/2000, 耗时:0.00分/1.11分 | step:  3680 | performance: 1.0 | accuracy: 0.31 | loss: 0.29
update:465/2000, 耗时:0.00分/1.12分 | step:  3720 | performance: 1.0 | accuracy: 0.31 | loss: 0.19
update:470/2000, 耗时:0.00分/1.13分 | step:  3760 | performance: 1.0 | accuracy: 0.31 | loss: 0.23
update:475/2000, 耗时:0.00分/1.14分 | step:  3800 | performance: 1.0 | accuracy: 0.31 | loss: 0.49
update:480/2000, 耗时:0.00分/1.16分 | step:  3840 | performance: 1.0 | accuracy: 0.31 | loss: 0.26
update:485/2000, 耗时:0.00分/1.17分 | step:  3880 | performance: 1.0 | accuracy: 0.31 | loss: 0.35
update:490/2000, 耗时:0.00分/1.18分 | step:  3920 | performance: 1.0 | accuracy: 0.31 | loss: 0.23
update:495/2000, 耗时:0.00分/1.19分 | step:  3960 | performance: 1.0 | accuracy: 0.30 | loss: 0.17
update:500/2000, 耗时:0.00分/1.20分 | step:  4000 | performance: 0.9 | accuracy: 0.30 | loss: 0.09
update:505/2000, 耗时:0.00分/1.22分 | step:  4040 | performance: 0.9 | accuracy: 0.30 | loss: 0.24
update:510/2000, 耗时:0.00分/1.23分 | step:  4080 | performance: 0.9 | accuracy: 0.30 | loss: 0.15
update:515/2000, 耗时:0.00分/1.24分 | step:  4120 | performance: 0.9 | accuracy: 0.30 | loss: 1.10
update:520/2000, 耗时:0.00分/1.25分 | step:  4160 | performance: 0.9 | accuracy: 0.31 | loss: 0.52
update:525/2000, 耗时:0.00分/1.26分 | step:  4200 | performance: 0.9 | accuracy: 0.30 | loss: 1.17
update:530/2000, 耗时:0.00分/1.27分 | step:  4240 | performance: 0.8 | accuracy: 0.30 | loss: 0.49
update:535/2000, 耗时:0.00分/1.29分 | step:  4280 | performance: 0.9 | accuracy: 0.30 | loss: 0.84
update:540/2000, 耗时:0.00分/1.30分 | step:  4320 | performance: 0.8 | accuracy: 0.31 | loss: 0.47
update:545/2000, 耗时:0.00分/1.31分 | step:  4360 | performance: 0.9 | accuracy: 0.31 | loss: 1.07
update:550/2000, 耗时:0.00分/1.32分 | step:  4400 | performance: 0.9 | accuracy: 0.31 | loss: 0.17
update:555/2000, 耗时:0.00分/1.33分 | step:  4440 | performance: 0.9 | accuracy: 0.31 | loss: 0.36
update:560/2000, 耗时:0.00分/1.35分 | step:  4480 | performance: 1.0 | accuracy: 0.31 | loss: 0.21
update:565/2000, 耗时:0.00分/1.36分 | step:  4520 | performance: 1.0 | accuracy: 0.31 | loss: -0.01
update:570/2000, 耗时:0.00分/1.37分 | step:  4560 | performance: 1.1 | accuracy: 0.31 | loss: 0.24
update:575/2000, 耗时:0.00分/1.38分 | step:  4600 | performance: 1.1 | accuracy: 0.31 | loss: 0.41
update:580/2000, 耗时:0.00分/1.39分 | step:  4640 | performance: 1.1 | accuracy: 0.31 | loss: 0.66
update:585/2000, 耗时:0.00分/1.41分 | step:  4680 | performance: 1.0 | accuracy: 0.31 | loss: 0.25
update:590/2000, 耗时:0.00分/1.42分 | step:  4720 | performance: 1.0 | accuracy: 0.31 | loss: 0.56
update:595/2000, 耗时:0.00分/1.43分 | step:  4760 | performance: 1.0 | accuracy: 0.31 | loss: 0.24
update:600/2000, 耗时:0.00分/1.44分 | step:  4800 | performance: 1.0 | accuracy: 0.30 | loss: 0.07
update:605/2000, 耗时:0.00分/1.45分 | step:  4840 | performance: 1.1 | accuracy: 0.31 | loss: 0.05
update:610/2000, 耗时:0.00分/1.47分 | step:  4880 | performance: 1.0 | accuracy: 0.30 | loss: 0.51
update:615/2000, 耗时:0.00分/1.48分 | step:  4920 | performance: 1.1 | accuracy: 0.31 | loss: 0.47
update:620/2000, 耗时:0.00分/1.49分 | step:  4960 | performance: 1.1 | accuracy: 0.30 | loss: 0.43
update:625/2000, 耗时:0.00分/1.50分 | step:  5000 | performance: 1.1 | accuracy: 0.31 | loss: 0.29
update:630/2000, 耗时:0.00分/1.51分 | step:  5040 | performance: 1.1 | accuracy: 0.31 | loss: 0.36
update:635/2000, 耗时:0.00分/1.52分 | step:  5080 | performance: 1.1 | accuracy: 0.31 | loss: 0.52
update:640/2000, 耗时:0.00分/1.54分 | step:  5120 | performance: 1.2 | accuracy: 0.31 | loss: 0.26
update:645/2000, 耗时:0.00分/1.55分 | step:  5160 | performance: 1.1 | accuracy: 0.31 | loss: 0.55
update:650/2000, 耗时:0.00分/1.56分 | step:  5200 | performance: 1.1 | accuracy: 0.31 | loss: 0.32
update:655/2000, 耗时:0.00分/1.57分 | step:  5240 | performance: 1.0 | accuracy: 0.31 | loss: 0.18
update:660/2000, 耗时:0.00分/1.58分 | step:  5280 | performance: 1.0 | accuracy: 0.31 | loss: 0.15
update:665/2000, 耗时:0.00分/1.60分 | step:  5320 | performance: 1.1 | accuracy: 0.31 | loss: 0.29
update:670/2000, 耗时:0.00分/1.61分 | step:  5360 | performance: 1.1 | accuracy: 0.31 | loss: 0.29
update:675/2000, 耗时:0.00分/1.62分 | step:  5400 | performance: 1.1 | accuracy: 0.31 | loss: 0.36
update:680/2000, 耗时:0.00分/1.63分 | step:  5440 | performance: 1.1 | accuracy: 0.31 | loss: 0.17
update:685/2000, 耗时:0.00分/1.64分 | step:  5480 | performance: 1.1 | accuracy: 0.31 | loss: 0.30
update:690/2000, 耗时:0.00分/1.66分 | step:  5520 | performance: 1.1 | accuracy: 0.31 | loss: 0.24
update:695/2000, 耗时:0.00分/1.67分 | step:  5560 | performance: 1.1 | accuracy: 0.31 | loss: 0.04
update:700/2000, 耗时:0.00分/1.68分 | step:  5600 | performance: 1.1 | accuracy: 0.31 | loss: 0.29
update:705/2000, 耗时:0.00分/1.69分 | step:  5640 | performance: 1.1 | accuracy: 0.31 | loss: 0.15
update:710/2000, 耗时:0.00分/1.70分 | step:  5680 | performance: 1.1 | accuracy: 0.31 | loss: 0.19
update:715/2000, 耗时:0.00分/1.72分 | step:  5720 | performance: 1.1 | accuracy: 0.31 | loss: 0.19
update:720/2000, 耗时:0.00分/1.73分 | step:  5760 | performance: 1.0 | accuracy: 0.32 | loss: 0.26
update:725/2000, 耗时:0.00分/1.74分 | step:  5800 | performance: 1.1 | accuracy: 0.32 | loss: 0.22
update:730/2000, 耗时:0.00分/1.75分 | step:  5840 | performance: 1.1 | accuracy: 0.32 | loss: 0.13
update:735/2000, 耗时:0.00分/1.76分 | step:  5880 | performance: 1.1 | accuracy: 0.32 | loss: 0.52
update:740/2000, 耗时:0.00分/1.78分 | step:  5920 | performance: 1.0 | accuracy: 0.32 | loss: 0.29
update:745/2000, 耗时:0.00分/1.79分 | step:  5960 | performance: 1.0 | accuracy: 0.32 | loss: 0.28
update:750/2000, 耗时:0.00分/1.80分 | step:  6000 | performance: 1.0 | accuracy: 0.32 | loss: 0.22
update:755/2000, 耗时:0.00分/1.81分 | step:  6040 | performance: 1.0 | accuracy: 0.32 | loss: 0.11
update:760/2000, 耗时:0.00分/1.82分 | step:  6080 | performance: 1.0 | accuracy: 0.32 | loss: 0.24
update:765/2000, 耗时:0.00分/1.83分 | step:  6120 | performance: 1.0 | accuracy: 0.32 | loss: 0.29
update:770/2000, 耗时:0.00分/1.85分 | step:  6160 | performance: 1.0 | accuracy: 0.32 | loss: 0.37
update:775/2000, 耗时:0.00分/1.86分 | step:  6200 | performance: 1.0 | accuracy: 0.32 | loss: 0.16
update:780/2000, 耗时:0.00分/1.87分 | step:  6240 | performance: 1.0 | accuracy: 0.32 | loss: 0.34
update:785/2000, 耗时:0.00分/1.88分 | step:  6280 | performance: 1.0 | accuracy: 0.32 | loss: 0.42
update:790/2000, 耗时:0.00分/1.90分 | step:  6320 | performance: 1.0 | accuracy: 0.32 | loss: 0.36
update:795/2000, 耗时:0.00分/1.91分 | step:  6360 | performance: 1.0 | accuracy: 0.32 | loss: 0.14
update:800/2000, 耗时:0.00分/1.92分 | step:  6400 | performance: 1.0 | accuracy: 0.32 | loss: 0.33
update:805/2000, 耗时:0.00分/1.93分 | step:  6440 | performance: 1.0 | accuracy: 0.32 | loss: 0.29
update:810/2000, 耗时:0.00分/1.94分 | step:  6480 | performance: 1.1 | accuracy: 0.32 | loss: 0.29
update:815/2000, 耗时:0.00分/1.95分 | step:  6520 | performance: 1.1 | accuracy: 0.32 | loss: 0.19
update:820/2000, 耗时:0.00分/1.96分 | step:  6560 | performance: 1.1 | accuracy: 0.32 | loss: 0.42
update:825/2000, 耗时:0.00分/1.98分 | step:  6600 | performance: 1.1 | accuracy: 0.32 | loss: 0.35
update:830/2000, 耗时:0.00分/1.99分 | step:  6640 | performance: 1.1 | accuracy: 0.32 | loss: 0.37
update:835/2000, 耗时:0.00分/2.00分 | step:  6680 | performance: 1.1 | accuracy: 0.32 | loss: 0.15
update:840/2000, 耗时:0.00分/2.01分 | step:  6720 | performance: 1.1 | accuracy: 0.32 | loss: 0.49
update:845/2000, 耗时:0.00分/2.02分 | step:  6760 | performance: 1.1 | accuracy: 0.32 | loss: 0.33
update:850/2000, 耗时:0.00分/2.03分 | step:  6800 | performance: 1.1 | accuracy: 0.32 | loss: 0.30
update:855/2000, 耗时:0.00分/2.04分 | step:  6840 | performance: 1.2 | accuracy: 0.32 | loss: 0.24
update:860/2000, 耗时:0.00分/2.06分 | step:  6880 | performance: 1.2 | accuracy: 0.32 | loss: 0.14
update:865/2000, 耗时:0.00分/2.07分 | step:  6920 | performance: 1.2 | accuracy: 0.32 | loss: 0.20
update:870/2000, 耗时:0.00分/2.08分 | step:  6960 | performance: 1.4 | accuracy: 0.32 | loss: 0.59
update:875/2000, 耗时:0.00分/2.09分 | step:  7000 | performance: 1.6 | accuracy: 0.32 | loss: 0.54
update:880/2000, 耗时:0.00分/2.10分 | step:  7040 | performance: 1.5 | accuracy: 0.32 | loss: 0.46
update:885/2000, 耗时:0.00分/2.11分 | step:  7080 | performance: 1.5 | accuracy: 0.32 | loss: 0.47
update:890/2000, 耗时:0.00分/2.12分 | step:  7120 | performance: 1.6 | accuracy: 0.32 | loss: 0.34
update:895/2000, 耗时:0.00分/2.14分 | step:  7160 | performance: 1.5 | accuracy: 0.32 | loss: 0.22
update:900/2000, 耗时:0.00分/2.15分 | step:  7200 | performance: 1.4 | accuracy: 0.32 | loss: 0.78
update:905/2000, 耗时:0.00分/2.16分 | step:  7240 | performance: 1.5 | accuracy: 0.32 | loss: 0.38
update:910/2000, 耗时:0.00分/2.17分 | step:  7280 | performance: 1.5 | accuracy: 0.32 | loss: 0.40
update:915/2000, 耗时:0.00分/2.18分 | step:  7320 | performance: 1.4 | accuracy: 0.31 | loss: 0.15
update:920/2000, 耗时:0.00分/2.19分 | step:  7360 | performance: 1.5 | accuracy: 0.31 | loss: 0.25
update:925/2000, 耗时:0.00分/2.20分 | step:  7400 | performance: 1.5 | accuracy: 0.31 | loss: 0.30
update:930/2000, 耗时:0.00分/2.21分 | step:  7440 | performance: 1.6 | accuracy: 0.31 | loss: 0.63
update:935/2000, 耗时:0.00分/2.23分 | step:  7480 | performance: 1.7 | accuracy: 0.32 | loss: 0.37
update:940/2000, 耗时:0.00分/2.24分 | step:  7520 | performance: 1.6 | accuracy: 0.31 | loss: 0.24
update:945/2000, 耗时:0.00分/2.25分 | step:  7560 | performance: 1.7 | accuracy: 0.32 | loss: 0.32
update:950/2000, 耗时:0.00分/2.26分 | step:  7600 | performance: 1.7 | accuracy: 0.32 | loss: 0.37
update:955/2000, 耗时:0.00分/2.27分 | step:  7640 | performance: 1.6 | accuracy: 0.31 | loss: 0.27
update:960/2000, 耗时:0.00分/2.28分 | step:  7680 | performance: 1.8 | accuracy: 0.32 | loss: 0.53
update:965/2000, 耗时:0.00分/2.30分 | step:  7720 | performance: 1.9 | accuracy: 0.32 | loss: 0.75
update:970/2000, 耗时:0.00分/2.31分 | step:  7760 | performance: 1.9 | accuracy: 0.32 | loss: 0.71
update:975/2000, 耗时:0.00分/2.32分 | step:  7800 | performance: 1.8 | accuracy: 0.32 | loss: 0.67
update:980/2000, 耗时:0.00分/2.33分 | step:  7840 | performance: 1.7 | accuracy: 0.31 | loss: 0.33
update:985/2000, 耗时:0.00分/2.34分 | step:  7880 | performance: 1.6 | accuracy: 0.32 | loss: 0.29
update:990/2000, 耗时:0.00分/2.35分 | step:  7920 | performance: 1.8 | accuracy: 0.32 | loss: 0.54
update:995/2000, 耗时:0.00分/2.36分 | step:  7960 | performance: 1.5 | accuracy: 0.32 | loss: 0.26
update:1000/2000, 耗时:0.00分/2.37分 | step:  8000 | performance: 1.6 | accuracy: 0.32 | loss: 0.50
update:1005/2000, 耗时:0.00分/2.39分 | step:  8040 | performance: 2.0 | accuracy: 0.32 | loss: 0.50
update:1010/2000, 耗时:0.00分/2.40分 | step:  8080 | performance: 1.8 | accuracy: 0.32 | loss: 0.62
update:1015/2000, 耗时:0.00分/2.41分 | step:  8120 | performance: 1.8 | accuracy: 0.32 | loss: 0.71
update:1020/2000, 耗时:0.00分/2.42分 | step:  8160 | performance: 1.9 | accuracy: 0.32 | loss: 0.30
update:1025/2000, 耗时:0.00分/2.43分 | step:  8200 | performance: 1.7 | accuracy: 0.32 | loss: 0.10
update:1030/2000, 耗时:0.00分/2.44分 | step:  8240 | performance: 1.7 | accuracy: 0.32 | loss: 0.57
update:1035/2000, 耗时:0.00分/2.45分 | step:  8280 | performance: 1.6 | accuracy: 0.32 | loss: 0.58
update:1040/2000, 耗时:0.00分/2.46分 | step:  8320 | performance: 1.5 | accuracy: 0.32 | loss: 0.29
update:1045/2000, 耗时:0.00分/2.47分 | step:  8360 | performance: 1.3 | accuracy: 0.32 | loss: 0.19
update:1050/2000, 耗时:0.00分/2.48分 | step:  8400 | performance: 1.3 | accuracy: 0.32 | loss: 0.30
update:1055/2000, 耗时:0.00分/2.50分 | step:  8440 | performance: 1.3 | accuracy: 0.31 | loss: 0.11
update:1060/2000, 耗时:0.00分/2.51分 | step:  8480 | performance: 1.2 | accuracy: 0.31 | loss: -0.01
update:1065/2000, 耗时:0.00分/2.52分 | step:  8520 | performance: 1.1 | accuracy: 0.31 | loss: 0.38
update:1070/2000, 耗时:0.00分/2.53分 | step:  8560 | performance: 1.1 | accuracy: 0.31 | loss: 0.65
update:1075/2000, 耗时:0.00分/2.54分 | step:  8600 | performance: 0.9 | accuracy: 0.31 | loss: 0.32
update:1080/2000, 耗时:0.00分/2.55分 | step:  8640 | performance: 0.9 | accuracy: 0.31 | loss: 0.51
update:1085/2000, 耗时:0.00分/2.56分 | step:  8680 | performance: 0.9 | accuracy: 0.31 | loss: 0.46
update:1090/2000, 耗时:0.00分/2.57分 | step:  8720 | performance: 0.9 | accuracy: 0.31 | loss: 0.44
update:1095/2000, 耗时:0.00分/2.58分 | step:  8760 | performance: 0.9 | accuracy: 0.31 | loss: 0.35
update:1100/2000, 耗时:0.00分/2.60分 | step:  8800 | performance: 1.0 | accuracy: 0.31 | loss: 0.42
update:1105/2000, 耗时:0.00分/2.61分 | step:  8840 | performance: 1.1 | accuracy: 0.31 | loss: 0.61
update:1110/2000, 耗时:0.00分/2.62分 | step:  8880 | performance: 1.0 | accuracy: 0.31 | loss: 0.18
update:1115/2000, 耗时:0.00分/2.63分 | step:  8920 | performance: 1.0 | accuracy: 0.31 | loss: 0.28
update:1120/2000, 耗时:0.00分/2.64分 | step:  8960 | performance: 1.0 | accuracy: 0.31 | loss: 0.36
update:1125/2000, 耗时:0.00分/2.65分 | step:  9000 | performance: 1.0 | accuracy: 0.31 | loss: 0.23
update:1130/2000, 耗时:0.00分/2.66分 | step:  9040 | performance: 1.0 | accuracy: 0.31 | loss: 0.23
update:1135/2000, 耗时:0.00分/2.67分 | step:  9080 | performance: 1.1 | accuracy: 0.31 | loss: 0.40
update:1140/2000, 耗时:0.00分/2.69分 | step:  9120 | performance: 1.1 | accuracy: 0.31 | loss: 0.22
update:1145/2000, 耗时:0.00分/2.70分 | step:  9160 | performance: 1.1 | accuracy: 0.31 | loss: 0.42
update:1150/2000, 耗时:0.00分/2.71分 | step:  9200 | performance: 1.0 | accuracy: 0.31 | loss: 0.22
update:1155/2000, 耗时:0.00分/2.72分 | step:  9240 | performance: 0.9 | accuracy: 0.31 | loss: 0.44
update:1160/2000, 耗时:0.00分/2.73分 | step:  9280 | performance: 0.9 | accuracy: 0.31 | loss: 0.47
update:1165/2000, 耗时:0.00分/2.74分 | step:  9320 | performance: 1.0 | accuracy: 0.31 | loss: 0.57
update:1170/2000, 耗时:0.00分/2.75分 | step:  9360 | performance: 0.9 | accuracy: 0.31 | loss: 0.07
update:1175/2000, 耗时:0.00分/2.76分 | step:  9400 | performance: 0.9 | accuracy: 0.31 | loss: 0.38
update:1180/2000, 耗时:0.00分/2.77分 | step:  9440 | performance: 0.9 | accuracy: 0.31 | loss: 0.21
update:1185/2000, 耗时:0.00分/2.79分 | step:  9480 | performance: 0.8 | accuracy: 0.31 | loss: 0.64
update:1190/2000, 耗时:0.00分/2.80分 | step:  9520 | performance: 0.9 | accuracy: 0.31 | loss: 0.26
update:1195/2000, 耗时:0.00分/2.81分 | step:  9560 | performance: 0.9 | accuracy: 0.31 | loss: 0.17
update:1200/2000, 耗时:0.00分/2.82分 | step:  9600 | performance: 0.9 | accuracy: 0.31 | loss: 0.55
update:1205/2000, 耗时:0.00分/2.83分 | step:  9640 | performance: 0.9 | accuracy: 0.31 | loss: 1.72
update:1210/2000, 耗时:0.00分/2.84分 | step:  9680 | performance: 0.8 | accuracy: 0.31 | loss: 0.53
update:1215/2000, 耗时:0.00分/2.85分 | step:  9720 | performance: 0.8 | accuracy: 0.31 | loss: 0.28
update:1220/2000, 耗时:0.00分/2.86分 | step:  9760 | performance: 0.8 | accuracy: 0.31 | loss: 0.28
update:1225/2000, 耗时:0.00分/2.87分 | step:  9800 | performance: 0.7 | accuracy: 0.31 | loss: 0.27
update:1230/2000, 耗时:0.00分/2.89分 | step:  9840 | performance: 0.8 | accuracy: 0.31 | loss: 0.16
update:1235/2000, 耗时:0.00分/2.90分 | step:  9880 | performance: 0.8 | accuracy: 0.31 | loss: 0.34
update:1240/2000, 耗时:0.00分/2.91分 | step:  9920 | performance: 0.8 | accuracy: 0.31 | loss: 0.09
update:1245/2000, 耗时:0.00分/2.92分 | step:  9960 | performance: 0.8 | accuracy: 0.31 | loss: 0.15
update:1250/2000, 耗时:0.00分/2.93分 | step: 10000 | performance: 0.8 | accuracy: 0.31 | loss: 0.45
update:1255/2000, 耗时:0.00分/2.94分 | step: 10040 | performance: 0.7 | accuracy: 0.31 | loss: 0.35
update:1260/2000, 耗时:0.00分/2.95分 | step: 10080 | performance: 0.7 | accuracy: 0.31 | loss: 0.64
update:1265/2000, 耗时:0.00分/2.96分 | step: 10120 | performance: 0.7 | accuracy: 0.31 | loss: 0.45
update:1270/2000, 耗时:0.00分/2.98分 | step: 10160 | performance: 0.7 | accuracy: 0.31 | loss: 0.66
update:1275/2000, 耗时:0.00分/2.99分 | step: 10200 | performance: 0.8 | accuracy: 0.31 | loss: 0.36
update:1280/2000, 耗时:0.00分/3.00分 | step: 10240 | performance: 0.7 | accuracy: 0.31 | loss: 0.25
update:1285/2000, 耗时:0.00分/3.01分 | step: 10280 | performance: 0.7 | accuracy: 0.31 | loss: 0.24
update:1290/2000, 耗时:0.00分/3.02分 | step: 10320 | performance: 0.7 | accuracy: 0.31 | loss: 0.18
update:1295/2000, 耗时:0.00分/3.03分 | step: 10360 | performance: 0.7 | accuracy: 0.31 | loss: 0.24
update:1300/2000, 耗时:0.00分/3.04分 | step: 10400 | performance: 0.7 | accuracy: 0.31 | loss: 0.29
update:1305/2000, 耗时:0.00分/3.06分 | step: 10440 | performance: 0.7 | accuracy: 0.32 | loss: 0.43
update:1310/2000, 耗时:0.00分/3.07分 | step: 10480 | performance: 0.7 | accuracy: 0.32 | loss: 0.61
update:1315/2000, 耗时:0.00分/3.08分 | step: 10520 | performance: 0.7 | accuracy: 0.32 | loss: 0.13
update:1320/2000, 耗时:0.00分/3.09分 | step: 10560 | performance: 0.6 | accuracy: 0.32 | loss: 0.49
update:1325/2000, 耗时:0.00分/3.10分 | step: 10600 | performance: 0.7 | accuracy: 0.32 | loss: 0.58
update:1330/2000, 耗时:0.00分/3.11分 | step: 10640 | performance: 0.7 | accuracy: 0.32 | loss: 0.31
update:1335/2000, 耗时:0.00分/3.12分 | step: 10680 | performance: 0.7 | accuracy: 0.32 | loss: 0.31
update:1340/2000, 耗时:0.00分/3.14分 | step: 10720 | performance: 0.7 | accuracy: 0.32 | loss: 0.08
update:1345/2000, 耗时:0.00分/3.15分 | step: 10760 | performance: 0.6 | accuracy: 0.32 | loss: 0.09
update:1350/2000, 耗时:0.00分/3.16分 | step: 10800 | performance: 0.6 | accuracy: 0.31 | loss: 0.38
update:1355/2000, 耗时:0.00分/3.17分 | step: 10840 | performance: 0.6 | accuracy: 0.31 | loss: 0.38
update:1360/2000, 耗时:0.00分/3.18分 | step: 10880 | performance: 0.6 | accuracy: 0.31 | loss: 0.06
update:1365/2000, 耗时:0.00分/3.19分 | step: 10920 | performance: 0.5 | accuracy: 0.31 | loss: 0.54
update:1370/2000, 耗时:0.00分/3.20分 | step: 10960 | performance: 0.6 | accuracy: 0.32 | loss: 0.47
update:1375/2000, 耗时:0.00分/3.21分 | step: 11000 | performance: 0.6 | accuracy: 0.32 | loss: 0.40
update:1380/2000, 耗时:0.00分/3.22分 | step: 11040 | performance: 0.6 | accuracy: 0.32 | loss: 0.41
update:1385/2000, 耗时:0.00分/3.24分 | step: 11080 | performance: 0.6 | accuracy: 0.32 | loss: 0.11
update:1390/2000, 耗时:0.00分/3.25分 | step: 11120 | performance: 0.6 | accuracy: 0.32 | loss: 0.22
update:1395/2000, 耗时:0.00分/3.26分 | step: 11160 | performance: 0.6 | accuracy: 0.32 | loss: 0.29
update:1400/2000, 耗时:0.00分/3.27分 | step: 11200 | performance: 0.6 | accuracy: 0.32 | loss: 0.34
update:1405/2000, 耗时:0.00分/3.28分 | step: 11240 | performance: 0.6 | accuracy: 0.32 | loss: 0.39
update:1410/2000, 耗时:0.00分/3.29分 | step: 11280 | performance: 0.6 | accuracy: 0.32 | loss: 0.26
update:1415/2000, 耗时:0.00分/3.30分 | step: 11320 | performance: 0.6 | accuracy: 0.32 | loss: 0.05
update:1420/2000, 耗时:0.00分/3.31分 | step: 11360 | performance: 0.6 | accuracy: 0.32 | loss: 0.30
update:1425/2000, 耗时:0.00分/3.33分 | step: 11400 | performance: 0.5 | accuracy: 0.32 | loss: 0.27
update:1430/2000, 耗时:0.00分/3.34分 | step: 11440 | performance: 0.6 | accuracy: 0.32 | loss: 0.38
update:1435/2000, 耗时:0.00分/3.35分 | step: 11480 | performance: 0.6 | accuracy: 0.31 | loss: 0.44
update:1440/2000, 耗时:0.00分/3.36分 | step: 11520 | performance: 0.5 | accuracy: 0.31 | loss: 0.10
update:1445/2000, 耗时:0.00分/3.37分 | step: 11560 | performance: 0.5 | accuracy: 0.31 | loss: 0.57
update:1450/2000, 耗时:0.00分/3.38分 | step: 11600 | performance: 0.4 | accuracy: 0.31 | loss: 0.51
update:1455/2000, 耗时:0.00分/3.39分 | step: 11640 | performance: 0.5 | accuracy: 0.32 | loss: 0.38
update:1460/2000, 耗时:0.00分/3.41分 | step: 11680 | performance: 0.5 | accuracy: 0.32 | loss: 0.13
update:1465/2000, 耗时:0.00分/3.42分 | step: 11720 | performance: 0.4 | accuracy: 0.32 | loss: 0.56
update:1470/2000, 耗时:0.00分/3.43分 | step: 11760 | performance: 0.4 | accuracy: 0.32 | loss: 0.28
update:1475/2000, 耗时:0.00分/3.44分 | step: 11800 | performance: 0.4 | accuracy: 0.31 | loss: 0.76
update:1480/2000, 耗时:0.00分/3.45分 | step: 11840 | performance: 0.4 | accuracy: 0.31 | loss: 0.18
update:1485/2000, 耗时:0.00分/3.46分 | step: 11880 | performance: 0.5 | accuracy: 0.32 | loss: 0.45
update:1490/2000, 耗时:0.00分/3.47分 | step: 11920 | performance: 0.6 | accuracy: 0.31 | loss: 0.11
update:1495/2000, 耗时:0.00分/3.48分 | step: 11960 | performance: 0.5 | accuracy: 0.31 | loss: 0.45
update:1500/2000, 耗时:0.00分/3.50分 | step: 12000 | performance: 0.5 | accuracy: 0.31 | loss: 0.33
update:1505/2000, 耗时:0.00分/3.51分 | step: 12040 | performance: 0.4 | accuracy: 0.31 | loss: 0.87
update:1510/2000, 耗时:0.00分/3.52分 | step: 12080 | performance: 0.4 | accuracy: 0.31 | loss: 0.28
update:1515/2000, 耗时:0.00分/3.53分 | step: 12120 | performance: 0.4 | accuracy: 0.31 | loss: 0.22
update:1520/2000, 耗时:0.00分/3.54分 | step: 12160 | performance: 0.4 | accuracy: 0.31 | loss: 0.08
update:1525/2000, 耗时:0.00分/3.55分 | step: 12200 | performance: 0.3 | accuracy: 0.31 | loss: 0.13
update:1530/2000, 耗时:0.00分/3.56分 | step: 12240 | performance: 0.4 | accuracy: 0.31 | loss: 0.29
update:1535/2000, 耗时:0.00分/3.57分 | step: 12280 | performance: 0.4 | accuracy: 0.31 | loss: 0.35
update:1540/2000, 耗时:0.00分/3.59分 | step: 12320 | performance: 0.4 | accuracy: 0.31 | loss: 0.40
update:1545/2000, 耗时:0.00分/3.60分 | step: 12360 | performance: 0.4 | accuracy: 0.31 | loss: 0.32
update:1550/2000, 耗时:0.00分/3.61分 | step: 12400 | performance: 0.4 | accuracy: 0.31 | loss: 0.47
update:1555/2000, 耗时:0.00分/3.62分 | step: 12440 | performance: 0.4 | accuracy: 0.31 | loss: 0.32
update:1560/2000, 耗时:0.00分/3.63分 | step: 12480 | performance: 0.5 | accuracy: 0.32 | loss: 0.63
update:1565/2000, 耗时:0.00分/3.64分 | step: 12520 | performance: 0.5 | accuracy: 0.32 | loss: 0.37
update:1570/2000, 耗时:0.00分/3.65分 | step: 12560 | performance: 0.5 | accuracy: 0.31 | loss: 0.36
update:1575/2000, 耗时:0.00分/3.66分 | step: 12600 | performance: 0.5 | accuracy: 0.31 | loss: 0.34
update:1580/2000, 耗时:0.00分/3.68分 | step: 12640 | performance: 0.4 | accuracy: 0.31 | loss: 0.17
update:1585/2000, 耗时:0.00分/3.69分 | step: 12680 | performance: 0.4 | accuracy: 0.31 | loss: 0.48
update:1590/2000, 耗时:0.00分/3.70分 | step: 12720 | performance: 0.5 | accuracy: 0.32 | loss: 0.32
update:1595/2000, 耗时:0.00分/3.71分 | step: 12760 | performance: 0.5 | accuracy: 0.31 | loss: 0.54
update:1600/2000, 耗时:0.00分/3.72分 | step: 12800 | performance: 0.4 | accuracy: 0.31 | loss: 0.46
update:1605/2000, 耗时:0.00分/3.73分 | step: 12840 | performance: 0.4 | accuracy: 0.31 | loss: 0.54
update:1610/2000, 耗时:0.00分/3.74分 | step: 12880 | performance: 0.4 | accuracy: 0.31 | loss: 0.37
update:1615/2000, 耗时:0.00分/3.75分 | step: 12920 | performance: 0.4 | accuracy: 0.31 | loss: 0.27
update:1620/2000, 耗时:0.00分/3.77分 | step: 12960 | performance: 0.4 | accuracy: 0.31 | loss: 0.34
update:1625/2000, 耗时:0.00分/3.78分 | step: 13000 | performance: 0.4 | accuracy: 0.31 | loss: 0.11
update:1630/2000, 耗时:0.00分/3.79分 | step: 13040 | performance: 0.4 | accuracy: 0.31 | loss: 0.51
update:1635/2000, 耗时:0.00分/3.80分 | step: 13080 | performance: 0.4 | accuracy: 0.31 | loss: 0.28
update:1640/2000, 耗时:0.00分/3.81分 | step: 13120 | performance: 0.5 | accuracy: 0.31 | loss: 0.29
update:1645/2000, 耗时:0.00分/3.82分 | step: 13160 | performance: 0.5 | accuracy: 0.31 | loss: 0.52
update:1650/2000, 耗时:0.00分/3.83分 | step: 13200 | performance: 0.5 | accuracy: 0.31 | loss: 0.40
update:1655/2000, 耗时:0.00分/3.85分 | step: 13240 | performance: 0.5 | accuracy: 0.31 | loss: 0.13
update:1660/2000, 耗时:0.00分/3.86分 | step: 13280 | performance: 0.5 | accuracy: 0.31 | loss: 0.03
update:1665/2000, 耗时:0.00分/3.87分 | step: 13320 | performance: 0.5 | accuracy: 0.31 | loss: 0.31
update:1670/2000, 耗时:0.00分/3.88分 | step: 13360 | performance: 0.5 | accuracy: 0.31 | loss: 0.31
update:1675/2000, 耗时:0.00分/3.89分 | step: 13400 | performance: 0.6 | accuracy: 0.31 | loss: 0.25
update:1680/2000, 耗时:0.00分/3.90分 | step: 13440 | performance: 0.6 | accuracy: 0.31 | loss: 0.29
update:1685/2000, 耗时:0.00分/3.91分 | step: 13480 | performance: 0.6 | accuracy: 0.31 | loss: 0.53
update:1690/2000, 耗时:0.00分/3.93分 | step: 13520 | performance: 0.6 | accuracy: 0.31 | loss: 0.48
update:1695/2000, 耗时:0.00分/3.94分 | step: 13560 | performance: 0.6 | accuracy: 0.31 | loss: 0.35
update:1700/2000, 耗时:0.00分/3.95分 | step: 13600 | performance: 0.6 | accuracy: 0.31 | loss: 0.29
update:1705/2000, 耗时:0.00分/3.96分 | step: 13640 | performance: 0.6 | accuracy: 0.31 | loss: 0.36
update:1710/2000, 耗时:0.00分/3.97分 | step: 13680 | performance: 0.6 | accuracy: 0.31 | loss: 0.52
update:1715/2000, 耗时:0.00分/3.98分 | step: 13720 | performance: 0.6 | accuracy: 0.31 | loss: 0.16
update:1720/2000, 耗时:0.00分/4.00分 | step: 13760 | performance: 0.6 | accuracy: 0.31 | loss: 0.37
update:1725/2000, 耗时:0.00分/4.01分 | step: 13800 | performance: 0.6 | accuracy: 0.31 | loss: 0.31
update:1730/2000, 耗时:0.00分/4.02分 | step: 13840 | performance: 0.6 | accuracy: 0.31 | loss: 0.11
update:1735/2000, 耗时:0.00分/4.03分 | step: 13880 | performance: 0.6 | accuracy: 0.31 | loss: 0.31
update:1740/2000, 耗时:0.00分/4.04分 | step: 13920 | performance: 0.6 | accuracy: 0.31 | loss: 0.36
update:1745/2000, 耗时:0.00分/4.05分 | step: 13960 | performance: 0.6 | accuracy: 0.31 | loss: 0.14
update:1750/2000, 耗时:0.00分/4.06分 | step: 14000 | performance: 0.6 | accuracy: 0.31 | loss: 0.39
update:1755/2000, 耗时:0.00分/4.07分 | step: 14040 | performance: 0.6 | accuracy: 0.31 | loss: 0.22
update:1760/2000, 耗时:0.00分/4.09分 | step: 14080 | performance: 0.6 | accuracy: 0.31 | loss: 0.37
update:1765/2000, 耗时:0.00分/4.10分 | step: 14120 | performance: 0.7 | accuracy: 0.31 | loss: 0.65
update:1770/2000, 耗时:0.00分/4.11分 | step: 14160 | performance: 0.6 | accuracy: 0.31 | loss: 0.23
update:1775/2000, 耗时:0.00分/4.12分 | step: 14200 | performance: 0.7 | accuracy: 0.31 | loss: 0.19
update:1780/2000, 耗时:0.00分/4.13分 | step: 14240 | performance: 0.7 | accuracy: 0.31 | loss: 0.10
update:1785/2000, 耗时:0.00分/4.14分 | step: 14280 | performance: 0.7 | accuracy: 0.32 | loss: 0.13
update:1790/2000, 耗时:0.00分/4.15分 | step: 14320 | performance: 0.6 | accuracy: 0.31 | loss: 0.34
update:1795/2000, 耗时:0.00分/4.16分 | step: 14360 | performance: 0.7 | accuracy: 0.32 | loss: 0.39
update:1800/2000, 耗时:0.00分/4.17分 | step: 14400 | performance: 0.6 | accuracy: 0.32 | loss: 0.55
update:1805/2000, 耗时:0.00分/4.19分 | step: 14440 | performance: 0.7 | accuracy: 0.32 | loss: 0.17
update:1810/2000, 耗时:0.00分/4.20分 | step: 14480 | performance: 0.7 | accuracy: 0.32 | loss: 0.22
update:1815/2000, 耗时:0.00分/4.21分 | step: 14520 | performance: 0.7 | accuracy: 0.32 | loss: 0.40
update:1820/2000, 耗时:0.00分/4.22分 | step: 14560 | performance: 0.7 | accuracy: 0.32 | loss: 0.52
update:1825/2000, 耗时:0.00分/4.23分 | step: 14600 | performance: 0.7 | accuracy: 0.32 | loss: 0.18
update:1830/2000, 耗时:0.00分/4.24分 | step: 14640 | performance: 0.7 | accuracy: 0.32 | loss: 0.52
update:1835/2000, 耗时:0.00分/4.26分 | step: 14680 | performance: 0.8 | accuracy: 0.32 | loss: 0.32
update:1840/2000, 耗时:0.00分/4.27分 | step: 14720 | performance: 0.8 | accuracy: 0.32 | loss: 0.26
update:1845/2000, 耗时:0.00分/4.28分 | step: 14760 | performance: 0.9 | accuracy: 0.32 | loss: 0.33
update:1850/2000, 耗时:0.00分/4.29分 | step: 14800 | performance: 0.9 | accuracy: 0.32 | loss: 0.27
update:1855/2000, 耗时:0.00分/4.30分 | step: 14840 | performance: 0.9 | accuracy: 0.32 | loss: 0.52
update:1860/2000, 耗时:0.00分/4.31分 | step: 14880 | performance: 0.9 | accuracy: 0.32 | loss: 0.26
update:1865/2000, 耗时:0.00分/4.32分 | step: 14920 | performance: 0.9 | accuracy: 0.32 | loss: 0.42
update:1870/2000, 耗时:0.00分/4.34分 | step: 14960 | performance: 0.8 | accuracy: 0.32 | loss: 0.48
update:1875/2000, 耗时:0.00分/4.35分 | step: 15000 | performance: 0.9 | accuracy: 0.32 | loss: 0.44
update:1880/2000, 耗时:0.00分/4.36分 | step: 15040 | performance: 0.9 | accuracy: 0.32 | loss: 0.29
update:1885/2000, 耗时:0.00分/4.37分 | step: 15080 | performance: 1.0 | accuracy: 0.32 | loss: 0.38
update:1890/2000, 耗时:0.00分/4.38分 | step: 15120 | performance: 1.0 | accuracy: 0.32 | loss: 0.25
update:1895/2000, 耗时:0.00分/4.39分 | step: 15160 | performance: 1.0 | accuracy: 0.32 | loss: 0.32
update:1900/2000, 耗时:0.00分/4.40分 | step: 15200 | performance: 0.9 | accuracy: 0.32 | loss: 0.40
update:1905/2000, 耗时:0.00分/4.42分 | step: 15240 | performance: 1.0 | accuracy: 0.32 | loss: 0.28
update:1910/2000, 耗时:0.00分/4.43分 | step: 15280 | performance: 0.9 | accuracy: 0.32 | loss: 0.40
update:1915/2000, 耗时:0.00分/4.44分 | step: 15320 | performance: 0.9 | accuracy: 0.32 | loss: 0.43
update:1920/2000, 耗时:0.00分/4.45分 | step: 15360 | performance: 0.9 | accuracy: 0.32 | loss: 0.44
update:1925/2000, 耗时:0.00分/4.46分 | step: 15400 | performance: 0.8 | accuracy: 0.32 | loss: 0.60
update:1930/2000, 耗时:0.00分/4.47分 | step: 15440 | performance: 0.9 | accuracy: 0.32 | loss: 0.30
update:1935/2000, 耗时:0.00分/4.49分 | step: 15480 | performance: 0.8 | accuracy: 0.32 | loss: 0.30
update:1940/2000, 耗时:0.00分/4.50分 | step: 15520 | performance: 0.9 | accuracy: 0.32 | loss: 0.65
update:1945/2000, 耗时:0.00分/4.51分 | step: 15560 | performance: 0.9 | accuracy: 0.32 | loss: 0.22
update:1950/2000, 耗时:0.00分/4.52分 | step: 15600 | performance: 0.8 | accuracy: 0.32 | loss: 0.30
update:1955/2000, 耗时:0.00分/4.53分 | step: 15640 | performance: 0.9 | accuracy: 0.32 | loss: 0.47
update:1960/2000, 耗时:0.00分/4.54分 | step: 15680 | performance: 0.9 | accuracy: 0.32 | loss: 0.08
update:1965/2000, 耗时:0.00分/4.56分 | step: 15720 | performance: 0.8 | accuracy: 0.32 | loss: 0.26
update:1970/2000, 耗时:0.00分/4.57分 | step: 15760 | performance: 0.8 | accuracy: 0.32 | loss: 0.22
update:1975/2000, 耗时:0.00分/4.58分 | step: 15800 | performance: 0.8 | accuracy: 0.32 | loss: 0.53
update:1980/2000, 耗时:0.00分/4.59分 | step: 15840 | performance: 0.8 | accuracy: 0.32 | loss: 0.37
update:1985/2000, 耗时:0.00分/4.60分 | step: 15880 | performance: 0.8 | accuracy: 0.32 | loss: 0.40
update:1990/2000, 耗时:0.00分/4.61分 | step: 15920 | performance: 0.8 | accuracy: 0.32 | loss: 0.25
update:1995/2000, 耗时:0.00分/4.62分 | step: 15960 | performance: 0.8 | accuracy: 0.32 | loss: 0.41
  0%|          | 0/401 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/4.64分 | step: 16000 | performance: 0.7 | accuracy: 0.32 | loss: 0.79
----------------------------------------finished----------------------------------------
100%|| 401/401 [00:00<00:00, 138726.16it/s]
==================================================
2023-01-05T12:00:00 | *** START BACKTEST ***
2023-01-05T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1208.65
2023-07-24T12:00:00 | net performance [%] = 20.8650
2023-07-24T12:00:00 | number of trades [#] = 136
==================================================
Trial 40 Complete [00h 05m 05s]
net_wealth: 1208.6501330448555

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 05h 14m 43s

Search: Running Trial #41

Value             |Best Value So Far |Hyperparameter
5                 |7                 |horizon
365               |730               |lookback
False             |False             |MarketFactor
5                 |14                |lags
0.95              |0.7               |gamma
32                |32                |batch_size
20                |32                |n_step
0.85              |0.92              |gae_lambda
5                 |0.1               |gradient_clip_norm
5                 |5                 |epochs
0.0005            |0.0001            |actor_lr
1e-05             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4310.000000   4315.000000
mean      0.000441    20062.255222  ...   20136.939364  20118.633889
std       0.027818    16039.874230  ...   16077.430342  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7696.969971   7690.540039
50%       0.000642    11554.824463  ...   11742.710449  11715.610352
75%       0.011655    29873.081836  ...   29945.211914  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 03:18:06.722136: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in 2202022033-07--07-228p 03:18:206.722140:er 3-0fI7 -te2on8sorfrma ln0oc3w/c20e-ocreriti/:18plat:cfaolr 0moperation/cp6s.2722135: I 0u2_8 03f2eattensorflow/core/platform/cpu_featu3-0r:  AVX AVX2
To enable them eu_gin other ouaper:18d.:06crac.:tio713ns, rebuild -4027] This Ten7-s-28re2_orFlow g280 2303:18:06.7bua22r2361: I0idnary is o2.3p-T tensor0cc:t71-428fliomei 032nsorFlwzoe:w ]/wc-d o 10rw2i82233::e7t h  0/I -opit238lnha:t tefthe1A8PI :0oe6n. 7ap0Dee2p2  360N3:rpr.m/118:oT7cps0: hI0pur_2 6fi.s2 T57i2ean9tteen2e:a tIu2 sor5r6e7cf :t I_lgoue atred.nw/ccsorore/npslactofr:foemufploslow/1ooroarlf lwNe/crioleFr rromctflewolr//copu_aprlka fgesetfa./Lpiloarotwu/re_
cmw4tform/o/re cpbrag/u2]up_f eaarbilnatarrdf.ocy itury (orm/esc:14 Tc_2cguardohpiupt_]fe.cpa iTmhiticz:u1r4ees_ guTd2 ]wia Thru_eid.fnsstch on ocsTre :TeAePI aenD142entssFuorre_geFp NullaordorFle.oww b ibnuraacroinary w yicb s:14i ]ina s optiorTmptimized with oneAPI Deep Neural Network Library (oneDNN) to use theiy h2is opl  zfed with] ToisNllowie h tiTtng wneDorkm iLziiNbCPU instructions irNaeensosr Te) to uFrnylsorFo wo nblo(eAoinary iPneDNNsI  noptimD) tosd perfiozeed wirepmet u an thwce-cr itiw se tih ohetcanleAb opPe eI hNienary is oufforrollo Deep Neural Network Libralptimlwialonwir Network Library (oneDNN) to  use yoneAPI gn g  CDPiCPze(do nUw ieDNN) thiUttnosh eetatu efoprsi ll euon Neuo nerowins:  APctatlh ginst CPeNetw following CPU instructions in performance-critical opeorructionsUrations Ak LibViXon :i AVX2s
 ii Tnn o eA  nVppaXeerformance-crfobIr AiVt lXe rmtarDenshiep Nenemtc2
Tora riuccyaule- tn other (raocri oper ila pNeertwootaitcneetaDNN) oions, rrknnltes  abou ilLiiuble thse dt bienhonT rpeesn:so r fAVaeryro  X(onerFDf mloaolNwA nNlVwXc)2i
oTet h to o-cth e rwii me anpgunopaesetpble rrth ini coaaet l mChPothteieU rfoop i  pinopolnrenesrtiaat ioolorruatntwsis, c:ttie compiler flagshi o oAnes rrVebn.X
ig   Cn poAVXpPU eera2ins
rfttriTo oucronsemnaa,btlnce- ecritical operations:  AVirn s:Xo nethebuilmds T iuild nT  A ensoe Ain performaVonVXrs AXoFrVX2loFlow
2
Tow  enablw wiToeth t thenitce-crm in other operationshth eheit, rt apichre aa ebuild TopeenlrpapsrotpiornFs,rl op roewe narb oiapbelrawte compiliett them oheions:  AVr fp tX AlrViXatagshe2.
 comp
Tiuild Teiolen nsorFlow  wenorthither a opee  falpratbptagslionsreh e tappr,o rebuild Tenshoem in other operapro.iate cptr
Fiolrompileiow ans, rebuild te compiler flags.
TensorFlow wr flags.
with the appropriatith te chompiler flags.
e appropriate compiler flags.
2023-07-28 03:18:07.316238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:18:07.325354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:18:07.335470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:18:07.356887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:18:07.360780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:18:07.362300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:18:07.369982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:18:07.398374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.04分 | step:   800 | performance: 0.3 | accuracy: 0.33 | loss: 1.95
update: 10/2000, 耗时:0.00分/0.06分 | step:  1600 | performance: 0.1 | accuracy: 0.31 | loss: 1.21
update: 15/2000, 耗时:0.00分/0.08分 | step:  2400 | performance: 0.3 | accuracy: 0.35 | loss: 1.25
update: 20/2000, 耗时:0.00分/0.10分 | step:  3200 | performance: 0.3 | accuracy: 0.37 | loss: 1.73
update: 25/2000, 耗时:0.00分/0.12分 | step:  4000 | performance: 0.4 | accuracy: 0.36 | loss: 1.42
update: 30/2000, 耗时:0.00分/0.15分 | step:  4800 | performance: 0.6 | accuracy: 0.39 | loss: 7.35
update: 35/2000, 耗时:0.00分/0.17分 | step:  5600 | performance: 0.8 | accuracy: 0.41 | loss: 1.92
update: 40/2000, 耗时:0.00分/0.20分 | step:  6400 | performance: 0.4 | accuracy: 0.40 | loss: 2.86
update: 45/2000, 耗时:0.00分/0.22分 | step:  7200 | performance: 0.7 | accuracy: 0.40 | loss: 2.22
update: 50/2000, 耗时:0.00分/0.25分 | step:  8000 | performance: 1.3 | accuracy: 0.39 | loss: 4.78
update: 55/2000, 耗时:0.01分/0.27分 | step:  8800 | performance: 0.6 | accuracy: 0.38 | loss: 1.14
update: 60/2000, 耗时:0.00分/0.30分 | step:  9600 | performance: 0.9 | accuracy: 0.38 | loss: 1.82
update: 65/2000, 耗时:0.00分/0.32分 | step: 10400 | performance: 0.6 | accuracy: 0.38 | loss: 2.72
update: 70/2000, 耗时:0.00分/0.35分 | step: 11200 | performance: 0.2 | accuracy: 0.38 | loss: 1.39
update: 75/2000, 耗时:0.01分/0.37分 | step: 12000 | performance: 0.1 | accuracy: 0.37 | loss: 5.88
update: 80/2000, 耗时:0.01分/0.40分 | step: 12800 | performance: 0.1 | accuracy: 0.36 | loss: 1.75
update: 85/2000, 耗时:0.01分/0.42分 | step: 13600 | performance: 0.0 | accuracy: 0.36 | loss: 1.48
update: 90/2000, 耗时:0.01分/0.45分 | step: 14400 | performance: 0.1 | accuracy: 0.36 | loss: 1.09
update: 95/2000, 耗时:0.01分/0.47分 | step: 15200 | performance: 0.0 | accuracy: 0.36 | loss: 1.23
update:100/2000, 耗时:0.00分/0.50分 | step: 16000 | performance: 0.6 | accuracy: 0.37 | loss: 9.58
update:105/2000, 耗时:0.00分/0.52分 | step: 16800 | performance: 15.4 | accuracy: 0.39 | loss: 7.92
update:110/2000, 耗时:0.01分/0.55分 | step: 17600 | performance: 59.6 | accuracy: 0.40 | loss: 4.45
update:115/2000, 耗时:0.01分/0.57分 | step: 18400 | performance: 53.0 | accuracy: 0.40 | loss: 12.24
update:120/2000, 耗时:0.01分/0.60分 | step: 19200 | performance: 10.4 | accuracy: 0.40 | loss: 4.33
update:125/2000, 耗时:0.00分/0.62分 | step: 20000 | performance: 7.0 | accuracy: 0.40 | loss: 3.32
update:130/2000, 耗时:0.01分/0.65分 | step: 20800 | performance: 9.0 | accuracy: 0.40 | loss: 4.00
update:135/2000, 耗时:0.01分/0.68分 | step: 21600 | performance: 66.9 | accuracy: 0.41 | loss: 3.42
update:140/2000, 耗时:0.01分/0.70分 | step: 22400 | performance: 11.9 | accuracy: 0.41 | loss: 6.45
update:145/2000, 耗时:0.01分/0.73分 | step: 23200 | performance: 6.2 | accuracy: 0.41 | loss: 2.31
update:150/2000, 耗时:0.01分/0.76分 | step: 24000 | performance: 4.6 | accuracy: 0.41 | loss: 4.92
update:155/2000, 耗时:0.01分/0.78分 | step: 24800 | performance: 0.9 | accuracy: 0.40 | loss: 1.29
update:160/2000, 耗时:0.01分/0.81分 | step: 25600 | performance: 0.4 | accuracy: 0.40 | loss: 1.37
update:165/2000, 耗时:0.01分/0.83分 | step: 26400 | performance: 0.3 | accuracy: 0.39 | loss: 0.63
update:170/2000, 耗时:0.01分/0.86分 | step: 27200 | performance: 0.3 | accuracy: 0.39 | loss: 0.83
update:175/2000, 耗时:0.01分/0.88分 | step: 28000 | performance: 0.5 | accuracy: 0.39 | loss: 0.54
Saving PPO weights in both H5 format and checkpoint @ update:177 
update:180/2000, 耗时:0.00分/0.91分 | step: 28800 | performance: 0.7 | accuracy: 0.35 | loss: 0.78
update:185/2000, 耗时:0.00分/0.94分 | step: 29600 | performance: 0.7 | accuracy: 0.29 | loss: 0.82
update:190/2000, 耗时:0.01分/0.96分 | step: 30400 | performance: 0.7 | accuracy: 0.24 | loss: 1.24
update:195/2000, 耗时:0.01分/0.99分 | step: 31200 | performance: 0.9 | accuracy: 0.23 | loss: 1.36
update:200/2000, 耗时:0.01分/1.01分 | step: 32000 | performance: 0.9 | accuracy: 0.22 | loss: 0.64
update:205/2000, 耗时:0.00分/1.04分 | step: 32800 | performance: 2.2 | accuracy: 0.22 | loss: 3.30
update:210/2000, 耗时:0.01分/1.06分 | step: 33600 | performance: 2.0 | accuracy: 0.23 | loss: 0.79
update:215/2000, 耗时:0.01分/1.09分 | step: 34400 | performance: 1.3 | accuracy: 0.23 | loss: 0.63
update:220/2000, 耗时:0.00分/1.11分 | step: 35200 | performance: 2.3 | accuracy: 0.24 | loss: 2.58
update:225/2000, 耗时:0.01分/1.14分 | step: 36000 | performance: 58.5 | accuracy: 0.29 | loss: 12.14
update:230/2000, 耗时:0.01分/1.17分 | step: 36800 | performance: 34.8 | accuracy: 0.30 | loss: 5.92
update:235/2000, 耗时:0.01分/1.19分 | step: 37600 | performance: 32.1 | accuracy: 0.31 | loss: 1.97
update:240/2000, 耗时:0.01分/1.22分 | step: 38400 | performance: 26.3 | accuracy: 0.30 | loss: 0.96
update:245/2000, 耗时:0.01分/1.24分 | step: 39200 | performance: 32.5 | accuracy: 0.29 | loss: 0.48
update:250/2000, 耗时:0.00分/1.27分 | step: 40000 | performance: 22.6 | accuracy: 0.29 | loss: 4.81
update:255/2000, 耗时:0.01分/1.29分 | step: 40800 | performance: 13.2 | accuracy: 0.28 | loss: 0.21
update:260/2000, 耗时:0.01分/1.32分 | step: 41600 | performance: 12.0 | accuracy: 0.28 | loss: 1.39
update:265/2000, 耗时:0.00分/1.34分 | step: 42400 | performance: 10.3 | accuracy: 0.28 | loss: 1.38
update:270/2000, 耗时:0.01分/1.37分 | step: 43200 | performance: 7.2 | accuracy: 0.29 | loss: 2.06
update:275/2000, 耗时:0.00分/1.39分 | step: 44000 | performance: 24.8 | accuracy: 0.30 | loss: 4.45
update:280/2000, 耗时:0.00分/1.42分 | step: 44800 | performance: 287.3 | accuracy: 0.32 | loss: 7.32
update:285/2000, 耗时:0.00分/1.44分 | step: 45600 | performance: 5905.6 | accuracy: 0.34 | loss: 13.76
update:290/2000, 耗时:0.00分/1.47分 | step: 46400 | performance: 14584.4 | accuracy: 0.35 | loss: 4.64
update:295/2000, 耗时:0.01分/1.49分 | step: 47200 | performance: 4087.8 | accuracy: 0.35 | loss: 4.04
update:300/2000, 耗时:0.00分/1.52分 | step: 48000 | performance: 4708.7 | accuracy: 0.34 | loss: 0.04
update:305/2000, 耗时:0.00分/1.54分 | step: 48800 | performance: 5659.2 | accuracy: 0.33 | loss: 1.07
update:310/2000, 耗时:0.01分/1.57分 | step: 49600 | performance: 13430.3 | accuracy: 0.33 | loss: 6.40
update:315/2000, 耗时:0.01分/1.59分 | step: 50400 | performance: 4797.8 | accuracy: 0.33 | loss: 3.93
update:320/2000, 耗时:0.01分/1.62分 | step: 51200 | performance: 4008.9 | accuracy: 0.32 | loss: 0.24
update:325/2000, 耗时:0.00分/1.64分 | step: 52000 | performance: 3856.8 | accuracy: 0.31 | loss: 0.12
update:330/2000, 耗时:0.01分/1.67分 | step: 52800 | performance: 3028.7 | accuracy: 0.30 | loss: 0.14
update:335/2000, 耗时:0.00分/1.69分 | step: 53600 | performance: 3102.6 | accuracy: 0.29 | loss: 0.28
update:340/2000, 耗时:0.00分/1.72分 | step: 54400 | performance: 2900.3 | accuracy: 0.29 | loss: 0.04
update:345/2000, 耗时:0.00分/1.74分 | step: 55200 | performance: 2717.7 | accuracy: 0.28 | loss: 0.11
update:350/2000, 耗时:0.01分/1.77分 | step: 56000 | performance: 2499.4 | accuracy: 0.27 | loss: 0.34
Saving PPO weights in both H5 format and checkpoint @ update:354 
update:355/2000, 耗时:0.01分/1.80分 | step: 56800 | performance: 1.1 | accuracy: 0.20 | loss: 0.84
step: 57280 | worker_7@n_step_19: average total_reward after train data exhaustion : 51.2 | max total_reward: 253.3
step: 57436 | worker_3@n_step_19: average total_reward after train data exhaustion : 42.9 | max total_reward: 253.3
step: 57437 | worker_4@n_step_19: average total_reward after train data exhaustion : 40.6 | max total_reward: 253.3
update:360/2000, 耗时:0.01分/1.82分 | step: 57600 | performance: 1.0 | accuracy: 0.17 | loss: 0.25
step: 58395 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.2 | max total_reward: 253.3
update:365/2000, 耗时:0.00分/1.85分 | step: 58400 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
step: 59038 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.3 | max total_reward: 253.3
update:370/2000, 耗时:0.01分/1.88分 | step: 59200 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 59513 | worker_0@n_step_19: average total_reward after train data exhaustion : -0.2 | max total_reward: 253.3
step: 59834 | worker_1@n_step_19: average total_reward after train data exhaustion : -0.2 | max total_reward: 253.3
step: 59999 | worker_6@n_step_19: average total_reward after train data exhaustion : -0.2 | max total_reward: 253.3
step: 60000 | worker_7@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
update:375/2000, 耗时:0.01分/1.90分 | step: 60000 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 60156 | worker_3@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 60157 | worker_4@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
update:380/2000, 耗时:0.01分/1.93分 | step: 60800 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 61115 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:385/2000, 耗时:0.01分/1.96分 | step: 61600 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 61758 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 62233 | worker_0@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
update:390/2000, 耗时:0.01分/1.99分 | step: 62400 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 62554 | worker_1@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 62719 | worker_6@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 62720 | worker_7@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 62876 | worker_3@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 62877 | worker_4@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:395/2000, 耗时:0.01分/2.01分 | step: 63200 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 63835 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:400/2000, 耗时:0.01分/2.04分 | step: 64000 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 64478 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.1 | max total_reward: 253.3
update:405/2000, 耗时:0.01分/2.07分 | step: 64800 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 64953 | worker_0@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 65274 | worker_1@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 65439 | worker_6@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 65440 | worker_7@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 65596 | worker_3@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 65597 | worker_4@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:410/2000, 耗时:0.01分/2.10分 | step: 65600 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:415/2000, 耗时:0.01分/2.13分 | step: 66400 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 66555 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 67198 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:420/2000, 耗时:0.01分/2.15分 | step: 67200 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 67673 | worker_0@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 67994 | worker_1@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
update:425/2000, 耗时:0.01分/2.18分 | step: 68000 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 68159 | worker_6@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 68160 | worker_7@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 68316 | worker_3@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 68317 | worker_4@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
update:430/2000, 耗时:0.01分/2.21分 | step: 68800 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 69275 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:435/2000, 耗时:0.01分/2.23分 | step: 69600 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 69918 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 70393 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:440/2000, 耗时:0.01分/2.26分 | step: 70400 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 70714 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 70879 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 70880 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 71036 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 71037 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:445/2000, 耗时:0.01分/2.29分 | step: 71200 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 71995 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
update:450/2000, 耗时:0.01分/2.32分 | step: 72000 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 72638 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:455/2000, 耗时:0.01分/2.34分 | step: 72800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 73113 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 73434 | worker_1@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 73599 | worker_6@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 73600 | worker_7@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:460/2000, 耗时:0.00分/2.37分 | step: 73600 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 73756 | worker_3@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 73757 | worker_4@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:465/2000, 耗时:0.01分/2.39分 | step: 74400 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 74715 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:470/2000, 耗时:0.00分/2.42分 | step: 75200 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 75358 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 75833 | worker_0@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
update:475/2000, 耗时:0.00分/2.44分 | step: 76000 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 76154 | worker_1@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 76319 | worker_6@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
step: 76320 | worker_7@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 76476 | worker_3@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 76477 | worker_4@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:480/2000, 耗时:0.00分/2.47分 | step: 76800 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 77435 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:485/2000, 耗时:0.01分/2.49分 | step: 77600 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 78078 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
update:490/2000, 耗时:0.00分/2.52分 | step: 78400 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 78553 | worker_0@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 78874 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 79039 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 79040 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 79196 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 79197 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:495/2000, 耗时:0.01分/2.54分 | step: 79200 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:500/2000, 耗时:0.01分/2.57分 | step: 80000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 80155 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 80798 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:505/2000, 耗时:0.01分/2.59分 | step: 80800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 81273 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 81594 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:510/2000, 耗时:0.01分/2.62分 | step: 81600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 81759 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 81760 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 81916 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 81917 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:515/2000, 耗时:0.01分/2.64分 | step: 82400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 82875 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:520/2000, 耗时:0.01分/2.67分 | step: 83200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 83518 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 83993 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:525/2000, 耗时:0.00分/2.69分 | step: 84000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 84314 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 84479 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 84480 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 84636 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 84637 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:530/2000, 耗时:0.01分/2.72分 | step: 84800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 85595 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:535/2000, 耗时:0.00分/2.74分 | step: 85600 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 86238 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.1 | max total_reward: 253.3
update:540/2000, 耗时:0.01分/2.77分 | step: 86400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 86713 | worker_0@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 87034 | worker_1@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 87199 | worker_6@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 87200 | worker_7@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:545/2000, 耗时:0.01分/2.79分 | step: 87200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 87356 | worker_3@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 87357 | worker_4@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:550/2000, 耗时:0.00分/2.82分 | step: 88000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 88315 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:555/2000, 耗时:0.01分/2.85分 | step: 88800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 88958 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 89433 | worker_0@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:560/2000, 耗时:0.01分/2.87分 | step: 89600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 89754 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 89919 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 89920 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 90076 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 90077 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:565/2000, 耗时:0.01分/2.90分 | step: 90400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 91035 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:570/2000, 耗时:0.01分/2.92分 | step: 91200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 91678 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:575/2000, 耗时:0.01分/2.95分 | step: 92000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 92153 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 92474 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 92639 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 92640 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 92796 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 92797 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:580/2000, 耗时:0.01分/2.97分 | step: 92800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:585/2000, 耗时:0.01分/3.00分 | step: 93600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 93755 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 94398 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:590/2000, 耗时:0.01分/3.03分 | step: 94400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 94873 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 95194 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:595/2000, 耗时:0.01分/3.05分 | step: 95200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 95359 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 95360 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 95516 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 95517 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:600/2000, 耗时:0.00分/3.08分 | step: 96000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 96475 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:605/2000, 耗时:0.00分/3.10分 | step: 96800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 97118 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 97593 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:610/2000, 耗时:0.00分/3.13分 | step: 97600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 97914 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 98079 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 98080 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 98236 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 98237 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:615/2000, 耗时:0.00分/3.15分 | step: 98400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 99195 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:620/2000, 耗时:0.01分/3.18分 | step: 99200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 99838 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:625/2000, 耗时:0.01分/3.20分 | step: 100000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 100313 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 100634 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 100799 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 100800 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:630/2000, 耗时:0.00分/3.23分 | step: 100800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 100956 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 100957 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:635/2000, 耗时:0.00分/3.25分 | step: 101600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 101915 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:640/2000, 耗时:0.00分/3.27分 | step: 102400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 102558 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 103033 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:645/2000, 耗时:0.00分/3.29分 | step: 103200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 103354 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 103519 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 103520 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 103676 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 103677 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:650/2000, 耗时:0.00分/3.32分 | step: 104000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 104635 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:655/2000, 耗时:0.01分/3.34分 | step: 104800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 105278 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:660/2000, 耗时:0.00分/3.37分 | step: 105600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 105753 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 106074 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 106239 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 106240 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 106396 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 106397 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:665/2000, 耗时:0.00分/3.39分 | step: 106400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:670/2000, 耗时:0.00分/3.41分 | step: 107200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 107355 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 107998 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:675/2000, 耗时:0.00分/3.44分 | step: 108000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 108473 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 108794 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:680/2000, 耗时:0.00分/3.46分 | step: 108800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 108959 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 108960 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 109116 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 109117 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:685/2000, 耗时:0.00分/3.49分 | step: 109600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 110075 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:690/2000, 耗时:0.01分/3.51分 | step: 110400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 110718 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 111193 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:695/2000, 耗时:0.01分/3.54分 | step: 111200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 111514 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 111679 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 111680 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 111836 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 111837 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:700/2000, 耗时:0.00分/3.56分 | step: 112000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 112795 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:705/2000, 耗时:0.00分/3.59分 | step: 112800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 113438 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:710/2000, 耗时:0.00分/3.61分 | step: 113600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 113913 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 114234 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 114399 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 114400 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:715/2000, 耗时:0.00分/3.64分 | step: 114400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 114556 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 114557 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:720/2000, 耗时:0.00分/3.66分 | step: 115200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 115515 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:725/2000, 耗时:0.00分/3.69分 | step: 116000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 116158 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 116633 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:730/2000, 耗时:0.01分/3.71分 | step: 116800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 116954 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 117119 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 117120 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 117276 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 117277 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:735/2000, 耗时:0.00分/3.74分 | step: 117600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 118235 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:740/2000, 耗时:0.01分/3.76分 | step: 118400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 118878 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:745/2000, 耗时:0.00分/3.79分 | step: 119200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 119353 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 119674 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 119839 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 119840 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 119996 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 119997 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:750/2000, 耗时:0.01分/3.81分 | step: 120000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:755/2000, 耗时:0.01分/3.84分 | step: 120800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 120955 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 121598 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:760/2000, 耗时:0.01分/3.87分 | step: 121600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 122073 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 122394 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:765/2000, 耗时:0.01分/3.89分 | step: 122400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 122559 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 122560 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 122716 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 122717 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:770/2000, 耗时:0.01分/3.92分 | step: 123200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 123675 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:775/2000, 耗时:0.01分/3.94分 | step: 124000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 124318 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 124793 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:780/2000, 耗时:0.00分/3.97分 | step: 124800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 125114 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 125279 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 125280 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 125436 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 125437 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:785/2000, 耗时:0.00分/3.99分 | step: 125600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 126395 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:790/2000, 耗时:0.00分/4.02分 | step: 126400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 127038 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:795/2000, 耗时:0.00分/4.04分 | step: 127200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 127513 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 127834 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 127999 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 128000 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:800/2000, 耗时:0.00分/4.07分 | step: 128000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 128156 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 128157 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:805/2000, 耗时:0.00分/4.09分 | step: 128800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 129115 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:810/2000, 耗时:0.00分/4.12分 | step: 129600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 129758 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 130233 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:815/2000, 耗时:0.00分/4.14分 | step: 130400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 130554 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 130719 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 130720 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 130876 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 130877 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:820/2000, 耗时:0.00分/4.16分 | step: 131200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 131835 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:825/2000, 耗时:0.01分/4.19分 | step: 132000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 132478 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:830/2000, 耗时:0.01分/4.22分 | step: 132800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 132953 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 133274 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 133439 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 133440 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 133596 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 133597 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:835/2000, 耗时:0.01分/4.24分 | step: 133600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:840/2000, 耗时:0.00分/4.27分 | step: 134400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 134555 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 135198 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:845/2000, 耗时:0.00分/4.29分 | step: 135200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 135673 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 135994 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:850/2000, 耗时:0.00分/4.32分 | step: 136000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 136159 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 136160 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 136316 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 136317 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:855/2000, 耗时:0.00分/4.34分 | step: 136800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 137275 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:860/2000, 耗时:0.00分/4.37分 | step: 137600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 137918 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 138393 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:865/2000, 耗时:0.00分/4.39分 | step: 138400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 138714 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 138879 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 138880 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 139036 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 139037 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:870/2000, 耗时:0.00分/4.41分 | step: 139200 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 139995 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:875/2000, 耗时:0.00分/4.44分 | step: 140000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 140638 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:880/2000, 耗时:0.00分/4.46分 | step: 140800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 141113 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 141434 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 141599 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 141600 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:885/2000, 耗时:0.01分/4.49分 | step: 141600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 141756 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 141757 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:890/2000, 耗时:0.01分/4.51分 | step: 142400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 142715 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:895/2000, 耗时:0.00分/4.54分 | step: 143200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 143358 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 143833 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:900/2000, 耗时:0.01分/4.56分 | step: 144000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 144154 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 144319 | worker_6@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 144320 | worker_7@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 144476 | worker_3@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 144477 | worker_4@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:905/2000, 耗时:0.00分/4.59分 | step: 144800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 145435 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:910/2000, 耗时:0.00分/4.61分 | step: 145600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 146078 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:915/2000, 耗时:0.00分/4.64分 | step: 146400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 146553 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 146874 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 147039 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 147040 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 147196 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 147197 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:920/2000, 耗时:0.00分/4.66分 | step: 147200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:925/2000, 耗时:0.00分/4.69分 | step: 148000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 148155 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 148798 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:930/2000, 耗时:0.00分/4.71分 | step: 148800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 149273 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 149594 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:935/2000, 耗时:0.00分/4.73分 | step: 149600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 149759 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 149760 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 149916 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 149917 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:940/2000, 耗时:0.00分/4.76分 | step: 150400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 150875 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:945/2000, 耗时:0.00分/4.78分 | step: 151200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 151518 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 151993 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:950/2000, 耗时:0.00分/4.81分 | step: 152000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 152314 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 152479 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 152480 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 152636 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 152637 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:955/2000, 耗时:0.00分/4.83分 | step: 152800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 153595 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:960/2000, 耗时:0.00分/4.86分 | step: 153600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 154238 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:965/2000, 耗时:0.00分/4.88分 | step: 154400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 154713 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 155034 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 155199 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 155200 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:970/2000, 耗时:0.01分/4.91分 | step: 155200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 155356 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 155357 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:975/2000, 耗时:0.00分/4.93分 | step: 156000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 156315 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:980/2000, 耗时:0.01分/4.96分 | step: 156800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 156958 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 157433 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:985/2000, 耗时:0.00分/4.98分 | step: 157600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 157754 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 157919 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 157920 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 158076 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 158077 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:990/2000, 耗时:0.00分/5.01分 | step: 158400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 159035 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:995/2000, 耗时:0.01分/5.03分 | step: 159200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 159678 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1000/2000, 耗时:0.01分/5.06分 | step: 160000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 160153 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 160474 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 160639 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 160640 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 160796 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 160797 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1005/2000, 耗时:0.01分/5.08分 | step: 160800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1010/2000, 耗时:0.01分/5.11分 | step: 161600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 161755 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 162398 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1015/2000, 耗时:0.00分/5.13分 | step: 162400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 162873 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 163194 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1020/2000, 耗时:0.00分/5.16分 | step: 163200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 163359 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 163360 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 163516 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 163517 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1025/2000, 耗时:0.00分/5.18分 | step: 164000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 164475 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1030/2000, 耗时:0.00分/5.21分 | step: 164800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 165118 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 165593 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1035/2000, 耗时:0.00分/5.23分 | step: 165600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 165914 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 166079 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 166080 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 166236 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 166237 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1040/2000, 耗时:0.00分/5.26分 | step: 166400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 167195 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1045/2000, 耗时:0.00分/5.28分 | step: 167200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 167838 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1050/2000, 耗时:0.00分/5.31分 | step: 168000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 168313 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 168634 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 168799 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 168800 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1055/2000, 耗时:0.00分/5.33分 | step: 168800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 168956 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 168957 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1060/2000, 耗时:0.00分/5.36分 | step: 169600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 169915 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1065/2000, 耗时:0.00分/5.38分 | step: 170400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 170558 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 171033 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1070/2000, 耗时:0.00分/5.41分 | step: 171200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 171354 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 171519 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 171520 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 171676 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 171677 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1075/2000, 耗时:0.00分/5.43分 | step: 172000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 172635 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1080/2000, 耗时:0.00分/5.46分 | step: 172800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 173278 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1085/2000, 耗时:0.00分/5.48分 | step: 173600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 173753 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 174074 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 174239 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 174240 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 174396 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 174397 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1090/2000, 耗时:0.00分/5.50分 | step: 174400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1095/2000, 耗时:0.00分/5.53分 | step: 175200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 175355 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 175998 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1100/2000, 耗时:0.00分/5.55分 | step: 176000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 176473 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 176794 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1105/2000, 耗时:0.00分/5.58分 | step: 176800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 176959 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 176960 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 177116 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 177117 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1110/2000, 耗时:0.00分/5.60分 | step: 177600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 178075 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1115/2000, 耗时:0.00分/5.62分 | step: 178400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 178718 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 179193 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1120/2000, 耗时:0.00分/5.65分 | step: 179200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 179514 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 179679 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 179680 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 179836 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 179837 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1125/2000, 耗时:0.00分/5.67分 | step: 180000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 180795 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1130/2000, 耗时:0.00分/5.70分 | step: 180800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 181438 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1135/2000, 耗时:0.00分/5.72分 | step: 181600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 181913 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 182234 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 182399 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 182400 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1140/2000, 耗时:0.00分/5.75分 | step: 182400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 182556 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 182557 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1145/2000, 耗时:0.00分/5.77分 | step: 183200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 183515 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1150/2000, 耗时:0.00分/5.80分 | step: 184000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 184158 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 184633 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1155/2000, 耗时:0.00分/5.82分 | step: 184800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 184954 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 185119 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 185120 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 185276 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 185277 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1160/2000, 耗时:0.00分/5.85分 | step: 185600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 186235 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1165/2000, 耗时:0.00分/5.87分 | step: 186400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 186878 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1170/2000, 耗时:0.00分/5.90分 | step: 187200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 187353 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 187674 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 187839 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 187840 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 187996 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 187997 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1175/2000, 耗时:0.00分/5.92分 | step: 188000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1180/2000, 耗时:0.01分/5.94分 | step: 188800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 188955 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 189598 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1185/2000, 耗时:0.00分/5.97分 | step: 189600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 190073 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 190394 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1190/2000, 耗时:0.01分/5.99分 | step: 190400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 190559 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 190560 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 190716 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 190717 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1195/2000, 耗时:0.00分/6.02分 | step: 191200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 191675 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1200/2000, 耗时:0.01分/6.04分 | step: 192000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 192318 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 192793 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1205/2000, 耗时:0.00分/6.07分 | step: 192800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 193114 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 193279 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 193280 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 193436 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 193437 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1210/2000, 耗时:0.00分/6.09分 | step: 193600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 194395 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1215/2000, 耗时:0.01分/6.12分 | step: 194400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 195038 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1220/2000, 耗时:0.00分/6.14分 | step: 195200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 195513 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 195834 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 195999 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 196000 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1225/2000, 耗时:0.00分/6.17分 | step: 196000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 196156 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 196157 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1230/2000, 耗时:0.00分/6.19分 | step: 196800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 197115 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1235/2000, 耗时:0.01分/6.22分 | step: 197600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 197758 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 198233 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1240/2000, 耗时:0.00分/6.24分 | step: 198400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 198554 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 198719 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 198720 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 198876 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 198877 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1245/2000, 耗时:0.00分/6.27分 | step: 199200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 199835 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1250/2000, 耗时:0.01分/6.29分 | step: 200000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 200478 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1255/2000, 耗时:0.01分/6.32分 | step: 200800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 200953 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 201274 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 201439 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 201440 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 201596 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 201597 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1260/2000, 耗时:0.01分/6.34分 | step: 201600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1265/2000, 耗时:0.01分/6.37分 | step: 202400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 202555 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 203198 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1270/2000, 耗时:0.01分/6.39分 | step: 203200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 203673 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 203994 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1275/2000, 耗时:0.00分/6.42分 | step: 204000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 204159 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 204160 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 204316 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 204317 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1280/2000, 耗时:0.00分/6.44分 | step: 204800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 205275 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1285/2000, 耗时:0.00分/6.47分 | step: 205600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 205918 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 206393 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1290/2000, 耗时:0.00分/6.49分 | step: 206400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 206714 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 206879 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 206880 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 207036 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 207037 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1295/2000, 耗时:0.00分/6.52分 | step: 207200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 207995 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1300/2000, 耗时:0.01分/6.54分 | step: 208000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 208638 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1305/2000, 耗时:0.00分/6.57分 | step: 208800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 209113 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 209434 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 209599 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 209600 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1310/2000, 耗时:0.00分/6.59分 | step: 209600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 209756 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 209757 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1315/2000, 耗时:0.00分/6.62分 | step: 210400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 210715 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1320/2000, 耗时:0.00分/6.64分 | step: 211200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 211358 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 211833 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1325/2000, 耗时:0.00分/6.67分 | step: 212000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 212154 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 212319 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 212320 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 212476 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 212477 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1330/2000, 耗时:0.00分/6.69分 | step: 212800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 213435 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1335/2000, 耗时:0.00分/6.72分 | step: 213600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 214078 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1340/2000, 耗时:0.00分/6.74分 | step: 214400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 214553 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 214874 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 215039 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 215040 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 215196 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 215197 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1345/2000, 耗时:0.00分/6.77分 | step: 215200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1350/2000, 耗时:0.01分/6.79分 | step: 216000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 216155 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 216798 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1355/2000, 耗时:0.00分/6.81分 | step: 216800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 217273 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 217594 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1360/2000, 耗时:0.00分/6.84分 | step: 217600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 217759 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 217760 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 217916 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 217917 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1365/2000, 耗时:0.01分/6.87分 | step: 218400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 218875 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1370/2000, 耗时:0.01分/6.89分 | step: 219200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 219518 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 219993 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1375/2000, 耗时:0.01分/6.92分 | step: 220000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 220314 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 220479 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 220480 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 220636 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 220637 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1380/2000, 耗时:0.01分/6.94分 | step: 220800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 221595 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1385/2000, 耗时:0.01分/6.97分 | step: 221600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 222238 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1390/2000, 耗时:0.01分/6.99分 | step: 222400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 222713 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 223034 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 223199 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 223200 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1395/2000, 耗时:0.01分/7.02分 | step: 223200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 223356 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 223357 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1400/2000, 耗时:0.01分/7.04分 | step: 224000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 224315 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1405/2000, 耗时:0.01分/7.07分 | step: 224800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 224958 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 225433 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1410/2000, 耗时:0.01分/7.09分 | step: 225600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 225754 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 225919 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 225920 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 226076 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 226077 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1415/2000, 耗时:0.01分/7.12分 | step: 226400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 227035 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1420/2000, 耗时:0.01分/7.15分 | step: 227200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 227678 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1425/2000, 耗时:0.01分/7.17分 | step: 228000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 228153 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 228474 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 228639 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 228640 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 228796 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 228797 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1430/2000, 耗时:0.01分/7.20分 | step: 228800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1435/2000, 耗时:0.01分/7.22分 | step: 229600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 229755 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 230398 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1440/2000, 耗时:0.00分/7.25分 | step: 230400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 230873 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 231194 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1445/2000, 耗时:0.01分/7.27分 | step: 231200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 231359 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 231360 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 231516 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 231517 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1450/2000, 耗时:0.01分/7.30分 | step: 232000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 232475 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1455/2000, 耗时:0.01分/7.32分 | step: 232800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 233118 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 233593 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1460/2000, 耗时:0.01分/7.35分 | step: 233600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 233914 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 234079 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 234080 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 234236 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 234237 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1465/2000, 耗时:0.01分/7.38分 | step: 234400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 235195 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1470/2000, 耗时:0.00分/7.40分 | step: 235200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 235838 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1475/2000, 耗时:0.01分/7.43分 | step: 236000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 236313 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 236634 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 236799 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 236800 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1480/2000, 耗时:0.01分/7.45分 | step: 236800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 236956 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 236957 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1485/2000, 耗时:0.01分/7.48分 | step: 237600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 237915 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1490/2000, 耗时:0.00分/7.50分 | step: 238400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 238558 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 239033 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1495/2000, 耗时:0.01分/7.53分 | step: 239200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 239354 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 239519 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 239520 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 239676 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 239677 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1500/2000, 耗时:0.00分/7.55分 | step: 240000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 240635 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1505/2000, 耗时:0.00分/7.58分 | step: 240800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 241278 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1510/2000, 耗时:0.00分/7.60分 | step: 241600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 241753 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 242074 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 242239 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 242240 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 242396 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 242397 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1515/2000, 耗时:0.01分/7.63分 | step: 242400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1520/2000, 耗时:0.00分/7.65分 | step: 243200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 243355 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 243998 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1525/2000, 耗时:0.00分/7.68分 | step: 244000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 244473 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 244794 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1530/2000, 耗时:0.00分/7.70分 | step: 244800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 244959 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 244960 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 245116 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 245117 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1535/2000, 耗时:0.00分/7.72分 | step: 245600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 246075 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1540/2000, 耗时:0.00分/7.75分 | step: 246400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 246718 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 247193 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1545/2000, 耗时:0.00分/7.77分 | step: 247200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 247514 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 247679 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 247680 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 247836 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 247837 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1550/2000, 耗时:0.00分/7.80分 | step: 248000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 248795 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1555/2000, 耗时:0.00分/7.82分 | step: 248800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 249438 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1560/2000, 耗时:0.00分/7.85分 | step: 249600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 249913 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 250234 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 250399 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 250400 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1565/2000, 耗时:0.01分/7.87分 | step: 250400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 250556 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 250557 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1570/2000, 耗时:0.01分/7.90分 | step: 251200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 251515 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1575/2000, 耗时:0.01分/7.93分 | step: 252000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 252158 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 252633 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1580/2000, 耗时:0.01分/7.96分 | step: 252800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 252954 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 253119 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 253120 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 253276 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 253277 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1585/2000, 耗时:0.01分/7.98分 | step: 253600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 254235 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1590/2000, 耗时:0.01分/8.01分 | step: 254400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 254878 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1595/2000, 耗时:0.01分/8.04分 | step: 255200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 255353 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 255674 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 255839 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 255840 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 255996 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 255997 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1600/2000, 耗时:0.01分/8.07分 | step: 256000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1605/2000, 耗时:0.01分/8.09分 | step: 256800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 256955 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 257598 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1610/2000, 耗时:0.01分/8.12分 | step: 257600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 258073 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 258394 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1615/2000, 耗时:0.01分/8.15分 | step: 258400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 258559 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 258560 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 258716 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 258717 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1620/2000, 耗时:0.01分/8.18分 | step: 259200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 259675 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1625/2000, 耗时:0.01分/8.20分 | step: 260000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 260318 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 260793 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1630/2000, 耗时:0.01分/8.23分 | step: 260800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 261114 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 261279 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 261280 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 261436 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 261437 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1635/2000, 耗时:0.01分/8.26分 | step: 261600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 262395 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1640/2000, 耗时:0.01分/8.29分 | step: 262400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 263038 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1645/2000, 耗时:0.01分/8.31分 | step: 263200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 263513 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 263834 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 263999 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 264000 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1650/2000, 耗时:0.01分/8.34分 | step: 264000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 264156 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 264157 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1655/2000, 耗时:0.01分/8.37分 | step: 264800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 265115 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1660/2000, 耗时:0.00分/8.39分 | step: 265600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 265758 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 266233 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1665/2000, 耗时:0.00分/8.41分 | step: 266400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 266554 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 266719 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 266720 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 266876 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 266877 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1670/2000, 耗时:0.00分/8.44分 | step: 267200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 267835 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1675/2000, 耗时:0.00分/8.46分 | step: 268000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 268478 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1680/2000, 耗时:0.01分/8.49分 | step: 268800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 268953 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 269274 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 269439 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 269440 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 269596 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 269597 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1685/2000, 耗时:0.00分/8.51分 | step: 269600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1690/2000, 耗时:0.01分/8.54分 | step: 270400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 270555 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 271198 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1695/2000, 耗时:0.01分/8.56分 | step: 271200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 271673 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 271994 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1700/2000, 耗时:0.00分/8.59分 | step: 272000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 272159 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 272160 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 272316 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 272317 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1705/2000, 耗时:0.00分/8.61分 | step: 272800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 273275 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1710/2000, 耗时:0.00分/8.64分 | step: 273600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 273918 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 274393 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1715/2000, 耗时:0.00分/8.66分 | step: 274400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 274714 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 274879 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 274880 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 275036 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 275037 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1720/2000, 耗时:0.00分/8.69分 | step: 275200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 275995 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1725/2000, 耗时:0.00分/8.71分 | step: 276000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 276638 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1730/2000, 耗时:0.00分/8.74分 | step: 276800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 277113 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 277434 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 277599 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 277600 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1735/2000, 耗时:0.00分/8.76分 | step: 277600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 277756 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 277757 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1740/2000, 耗时:0.01分/8.79分 | step: 278400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 278715 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1745/2000, 耗时:0.01分/8.81分 | step: 279200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 279358 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 279833 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1750/2000, 耗时:0.01分/8.84分 | step: 280000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 280154 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 280319 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 280320 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 280476 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 280477 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1755/2000, 耗时:0.01分/8.86分 | step: 280800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 281435 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1760/2000, 耗时:0.01分/8.89分 | step: 281600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 282078 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1765/2000, 耗时:0.01分/8.91分 | step: 282400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 282553 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 282874 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 283039 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 283040 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 283196 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 283197 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1770/2000, 耗时:0.01分/8.94分 | step: 283200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1775/2000, 耗时:0.01分/8.97分 | step: 284000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 284155 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 284798 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1780/2000, 耗时:0.00分/8.99分 | step: 284800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 285273 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 285594 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1785/2000, 耗时:0.00分/9.01分 | step: 285600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 285759 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 285760 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 285916 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 285917 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1790/2000, 耗时:0.00分/9.04分 | step: 286400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 286875 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1795/2000, 耗时:0.00分/9.07分 | step: 287200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 287518 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 287993 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1800/2000, 耗时:0.00分/9.09分 | step: 288000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 288314 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 288479 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 288480 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 288636 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 288637 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1805/2000, 耗时:0.01分/9.12分 | step: 288800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 289595 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1810/2000, 耗时:0.00分/9.14分 | step: 289600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 290238 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1815/2000, 耗时:0.01分/9.17分 | step: 290400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 290713 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 291034 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 291199 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 291200 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1820/2000, 耗时:0.01分/9.19分 | step: 291200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 291356 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 291357 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1825/2000, 耗时:0.01分/9.22分 | step: 292000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 292315 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1830/2000, 耗时:0.00分/9.24分 | step: 292800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 292958 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 293433 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1835/2000, 耗时:0.00分/9.27分 | step: 293600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 293754 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 293919 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 293920 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 294076 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 294077 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1840/2000, 耗时:0.00分/9.29分 | step: 294400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 295035 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1845/2000, 耗时:0.01分/9.32分 | step: 295200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 295678 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1850/2000, 耗时:0.01分/9.34分 | step: 296000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 296153 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 296474 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 296639 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 296640 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 296796 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 296797 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1855/2000, 耗时:0.01分/9.37分 | step: 296800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1860/2000, 耗时:0.01分/9.40分 | step: 297600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 297755 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 298398 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1865/2000, 耗时:0.01分/9.42分 | step: 298400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 298873 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 299194 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1870/2000, 耗时:0.01分/9.45分 | step: 299200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 299359 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 299360 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 299516 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 299517 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1875/2000, 耗时:0.01分/9.47分 | step: 300000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 300475 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1880/2000, 耗时:0.00分/9.50分 | step: 300800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 301118 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 301593 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1885/2000, 耗时:0.00分/9.52分 | step: 301600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 301914 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 302079 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 302080 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 302236 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 302237 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1890/2000, 耗时:0.00分/9.55分 | step: 302400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 303195 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1895/2000, 耗时:0.01分/9.57分 | step: 303200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 303838 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1900/2000, 耗时:0.00分/9.60分 | step: 304000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 304313 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 304634 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 304799 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 304800 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1905/2000, 耗时:0.00分/9.62分 | step: 304800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 304956 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 304957 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1910/2000, 耗时:0.00分/9.65分 | step: 305600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 305915 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1915/2000, 耗时:0.00分/9.67分 | step: 306400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 306558 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 307033 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1920/2000, 耗时:0.00分/9.69分 | step: 307200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 307354 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 307519 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 307520 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 307676 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 307677 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1925/2000, 耗时:0.00分/9.72分 | step: 308000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 308635 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1930/2000, 耗时:0.00分/9.74分 | step: 308800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 309278 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1935/2000, 耗时:0.00分/9.77分 | step: 309600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 309753 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 310074 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 310239 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 310240 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 310396 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 310397 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1940/2000, 耗时:0.01分/9.79分 | step: 310400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
update:1945/2000, 耗时:0.01分/9.82分 | step: 311200 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 311355 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 311998 | worker_5@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:1950/2000, 耗时:0.00分/9.84分 | step: 312000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 312473 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 312794 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1955/2000, 耗时:0.00分/9.87分 | step: 312800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 312959 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 312960 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 313116 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 313117 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1960/2000, 耗时:0.01分/9.89分 | step: 313600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 314075 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1965/2000, 耗时:0.00分/9.92分 | step: 314400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 314718 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 315193 | worker_0@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1970/2000, 耗时:0.00分/9.94分 | step: 315200 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 315514 | worker_1@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 315679 | worker_6@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 315680 | worker_7@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 315836 | worker_3@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
step: 315837 | worker_4@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1975/2000, 耗时:0.00分/9.96分 | step: 316000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 316795 | worker_2@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1980/2000, 耗时:0.00分/9.99分 | step: 316800 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 317438 | worker_5@n_step_19: average total_reward after train data exhaustion : 0.0 | max total_reward: 253.3
update:1985/2000, 耗时:0.00分/10.01分 | step: 317600 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 317913 | worker_0@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 318234 | worker_1@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 318399 | worker_6@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 318400 | worker_7@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:1990/2000, 耗时:0.00分/10.04分 | step: 318400 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 318556 | worker_3@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
step: 318557 | worker_4@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
update:1995/2000, 耗时:0.00分/10.06分 | step: 319200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 319515 | worker_2@n_step_19: average total_reward after train data exhaustion : -0.0 | max total_reward: 253.3
  0%|          | 0/406 [00:00<?, ?it/s]100%|| 406/406 [00:00<00:00, 115223.45it/s]
update:2000/2000, 耗时:0.00分/10.09分 | step: 320000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
----------------------------------------finished----------------------------------------
==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1000.00
2023-07-24T12:00:00 | net performance [%] = 0.0000
2023-07-24T12:00:00 | number of trades [#] = 0
==================================================
Trial 41 Complete [00h 10m 32s]
net_wealth: 1000.0

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 05h 25m 15s

Search: Running Trial #42

Value             |Best Value So Far |Hyperparameter
2                 |7                 |horizon
730               |730               |lookback
False             |False             |MarketFactor
14                |14                |lags
0.92              |0.7               |gamma
32                |32                |batch_size
5                 |32                |n_step
0.85              |0.92              |gae_lambda
5                 |0.1               |gradient_clip_norm
3                 |5                 |epochs
0.001             |0.0001            |actor_lr
1e-05             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4313.000000   4315.000000
mean      0.000441    20062.255222  ...   20125.961477  20118.633889
std       0.027818    16039.874230  ...   16077.223335  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7693.100098   7690.540039
50%       0.000642    11554.824463  ...   11733.030273  11715.610352
75%       0.011655    29873.081836  ...   29928.000000  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 03:28:38.465510: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Libr2023-07-28 02203:28:203328-0.3-047-28 03:6725-85892::8 38I 03:28 .:3846.ten45s65o50r58f0:l9 o: ary (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 032I0w/core/platform/cpu_2 tensorflfow/core/platform/cpu_feature_gu:28:38.465954: I tensorflow/core/platform/cpu_feature_guaearatud.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the fo2rd.cc:10I42]2r3-le_l0 7This T ow-tengeuarsdorn.csor28 f3-li07-28 03:28:3ng 28.0c2:CP142] 40ThoUis w/3T: i28:38.6nsFcore/p5t4l3ar-ltform/cpu0uocw9 6e61: tionsbin_f7 nas-5in royea28pIer Ft98ure_gu3t renis ofsoprorfltmaniow/cocmiere/platforz-cem/cprdiu_f tiweature_guard.cith ocalcne:alr1API 4ow binaD2d.cc] eep Neural Netwo:ry is optimized with oneAPI Deep Neural Network Library (oneDNN)T hisorpk :Tee1 4I2] Th ran 03:2iL totiis  tTe onsnbs:ouen rrFs8s:3loswary oe (o8rFl nbeio.w bina nrytDhoAre  is opftary isf466259VX Nol ip: otmN) to AwoiziVuseld w/corme/ized with oneAPI Deep Neural NeplaietworXtt ht oflkohn2e Iwin goAL
ibTroa rrm/tPIe nCaPbcpu_feature_gu eDnearUye (posd inorf neNDe.lcNsNe)eura ltohe  totruw/cl Netwom inf uoro loe/rlkstp eL ilcat:h14ofer2brarwc] Ttiionng t hyio phee rations, rebuild TensorFlow with th(CoPU inos in rsn TensorFlow binary ifssotl m/cpu_feature_orptimlowiueDzNedNcginuard )g.p wteCicPc  :taie142t]hrfopp on  Thiuso rroTeAPIeomance-ns  crDipnsiU orFlerep Neutrn icaow piealb al rNftiinary operaetiwotsierms t e compons: o rAVoX nik ALViXbrlser 2hpatimie r
To fy truc(zoeolfelnolnawbalegdeDNNs with i then). 
g Coto nPuseaneAc thtUiPeIe-criomn   is fDoeenint in performanceipcslta Neural Network l oper othationlructiooewri ng-Liso:  AVX AVX2
To enable them in ot crihCer Ppertatioiopensns, rbrebacr utary iiai(nolon ld Upe in rsftrucormtTieooannpecnsse-orratFnleocwrit ical operaiDn performas, rebuild  tNN) to use the Teifowith thensornF oanllopceions: -cs:  AVX AVX2
rwi tlpowr AoprViianwTiiXtoc al  Ate eh theVX2
Togo  paCecroP pennabUle pampritoatiobn hlemelpiriate compiler flags.
e them in ot sin other nst:  AVX Arhru oeperatrVX2
c toiiflags.
perations, rebuild TensorFlow with the appropriate compiler flags.
onsTo enable them in other operations, rebuild TensorFlow ons, rebuiin performance-critical with the appropriate compiler flags.d TensorFlow with the appropriate compiler flags.

l operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 03:28:39.087525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:28:39.117979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:28:39.121962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:28:39.124585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:28:39.124810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:28:39.130407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:28:39.131138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:28:39.134476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   200 | performance: 1.2 | accuracy: 0.44 | loss: 0.48
update: 10/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 1.1 | accuracy: 0.38 | loss: 1.31
update: 15/2000, 耗时:0.00分/0.04分 | step:   600 | performance: 1.2 | accuracy: 0.44 | loss: 1.16
update: 20/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 1.3 | accuracy: 0.46 | loss: 1.39
update: 25/2000, 耗时:0.00分/0.06分 | step:  1000 | performance: 1.3 | accuracy: 0.47 | loss: 0.61
update: 30/2000, 耗时:0.00分/0.07分 | step:  1200 | performance: 1.8 | accuracy: 0.47 | loss: 1.72
update: 35/2000, 耗时:0.00分/0.08分 | step:  1400 | performance: 2.6 | accuracy: 0.47 | loss: 4.41
update: 40/2000, 耗时:0.00分/0.09分 | step:  1600 | performance: 4.3 | accuracy: 0.49 | loss: 2.22
update: 45/2000, 耗时:0.00分/0.09分 | step:  1800 | performance: 3.1 | accuracy: 0.48 | loss: 1.37
update: 50/2000, 耗时:0.00分/0.10分 | step:  2000 | performance: 3.6 | accuracy: 0.48 | loss: 0.26
update: 55/2000, 耗时:0.00分/0.11分 | step:  2200 | performance: 4.1 | accuracy: 0.49 | loss: 0.41
update: 60/2000, 耗时:0.00分/0.12分 | step:  2400 | performance: 4.6 | accuracy: 0.50 | loss: 0.54
update: 65/2000, 耗时:0.00分/0.13分 | step:  2600 | performance: 4.3 | accuracy: 0.49 | loss: 1.22
update: 70/2000, 耗时:0.00分/0.14分 | step:  2800 | performance: 4.1 | accuracy: 0.48 | loss: 0.98
update: 75/2000, 耗时:0.00分/0.15分 | step:  3000 | performance: 3.8 | accuracy: 0.47 | loss: 0.66
update: 80/2000, 耗时:0.00分/0.16分 | step:  3200 | performance: 4.0 | accuracy: 0.47 | loss: 1.02
update: 85/2000, 耗时:0.00分/0.17分 | step:  3400 | performance: 2.7 | accuracy: 0.46 | loss: 6.22
update: 90/2000, 耗时:0.00分/0.18分 | step:  3600 | performance: 2.6 | accuracy: 0.46 | loss: 1.32
update: 95/2000, 耗时:0.00分/0.19分 | step:  3800 | performance: 2.4 | accuracy: 0.45 | loss: 0.86
update:100/2000, 耗时:0.00分/0.20分 | step:  4000 | performance: 2.7 | accuracy: 0.45 | loss: 1.80
update:105/2000, 耗时:0.00分/0.21分 | step:  4200 | performance: 2.8 | accuracy: 0.45 | loss: 3.43
update:110/2000, 耗时:0.00分/0.22分 | step:  4400 | performance: 2.6 | accuracy: 0.44 | loss: 4.05
update:115/2000, 耗时:0.00分/0.23分 | step:  4600 | performance: 3.6 | accuracy: 0.46 | loss: 3.01
update:120/2000, 耗时:0.00分/0.24分 | step:  4800 | performance: 5.7 | accuracy: 0.46 | loss: 7.41
update:125/2000, 耗时:0.00分/0.25分 | step:  5000 | performance: 5.5 | accuracy: 0.47 | loss: 2.97
update:130/2000, 耗时:0.00分/0.26分 | step:  5200 | performance: 3.8 | accuracy: 0.46 | loss: 2.55
update:135/2000, 耗时:0.00分/0.27分 | step:  5400 | performance: 5.1 | accuracy: 0.47 | loss: 1.34
update:140/2000, 耗时:0.00分/0.28分 | step:  5600 | performance: 4.1 | accuracy: 0.47 | loss: 1.76
update:145/2000, 耗时:0.00分/0.29分 | step:  5800 | performance: 3.3 | accuracy: 0.47 | loss: 0.83
update:150/2000, 耗时:0.00分/0.30分 | step:  6000 | performance: 3.8 | accuracy: 0.47 | loss: 2.65
update:155/2000, 耗时:0.00分/0.31分 | step:  6200 | performance: 2.4 | accuracy: 0.46 | loss: 9.22
update:160/2000, 耗时:0.00分/0.32分 | step:  6400 | performance: 2.2 | accuracy: 0.46 | loss: 2.53
update:165/2000, 耗时:0.00分/0.33分 | step:  6600 | performance: 2.2 | accuracy: 0.46 | loss: 0.57
update:170/2000, 耗时:0.00分/0.34分 | step:  6800 | performance: 2.3 | accuracy: 0.46 | loss: 2.78
update:175/2000, 耗时:0.00分/0.35分 | step:  7000 | performance: 2.1 | accuracy: 0.46 | loss: 1.44
update:180/2000, 耗时:0.00分/0.36分 | step:  7200 | performance: 1.8 | accuracy: 0.46 | loss: 0.91
update:185/2000, 耗时:0.00分/0.37分 | step:  7400 | performance: 1.6 | accuracy: 0.46 | loss: 1.02
update:190/2000, 耗时:0.00分/0.38分 | step:  7600 | performance: 1.4 | accuracy: 0.46 | loss: 1.14
update:195/2000, 耗时:0.00分/0.39分 | step:  7800 | performance: 1.7 | accuracy: 0.46 | loss: 0.46
update:200/2000, 耗时:0.00分/0.40分 | step:  8000 | performance: 1.4 | accuracy: 0.46 | loss: 0.84
update:205/2000, 耗时:0.00分/0.41分 | step:  8200 | performance: 1.4 | accuracy: 0.45 | loss: 1.72
update:210/2000, 耗时:0.00分/0.42分 | step:  8400 | performance: 1.4 | accuracy: 0.45 | loss: 0.65
update:215/2000, 耗时:0.00分/0.43分 | step:  8600 | performance: 1.3 | accuracy: 0.45 | loss: 1.24
update:220/2000, 耗时:0.00分/0.44分 | step:  8800 | performance: 1.5 | accuracy: 0.45 | loss: 2.15
update:225/2000, 耗时:0.00分/0.45分 | step:  9000 | performance: 2.1 | accuracy: 0.45 | loss: 11.17
update:230/2000, 耗时:0.00分/0.46分 | step:  9200 | performance: 1.4 | accuracy: 0.45 | loss: 4.45
update:235/2000, 耗时:0.00分/0.47分 | step:  9400 | performance: 1.5 | accuracy: 0.45 | loss: 0.63
update:240/2000, 耗时:0.00分/0.48分 | step:  9600 | performance: 1.7 | accuracy: 0.45 | loss: 1.38
update:245/2000, 耗时:0.00分/0.49分 | step:  9800 | performance: 2.1 | accuracy: 0.45 | loss: 2.03
update:250/2000, 耗时:0.00分/0.50分 | step: 10000 | performance: 1.8 | accuracy: 0.45 | loss: 0.83
update:255/2000, 耗时:0.00分/0.51分 | step: 10200 | performance: 1.9 | accuracy: 0.44 | loss: 0.93
update:260/2000, 耗时:0.00分/0.52分 | step: 10400 | performance: 1.7 | accuracy: 0.44 | loss: 0.32
update:265/2000, 耗时:0.00分/0.53分 | step: 10600 | performance: 1.7 | accuracy: 0.44 | loss: 1.40
update:270/2000, 耗时:0.00分/0.54分 | step: 10800 | performance: 1.8 | accuracy: 0.44 | loss: 0.98
update:275/2000, 耗时:0.00分/0.55分 | step: 11000 | performance: 1.7 | accuracy: 0.43 | loss: 0.48
update:280/2000, 耗时:0.00分/0.56分 | step: 11200 | performance: 1.7 | accuracy: 0.43 | loss: 0.96
update:285/2000, 耗时:0.00分/0.57分 | step: 11400 | performance: 1.6 | accuracy: 0.43 | loss: 0.11
update:290/2000, 耗时:0.00分/0.59分 | step: 11600 | performance: 1.7 | accuracy: 0.42 | loss: 0.37
update:295/2000, 耗时:0.00分/0.60分 | step: 11800 | performance: 1.8 | accuracy: 0.42 | loss: 1.94
update:300/2000, 耗时:0.00分/0.61分 | step: 12000 | performance: 1.5 | accuracy: 0.42 | loss: 0.93
update:305/2000, 耗时:0.00分/0.62分 | step: 12200 | performance: 1.5 | accuracy: 0.41 | loss: 0.82
update:310/2000, 耗时:0.00分/0.63分 | step: 12400 | performance: 1.5 | accuracy: 0.41 | loss: 0.10
update:315/2000, 耗时:0.00分/0.64分 | step: 12600 | performance: 1.5 | accuracy: 0.40 | loss: 0.11
update:320/2000, 耗时:0.00分/0.65分 | step: 12800 | performance: 1.5 | accuracy: 0.40 | loss: 0.13
update:325/2000, 耗时:0.00分/0.66分 | step: 13000 | performance: 1.5 | accuracy: 0.39 | loss: 0.22
update:330/2000, 耗时:0.00分/0.67分 | step: 13200 | performance: 1.5 | accuracy: 0.39 | loss: 0.13
update:335/2000, 耗时:0.00分/0.68分 | step: 13400 | performance: 1.5 | accuracy: 0.38 | loss: 0.35
update:340/2000, 耗时:0.00分/0.69分 | step: 13600 | performance: 1.5 | accuracy: 0.38 | loss: 0.45
update:345/2000, 耗时:0.00分/0.70分 | step: 13800 | performance: 1.5 | accuracy: 0.37 | loss: 0.62
update:350/2000, 耗时:0.00分/0.71分 | step: 14000 | performance: 1.5 | accuracy: 0.37 | loss: 0.79
update:355/2000, 耗时:0.00分/0.72分 | step: 14200 | performance: 1.5 | accuracy: 0.36 | loss: 0.31
update:360/2000, 耗时:0.00分/0.73分 | step: 14400 | performance: 1.5 | accuracy: 0.36 | loss: 0.12
update:365/2000, 耗时:0.00分/0.74分 | step: 14600 | performance: 1.5 | accuracy: 0.35 | loss: 0.43
update:370/2000, 耗时:0.00分/0.75分 | step: 14800 | performance: 1.5 | accuracy: 0.35 | loss: 0.09
update:375/2000, 耗时:0.00分/0.76分 | step: 15000 | performance: 1.5 | accuracy: 0.34 | loss: 0.53
update:380/2000, 耗时:0.00分/0.77分 | step: 15200 | performance: 1.5 | accuracy: 0.34 | loss: 0.10
update:385/2000, 耗时:0.00分/0.78分 | step: 15400 | performance: 1.5 | accuracy: 0.34 | loss: 0.58
update:390/2000, 耗时:0.00分/0.79分 | step: 15600 | performance: 1.4 | accuracy: 0.33 | loss: 0.20
update:395/2000, 耗时:0.00分/0.80分 | step: 15800 | performance: 1.5 | accuracy: 0.33 | loss: 1.57
update:400/2000, 耗时:0.00分/0.81分 | step: 16000 | performance: 2.4 | accuracy: 0.33 | loss: 1.95
update:405/2000, 耗时:0.00分/0.82分 | step: 16200 | performance: 2.6 | accuracy: 0.33 | loss: 0.78
update:410/2000, 耗时:0.00分/0.83分 | step: 16400 | performance: 2.6 | accuracy: 0.34 | loss: 1.04
update:415/2000, 耗时:0.00分/0.84分 | step: 16600 | performance: 2.4 | accuracy: 0.34 | loss: 1.06
update:420/2000, 耗时:0.00分/0.85分 | step: 16800 | performance: 2.4 | accuracy: 0.33 | loss: 0.37
update:425/2000, 耗时:0.00分/0.86分 | step: 17000 | performance: 3.0 | accuracy: 0.33 | loss: 0.83
update:430/2000, 耗时:0.00分/0.87分 | step: 17200 | performance: 2.8 | accuracy: 0.33 | loss: 0.95
update:435/2000, 耗时:0.00分/0.88分 | step: 17400 | performance: 2.8 | accuracy: 0.33 | loss: 0.99
update:440/2000, 耗时:0.00分/0.89分 | step: 17600 | performance: 3.0 | accuracy: 0.33 | loss: 0.17
update:445/2000, 耗时:0.00分/0.90分 | step: 17800 | performance: 2.5 | accuracy: 0.33 | loss: 0.29
update:450/2000, 耗时:0.00分/0.91分 | step: 18000 | performance: 1.9 | accuracy: 0.32 | loss: 4.18
update:455/2000, 耗时:0.00分/0.92分 | step: 18200 | performance: 1.4 | accuracy: 0.32 | loss: 0.91
update:460/2000, 耗时:0.00分/0.93分 | step: 18400 | performance: 1.5 | accuracy: 0.32 | loss: 0.62
update:465/2000, 耗时:0.00分/0.94分 | step: 18600 | performance: 1.5 | accuracy: 0.32 | loss: 0.07
update:470/2000, 耗时:0.00分/0.95分 | step: 18800 | performance: 1.5 | accuracy: 0.31 | loss: 0.03
update:475/2000, 耗时:0.00分/0.96分 | step: 19000 | performance: 1.7 | accuracy: 0.31 | loss: 0.61
update:480/2000, 耗时:0.00分/0.97分 | step: 19200 | performance: 1.7 | accuracy: 0.31 | loss: 2.62
update:485/2000, 耗时:0.00分/0.98分 | step: 19400 | performance: 1.8 | accuracy: 0.31 | loss: 1.52
update:490/2000, 耗时:0.00分/0.99分 | step: 19600 | performance: 1.7 | accuracy: 0.31 | loss: 0.16
update:495/2000, 耗时:0.00分/1.00分 | step: 19800 | performance: 1.7 | accuracy: 0.31 | loss: 0.02
update:500/2000, 耗时:0.00分/1.01分 | step: 20000 | performance: 1.7 | accuracy: 0.31 | loss: 1.18
update:505/2000, 耗时:0.00分/1.02分 | step: 20200 | performance: 1.9 | accuracy: 0.31 | loss: 1.24
update:510/2000, 耗时:0.00分/1.03分 | step: 20400 | performance: 1.5 | accuracy: 0.31 | loss: 0.51
update:515/2000, 耗时:0.00分/1.04分 | step: 20600 | performance: 1.5 | accuracy: 0.31 | loss: 2.03
update:520/2000, 耗时:0.00分/1.05分 | step: 20800 | performance: 1.3 | accuracy: 0.31 | loss: 0.17
update:525/2000, 耗时:0.00分/1.06分 | step: 21000 | performance: 1.3 | accuracy: 0.30 | loss: 0.06
update:530/2000, 耗时:0.00分/1.07分 | step: 21200 | performance: 1.3 | accuracy: 0.30 | loss: 0.11
update:535/2000, 耗时:0.00分/1.08分 | step: 21400 | performance: 1.3 | accuracy: 0.30 | loss: 0.14
update:540/2000, 耗时:0.00分/1.09分 | step: 21600 | performance: 1.3 | accuracy: 0.30 | loss: 1.64
update:545/2000, 耗时:0.00分/1.10分 | step: 21800 | performance: 1.4 | accuracy: 0.30 | loss: 3.52
update:550/2000, 耗时:0.00分/1.12分 | step: 22000 | performance: 1.4 | accuracy: 0.30 | loss: 0.80
update:555/2000, 耗时:0.00分/1.13分 | step: 22200 | performance: 1.9 | accuracy: 0.30 | loss: 1.24
update:560/2000, 耗时:0.00分/1.14分 | step: 22400 | performance: 2.3 | accuracy: 0.30 | loss: 0.59
update:565/2000, 耗时:0.00分/1.15分 | step: 22600 | performance: 2.1 | accuracy: 0.30 | loss: 1.02
update:570/2000, 耗时:0.00分/1.16分 | step: 22800 | performance: 1.9 | accuracy: 0.30 | loss: 4.10
update:575/2000, 耗时:0.00分/1.17分 | step: 23000 | performance: 1.9 | accuracy: 0.31 | loss: 0.92
update:580/2000, 耗时:0.00分/1.18分 | step: 23200 | performance: 1.9 | accuracy: 0.30 | loss: 0.21
update:585/2000, 耗时:0.00分/1.19分 | step: 23400 | performance: 1.9 | accuracy: 0.30 | loss: 0.40
update:590/2000, 耗时:0.00分/1.20分 | step: 23600 | performance: 1.6 | accuracy: 0.30 | loss: 1.33
update:595/2000, 耗时:0.00分/1.21分 | step: 23800 | performance: 1.6 | accuracy: 0.31 | loss: 0.90
update:600/2000, 耗时:0.00分/1.22分 | step: 24000 | performance: 1.7 | accuracy: 0.31 | loss: 0.09
update:605/2000, 耗时:0.00分/1.23分 | step: 24200 | performance: 1.8 | accuracy: 0.31 | loss: 0.04
update:610/2000, 耗时:0.00分/1.24分 | step: 24400 | performance: 1.8 | accuracy: 0.30 | loss: 0.01
update:615/2000, 耗时:0.00分/1.25分 | step: 24600 | performance: 1.9 | accuracy: 0.30 | loss: 0.54
update:620/2000, 耗时:0.00分/1.26分 | step: 24800 | performance: 2.0 | accuracy: 0.30 | loss: 0.12
update:625/2000, 耗时:0.00分/1.27分 | step: 25000 | performance: 2.0 | accuracy: 0.30 | loss: 0.18
update:630/2000, 耗时:0.00分/1.28分 | step: 25200 | performance: 2.0 | accuracy: 0.30 | loss: 0.56
Saving PPO weights in both H5 format and checkpoint @ update:633 
update:635/2000, 耗时:0.00分/1.29分 | step: 25400 | performance: 1.0 | accuracy: 0.17 | loss: 0.04
step: 25433 | worker_0@n_step_4: average total_reward after train data exhaustion : 33.3 | max total_reward: 61.1
step: 25434 | worker_1@n_step_4: average total_reward after train data exhaustion : 30.0 | max total_reward: 61.1
step: 25435 | worker_2@n_step_4: average total_reward after train data exhaustion : 27.4 | max total_reward: 61.1
step: 25436 | worker_3@n_step_4: average total_reward after train data exhaustion : 25.1 | max total_reward: 61.1
step: 25437 | worker_4@n_step_4: average total_reward after train data exhaustion : 23.1 | max total_reward: 61.1
step: 25438 | worker_5@n_step_4: average total_reward after train data exhaustion : 21.4 | max total_reward: 61.1
step: 25439 | worker_6@n_step_4: average total_reward after train data exhaustion : 20.0 | max total_reward: 61.1
update:640/2000, 耗时:0.00分/1.30分 | step: 25600 | performance: 1.0 | accuracy: 0.16 | loss: 0.10
update:645/2000, 耗时:0.00分/1.31分 | step: 25800 | performance: 1.0 | accuracy: 0.11 | loss: 0.28
step: 25873 | worker_0@n_step_4: average total_reward after train data exhaustion : 10.4 | max total_reward: 61.1
step: 25876 | worker_3@n_step_4: average total_reward after train data exhaustion : 10.1 | max total_reward: 61.1
step: 25878 | worker_5@n_step_4: average total_reward after train data exhaustion : 9.7 | max total_reward: 61.1
update:650/2000, 耗时:0.00分/1.32分 | step: 26000 | performance: 0.9 | accuracy: 0.14 | loss: 0.97
update:655/2000, 耗时:0.00分/1.33分 | step: 26200 | performance: 1.0 | accuracy: 0.26 | loss: 1.34
update:660/2000, 耗时:0.00分/1.34分 | step: 26400 | performance: 1.0 | accuracy: 0.28 | loss: 1.35
update:665/2000, 耗时:0.00分/1.35分 | step: 26600 | performance: 2.0 | accuracy: 0.33 | loss: 1.45
update:670/2000, 耗时:0.00分/1.36分 | step: 26800 | performance: 2.6 | accuracy: 0.36 | loss: 2.18
update:675/2000, 耗时:0.00分/1.37分 | step: 27000 | performance: 3.3 | accuracy: 0.38 | loss: 1.41
update:680/2000, 耗时:0.00分/1.38分 | step: 27200 | performance: 2.9 | accuracy: 0.38 | loss: 2.01
update:685/2000, 耗时:0.00分/1.39分 | step: 27400 | performance: 3.3 | accuracy: 0.39 | loss: 3.23
update:690/2000, 耗时:0.00分/1.40分 | step: 27600 | performance: 3.4 | accuracy: 0.41 | loss: 2.17
update:695/2000, 耗时:0.00分/1.41分 | step: 27800 | performance: 3.8 | accuracy: 0.42 | loss: 0.94
update:700/2000, 耗时:0.00分/1.42分 | step: 28000 | performance: 3.1 | accuracy: 0.41 | loss: 0.90
update:705/2000, 耗时:0.00分/1.43分 | step: 28200 | performance: 3.2 | accuracy: 0.41 | loss: 0.69
update:710/2000, 耗时:0.00分/1.44分 | step: 28400 | performance: 3.1 | accuracy: 0.41 | loss: 1.13
update:715/2000, 耗时:0.00分/1.45分 | step: 28600 | performance: 3.0 | accuracy: 0.41 | loss: 2.13
update:720/2000, 耗时:0.00分/1.46分 | step: 28800 | performance: 1.9 | accuracy: 0.40 | loss: 1.49
update:725/2000, 耗时:0.00分/1.47分 | step: 29000 | performance: 1.9 | accuracy: 0.39 | loss: 1.25
update:730/2000, 耗时:0.00分/1.48分 | step: 29200 | performance: 1.6 | accuracy: 0.39 | loss: 1.77
update:735/2000, 耗时:0.00分/1.49分 | step: 29400 | performance: 1.2 | accuracy: 0.39 | loss: 1.27
update:740/2000, 耗时:0.00分/1.50分 | step: 29600 | performance: 1.3 | accuracy: 0.39 | loss: 2.34
update:745/2000, 耗时:0.00分/1.51分 | step: 29800 | performance: 1.2 | accuracy: 0.37 | loss: 1.92
update:750/2000, 耗时:0.00分/1.52分 | step: 30000 | performance: 0.9 | accuracy: 0.36 | loss: 1.75
update:755/2000, 耗时:0.00分/1.53分 | step: 30200 | performance: 0.8 | accuracy: 0.37 | loss: 2.40
update:760/2000, 耗时:0.00分/1.54分 | step: 30400 | performance: 0.9 | accuracy: 0.37 | loss: 2.13
update:765/2000, 耗时:0.00分/1.55分 | step: 30600 | performance: 1.0 | accuracy: 0.38 | loss: 2.52
update:770/2000, 耗时:0.00分/1.56分 | step: 30800 | performance: 0.8 | accuracy: 0.38 | loss: 1.65
update:775/2000, 耗时:0.00分/1.57分 | step: 31000 | performance: 1.0 | accuracy: 0.38 | loss: 1.59
update:780/2000, 耗时:0.00分/1.58分 | step: 31200 | performance: 0.9 | accuracy: 0.38 | loss: 2.35
update:785/2000, 耗时:0.00分/1.59分 | step: 31400 | performance: 1.0 | accuracy: 0.39 | loss: 2.69
update:790/2000, 耗时:0.00分/1.60分 | step: 31600 | performance: 1.6 | accuracy: 0.39 | loss: 0.99
update:795/2000, 耗时:0.00分/1.61分 | step: 31800 | performance: 1.6 | accuracy: 0.40 | loss: 1.16
update:800/2000, 耗时:0.00分/1.62分 | step: 32000 | performance: 1.3 | accuracy: 0.40 | loss: 1.36
update:805/2000, 耗时:0.00分/1.63分 | step: 32200 | performance: 1.4 | accuracy: 0.40 | loss: 1.18
update:810/2000, 耗时:0.00分/1.64分 | step: 32400 | performance: 1.8 | accuracy: 0.40 | loss: 1.27
update:815/2000, 耗时:0.00分/1.65分 | step: 32600 | performance: 2.3 | accuracy: 0.41 | loss: 2.91
update:820/2000, 耗时:0.00分/1.66分 | step: 32800 | performance: 2.5 | accuracy: 0.41 | loss: 1.45
update:825/2000, 耗时:0.00分/1.67分 | step: 33000 | performance: 2.4 | accuracy: 0.42 | loss: 2.94
update:830/2000, 耗时:0.00分/1.68分 | step: 33200 | performance: 2.1 | accuracy: 0.42 | loss: 1.50
update:835/2000, 耗时:0.00分/1.69分 | step: 33400 | performance: 1.8 | accuracy: 0.42 | loss: 1.56
update:840/2000, 耗时:0.00分/1.70分 | step: 33600 | performance: 1.6 | accuracy: 0.42 | loss: 1.91
update:845/2000, 耗时:0.00分/1.71分 | step: 33800 | performance: 1.4 | accuracy: 0.42 | loss: 1.36
update:850/2000, 耗时:0.00分/1.72分 | step: 34000 | performance: 1.9 | accuracy: 0.42 | loss: 1.22
update:855/2000, 耗时:0.00分/1.73分 | step: 34200 | performance: 3.1 | accuracy: 0.43 | loss: 1.27
update:860/2000, 耗时:0.00分/1.74分 | step: 34400 | performance: 3.4 | accuracy: 0.43 | loss: 1.65
update:865/2000, 耗时:0.00分/1.75分 | step: 34600 | performance: 3.3 | accuracy: 0.43 | loss: 3.06
update:870/2000, 耗时:0.00分/1.76分 | step: 34800 | performance: 3.1 | accuracy: 0.43 | loss: 3.40
update:875/2000, 耗时:0.00分/1.77分 | step: 35000 | performance: 2.1 | accuracy: 0.42 | loss: 1.29
update:880/2000, 耗时:0.00分/1.78分 | step: 35200 | performance: 2.0 | accuracy: 0.43 | loss: 1.83
update:885/2000, 耗时:0.00分/1.79分 | step: 35400 | performance: 2.2 | accuracy: 0.43 | loss: 1.01
update:890/2000, 耗时:0.00分/1.80分 | step: 35600 | performance: 1.9 | accuracy: 0.42 | loss: 1.72
update:895/2000, 耗时:0.00分/1.81分 | step: 35800 | performance: 2.1 | accuracy: 0.43 | loss: 2.09
update:900/2000, 耗时:0.00分/1.82分 | step: 36000 | performance: 2.2 | accuracy: 0.43 | loss: 1.34
update:905/2000, 耗时:0.00分/1.83分 | step: 36200 | performance: 2.2 | accuracy: 0.43 | loss: 1.76
update:910/2000, 耗时:0.00分/1.84分 | step: 36400 | performance: 1.7 | accuracy: 0.42 | loss: 1.13
update:915/2000, 耗时:0.00分/1.85分 | step: 36600 | performance: 1.5 | accuracy: 0.42 | loss: 1.94
update:920/2000, 耗时:0.00分/1.86分 | step: 36800 | performance: 1.5 | accuracy: 0.42 | loss: 1.57
update:925/2000, 耗时:0.00分/1.87分 | step: 37000 | performance: 1.7 | accuracy: 0.42 | loss: 1.50
update:930/2000, 耗时:0.00分/1.88分 | step: 37200 | performance: 1.9 | accuracy: 0.42 | loss: 1.16
update:935/2000, 耗时:0.00分/1.89分 | step: 37400 | performance: 1.9 | accuracy: 0.42 | loss: 1.42
update:940/2000, 耗时:0.00分/1.90分 | step: 37600 | performance: 1.8 | accuracy: 0.42 | loss: 1.80
update:945/2000, 耗时:0.00分/1.91分 | step: 37800 | performance: 1.4 | accuracy: 0.42 | loss: 2.09
update:950/2000, 耗时:0.00分/1.92分 | step: 38000 | performance: 1.2 | accuracy: 0.42 | loss: 1.30
update:955/2000, 耗时:0.00分/1.93分 | step: 38200 | performance: 0.9 | accuracy: 0.42 | loss: 2.26
update:960/2000, 耗时:0.00分/1.94分 | step: 38400 | performance: 0.8 | accuracy: 0.42 | loss: 1.51
update:965/2000, 耗时:0.00分/1.95分 | step: 38600 | performance: 0.8 | accuracy: 0.42 | loss: 2.49
update:970/2000, 耗时:0.00分/1.96分 | step: 38800 | performance: 0.5 | accuracy: 0.42 | loss: 2.37
update:975/2000, 耗时:0.00分/1.97分 | step: 39000 | performance: 0.2 | accuracy: 0.41 | loss: 2.49
update:980/2000, 耗时:0.00分/1.98分 | step: 39200 | performance: 0.2 | accuracy: 0.41 | loss: 2.09
update:985/2000, 耗时:0.00分/1.99分 | step: 39400 | performance: 0.2 | accuracy: 0.42 | loss: 2.74
update:990/2000, 耗时:0.00分/2.00分 | step: 39600 | performance: 0.1 | accuracy: 0.41 | loss: 2.97
update:995/2000, 耗时:0.00分/2.01分 | step: 39800 | performance: 0.1 | accuracy: 0.41 | loss: 1.53
update:1000/2000, 耗时:0.00分/2.02分 | step: 40000 | performance: 0.1 | accuracy: 0.41 | loss: 1.21
update:1005/2000, 耗时:0.00分/2.03分 | step: 40200 | performance: 0.1 | accuracy: 0.41 | loss: 1.26
update:1010/2000, 耗时:0.00分/2.05分 | step: 40400 | performance: 0.1 | accuracy: 0.41 | loss: 2.11
update:1015/2000, 耗时:0.00分/2.06分 | step: 40600 | performance: 0.1 | accuracy: 0.41 | loss: 2.33
update:1020/2000, 耗时:0.00分/2.07分 | step: 40800 | performance: 0.1 | accuracy: 0.42 | loss: 0.91
update:1025/2000, 耗时:0.00分/2.08分 | step: 41000 | performance: 0.1 | accuracy: 0.42 | loss: 1.65
update:1030/2000, 耗时:0.00分/2.09分 | step: 41200 | performance: 0.3 | accuracy: 0.42 | loss: 1.51
update:1035/2000, 耗时:0.00分/2.10分 | step: 41400 | performance: 0.3 | accuracy: 0.42 | loss: 3.13
update:1040/2000, 耗时:0.00分/2.11分 | step: 41600 | performance: 0.3 | accuracy: 0.42 | loss: 1.48
update:1045/2000, 耗时:0.00分/2.12分 | step: 41800 | performance: 0.3 | accuracy: 0.42 | loss: 0.85
update:1050/2000, 耗时:0.00分/2.13分 | step: 42000 | performance: 0.4 | accuracy: 0.42 | loss: 1.55
update:1055/2000, 耗时:0.00分/2.14分 | step: 42200 | performance: 0.3 | accuracy: 0.42 | loss: 2.01
update:1060/2000, 耗时:0.00分/2.15分 | step: 42400 | performance: 0.2 | accuracy: 0.42 | loss: 2.42
update:1065/2000, 耗时:0.00分/2.16分 | step: 42600 | performance: 0.2 | accuracy: 0.43 | loss: 2.90
update:1070/2000, 耗时:0.00分/2.17分 | step: 42800 | performance: 0.2 | accuracy: 0.43 | loss: 2.70
update:1075/2000, 耗时:0.00分/2.18分 | step: 43000 | performance: 0.2 | accuracy: 0.43 | loss: 2.47
update:1080/2000, 耗时:0.00分/2.19分 | step: 43200 | performance: 0.3 | accuracy: 0.43 | loss: 2.14
update:1085/2000, 耗时:0.00分/2.20分 | step: 43400 | performance: 0.2 | accuracy: 0.42 | loss: 2.11
update:1090/2000, 耗时:0.00分/2.21分 | step: 43600 | performance: 0.1 | accuracy: 0.42 | loss: 1.22
update:1095/2000, 耗时:0.00分/2.22分 | step: 43800 | performance: 0.1 | accuracy: 0.42 | loss: 1.84
update:1100/2000, 耗时:0.00分/2.23分 | step: 44000 | performance: 0.1 | accuracy: 0.43 | loss: 1.64
update:1105/2000, 耗时:0.00分/2.24分 | step: 44200 | performance: 0.2 | accuracy: 0.43 | loss: 0.92
update:1110/2000, 耗时:0.00分/2.25分 | step: 44400 | performance: 0.2 | accuracy: 0.43 | loss: 1.15
update:1115/2000, 耗时:0.00分/2.26分 | step: 44600 | performance: 0.2 | accuracy: 0.43 | loss: 1.41
update:1120/2000, 耗时:0.00分/2.27分 | step: 44800 | performance: 0.3 | accuracy: 0.43 | loss: 1.02
update:1125/2000, 耗时:0.00分/2.28分 | step: 45000 | performance: 0.3 | accuracy: 0.43 | loss: 2.50
update:1130/2000, 耗时:0.00分/2.29分 | step: 45200 | performance: 0.4 | accuracy: 0.43 | loss: 0.62
update:1135/2000, 耗时:0.00分/2.30分 | step: 45400 | performance: 0.3 | accuracy: 0.43 | loss: 1.32
update:1140/2000, 耗时:0.00分/2.31分 | step: 45600 | performance: 0.4 | accuracy: 0.43 | loss: 1.73
update:1145/2000, 耗时:0.00分/2.32分 | step: 45800 | performance: 0.4 | accuracy: 0.43 | loss: 2.78
update:1150/2000, 耗时:0.00分/2.33分 | step: 46000 | performance: 0.4 | accuracy: 0.43 | loss: 2.06
update:1155/2000, 耗时:0.00分/2.34分 | step: 46200 | performance: 0.3 | accuracy: 0.43 | loss: 1.44
update:1160/2000, 耗时:0.00分/2.35分 | step: 46400 | performance: 0.4 | accuracy: 0.44 | loss: 0.91
update:1165/2000, 耗时:0.00分/2.36分 | step: 46600 | performance: 0.4 | accuracy: 0.44 | loss: 1.34
update:1170/2000, 耗时:0.00分/2.37分 | step: 46800 | performance: 0.6 | accuracy: 0.44 | loss: 1.13
update:1175/2000, 耗时:0.00分/2.38分 | step: 47000 | performance: 0.9 | accuracy: 0.44 | loss: 0.78
update:1180/2000, 耗时:0.00分/2.39分 | step: 47200 | performance: 0.8 | accuracy: 0.44 | loss: 0.84
update:1185/2000, 耗时:0.00分/2.40分 | step: 47400 | performance: 1.7 | accuracy: 0.44 | loss: 2.91
update:1190/2000, 耗时:0.00分/2.41分 | step: 47600 | performance: 1.8 | accuracy: 0.44 | loss: 1.77
update:1195/2000, 耗时:0.00分/2.43分 | step: 47800 | performance: 1.8 | accuracy: 0.44 | loss: 1.81
update:1200/2000, 耗时:0.00分/2.44分 | step: 48000 | performance: 1.6 | accuracy: 0.44 | loss: 1.33
update:1205/2000, 耗时:0.00分/2.45分 | step: 48200 | performance: 1.6 | accuracy: 0.44 | loss: 2.20
update:1210/2000, 耗时:0.00分/2.46分 | step: 48400 | performance: 1.5 | accuracy: 0.44 | loss: 1.80
update:1215/2000, 耗时:0.00分/2.47分 | step: 48600 | performance: 2.3 | accuracy: 0.45 | loss: 1.39
update:1220/2000, 耗时:0.00分/2.48分 | step: 48800 | performance: 2.0 | accuracy: 0.45 | loss: 1.38
update:1225/2000, 耗时:0.00分/2.49分 | step: 49000 | performance: 2.6 | accuracy: 0.45 | loss: 1.68
update:1230/2000, 耗时:0.00分/2.50分 | step: 49200 | performance: 2.4 | accuracy: 0.45 | loss: 1.26
update:1235/2000, 耗时:0.00分/2.51分 | step: 49400 | performance: 2.6 | accuracy: 0.45 | loss: 2.05
update:1240/2000, 耗时:0.00分/2.52分 | step: 49600 | performance: 2.4 | accuracy: 0.45 | loss: 1.23
update:1245/2000, 耗时:0.00分/2.53分 | step: 49800 | performance: 3.7 | accuracy: 0.45 | loss: 0.77
update:1250/2000, 耗时:0.00分/2.54分 | step: 50000 | performance: 3.9 | accuracy: 0.45 | loss: 1.74
update:1255/2000, 耗时:0.00分/2.55分 | step: 50200 | performance: 3.9 | accuracy: 0.45 | loss: 1.19
update:1260/2000, 耗时:0.00分/2.56分 | step: 50400 | performance: 4.1 | accuracy: 0.45 | loss: 2.15
update:1265/2000, 耗时:0.00分/2.57分 | step: 50600 | performance: 4.2 | accuracy: 0.45 | loss: 0.83
update:1270/2000, 耗时:0.00分/2.58分 | step: 50800 | performance: 1.3 | accuracy: 0.62 | loss: 0.64
step: 50875 | worker_2@n_step_4: average total_reward after train data exhaustion : 4.6 | max total_reward: 61.1
step: 50879 | worker_6@n_step_4: average total_reward after train data exhaustion : 2.4 | max total_reward: 61.1
update:1275/2000, 耗时:0.00分/2.60分 | step: 51000 | performance: 1.3 | accuracy: 0.57 | loss: 0.85
update:1280/2000, 耗时:0.00分/2.61分 | step: 51200 | performance: 1.3 | accuracy: 0.55 | loss: 0.47
step: 51314 | worker_1@n_step_4: average total_reward after train data exhaustion : -6.9 | max total_reward: 61.1
update:1285/2000, 耗时:0.00分/2.62分 | step: 51400 | performance: 1.3 | accuracy: 0.54 | loss: 1.07
update:1290/2000, 耗时:0.00分/2.63分 | step: 51600 | performance: 1.5 | accuracy: 0.55 | loss: 0.99
update:1295/2000, 耗时:0.00分/2.64分 | step: 51800 | performance: 1.9 | accuracy: 0.53 | loss: 2.85
update:1300/2000, 耗时:0.00分/2.65分 | step: 52000 | performance: 3.4 | accuracy: 0.53 | loss: 1.89
update:1305/2000, 耗时:0.00分/2.66分 | step: 52200 | performance: 5.6 | accuracy: 0.55 | loss: 1.38
update:1310/2000, 耗时:0.00分/2.67分 | step: 52400 | performance: 4.1 | accuracy: 0.53 | loss: 2.02
update:1315/2000, 耗时:0.00分/2.68分 | step: 52600 | performance: 4.7 | accuracy: 0.53 | loss: 2.00
update:1320/2000, 耗时:0.00分/2.69分 | step: 52800 | performance: 5.3 | accuracy: 0.53 | loss: 0.76
update:1325/2000, 耗时:0.00分/2.70分 | step: 53000 | performance: 6.0 | accuracy: 0.54 | loss: 0.78
update:1330/2000, 耗时:0.00分/2.71分 | step: 53200 | performance: 5.6 | accuracy: 0.53 | loss: 1.12
update:1335/2000, 耗时:0.00分/2.72分 | step: 53400 | performance: 4.8 | accuracy: 0.51 | loss: 1.31
update:1340/2000, 耗时:0.00分/2.73分 | step: 53600 | performance: 5.1 | accuracy: 0.50 | loss: 1.61
update:1345/2000, 耗时:0.00分/2.74分 | step: 53800 | performance: 4.9 | accuracy: 0.49 | loss: 1.30
update:1350/2000, 耗时:0.00分/2.75分 | step: 54000 | performance: 3.4 | accuracy: 0.48 | loss: 1.67
update:1355/2000, 耗时:0.00分/2.76分 | step: 54200 | performance: 3.2 | accuracy: 0.47 | loss: 1.04
update:1360/2000, 耗时:0.00分/2.78分 | step: 54400 | performance: 3.0 | accuracy: 0.47 | loss: 1.03
update:1365/2000, 耗时:0.00分/2.79分 | step: 54600 | performance: 2.2 | accuracy: 0.46 | loss: 2.37
update:1370/2000, 耗时:0.00分/2.80分 | step: 54800 | performance: 1.5 | accuracy: 0.46 | loss: 1.24
update:1375/2000, 耗时:0.00分/2.81分 | step: 55000 | performance: 1.5 | accuracy: 0.46 | loss: 1.71
update:1380/2000, 耗时:0.00分/2.82分 | step: 55200 | performance: 1.1 | accuracy: 0.45 | loss: 3.72
update:1385/2000, 耗时:0.00分/2.83分 | step: 55400 | performance: 0.7 | accuracy: 0.45 | loss: 1.19
update:1390/2000, 耗时:0.00分/2.84分 | step: 55600 | performance: 0.7 | accuracy: 0.45 | loss: 2.10
update:1395/2000, 耗时:0.00分/2.85分 | step: 55800 | performance: 1.1 | accuracy: 0.45 | loss: 1.76
update:1400/2000, 耗时:0.00分/2.86分 | step: 56000 | performance: 0.7 | accuracy: 0.45 | loss: 3.66
update:1405/2000, 耗时:0.00分/2.87分 | step: 56200 | performance: 1.0 | accuracy: 0.45 | loss: 1.97
update:1410/2000, 耗时:0.00分/2.88分 | step: 56400 | performance: 1.2 | accuracy: 0.45 | loss: 1.84
update:1415/2000, 耗时:0.00分/2.89分 | step: 56600 | performance: 1.1 | accuracy: 0.45 | loss: 0.72
update:1420/2000, 耗时:0.00分/2.90分 | step: 56800 | performance: 1.6 | accuracy: 0.46 | loss: 2.49
update:1425/2000, 耗时:0.00分/2.91分 | step: 57000 | performance: 1.8 | accuracy: 0.46 | loss: 0.69
update:1430/2000, 耗时:0.00分/2.92分 | step: 57200 | performance: 1.9 | accuracy: 0.46 | loss: 0.97
update:1435/2000, 耗时:0.00分/2.93分 | step: 57400 | performance: 1.5 | accuracy: 0.46 | loss: 1.59
update:1440/2000, 耗时:0.00分/2.94分 | step: 57600 | performance: 1.7 | accuracy: 0.46 | loss: 1.62
update:1445/2000, 耗时:0.00分/2.95分 | step: 57800 | performance: 2.5 | accuracy: 0.46 | loss: 1.02
update:1450/2000, 耗时:0.00分/2.96分 | step: 58000 | performance: 2.4 | accuracy: 0.47 | loss: 1.72
update:1455/2000, 耗时:0.00分/2.97分 | step: 58200 | performance: 2.7 | accuracy: 0.47 | loss: 1.40
update:1460/2000, 耗时:0.00分/2.98分 | step: 58400 | performance: 2.7 | accuracy: 0.47 | loss: 1.48
update:1465/2000, 耗时:0.00分/2.99分 | step: 58600 | performance: 1.9 | accuracy: 0.47 | loss: 2.49
update:1470/2000, 耗时:0.00分/3.00分 | step: 58800 | performance: 1.8 | accuracy: 0.47 | loss: 1.56
update:1475/2000, 耗时:0.00分/3.01分 | step: 59000 | performance: 1.5 | accuracy: 0.47 | loss: 1.62
update:1480/2000, 耗时:0.00分/3.02分 | step: 59200 | performance: 1.7 | accuracy: 0.47 | loss: 1.21
update:1485/2000, 耗时:0.00分/3.03分 | step: 59400 | performance: 1.9 | accuracy: 0.47 | loss: 1.58
update:1490/2000, 耗时:0.00分/3.04分 | step: 59600 | performance: 6.0 | accuracy: 0.47 | loss: 1.17
update:1495/2000, 耗时:0.00分/3.05分 | step: 59800 | performance: 4.1 | accuracy: 0.47 | loss: 2.06
update:1500/2000, 耗时:0.00分/3.06分 | step: 60000 | performance: 3.6 | accuracy: 0.47 | loss: 1.31
update:1505/2000, 耗时:0.00分/3.07分 | step: 60200 | performance: 3.1 | accuracy: 0.47 | loss: 2.91
update:1510/2000, 耗时:0.00分/3.08分 | step: 60400 | performance: 2.1 | accuracy: 0.47 | loss: 1.40
update:1515/2000, 耗时:0.00分/3.09分 | step: 60600 | performance: 1.9 | accuracy: 0.47 | loss: 1.40
update:1520/2000, 耗时:0.00分/3.11分 | step: 60800 | performance: 2.1 | accuracy: 0.47 | loss: 2.22
update:1525/2000, 耗时:0.00分/3.12分 | step: 61000 | performance: 2.2 | accuracy: 0.46 | loss: 1.49
update:1530/2000, 耗时:0.00分/3.13分 | step: 61200 | performance: 2.3 | accuracy: 0.47 | loss: 1.31
update:1535/2000, 耗时:0.00分/3.14分 | step: 61400 | performance: 2.3 | accuracy: 0.47 | loss: 0.79
update:1540/2000, 耗时:0.00分/3.15分 | step: 61600 | performance: 2.4 | accuracy: 0.47 | loss: 1.47
update:1545/2000, 耗时:0.00分/3.16分 | step: 61800 | performance: 1.7 | accuracy: 0.46 | loss: 2.51
update:1550/2000, 耗时:0.00分/3.17分 | step: 62000 | performance: 1.6 | accuracy: 0.46 | loss: 1.14
update:1555/2000, 耗时:0.00分/3.18分 | step: 62200 | performance: 1.8 | accuracy: 0.46 | loss: 1.03
update:1560/2000, 耗时:0.00分/3.19分 | step: 62400 | performance: 2.2 | accuracy: 0.46 | loss: 1.09
update:1565/2000, 耗时:0.00分/3.20分 | step: 62600 | performance: 2.1 | accuracy: 0.46 | loss: 1.43
update:1570/2000, 耗时:0.00分/3.21分 | step: 62800 | performance: 2.2 | accuracy: 0.46 | loss: 0.90
update:1575/2000, 耗时:0.00分/3.22分 | step: 63000 | performance: 1.9 | accuracy: 0.46 | loss: 1.30
update:1580/2000, 耗时:0.00分/3.23分 | step: 63200 | performance: 1.5 | accuracy: 0.46 | loss: 1.09
update:1585/2000, 耗时:0.00分/3.24分 | step: 63400 | performance: 1.1 | accuracy: 0.45 | loss: 1.18
update:1590/2000, 耗时:0.00分/3.25分 | step: 63600 | performance: 0.8 | accuracy: 0.45 | loss: 1.89
update:1595/2000, 耗时:0.00分/3.26分 | step: 63800 | performance: 0.8 | accuracy: 0.45 | loss: 2.11
update:1600/2000, 耗时:0.00分/3.27分 | step: 64000 | performance: 0.5 | accuracy: 0.45 | loss: 2.20
update:1605/2000, 耗时:0.00分/3.28分 | step: 64200 | performance: 0.4 | accuracy: 0.45 | loss: 1.46
update:1610/2000, 耗时:0.00分/3.29分 | step: 64400 | performance: 0.2 | accuracy: 0.44 | loss: 2.66
update:1615/2000, 耗时:0.00分/3.30分 | step: 64600 | performance: 0.3 | accuracy: 0.45 | loss: 2.53
update:1620/2000, 耗时:0.00分/3.31分 | step: 64800 | performance: 0.2 | accuracy: 0.44 | loss: 2.60
update:1625/2000, 耗时:0.00分/3.32分 | step: 65000 | performance: 0.1 | accuracy: 0.44 | loss: 1.01
update:1630/2000, 耗时:0.00分/3.33分 | step: 65200 | performance: 0.1 | accuracy: 0.45 | loss: 1.39
update:1635/2000, 耗时:0.00分/3.34分 | step: 65400 | performance: 0.1 | accuracy: 0.44 | loss: 2.16
update:1640/2000, 耗时:0.00分/3.36分 | step: 65600 | performance: 0.1 | accuracy: 0.44 | loss: 2.06
update:1645/2000, 耗时:0.00分/3.37分 | step: 65800 | performance: 0.1 | accuracy: 0.44 | loss: 1.34
update:1650/2000, 耗时:0.00分/3.38分 | step: 66000 | performance: 0.1 | accuracy: 0.44 | loss: 1.44
update:1655/2000, 耗时:0.00分/3.39分 | step: 66200 | performance: 0.1 | accuracy: 0.44 | loss: 1.64
update:1660/2000, 耗时:0.00分/3.40分 | step: 66400 | performance: 0.2 | accuracy: 0.44 | loss: 2.05
update:1665/2000, 耗时:0.00分/3.41分 | step: 66600 | performance: 0.3 | accuracy: 0.45 | loss: 1.92
update:1670/2000, 耗时:0.00分/3.42分 | step: 66800 | performance: 0.3 | accuracy: 0.45 | loss: 1.31
update:1675/2000, 耗时:0.00分/3.43分 | step: 67000 | performance: 0.4 | accuracy: 0.45 | loss: 2.60
update:1680/2000, 耗时:0.00分/3.45分 | step: 67200 | performance: 0.4 | accuracy: 0.45 | loss: 1.62
update:1685/2000, 耗时:0.00分/3.46分 | step: 67400 | performance: 0.4 | accuracy: 0.45 | loss: 2.11
update:1690/2000, 耗时:0.00分/3.47分 | step: 67600 | performance: 0.3 | accuracy: 0.45 | loss: 1.65
update:1695/2000, 耗时:0.00分/3.48分 | step: 67800 | performance: 0.2 | accuracy: 0.45 | loss: 2.01
update:1700/2000, 耗时:0.00分/3.49分 | step: 68000 | performance: 0.2 | accuracy: 0.45 | loss: 2.18
update:1705/2000, 耗时:0.00分/3.50分 | step: 68200 | performance: 0.2 | accuracy: 0.45 | loss: 1.62
update:1710/2000, 耗时:0.00分/3.51分 | step: 68400 | performance: 0.2 | accuracy: 0.45 | loss: 1.09
update:1715/2000, 耗时:0.00分/3.52分 | step: 68600 | performance: 0.2 | accuracy: 0.45 | loss: 1.90
update:1720/2000, 耗时:0.00分/3.53分 | step: 68800 | performance: 0.2 | accuracy: 0.45 | loss: 1.82
update:1725/2000, 耗时:0.00分/3.54分 | step: 69000 | performance: 0.1 | accuracy: 0.45 | loss: 2.17
update:1730/2000, 耗时:0.00分/3.56分 | step: 69200 | performance: 0.1 | accuracy: 0.45 | loss: 1.29
update:1735/2000, 耗时:0.00分/3.57分 | step: 69400 | performance: 0.2 | accuracy: 0.45 | loss: 1.81
update:1740/2000, 耗时:0.00分/3.58分 | step: 69600 | performance: 0.2 | accuracy: 0.45 | loss: 1.29
update:1745/2000, 耗时:0.00分/3.59分 | step: 69800 | performance: 0.2 | accuracy: 0.45 | loss: 1.26
update:1750/2000, 耗时:0.00分/3.60分 | step: 70000 | performance: 0.2 | accuracy: 0.45 | loss: 1.61
update:1755/2000, 耗时:0.00分/3.61分 | step: 70200 | performance: 0.3 | accuracy: 0.45 | loss: 1.67
update:1760/2000, 耗时:0.00分/3.62分 | step: 70400 | performance: 0.5 | accuracy: 0.45 | loss: 1.77
update:1765/2000, 耗时:0.00分/3.63分 | step: 70600 | performance: 0.5 | accuracy: 0.45 | loss: 2.26
update:1770/2000, 耗时:0.00分/3.64分 | step: 70800 | performance: 0.3 | accuracy: 0.45 | loss: 1.24
update:1775/2000, 耗时:0.00分/3.65分 | step: 71000 | performance: 0.4 | accuracy: 0.45 | loss: 1.09
update:1780/2000, 耗时:0.00分/3.66分 | step: 71200 | performance: 0.5 | accuracy: 0.45 | loss: 1.82
update:1785/2000, 耗时:0.00分/3.67分 | step: 71400 | performance: 0.4 | accuracy: 0.45 | loss: 1.92
update:1790/2000, 耗时:0.00分/3.68分 | step: 71600 | performance: 0.4 | accuracy: 0.46 | loss: 2.58
update:1795/2000, 耗时:0.00分/3.70分 | step: 71800 | performance: 0.4 | accuracy: 0.46 | loss: 1.10
update:1800/2000, 耗时:0.00分/3.71分 | step: 72000 | performance: 0.5 | accuracy: 0.46 | loss: 0.91
update:1805/2000, 耗时:0.00分/3.72分 | step: 72200 | performance: 0.9 | accuracy: 0.46 | loss: 0.88
update:1810/2000, 耗时:0.00分/3.73分 | step: 72400 | performance: 1.0 | accuracy: 0.46 | loss: 2.47
update:1815/2000, 耗时:0.00分/3.74分 | step: 72600 | performance: 0.9 | accuracy: 0.46 | loss: 1.12
update:1820/2000, 耗时:0.00分/3.75分 | step: 72800 | performance: 2.0 | accuracy: 0.46 | loss: 1.41
update:1825/2000, 耗时:0.00分/3.76分 | step: 73000 | performance: 2.4 | accuracy: 0.46 | loss: 1.20
update:1830/2000, 耗时:0.00分/3.77分 | step: 73200 | performance: 2.1 | accuracy: 0.46 | loss: 2.25
update:1835/2000, 耗时:0.00分/3.78分 | step: 73400 | performance: 1.7 | accuracy: 0.46 | loss: 2.33
update:1840/2000, 耗时:0.00分/3.79分 | step: 73600 | performance: 1.7 | accuracy: 0.46 | loss: 1.16
update:1845/2000, 耗时:0.00分/3.80分 | step: 73800 | performance: 2.1 | accuracy: 0.46 | loss: 0.89
update:1850/2000, 耗时:0.00分/3.81分 | step: 74000 | performance: 2.5 | accuracy: 0.47 | loss: 1.62
update:1855/2000, 耗时:0.00分/3.82分 | step: 74200 | performance: 2.6 | accuracy: 0.46 | loss: 0.77
update:1860/2000, 耗时:0.00分/3.83分 | step: 74400 | performance: 2.7 | accuracy: 0.47 | loss: 1.41
update:1865/2000, 耗时:0.00分/3.84分 | step: 74600 | performance: 2.9 | accuracy: 0.47 | loss: 1.29
update:1870/2000, 耗时:0.00分/3.85分 | step: 74800 | performance: 2.9 | accuracy: 0.47 | loss: 1.28
update:1875/2000, 耗时:0.00分/3.87分 | step: 75000 | performance: 2.4 | accuracy: 0.47 | loss: 1.40
update:1880/2000, 耗时:0.00分/3.88分 | step: 75200 | performance: 4.1 | accuracy: 0.47 | loss: 1.45
update:1885/2000, 耗时:0.00分/3.89分 | step: 75400 | performance: 4.0 | accuracy: 0.47 | loss: 1.82
update:1890/2000, 耗时:0.00分/3.90分 | step: 75600 | performance: 4.0 | accuracy: 0.47 | loss: 0.90
update:1895/2000, 耗时:0.00分/3.91分 | step: 75800 | performance: 4.4 | accuracy: 0.47 | loss: 0.69
update:1900/2000, 耗时:0.00分/3.92分 | step: 76000 | performance: 1.3 | accuracy: 0.73 | loss: 1.10
update:1905/2000, 耗时:0.00分/3.93分 | step: 76200 | performance: 1.3 | accuracy: 0.56 | loss: 1.95
step: 76317 | worker_4@n_step_4: average total_reward after train data exhaustion : -12.3 | max total_reward: 61.1
update:1910/2000, 耗时:0.00分/3.94分 | step: 76400 | performance: 1.3 | accuracy: 0.61 | loss: 0.91
update:1915/2000, 耗时:0.00分/3.95分 | step: 76600 | performance: 1.3 | accuracy: 0.52 | loss: 0.90
update:1920/2000, 耗时:0.00分/3.96分 | step: 76800 | performance: 1.4 | accuracy: 0.55 | loss: 2.06
update:1925/2000, 耗时:0.00分/3.97分 | step: 77000 | performance: 1.5 | accuracy: 0.54 | loss: 1.57
update:1930/2000, 耗时:0.00分/3.98分 | step: 77200 | performance: 3.1 | accuracy: 0.54 | loss: 0.81
update:1935/2000, 耗时:0.00分/3.99分 | step: 77400 | performance: 4.1 | accuracy: 0.54 | loss: 1.96
update:1940/2000, 耗时:0.00分/4.00分 | step: 77600 | performance: 5.7 | accuracy: 0.55 | loss: 1.14
update:1945/2000, 耗时:0.00分/4.01分 | step: 77800 | performance: 4.8 | accuracy: 0.53 | loss: 1.37
update:1950/2000, 耗时:0.00分/4.02分 | step: 78000 | performance: 5.3 | accuracy: 0.52 | loss: 1.64
update:1955/2000, 耗时:0.00分/4.03分 | step: 78200 | performance: 5.6 | accuracy: 0.53 | loss: 2.92
update:1960/2000, 耗时:0.00分/4.04分 | step: 78400 | performance: 6.0 | accuracy: 0.53 | loss: 1.21
update:1965/2000, 耗时:0.00分/4.05分 | step: 78600 | performance: 5.4 | accuracy: 0.52 | loss: 0.70
update:1970/2000, 耗时:0.00分/4.06分 | step: 78800 | performance: 5.2 | accuracy: 0.50 | loss: 0.73
update:1975/2000, 耗时:0.00分/4.07分 | step: 79000 | performance: 5.1 | accuracy: 0.50 | loss: 1.09
update:1980/2000, 耗时:0.00分/4.08分 | step: 79200 | performance: 4.9 | accuracy: 0.49 | loss: 1.94
update:1985/2000, 耗时:0.00分/4.09分 | step: 79400 | performance: 3.0 | accuracy: 0.48 | loss: 0.85
update:1990/2000, 耗时:0.00分/4.10分 | step: 79600 | performance: 3.1 | accuracy: 0.47 | loss: 2.29
update:1995/2000, 耗时:0.00分/4.11分 | step: 79800 | performance: 2.6 | accuracy: 0.46 | loss: 1.51
  0%|          | 0/397 [00:00<?, ?it/s]100%|| 397/397 [00:00<00:00, 132185.34it/s]
update:2000/2000, 耗时:0.00分/4.12分 | step: 80000 | performance: 1.4 | accuracy: 0.46 | loss: 1.14
----------------------------------------finished----------------------------------------
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1000.00
2023-07-24T12:00:00 | net performance [%] = 0.0000
2023-07-24T12:00:00 | number of trades [#] = 0
==================================================
Trial 42 Complete [00h 04m 34s]
net_wealth: 1000.0

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 05h 29m 49s

Search: Running Trial #43

Value             |Best Value So Far |Hyperparameter
1                 |7                 |horizon
225               |730               |lookback
False             |False             |MarketFactor
20                |14                |lags
0.7               |0.7               |gamma
16                |32                |batch_size
32                |32                |n_step
0.92              |0.92              |gae_lambda
1                 |0.1               |gradient_clip_norm
5                 |5                 |epochs
5e-05             |0.0001            |actor_lr
0.001             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4314.000000   4315.000000
mean      0.000441    20062.255222  ...   20122.295285  20118.633889
std       0.027818    16039.874230  ...   16077.162832  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7691.585083   7690.540039
50%       0.000642    11554.824463  ...   11724.320312  11715.610352
75%       0.011655    29873.081836  ...   29925.802734  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 03:33:12.339667: I tensorflow/core/platform/cpu_fea22023-07-28 03:33:12.22023023-07-28 03:33-0:323970703-:3 -07I128-28 03:33  2:.0333:t9133:12.2.3397339e7n2s1o627:: I99:  r tIIf tensolo rfetewlonnstorflow/core/platuwrforme/_/g/ccpuocore/platfsrorfe/pluoraatm/rfdc.lcocpu:ow1r_42fm//c]eaturcpuo_fe reTe_/_gfahis Tetuunspare_georFalatform/cpu_featurrlde_guaruow a.rd.ccbdi:142cnc]:.c1a4 2c]ry is op: T1This Tet4insorFlowthiu bimsir2e n] aTrhiys z_gTieuned  s Taewitnssoorrh oodrFFneAPI .lcptimized woDwl ibc:142oi2]ew0n2 t h 3Tehpa-rbyo2 n0i07-28 03N 2eAsi: Ts op3P3enst:312I.or-Fl3o0 7i-Dn2840ary e1w4 im i60:seibinep Nu or aIr ytezaelue n sodr wpfliNet2ral to0wsw2ork  ith33/ oiptNeL-o:0n7-2emAiPbirti3acmz8erdwo 3ro:ri12.wze34Id0 Dk  e1 iwtih eo/npeALPI0 epi3:3bDteer3 :hlNatfp aoon1yry (o n2e.Neur3ael rAmPeIN u403ral /05e: I  tcpu(5oneDNN)0te_ tNetwworko:ns oorfIDf   LloteatrekuiN LibDesebuNr)a r ythnrseet_goo (o rary p( oNneeurwrnalu NseueetDN Nt)D NtNo)hw/orak L cteo rfe o ibra/uuoslrlpolwafrsdee li negtyo (.tfheoronct hewm// c Ccpuf_olPffeael ooct:u1r42e]fl ToU _iguDaNrN)lol d.honlowiwniwitign gCcncsgPs: oC PU  14U  iCPtUrirnus2 iTesnet]unestr/u cpTsorFlolnsattw b itform/trhicucicnapry sis ohnes  otitTreuuoinnnctionsi optinss miz iin pei sorper fendrffollno peo wro rpFlwoimtare_manceff-ecrrwnocheingitif ob Crma o-cPrmnerU iicAaPlnnsniI op ceraeDaeatiacterty nucree-_ciatl -ocrguparrions :pu dNietcrsa  eitciru.cctoAiVtir:a1l42 oc]a lT hiNs pTeonXtneitopiesn s:ral  miinz epdeaAowpoVrX2refko r 
tTioo nmsa:n rwaen   AtsaAbLicieVt-Xl eA oVrFVithobcXr hn sXa2Aelmo wroitn
rToy Vi :( o  nbeAnXe2nAaibil
VPcanl eX  t aerIAVoXt2h
erTohe oDpeme  TooDpNeNrype ra tei)n   ioNteoe ninunother saataisoopnr a,l bulblssee    Nthetoh:reetwpotrik ratm ee meibouL i bAranry tihfiollV(zoend Xelme DiN  sN, rioAwVi)edn  Toetnhs too nugsXe2 
Te CbwPitnutiU r hled rTienn ostht sfoerh  ooruFopolocplrowelrtaeirons   onwwiieFnittaht itohnen gape lbilAnasp oCPo,p rneIr fDoeroPswUerempa , pi nth  rNieaweimn cbeurt-hcrsitteeludr utch Trian oeblt iNiethetre uoeioins pn sorltecaaF dw ioppcTnenslorolr opw mppeirlfeorokoprFelr mrriowfanart   cwe-Lwiibiacilonrtae attry agcth (onrishi oesD.:ttNtNh)e  aipcnaltom  ho
 sp AeV pu,ilerroprise ta te X  flArocaohepbueVmXp2i
grs.a
lapTtediplreor fp rfiolal lTeioaonsorFloowi ngwtneges:  Ansa.V Xw bAle VX 
them it 2
ihn oth cCPetr opUhompiler flags.
erations, rebuild TensorFlow with the appropriate compiler flags.
e appropTo en instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
rable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
iate compiler flags.
2023-07-28 03:33:12.984801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:33:12.990761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:33:12.991200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:33:12.992314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:33:13.002600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:33:13.005187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:33:13.005572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:33:13.025092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.05分 | step:  1280 | performance: 0.9 | accuracy: 0.34 | loss: 0.75
update: 10/2000, 耗时:0.01分/0.07分 | step:  2560 | performance: 1.0 | accuracy: 0.35 | loss: 0.65
update: 15/2000, 耗时:0.01分/0.10分 | step:  3840 | performance: 0.8 | accuracy: 0.35 | loss: 0.84
update: 20/2000, 耗时:0.01分/0.13分 | step:  5120 | performance: 0.8 | accuracy: 0.36 | loss: 0.59
update: 25/2000, 耗时:0.01分/0.17分 | step:  6400 | performance: 0.7 | accuracy: 0.36 | loss: 0.73
update: 30/2000, 耗时:0.01分/0.20分 | step:  7680 | performance: 0.6 | accuracy: 0.35 | loss: 0.46
update: 35/2000, 耗时:0.01分/0.23分 | step:  8960 | performance: 0.6 | accuracy: 0.34 | loss: 0.95
update: 40/2000, 耗时:0.01分/0.27分 | step: 10240 | performance: 0.7 | accuracy: 0.35 | loss: 0.70
update: 45/2000, 耗时:0.01分/0.30分 | step: 11520 | performance: 0.7 | accuracy: 0.36 | loss: 0.57
update: 50/2000, 耗时:0.01分/0.34分 | step: 12800 | performance: 0.7 | accuracy: 0.36 | loss: 0.69
update: 55/2000, 耗时:0.01分/0.37分 | step: 14080 | performance: 0.3 | accuracy: 0.35 | loss: 0.68
update: 60/2000, 耗时:0.01分/0.40分 | step: 15360 | performance: 0.2 | accuracy: 0.35 | loss: 0.49
update: 65/2000, 耗时:0.01分/0.44分 | step: 16640 | performance: 0.2 | accuracy: 0.35 | loss: 0.50
update: 70/2000, 耗时:0.01分/0.47分 | step: 17920 | performance: 0.3 | accuracy: 0.35 | loss: 1.01
update: 75/2000, 耗时:0.01分/0.51分 | step: 19200 | performance: 0.5 | accuracy: 0.35 | loss: 0.61
update: 80/2000, 耗时:0.01分/0.54分 | step: 20480 | performance: 0.4 | accuracy: 0.35 | loss: 0.90
update: 85/2000, 耗时:0.01分/0.58分 | step: 21760 | performance: 0.4 | accuracy: 0.35 | loss: 0.43
update: 90/2000, 耗时:0.01分/0.61分 | step: 23040 | performance: 0.3 | accuracy: 0.34 | loss: 0.49
update: 95/2000, 耗时:0.01分/0.64分 | step: 24320 | performance: 0.3 | accuracy: 0.34 | loss: 0.81
update:100/2000, 耗时:0.01分/0.68分 | step: 25600 | performance: 0.3 | accuracy: 0.34 | loss: 0.82
update:105/2000, 耗时:0.01分/0.71分 | step: 26880 | performance: 0.4 | accuracy: 0.35 | loss: 0.69
update:110/2000, 耗时:0.01分/0.75分 | step: 28160 | performance: 0.4 | accuracy: 0.34 | loss: 0.52
update:115/2000, 耗时:0.01分/0.78分 | step: 29440 | performance: 0.9 | accuracy: 0.44 | loss: 1.02
Saving PPO weights in both H5 format and checkpoint @ update:115 
update:120/2000, 耗时:0.01分/0.81分 | step: 30720 | performance: 0.6 | accuracy: 0.29 | loss: 0.43
update:125/2000, 耗时:0.01分/0.85分 | step: 32000 | performance: 0.6 | accuracy: 0.29 | loss: 0.44
update:130/2000, 耗时:0.01分/0.88分 | step: 33280 | performance: 0.8 | accuracy: 0.27 | loss: 0.34
update:135/2000, 耗时:0.01分/0.91分 | step: 34560 | performance: 1.0 | accuracy: 0.25 | loss: 0.27
update:140/2000, 耗时:0.01分/0.95分 | step: 35840 | performance: 0.9 | accuracy: 0.24 | loss: 0.41
update:145/2000, 耗时:0.01分/0.98分 | step: 37120 | performance: 1.0 | accuracy: 0.25 | loss: 0.54
update:150/2000, 耗时:0.01分/1.01分 | step: 38400 | performance: 0.7 | accuracy: 0.26 | loss: 0.72
update:155/2000, 耗时:0.01分/1.05分 | step: 39680 | performance: 0.7 | accuracy: 0.25 | loss: 0.30
update:160/2000, 耗时:0.01分/1.08分 | step: 40960 | performance: 0.6 | accuracy: 0.25 | loss: 0.21
update:165/2000, 耗时:0.01分/1.11分 | step: 42240 | performance: 0.4 | accuracy: 0.24 | loss: 0.45
update:170/2000, 耗时:0.01分/1.15分 | step: 43520 | performance: 0.4 | accuracy: 0.24 | loss: 0.30
update:175/2000, 耗时:0.01分/1.18分 | step: 44800 | performance: 0.4 | accuracy: 0.23 | loss: 0.28
update:180/2000, 耗时:0.01分/1.21分 | step: 46080 | performance: 0.4 | accuracy: 0.22 | loss: 0.22
update:185/2000, 耗时:0.01分/1.25分 | step: 47360 | performance: 0.5 | accuracy: 0.22 | loss: 0.12
update:190/2000, 耗时:0.01分/1.28分 | step: 48640 | performance: 0.5 | accuracy: 0.21 | loss: 0.09
update:195/2000, 耗时:0.01分/1.31分 | step: 49920 | performance: 0.5 | accuracy: 0.20 | loss: 0.07
update:200/2000, 耗时:0.01分/1.34分 | step: 51200 | performance: 0.5 | accuracy: 0.19 | loss: 0.07
update:205/2000, 耗时:0.01分/1.38分 | step: 52480 | performance: 0.4 | accuracy: 0.18 | loss: 0.07
update:210/2000, 耗时:0.01分/1.41分 | step: 53760 | performance: 0.4 | accuracy: 0.18 | loss: 0.07
update:215/2000, 耗时:0.01分/1.44分 | step: 55040 | performance: 0.4 | accuracy: 0.17 | loss: 0.04
update:220/2000, 耗时:0.01分/1.47分 | step: 56320 | performance: 0.4 | accuracy: 0.16 | loss: 0.03
update:225/2000, 耗时:0.01分/1.51分 | step: 57600 | performance: 0.4 | accuracy: 0.16 | loss: 0.05
Saving PPO weights in both H5 format and checkpoint @ update:229 
update:230/2000, 耗时:0.01分/1.54分 | step: 58880 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 59129 | worker_0@n_step_31: average total_reward after train data exhaustion : 51.1 | max total_reward: 206.2
step: 59130 | worker_1@n_step_31: average total_reward after train data exhaustion : 49.9 | max total_reward: 206.2
step: 59131 | worker_2@n_step_31: average total_reward after train data exhaustion : 48.8 | max total_reward: 206.2
step: 59132 | worker_3@n_step_31: average total_reward after train data exhaustion : 47.7 | max total_reward: 206.2
step: 59133 | worker_4@n_step_31: average total_reward after train data exhaustion : 46.6 | max total_reward: 206.2
step: 59135 | worker_6@n_step_31: average total_reward after train data exhaustion : 45.6 | max total_reward: 206.2
step: 59136 | worker_7@n_step_31: average total_reward after train data exhaustion : 44.7 | max total_reward: 206.2
update:235/2000, 耗时:0.01分/1.58分 | step: 60160 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:240/2000, 耗时:0.01分/1.61分 | step: 61440 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 62462 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 206.2
update:245/2000, 耗时:0.01分/1.64分 | step: 62720 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 63481 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 63482 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 63483 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 63484 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 63485 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 63487 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 63488 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:250/2000, 耗时:0.01分/1.68分 | step: 64000 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
update:255/2000, 耗时:0.01分/1.71分 | step: 65280 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:260/2000, 耗时:0.01分/1.74分 | step: 66560 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 66809 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 66810 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 66811 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 67837 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 206.2
step: 67838 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 206.2
update:265/2000, 耗时:0.01分/1.78分 | step: 67840 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 68346 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 68859 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 68863 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:270/2000, 耗时:0.01分/1.81分 | step: 69120 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 69627 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
step: 70140 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
update:275/2000, 耗时:0.01分/1.85分 | step: 70400 | performance: 1.0 | accuracy: 0.12 | loss: 0.23
step: 71424 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
update:280/2000, 耗时:0.01分/1.88分 | step: 71680 | performance: 1.0 | accuracy: 0.12 | loss: 0.21
step: 72699 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
step: 72959 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
update:285/2000, 耗时:0.01分/1.91分 | step: 72960 | performance: 1.1 | accuracy: 0.10 | loss: 0.21
step: 73470 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 74235 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:290/2000, 耗时:0.01分/1.95分 | step: 74240 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 75516 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
update:295/2000, 耗时:0.01分/1.98分 | step: 75520 | performance: 1.0 | accuracy: 0.21 | loss: 0.27
step: 76282 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
update:300/2000, 耗时:0.01分/2.01分 | step: 76800 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
step: 78077 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 206.2
update:305/2000, 耗时:0.01分/2.05分 | step: 78080 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
step: 78329 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 206.2
update:310/2000, 耗时:0.01分/2.08分 | step: 79360 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 79871 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:315/2000, 耗时:0.01分/2.12分 | step: 80640 | performance: 1.1 | accuracy: 0.14 | loss: 0.15
step: 81920 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
update:320/2000, 耗时:0.01分/2.15分 | step: 81920 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
step: 82425 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
step: 82682 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
step: 82685 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
step: 82942 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
update:325/2000, 耗时:0.01分/2.18分 | step: 83200 | performance: 1.0 | accuracy: 0.17 | loss: 0.09
update:330/2000, 耗时:0.01分/2.22分 | step: 84480 | performance: 1.0 | accuracy: 0.06 | loss: 0.21
update:335/2000, 耗时:0.01分/2.25分 | step: 85760 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 86014 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 86016 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 86269 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:340/2000, 耗时:0.01分/2.29分 | step: 87040 | performance: 1.1 | accuracy: 0.19 | loss: 0.28
step: 88062 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:345/2000, 耗时:0.01分/2.32分 | step: 88320 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 89340 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
update:350/2000, 耗时:0.01分/2.35分 | step: 89600 | performance: 1.0 | accuracy: 0.50 | loss: 0.10
step: 89856 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 206.2
step: 90106 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:355/2000, 耗时:0.01分/2.39分 | step: 90880 | performance: 1.1 | accuracy: 0.14 | loss: 0.17
step: 91129 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 91131 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 91646 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 206.2
update:360/2000, 耗时:0.01分/2.42分 | step: 92160 | performance: 0.9 | accuracy: 0.07 | loss: 0.17
step: 93180 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
update:365/2000, 耗时:0.01分/2.45分 | step: 93440 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 94460 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:370/2000, 耗时:0.01分/2.49分 | step: 94720 | performance: 1.0 | accuracy: 0.15 | loss: 0.15
step: 95226 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 206.2
update:375/2000, 耗时:0.01分/2.52分 | step: 96000 | performance: 1.2 | accuracy: 0.15 | loss: 0.21
step: 96250 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 96254 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 96768 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
step: 97275 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
update:380/2000, 耗时:0.01分/2.55分 | step: 97280 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 97535 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
step: 97789 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:385/2000, 耗时:0.01分/2.59分 | step: 98560 | performance: 1.0 | accuracy: 0.11 | loss: 0.15
step: 98814 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 99578 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 206.2
step: 99580 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 206.2
step: 99840 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
update:390/2000, 耗时:0.01分/2.62分 | step: 99840 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 100858 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:395/2000, 耗时:0.01分/2.65分 | step: 101120 | performance: 1.0 | accuracy: 0.17 | loss: 0.16
step: 101630 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:400/2000, 耗时:0.01分/2.69分 | step: 102400 | performance: 1.0 | accuracy: 0.14 | loss: 0.17
step: 103163 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 206.2
step: 103679 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
update:405/2000, 耗时:0.01分/2.72分 | step: 103680 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 103936 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 104698 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
step: 104700 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
update:410/2000, 耗时:0.01分/2.75分 | step: 104960 | performance: 1.1 | accuracy: 0.10 | loss: 0.15
step: 105727 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 105982 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 106236 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
update:415/2000, 耗时:0.01分/2.79分 | step: 106240 | performance: 1.1 | accuracy: 0.19 | loss: 0.11
step: 106745 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 106747 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 106752 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 107513 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 107515 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:420/2000, 耗时:0.01分/2.82分 | step: 107520 | performance: 1.0 | accuracy: 0.10 | loss: 0.16
step: 107772 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 108031 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 108288 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
update:425/2000, 耗时:0.01分/2.86分 | step: 108800 | performance: 0.9 | accuracy: 0.12 | loss: 0.17
step: 109567 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 206.2
step: 109824 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 206.2
update:430/2000, 耗时:0.01分/2.89分 | step: 110080 | performance: 0.9 | accuracy: 0.07 | loss: 0.17
step: 110589 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:435/2000, 耗时:0.01分/2.92分 | step: 111360 | performance: 1.0 | accuracy: 0.14 | loss: 0.13
step: 111610 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 111615 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
step: 112378 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 206.2
step: 112637 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:440/2000, 耗时:0.01分/2.96分 | step: 112640 | performance: 1.1 | accuracy: 0.10 | loss: 0.13
step: 113659 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
step: 113664 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 206.2
update:445/2000, 耗时:0.01分/2.99分 | step: 113920 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 114169 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
update:450/2000, 耗时:0.01分/3.03分 | step: 115200 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
update:455/2000, 耗时:0.01分/3.06分 | step: 116480 | performance: 1.5 | accuracy: 0.11 | loss: 0.23
step: 116730 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
step: 117248 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 206.2
update:460/2000, 耗时:0.01分/3.09分 | step: 117760 | performance: 0.9 | accuracy: 0.11 | loss: 0.19
step: 118268 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
step: 118269 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
step: 118271 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 118522 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
update:465/2000, 耗时:0.01分/3.13分 | step: 119040 | performance: 1.0 | accuracy: 0.14 | loss: 0.18
step: 119805 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:470/2000, 耗时:0.01分/3.15分 | step: 120320 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
update:475/2000, 耗时:0.01分/3.18分 | step: 121600 | performance: 0.9 | accuracy: 0.00 | loss: 0.25
step: 121852 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 121854 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 122363 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
update:480/2000, 耗时:0.01分/3.22分 | step: 122880 | performance: 0.9 | accuracy: 0.00 | loss: 0.16
step: 123133 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 206.2
step: 123134 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 206.2
step: 123898 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 206.2
update:485/2000, 耗时:0.01分/3.25分 | step: 124160 | performance: 1.0 | accuracy: 0.13 | loss: 0.22
step: 124667 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:490/2000, 耗时:0.01分/3.28分 | step: 125440 | performance: 1.0 | accuracy: 0.00 | loss: 0.24
update:495/2000, 耗时:0.01分/3.32分 | step: 126720 | performance: 1.0 | accuracy: 0.09 | loss: 0.17
step: 127230 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 206.2
update:500/2000, 耗时:0.01分/3.35分 | step: 128000 | performance: 1.0 | accuracy: 0.12 | loss: 0.21
update:505/2000, 耗时:0.01分/3.38分 | step: 129280 | performance: 1.0 | accuracy: 0.14 | loss: 0.16
step: 129533 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
step: 130298 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
update:510/2000, 耗时:0.01分/3.42分 | step: 130560 | performance: 1.1 | accuracy: 0.14 | loss: 0.22
step: 131321 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 131836 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:515/2000, 耗时:0.01分/3.45分 | step: 131840 | performance: 0.9 | accuracy: 0.08 | loss: 0.08
step: 132093 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
step: 132604 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 206.2
update:520/2000, 耗时:0.01分/3.48分 | step: 133120 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
update:525/2000, 耗时:0.01分/3.52分 | step: 134400 | performance: 1.0 | accuracy: 0.07 | loss: 0.11
step: 134906 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
update:530/2000, 耗时:0.01分/3.55分 | step: 135680 | performance: 0.9 | accuracy: 0.00 | loss: 0.10
step: 136185 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 206.2
step: 136186 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 206.2
step: 136188 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 206.2
step: 136189 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 206.2
update:535/2000, 耗时:0.01分/3.59分 | step: 136960 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 137215 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 137980 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
update:540/2000, 耗时:0.01分/3.62分 | step: 138240 | performance: 1.0 | accuracy: 0.10 | loss: 0.09
step: 138489 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 138493 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 139258 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 206.2
step: 139264 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 206.2
update:545/2000, 耗时:0.01分/3.65分 | step: 139520 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 139775 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 206.2
step: 140028 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 206.2
update:550/2000, 耗时:0.01分/3.68分 | step: 140800 | performance: 1.1 | accuracy: 0.14 | loss: 0.14
update:555/2000, 耗时:0.01分/3.72分 | step: 142080 | performance: 1.2 | accuracy: 0.12 | loss: 0.34
step: 142848 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 206.2
update:560/2000, 耗时:0.01分/3.75分 | step: 143360 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
step: 143613 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 206.2
update:565/2000, 耗时:0.01分/3.79分 | step: 144640 | performance: 1.2 | accuracy: 0.11 | loss: 0.14
step: 144895 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
step: 145146 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 206.2
update:570/2000, 耗时:0.01分/3.82分 | step: 145920 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 146426 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
update:575/2000, 耗时:0.01分/3.85分 | step: 147200 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 148475 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 148477 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:580/2000, 耗时:0.01分/3.89分 | step: 148480 | performance: 1.1 | accuracy: 0.08 | loss: 0.12
step: 149242 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
update:585/2000, 耗时:0.01分/3.92分 | step: 149760 | performance: 1.1 | accuracy: 0.12 | loss: 0.19
step: 151033 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
step: 151037 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:590/2000, 耗时:0.01分/3.96分 | step: 151040 | performance: 1.2 | accuracy: 0.13 | loss: 0.15
step: 151546 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:595/2000, 耗时:0.01分/3.99分 | step: 152320 | performance: 1.2 | accuracy: 0.12 | loss: 0.24
step: 153337 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
update:600/2000, 耗时:0.01分/4.03分 | step: 153600 | performance: 1.2 | accuracy: 0.11 | loss: 0.16
step: 153850 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 206.2
step: 154107 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 206.2
update:605/2000, 耗时:0.01分/4.06分 | step: 154880 | performance: 0.9 | accuracy: 0.11 | loss: 0.17
step: 155901 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 206.2
step: 156154 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:610/2000, 耗时:0.01分/4.09分 | step: 156160 | performance: 1.1 | accuracy: 0.12 | loss: 0.29
update:615/2000, 耗时:0.01分/4.13分 | step: 157440 | performance: 1.5 | accuracy: 0.13 | loss: 0.13
update:620/2000, 耗时:0.01分/4.16分 | step: 158720 | performance: 1.7 | accuracy: 0.12 | loss: 0.17
step: 159482 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
step: 159483 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:625/2000, 耗时:0.01分/4.20分 | step: 160000 | performance: 1.5 | accuracy: 0.12 | loss: 0.20
step: 160762 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 206.2
update:630/2000, 耗时:0.01分/4.23分 | step: 161280 | performance: 1.5 | accuracy: 0.12 | loss: 0.16
update:635/2000, 耗时:0.01分/4.26分 | step: 162560 | performance: 1.5 | accuracy: 0.12 | loss: 0.13
step: 163066 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 206.2
update:640/2000, 耗时:0.01分/4.30分 | step: 163840 | performance: 1.5 | accuracy: 0.12 | loss: 0.13
step: 164861 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 206.2
update:645/2000, 耗时:0.01分/4.33分 | step: 165120 | performance: 1.4 | accuracy: 0.12 | loss: 0.11
update:650/2000, 耗时:0.01分/4.37分 | step: 166400 | performance: 1.6 | accuracy: 0.12 | loss: 0.12
step: 166907 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 206.2
update:655/2000, 耗时:0.01分/4.40分 | step: 167680 | performance: 1.6 | accuracy: 0.12 | loss: 0.08
update:660/2000, 耗时:0.01分/4.43分 | step: 168960 | performance: 1.6 | accuracy: 0.12 | loss: 0.10
update:665/2000, 耗时:0.01分/4.46分 | step: 170240 | performance: 1.6 | accuracy: 0.12 | loss: 0.13
step: 171003 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.5 | max total_reward: 217.6
step: 171006 | worker_5@n_step_31: average total_reward after train data exhaustion : 4.5 | max total_reward: 217.6
update:670/2000, 耗时:0.01分/4.50分 | step: 171520 | performance: 1.5 | accuracy: 0.11 | loss: 0.10
step: 172029 | worker_4@n_step_31: average total_reward after train data exhaustion : 4.5 | max total_reward: 217.6
update:675/2000, 耗时:0.01分/4.53分 | step: 172800 | performance: 1.4 | accuracy: 0.11 | loss: 0.16
update:680/2000, 耗时:0.01分/4.56分 | step: 174080 | performance: 1.4 | accuracy: 0.11 | loss: 0.16
step: 174846 | worker_5@n_step_31: average total_reward after train data exhaustion : 8.9 | max total_reward: 239.6
step: 175355 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.8 | max total_reward: 239.6
update:685/2000, 耗时:0.01分/4.60分 | step: 175360 | performance: 1.2 | accuracy: 0.11 | loss: 0.07
step: 176383 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 239.6
update:690/2000, 耗时:0.01分/4.63分 | step: 176640 | performance: 1.1 | accuracy: 0.10 | loss: 0.09
step: 176894 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 239.6
step: 177402 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 239.6
step: 177916 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 239.6
update:695/2000, 耗时:0.01分/4.66分 | step: 177920 | performance: 1.0 | accuracy: 0.10 | loss: 0.17
update:700/2000, 耗时:0.01分/4.70分 | step: 179200 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 179452 | worker_3@n_step_31: average total_reward after train data exhaustion : 8.1 | max total_reward: 239.6
step: 180473 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 239.6
update:705/2000, 耗时:0.01分/4.73分 | step: 180480 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
step: 181498 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 239.6
step: 181500 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 239.6
step: 181759 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 239.6
update:710/2000, 耗时:0.01分/4.77分 | step: 181760 | performance: 0.8 | accuracy: 0.12 | loss: 0.23
update:715/2000, 耗时:0.01分/4.80分 | step: 183040 | performance: 1.1 | accuracy: 0.17 | loss: 0.23
update:720/2000, 耗时:0.01分/4.84分 | step: 184320 | performance: 0.6 | accuracy: 0.12 | loss: 0.19
step: 185337 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 239.6
update:725/2000, 耗时:0.01分/4.87分 | step: 185600 | performance: 0.5 | accuracy: 0.11 | loss: 0.20
step: 186366 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 239.6
update:730/2000, 耗时:0.01分/4.91分 | step: 186880 | performance: 0.4 | accuracy: 0.11 | loss: 0.19
step: 187897 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 239.6
update:735/2000, 耗时:0.01分/4.94分 | step: 188160 | performance: 0.4 | accuracy: 0.12 | loss: 0.14
update:740/2000, 耗时:0.01分/4.98分 | step: 189440 | performance: 0.4 | accuracy: 0.12 | loss: 0.20
update:745/2000, 耗时:0.01分/5.01分 | step: 190720 | performance: 0.4 | accuracy: 0.12 | loss: 0.13
step: 191993 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 239.6
update:750/2000, 耗时:0.01分/5.05分 | step: 192000 | performance: 0.3 | accuracy: 0.11 | loss: 0.08
update:755/2000, 耗时:0.01分/5.08分 | step: 193280 | performance: 0.3 | accuracy: 0.11 | loss: 0.08
update:760/2000, 耗时:0.01分/5.12分 | step: 194560 | performance: 0.3 | accuracy: 0.11 | loss: 0.13
step: 195833 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 239.6
update:765/2000, 耗时:0.01分/5.15分 | step: 195840 | performance: 0.2 | accuracy: 0.11 | loss: 0.14
update:770/2000, 耗时:0.01分/5.19分 | step: 197120 | performance: 0.2 | accuracy: 0.11 | loss: 0.09
update:775/2000, 耗时:0.01分/5.22分 | step: 198400 | performance: 0.3 | accuracy: 0.11 | loss: 0.12
update:780/2000, 耗时:0.01分/5.26分 | step: 199680 | performance: 0.3 | accuracy: 0.12 | loss: 0.09
update:785/2000, 耗时:0.01分/5.29分 | step: 200960 | performance: 0.2 | accuracy: 0.11 | loss: 0.13
update:790/2000, 耗时:0.01分/5.32分 | step: 202240 | performance: 0.3 | accuracy: 0.11 | loss: 0.10
update:795/2000, 耗时:0.01分/5.36分 | step: 203520 | performance: 0.2 | accuracy: 0.11 | loss: 0.13
update:800/2000, 耗时:0.01分/5.39分 | step: 204800 | performance: 0.2 | accuracy: 0.10 | loss: 0.07
update:805/2000, 耗时:0.01分/5.43分 | step: 206080 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
update:810/2000, 耗时:0.01分/5.46分 | step: 207360 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 207611 | worker_2@n_step_31: average total_reward after train data exhaustion : 7.1 | max total_reward: 239.6
update:815/2000, 耗时:0.01分/5.49分 | step: 208640 | performance: 1.0 | accuracy: 0.14 | loss: 0.11
step: 209408 | worker_7@n_step_31: average total_reward after train data exhaustion : 3.6 | max total_reward: 239.6
update:820/2000, 耗时:0.01分/5.52分 | step: 209920 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:825/2000, 耗时:0.01分/5.56分 | step: 211200 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 211707 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 239.6
step: 212474 | worker_1@n_step_31: average total_reward after train data exhaustion : 10.2 | max total_reward: 254.8
update:830/2000, 耗时:0.01分/5.59分 | step: 212480 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 212736 | worker_7@n_step_31: average total_reward after train data exhaustion : 10.2 | max total_reward: 254.8
step: 212991 | worker_6@n_step_31: average total_reward after train data exhaustion : 14.6 | max total_reward: 254.8
step: 213499 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.5 | max total_reward: 254.8
step: 213500 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.6 | max total_reward: 254.8
update:835/2000, 耗时:0.01分/5.62分 | step: 213760 | performance: 1.0 | accuracy: 0.14 | loss: 0.13
update:840/2000, 耗时:0.01分/5.66分 | step: 215040 | performance: 0.9 | accuracy: 0.07 | loss: 0.19
step: 216318 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
update:845/2000, 耗时:0.01分/5.69分 | step: 216320 | performance: 1.0 | accuracy: 0.07 | loss: 0.16
step: 216825 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 254.8
step: 217598 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 254.8
update:850/2000, 耗时:0.01分/5.72分 | step: 217600 | performance: 1.0 | accuracy: 0.10 | loss: 0.21
step: 217853 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:855/2000, 耗时:0.01分/5.75分 | step: 218880 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
update:860/2000, 耗时:0.01分/5.79分 | step: 220160 | performance: 1.1 | accuracy: 0.13 | loss: 0.19
update:865/2000, 耗时:0.01分/5.82分 | step: 221440 | performance: 1.2 | accuracy: 0.11 | loss: 0.19
update:870/2000, 耗时:0.01分/5.85分 | step: 222720 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
step: 223226 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.8
step: 223484 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.8
step: 223993 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
step: 223994 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
update:875/2000, 耗时:0.01分/5.89分 | step: 224000 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:880/2000, 耗时:0.01分/5.92分 | step: 225280 | performance: 1.0 | accuracy: 0.14 | loss: 0.24
update:885/2000, 耗时:0.01分/5.95分 | step: 226560 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
step: 226810 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 254.8
update:890/2000, 耗时:0.01分/5.98分 | step: 227840 | performance: 1.0 | accuracy: 0.10 | loss: 0.18
update:895/2000, 耗时:0.01分/6.02分 | step: 229120 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:900/2000, 耗时:0.01分/6.05分 | step: 230400 | performance: 1.2 | accuracy: 0.18 | loss: 0.24
update:905/2000, 耗时:0.01分/6.08分 | step: 231680 | performance: 1.1 | accuracy: 0.13 | loss: 0.14
update:910/2000, 耗时:0.01分/6.12分 | step: 232960 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 233978 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.8
update:915/2000, 耗时:0.01分/6.15分 | step: 234240 | performance: 1.1 | accuracy: 0.15 | loss: 0.15
step: 234496 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
update:920/2000, 耗时:0.01分/6.18分 | step: 235520 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
update:925/2000, 耗时:0.01分/6.22分 | step: 236800 | performance: 1.1 | accuracy: 0.18 | loss: 0.14
step: 237306 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
step: 237824 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
update:930/2000, 耗时:0.01分/6.25分 | step: 238080 | performance: 1.0 | accuracy: 0.07 | loss: 0.19
update:935/2000, 耗时:0.01分/6.28分 | step: 239360 | performance: 1.1 | accuracy: 0.12 | loss: 0.26
update:940/2000, 耗时:0.01分/6.31分 | step: 240640 | performance: 1.0 | accuracy: 0.16 | loss: 0.16
update:945/2000, 耗时:0.01分/6.35分 | step: 241920 | performance: 0.9 | accuracy: 0.08 | loss: 0.13
step: 242688 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
update:950/2000, 耗时:0.01分/6.38分 | step: 243200 | performance: 1.1 | accuracy: 0.15 | loss: 0.14
update:955/2000, 耗时:0.01分/6.41分 | step: 244480 | performance: 0.8 | accuracy: 0.12 | loss: 0.13
update:960/2000, 耗时:0.01分/6.45分 | step: 245760 | performance: 0.9 | accuracy: 0.14 | loss: 0.18
step: 247040 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:965/2000, 耗时:0.01分/6.48分 | step: 247040 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
update:970/2000, 耗时:0.01分/6.50分 | step: 248320 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
update:975/2000, 耗时:0.01分/6.53分 | step: 249600 | performance: 1.1 | accuracy: 0.11 | loss: 0.09
step: 250363 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.0 | max total_reward: 254.8
update:980/2000, 耗时:0.01分/6.56分 | step: 250880 | performance: 1.0 | accuracy: 0.08 | loss: 0.10
step: 251131 | worker_2@n_step_31: average total_reward after train data exhaustion : 12.3 | max total_reward: 254.8
step: 252157 | worker_4@n_step_31: average total_reward after train data exhaustion : 12.1 | max total_reward: 254.8
update:985/2000, 耗时:0.01分/6.59分 | step: 252160 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 253436 | worker_3@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 254.8
update:990/2000, 耗时:0.01分/6.62分 | step: 253440 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 253949 | worker_4@n_step_31: average total_reward after train data exhaustion : 9.2 | max total_reward: 254.8
step: 254208 | worker_7@n_step_31: average total_reward after train data exhaustion : 9.0 | max total_reward: 254.8
update:995/2000, 耗时:0.01分/6.65分 | step: 254720 | performance: 0.9 | accuracy: 0.08 | loss: 0.08
update:1000/2000, 耗时:0.01分/6.69分 | step: 256000 | performance: 0.8 | accuracy: 0.00 | loss: 0.11
step: 256254 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 254.8
step: 256767 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
update:1005/2000, 耗时:0.01分/6.72分 | step: 257280 | performance: 1.0 | accuracy: 0.10 | loss: 0.13
step: 258301 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
step: 258302 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
update:1010/2000, 耗时:0.01分/6.75分 | step: 258560 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
step: 259584 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
update:1015/2000, 耗时:0.01分/6.78分 | step: 259840 | performance: 0.9 | accuracy: 0.07 | loss: 0.22
step: 261113 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 254.8
update:1020/2000, 耗时:0.01分/6.82分 | step: 261120 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 262140 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 254.8
step: 262400 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
update:1025/2000, 耗时:0.01分/6.85分 | step: 262400 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 262653 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
step: 263161 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
step: 263680 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
update:1030/2000, 耗时:0.01分/6.88分 | step: 263680 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 264956 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
update:1035/2000, 耗时:0.01分/6.92分 | step: 264960 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 265216 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
update:1040/2000, 耗时:0.01分/6.95分 | step: 266240 | performance: 1.2 | accuracy: 0.14 | loss: 0.16
step: 267263 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
update:1045/2000, 耗时:0.01分/6.98分 | step: 267520 | performance: 0.9 | accuracy: 0.12 | loss: 0.18
update:1050/2000, 耗时:0.01分/7.01分 | step: 268800 | performance: 0.9 | accuracy: 0.13 | loss: 0.20
update:1055/2000, 耗时:0.01分/7.05分 | step: 270080 | performance: 0.7 | accuracy: 0.12 | loss: 0.11
step: 270333 | worker_4@n_step_31: average total_reward after train data exhaustion : 4.2 | max total_reward: 254.8
update:1060/2000, 耗时:0.01分/7.08分 | step: 271360 | performance: 0.7 | accuracy: 0.12 | loss: 0.08
update:1065/2000, 耗时:0.01分/7.11分 | step: 272640 | performance: 0.7 | accuracy: 0.12 | loss: 0.19
update:1070/2000, 耗时:0.01分/7.14分 | step: 273920 | performance: 0.9 | accuracy: 0.12 | loss: 0.16
update:1075/2000, 耗时:0.01分/7.17分 | step: 275200 | performance: 0.8 | accuracy: 0.12 | loss: 0.19
step: 276217 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.8
update:1080/2000, 耗时:0.01分/7.20分 | step: 276480 | performance: 0.8 | accuracy: 0.12 | loss: 0.16
update:1085/2000, 耗时:0.01分/7.24分 | step: 277760 | performance: 0.7 | accuracy: 0.12 | loss: 0.19
step: 278012 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 254.8
step: 278269 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 254.8
step: 278271 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
step: 278777 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
update:1090/2000, 耗时:0.01分/7.27分 | step: 279040 | performance: 0.7 | accuracy: 0.12 | loss: 0.09
step: 279295 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
step: 279548 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 254.8
update:1095/2000, 耗时:0.01分/7.30分 | step: 280320 | performance: 0.6 | accuracy: 0.12 | loss: 0.13
update:1100/2000, 耗时:0.01分/7.33分 | step: 281600 | performance: 0.6 | accuracy: 0.13 | loss: 0.21
update:1105/2000, 耗时:0.01分/7.36分 | step: 282880 | performance: 0.7 | accuracy: 0.13 | loss: 0.24
update:1110/2000, 耗时:0.01分/7.40分 | step: 284160 | performance: 0.9 | accuracy: 0.13 | loss: 0.17
update:1115/2000, 耗时:0.01分/7.43分 | step: 285440 | performance: 0.9 | accuracy: 0.13 | loss: 0.26
update:1120/2000, 耗时:0.01分/7.46分 | step: 286720 | performance: 1.1 | accuracy: 0.13 | loss: 0.19
update:1125/2000, 耗时:0.01分/7.49分 | step: 288000 | performance: 1.3 | accuracy: 0.13 | loss: 0.17
update:1130/2000, 耗时:0.01分/7.52分 | step: 289280 | performance: 1.2 | accuracy: 0.13 | loss: 0.28
update:1135/2000, 耗时:0.01分/7.56分 | step: 290560 | performance: 1.2 | accuracy: 0.13 | loss: 0.29
update:1140/2000, 耗时:0.01分/7.59分 | step: 291840 | performance: 1.0 | accuracy: 0.13 | loss: 0.18
update:1145/2000, 耗时:0.01分/7.62分 | step: 293120 | performance: 0.9 | accuracy: 0.13 | loss: 0.18
update:1150/2000, 耗时:0.01分/7.65分 | step: 294400 | performance: 0.9 | accuracy: 0.13 | loss: 0.20
step: 295168 | worker_7@n_step_31: average total_reward after train data exhaustion : 12.9 | max total_reward: 254.8
update:1155/2000, 耗时:0.01分/7.69分 | step: 295680 | performance: 1.0 | accuracy: 0.08 | loss: 0.11
step: 296704 | worker_7@n_step_31: average total_reward after train data exhaustion : 13.0 | max total_reward: 254.8
update:1160/2000, 耗时:0.01分/7.72分 | step: 296960 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:1165/2000, 耗时:0.01分/7.75分 | step: 298240 | performance: 1.2 | accuracy: 0.15 | loss: 0.15
step: 299259 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
update:1170/2000, 耗时:0.01分/7.78分 | step: 299520 | performance: 0.9 | accuracy: 0.12 | loss: 0.10
update:1175/2000, 耗时:0.01分/7.81分 | step: 300800 | performance: 1.0 | accuracy: 0.11 | loss: 0.22
update:1180/2000, 耗时:0.01分/7.85分 | step: 302080 | performance: 1.1 | accuracy: 0.16 | loss: 0.16
update:1185/2000, 耗时:0.01分/7.88分 | step: 303360 | performance: 1.1 | accuracy: 0.12 | loss: 0.16
update:1190/2000, 耗时:0.01分/7.91分 | step: 304640 | performance: 1.2 | accuracy: 0.15 | loss: 0.23
update:1195/2000, 耗时:0.01分/7.95分 | step: 305920 | performance: 1.2 | accuracy: 0.15 | loss: 0.18
update:1200/2000, 耗时:0.01分/7.98分 | step: 307200 | performance: 1.2 | accuracy: 0.15 | loss: 0.16
update:1205/2000, 耗时:0.01分/8.01分 | step: 308480 | performance: 1.2 | accuracy: 0.15 | loss: 0.17
update:1210/2000, 耗时:0.01分/8.05分 | step: 309760 | performance: 1.2 | accuracy: 0.15 | loss: 0.15
step: 311036 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.5 | max total_reward: 254.8
update:1215/2000, 耗时:0.01分/8.08分 | step: 311040 | performance: 1.3 | accuracy: 0.15 | loss: 0.17
step: 311805 | worker_4@n_step_31: average total_reward after train data exhaustion : 12.3 | max total_reward: 254.8
update:1220/2000, 耗时:0.01分/8.11分 | step: 312320 | performance: 1.2 | accuracy: 0.14 | loss: 0.11
step: 312575 | worker_6@n_step_31: average total_reward after train data exhaustion : 16.4 | max total_reward: 254.8
update:1225/2000, 耗时:0.01分/8.14分 | step: 313600 | performance: 1.0 | accuracy: 0.15 | loss: 0.15
step: 314365 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 254.8
update:1230/2000, 耗时:0.01分/8.18分 | step: 314880 | performance: 1.0 | accuracy: 0.14 | loss: 0.10
step: 316157 | worker_4@n_step_31: average total_reward after train data exhaustion : 4.5 | max total_reward: 254.8
update:1235/2000, 耗时:0.01分/8.21分 | step: 316160 | performance: 1.1 | accuracy: 0.14 | loss: 0.14
update:1240/2000, 耗时:0.01分/8.24分 | step: 317440 | performance: 1.1 | accuracy: 0.14 | loss: 0.11
update:1245/2000, 耗时:0.01分/8.27分 | step: 318720 | performance: 1.2 | accuracy: 0.14 | loss: 0.14
step: 319484 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1250/2000, 耗时:0.01分/8.31分 | step: 320000 | performance: 1.4 | accuracy: 0.14 | loss: 0.16
step: 320249 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
step: 320762 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.8
update:1255/2000, 耗时:0.01分/8.34分 | step: 321280 | performance: 1.3 | accuracy: 0.14 | loss: 0.15
step: 321532 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1260/2000, 耗时:0.01分/8.37分 | step: 322560 | performance: 1.2 | accuracy: 0.13 | loss: 0.20
step: 323581 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
step: 323833 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1265/2000, 耗时:0.01分/8.40分 | step: 323840 | performance: 1.4 | accuracy: 0.13 | loss: 0.18
update:1270/2000, 耗时:0.01分/8.44分 | step: 325120 | performance: 1.5 | accuracy: 0.13 | loss: 0.14
step: 325882 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 254.8
update:1275/2000, 耗时:0.01分/8.47分 | step: 326400 | performance: 1.1 | accuracy: 0.13 | loss: 0.13
step: 326905 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.5 | max total_reward: 254.8
step: 327162 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.3 | max total_reward: 254.8
update:1280/2000, 耗时:0.01分/8.50分 | step: 327680 | performance: 1.1 | accuracy: 0.12 | loss: 0.13
step: 327935 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
update:1285/2000, 耗时:0.01分/8.53分 | step: 328960 | performance: 1.1 | accuracy: 0.12 | loss: 0.20
step: 329977 | worker_0@n_step_31: average total_reward after train data exhaustion : 4.7 | max total_reward: 254.8
update:1290/2000, 耗时:0.01分/8.57分 | step: 330240 | performance: 1.1 | accuracy: 0.12 | loss: 0.11
step: 331007 | worker_6@n_step_31: average total_reward after train data exhaustion : 4.9 | max total_reward: 254.8
update:1295/2000, 耗时:0.01分/8.60分 | step: 331520 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 331770 | worker_1@n_step_31: average total_reward after train data exhaustion : 5.0 | max total_reward: 254.8
step: 331776 | worker_7@n_step_31: average total_reward after train data exhaustion : 4.8 | max total_reward: 254.8
step: 332029 | worker_4@n_step_31: average total_reward after train data exhaustion : 4.9 | max total_reward: 254.8
update:1300/2000, 耗时:0.01分/8.63分 | step: 332800 | performance: 1.0 | accuracy: 0.25 | loss: 0.14
step: 333824 | worker_7@n_step_31: average total_reward after train data exhaustion : 4.7 | max total_reward: 254.8
update:1305/2000, 耗时:0.01分/8.66分 | step: 334080 | performance: 1.0 | accuracy: 0.09 | loss: 0.10
step: 334848 | worker_7@n_step_31: average total_reward after train data exhaustion : 4.6 | max total_reward: 254.8
update:1310/2000, 耗时:0.01分/8.70分 | step: 335360 | performance: 0.9 | accuracy: 0.40 | loss: 0.16
step: 335613 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
update:1315/2000, 耗时:0.01分/8.73分 | step: 336640 | performance: 1.1 | accuracy: 0.11 | loss: 0.21
step: 337661 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 254.8
update:1320/2000, 耗时:0.01分/8.76分 | step: 337920 | performance: 1.0 | accuracy: 0.25 | loss: 0.11
step: 338430 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 254.8
update:1325/2000, 耗时:0.01分/8.80分 | step: 339200 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
step: 340477 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
update:1330/2000, 耗时:0.01分/8.83分 | step: 340480 | performance: 0.9 | accuracy: 0.25 | loss: 0.14
step: 341245 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1335/2000, 耗时:0.01分/8.86分 | step: 341760 | performance: 1.0 | accuracy: 0.12 | loss: 0.22
step: 342271 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.8
update:1340/2000, 耗时:0.01分/8.89分 | step: 343040 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
update:1345/2000, 耗时:0.01分/8.93分 | step: 344320 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 344832 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.8
update:1350/2000, 耗时:0.01分/8.96分 | step: 345600 | performance: 1.2 | accuracy: 0.14 | loss: 0.14
update:1355/2000, 耗时:0.01分/8.99分 | step: 346880 | performance: 1.7 | accuracy: 0.13 | loss: 0.10
step: 347903 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.8
update:1360/2000, 耗时:0.01分/9.02分 | step: 348160 | performance: 1.6 | accuracy: 0.11 | loss: 0.13
update:1365/2000, 耗时:0.01分/9.05分 | step: 349440 | performance: 1.7 | accuracy: 0.12 | loss: 0.13
update:1370/2000, 耗时:0.01分/9.09分 | step: 350720 | performance: 1.6 | accuracy: 0.11 | loss: 0.11
step: 351487 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 254.8
update:1375/2000, 耗时:0.01分/9.12分 | step: 352000 | performance: 1.5 | accuracy: 0.11 | loss: 0.12
update:1380/2000, 耗时:0.01分/9.15分 | step: 353280 | performance: 1.5 | accuracy: 0.11 | loss: 0.09
update:1385/2000, 耗时:0.01分/9.18分 | step: 354560 | performance: 1.5 | accuracy: 0.10 | loss: 0.08
step: 355839 | worker_6@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 254.8
update:1390/2000, 耗时:0.01分/9.22分 | step: 355840 | performance: 1.5 | accuracy: 0.11 | loss: 0.09
step: 356092 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 254.8
update:1395/2000, 耗时:0.01分/9.25分 | step: 357120 | performance: 1.5 | accuracy: 0.11 | loss: 0.09
step: 358140 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 254.8
update:1400/2000, 耗时:0.01分/9.28分 | step: 358400 | performance: 1.4 | accuracy: 0.11 | loss: 0.11
update:1405/2000, 耗时:0.01分/9.31分 | step: 359680 | performance: 1.4 | accuracy: 0.11 | loss: 0.12
step: 360191 | worker_6@n_step_31: average total_reward after train data exhaustion : 3.0 | max total_reward: 254.8
step: 360700 | worker_3@n_step_31: average total_reward after train data exhaustion : 2.9 | max total_reward: 254.8
update:1410/2000, 耗时:0.01分/9.35分 | step: 360960 | performance: 1.4 | accuracy: 0.11 | loss: 0.09
step: 361723 | worker_2@n_step_31: average total_reward after train data exhaustion : 5.9 | max total_reward: 254.8
update:1415/2000, 耗时:0.01分/9.38分 | step: 362240 | performance: 1.5 | accuracy: 0.11 | loss: 0.09
step: 363001 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 254.8
step: 363519 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1420/2000, 耗时:0.01分/9.41分 | step: 363520 | performance: 1.5 | accuracy: 0.11 | loss: 0.09
update:1425/2000, 耗时:0.01分/9.44分 | step: 364800 | performance: 1.6 | accuracy: 0.10 | loss: 0.08
step: 365818 | worker_1@n_step_31: average total_reward after train data exhaustion : 7.2 | max total_reward: 254.8
update:1430/2000, 耗时:0.01分/9.48分 | step: 366080 | performance: 1.4 | accuracy: 0.10 | loss: 0.11
step: 366843 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 254.8
step: 367359 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
update:1435/2000, 耗时:0.01分/9.51分 | step: 367360 | performance: 1.5 | accuracy: 0.10 | loss: 0.09
step: 367611 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
step: 367872 | worker_7@n_step_31: average total_reward after train data exhaustion : 4.0 | max total_reward: 254.8
step: 368380 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.1 | max total_reward: 254.8
update:1440/2000, 耗时:0.01分/9.54分 | step: 368640 | performance: 1.0 | accuracy: 0.09 | loss: 0.18
step: 369147 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1445/2000, 耗时:0.01分/9.57分 | step: 369920 | performance: 1.0 | accuracy: 0.10 | loss: 0.25
step: 370941 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1450/2000, 耗时:0.01分/9.61分 | step: 371200 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 371454 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.8
step: 371961 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.8
step: 371962 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.8 | max total_reward: 254.8
step: 372477 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
step: 372480 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
update:1455/2000, 耗时:0.01分/9.64分 | step: 372480 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 373498 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
step: 373756 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
update:1460/2000, 耗时:0.01分/9.67分 | step: 373760 | performance: 0.9 | accuracy: 0.11 | loss: 0.23
update:1465/2000, 耗时:0.01分/9.70分 | step: 375040 | performance: 0.8 | accuracy: 0.12 | loss: 0.18
update:1470/2000, 耗时:0.01分/9.73分 | step: 376320 | performance: 1.0 | accuracy: 0.10 | loss: 0.14
step: 376825 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
step: 377599 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 254.8
update:1475/2000, 耗时:0.01分/9.77分 | step: 377600 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
update:1480/2000, 耗时:0.01分/9.80分 | step: 378880 | performance: 0.9 | accuracy: 0.12 | loss: 0.09
step: 379392 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 254.8
step: 379647 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1485/2000, 耗时:0.01分/9.83分 | step: 380160 | performance: 1.2 | accuracy: 0.15 | loss: 0.18
update:1490/2000, 耗时:0.01分/9.87分 | step: 381440 | performance: 1.1 | accuracy: 0.21 | loss: 0.19
update:1495/2000, 耗时:0.01分/9.90分 | step: 382720 | performance: 0.7 | accuracy: 0.10 | loss: 0.22
update:1500/2000, 耗时:0.01分/9.93分 | step: 384000 | performance: 1.1 | accuracy: 0.13 | loss: 0.21
update:1505/2000, 耗时:0.01分/9.97分 | step: 385280 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
update:1510/2000, 耗时:0.01分/10.00分 | step: 386560 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
update:1515/2000, 耗时:0.01分/10.03分 | step: 387840 | performance: 0.9 | accuracy: 0.19 | loss: 0.18
update:1520/2000, 耗时:0.01分/10.07分 | step: 389120 | performance: 1.0 | accuracy: 0.17 | loss: 0.17
update:1525/2000, 耗时:0.01分/10.10分 | step: 390400 | performance: 1.0 | accuracy: 0.07 | loss: 0.18
update:1530/2000, 耗时:0.01分/10.13分 | step: 391680 | performance: 1.0 | accuracy: 0.08 | loss: 0.19
step: 392192 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 254.8
update:1535/2000, 耗时:0.01分/10.17分 | step: 392960 | performance: 1.0 | accuracy: 0.11 | loss: 0.17
update:1540/2000, 耗时:0.01分/10.20分 | step: 394240 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 395008 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 254.8
update:1545/2000, 耗时:0.01分/10.23分 | step: 395520 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:1550/2000, 耗时:0.01分/10.27分 | step: 396800 | performance: 1.1 | accuracy: 0.13 | loss: 0.11
update:1555/2000, 耗时:0.01分/10.30分 | step: 398080 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
update:1560/2000, 耗时:0.01分/10.33分 | step: 399360 | performance: 0.9 | accuracy: 0.00 | loss: 0.15
step: 399872 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1565/2000, 耗时:0.01分/10.36分 | step: 400640 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 401920 | worker_7@n_step_31: average total_reward after train data exhaustion : 4.3 | max total_reward: 254.8
update:1570/2000, 耗时:0.01分/10.40分 | step: 401920 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 403195 | worker_2@n_step_31: average total_reward after train data exhaustion : 13.2 | max total_reward: 254.8
update:1575/2000, 耗时:0.01分/10.43分 | step: 403200 | performance: 0.9 | accuracy: 0.11 | loss: 0.10
step: 404478 | worker_5@n_step_31: average total_reward after train data exhaustion : 8.6 | max total_reward: 254.8
update:1580/2000, 耗时:0.01分/10.46分 | step: 404480 | performance: 0.8 | accuracy: 0.08 | loss: 0.16
update:1585/2000, 耗时:0.01分/10.50分 | step: 405760 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 407040 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 254.8
update:1590/2000, 耗时:0.01分/10.53分 | step: 407040 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:1595/2000, 耗时:0.01分/10.56分 | step: 408320 | performance: 0.9 | accuracy: 0.06 | loss: 0.15
update:1600/2000, 耗时:0.01分/10.59分 | step: 409600 | performance: 1.1 | accuracy: 0.19 | loss: 0.16
step: 409849 | worker_0@n_step_31: average total_reward after train data exhaustion : 9.7 | max total_reward: 254.8
update:1605/2000, 耗时:0.01分/10.63分 | step: 410880 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 411903 | worker_6@n_step_31: average total_reward after train data exhaustion : 3.9 | max total_reward: 254.8
update:1610/2000, 耗时:0.01分/10.66分 | step: 412160 | performance: 1.0 | accuracy: 0.11 | loss: 0.11
update:1615/2000, 耗时:0.01分/10.69分 | step: 413440 | performance: 0.9 | accuracy: 0.09 | loss: 0.22
update:1620/2000, 耗时:0.01分/10.72分 | step: 414720 | performance: 0.9 | accuracy: 0.00 | loss: 0.19
update:1625/2000, 耗时:0.01分/10.76分 | step: 416000 | performance: 1.0 | accuracy: 0.14 | loss: 0.18
update:1630/2000, 耗时:0.01分/10.79分 | step: 417280 | performance: 1.1 | accuracy: 0.16 | loss: 0.13
update:1635/2000, 耗时:0.01分/10.82分 | step: 418560 | performance: 1.1 | accuracy: 0.18 | loss: 0.16
update:1640/2000, 耗时:0.01分/10.86分 | step: 419840 | performance: 1.1 | accuracy: 0.11 | loss: 0.16
update:1645/2000, 耗时:0.01分/10.89分 | step: 421120 | performance: 1.1 | accuracy: 0.12 | loss: 0.11
update:1650/2000, 耗时:0.01分/10.93分 | step: 422400 | performance: 1.1 | accuracy: 0.14 | loss: 0.17
update:1655/2000, 耗时:0.01分/10.96分 | step: 423680 | performance: 1.1 | accuracy: 0.14 | loss: 0.18
update:1660/2000, 耗时:0.01分/11.00分 | step: 424960 | performance: 1.1 | accuracy: 0.14 | loss: 0.19
update:1665/2000, 耗时:0.01分/11.04分 | step: 426240 | performance: 1.1 | accuracy: 0.14 | loss: 0.19
update:1670/2000, 耗时:0.01分/11.07分 | step: 427520 | performance: 1.3 | accuracy: 0.14 | loss: 0.17
update:1675/2000, 耗时:0.01分/11.11分 | step: 428800 | performance: 1.3 | accuracy: 0.14 | loss: 0.11
update:1680/2000, 耗时:0.01分/11.14分 | step: 430080 | performance: 1.2 | accuracy: 0.14 | loss: 0.17
update:1685/2000, 耗时:0.01分/11.17分 | step: 431360 | performance: 1.1 | accuracy: 0.14 | loss: 0.12
update:1690/2000, 耗时:0.01分/11.21分 | step: 432640 | performance: 1.2 | accuracy: 0.14 | loss: 0.16
update:1695/2000, 耗时:0.01分/11.24分 | step: 433920 | performance: 1.2 | accuracy: 0.14 | loss: 0.10
update:1700/2000, 耗时:0.01分/11.28分 | step: 435200 | performance: 1.2 | accuracy: 0.14 | loss: 0.11
step: 435452 | worker_3@n_step_31: average total_reward after train data exhaustion : 5.4 | max total_reward: 254.8
update:1705/2000, 耗时:0.01分/11.31分 | step: 436480 | performance: 1.5 | accuracy: 0.14 | loss: 0.12
step: 437756 | worker_3@n_step_31: average total_reward after train data exhaustion : 5.6 | max total_reward: 254.8
update:1710/2000, 耗时:0.01分/11.34分 | step: 437760 | performance: 1.4 | accuracy: 0.13 | loss: 0.13
update:1715/2000, 耗时:0.01分/11.37分 | step: 439040 | performance: 1.3 | accuracy: 0.13 | loss: 0.11
step: 439547 | worker_2@n_step_31: average total_reward after train data exhaustion : 8.9 | max total_reward: 254.8
update:1720/2000, 耗时:0.01分/11.41分 | step: 440320 | performance: 1.3 | accuracy: 0.13 | loss: 0.07
step: 440572 | worker_3@n_step_31: average total_reward after train data exhaustion : 4.0 | max total_reward: 254.8
step: 441595 | worker_2@n_step_31: average total_reward after train data exhaustion : 7.8 | max total_reward: 254.8
update:1725/2000, 耗时:0.01分/11.44分 | step: 441600 | performance: 1.3 | accuracy: 0.12 | loss: 0.07
step: 442108 | worker_3@n_step_31: average total_reward after train data exhaustion : 6.9 | max total_reward: 254.8
step: 442877 | worker_4@n_step_31: average total_reward after train data exhaustion : 6.9 | max total_reward: 254.8
update:1730/2000, 耗时:0.01分/11.47分 | step: 442880 | performance: 1.3 | accuracy: 0.12 | loss: 0.05
step: 443647 | worker_6@n_step_31: average total_reward after train data exhaustion : 4.4 | max total_reward: 254.8
update:1735/2000, 耗时:0.01分/11.51分 | step: 444160 | performance: 1.2 | accuracy: 0.12 | loss: 0.08
step: 444665 | worker_0@n_step_31: average total_reward after train data exhaustion : 3.8 | max total_reward: 254.8
step: 444923 | worker_2@n_step_31: average total_reward after train data exhaustion : 4.0 | max total_reward: 254.8
step: 445178 | worker_1@n_step_31: average total_reward after train data exhaustion : 3.9 | max total_reward: 254.8
update:1740/2000, 耗时:0.01分/11.54分 | step: 445440 | performance: 1.1 | accuracy: 0.11 | loss: 0.03
step: 446205 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 254.8
update:1745/2000, 耗时:0.01分/11.57分 | step: 446720 | performance: 1.1 | accuracy: 0.11 | loss: 0.02
step: 447999 | worker_6@n_step_31: average total_reward after train data exhaustion : 7.4 | max total_reward: 254.8
update:1750/2000, 耗时:0.01分/11.61分 | step: 448000 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 448505 | worker_0@n_step_31: average total_reward after train data exhaustion : 4.6 | max total_reward: 254.8
step: 448510 | worker_5@n_step_31: average total_reward after train data exhaustion : 4.6 | max total_reward: 254.8
step: 448763 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 254.8
step: 448764 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 254.8
update:1755/2000, 耗时:0.01分/11.64分 | step: 449280 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 449790 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
step: 450045 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 254.8
step: 450304 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 254.8
update:1760/2000, 耗时:0.01分/11.67分 | step: 450560 | performance: 0.9 | accuracy: 0.09 | loss: 0.10
step: 451840 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
update:1765/2000, 耗时:0.01分/11.71分 | step: 451840 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 452092 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
step: 452345 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
update:1770/2000, 耗时:0.01分/11.74分 | step: 453120 | performance: 0.9 | accuracy: 0.00 | loss: 0.04
step: 453370 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 254.8
step: 453630 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 254.8
step: 454139 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 254.8
step: 454400 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1775/2000, 耗时:0.01分/11.77分 | step: 454400 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 454653 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
step: 454907 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 254.8
step: 455678 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.8
update:1780/2000, 耗时:0.01分/11.81分 | step: 455680 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 456443 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
step: 456448 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
update:1785/2000, 耗时:0.01分/11.84分 | step: 456960 | performance: 1.2 | accuracy: 0.12 | loss: 0.17
step: 457212 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 254.8
step: 457977 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.8
step: 458234 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 254.8
update:1790/2000, 耗时:0.01分/11.87分 | step: 458240 | performance: 0.9 | accuracy: 0.11 | loss: 0.14
step: 458748 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.7 | max total_reward: 254.8
update:1795/2000, 耗时:0.01分/11.91分 | step: 459520 | performance: 1.0 | accuracy: 0.10 | loss: 0.27
step: 460794 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 254.8
update:1800/2000, 耗时:0.01分/11.94分 | step: 460800 | performance: 1.7 | accuracy: 0.14 | loss: 0.12
step: 461053 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.9 | max total_reward: 254.8
update:1805/2000, 耗时:0.01分/11.97分 | step: 462080 | performance: 1.6 | accuracy: 0.13 | loss: 0.27
update:1810/2000, 耗时:0.01分/12.01分 | step: 463360 | performance: 1.5 | accuracy: 0.12 | loss: 0.18
update:1815/2000, 耗时:0.01分/12.04分 | step: 464640 | performance: 1.3 | accuracy: 0.12 | loss: 0.16
update:1820/2000, 耗时:0.01分/12.07分 | step: 465920 | performance: 1.1 | accuracy: 0.11 | loss: 0.14
step: 466426 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 254.8
update:1825/2000, 耗时:0.01分/12.10分 | step: 467200 | performance: 1.2 | accuracy: 0.13 | loss: 0.21
update:1830/2000, 耗时:0.01分/12.14分 | step: 468480 | performance: 1.5 | accuracy: 0.13 | loss: 0.30
update:1835/2000, 耗时:0.01分/12.17分 | step: 469760 | performance: 1.4 | accuracy: 0.14 | loss: 0.23
update:1840/2000, 耗时:0.01分/12.20分 | step: 471040 | performance: 1.6 | accuracy: 0.14 | loss: 0.20
update:1845/2000, 耗时:0.01分/12.23分 | step: 472320 | performance: 1.5 | accuracy: 0.14 | loss: 0.17
update:1850/2000, 耗时:0.01分/12.27分 | step: 473600 | performance: 1.7 | accuracy: 0.15 | loss: 0.26
update:1855/2000, 耗时:0.01分/12.30分 | step: 474880 | performance: 1.8 | accuracy: 0.15 | loss: 0.21
update:1860/2000, 耗时:0.01分/12.33分 | step: 476160 | performance: 2.1 | accuracy: 0.15 | loss: 0.28
update:1865/2000, 耗时:0.01分/12.37分 | step: 477440 | performance: 1.8 | accuracy: 0.16 | loss: 0.33
update:1870/2000, 耗时:0.01分/12.40分 | step: 478720 | performance: 2.6 | accuracy: 0.15 | loss: 0.32
update:1875/2000, 耗时:0.01分/12.43分 | step: 480000 | performance: 2.2 | accuracy: 0.15 | loss: 0.32
update:1880/2000, 耗时:0.01分/12.46分 | step: 481280 | performance: 1.9 | accuracy: 0.15 | loss: 0.32
update:1885/2000, 耗时:0.01分/12.50分 | step: 482560 | performance: 2.2 | accuracy: 0.15 | loss: 0.29
update:1890/2000, 耗时:0.01分/12.53分 | step: 483840 | performance: 1.9 | accuracy: 0.15 | loss: 0.32
update:1895/2000, 耗时:0.01分/12.56分 | step: 485120 | performance: 1.7 | accuracy: 0.15 | loss: 0.29
update:1900/2000, 耗时:0.01分/12.60分 | step: 486400 | performance: 1.5 | accuracy: 0.16 | loss: 0.29
update:1905/2000, 耗时:0.01分/12.63分 | step: 487680 | performance: 1.3 | accuracy: 0.16 | loss: 0.27
update:1910/2000, 耗时:0.01分/12.66分 | step: 488960 | performance: 1.1 | accuracy: 0.25 | loss: 0.31
update:1915/2000, 耗时:0.01分/12.69分 | step: 490240 | performance: 0.8 | accuracy: 0.16 | loss: 0.21
update:1920/2000, 耗时:0.01分/12.73分 | step: 491520 | performance: 0.8 | accuracy: 0.15 | loss: 0.12
step: 492281 | worker_0@n_step_31: average total_reward after train data exhaustion : 21.8 | max total_reward: 286.4
step: 492539 | worker_2@n_step_31: average total_reward after train data exhaustion : 25.7 | max total_reward: 286.4
update:1925/2000, 耗时:0.01分/12.76分 | step: 492800 | performance: 0.7 | accuracy: 0.14 | loss: 0.11
step: 493054 | worker_5@n_step_31: average total_reward after train data exhaustion : 25.6 | max total_reward: 286.4
step: 494073 | worker_0@n_step_31: average total_reward after train data exhaustion : 7.6 | max total_reward: 286.4
step: 494075 | worker_2@n_step_31: average total_reward after train data exhaustion : 7.6 | max total_reward: 286.4
update:1930/2000, 耗时:0.01分/12.80分 | step: 494080 | performance: 0.7 | accuracy: 0.14 | loss: 0.09
update:1935/2000, 耗时:0.01分/12.83分 | step: 495360 | performance: 0.6 | accuracy: 0.14 | loss: 0.16
step: 495870 | worker_5@n_step_31: average total_reward after train data exhaustion : 5.4 | max total_reward: 286.4
update:1940/2000, 耗时:0.01分/12.86分 | step: 496640 | performance: 0.6 | accuracy: 0.14 | loss: 0.06
step: 497405 | worker_4@n_step_31: average total_reward after train data exhaustion : 5.1 | max total_reward: 286.4
step: 497657 | worker_0@n_step_31: average total_reward after train data exhaustion : 5.2 | max total_reward: 286.4
update:1945/2000, 耗时:0.01分/12.89分 | step: 497920 | performance: 0.6 | accuracy: 0.13 | loss: 0.17
step: 498685 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 286.4
update:1950/2000, 耗时:0.01分/12.93分 | step: 499200 | performance: 0.6 | accuracy: 0.13 | loss: 0.15
step: 500479 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 286.4
update:1955/2000, 耗时:0.01分/12.96分 | step: 500480 | performance: 0.6 | accuracy: 0.14 | loss: 0.24
step: 500989 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.3 | max total_reward: 286.4
step: 501502 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.3 | max total_reward: 286.4
step: 501757 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.3 | max total_reward: 286.4
update:1960/2000, 耗时:0.01分/12.99分 | step: 501760 | performance: 0.5 | accuracy: 0.14 | loss: 0.22
update:1965/2000, 耗时:0.01分/13.02分 | step: 503040 | performance: 0.6 | accuracy: 0.14 | loss: 0.11
step: 503805 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 286.4
update:1970/2000, 耗时:0.01分/13.06分 | step: 504320 | performance: 0.6 | accuracy: 0.14 | loss: 0.19
update:1975/2000, 耗时:0.01分/13.09分 | step: 505600 | performance: 0.7 | accuracy: 0.14 | loss: 0.13
update:1980/2000, 耗时:0.01分/13.12分 | step: 506880 | performance: 0.7 | accuracy: 0.14 | loss: 0.27
update:1985/2000, 耗时:0.01分/13.15分 | step: 508160 | performance: 0.7 | accuracy: 0.14 | loss: 0.15
step: 509182 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 286.4
update:1990/2000, 耗时:0.01分/13.19分 | step: 509440 | performance: 0.6 | accuracy: 0.13 | loss: 0.17
update:1995/2000, 耗时:0.01分/13.22分 | step: 510720 | performance: 0.6 | accuracy: 0.13 | loss: 0.17
update:2000/2000, 耗时:0.01分/13.25分 | step: 512000 | performance: 0.5 | accuracy: 0.13 | loss: 0.12
----------------------------------------finished----------------------------------------
==================================================
2023-01-10T12:00:00 | *** START BACKTEST ***
2023-01-10T12:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/391 [00:00<?, ?it/s]100%|| 391/391 [00:00<00:00, 129621.63it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1370.99
2023-07-24T12:00:00 | net performance [%] = 37.0989
2023-07-24T12:00:00 | number of trades [#] = 2
==================================================
Trial 43 Complete [00h 13m 42s]
net_wealth: 1372.3612409201346

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 05h 43m 31s

Search: Running Trial #44

Value             |Best Value So Far |Hyperparameter
5                 |7                 |horizon
730               |730               |lookback
False             |False             |MarketFactor
7                 |14                |lags
0.6               |0.7               |gamma
32                |32                |batch_size
7                 |32                |n_step
0.92              |0.92              |gae_lambda
2                 |0.1               |gradient_clip_norm
3                 |5                 |epochs
0.001             |0.0001            |actor_lr
0.0001            |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4310.000000   4315.000000
mean      0.000441    20062.255222  ...   20136.939364  20118.633889
std       0.027818    16039.874230  ...   16077.430342  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7696.969971   7690.540039
50%       0.000642    11554.824463  ...   11742.710449  11715.610352
75%       0.011655    29873.081836  ...   29945.211914  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 03:46:54.030477: I tensorflow/core/platform/cpu_feature_guard.cc:142] This Te2023-07-28 03:46:54.030530: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performan202023-07-28 03:46:54.02023-0ce-27cri-28 03:46:54.tical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the30477: I te02323-07-nn- a28sor 03:047-F62low bi8:n 03:4a54.r60y i:30s 0optimi543602465so:z Ied wpp3: I tr.r03flow0624o20p2re3it- h 0oit7/cor-n282asne02t3e e-0:or fAI nlow/30:socroflroe/wp7la/co4re/tfe-/tenp268:l5 oarpm/cl0pts4orf.f0aut3103o1r lcow_m/fcpou_:o3mp:featu Ifre4ateiP6l _tugeuIn Dee:rr5e_4agup.s No/er efcrd.oml/acrca:01geru/prflow/dc.pc3os.
urlra14_20a]ft8cc9e:a1e:/4 lpf NtuoreltworIatre_ mT/k forgc hLtueainbm2rd.irscc /cpu_s:142] TThe]n saory (oneTpufr_feeatfhlisDNua Toensw/tuN)r tciosoreore _Tguard.cc:142_guard.cc:14o use the following CPU instructions in performe] Thirrs2F/lpl] Thisa TetFlow binaryfn ioorwmsea bin/cpu n_fTs eaeroptimiaznyedc e-critture_wsgiuc oailsaror F ioperadt.hloopwncsorF clr: timboow1i narb4inarFyl i2s ]ow b inay ortneAiTypohnPI Die isiz optiteedss  Tew:nsorFlow bin  AVX AVX2
To enablary is optimized with oneAPI Deep Neural Network Libeipi th rarytm m(oih ienm zeinNo otehd DNN)n eeAPwittohz  use the fuoerorallne opA NetworkPerII Libra ilr Dse oDep ptNoyeaed iwt meiiotns,iw(zoh eidn we p NeuoneAirethrbnge  aolnuD NN) tNPoCePU instructions in performance-criiI teuraical operations: u Deep Nesl Network Library (oAe the folloturwalnPolIeDNN r Deep NNetwodrkkeur )Lw i nT  Litaol gAibensoVbraryNr   Cetwork LFlusX A(owe thiPU bVreroXary with anr2yinstruct  
 (ei(thTo enabloeefoonllDowNN  approtsin)p rhemiattoe  cuneDNgompiler flags.
N) to useo the f CPUn inse  ie Dstructiotnhoen sNNi)l f plo ienwtoring Cllowing CPU insfo nPU oorm  use instruttruche following CPptherancUee insrf-tions in performc critical opooepertructions ain prations:  AVX AVXrerfmtiot2
Tons oriannmanc en caeie--pebrformancelccriticori-ae tl opnticacl heeraanmctieons:-critoprs,itic   AVialX opca lAV X2erra
Toetb ueirli oeoanaint nspbdioons:  tlhe AV:t  TeXr hAeemn seoVXrai AVX2r topinons:  
FT  oAlVotwher operations, rebuoAeX2VX A VX 
ei2nTo
To la blre tde hTewnaiansoth ble them in treoetnhe tm aippabhler opee them in other rnoions,prations,  Flow with the aoperarrppropreri baitiuontialte oetdc o eTbmpcheuri osp,oelil d Tmeernpr flagrs.
ationsieelner, sorb usorFlFrebuild Tflliold TensorFlowow ew w nasiwith thgth tse apprwoitr.F
lhheopri ow a wtite appcrootphreimah the ate compiler  pilapfprlags.
pproproiate cerompilep flarri flags.
ate compiler flags.
gs.
2023-07-28 03:46:54.648924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2022023-3-07-28 03:07-2846:54 03:46:54..659115: I 659120: Ite tensonsorflowr/core/common_runtime/gpu/gpu_device.ccf:1510] Created devlow/core/common_ice /job:localhruntime/gost/reppu/gpu_delica:0/task:0/device:GPU:vi0 with 5454 ce.ccMB memor:1510] Created device /job:ly:  -> devicocalhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, e: 0, name: NcomputeVIDIA GeForce RTX 3070, pc capability: i bu8.6
s id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:46:54.664865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:46:54.668955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:46:54.675266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:46:54.703757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:46:54.706695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   280 | performance: 0.6 | accuracy: 0.49 | loss: 0.69
update: 10/2000, 耗时:0.00分/0.04分 | step:   560 | performance: 0.7 | accuracy: 0.50 | loss: 0.79
update: 15/2000, 耗时:0.00分/0.05分 | step:   840 | performance: 0.7 | accuracy: 0.48 | loss: 0.65
update: 20/2000, 耗时:0.00分/0.06分 | step:  1120 | performance: 0.7 | accuracy: 0.46 | loss: 0.81
update: 25/2000, 耗时:0.00分/0.07分 | step:  1400 | performance: 0.1 | accuracy: 0.41 | loss: 1.76
update: 30/2000, 耗时:0.00分/0.08分 | step:  1680 | performance: 0.2 | accuracy: 0.43 | loss: 3.99
update: 35/2000, 耗时:0.00分/0.09分 | step:  1960 | performance: 0.1 | accuracy: 0.43 | loss: 0.88
update: 40/2000, 耗时:0.00分/0.10分 | step:  2240 | performance: 0.2 | accuracy: 0.43 | loss: 1.22
update: 45/2000, 耗时:0.00分/0.10分 | step:  2520 | performance: 0.2 | accuracy: 0.44 | loss: 0.64
update: 50/2000, 耗时:0.00分/0.11分 | step:  2800 | performance: 0.1 | accuracy: 0.44 | loss: 2.38
update: 55/2000, 耗时:0.00分/0.13分 | step:  3080 | performance: 0.1 | accuracy: 0.43 | loss: 1.36
update: 60/2000, 耗时:0.00分/0.14分 | step:  3360 | performance: 0.1 | accuracy: 0.42 | loss: 2.75
update: 65/2000, 耗时:0.00分/0.15分 | step:  3640 | performance: 0.0 | accuracy: 0.40 | loss: 0.25
update: 70/2000, 耗时:0.00分/0.16分 | step:  3920 | performance: 0.0 | accuracy: 0.37 | loss: 0.43
update: 75/2000, 耗时:0.00分/0.17分 | step:  4200 | performance: 0.1 | accuracy: 0.36 | loss: 0.40
update: 80/2000, 耗时:0.00分/0.18分 | step:  4480 | performance: 0.1 | accuracy: 0.34 | loss: 0.49
update: 85/2000, 耗时:0.00分/0.19分 | step:  4760 | performance: 0.2 | accuracy: 0.35 | loss: 1.75
update: 90/2000, 耗时:0.00分/0.20分 | step:  5040 | performance: 0.2 | accuracy: 0.36 | loss: 2.14
update: 95/2000, 耗时:0.00分/0.21分 | step:  5320 | performance: 0.1 | accuracy: 0.36 | loss: 0.84
update:100/2000, 耗时:0.00分/0.23分 | step:  5600 | performance: 0.1 | accuracy: 0.36 | loss: 4.28
update:105/2000, 耗时:0.00分/0.24分 | step:  5880 | performance: 0.1 | accuracy: 0.37 | loss: 2.65
update:110/2000, 耗时:0.00分/0.25分 | step:  6160 | performance: 0.1 | accuracy: 0.37 | loss: 1.08
update:115/2000, 耗时:0.00分/0.26分 | step:  6440 | performance: 0.0 | accuracy: 0.37 | loss: 1.63
update:120/2000, 耗时:0.00分/0.27分 | step:  6720 | performance: 0.0 | accuracy: 0.37 | loss: 1.50
update:125/2000, 耗时:0.00分/0.28分 | step:  7000 | performance: 0.0 | accuracy: 0.37 | loss: 0.82
update:130/2000, 耗时:0.00分/0.29分 | step:  7280 | performance: 0.0 | accuracy: 0.36 | loss: 0.85
update:135/2000, 耗时:0.00分/0.31分 | step:  7560 | performance: 0.0 | accuracy: 0.35 | loss: 0.85
update:140/2000, 耗时:0.00分/0.32分 | step:  7840 | performance: 0.0 | accuracy: 0.35 | loss: 0.70
update:145/2000, 耗时:0.00分/0.33分 | step:  8120 | performance: 0.0 | accuracy: 0.34 | loss: 0.16
update:150/2000, 耗时:0.00分/0.34分 | step:  8400 | performance: 0.0 | accuracy: 0.34 | loss: 0.27
update:155/2000, 耗时:0.00分/0.35分 | step:  8680 | performance: 0.0 | accuracy: 0.34 | loss: 0.56
update:160/2000, 耗时:0.00分/0.36分 | step:  8960 | performance: 0.0 | accuracy: 0.33 | loss: 1.54
update:165/2000, 耗时:0.00分/0.38分 | step:  9240 | performance: 0.0 | accuracy: 0.33 | loss: 0.19
update:170/2000, 耗时:0.00分/0.39分 | step:  9520 | performance: 0.0 | accuracy: 0.32 | loss: 0.14
update:175/2000, 耗时:0.00分/0.40分 | step:  9800 | performance: 0.0 | accuracy: 0.31 | loss: 0.18
update:180/2000, 耗时:0.00分/0.41分 | step: 10080 | performance: 0.0 | accuracy: 0.31 | loss: 0.61
update:185/2000, 耗时:0.00分/0.42分 | step: 10360 | performance: 0.0 | accuracy: 0.30 | loss: 0.06
update:190/2000, 耗时:0.00分/0.43分 | step: 10640 | performance: 0.0 | accuracy: 0.30 | loss: 0.30
update:195/2000, 耗时:0.00分/0.44分 | step: 10920 | performance: 0.0 | accuracy: 0.29 | loss: 0.15
update:200/2000, 耗时:0.00分/0.45分 | step: 11200 | performance: 0.0 | accuracy: 0.29 | loss: 0.23
update:205/2000, 耗时:0.00分/0.46分 | step: 11480 | performance: 0.0 | accuracy: 0.28 | loss: 0.27
update:210/2000, 耗时:0.00分/0.47分 | step: 11760 | performance: 0.0 | accuracy: 0.27 | loss: 0.39
update:215/2000, 耗时:0.00分/0.48分 | step: 12040 | performance: 0.0 | accuracy: 0.27 | loss: 0.09
update:220/2000, 耗时:0.00分/0.49分 | step: 12320 | performance: 0.0 | accuracy: 0.27 | loss: 0.09
update:225/2000, 耗时:0.00分/0.50分 | step: 12600 | performance: 0.0 | accuracy: 0.26 | loss: 0.07
update:230/2000, 耗时:0.00分/0.52分 | step: 12880 | performance: 0.0 | accuracy: 0.27 | loss: 0.83
update:235/2000, 耗时:0.00分/0.53分 | step: 13160 | performance: 0.0 | accuracy: 0.28 | loss: 1.42
update:240/2000, 耗时:0.00分/0.54分 | step: 13440 | performance: 0.0 | accuracy: 0.28 | loss: 3.64
update:245/2000, 耗时:0.00分/0.55分 | step: 13720 | performance: 0.1 | accuracy: 0.29 | loss: 1.31
update:250/2000, 耗时:0.00分/0.56分 | step: 14000 | performance: 0.1 | accuracy: 0.30 | loss: 8.21
update:255/2000, 耗时:0.00分/0.57分 | step: 14280 | performance: 0.3 | accuracy: 0.30 | loss: 1.73
update:260/2000, 耗时:0.00分/0.58分 | step: 14560 | performance: 0.4 | accuracy: 0.31 | loss: 7.16
update:265/2000, 耗时:0.00分/0.59分 | step: 14840 | performance: 0.9 | accuracy: 0.32 | loss: 3.22
update:270/2000, 耗时:0.00分/0.61分 | step: 15120 | performance: 1.0 | accuracy: 0.32 | loss: 0.51
update:275/2000, 耗时:0.00分/0.62分 | step: 15400 | performance: 0.8 | accuracy: 0.32 | loss: 4.58
update:280/2000, 耗时:0.00分/0.63分 | step: 15680 | performance: 0.7 | accuracy: 0.33 | loss: 0.95
update:285/2000, 耗时:0.00分/0.64分 | step: 15960 | performance: 0.1 | accuracy: 0.32 | loss: 0.69
update:290/2000, 耗时:0.00分/0.65分 | step: 16240 | performance: 0.1 | accuracy: 0.32 | loss: 0.22
update:295/2000, 耗时:0.00分/0.66分 | step: 16520 | performance: 0.1 | accuracy: 0.31 | loss: 0.14
update:300/2000, 耗时:0.00分/0.68分 | step: 16800 | performance: 0.1 | accuracy: 0.31 | loss: 0.05
update:305/2000, 耗时:0.00分/0.69分 | step: 17080 | performance: 0.1 | accuracy: 0.31 | loss: 0.54
update:310/2000, 耗时:0.00分/0.70分 | step: 17360 | performance: 0.1 | accuracy: 0.31 | loss: 0.63
update:315/2000, 耗时:0.00分/0.71分 | step: 17640 | performance: 0.1 | accuracy: 0.31 | loss: 0.60
update:320/2000, 耗时:0.00分/0.72分 | step: 17920 | performance: 0.1 | accuracy: 0.30 | loss: 0.31
update:325/2000, 耗时:0.00分/0.74分 | step: 18200 | performance: 0.1 | accuracy: 0.30 | loss: 0.51
update:330/2000, 耗时:0.00分/0.75分 | step: 18480 | performance: 0.1 | accuracy: 0.31 | loss: 1.48
update:335/2000, 耗时:0.00分/0.76分 | step: 18760 | performance: 0.1 | accuracy: 0.31 | loss: 0.86
update:340/2000, 耗时:0.00分/0.77分 | step: 19040 | performance: 0.0 | accuracy: 0.31 | loss: 0.58
update:345/2000, 耗时:0.00分/0.78分 | step: 19320 | performance: 0.0 | accuracy: 0.30 | loss: 0.18
update:350/2000, 耗时:0.00分/0.79分 | step: 19600 | performance: 0.0 | accuracy: 0.30 | loss: 0.09
update:355/2000, 耗时:0.00分/0.81分 | step: 19880 | performance: 0.0 | accuracy: 0.30 | loss: 0.19
update:360/2000, 耗时:0.00分/0.82分 | step: 20160 | performance: 0.0 | accuracy: 0.29 | loss: 0.06
update:365/2000, 耗时:0.00分/0.83分 | step: 20440 | performance: 0.0 | accuracy: 0.29 | loss: 0.04
update:370/2000, 耗时:0.00分/0.84分 | step: 20720 | performance: 0.0 | accuracy: 0.28 | loss: 0.00
update:375/2000, 耗时:0.00分/0.85分 | step: 21000 | performance: 0.0 | accuracy: 0.28 | loss: 0.20
update:380/2000, 耗时:0.00分/0.87分 | step: 21280 | performance: 0.0 | accuracy: 0.28 | loss: 0.00
update:385/2000, 耗时:0.00分/0.88分 | step: 21560 | performance: 0.0 | accuracy: 0.27 | loss: 0.01
update:390/2000, 耗时:0.00分/0.89分 | step: 21840 | performance: 0.0 | accuracy: 0.27 | loss: -0.01
update:395/2000, 耗时:0.00分/0.90分 | step: 22120 | performance: 0.0 | accuracy: 0.27 | loss: 0.72
update:400/2000, 耗时:0.00分/0.91分 | step: 22400 | performance: 0.1 | accuracy: 0.28 | loss: 2.04
update:405/2000, 耗时:0.00分/0.92分 | step: 22680 | performance: 0.0 | accuracy: 0.28 | loss: 3.10
update:410/2000, 耗时:0.00分/0.94分 | step: 22960 | performance: 0.0 | accuracy: 0.28 | loss: 0.51
update:415/2000, 耗时:0.00分/0.95分 | step: 23240 | performance: 0.0 | accuracy: 0.28 | loss: 1.10
update:420/2000, 耗时:0.00分/0.96分 | step: 23520 | performance: 0.0 | accuracy: 0.28 | loss: 1.76
update:425/2000, 耗时:0.00分/0.97分 | step: 23800 | performance: 0.1 | accuracy: 0.29 | loss: 0.77
update:430/2000, 耗时:0.00分/0.98分 | step: 24080 | performance: 0.1 | accuracy: 0.29 | loss: 0.79
update:435/2000, 耗时:0.00分/0.99分 | step: 24360 | performance: 0.0 | accuracy: 0.29 | loss: 0.81
update:440/2000, 耗时:0.00分/1.00分 | step: 24640 | performance: 0.1 | accuracy: 0.30 | loss: 0.58
update:445/2000, 耗时:0.00分/1.02分 | step: 24920 | performance: 0.1 | accuracy: 0.30 | loss: 1.25
update:450/2000, 耗时:0.00分/1.03分 | step: 25200 | performance: 0.1 | accuracy: 0.30 | loss: 0.78
Saving PPO weights in both H5 format and checkpoint @ update:453 
update:455/2000, 耗时:0.00分/1.05分 | step: 25480 | performance: 0.9 | accuracy: 0.07 | loss: 0.12
update:460/2000, 耗时:0.00分/1.06分 | step: 25760 | performance: 1.1 | accuracy: 0.15 | loss: 0.57
update:465/2000, 耗时:0.00分/1.07分 | step: 26040 | performance: 1.1 | accuracy: 0.21 | loss: 0.33
update:470/2000, 耗时:0.00分/1.08分 | step: 26320 | performance: 1.3 | accuracy: 0.23 | loss: 0.64
update:475/2000, 耗时:0.00分/1.09分 | step: 26600 | performance: 1.4 | accuracy: 0.28 | loss: 1.68
update:480/2000, 耗时:0.00分/1.10分 | step: 26880 | performance: 13.8 | accuracy: 0.38 | loss: 1.38
update:485/2000, 耗时:0.00分/1.11分 | step: 27160 | performance: 32.4 | accuracy: 0.44 | loss: 2.54
update:490/2000, 耗时:0.00分/1.13分 | step: 27440 | performance: 19.9 | accuracy: 0.45 | loss: 1.88
update:495/2000, 耗时:0.00分/1.14分 | step: 27720 | performance: 25.2 | accuracy: 0.45 | loss: 1.05
update:500/2000, 耗时:0.00分/1.15分 | step: 28000 | performance: 31.4 | accuracy: 0.45 | loss: 0.99
update:505/2000, 耗时:0.00分/1.16分 | step: 28280 | performance: 16.8 | accuracy: 0.45 | loss: 2.11
update:510/2000, 耗时:0.00分/1.17分 | step: 28560 | performance: 18.6 | accuracy: 0.44 | loss: 0.98
update:515/2000, 耗时:0.00分/1.18分 | step: 28840 | performance: 16.3 | accuracy: 0.44 | loss: 1.68
update:520/2000, 耗时:0.00分/1.19分 | step: 29120 | performance: 4.3 | accuracy: 0.42 | loss: 0.75
update:525/2000, 耗时:0.00分/1.21分 | step: 29400 | performance: 4.0 | accuracy: 0.39 | loss: 0.59
update:530/2000, 耗时:0.00分/1.22分 | step: 29680 | performance: 20.5 | accuracy: 0.41 | loss: 2.32
update:535/2000, 耗时:0.00分/1.23分 | step: 29960 | performance: 17.0 | accuracy: 0.41 | loss: 1.72
update:540/2000, 耗时:0.00分/1.24分 | step: 30240 | performance: 65.9 | accuracy: 0.42 | loss: 3.10
update:545/2000, 耗时:0.00分/1.25分 | step: 30520 | performance: 101.6 | accuracy: 0.43 | loss: 1.86
update:550/2000, 耗时:0.00分/1.26分 | step: 30800 | performance: 33.4 | accuracy: 0.41 | loss: 2.20
update:555/2000, 耗时:0.00分/1.27分 | step: 31080 | performance: 46.7 | accuracy: 0.42 | loss: 2.68
update:560/2000, 耗时:0.00分/1.29分 | step: 31360 | performance: 33.9 | accuracy: 0.43 | loss: 1.28
update:565/2000, 耗时:0.00分/1.30分 | step: 31640 | performance: 35.1 | accuracy: 0.43 | loss: 2.27
update:570/2000, 耗时:0.00分/1.31分 | step: 31920 | performance: 10.9 | accuracy: 0.42 | loss: 0.77
update:575/2000, 耗时:0.00分/1.32分 | step: 32200 | performance: 9.8 | accuracy: 0.41 | loss: 0.85
update:580/2000, 耗时:0.00分/1.33分 | step: 32480 | performance: 16.9 | accuracy: 0.41 | loss: 0.87
update:585/2000, 耗时:0.00分/1.34分 | step: 32760 | performance: 17.7 | accuracy: 0.40 | loss: 0.75
update:590/2000, 耗时:0.00分/1.35分 | step: 33040 | performance: 17.0 | accuracy: 0.40 | loss: 1.21
update:595/2000, 耗时:0.00分/1.37分 | step: 33320 | performance: 15.6 | accuracy: 0.40 | loss: 0.66
update:600/2000, 耗时:0.00分/1.38分 | step: 33600 | performance: 9.1 | accuracy: 0.39 | loss: 0.16
update:605/2000, 耗时:0.00分/1.39分 | step: 33880 | performance: 9.1 | accuracy: 0.38 | loss: 0.06
update:610/2000, 耗时:0.00分/1.40分 | step: 34160 | performance: 9.1 | accuracy: 0.37 | loss: 0.03
update:615/2000, 耗时:0.00分/1.41分 | step: 34440 | performance: 8.9 | accuracy: 0.36 | loss: 0.49
update:620/2000, 耗时:0.00分/1.42分 | step: 34720 | performance: 16.6 | accuracy: 0.35 | loss: 0.26
update:625/2000, 耗时:0.00分/1.43分 | step: 35000 | performance: 15.8 | accuracy: 0.34 | loss: 0.22
update:630/2000, 耗时:0.00分/1.44分 | step: 35280 | performance: 15.3 | accuracy: 0.33 | loss: 0.01
update:635/2000, 耗时:0.00分/1.46分 | step: 35560 | performance: 15.3 | accuracy: 0.32 | loss: 0.01
update:640/2000, 耗时:0.00分/1.47分 | step: 35840 | performance: 15.3 | accuracy: 0.32 | loss: 0.02
update:645/2000, 耗时:0.00分/1.48分 | step: 36120 | performance: 15.3 | accuracy: 0.31 | loss: 0.04
update:650/2000, 耗时:0.00分/1.49分 | step: 36400 | performance: 15.2 | accuracy: 0.30 | loss: 0.11
update:655/2000, 耗时:0.00分/1.50分 | step: 36680 | performance: 15.3 | accuracy: 0.30 | loss: 0.01
update:660/2000, 耗时:0.00分/1.51分 | step: 36960 | performance: 15.3 | accuracy: 0.29 | loss: 0.00
update:665/2000, 耗时:0.00分/1.52分 | step: 37240 | performance: 15.7 | accuracy: 0.28 | loss: -0.01
update:670/2000, 耗时:0.00分/1.53分 | step: 37520 | performance: 14.7 | accuracy: 0.28 | loss: 0.05
update:675/2000, 耗时:0.00分/1.55分 | step: 37800 | performance: 14.6 | accuracy: 0.28 | loss: 0.07
update:680/2000, 耗时:0.00分/1.56分 | step: 38080 | performance: 14.4 | accuracy: 0.27 | loss: 0.00
update:685/2000, 耗时:0.00分/1.57分 | step: 38360 | performance: 14.4 | accuracy: 0.27 | loss: 0.00
update:690/2000, 耗时:0.00分/1.58分 | step: 38640 | performance: 18.4 | accuracy: 0.26 | loss: 0.02
update:695/2000, 耗时:0.00分/1.59分 | step: 38920 | performance: 17.2 | accuracy: 0.26 | loss: 0.15
update:700/2000, 耗时:0.00分/1.60分 | step: 39200 | performance: 17.0 | accuracy: 0.25 | loss: 0.04
update:705/2000, 耗时:0.00分/1.61分 | step: 39480 | performance: 16.8 | accuracy: 0.25 | loss: 0.06
update:710/2000, 耗时:0.00分/1.63分 | step: 39760 | performance: 18.2 | accuracy: 0.24 | loss: 0.35
update:715/2000, 耗时:0.00分/1.64分 | step: 40040 | performance: 32.6 | accuracy: 0.25 | loss: 3.24
update:720/2000, 耗时:0.00分/1.65分 | step: 40320 | performance: 72.7 | accuracy: 0.26 | loss: 2.15
update:725/2000, 耗时:0.00分/1.66分 | step: 40600 | performance: 78.8 | accuracy: 0.26 | loss: 1.75
update:730/2000, 耗时:0.00分/1.67分 | step: 40880 | performance: 53.3 | accuracy: 0.27 | loss: 2.28
update:735/2000, 耗时:0.00分/1.68分 | step: 41160 | performance: 39.4 | accuracy: 0.27 | loss: 0.97
update:740/2000, 耗时:0.00分/1.69分 | step: 41440 | performance: 25.1 | accuracy: 0.26 | loss: 0.29
update:745/2000, 耗时:0.00分/1.71分 | step: 41720 | performance: 25.4 | accuracy: 0.26 | loss: -0.00
update:750/2000, 耗时:0.00分/1.72分 | step: 42000 | performance: 25.4 | accuracy: 0.25 | loss: 0.01
update:755/2000, 耗时:0.00分/1.73分 | step: 42280 | performance: 25.4 | accuracy: 0.25 | loss: 0.05
update:760/2000, 耗时:0.00分/1.74分 | step: 42560 | performance: 25.4 | accuracy: 0.25 | loss: 0.02
update:765/2000, 耗时:0.00分/1.75分 | step: 42840 | performance: 25.4 | accuracy: 0.24 | loss: 0.00
update:770/2000, 耗时:0.00分/1.76分 | step: 43120 | performance: 25.4 | accuracy: 0.24 | loss: 0.04
update:775/2000, 耗时:0.00分/1.77分 | step: 43400 | performance: 25.6 | accuracy: 0.24 | loss: 0.04
update:780/2000, 耗时:0.00分/1.78分 | step: 43680 | performance: 25.2 | accuracy: 0.23 | loss: 0.07
update:785/2000, 耗时:0.00分/1.80分 | step: 43960 | performance: 25.5 | accuracy: 0.23 | loss: 0.13
update:790/2000, 耗时:0.00分/1.81分 | step: 44240 | performance: 27.4 | accuracy: 0.23 | loss: 0.16
update:795/2000, 耗时:0.00分/1.82分 | step: 44520 | performance: 27.4 | accuracy: 0.23 | loss: 0.13
update:800/2000, 耗时:0.00分/1.83分 | step: 44800 | performance: 19.6 | accuracy: 0.22 | loss: 0.16
update:805/2000, 耗时:0.00分/1.84分 | step: 45080 | performance: 20.9 | accuracy: 0.22 | loss: 0.07
update:810/2000, 耗时:0.00分/1.85分 | step: 45360 | performance: 38.7 | accuracy: 0.22 | loss: 0.55
update:815/2000, 耗时:0.00分/1.86分 | step: 45640 | performance: 30.9 | accuracy: 0.22 | loss: 0.23
update:820/2000, 耗时:0.00分/1.88分 | step: 45920 | performance: 33.1 | accuracy: 0.22 | loss: 0.01
update:825/2000, 耗时:0.00分/1.89分 | step: 46200 | performance: 33.1 | accuracy: 0.21 | loss: 0.01
update:830/2000, 耗时:0.00分/1.90分 | step: 46480 | performance: 32.0 | accuracy: 0.21 | loss: 0.09
update:835/2000, 耗时:0.00分/1.91分 | step: 46760 | performance: 32.0 | accuracy: 0.21 | loss: 0.10
update:840/2000, 耗时:0.00分/1.92分 | step: 47040 | performance: 32.0 | accuracy: 0.21 | loss: 0.16
update:845/2000, 耗时:0.00分/1.93分 | step: 47320 | performance: 35.8 | accuracy: 0.21 | loss: 0.12
update:850/2000, 耗时:0.00分/1.94分 | step: 47600 | performance: 48.5 | accuracy: 0.21 | loss: 0.96
update:855/2000, 耗时:0.00分/1.95分 | step: 47880 | performance: 104.9 | accuracy: 0.21 | loss: 2.60
update:860/2000, 耗时:0.00分/1.97分 | step: 48160 | performance: 68.4 | accuracy: 0.21 | loss: 2.26
update:865/2000, 耗时:0.00分/1.98分 | step: 48440 | performance: 47.6 | accuracy: 0.22 | loss: 1.14
update:870/2000, 耗时:0.00分/1.99分 | step: 48720 | performance: 73.4 | accuracy: 0.22 | loss: 1.15
update:875/2000, 耗时:0.00分/2.00分 | step: 49000 | performance: 119.8 | accuracy: 0.22 | loss: 1.30
update:880/2000, 耗时:0.00分/2.01分 | step: 49280 | performance: 133.4 | accuracy: 0.23 | loss: 0.98
update:885/2000, 耗时:0.00分/2.02分 | step: 49560 | performance: 130.9 | accuracy: 0.23 | loss: 1.18
update:890/2000, 耗时:0.00分/2.04分 | step: 49840 | performance: 93.3 | accuracy: 0.23 | loss: 1.39
update:895/2000, 耗时:0.00分/2.05分 | step: 50120 | performance: 281.9 | accuracy: 0.24 | loss: 1.83
update:900/2000, 耗时:0.00分/2.06分 | step: 50400 | performance: 262.3 | accuracy: 0.24 | loss: 1.22
update:905/2000, 耗时:0.00分/2.07分 | step: 50680 | performance: 270.3 | accuracy: 0.24 | loss: 1.30
Saving PPO weights in both H5 format and checkpoint @ update:909 
update:910/2000, 耗时:0.00分/2.09分 | step: 50960 | performance: 1.4 | accuracy: 0.38 | loss: 1.87
Saving PPO weights in both H5 format and checkpoint @ update:911 
update:915/2000, 耗时:0.00分/2.10分 | step: 51240 | performance: 1.3 | accuracy: 0.46 | loss: 0.97
update:920/2000, 耗时:0.00分/2.12分 | step: 51520 | performance: 1.7 | accuracy: 0.47 | loss: 1.51
update:925/2000, 耗时:0.00分/2.13分 | step: 51800 | performance: 1.7 | accuracy: 0.52 | loss: 1.52
update:930/2000, 耗时:0.00分/2.14分 | step: 52080 | performance: 3.2 | accuracy: 0.50 | loss: 2.39
update:935/2000, 耗时:0.00分/2.15分 | step: 52360 | performance: 18.9 | accuracy: 0.55 | loss: 1.11
update:940/2000, 耗时:0.00分/2.16分 | step: 52640 | performance: 23.4 | accuracy: 0.57 | loss: 3.15
update:945/2000, 耗时:0.00分/2.18分 | step: 52920 | performance: 22.8 | accuracy: 0.55 | loss: 1.45
update:950/2000, 耗时:0.00分/2.19分 | step: 53200 | performance: 39.9 | accuracy: 0.55 | loss: 1.63
update:955/2000, 耗时:0.00分/2.20分 | step: 53480 | performance: 37.0 | accuracy: 0.55 | loss: 2.29
update:960/2000, 耗时:0.00分/2.21分 | step: 53760 | performance: 29.9 | accuracy: 0.53 | loss: 1.66
update:965/2000, 耗时:0.00分/2.22分 | step: 54040 | performance: 25.2 | accuracy: 0.52 | loss: 1.05
update:970/2000, 耗时:0.00分/2.24分 | step: 54320 | performance: 8.8 | accuracy: 0.50 | loss: 2.20
update:975/2000, 耗时:0.00分/2.25分 | step: 54600 | performance: 7.1 | accuracy: 0.47 | loss: 0.74
update:980/2000, 耗时:0.00分/2.26分 | step: 54880 | performance: 6.0 | accuracy: 0.46 | loss: 0.37
update:985/2000, 耗时:0.00分/2.27分 | step: 55160 | performance: 11.2 | accuracy: 0.45 | loss: 1.74
update:990/2000, 耗时:0.00分/2.28分 | step: 55440 | performance: 9.4 | accuracy: 0.44 | loss: 1.07
update:995/2000, 耗时:0.00分/2.30分 | step: 55720 | performance: 34.2 | accuracy: 0.45 | loss: 2.97
update:1000/2000, 耗时:0.00分/2.31分 | step: 56000 | performance: 24.2 | accuracy: 0.45 | loss: 2.59
update:1005/2000, 耗时:0.00分/2.32分 | step: 56280 | performance: 40.9 | accuracy: 0.46 | loss: 2.57
update:1010/2000, 耗时:0.00分/2.33分 | step: 56560 | performance: 22.2 | accuracy: 0.46 | loss: 2.62
update:1015/2000, 耗时:0.00分/2.34分 | step: 56840 | performance: 23.6 | accuracy: 0.46 | loss: 1.79
update:1020/2000, 耗时:0.00分/2.36分 | step: 57120 | performance: 7.3 | accuracy: 0.45 | loss: 2.62
update:1025/2000, 耗时:0.00分/2.37分 | step: 57400 | performance: 8.5 | accuracy: 0.45 | loss: 0.64
update:1030/2000, 耗时:0.00分/2.38分 | step: 57680 | performance: 10.9 | accuracy: 0.44 | loss: 0.88
update:1035/2000, 耗时:0.00分/2.39分 | step: 57960 | performance: 8.8 | accuracy: 0.43 | loss: 0.55
update:1040/2000, 耗时:0.00分/2.40分 | step: 58240 | performance: 9.2 | accuracy: 0.43 | loss: 0.82
update:1045/2000, 耗时:0.00分/2.42分 | step: 58520 | performance: 10.6 | accuracy: 0.43 | loss: 0.45
update:1050/2000, 耗时:0.00分/2.43分 | step: 58800 | performance: 10.8 | accuracy: 0.42 | loss: 0.47
update:1055/2000, 耗时:0.00分/2.44分 | step: 59080 | performance: 10.5 | accuracy: 0.42 | loss: 0.37
update:1060/2000, 耗时:0.00分/2.45分 | step: 59360 | performance: 11.5 | accuracy: 0.41 | loss: 0.28
update:1065/2000, 耗时:0.00分/2.46分 | step: 59640 | performance: 8.6 | accuracy: 0.40 | loss: 0.36
update:1070/2000, 耗时:0.00分/2.48分 | step: 59920 | performance: 6.6 | accuracy: 0.39 | loss: 1.38
update:1075/2000, 耗时:0.00分/2.49分 | step: 60200 | performance: 6.0 | accuracy: 0.39 | loss: 0.33
update:1080/2000, 耗时:0.00分/2.50分 | step: 60480 | performance: 7.0 | accuracy: 0.38 | loss: 0.51
update:1085/2000, 耗时:0.00分/2.51分 | step: 60760 | performance: 6.4 | accuracy: 0.38 | loss: 1.03
update:1090/2000, 耗时:0.00分/2.52分 | step: 61040 | performance: 6.2 | accuracy: 0.37 | loss: 0.33
update:1095/2000, 耗时:0.00分/2.54分 | step: 61320 | performance: 6.0 | accuracy: 0.37 | loss: 0.30
update:1100/2000, 耗时:0.00分/2.55分 | step: 61600 | performance: 6.1 | accuracy: 0.36 | loss: 0.13
update:1105/2000, 耗时:0.00分/2.56分 | step: 61880 | performance: 6.3 | accuracy: 0.36 | loss: 0.20
update:1110/2000, 耗时:0.00分/2.57分 | step: 62160 | performance: 11.9 | accuracy: 0.36 | loss: 0.55
update:1115/2000, 耗时:0.00分/2.58分 | step: 62440 | performance: 10.6 | accuracy: 0.35 | loss: 0.30
update:1120/2000, 耗时:0.00分/2.60分 | step: 62720 | performance: 11.8 | accuracy: 0.35 | loss: 0.07
update:1125/2000, 耗时:0.00分/2.61分 | step: 63000 | performance: 11.8 | accuracy: 0.34 | loss: 0.14
update:1130/2000, 耗时:0.00分/2.62分 | step: 63280 | performance: 12.6 | accuracy: 0.34 | loss: 0.19
update:1135/2000, 耗时:0.00分/2.63分 | step: 63560 | performance: 19.7 | accuracy: 0.34 | loss: 0.66
update:1140/2000, 耗时:0.00分/2.64分 | step: 63840 | performance: 63.5 | accuracy: 0.35 | loss: 2.19
update:1145/2000, 耗时:0.00分/2.65分 | step: 64120 | performance: 81.2 | accuracy: 0.35 | loss: 1.27
update:1150/2000, 耗时:0.00分/2.66分 | step: 64400 | performance: 240.4 | accuracy: 0.36 | loss: 1.40
update:1155/2000, 耗时:0.00分/2.68分 | step: 64680 | performance: 1917.8 | accuracy: 0.37 | loss: 3.82
update:1160/2000, 耗时:0.00分/2.69分 | step: 64960 | performance: 1166.5 | accuracy: 0.37 | loss: 2.76
update:1165/2000, 耗时:0.00分/2.70分 | step: 65240 | performance: 7457.3 | accuracy: 0.38 | loss: 3.12
update:1170/2000, 耗时:0.00分/2.71分 | step: 65520 | performance: 7499.6 | accuracy: 0.38 | loss: 2.45
update:1175/2000, 耗时:0.00分/2.72分 | step: 65800 | performance: 14239.4 | accuracy: 0.38 | loss: 2.20
update:1180/2000, 耗时:0.00分/2.73分 | step: 66080 | performance: 15098.1 | accuracy: 0.39 | loss: 1.81
update:1185/2000, 耗时:0.00分/2.74分 | step: 66360 | performance: 9063.6 | accuracy: 0.39 | loss: 2.33
update:1190/2000, 耗时:0.00分/2.76分 | step: 66640 | performance: 7942.9 | accuracy: 0.39 | loss: 2.05
update:1195/2000, 耗时:0.00分/2.77分 | step: 66920 | performance: 2862.0 | accuracy: 0.38 | loss: 0.09
update:1200/2000, 耗时:0.00分/2.78分 | step: 67200 | performance: 2447.8 | accuracy: 0.38 | loss: 0.01
update:1205/2000, 耗时:0.00分/2.79分 | step: 67480 | performance: 2447.8 | accuracy: 0.37 | loss: 0.00
update:1210/2000, 耗时:0.00分/2.80分 | step: 67760 | performance: 2447.8 | accuracy: 0.36 | loss: 0.07
update:1215/2000, 耗时:0.00分/2.81分 | step: 68040 | performance: 2447.8 | accuracy: 0.36 | loss: 0.05
update:1220/2000, 耗时:0.00分/2.83分 | step: 68320 | performance: 2447.8 | accuracy: 0.35 | loss: 0.00
update:1225/2000, 耗时:0.00分/2.84分 | step: 68600 | performance: 2447.8 | accuracy: 0.35 | loss: 0.07
update:1230/2000, 耗时:0.00分/2.85分 | step: 68880 | performance: 1843.1 | accuracy: 0.34 | loss: 0.16
update:1235/2000, 耗时:0.00分/2.86分 | step: 69160 | performance: 3385.9 | accuracy: 0.34 | loss: 0.42
update:1240/2000, 耗时:0.00分/2.87分 | step: 69440 | performance: 3523.2 | accuracy: 0.34 | loss: 0.87
update:1245/2000, 耗时:0.00分/2.88分 | step: 69720 | performance: 3807.5 | accuracy: 0.34 | loss: 0.12
update:1250/2000, 耗时:0.00分/2.90分 | step: 70000 | performance: 4051.2 | accuracy: 0.33 | loss: 0.15
update:1255/2000, 耗时:0.00分/2.91分 | step: 70280 | performance: 4392.1 | accuracy: 0.33 | loss: 0.08
update:1260/2000, 耗时:0.00分/2.92分 | step: 70560 | performance: 4150.6 | accuracy: 0.33 | loss: 0.56
update:1265/2000, 耗时:0.00分/2.93分 | step: 70840 | performance: 4514.1 | accuracy: 0.33 | loss: 1.49
update:1270/2000, 耗时:0.00分/2.94分 | step: 71120 | performance: 2702.4 | accuracy: 0.33 | loss: 0.79
update:1275/2000, 耗时:0.00分/2.95分 | step: 71400 | performance: 3206.1 | accuracy: 0.33 | loss: 1.01
update:1280/2000, 耗时:0.00分/2.97分 | step: 71680 | performance: 3254.9 | accuracy: 0.32 | loss: 0.25
update:1285/2000, 耗时:0.00分/2.98分 | step: 71960 | performance: 3479.5 | accuracy: 0.32 | loss: 0.37
update:1290/2000, 耗时:0.00分/2.99分 | step: 72240 | performance: 4252.1 | accuracy: 0.32 | loss: 0.84
update:1295/2000, 耗时:0.00分/3.00分 | step: 72520 | performance: 10204.9 | accuracy: 0.33 | loss: 1.97
update:1300/2000, 耗时:0.00分/3.01分 | step: 72800 | performance: 11223.0 | accuracy: 0.33 | loss: 1.05
update:1305/2000, 耗时:0.00分/3.02分 | step: 73080 | performance: 77565.9 | accuracy: 0.34 | loss: 1.82
update:1310/2000, 耗时:0.00分/3.03分 | step: 73360 | performance: 73362.4 | accuracy: 0.34 | loss: 3.00
update:1315/2000, 耗时:0.00分/3.05分 | step: 73640 | performance: 62197.6 | accuracy: 0.34 | loss: 1.30
update:1320/2000, 耗时:0.00分/3.06分 | step: 73920 | performance: 43840.1 | accuracy: 0.34 | loss: 1.83
update:1325/2000, 耗时:0.00分/3.07分 | step: 74200 | performance: 118823.8 | accuracy: 0.34 | loss: 1.23
update:1330/2000, 耗时:0.00分/3.08分 | step: 74480 | performance: 114585.0 | accuracy: 0.34 | loss: 1.43
update:1335/2000, 耗时:0.00分/3.10分 | step: 74760 | performance: 131670.6 | accuracy: 0.35 | loss: 1.11
update:1340/2000, 耗时:0.00分/3.11分 | step: 75040 | performance: 147934.7 | accuracy: 0.35 | loss: 1.24
update:1345/2000, 耗时:0.00分/3.12分 | step: 75320 | performance: 102542.6 | accuracy: 0.35 | loss: 1.14
update:1350/2000, 耗时:0.00分/3.13分 | step: 75600 | performance: 318515.3 | accuracy: 0.35 | loss: 1.45
update:1355/2000, 耗时:0.00分/3.15分 | step: 75880 | performance: 275026.3 | accuracy: 0.35 | loss: 0.95
Saving PPO weights in both H5 format and checkpoint @ update:1359 
update:1360/2000, 耗时:0.00分/3.16分 | step: 76160 | performance: 340493.7 | accuracy: 0.35 | loss: 1.45
step: 76211 | worker_2@n_step_6: average total_reward after train data exhaustion : 69.8 | max total_reward: 229.7
step: 76215 | worker_6@n_step_6: average total_reward after train data exhaustion : 75.8 | max total_reward: 229.7
step: 76216 | worker_7@n_step_6: average total_reward after train data exhaustion : 83.0 | max total_reward: 270.6
Saving PPO weights in both H5 format and checkpoint @ update:1361 
step: 76325 | worker_4@n_step_6: average total_reward after train data exhaustion : 92.1 | max total_reward: 338.6
step: 76326 | worker_5@n_step_6: average total_reward after train data exhaustion : 100.0 | max total_reward: 338.6
Saving PPO weights in both H5 format and checkpoint @ update:1363 
update:1365/2000, 耗时:0.00分/3.19分 | step: 76440 | performance: 1.5 | accuracy: 0.50 | loss: 2.27
update:1370/2000, 耗时:0.00分/3.20分 | step: 76720 | performance: 1.5 | accuracy: 0.51 | loss: 1.01
update:1375/2000, 耗时:0.00分/3.21分 | step: 77000 | performance: 1.5 | accuracy: 0.49 | loss: 1.60
update:1380/2000, 耗时:0.00分/3.22分 | step: 77280 | performance: 1.7 | accuracy: 0.50 | loss: 1.48
update:1385/2000, 耗时:0.00分/3.24分 | step: 77560 | performance: 11.6 | accuracy: 0.55 | loss: 1.92
update:1390/2000, 耗时:0.00分/3.25分 | step: 77840 | performance: 41.7 | accuracy: 0.58 | loss: 3.14
update:1395/2000, 耗时:0.00分/3.26分 | step: 78120 | performance: 30.2 | accuracy: 0.58 | loss: 2.11
update:1400/2000, 耗时:0.00分/3.27分 | step: 78400 | performance: 38.8 | accuracy: 0.57 | loss: 1.35
update:1405/2000, 耗时:0.00分/3.28分 | step: 78680 | performance: 46.2 | accuracy: 0.56 | loss: 1.78
update:1410/2000, 耗时:0.00分/3.30分 | step: 78960 | performance: 28.8 | accuracy: 0.55 | loss: 2.01
update:1415/2000, 耗时:0.00分/3.31分 | step: 79240 | performance: 27.6 | accuracy: 0.53 | loss: 1.77
update:1420/2000, 耗时:0.00分/3.32分 | step: 79520 | performance: 26.0 | accuracy: 0.53 | loss: 2.31
update:1425/2000, 耗时:0.00分/3.33分 | step: 79800 | performance: 8.1 | accuracy: 0.50 | loss: 1.88
update:1430/2000, 耗时:0.00分/3.35分 | step: 80080 | performance: 6.5 | accuracy: 0.48 | loss: 1.16
update:1435/2000, 耗时:0.00分/3.36分 | step: 80360 | performance: 3.3 | accuracy: 0.45 | loss: 0.51
update:1440/2000, 耗时:0.00分/3.37分 | step: 80640 | performance: 3.1 | accuracy: 0.43 | loss: 0.16
update:1445/2000, 耗时:0.00分/3.38分 | step: 80920 | performance: 5.0 | accuracy: 0.42 | loss: 0.56
update:1450/2000, 耗时:0.00分/3.40分 | step: 81200 | performance: 10.8 | accuracy: 0.43 | loss: 3.02
update:1455/2000, 耗时:0.00分/3.41分 | step: 81480 | performance: 5.9 | accuracy: 0.41 | loss: 0.70
update:1460/2000, 耗时:0.00分/3.42分 | step: 81760 | performance: 8.7 | accuracy: 0.42 | loss: 1.60
update:1465/2000, 耗时:0.00分/3.43分 | step: 82040 | performance: 5.1 | accuracy: 0.41 | loss: 0.77
update:1470/2000, 耗时:0.00分/3.45分 | step: 82320 | performance: 6.3 | accuracy: 0.40 | loss: 0.52
update:1475/2000, 耗时:0.00分/3.46分 | step: 82600 | performance: 5.3 | accuracy: 0.39 | loss: 0.10
update:1480/2000, 耗时:0.00分/3.47分 | step: 82880 | performance: 5.5 | accuracy: 0.37 | loss: 0.09
update:1485/2000, 耗时:0.00分/3.48分 | step: 83160 | performance: 5.9 | accuracy: 0.36 | loss: 0.03
update:1490/2000, 耗时:0.00分/3.50分 | step: 83440 | performance: 5.9 | accuracy: 0.35 | loss: 0.12
update:1495/2000, 耗时:0.00分/3.51分 | step: 83720 | performance: 5.8 | accuracy: 0.35 | loss: 0.59
update:1500/2000, 耗时:0.00分/3.52分 | step: 84000 | performance: 5.7 | accuracy: 0.34 | loss: 0.99
update:1505/2000, 耗时:0.00分/3.53分 | step: 84280 | performance: 4.3 | accuracy: 0.34 | loss: 0.32
update:1510/2000, 耗时:0.00分/3.55分 | step: 84560 | performance: 3.9 | accuracy: 0.33 | loss: 0.20
update:1515/2000, 耗时:0.00分/3.56分 | step: 84840 | performance: 3.9 | accuracy: 0.33 | loss: 0.18
update:1520/2000, 耗时:0.00分/3.57分 | step: 85120 | performance: 5.2 | accuracy: 0.32 | loss: 0.68
update:1525/2000, 耗时:0.00分/3.58分 | step: 85400 | performance: 4.9 | accuracy: 0.32 | loss: 0.86
update:1530/2000, 耗时:0.00分/3.60分 | step: 85680 | performance: 4.6 | accuracy: 0.32 | loss: 0.45
update:1535/2000, 耗时:0.00分/3.61分 | step: 85960 | performance: 6.1 | accuracy: 0.32 | loss: 0.49
update:1540/2000, 耗时:0.00分/3.62分 | step: 86240 | performance: 3.6 | accuracy: 0.32 | loss: 0.51
update:1545/2000, 耗时:0.00分/3.63分 | step: 86520 | performance: 4.0 | accuracy: 0.32 | loss: 0.25
update:1550/2000, 耗时:0.00分/3.64分 | step: 86800 | performance: 3.8 | accuracy: 0.31 | loss: 0.31
update:1555/2000, 耗时:0.00分/3.65分 | step: 87080 | performance: 3.9 | accuracy: 0.31 | loss: 0.21
update:1560/2000, 耗时:0.00分/3.66分 | step: 87360 | performance: 5.1 | accuracy: 0.31 | loss: 0.20
update:1565/2000, 耗时:0.00分/3.67分 | step: 87640 | performance: 6.9 | accuracy: 0.31 | loss: 0.70
update:1570/2000, 耗时:0.00分/3.69分 | step: 87920 | performance: 6.7 | accuracy: 0.31 | loss: 0.67
update:1575/2000, 耗时:0.00分/3.70分 | step: 88200 | performance: 7.1 | accuracy: 0.31 | loss: 0.22
update:1580/2000, 耗时:0.00分/3.71分 | step: 88480 | performance: 6.0 | accuracy: 0.31 | loss: 0.30
update:1585/2000, 耗时:0.00分/3.72分 | step: 88760 | performance: 12.8 | accuracy: 0.31 | loss: 1.41
update:1590/2000, 耗时:0.00分/3.73分 | step: 89040 | performance: 26.1 | accuracy: 0.32 | loss: 1.12
update:1595/2000, 耗时:0.00分/3.74分 | step: 89320 | performance: 41.7 | accuracy: 0.33 | loss: 3.13
update:1600/2000, 耗时:0.00分/3.75分 | step: 89600 | performance: 73.6 | accuracy: 0.33 | loss: 1.18
update:1605/2000, 耗时:0.00分/3.76分 | step: 89880 | performance: 575.6 | accuracy: 0.34 | loss: 1.06
update:1610/2000, 耗时:0.00分/3.78分 | step: 90160 | performance: 1663.4 | accuracy: 0.35 | loss: 5.06
update:1615/2000, 耗时:0.00分/3.79分 | step: 90440 | performance: 2008.3 | accuracy: 0.35 | loss: 1.41
update:1620/2000, 耗时:0.00分/3.80分 | step: 90720 | performance: 9319.6 | accuracy: 0.36 | loss: 1.83
update:1625/2000, 耗时:0.00分/3.81分 | step: 91000 | performance: 14743.0 | accuracy: 0.37 | loss: 1.75
update:1630/2000, 耗时:0.00分/3.82分 | step: 91280 | performance: 14659.1 | accuracy: 0.37 | loss: 2.19
update:1635/2000, 耗时:0.00分/3.83分 | step: 91560 | performance: 19580.3 | accuracy: 0.37 | loss: 2.55
update:1640/2000, 耗时:0.00分/3.85分 | step: 91840 | performance: 11963.2 | accuracy: 0.37 | loss: 2.15
update:1645/2000, 耗时:0.00分/3.86分 | step: 92120 | performance: 2078.8 | accuracy: 0.37 | loss: 2.60
update:1650/2000, 耗时:0.00分/3.87分 | step: 92400 | performance: 1009.5 | accuracy: 0.37 | loss: 2.26
update:1655/2000, 耗时:0.00分/3.88分 | step: 92680 | performance: 930.5 | accuracy: 0.38 | loss: 1.18
update:1660/2000, 耗时:0.00分/3.89分 | step: 92960 | performance: 1068.0 | accuracy: 0.37 | loss: 0.53
update:1665/2000, 耗时:0.00分/3.90分 | step: 93240 | performance: 1046.0 | accuracy: 0.37 | loss: 1.08
update:1670/2000, 耗时:0.00分/3.91分 | step: 93520 | performance: 1470.8 | accuracy: 0.37 | loss: 1.48
update:1675/2000, 耗时:0.00分/3.93分 | step: 93800 | performance: 1990.1 | accuracy: 0.37 | loss: 1.96
update:1680/2000, 耗时:0.00分/3.94分 | step: 94080 | performance: 975.0 | accuracy: 0.37 | loss: 1.41
update:1685/2000, 耗时:0.00分/3.95分 | step: 94360 | performance: 1533.2 | accuracy: 0.37 | loss: 1.85
update:1690/2000, 耗时:0.00分/3.96分 | step: 94640 | performance: 2831.8 | accuracy: 0.38 | loss: 0.98
update:1695/2000, 耗时:0.00分/3.97分 | step: 94920 | performance: 3293.8 | accuracy: 0.38 | loss: 1.90
update:1700/2000, 耗时:0.00分/3.98分 | step: 95200 | performance: 1787.2 | accuracy: 0.38 | loss: 1.39
update:1705/2000, 耗时:0.00分/4.00分 | step: 95480 | performance: 669.4 | accuracy: 0.38 | loss: 1.35
update:1710/2000, 耗时:0.00分/4.01分 | step: 95760 | performance: 600.8 | accuracy: 0.38 | loss: 0.94
update:1715/2000, 耗时:0.00分/4.02分 | step: 96040 | performance: 353.8 | accuracy: 0.38 | loss: 0.16
update:1720/2000, 耗时:0.00分/4.03分 | step: 96320 | performance: 326.2 | accuracy: 0.37 | loss: 0.19
update:1725/2000, 耗时:0.00分/4.04分 | step: 96600 | performance: 287.3 | accuracy: 0.37 | loss: 0.53
update:1730/2000, 耗时:0.00分/4.05分 | step: 96880 | performance: 320.5 | accuracy: 0.37 | loss: 0.22
update:1735/2000, 耗时:0.00分/4.06分 | step: 97160 | performance: 440.4 | accuracy: 0.37 | loss: 1.30
update:1740/2000, 耗时:0.00分/4.08分 | step: 97440 | performance: 300.0 | accuracy: 0.37 | loss: 0.24
update:1745/2000, 耗时:0.00分/4.09分 | step: 97720 | performance: 277.5 | accuracy: 0.36 | loss: 0.27
update:1750/2000, 耗时:0.00分/4.10分 | step: 98000 | performance: 309.5 | accuracy: 0.36 | loss: 0.18
update:1755/2000, 耗时:0.00分/4.11分 | step: 98280 | performance: 319.6 | accuracy: 0.36 | loss: 0.38
update:1760/2000, 耗时:0.00分/4.12分 | step: 98560 | performance: 1068.8 | accuracy: 0.36 | loss: 2.06
update:1765/2000, 耗时:0.00分/4.13分 | step: 98840 | performance: 1127.8 | accuracy: 0.36 | loss: 1.66
update:1770/2000, 耗时:0.00分/4.14分 | step: 99120 | performance: 633.5 | accuracy: 0.36 | loss: 0.47
update:1775/2000, 耗时:0.00分/4.16分 | step: 99400 | performance: 676.3 | accuracy: 0.36 | loss: 0.46
update:1780/2000, 耗时:0.00分/4.17分 | step: 99680 | performance: 911.5 | accuracy: 0.36 | loss: 0.75
update:1785/2000, 耗时:0.00分/4.18分 | step: 99960 | performance: 858.5 | accuracy: 0.36 | loss: 0.92
update:1790/2000, 耗时:0.00分/4.19分 | step: 100240 | performance: 823.2 | accuracy: 0.36 | loss: 1.18
update:1795/2000, 耗时:0.00分/4.20分 | step: 100520 | performance: 639.4 | accuracy: 0.36 | loss: 1.33
update:1800/2000, 耗时:0.00分/4.21分 | step: 100800 | performance: 1746.4 | accuracy: 0.36 | loss: 1.19
update:1805/2000, 耗时:0.00分/4.22分 | step: 101080 | performance: 1708.5 | accuracy: 0.36 | loss: 1.77
update:1810/2000, 耗时:0.00分/4.24分 | step: 101360 | performance: 2011.2 | accuracy: 0.36 | loss: 0.87
Saving PPO weights in both H5 format and checkpoint @ update:1814 
update:1815/2000, 耗时:0.00分/4.25分 | step: 101640 | performance: 1.0 | accuracy: 0.25 | loss: 0.71
Saving PPO weights in both H5 format and checkpoint @ update:1816 
update:1820/2000, 耗时:0.00分/4.27分 | step: 101920 | performance: 0.8 | accuracy: 0.30 | loss: 0.95
update:1825/2000, 耗时:0.00分/4.28分 | step: 102200 | performance: 0.9 | accuracy: 0.33 | loss: 0.66
update:1830/2000, 耗时:0.00分/4.29分 | step: 102480 | performance: 0.7 | accuracy: 0.33 | loss: 0.63
update:1835/2000, 耗时:0.00分/4.30分 | step: 102760 | performance: 0.8 | accuracy: 0.34 | loss: 1.97
update:1840/2000, 耗时:0.00分/4.31分 | step: 103040 | performance: 6.2 | accuracy: 0.43 | loss: 1.81
update:1845/2000, 耗时:0.00分/4.33分 | step: 103320 | performance: 14.4 | accuracy: 0.48 | loss: 2.29
update:1850/2000, 耗时:0.00分/4.34分 | step: 103600 | performance: 10.3 | accuracy: 0.47 | loss: 1.15
update:1855/2000, 耗时:0.00分/4.35分 | step: 103880 | performance: 14.6 | accuracy: 0.48 | loss: 0.83
update:1860/2000, 耗时:0.00分/4.36分 | step: 104160 | performance: 14.9 | accuracy: 0.48 | loss: 1.78
update:1865/2000, 耗时:0.00分/4.37分 | step: 104440 | performance: 10.9 | accuracy: 0.47 | loss: 2.00
update:1870/2000, 耗时:0.00分/4.38分 | step: 104720 | performance: 9.4 | accuracy: 0.46 | loss: 1.07
update:1875/2000, 耗时:0.00分/4.39分 | step: 105000 | performance: 4.8 | accuracy: 0.45 | loss: 1.15
update:1880/2000, 耗时:0.00分/4.41分 | step: 105280 | performance: 3.1 | accuracy: 0.44 | loss: 0.54
update:1885/2000, 耗时:0.00分/4.42分 | step: 105560 | performance: 3.5 | accuracy: 0.44 | loss: 1.69
update:1890/2000, 耗时:0.00分/4.43分 | step: 105840 | performance: 15.4 | accuracy: 0.45 | loss: 1.52
update:1895/2000, 耗时:0.00分/4.44分 | step: 106120 | performance: 14.5 | accuracy: 0.45 | loss: 0.84
update:1900/2000, 耗时:0.00分/4.45分 | step: 106400 | performance: 111.4 | accuracy: 0.47 | loss: 1.50
update:1905/2000, 耗时:0.00分/4.46分 | step: 106680 | performance: 45.2 | accuracy: 0.47 | loss: 3.46
update:1910/2000, 耗时:0.00分/4.47分 | step: 106960 | performance: 56.3 | accuracy: 0.47 | loss: 2.15
update:1915/2000, 耗时:0.00分/4.48分 | step: 107240 | performance: 53.6 | accuracy: 0.47 | loss: 1.53
update:1920/2000, 耗时:0.00分/4.49分 | step: 107520 | performance: 48.6 | accuracy: 0.47 | loss: 1.38
update:1925/2000, 耗时:0.00分/4.50分 | step: 107800 | performance: 24.2 | accuracy: 0.46 | loss: 1.89
update:1930/2000, 耗时:0.00分/4.51分 | step: 108080 | performance: 13.0 | accuracy: 0.46 | loss: 1.11
update:1935/2000, 耗时:0.00分/4.52分 | step: 108360 | performance: 18.6 | accuracy: 0.46 | loss: 1.22
update:1940/2000, 耗时:0.00分/4.53分 | step: 108640 | performance: 11.8 | accuracy: 0.45 | loss: 1.50
update:1945/2000, 耗时:0.00分/4.54分 | step: 108920 | performance: 6.0 | accuracy: 0.44 | loss: 0.29
update:1950/2000, 耗时:0.00分/4.55分 | step: 109200 | performance: 5.3 | accuracy: 0.43 | loss: 0.52
update:1955/2000, 耗时:0.00分/4.56分 | step: 109480 | performance: 6.2 | accuracy: 0.42 | loss: 0.48
update:1960/2000, 耗时:0.00分/4.57分 | step: 109760 | performance: 6.5 | accuracy: 0.42 | loss: 1.24
update:1965/2000, 耗时:0.00分/4.58分 | step: 110040 | performance: 12.7 | accuracy: 0.43 | loss: 0.71
update:1970/2000, 耗时:0.00分/4.60分 | step: 110320 | performance: 8.8 | accuracy: 0.42 | loss: 1.39
update:1975/2000, 耗时:0.00分/4.61分 | step: 110600 | performance: 1.2 | accuracy: 0.42 | loss: 0.29
update:1980/2000, 耗时:0.00分/4.62分 | step: 110880 | performance: 1.0 | accuracy: 0.42 | loss: 0.78
update:1985/2000, 耗时:0.00分/4.63分 | step: 111160 | performance: 0.8 | accuracy: 0.41 | loss: 1.87
update:1990/2000, 耗时:0.00分/4.64分 | step: 111440 | performance: 3.3 | accuracy: 0.42 | loss: 1.85
update:1995/2000, 耗时:0.00分/4.65分 | step: 111720 | performance: 2.1 | accuracy: 0.42 | loss: 0.95
update:2000/2000, 耗时:0.00分/4.66分 | step: 112000 | performance: 2.6 | accuracy: 0.43 | loss: 1.20
----------------------------------------finished----------------------------------------
==================================================
2023-01-04T00:00:00 | *** START BACKTEST ***
2023-01-04T00:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/404 [00:00<?, ?it/s]100%|| 404/404 [00:00<00:00, 134548.10it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1725.26
2023-07-24T12:00:00 | net performance [%] = 72.5256
2023-07-24T12:00:00 | number of trades [#] = 2
==================================================
Trial 44 Complete [00h 05m 06s]
net_wealth: 1726.9829154412218

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 05h 48m 37s

Search: Running Trial #45

Value             |Best Value So Far |Hyperparameter
5                 |7                 |horizon
365               |730               |lookback
True              |False             |MarketFactor
14                |14                |lags
0.98              |0.7               |gamma
16                |32                |batch_size
64                |32                |n_step
0.98              |0.92              |gae_lambda
0.5               |0.1               |gradient_clip_norm
3                 |5                 |epochs
5e-05             |0.0001            |actor_lr
5e-05             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4296.000000   4301.000000
mean      0.000435    20113.607657  ...   20187.844288  20169.373185
std       0.027833    16040.642334  ...   16078.813220  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7752.362549   7730.930176
50%       0.000642    11571.842969  ...   11756.264648  11751.469727
75%       0.011590    29894.706152  ...   30017.365723  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 03:52:00.450423: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimize2023-07-28 03:52:00.450424: I tensorflow/core/platform/cpu_feature_guard.cc:142] This Te2023-07-28 03:52:0nd ws0io.th oneA450r5FlP4ow binI2023: I tensorf3ary isl- ow/opt0cimized7o -2w8it rh0e oneAP3/pI Deep Nlatform/cp:5 2:00.450489: IDe2u0 e_featut2epnsrorflowe_3 Neurguara-07dl/co- .Ncetw28 03:52:00crork e:Lib/1rp42] laary (oneDNeuN)t to formThis T/ural seNetwo .trk Li45hb0c5e follopru_featuwearnysing CPo (orU inFneDlstroNN)u250cti2w5:onr s in pebe_guari I terfodn.cc: nsotarfor yl14 ow/ius22] 0rem2T st hoe follo3cor-w032-023-ip07-et/p0l2h77-28nig- Ca i083 :s5032Pa2ncU 8: 52ei 03:T0:05e2nn-:c0ritis0t:m.irz4s.ue04o0rtdFlow.5545 0 1cfo9rm/bc0w4icta13066:p tiio: hun_ar5If enaI  3s: tteu ioI rtee_gnunatynesAePnI o ridpnsss op Doortfrlofwllrfe .copeepoiwem/l /Nrcizeoeautrcf:1orraowicolder/mcao 42] Tnw/iptlh h oraet/pNnecoissl rtenT:e e fao/n-scorriAteFAlPIiwVoXt pAlVarowrXm2/
Tfko oL tcfao rrbli no aDenmapber/ycpru_fceple aeup_f tthmie Neuro/ieatubirs eraemacpu _fta_oien onguararly Ndtthse:  (e. Aurtcwcor:e1 pot_i4m2i]z rVkpur egeu_ardd gwiuaX.teratih cALonrdi co:V1X4sn, r2e2.oneA]PcbbrTuIi heiDlds cD
eNTaheTp  oN :Tirsey  Te(on eun1eeDr4Tnensnaslo rFsN2Nooarbl]lNN) toee tT tow oursFerkh is FLlolwo w ibbt iThrhewm wei  einbafroln ionalnotahr y rtthesyw) ish ito ey souo ianpg  C PU op(sie tphronnserFopttrucpDeN firiltNr) ttoiom ioma uioopnelstwe isle coz reomwpi db inzaetdwanr pieornfsi iy ,is linogwtehrrtohp toinme ie CfPUmiAzot PeI  ia nrfebculilonhde stwi-nwgi lc toDCrPurh doU nietAineAc TeectnisooinaPIr DeFlPIowlespnlags.
e ot Dperaeep p Ne ruNtic Noeteiurounras lansw:li   tNei hANtwoetwosr rVkXt  n  inAhVpk  Lieb paperefrfoX2rprorraLo
maTnce-crior tmipy uancereabrary (onenable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
ical operations:  AVX AVX2
To enable themr(onilate DNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them  cinompiler fi oneDNN) to us o-e ltatchNher gset.
workerrtit  ohLie capf operations, rebuiil lbrarydollowing   CPU instructions in performance-critT(eratiooperations:  AVX AVX2
To enable them in other operations, rebuiical operations:  AVX AVX2
To enns, rebuild TensorFlow with the appropriate compileloaerdn eb lflags.
DnTensorFlow with the appropriate compisorFlow with the appropriate coleNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
r flags.
mpiler flags.
e them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 03:52:01.049269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:52:01.065666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:52:01.068560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:52:01.092587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:52:01.096333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:52:01.105397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:52:01.107842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 03:52:01.127427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.06分 | step:  2560 | performance: 1.2 | accuracy: 0.33 | loss: 9.44
update: 10/2000, 耗时:0.01分/0.11分 | step:  5120 | performance: 1.3 | accuracy: 0.33 | loss: 5.97
update: 15/2000, 耗时:0.01分/0.15分 | step:  7680 | performance: 2.3 | accuracy: 0.34 | loss: 14.30
update: 20/2000, 耗时:0.01分/0.20分 | step: 10240 | performance: 1.2 | accuracy: 0.33 | loss: 6.77
update: 25/2000, 耗时:0.01分/0.25分 | step: 12800 | performance: 0.6 | accuracy: 0.34 | loss: 6.54
update: 30/2000, 耗时:0.01分/0.30分 | step: 15360 | performance: 1.1 | accuracy: 0.34 | loss: 20.12
update: 35/2000, 耗时:0.01分/0.35分 | step: 17920 | performance: 62.3 | accuracy: 0.37 | loss: 7.84
update: 40/2000, 耗时:0.01分/0.40分 | step: 20480 | performance: 10.9 | accuracy: 0.36 | loss: 5.35
update: 45/2000, 耗时:0.01分/0.45分 | step: 23040 | performance: 23.1 | accuracy: 0.36 | loss: 8.54
update: 50/2000, 耗时:0.01分/0.50分 | step: 25600 | performance: 72.6 | accuracy: 0.35 | loss: 7.37
update: 55/2000, 耗时:0.01分/0.55分 | step: 28160 | performance: 1.0 | accuracy: 0.33 | loss: 4.72
Saving PPO weights in both H5 format and checkpoint @ update:55 
update: 60/2000, 耗时:0.01分/0.60分 | step: 30720 | performance: 8.7 | accuracy: 0.39 | loss: 5.44
update: 65/2000, 耗时:0.01分/0.65分 | step: 33280 | performance: 13.7 | accuracy: 0.39 | loss: 6.38
update: 70/2000, 耗时:0.01分/0.69分 | step: 35840 | performance: 109.1 | accuracy: 0.40 | loss: 32.07
update: 75/2000, 耗时:0.01分/0.74分 | step: 38400 | performance: 63.2 | accuracy: 0.38 | loss: 5.68
update: 80/2000, 耗时:0.01分/0.79分 | step: 40960 | performance: 24.1 | accuracy: 0.36 | loss: 7.06
update: 85/2000, 耗时:0.01分/0.83分 | step: 43520 | performance: 63.6 | accuracy: 0.37 | loss: 18.39
update: 90/2000, 耗时:0.01分/0.88分 | step: 46080 | performance: 2818.7 | accuracy: 0.38 | loss: 4.78
update: 95/2000, 耗时:0.01分/0.93分 | step: 48640 | performance: 1159.0 | accuracy: 0.37 | loss: 3.97
update:100/2000, 耗时:0.01分/0.97分 | step: 51200 | performance: 231.6 | accuracy: 0.37 | loss: 3.98
update:105/2000, 耗时:0.01分/1.02分 | step: 53760 | performance: 178.2 | accuracy: 0.36 | loss: 6.43
update:110/2000, 耗时:0.01分/1.06分 | step: 56320 | performance: 0.7 | accuracy: 0.33 | loss: 4.53
update:115/2000, 耗时:0.01分/1.11分 | step: 58880 | performance: 0.9 | accuracy: 0.36 | loss: 6.29
update:120/2000, 耗时:0.01分/1.16分 | step: 61440 | performance: 2.2 | accuracy: 0.36 | loss: 2.73
update:125/2000, 耗时:0.01分/1.20分 | step: 64000 | performance: 14.6 | accuracy: 0.37 | loss: 20.98
update:130/2000, 耗时:0.01分/1.25分 | step: 66560 | performance: 8.0 | accuracy: 0.36 | loss: 4.99
update:135/2000, 耗时:0.01分/1.29分 | step: 69120 | performance: 3.5 | accuracy: 0.34 | loss: 5.51
update:140/2000, 耗时:0.01分/1.34分 | step: 71680 | performance: 4.8 | accuracy: 0.34 | loss: 9.04
update:145/2000, 耗时:0.01分/1.38分 | step: 74240 | performance: 25.1 | accuracy: 0.35 | loss: 5.95
update:150/2000, 耗时:0.01分/1.43分 | step: 76800 | performance: 29.2 | accuracy: 0.35 | loss: 6.12
update:155/2000, 耗时:0.01分/1.48分 | step: 79360 | performance: 6.8 | accuracy: 0.34 | loss: 2.86
update:160/2000, 耗时:0.01分/1.52分 | step: 81920 | performance: 11.9 | accuracy: 0.34 | loss: 6.50
update:165/2000, 耗时:0.01分/1.57分 | step: 84480 | performance: 1.5 | accuracy: 0.28 | loss: 5.39
update:170/2000, 耗时:0.01分/1.62分 | step: 87040 | performance: 18.2 | accuracy: 0.40 | loss: 12.28
update:175/2000, 耗时:0.01分/1.66分 | step: 89600 | performance: 62.9 | accuracy: 0.38 | loss: 4.51
update:180/2000, 耗时:0.01分/1.71分 | step: 92160 | performance: 84.3 | accuracy: 0.36 | loss: 13.41
update:185/2000, 耗时:0.01分/1.76分 | step: 94720 | performance: 87.5 | accuracy: 0.35 | loss: 4.47
update:190/2000, 耗时:0.01分/1.80分 | step: 97280 | performance: 36.0 | accuracy: 0.33 | loss: 8.62
update:195/2000, 耗时:0.01分/1.85分 | step: 99840 | performance: 42.9 | accuracy: 0.33 | loss: 13.64
update:200/2000, 耗时:0.01分/1.90分 | step: 102400 | performance: 4231.2 | accuracy: 0.35 | loss: 8.23
update:205/2000, 耗时:0.01分/1.94分 | step: 104960 | performance: 2487.8 | accuracy: 0.36 | loss: 5.15
update:210/2000, 耗时:0.01分/1.99分 | step: 107520 | performance: 7478.7 | accuracy: 0.36 | loss: 6.87
update:215/2000, 耗时:0.01分/2.03分 | step: 110080 | performance: 19022.7 | accuracy: 0.36 | loss: 6.84
update:220/2000, 耗时:0.01分/2.08分 | step: 112640 | performance: 1.4 | accuracy: 0.38 | loss: 4.26
update:225/2000, 耗时:0.01分/2.13分 | step: 115200 | performance: 5.3 | accuracy: 0.42 | loss: 12.52
update:230/2000, 耗时:0.01分/2.17分 | step: 117760 | performance: 13.8 | accuracy: 0.42 | loss: 5.01
update:235/2000, 耗时:0.01分/2.22分 | step: 120320 | performance: 8.6 | accuracy: 0.39 | loss: 11.80
update:240/2000, 耗时:0.01分/2.27分 | step: 122880 | performance: 57.0 | accuracy: 0.40 | loss: 6.42
update:245/2000, 耗时:0.01分/2.31分 | step: 125440 | performance: 6.4 | accuracy: 0.38 | loss: 5.30
update:250/2000, 耗时:0.01分/2.36分 | step: 128000 | performance: 12.2 | accuracy: 0.38 | loss: 18.32
update:255/2000, 耗时:0.01分/2.40分 | step: 130560 | performance: 438.7 | accuracy: 0.39 | loss: 4.38
update:260/2000, 耗时:0.01分/2.45分 | step: 133120 | performance: 261.8 | accuracy: 0.38 | loss: 9.96
update:265/2000, 耗时:0.01分/2.50分 | step: 135680 | performance: 174.3 | accuracy: 0.38 | loss: 3.47
update:270/2000, 耗时:0.01分/2.54分 | step: 138240 | performance: 993.1 | accuracy: 0.38 | loss: 9.52
update:275/2000, 耗时:0.01分/2.59分 | step: 140800 | performance: 1.0 | accuracy: 0.43 | loss: 5.44
update:280/2000, 耗时:0.01分/2.64分 | step: 143360 | performance: 0.9 | accuracy: 0.34 | loss: 12.91
update:285/2000, 耗时:0.01分/2.68分 | step: 145920 | performance: 1.6 | accuracy: 0.35 | loss: 2.68
update:290/2000, 耗时:0.01分/2.73分 | step: 148480 | performance: 1.5 | accuracy: 0.36 | loss: 13.64
update:295/2000, 耗时:0.01分/2.77分 | step: 151040 | performance: 1.0 | accuracy: 0.35 | loss: 6.81
update:300/2000, 耗时:0.01分/2.82分 | step: 153600 | performance: 2.7 | accuracy: 0.34 | loss: 5.26
update:305/2000, 耗时:0.01分/2.87分 | step: 156160 | performance: 2.9 | accuracy: 0.34 | loss: 19.39
update:310/2000, 耗时:0.01分/2.91分 | step: 158720 | performance: 82.2 | accuracy: 0.36 | loss: 6.93
update:315/2000, 耗时:0.01分/2.96分 | step: 161280 | performance: 12.4 | accuracy: 0.36 | loss: 6.61
update:320/2000, 耗时:0.01分/3.01分 | step: 163840 | performance: 7.8 | accuracy: 0.36 | loss: 5.28
update:325/2000, 耗时:0.01分/3.05分 | step: 166400 | performance: 15.0 | accuracy: 0.35 | loss: 8.69
update:330/2000, 耗时:0.01分/3.10分 | step: 168960 | performance: 1.9 | accuracy: 0.56 | loss: 11.16
update:335/2000, 耗时:0.01分/3.15分 | step: 171520 | performance: 2.4 | accuracy: 0.42 | loss: 8.85
update:340/2000, 耗时:0.01分/3.20分 | step: 174080 | performance: 15.1 | accuracy: 0.43 | loss: 2.72
update:345/2000, 耗时:0.01分/3.24分 | step: 176640 | performance: 27.7 | accuracy: 0.42 | loss: 7.70
update:350/2000, 耗时:0.01分/3.29分 | step: 179200 | performance: 39.7 | accuracy: 0.40 | loss: 3.44
update:355/2000, 耗时:0.01分/3.34分 | step: 181760 | performance: 149.7 | accuracy: 0.39 | loss: 3.26
update:360/2000, 耗时:0.01分/3.39分 | step: 184320 | performance: 381.3 | accuracy: 0.38 | loss: 10.65
update:365/2000, 耗时:0.01分/3.43分 | step: 186880 | performance: 2341.4 | accuracy: 0.39 | loss: 3.68
update:370/2000, 耗时:0.01分/3.48分 | step: 189440 | performance: 1467.1 | accuracy: 0.38 | loss: 5.01
update:375/2000, 耗时:0.01分/3.53分 | step: 192000 | performance: 502.6 | accuracy: 0.37 | loss: 2.85
update:380/2000, 耗时:0.01分/3.57分 | step: 194560 | performance: 243.6 | accuracy: 0.36 | loss: 4.17
update:385/2000, 耗时:0.01分/3.62分 | step: 197120 | performance: 2.0 | accuracy: 0.36 | loss: 5.51
update:390/2000, 耗时:0.01分/3.67分 | step: 199680 | performance: 3.0 | accuracy: 0.27 | loss: 3.69
update:395/2000, 耗时:0.01分/3.71分 | step: 202240 | performance: 6.6 | accuracy: 0.28 | loss: 2.39
update:400/2000, 耗时:0.01分/3.76分 | step: 204800 | performance: 24.7 | accuracy: 0.30 | loss: 8.31
update:405/2000, 耗时:0.01分/3.81分 | step: 207360 | performance: 46.1 | accuracy: 0.29 | loss: 3.80
update:410/2000, 耗时:0.01分/3.86分 | step: 209920 | performance: 39.3 | accuracy: 0.29 | loss: 2.44
update:415/2000, 耗时:0.01分/3.90分 | step: 212480 | performance: 107.3 | accuracy: 0.30 | loss: 10.65
update:420/2000, 耗时:0.01分/3.95分 | step: 215040 | performance: 3380.6 | accuracy: 0.32 | loss: 10.01
update:425/2000, 耗时:0.01分/4.00分 | step: 217600 | performance: 723.7 | accuracy: 0.31 | loss: 6.49
update:430/2000, 耗时:0.01分/4.05分 | step: 220160 | performance: 720.3 | accuracy: 0.31 | loss: 5.28
update:435/2000, 耗时:0.01分/4.09分 | step: 222720 | performance: 997.0 | accuracy: 0.30 | loss: 3.45
update:440/2000, 耗时:0.01分/4.14分 | step: 225280 | performance: 1.2 | accuracy: 0.40 | loss: 4.53
update:445/2000, 耗时:0.01分/4.20分 | step: 227840 | performance: 0.9 | accuracy: 0.29 | loss: 4.89
update:450/2000, 耗时:0.01分/4.25分 | step: 230400 | performance: 5.9 | accuracy: 0.31 | loss: 5.98
update:455/2000, 耗时:0.01分/4.30分 | step: 232960 | performance: 52.2 | accuracy: 0.32 | loss: 11.50
update:460/2000, 耗时:0.01分/4.35分 | step: 235520 | performance: 11.8 | accuracy: 0.30 | loss: 4.20
update:465/2000, 耗时:0.01分/4.40分 | step: 238080 | performance: 5.3 | accuracy: 0.30 | loss: 7.57
update:470/2000, 耗时:0.01分/4.45分 | step: 240640 | performance: 33.8 | accuracy: 0.31 | loss: 13.78
update:475/2000, 耗时:0.01分/4.49分 | step: 243200 | performance: 108.9 | accuracy: 0.32 | loss: 9.35
update:480/2000, 耗时:0.01分/4.54分 | step: 245760 | performance: 399.7 | accuracy: 0.32 | loss: 6.36
update:485/2000, 耗时:0.01分/4.59分 | step: 248320 | performance: 193.7 | accuracy: 0.32 | loss: 6.68
update:490/2000, 耗时:0.01分/4.63分 | step: 250880 | performance: 109.9 | accuracy: 0.31 | loss: 5.37
update:495/2000, 耗时:0.01分/4.68分 | step: 253440 | performance: 2.8 | accuracy: 0.46 | loss: 5.39
update:500/2000, 耗时:0.01分/4.72分 | step: 256000 | performance: 3.7 | accuracy: 0.33 | loss: 3.71
update:505/2000, 耗时:0.01分/4.77分 | step: 258560 | performance: 4.8 | accuracy: 0.31 | loss: 3.77
update:510/2000, 耗时:0.01分/4.82分 | step: 261120 | performance: 10.1 | accuracy: 0.32 | loss: 10.39
update:515/2000, 耗时:0.01分/4.86分 | step: 263680 | performance: 18.0 | accuracy: 0.31 | loss: 3.45
update:520/2000, 耗时:0.01分/4.91分 | step: 266240 | performance: 16.4 | accuracy: 0.30 | loss: 3.49
update:525/2000, 耗时:0.01分/4.96分 | step: 268800 | performance: 35.4 | accuracy: 0.29 | loss: 9.08
update:530/2000, 耗时:0.01分/5.00分 | step: 271360 | performance: 101.5 | accuracy: 0.29 | loss: 3.20
update:535/2000, 耗时:0.01分/5.05分 | step: 273920 | performance: 41.0 | accuracy: 0.29 | loss: 3.87
update:540/2000, 耗时:0.01分/5.09分 | step: 276480 | performance: 7.2 | accuracy: 0.28 | loss: 5.08
update:545/2000, 耗时:0.01分/5.14分 | step: 279040 | performance: 1.6 | accuracy: 0.27 | loss: 2.12
update:550/2000, 耗时:0.01分/5.19分 | step: 281600 | performance: 0.9 | accuracy: 0.23 | loss: 3.62
update:555/2000, 耗时:0.01分/5.23分 | step: 284160 | performance: 2.9 | accuracy: 0.24 | loss: 3.57
update:560/2000, 耗时:0.01分/5.28分 | step: 286720 | performance: 3.4 | accuracy: 0.21 | loss: 1.55
update:565/2000, 耗时:0.01分/5.32分 | step: 289280 | performance: 13.1 | accuracy: 0.23 | loss: 7.75
update:570/2000, 耗时:0.01分/5.37分 | step: 291840 | performance: 43.8 | accuracy: 0.24 | loss: 2.33
update:575/2000, 耗时:0.01分/5.42分 | step: 294400 | performance: 38.7 | accuracy: 0.23 | loss: 3.64
update:580/2000, 耗时:0.01分/5.46分 | step: 296960 | performance: 131.6 | accuracy: 0.24 | loss: 12.78
update:585/2000, 耗时:0.01分/5.51分 | step: 299520 | performance: 5159.6 | accuracy: 0.26 | loss: 5.18
update:590/2000, 耗时:0.01分/5.56分 | step: 302080 | performance: 5517.3 | accuracy: 0.26 | loss: 5.41
update:595/2000, 耗时:0.01分/5.60分 | step: 304640 | performance: 1984.4 | accuracy: 0.25 | loss: 2.29
update:600/2000, 耗时:0.01分/5.65分 | step: 307200 | performance: 3673.1 | accuracy: 0.25 | loss: 4.02
update:605/2000, 耗时:0.01分/5.69分 | step: 309760 | performance: 2.2 | accuracy: 0.27 | loss: 7.78
update:610/2000, 耗时:0.01分/5.74分 | step: 312320 | performance: 1.9 | accuracy: 0.21 | loss: 2.99
update:615/2000, 耗时:0.01分/5.79分 | step: 314880 | performance: 1.1 | accuracy: 0.18 | loss: 1.45
update:620/2000, 耗时:0.01分/5.83分 | step: 317440 | performance: 2.2 | accuracy: 0.21 | loss: 5.97
update:625/2000, 耗时:0.01分/5.88分 | step: 320000 | performance: 1.7 | accuracy: 0.20 | loss: 3.29
update:630/2000, 耗时:0.01分/5.93分 | step: 322560 | performance: 0.6 | accuracy: 0.20 | loss: 2.46
update:635/2000, 耗时:0.01分/5.97分 | step: 325120 | performance: 1.0 | accuracy: 0.21 | loss: 6.00
update:640/2000, 耗时:0.01分/6.02分 | step: 327680 | performance: 5.6 | accuracy: 0.21 | loss: 3.03
update:645/2000, 耗时:0.01分/6.06分 | step: 330240 | performance: 7.0 | accuracy: 0.21 | loss: 4.68
update:650/2000, 耗时:0.01分/6.11分 | step: 332800 | performance: 8.1 | accuracy: 0.21 | loss: 1.64
update:655/2000, 耗时:0.01分/6.16分 | step: 335360 | performance: 9.6 | accuracy: 0.20 | loss: 4.09
update:660/2000, 耗时:0.01分/6.21分 | step: 337920 | performance: 1.1 | accuracy: 0.22 | loss: 3.42
update:665/2000, 耗时:0.01分/6.25分 | step: 340480 | performance: 0.4 | accuracy: 0.16 | loss: 2.37
update:670/2000, 耗时:0.01分/6.30分 | step: 343040 | performance: 0.4 | accuracy: 0.18 | loss: 1.88
update:675/2000, 耗时:0.01分/6.35分 | step: 345600 | performance: 0.4 | accuracy: 0.19 | loss: 7.80
update:680/2000, 耗时:0.01分/6.39分 | step: 348160 | performance: 0.3 | accuracy: 0.19 | loss: 2.74
update:685/2000, 耗时:0.01分/6.44分 | step: 350720 | performance: 0.6 | accuracy: 0.19 | loss: 2.19
update:690/2000, 耗时:0.01分/6.49分 | step: 353280 | performance: 0.5 | accuracy: 0.18 | loss: 4.06
update:695/2000, 耗时:0.01分/6.53分 | step: 355840 | performance: 0.7 | accuracy: 0.18 | loss: 3.24
update:700/2000, 耗时:0.01分/6.58分 | step: 358400 | performance: 1.0 | accuracy: 0.17 | loss: 1.82
update:705/2000, 耗时:0.01分/6.62分 | step: 360960 | performance: 0.6 | accuracy: 0.16 | loss: 0.94
update:710/2000, 耗时:0.01分/6.67分 | step: 363520 | performance: 0.9 | accuracy: 0.16 | loss: 1.41
update:715/2000, 耗时:0.01分/6.72分 | step: 366080 | performance: 1.0 | accuracy: 0.12 | loss: 2.43
update:720/2000, 耗时:0.01分/6.76分 | step: 368640 | performance: 1.1 | accuracy: 0.13 | loss: 1.38
update:725/2000, 耗时:0.01分/6.81分 | step: 371200 | performance: 2.0 | accuracy: 0.13 | loss: 2.51
update:730/2000, 耗时:0.01分/6.85分 | step: 373760 | performance: 3.5 | accuracy: 0.14 | loss: 1.71
update:735/2000, 耗时:0.01分/6.90分 | step: 376320 | performance: 3.7 | accuracy: 0.14 | loss: 2.93
update:740/2000, 耗时:0.01分/6.94分 | step: 378880 | performance: 1.0 | accuracy: 0.13 | loss: 1.22
update:745/2000, 耗时:0.01分/6.99分 | step: 381440 | performance: 1.3 | accuracy: 0.14 | loss: 2.01
update:750/2000, 耗时:0.01分/7.04分 | step: 384000 | performance: 2.9 | accuracy: 0.15 | loss: 2.93
update:755/2000, 耗时:0.01分/7.08分 | step: 386560 | performance: 2.4 | accuracy: 0.14 | loss: 2.40
update:760/2000, 耗时:0.01分/7.13分 | step: 389120 | performance: 1.1 | accuracy: 0.14 | loss: 2.50
update:765/2000, 耗时:0.01分/7.18分 | step: 391680 | performance: 0.8 | accuracy: 0.14 | loss: 2.77
update:770/2000, 耗时:0.01分/7.22分 | step: 394240 | performance: 1.4 | accuracy: 0.18 | loss: 1.71
update:775/2000, 耗时:0.01分/7.27分 | step: 396800 | performance: 0.9 | accuracy: 0.11 | loss: 2.23
update:780/2000, 耗时:0.01分/7.32分 | step: 399360 | performance: 1.1 | accuracy: 0.12 | loss: 1.81
update:785/2000, 耗时:0.01分/7.36分 | step: 401920 | performance: 0.6 | accuracy: 0.14 | loss: 2.63
update:790/2000, 耗时:0.01分/7.41分 | step: 404480 | performance: 1.1 | accuracy: 0.15 | loss: 2.65
update:795/2000, 耗时:0.01分/7.46分 | step: 407040 | performance: 1.0 | accuracy: 0.15 | loss: 2.41
update:800/2000, 耗时:0.01分/7.50分 | step: 409600 | performance: 2.8 | accuracy: 0.15 | loss: 3.06
update:805/2000, 耗时:0.01分/7.55分 | step: 412160 | performance: 2.7 | accuracy: 0.15 | loss: 2.52
update:810/2000, 耗时:0.01分/7.60分 | step: 414720 | performance: 2.1 | accuracy: 0.15 | loss: 2.04
update:815/2000, 耗时:0.01分/7.64分 | step: 417280 | performance: 1.8 | accuracy: 0.15 | loss: 2.58
update:820/2000, 耗时:0.01分/7.69分 | step: 419840 | performance: 0.4 | accuracy: 0.14 | loss: 1.96
update:825/2000, 耗时:0.01分/7.74分 | step: 422400 | performance: 1.1 | accuracy: 0.21 | loss: 1.99
update:830/2000, 耗时:0.01分/7.78分 | step: 424960 | performance: 1.5 | accuracy: 0.15 | loss: 1.65
update:835/2000, 耗时:0.01分/7.83分 | step: 427520 | performance: 2.6 | accuracy: 0.15 | loss: 3.51
update:840/2000, 耗时:0.01分/7.87分 | step: 430080 | performance: 4.4 | accuracy: 0.14 | loss: 2.72
update:845/2000, 耗时:0.01分/7.92分 | step: 432640 | performance: 7.2 | accuracy: 0.15 | loss: 2.41
update:850/2000, 耗时:0.01分/7.97分 | step: 435200 | performance: 21.3 | accuracy: 0.15 | loss: 3.03
update:855/2000, 耗时:0.01分/8.01分 | step: 437760 | performance: 26.2 | accuracy: 0.15 | loss: 1.80
update:860/2000, 耗时:0.01分/8.06分 | step: 440320 | performance: 67.2 | accuracy: 0.15 | loss: 2.33
update:865/2000, 耗时:0.01分/8.11分 | step: 442880 | performance: 44.4 | accuracy: 0.14 | loss: 1.37
update:870/2000, 耗时:0.01分/8.15分 | step: 445440 | performance: 85.5 | accuracy: 0.14 | loss: 1.26
update:875/2000, 耗时:0.01分/8.20分 | step: 448000 | performance: 53.7 | accuracy: 0.13 | loss: 1.60
update:880/2000, 耗时:0.01分/8.24分 | step: 450560 | performance: 1.0 | accuracy: 0.00 | loss: 1.77
step: 451069 | worker_4@n_step_63: average total_reward after train data exhaustion : 30.5 | max total_reward: 242.8
update:885/2000, 耗时:0.01分/8.29分 | step: 453120 | performance: 0.6 | accuracy: 0.11 | loss: 1.34
step: 453629 | worker_4@n_step_63: average total_reward after train data exhaustion : 5.8 | max total_reward: 242.8
update:890/2000, 耗时:0.01分/8.34分 | step: 455680 | performance: 0.9 | accuracy: 0.13 | loss: 2.12
update:895/2000, 耗时:0.01分/8.38分 | step: 458240 | performance: 1.0 | accuracy: 0.11 | loss: 1.69
update:900/2000, 耗时:0.01分/8.43分 | step: 460800 | performance: 1.6 | accuracy: 0.13 | loss: 0.97
update:905/2000, 耗时:0.01分/8.47分 | step: 463360 | performance: 1.4 | accuracy: 0.13 | loss: 1.22
update:910/2000, 耗时:0.01分/8.52分 | step: 465920 | performance: 1.6 | accuracy: 0.12 | loss: 0.86
update:915/2000, 耗时:0.01分/8.57分 | step: 468480 | performance: 3.3 | accuracy: 0.12 | loss: 1.60
step: 471034 | worker_1@n_step_63: average total_reward after train data exhaustion : 4.1 | max total_reward: 242.8
update:920/2000, 耗时:0.01分/8.61分 | step: 471040 | performance: 2.4 | accuracy: 0.12 | loss: 0.67
update:925/2000, 耗时:0.01分/8.66分 | step: 473600 | performance: 3.1 | accuracy: 0.11 | loss: 1.00
step: 474111 | worker_6@n_step_63: average total_reward after train data exhaustion : 2.6 | max total_reward: 242.8
update:930/2000, 耗时:0.01分/8.71分 | step: 476160 | performance: 4.3 | accuracy: 0.10 | loss: 1.25
update:935/2000, 耗时:0.01分/8.75分 | step: 478720 | performance: 9.8 | accuracy: 0.10 | loss: 3.07
update:940/2000, 耗时:0.01分/8.80分 | step: 481280 | performance: 13.2 | accuracy: 0.10 | loss: 1.58
update:945/2000, 耗时:0.01分/8.84分 | step: 483840 | performance: 1.2 | accuracy: 0.15 | loss: 2.07
update:950/2000, 耗时:0.01分/8.89分 | step: 486400 | performance: 1.4 | accuracy: 0.15 | loss: 2.81
update:955/2000, 耗时:0.01分/8.94分 | step: 488960 | performance: 3.6 | accuracy: 0.16 | loss: 1.98
update:960/2000, 耗时:0.01分/8.98分 | step: 491520 | performance: 1.7 | accuracy: 0.13 | loss: 1.18
update:965/2000, 耗时:0.01分/9.03分 | step: 494080 | performance: 1.8 | accuracy: 0.12 | loss: 1.25
update:970/2000, 耗时:0.01分/9.08分 | step: 496640 | performance: 2.5 | accuracy: 0.11 | loss: 0.79
update:975/2000, 耗时:0.01分/9.12分 | step: 499200 | performance: 2.5 | accuracy: 0.10 | loss: 0.81
step: 500733 | worker_4@n_step_63: average total_reward after train data exhaustion : 12.0 | max total_reward: 242.8
update:980/2000, 耗时:0.01分/9.17分 | step: 501760 | performance: 1.0 | accuracy: 0.00 | loss: 0.50
step: 504318 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 242.8
update:985/2000, 耗时:0.01分/9.22分 | step: 504320 | performance: 1.2 | accuracy: 0.13 | loss: 1.15
update:990/2000, 耗时:0.01分/9.27分 | step: 506880 | performance: 1.5 | accuracy: 0.38 | loss: 1.85
update:995/2000, 耗时:0.01分/9.31分 | step: 509440 | performance: 1.9 | accuracy: 0.12 | loss: 1.05
update:1000/2000, 耗时:0.01分/9.36分 | step: 512000 | performance: 3.7 | accuracy: 0.11 | loss: 2.64
update:1005/2000, 耗时:0.01分/9.41分 | step: 514560 | performance: 2.9 | accuracy: 0.10 | loss: 1.24
step: 515071 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 242.8
update:1010/2000, 耗时:0.01分/9.46分 | step: 517120 | performance: 5.5 | accuracy: 0.11 | loss: 1.41
update:1015/2000, 耗时:0.01分/9.50分 | step: 519680 | performance: 5.2 | accuracy: 0.11 | loss: 1.66
update:1020/2000, 耗时:0.01分/9.55分 | step: 522240 | performance: 5.6 | accuracy: 0.11 | loss: 1.24
step: 523257 | worker_0@n_step_63: average total_reward after train data exhaustion : 3.5 | max total_reward: 242.8
update:1025/2000, 耗时:0.01分/9.59分 | step: 524800 | performance: 2.0 | accuracy: 0.10 | loss: 2.33
step: 527353 | worker_0@n_step_63: average total_reward after train data exhaustion : 4.5 | max total_reward: 242.8
update:1030/2000, 耗时:0.01分/9.64分 | step: 527360 | performance: 1.0 | accuracy: 0.00 | loss: 2.35
update:1035/2000, 耗时:0.01分/9.69分 | step: 529920 | performance: 1.7 | accuracy: 0.13 | loss: 1.67
step: 531451 | worker_2@n_step_63: average total_reward after train data exhaustion : 6.5 | max total_reward: 242.8
step: 531967 | worker_6@n_step_63: average total_reward after train data exhaustion : 6.0 | max total_reward: 242.8
update:1040/2000, 耗时:0.01分/9.73分 | step: 532480 | performance: 1.3 | accuracy: 0.11 | loss: 1.61
update:1045/2000, 耗时:0.01分/9.78分 | step: 535040 | performance: 2.7 | accuracy: 0.15 | loss: 1.78
update:1050/2000, 耗时:0.01分/9.83分 | step: 537600 | performance: 8.1 | accuracy: 0.13 | loss: 2.09
update:1055/2000, 耗时:0.01分/9.87分 | step: 540160 | performance: 8.3 | accuracy: 0.12 | loss: 3.32
update:1060/2000, 耗时:0.01分/9.92分 | step: 542720 | performance: 4.0 | accuracy: 0.11 | loss: 1.01
update:1065/2000, 耗时:0.01分/9.97分 | step: 545280 | performance: 1.3 | accuracy: 0.11 | loss: 0.98
update:1070/2000, 耗时:0.01分/10.02分 | step: 547840 | performance: 1.2 | accuracy: 0.13 | loss: 1.31
update:1075/2000, 耗时:0.01分/10.06分 | step: 550400 | performance: 1.5 | accuracy: 0.44 | loss: 2.00
update:1080/2000, 耗时:0.01分/10.12分 | step: 552960 | performance: 1.6 | accuracy: 0.13 | loss: 2.19
update:1085/2000, 耗时:0.01分/10.17分 | step: 555520 | performance: 7.9 | accuracy: 0.15 | loss: 4.27
update:1090/2000, 耗时:0.01分/10.21分 | step: 558080 | performance: 3.3 | accuracy: 0.14 | loss: 1.50
update:1095/2000, 耗时:0.01分/10.26分 | step: 560640 | performance: 3.8 | accuracy: 0.13 | loss: 1.33
update:1100/2000, 耗时:0.01分/10.31分 | step: 563200 | performance: 2.9 | accuracy: 0.11 | loss: 1.01
update:1105/2000, 耗时:0.01分/10.36分 | step: 565760 | performance: 2.3 | accuracy: 0.10 | loss: 0.34
step: 566269 | worker_4@n_step_63: average total_reward after train data exhaustion : 5.1 | max total_reward: 242.8
step: 568317 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 242.8
step: 568318 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 242.8
update:1110/2000, 耗时:0.01分/10.41分 | step: 568320 | performance: 1.1 | accuracy: 0.50 | loss: 0.33
step: 569340 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 242.8
update:1115/2000, 耗时:0.01分/10.46分 | step: 570880 | performance: 1.3 | accuracy: 0.50 | loss: 0.51
step: 572416 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 242.8
update:1120/2000, 耗时:0.01分/10.51分 | step: 573440 | performance: 1.7 | accuracy: 0.24 | loss: 2.44
step: 573950 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 242.8
update:1125/2000, 耗时:0.01分/10.55分 | step: 576000 | performance: 2.2 | accuracy: 0.10 | loss: 1.47
step: 576509 | worker_4@n_step_63: average total_reward after train data exhaustion : 2.3 | max total_reward: 242.8
update:1130/2000, 耗时:0.01分/10.60分 | step: 578560 | performance: 2.2 | accuracy: 0.16 | loss: 3.49
update:1135/2000, 耗时:0.01分/10.64分 | step: 581120 | performance: 4.5 | accuracy: 0.14 | loss: 2.70
update:1140/2000, 耗时:0.01分/10.69分 | step: 583680 | performance: 3.0 | accuracy: 0.12 | loss: 1.42
update:1145/2000, 耗时:0.01分/10.74分 | step: 586240 | performance: 1.5 | accuracy: 0.11 | loss: 1.32
update:1150/2000, 耗时:0.01分/10.78分 | step: 588800 | performance: 2.2 | accuracy: 0.11 | loss: 1.18
update:1155/2000, 耗时:0.01分/10.83分 | step: 591360 | performance: 2.0 | accuracy: 0.10 | loss: 1.01
update:1160/2000, 耗时:0.01分/10.88分 | step: 593920 | performance: 1.2 | accuracy: 0.20 | loss: 1.99
update:1165/2000, 耗时:0.01分/10.93分 | step: 596480 | performance: 1.7 | accuracy: 0.11 | loss: 2.34
update:1170/2000, 耗时:0.01分/10.97分 | step: 599040 | performance: 5.7 | accuracy: 0.13 | loss: 1.77
update:1175/2000, 耗时:0.01分/11.02分 | step: 601600 | performance: 2.8 | accuracy: 0.12 | loss: 1.69
update:1180/2000, 耗时:0.01分/11.07分 | step: 604160 | performance: 3.5 | accuracy: 0.11 | loss: 0.74
update:1185/2000, 耗时:0.01分/11.11分 | step: 606720 | performance: 12.2 | accuracy: 0.11 | loss: 2.74
update:1190/2000, 耗时:0.01分/11.16分 | step: 609280 | performance: 10.2 | accuracy: 0.11 | loss: 1.77
update:1195/2000, 耗时:0.01分/11.20分 | step: 611840 | performance: 1.0 | accuracy: 0.00 | loss: 1.15
step: 613882 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.8 | max total_reward: 242.8
update:1200/2000, 耗时:0.01分/11.25分 | step: 614400 | performance: 1.4 | accuracy: 0.19 | loss: 1.11
update:1205/2000, 耗时:0.01分/11.30分 | step: 616960 | performance: 1.0 | accuracy: 0.06 | loss: 1.61
update:1210/2000, 耗时:0.01分/11.34分 | step: 619520 | performance: 1.3 | accuracy: 0.13 | loss: 2.78
update:1215/2000, 耗时:0.01分/11.39分 | step: 622080 | performance: 1.7 | accuracy: 0.12 | loss: 1.25
update:1220/2000, 耗时:0.01分/11.44分 | step: 624640 | performance: 2.1 | accuracy: 0.12 | loss: 0.93
update:1225/2000, 耗时:0.01分/11.48分 | step: 627200 | performance: 0.8 | accuracy: 0.10 | loss: 1.76
step: 628732 | worker_3@n_step_63: average total_reward after train data exhaustion : 4.1 | max total_reward: 242.8
update:1230/2000, 耗时:0.01分/11.53分 | step: 629760 | performance: 1.3 | accuracy: 0.10 | loss: 1.71
step: 631292 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.4 | max total_reward: 242.8
update:1235/2000, 耗时:0.01分/11.58分 | step: 632320 | performance: 1.0 | accuracy: 0.00 | loss: 1.87
step: 633854 | worker_5@n_step_63: average total_reward after train data exhaustion : 4.5 | max total_reward: 242.8
update:1240/2000, 耗时:0.01分/11.62分 | step: 634880 | performance: 1.6 | accuracy: 0.17 | loss: 1.62
update:1245/2000, 耗时:0.01分/11.67分 | step: 637440 | performance: 1.5 | accuracy: 0.12 | loss: 1.11
update:1250/2000, 耗时:0.01分/11.71分 | step: 640000 | performance: 2.3 | accuracy: 0.11 | loss: 1.09
update:1255/2000, 耗时:0.01分/11.76分 | step: 642560 | performance: 1.6 | accuracy: 0.10 | loss: 1.39
step: 644606 | worker_5@n_step_63: average total_reward after train data exhaustion : 2.5 | max total_reward: 242.8
update:1260/2000, 耗时:0.01分/11.80分 | step: 645120 | performance: 2.1 | accuracy: 0.14 | loss: 1.87
update:1265/2000, 耗时:0.01分/11.85分 | step: 647680 | performance: 1.9 | accuracy: 0.12 | loss: 1.84
update:1270/2000, 耗时:0.01分/11.89分 | step: 650240 | performance: 1.9 | accuracy: 0.11 | loss: 2.47
update:1275/2000, 耗时:0.01分/11.94分 | step: 652800 | performance: 0.9 | accuracy: 0.11 | loss: 2.14
step: 653306 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 242.8
update:1280/2000, 耗时:0.01分/11.99分 | step: 655360 | performance: 0.5 | accuracy: 0.11 | loss: 1.17
update:1285/2000, 耗时:0.01分/12.03分 | step: 657920 | performance: 0.4 | accuracy: 0.11 | loss: 1.35
update:1290/2000, 耗时:0.01分/12.08分 | step: 660480 | performance: 1.2 | accuracy: 0.35 | loss: 2.03
step: 663034 | worker_1@n_step_63: average total_reward after train data exhaustion : 6.1 | max total_reward: 242.8
update:1295/2000, 耗时:0.01分/12.12分 | step: 663040 | performance: 1.0 | accuracy: 0.00 | loss: 0.96
step: 664570 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 242.8
step: 665596 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.8 | max total_reward: 242.8
update:1300/2000, 耗时:0.01分/12.17分 | step: 665600 | performance: 1.0 | accuracy: 0.00 | loss: 0.71
update:1305/2000, 耗时:0.01分/12.22分 | step: 668160 | performance: 1.4 | accuracy: 0.14 | loss: 1.82
update:1310/2000, 耗时:0.01分/12.26分 | step: 670720 | performance: 1.4 | accuracy: 0.12 | loss: 1.20
update:1315/2000, 耗时:0.01分/12.31分 | step: 673280 | performance: 3.5 | accuracy: 0.13 | loss: 2.65
update:1320/2000, 耗时:0.01分/12.35分 | step: 675840 | performance: 2.8 | accuracy: 0.13 | loss: 1.96
update:1325/2000, 耗时:0.01分/12.40分 | step: 678400 | performance: 1.8 | accuracy: 0.12 | loss: 0.93
update:1330/2000, 耗时:0.01分/12.45分 | step: 680960 | performance: 2.3 | accuracy: 0.11 | loss: 0.84
update:1335/2000, 耗时:0.01分/12.49分 | step: 683520 | performance: 1.7 | accuracy: 0.11 | loss: 0.82
update:1340/2000, 耗时:0.01分/12.54分 | step: 686080 | performance: 1.5 | accuracy: 0.10 | loss: 3.46
update:1345/2000, 耗时:0.01分/12.58分 | step: 688640 | performance: 1.0 | accuracy: 0.00 | loss: 1.48
step: 689152 | worker_7@n_step_63: average total_reward after train data exhaustion : 4.5 | max total_reward: 242.8
step: 690169 | worker_0@n_step_63: average total_reward after train data exhaustion : 3.2 | max total_reward: 242.8
update:1350/2000, 耗时:0.01分/12.63分 | step: 691200 | performance: 0.9 | accuracy: 0.12 | loss: 1.56
update:1355/2000, 耗时:0.01分/12.68分 | step: 693760 | performance: 1.6 | accuracy: 0.13 | loss: 1.51
update:1360/2000, 耗时:0.01分/12.72分 | step: 696320 | performance: 1.5 | accuracy: 0.14 | loss: 2.81
update:1365/2000, 耗时:0.01分/12.77分 | step: 698880 | performance: 1.5 | accuracy: 0.13 | loss: 1.31
step: 699902 | worker_5@n_step_63: average total_reward after train data exhaustion : 3.7 | max total_reward: 242.8
update:1370/2000, 耗时:0.01分/12.81分 | step: 701440 | performance: 1.0 | accuracy: 0.12 | loss: 1.17
update:1375/2000, 耗时:0.01分/12.86分 | step: 704000 | performance: 0.8 | accuracy: 0.11 | loss: 1.53
update:1380/2000, 耗时:0.01分/12.91分 | step: 706560 | performance: 0.9 | accuracy: 0.10 | loss: 0.41
step: 707581 | worker_4@n_step_63: average total_reward after train data exhaustion : 5.3 | max total_reward: 242.8
update:1385/2000, 耗时:0.01分/12.95分 | step: 709120 | performance: 1.2 | accuracy: 0.19 | loss: 1.88
update:1390/2000, 耗时:0.01分/13.00分 | step: 711680 | performance: 1.3 | accuracy: 0.16 | loss: 1.62
update:1395/2000, 耗时:0.01分/13.04分 | step: 714240 | performance: 1.0 | accuracy: 0.15 | loss: 4.04
update:1400/2000, 耗时:0.01分/13.09分 | step: 716800 | performance: 0.8 | accuracy: 0.14 | loss: 2.02
update:1405/2000, 耗时:0.01分/13.14分 | step: 719360 | performance: 0.3 | accuracy: 0.13 | loss: 1.90
update:1410/2000, 耗时:0.01分/13.18分 | step: 721920 | performance: 0.5 | accuracy: 0.12 | loss: 2.17
update:1415/2000, 耗时:0.01分/13.23分 | step: 724480 | performance: 1.6 | accuracy: 0.13 | loss: 1.33
update:1420/2000, 耗时:0.01分/13.27分 | step: 727040 | performance: 0.6 | accuracy: 0.12 | loss: 1.16
step: 728570 | worker_1@n_step_63: average total_reward after train data exhaustion : 6.7 | max total_reward: 242.8
update:1425/2000, 耗时:0.01分/13.32分 | step: 729600 | performance: 0.8 | accuracy: 0.10 | loss: 1.22
update:1430/2000, 耗时:0.01分/13.37分 | step: 732160 | performance: 1.0 | accuracy: 0.00 | loss: 0.78
update:1435/2000, 耗时:0.01分/13.41分 | step: 734720 | performance: 3.2 | accuracy: 0.11 | loss: 2.08
update:1440/2000, 耗时:0.01分/13.46分 | step: 737280 | performance: 2.2 | accuracy: 0.15 | loss: 2.68
update:1445/2000, 耗时:0.01分/13.50分 | step: 739840 | performance: 3.0 | accuracy: 0.16 | loss: 3.36
update:1450/2000, 耗时:0.01分/13.55分 | step: 742400 | performance: 1.8 | accuracy: 0.14 | loss: 2.41
update:1455/2000, 耗时:0.01分/13.60分 | step: 744960 | performance: 1.7 | accuracy: 0.13 | loss: 2.72
update:1460/2000, 耗时:0.01分/13.64分 | step: 747520 | performance: 2.1 | accuracy: 0.13 | loss: 1.39
update:1465/2000, 耗时:0.01分/13.69分 | step: 750080 | performance: 1.8 | accuracy: 0.12 | loss: 0.76
update:1470/2000, 耗时:0.01分/13.73分 | step: 752640 | performance: 1.5 | accuracy: 0.11 | loss: 0.73
step: 755200 | worker_7@n_step_63: average total_reward after train data exhaustion : 2.8 | max total_reward: 242.8
update:1475/2000, 耗时:0.01分/13.78分 | step: 755200 | performance: 1.0 | accuracy: 0.00 | loss: 0.99
step: 755708 | worker_3@n_step_63: average total_reward after train data exhaustion : 4.0 | max total_reward: 242.8
step: 756217 | worker_0@n_step_63: average total_reward after train data exhaustion : 3.1 | max total_reward: 242.8
step: 756223 | worker_6@n_step_63: average total_reward after train data exhaustion : 3.1 | max total_reward: 242.8
step: 757756 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.5 | max total_reward: 242.8
update:1480/2000, 耗时:0.01分/13.83分 | step: 757760 | performance: 1.1 | accuracy: 0.14 | loss: 1.07
step: 760314 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 242.8
update:1485/2000, 耗时:0.01分/13.87分 | step: 760320 | performance: 1.3 | accuracy: 0.11 | loss: 1.20
update:1490/2000, 耗时:0.01分/13.92分 | step: 762880 | performance: 1.0 | accuracy: 0.25 | loss: 1.71
update:1495/2000, 耗时:0.01分/13.97分 | step: 765440 | performance: 2.2 | accuracy: 0.11 | loss: 2.45
update:1500/2000, 耗时:0.01分/14.01分 | step: 768000 | performance: 3.3 | accuracy: 0.13 | loss: 3.29
update:1505/2000, 耗时:0.01分/14.06分 | step: 770560 | performance: 0.9 | accuracy: 0.13 | loss: 7.67
update:1510/2000, 耗时:0.01分/14.10分 | step: 773120 | performance: 0.5 | accuracy: 0.12 | loss: 2.49
update:1515/2000, 耗时:0.01分/14.15分 | step: 775680 | performance: 0.6 | accuracy: 0.12 | loss: 0.83
update:1520/2000, 耗时:0.01分/14.20分 | step: 778240 | performance: 0.4 | accuracy: 0.11 | loss: 0.92
step: 780793 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 242.8
update:1525/2000, 耗时:0.01分/14.24分 | step: 780800 | performance: 1.0 | accuracy: 0.00 | loss: 0.73
update:1530/2000, 耗时:0.01分/14.29分 | step: 783360 | performance: 1.0 | accuracy: 0.00 | loss: 0.83
step: 784377 | worker_0@n_step_63: average total_reward after train data exhaustion : 3.0 | max total_reward: 242.8
update:1535/2000, 耗时:0.01分/14.34分 | step: 785920 | performance: 2.2 | accuracy: 0.11 | loss: 1.13
update:1540/2000, 耗时:0.01分/14.38分 | step: 788480 | performance: 0.8 | accuracy: 0.13 | loss: 2.04
update:1545/2000, 耗时:0.01分/14.42分 | step: 791040 | performance: 1.1 | accuracy: 0.12 | loss: 1.85
update:1550/2000, 耗时:0.01分/14.47分 | step: 793600 | performance: 0.7 | accuracy: 0.12 | loss: 1.48
update:1555/2000, 耗时:0.01分/14.52分 | step: 796160 | performance: 0.5 | accuracy: 0.11 | loss: 1.58
update:1560/2000, 耗时:0.01分/14.56分 | step: 798720 | performance: 0.5 | accuracy: 0.10 | loss: 2.17
update:1565/2000, 耗时:0.01分/14.61分 | step: 801280 | performance: 0.9 | accuracy: 0.12 | loss: 0.77
update:1570/2000, 耗时:0.01分/14.65分 | step: 803840 | performance: 0.9 | accuracy: 0.07 | loss: 0.80
step: 805888 | worker_7@n_step_63: average total_reward after train data exhaustion : 3.9 | max total_reward: 242.8
update:1575/2000, 耗时:0.01分/14.70分 | step: 806400 | performance: 1.6 | accuracy: 0.14 | loss: 1.41
update:1580/2000, 耗时:0.01分/14.75分 | step: 808960 | performance: 3.1 | accuracy: 0.14 | loss: 2.99
update:1585/2000, 耗时:0.01分/14.79分 | step: 811520 | performance: 5.5 | accuracy: 0.13 | loss: 2.76
update:1590/2000, 耗时:0.01分/14.84分 | step: 814080 | performance: 2.4 | accuracy: 0.13 | loss: 2.62
update:1595/2000, 耗时:0.01分/14.88分 | step: 816640 | performance: 2.0 | accuracy: 0.13 | loss: 1.97
update:1600/2000, 耗时:0.01分/14.93分 | step: 819200 | performance: 4.6 | accuracy: 0.13 | loss: 2.34
update:1605/2000, 耗时:0.01分/14.98分 | step: 821760 | performance: 2.0 | accuracy: 0.12 | loss: 0.58
update:1610/2000, 耗时:0.01分/15.02分 | step: 824320 | performance: 0.7 | accuracy: 0.11 | loss: 1.15
update:1615/2000, 耗时:0.01分/15.07分 | step: 826880 | performance: 0.8 | accuracy: 0.10 | loss: 0.99
update:1620/2000, 耗时:0.01分/15.12分 | step: 829440 | performance: 1.5 | accuracy: 0.12 | loss: 0.94
step: 830975 | worker_6@n_step_63: average total_reward after train data exhaustion : 2.4 | max total_reward: 242.8
update:1625/2000, 耗时:0.01分/15.16分 | step: 832000 | performance: 1.6 | accuracy: 0.15 | loss: 1.13
step: 832505 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.0 | max total_reward: 242.8
step: 832506 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 242.8
update:1630/2000, 耗时:0.01分/15.21分 | step: 834560 | performance: 4.1 | accuracy: 0.13 | loss: 1.94
update:1635/2000, 耗时:0.01分/15.26分 | step: 837120 | performance: 4.4 | accuracy: 0.13 | loss: 3.79
update:1640/2000, 耗时:0.01分/15.31分 | step: 839680 | performance: 2.1 | accuracy: 0.13 | loss: 2.62
update:1645/2000, 耗时:0.01分/15.35分 | step: 842240 | performance: 2.3 | accuracy: 0.13 | loss: 1.14
update:1650/2000, 耗时:0.01分/15.40分 | step: 844800 | performance: 1.8 | accuracy: 0.13 | loss: 1.44
update:1655/2000, 耗时:0.01分/15.45分 | step: 847360 | performance: 1.0 | accuracy: 0.12 | loss: 1.20
update:1660/2000, 耗时:0.01分/15.49分 | step: 849920 | performance: 1.2 | accuracy: 0.11 | loss: 1.12
update:1665/2000, 耗时:0.01分/15.54分 | step: 852480 | performance: 1.0 | accuracy: 0.11 | loss: 1.25
step: 854013 | worker_4@n_step_63: average total_reward after train data exhaustion : 4.3 | max total_reward: 242.8
update:1670/2000, 耗时:0.01分/15.58分 | step: 855040 | performance: 1.5 | accuracy: 0.11 | loss: 2.12
update:1675/2000, 耗时:0.01分/15.63分 | step: 857600 | performance: 2.8 | accuracy: 0.10 | loss: 1.28
update:1680/2000, 耗时:0.01分/15.68分 | step: 860160 | performance: 1.3 | accuracy: 0.14 | loss: 4.62
update:1685/2000, 耗时:0.01分/15.72分 | step: 862720 | performance: 4.0 | accuracy: 0.14 | loss: 3.29
update:1690/2000, 耗时:0.01分/15.77分 | step: 865280 | performance: 2.4 | accuracy: 0.13 | loss: 2.24
update:1695/2000, 耗时:0.01分/15.82分 | step: 867840 | performance: 1.9 | accuracy: 0.13 | loss: 5.39
update:1700/2000, 耗时:0.01分/15.86分 | step: 870400 | performance: 2.2 | accuracy: 0.12 | loss: 1.44
update:1705/2000, 耗时:0.01分/15.91分 | step: 872960 | performance: 2.0 | accuracy: 0.11 | loss: 0.62
step: 875005 | worker_4@n_step_63: average total_reward after train data exhaustion : 8.3 | max total_reward: 242.8
update:1710/2000, 耗时:0.01分/15.95分 | step: 875520 | performance: 2.1 | accuracy: 0.10 | loss: 0.67
update:1715/2000, 耗时:0.01分/16.00分 | step: 878080 | performance: 1.1 | accuracy: 0.11 | loss: 0.36
step: 880121 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.8 | max total_reward: 242.8
step: 880124 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 242.8
update:1720/2000, 耗时:0.01分/16.05分 | step: 880640 | performance: 1.1 | accuracy: 0.25 | loss: 1.41
step: 881152 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 242.8
update:1725/2000, 耗时:0.01分/16.10分 | step: 883200 | performance: 0.8 | accuracy: 0.13 | loss: 1.44
step: 884730 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 242.8
update:1730/2000, 耗时:0.01分/16.15分 | step: 885760 | performance: 1.2 | accuracy: 0.33 | loss: 0.68
step: 886266 | worker_1@n_step_63: average total_reward after train data exhaustion : 2.7 | max total_reward: 242.8
step: 886267 | worker_2@n_step_63: average total_reward after train data exhaustion : 2.7 | max total_reward: 242.8
step: 886777 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.2 | max total_reward: 242.8
update:1735/2000, 耗时:0.01分/16.20分 | step: 888320 | performance: 1.2 | accuracy: 0.17 | loss: 2.00
update:1740/2000, 耗时:0.01分/16.25分 | step: 890880 | performance: 1.4 | accuracy: 0.14 | loss: 1.57
update:1745/2000, 耗时:0.01分/16.30分 | step: 893440 | performance: 2.2 | accuracy: 0.14 | loss: 1.97
update:1750/2000, 耗时:0.01分/16.35分 | step: 896000 | performance: 6.2 | accuracy: 0.15 | loss: 2.98
update:1755/2000, 耗时:0.01分/16.40分 | step: 898560 | performance: 5.3 | accuracy: 0.14 | loss: 1.72
update:1760/2000, 耗时:0.01分/16.45分 | step: 901120 | performance: 5.8 | accuracy: 0.13 | loss: 1.52
update:1765/2000, 耗时:0.01分/16.50分 | step: 903680 | performance: 3.3 | accuracy: 0.12 | loss: 2.15
step: 905721 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 242.8
update:1770/2000, 耗时:0.01分/16.55分 | step: 906240 | performance: 1.5 | accuracy: 0.12 | loss: 1.47
update:1775/2000, 耗时:0.01分/16.59分 | step: 908800 | performance: 1.5 | accuracy: 0.10 | loss: 1.01
step: 910334 | worker_5@n_step_63: average total_reward after train data exhaustion : 3.4 | max total_reward: 242.8
update:1780/2000, 耗时:0.01分/16.64分 | step: 911360 | performance: 1.1 | accuracy: 0.10 | loss: 1.32
update:1785/2000, 耗时:0.01分/16.69分 | step: 913920 | performance: 2.4 | accuracy: 0.13 | loss: 2.43
update:1790/2000, 耗时:0.01分/16.73分 | step: 916480 | performance: 4.4 | accuracy: 0.13 | loss: 1.84
update:1795/2000, 耗时:0.01分/16.78分 | step: 919040 | performance: 1.8 | accuracy: 0.12 | loss: 1.34
update:1800/2000, 耗时:0.01分/16.82分 | step: 921600 | performance: 1.5 | accuracy: 0.11 | loss: 0.98
update:1805/2000, 耗时:0.01分/16.87分 | step: 924160 | performance: 1.5 | accuracy: 0.10 | loss: 1.12
update:1810/2000, 耗时:0.01分/16.92分 | step: 926720 | performance: 1.4 | accuracy: 0.11 | loss: 1.47
step: 929275 | worker_2@n_step_63: average total_reward after train data exhaustion : 3.1 | max total_reward: 242.8
update:1815/2000, 耗时:0.01分/16.96分 | step: 929280 | performance: 1.3 | accuracy: 0.12 | loss: 1.50
update:1820/2000, 耗时:0.01分/17.01分 | step: 931840 | performance: 1.2 | accuracy: 0.25 | loss: 4.01
update:1825/2000, 耗时:0.01分/17.06分 | step: 934400 | performance: 1.6 | accuracy: 0.12 | loss: 2.06
update:1830/2000, 耗时:0.01分/17.10分 | step: 936960 | performance: 3.1 | accuracy: 0.13 | loss: 3.06
update:1835/2000, 耗时:0.01分/17.15分 | step: 939520 | performance: 0.5 | accuracy: 0.11 | loss: 3.11
update:1840/2000, 耗时:0.01分/17.19分 | step: 942080 | performance: 0.5 | accuracy: 0.11 | loss: 1.70
update:1845/2000, 耗时:0.01分/17.24分 | step: 944640 | performance: 0.2 | accuracy: 0.11 | loss: 1.14
update:1850/2000, 耗时:0.01分/17.29分 | step: 947200 | performance: 0.2 | accuracy: 0.10 | loss: 1.75
update:1855/2000, 耗时:0.01分/17.33分 | step: 949760 | performance: 1.7 | accuracy: 0.15 | loss: 1.04
step: 952319 | worker_6@n_step_63: average total_reward after train data exhaustion : 5.3 | max total_reward: 242.8
update:1860/2000, 耗时:0.01分/17.38分 | step: 952320 | performance: 2.2 | accuracy: 0.11 | loss: 2.37
update:1865/2000, 耗时:0.01分/17.42分 | step: 954880 | performance: 2.5 | accuracy: 0.11 | loss: 1.31
update:1870/2000, 耗时:0.01分/17.47分 | step: 957440 | performance: 1.0 | accuracy: 0.10 | loss: 2.05
update:1875/2000, 耗时:0.01分/17.52分 | step: 960000 | performance: 1.0 | accuracy: 0.21 | loss: 2.48
update:1880/2000, 耗时:0.01分/17.56分 | step: 962560 | performance: 1.2 | accuracy: 0.11 | loss: 1.62
update:1885/2000, 耗时:0.01分/17.61分 | step: 965120 | performance: 2.7 | accuracy: 0.12 | loss: 3.07
update:1890/2000, 耗时:0.01分/17.65分 | step: 967680 | performance: 0.7 | accuracy: 0.11 | loss: 2.36
update:1895/2000, 耗时:0.01分/17.70分 | step: 970240 | performance: 1.1 | accuracy: 0.12 | loss: 3.40
update:1900/2000, 耗时:0.01分/17.74分 | step: 972800 | performance: 1.2 | accuracy: 0.12 | loss: 2.94
update:1905/2000, 耗时:0.01分/17.79分 | step: 975360 | performance: 0.7 | accuracy: 0.11 | loss: 0.77
update:1910/2000, 耗时:0.01分/17.84分 | step: 977920 | performance: 0.3 | accuracy: 0.10 | loss: 0.87
step: 979452 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.9 | max total_reward: 242.8
update:1915/2000, 耗时:0.01分/17.88分 | step: 980480 | performance: 1.2 | accuracy: 0.11 | loss: 0.98
step: 980988 | worker_3@n_step_63: average total_reward after train data exhaustion : 4.6 | max total_reward: 242.8
update:1920/2000, 耗时:0.01分/17.93分 | step: 983040 | performance: 1.4 | accuracy: 0.16 | loss: 1.77
update:1925/2000, 耗时:0.01分/17.97分 | step: 985600 | performance: 1.7 | accuracy: 0.11 | loss: 1.63
update:1930/2000, 耗时:0.01分/18.02分 | step: 988160 | performance: 1.1 | accuracy: 0.10 | loss: 2.46
update:1935/2000, 耗时:0.01分/18.06分 | step: 990720 | performance: 1.1 | accuracy: 0.22 | loss: 1.71
update:1940/2000, 耗时:0.01分/18.11分 | step: 993280 | performance: 1.0 | accuracy: 0.08 | loss: 2.30
update:1945/2000, 耗时:0.01分/18.16分 | step: 995840 | performance: 1.4 | accuracy: 0.13 | loss: 1.08
update:1950/2000, 耗时:0.01分/18.20分 | step: 998400 | performance: 1.3 | accuracy: 0.13 | loss: 1.01
update:1955/2000, 耗时:0.01分/18.25分 | step: 1000960 | performance: 0.9 | accuracy: 0.12 | loss: 2.50
update:1960/2000, 耗时:0.01分/18.29分 | step: 1003520 | performance: 1.5 | accuracy: 0.22 | loss: 2.07
update:1965/2000, 耗时:0.01分/18.34分 | step: 1006080 | performance: 1.0 | accuracy: 0.00 | loss: 1.62
update:1970/2000, 耗时:0.01分/18.38分 | step: 1008640 | performance: 3.4 | accuracy: 0.15 | loss: 3.39
update:1975/2000, 耗时:0.01分/18.43分 | step: 1011200 | performance: 19.3 | accuracy: 0.17 | loss: 2.66
update:1980/2000, 耗时:0.01分/18.48分 | step: 1013760 | performance: 6.4 | accuracy: 0.15 | loss: 1.91
update:1985/2000, 耗时:0.01分/18.52分 | step: 1016320 | performance: 3.4 | accuracy: 0.14 | loss: 3.04
update:1990/2000, 耗时:0.01分/18.57分 | step: 1018880 | performance: 2.8 | accuracy: 0.13 | loss: 0.90
update:1995/2000, 耗时:0.01分/18.61分 | step: 1021440 | performance: 3.2 | accuracy: 0.12 | loss: 1.05
update:2000/2000, 耗时:0.01分/18.66分 | step: 1024000 | performance: 1.1 | accuracy: 0.12 | loss: 1.07
----------------------------------------finished----------------------------------------
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/397 [00:00<?, ?it/s]100%|| 397/397 [00:00<00:00, 132269.34it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1126.96
2023-07-24T12:00:00 | net performance [%] = 12.6962
2023-07-24T12:00:00 | number of trades [#] = 16
==================================================
Trial 45 Complete [00h 19m 06s]
net_wealth: 1126.961736080178

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 06h 07m 43s

Search: Running Trial #46

Value             |Best Value So Far |Hyperparameter
6                 |7                 |horizon
730               |730               |lookback
False             |False             |MarketFactor
14                |14                |lags
0.85              |0.7               |gamma
32                |32                |batch_size
3                 |32                |n_step
0.99              |0.92              |gae_lambda
2                 |0.1               |gradient_clip_norm
5                 |5                 |epochs
5e-05             |0.0001            |actor_lr
5e-05             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4309.000000   4315.000000
mean      0.000441    20062.255222  ...   20140.547965  20118.633889
std       0.027818    16039.874230  ...   16077.550480  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7699.189941   7690.540039
50%       0.000642    11554.824463  ...   11743.940430  11715.610352
75%       0.011655    29873.081836  ...   29950.949219  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 04:11:06.527758: I tensorflow/core/platform/cpu_feature_guard.cc:142] This Tenso2023-07-28 04:11:06.527804: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU i2023-07-28 04:11:06.527901: I tensorflow/core/platform/cpu_feature_guard.cc:2rFlow binary is optimi1nzstrue42dc ]tw iThoiis Tensontsh oner AFPI Din 2023-07-le2p8 04:1eerform1ow p Neura:bilna0n6 N0c23-.ary is optimized with on527e-c9eA9etwork Lrii6: I tensorflow/core/platform/cputic07-28 04:1_1faelat ou:06rpere._5gatiou279ans:r38:d  AV. I cX Act:b2r1V4e20]2P I DTnseep3 Neur-haolr0Xaflrow/c72ori
s Tensory (oeF/plToatform/cpu_featl oew b Nuere_tgnabwuloirarkne ar t20Li2by hrei3nesD dopam -t20NrN)07y-2-8 02 3t (oneDo24.c:8 1uc:s -0711NiNmiz-e2d84 0:e064) :2t] ihe1w f014:n oollo iT:11hth on06wing CPUteAPI Deh:06.e5pi.. er  os52Nt2 884139in:o  use epTe I tre8thsn5:sot rensorFluIrflo toecwns wbinar/coy5orfteire onusl2fo/w /o8lrlalcion2 owing C4r8e:PU in /Iplatfsotrucp  Net tplatform/cpu_feature_guard.ccierformoennss in:ois optirfl14m2 ]ipo wTerzheir/cod swr Titefoenstm/c/plrhp ooatform/cpau_nu_cationfmanceawtuorkse,-crn  fLiirrreeebtriaea_tguacuerrd.cbaF-AcPIeu_ cDreye ill opritil:pdow b1 (oT iNneennarys4ero 2ia]ti Thiorness ugroapt: Du FlNiNml No)Aasr T w izewVtXo eAdVX2d etn
sT.wc ow eciorFlon:au14seoc2a]l w  btbhtehl  i iettonahp  rfko hrteloyn eiAh easpelLPpI DrTroprhi aoemt iiiieopo wnspni ontgNs :bTreant hresroi myi aArzeCurPUt e c(VXedo nin s FeaAlV Noltru eotDNoXc2twith
Tow wpNe)er noim oanbelAer ako ptitnibPos  itLioI u sneaDhryembir an sl,i ne rp erenf ote pt hhroreeNibyufeerru ls  m(riaal Nfgosll eoatnoco.pltd 
onepwiiw-eTrenmiationocnrgesDzNeNi rsk)CdorFlP  with oneAPI Deep Neural Network Library (oneDNN) to u, rebuild TensorFlotow witU iwitcn w Lalo sh tiutrhe atusct ipbiponhe raorpyeratrot ions: h (oneDe ft oNsNAphe Vrlloiwa)aXi nsgptot pCreo ptri  u atePAVXhisne e compiler flags.
2 compile
pT retrhfoo enable the following CPU instructionsrmU instruction aees  imnf opl nice-ilowi ngfclne oar rCtgs.f
ormanPiUtical open ins performartruchnectaetiro nceoperations, rebuild TensorFlow with s:  AVX AVX2
To enable them in other o-criticipoerat-atnilons,chs inr itop pei cerations:  AVX AVX2
To enae rrebuild TensorFlow with tformbhance-crital operations:  AVX AVX2
To enable them in other operations, rebei acal operations:  AVX AVX2
To enable them in other operations, rappropriate compiler flags.
ppropriate compiler flags.
le them in other operatiouild TensorFlow with the appropriate compiler flags.
ns, rebuild TensorFlow with the appropriate compiler flags.
ebuild TensorFlow with the appropriate compiler flags.
2023-07-28 04:11:07.155110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:11:07.157230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:11:07.166497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:11:07.167670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:11:07.178094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:11:07.184256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:11:07.187135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:11:07.199741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   120 | performance: 1.2 | accuracy: 0.33 | loss: 0.62
update: 10/2000, 耗时:0.00分/0.04分 | step:   240 | performance: 1.3 | accuracy: 0.33 | loss: 0.51
update: 15/2000, 耗时:0.00分/0.05分 | step:   360 | performance: 1.7 | accuracy: 0.38 | loss: 0.71
update: 20/2000, 耗时:0.00分/0.06分 | step:   480 | performance: 1.6 | accuracy: 0.35 | loss: 0.31
update: 25/2000, 耗时:0.00分/0.07分 | step:   600 | performance: 1.6 | accuracy: 0.29 | loss: 1.23
update: 30/2000, 耗时:0.00分/0.08分 | step:   720 | performance: 1.4 | accuracy: 0.28 | loss: 1.69
update: 35/2000, 耗时:0.00分/0.10分 | step:   840 | performance: 1.4 | accuracy: 0.30 | loss: 0.70
update: 40/2000, 耗时:0.00分/0.11分 | step:   960 | performance: 1.4 | accuracy: 0.29 | loss: 0.79
update: 45/2000, 耗时:0.00分/0.12分 | step:  1080 | performance: 1.6 | accuracy: 0.30 | loss: 0.97
update: 50/2000, 耗时:0.00分/0.13分 | step:  1200 | performance: 2.5 | accuracy: 0.31 | loss: 1.32
update: 55/2000, 耗时:0.00分/0.15分 | step:  1320 | performance: 8.9 | accuracy: 0.35 | loss: 2.57
update: 60/2000, 耗时:0.00分/0.16分 | step:  1440 | performance: 9.3 | accuracy: 0.36 | loss: 0.36
update: 65/2000, 耗时:0.00分/0.17分 | step:  1560 | performance: 14.6 | accuracy: 0.37 | loss: 0.68
update: 70/2000, 耗时:0.00分/0.19分 | step:  1680 | performance: 13.9 | accuracy: 0.40 | loss: 8.79
update: 75/2000, 耗时:0.00分/0.20分 | step:  1800 | performance: 7.5 | accuracy: 0.39 | loss: 1.33
update: 80/2000, 耗时:0.00分/0.21分 | step:  1920 | performance: 8.8 | accuracy: 0.40 | loss: 1.75
update: 85/2000, 耗时:0.00分/0.23分 | step:  2040 | performance: 10.3 | accuracy: 0.40 | loss: 1.28
update: 90/2000, 耗时:0.00分/0.24分 | step:  2160 | performance: 16.4 | accuracy: 0.42 | loss: 0.35
update: 95/2000, 耗时:0.00分/0.25分 | step:  2280 | performance: 17.4 | accuracy: 0.42 | loss: 0.65
update:100/2000, 耗时:0.00分/0.27分 | step:  2400 | performance: 20.4 | accuracy: 0.42 | loss: 2.64
update:105/2000, 耗时:0.00分/0.28分 | step:  2520 | performance: 18.0 | accuracy: 0.42 | loss: 4.15
update:110/2000, 耗时:0.00分/0.29分 | step:  2640 | performance: 16.0 | accuracy: 0.42 | loss: 2.47
update:115/2000, 耗时:0.00分/0.31分 | step:  2760 | performance: 10.5 | accuracy: 0.41 | loss: 0.92
update:120/2000, 耗时:0.00分/0.32分 | step:  2880 | performance: 13.8 | accuracy: 0.42 | loss: 0.73
update:125/2000, 耗时:0.00分/0.33分 | step:  3000 | performance: 12.6 | accuracy: 0.41 | loss: 0.33
update:130/2000, 耗时:0.00分/0.34分 | step:  3120 | performance: 11.5 | accuracy: 0.40 | loss: 0.31
update:135/2000, 耗时:0.00分/0.36分 | step:  3240 | performance: 11.8 | accuracy: 0.40 | loss: 0.51
update:140/2000, 耗时:0.00分/0.37分 | step:  3360 | performance: 9.9 | accuracy: 0.39 | loss: 1.41
update:145/2000, 耗时:0.00分/0.38分 | step:  3480 | performance: 5.6 | accuracy: 0.38 | loss: 0.59
update:150/2000, 耗时:0.00分/0.40分 | step:  3600 | performance: 5.0 | accuracy: 0.37 | loss: 0.20
update:155/2000, 耗时:0.00分/0.41分 | step:  3720 | performance: 5.1 | accuracy: 0.37 | loss: 0.71
update:160/2000, 耗时:0.00分/0.42分 | step:  3840 | performance: 5.0 | accuracy: 0.36 | loss: 0.62
update:165/2000, 耗时:0.00分/0.43分 | step:  3960 | performance: 5.8 | accuracy: 0.36 | loss: 0.75
update:170/2000, 耗时:0.00分/0.45分 | step:  4080 | performance: 6.8 | accuracy: 0.36 | loss: 2.67
update:175/2000, 耗时:0.00分/0.46分 | step:  4200 | performance: 8.4 | accuracy: 0.37 | loss: 1.21
update:180/2000, 耗时:0.00分/0.47分 | step:  4320 | performance: 12.0 | accuracy: 0.37 | loss: 0.81
update:185/2000, 耗时:0.00分/0.49分 | step:  4440 | performance: 8.8 | accuracy: 0.37 | loss: 0.56
update:190/2000, 耗时:0.00分/0.50分 | step:  4560 | performance: 10.7 | accuracy: 0.37 | loss: 1.93
update:195/2000, 耗时:0.00分/0.51分 | step:  4680 | performance: 30.1 | accuracy: 0.38 | loss: 3.85
update:200/2000, 耗时:0.00分/0.52分 | step:  4800 | performance: 31.8 | accuracy: 0.39 | loss: 7.00
update:205/2000, 耗时:0.00分/0.54分 | step:  4920 | performance: 51.4 | accuracy: 0.40 | loss: 1.48
update:210/2000, 耗时:0.00分/0.55分 | step:  5040 | performance: 18.4 | accuracy: 0.39 | loss: 5.04
update:215/2000, 耗时:0.00分/0.56分 | step:  5160 | performance: 17.7 | accuracy: 0.39 | loss: 7.19
update:220/2000, 耗时:0.00分/0.58分 | step:  5280 | performance: 16.1 | accuracy: 0.39 | loss: 1.56
update:225/2000, 耗时:0.00分/0.59分 | step:  5400 | performance: 34.5 | accuracy: 0.40 | loss: 1.92
update:230/2000, 耗时:0.00分/0.60分 | step:  5520 | performance: 16.1 | accuracy: 0.39 | loss: 2.75
update:235/2000, 耗时:0.00分/0.62分 | step:  5640 | performance: 14.4 | accuracy: 0.39 | loss: 3.30
update:240/2000, 耗时:0.00分/0.63分 | step:  5760 | performance: 9.9 | accuracy: 0.39 | loss: 1.87
update:245/2000, 耗时:0.00分/0.64分 | step:  5880 | performance: 17.9 | accuracy: 0.40 | loss: 1.97
update:250/2000, 耗时:0.00分/0.66分 | step:  6000 | performance: 16.1 | accuracy: 0.40 | loss: 1.78
update:255/2000, 耗时:0.00分/0.67分 | step:  6120 | performance: 13.6 | accuracy: 0.39 | loss: 0.43
update:260/2000, 耗时:0.00分/0.68分 | step:  6240 | performance: 4.1 | accuracy: 0.39 | loss: 0.39
update:265/2000, 耗时:0.00分/0.69分 | step:  6360 | performance: 4.2 | accuracy: 0.39 | loss: 0.89
update:270/2000, 耗时:0.00分/0.71分 | step:  6480 | performance: 4.8 | accuracy: 0.39 | loss: 0.65
update:275/2000, 耗时:0.00分/0.72分 | step:  6600 | performance: 4.6 | accuracy: 0.38 | loss: 0.55
update:280/2000, 耗时:0.00分/0.73分 | step:  6720 | performance: 4.4 | accuracy: 0.38 | loss: 0.63
update:285/2000, 耗时:0.00分/0.75分 | step:  6840 | performance: 5.3 | accuracy: 0.38 | loss: 1.54
update:290/2000, 耗时:0.00分/0.76分 | step:  6960 | performance: 5.0 | accuracy: 0.38 | loss: 0.36
update:295/2000, 耗时:0.00分/0.77分 | step:  7080 | performance: 6.2 | accuracy: 0.38 | loss: 0.51
update:300/2000, 耗时:0.00分/0.79分 | step:  7200 | performance: 4.9 | accuracy: 0.38 | loss: 1.31
update:305/2000, 耗时:0.00分/0.80分 | step:  7320 | performance: 6.0 | accuracy: 0.38 | loss: 0.55
update:310/2000, 耗时:0.00分/0.81分 | step:  7440 | performance: 6.4 | accuracy: 0.38 | loss: 0.32
update:315/2000, 耗时:0.00分/0.82分 | step:  7560 | performance: 6.2 | accuracy: 0.37 | loss: 0.56
update:320/2000, 耗时:0.00分/0.84分 | step:  7680 | performance: 5.0 | accuracy: 0.37 | loss: 0.79
update:325/2000, 耗时:0.00分/0.85分 | step:  7800 | performance: 5.1 | accuracy: 0.37 | loss: 0.82
update:330/2000, 耗时:0.00分/0.86分 | step:  7920 | performance: 5.0 | accuracy: 0.37 | loss: 0.92
update:335/2000, 耗时:0.00分/0.88分 | step:  8040 | performance: 4.8 | accuracy: 0.37 | loss: 0.41
update:340/2000, 耗时:0.00分/0.89分 | step:  8160 | performance: 4.6 | accuracy: 0.36 | loss: 0.35
update:345/2000, 耗时:0.00分/0.90分 | step:  8280 | performance: 5.6 | accuracy: 0.36 | loss: 0.48
update:350/2000, 耗时:0.00分/0.92分 | step:  8400 | performance: 7.2 | accuracy: 0.36 | loss: 0.52
update:355/2000, 耗时:0.00分/0.93分 | step:  8520 | performance: 6.6 | accuracy: 0.36 | loss: 0.56
update:360/2000, 耗时:0.00分/0.94分 | step:  8640 | performance: 4.9 | accuracy: 0.36 | loss: 1.28
update:365/2000, 耗时:0.00分/0.96分 | step:  8760 | performance: 4.3 | accuracy: 0.36 | loss: 0.52
update:370/2000, 耗时:0.00分/0.97分 | step:  8880 | performance: 7.5 | accuracy: 0.36 | loss: 6.37
update:375/2000, 耗时:0.00分/0.98分 | step:  9000 | performance: 7.7 | accuracy: 0.36 | loss: 7.45
update:380/2000, 耗时:0.00分/1.00分 | step:  9120 | performance: 3.4 | accuracy: 0.36 | loss: 1.57
update:385/2000, 耗时:0.00分/1.01分 | step:  9240 | performance: 3.1 | accuracy: 0.36 | loss: 1.36
update:390/2000, 耗时:0.00分/1.02分 | step:  9360 | performance: 3.3 | accuracy: 0.36 | loss: 1.44
update:395/2000, 耗时:0.00分/1.04分 | step:  9480 | performance: 3.0 | accuracy: 0.36 | loss: 0.69
update:400/2000, 耗时:0.00分/1.05分 | step:  9600 | performance: 3.8 | accuracy: 0.36 | loss: 0.86
update:405/2000, 耗时:0.00分/1.06分 | step:  9720 | performance: 8.3 | accuracy: 0.37 | loss: 0.23
update:410/2000, 耗时:0.00分/1.08分 | step:  9840 | performance: 6.0 | accuracy: 0.37 | loss: 2.67
update:415/2000, 耗时:0.00分/1.09分 | step:  9960 | performance: 6.2 | accuracy: 0.37 | loss: 0.94
update:420/2000, 耗时:0.00分/1.10分 | step: 10080 | performance: 5.2 | accuracy: 0.37 | loss: 0.36
update:425/2000, 耗时:0.00分/1.12分 | step: 10200 | performance: 5.3 | accuracy: 0.36 | loss: 0.81
update:430/2000, 耗时:0.00分/1.13分 | step: 10320 | performance: 5.8 | accuracy: 0.37 | loss: 0.38
update:435/2000, 耗时:0.00分/1.14分 | step: 10440 | performance: 6.2 | accuracy: 0.36 | loss: 0.33
update:440/2000, 耗时:0.00分/1.15分 | step: 10560 | performance: 6.4 | accuracy: 0.36 | loss: 0.42
update:445/2000, 耗时:0.00分/1.17分 | step: 10680 | performance: 6.3 | accuracy: 0.36 | loss: 0.31
update:450/2000, 耗时:0.00分/1.18分 | step: 10800 | performance: 6.4 | accuracy: 0.36 | loss: 0.38
update:455/2000, 耗时:0.00分/1.19分 | step: 10920 | performance: 6.2 | accuracy: 0.36 | loss: 0.21
update:460/2000, 耗时:0.00分/1.21分 | step: 11040 | performance: 6.6 | accuracy: 0.36 | loss: 0.58
update:465/2000, 耗时:0.00分/1.22分 | step: 11160 | performance: 8.1 | accuracy: 0.36 | loss: 0.51
update:470/2000, 耗时:0.00分/1.23分 | step: 11280 | performance: 8.3 | accuracy: 0.35 | loss: 0.12
update:475/2000, 耗时:0.00分/1.24分 | step: 11400 | performance: 8.2 | accuracy: 0.35 | loss: 0.19
update:480/2000, 耗时:0.00分/1.26分 | step: 11520 | performance: 7.7 | accuracy: 0.35 | loss: 0.27
update:485/2000, 耗时:0.00分/1.27分 | step: 11640 | performance: 8.5 | accuracy: 0.35 | loss: 0.34
update:490/2000, 耗时:0.00分/1.28分 | step: 11760 | performance: 8.7 | accuracy: 0.35 | loss: 0.26
update:495/2000, 耗时:0.00分/1.29分 | step: 11880 | performance: 7.3 | accuracy: 0.35 | loss: 1.27
update:500/2000, 耗时:0.00分/1.31分 | step: 12000 | performance: 6.6 | accuracy: 0.34 | loss: 0.53
update:505/2000, 耗时:0.00分/1.32分 | step: 12120 | performance: 6.6 | accuracy: 0.34 | loss: 0.32
update:510/2000, 耗时:0.00分/1.33分 | step: 12240 | performance: 6.5 | accuracy: 0.34 | loss: 0.39
update:515/2000, 耗时:0.00分/1.34分 | step: 12360 | performance: 5.5 | accuracy: 0.34 | loss: 0.56
update:520/2000, 耗时:0.00分/1.36分 | step: 12480 | performance: 7.1 | accuracy: 0.34 | loss: 0.88
update:525/2000, 耗时:0.00分/1.37分 | step: 12600 | performance: 9.2 | accuracy: 0.35 | loss: 0.65
update:530/2000, 耗时:0.00分/1.38分 | step: 12720 | performance: 14.6 | accuracy: 0.35 | loss: 1.31
update:535/2000, 耗时:0.00分/1.39分 | step: 12840 | performance: 17.1 | accuracy: 0.35 | loss: 0.52
update:540/2000, 耗时:0.00分/1.41分 | step: 12960 | performance: 35.4 | accuracy: 0.36 | loss: 0.29
update:545/2000, 耗时:0.00分/1.42分 | step: 13080 | performance: 37.1 | accuracy: 0.36 | loss: 1.44
update:550/2000, 耗时:0.00分/1.43分 | step: 13200 | performance: 47.2 | accuracy: 0.36 | loss: 0.68
update:555/2000, 耗时:0.00分/1.45分 | step: 13320 | performance: 55.4 | accuracy: 0.36 | loss: 0.46
update:560/2000, 耗时:0.00分/1.46分 | step: 13440 | performance: 138.2 | accuracy: 0.36 | loss: 1.00
update:565/2000, 耗时:0.00分/1.47分 | step: 13560 | performance: 382.7 | accuracy: 0.37 | loss: 0.61
update:570/2000, 耗时:0.00分/1.48分 | step: 13680 | performance: 1469.9 | accuracy: 0.37 | loss: 0.83
update:575/2000, 耗时:0.00分/1.50分 | step: 13800 | performance: 2011.0 | accuracy: 0.38 | loss: 0.67
update:580/2000, 耗时:0.00分/1.51分 | step: 13920 | performance: 1174.9 | accuracy: 0.37 | loss: 13.61
update:585/2000, 耗时:0.00分/1.52分 | step: 14040 | performance: 1096.0 | accuracy: 0.38 | loss: 0.71
update:590/2000, 耗时:0.00分/1.53分 | step: 14160 | performance: 2309.0 | accuracy: 0.38 | loss: 1.86
update:595/2000, 耗时:0.00分/1.55分 | step: 14280 | performance: 8263.5 | accuracy: 0.38 | loss: 0.21
update:600/2000, 耗时:0.00分/1.56分 | step: 14400 | performance: 20438.5 | accuracy: 0.39 | loss: 0.07
update:605/2000, 耗时:0.00分/1.57分 | step: 14520 | performance: 7033.0 | accuracy: 0.39 | loss: 11.41
update:610/2000, 耗时:0.00分/1.58分 | step: 14640 | performance: 10842.8 | accuracy: 0.39 | loss: 0.36
update:615/2000, 耗时:0.00分/1.60分 | step: 14760 | performance: 29892.0 | accuracy: 0.39 | loss: 3.74
update:620/2000, 耗时:0.00分/1.61分 | step: 14880 | performance: 22985.8 | accuracy: 0.39 | loss: 9.86
update:625/2000, 耗时:0.00分/1.62分 | step: 15000 | performance: 23520.4 | accuracy: 0.39 | loss: 0.66
update:630/2000, 耗时:0.00分/1.64分 | step: 15120 | performance: 25820.6 | accuracy: 0.40 | loss: 1.60
update:635/2000, 耗时:0.00分/1.65分 | step: 15240 | performance: 39242.1 | accuracy: 0.40 | loss: 0.52
update:640/2000, 耗时:0.00分/1.66分 | step: 15360 | performance: 21456.6 | accuracy: 0.40 | loss: 2.33
update:645/2000, 耗时:0.00分/1.67分 | step: 15480 | performance: 20095.4 | accuracy: 0.40 | loss: 0.84
update:650/2000, 耗时:0.00分/1.69分 | step: 15600 | performance: 21125.7 | accuracy: 0.40 | loss: 0.91
update:655/2000, 耗时:0.00分/1.70分 | step: 15720 | performance: 11665.3 | accuracy: 0.40 | loss: 5.89
update:660/2000, 耗时:0.00分/1.71分 | step: 15840 | performance: 2565.2 | accuracy: 0.40 | loss: 2.07
update:665/2000, 耗时:0.00分/1.72分 | step: 15960 | performance: 3239.2 | accuracy: 0.40 | loss: 4.58
update:670/2000, 耗时:0.00分/1.74分 | step: 16080 | performance: 2604.8 | accuracy: 0.40 | loss: 1.79
update:675/2000, 耗时:0.00分/1.75分 | step: 16200 | performance: 2698.6 | accuracy: 0.40 | loss: 0.95
update:680/2000, 耗时:0.00分/1.76分 | step: 16320 | performance: 2041.3 | accuracy: 0.40 | loss: 2.44
update:685/2000, 耗时:0.00分/1.77分 | step: 16440 | performance: 1808.2 | accuracy: 0.39 | loss: 0.57
update:690/2000, 耗时:0.00分/1.78分 | step: 16560 | performance: 1554.6 | accuracy: 0.39 | loss: 0.87
update:695/2000, 耗时:0.00分/1.80分 | step: 16680 | performance: 1493.5 | accuracy: 0.39 | loss: 1.22
update:700/2000, 耗时:0.00分/1.81分 | step: 16800 | performance: 1397.1 | accuracy: 0.39 | loss: 0.82
update:705/2000, 耗时:0.00分/1.82分 | step: 16920 | performance: 777.2 | accuracy: 0.39 | loss: 1.11
update:710/2000, 耗时:0.00分/1.83分 | step: 17040 | performance: 720.8 | accuracy: 0.39 | loss: 2.60
update:715/2000, 耗时:0.00分/1.85分 | step: 17160 | performance: 1483.6 | accuracy: 0.39 | loss: 1.10
update:720/2000, 耗时:0.00分/1.86分 | step: 17280 | performance: 1490.5 | accuracy: 0.39 | loss: 0.48
update:725/2000, 耗时:0.00分/1.87分 | step: 17400 | performance: 2006.7 | accuracy: 0.39 | loss: 0.96
update:730/2000, 耗时:0.00分/1.89分 | step: 17520 | performance: 2057.4 | accuracy: 0.39 | loss: 0.68
update:735/2000, 耗时:0.00分/1.90分 | step: 17640 | performance: 1269.3 | accuracy: 0.39 | loss: 1.06
update:740/2000, 耗时:0.00分/1.91分 | step: 17760 | performance: 1536.6 | accuracy: 0.40 | loss: 0.49
update:745/2000, 耗时:0.00分/1.93分 | step: 17880 | performance: 1251.2 | accuracy: 0.39 | loss: 0.75
update:750/2000, 耗时:0.00分/1.94分 | step: 18000 | performance: 1191.4 | accuracy: 0.39 | loss: 0.60
update:755/2000, 耗时:0.00分/1.95分 | step: 18120 | performance: 1662.3 | accuracy: 0.39 | loss: 1.65
update:760/2000, 耗时:0.00分/1.97分 | step: 18240 | performance: 2896.1 | accuracy: 0.40 | loss: 0.67
update:765/2000, 耗时:0.00分/1.98分 | step: 18360 | performance: 2979.3 | accuracy: 0.40 | loss: 0.44
update:770/2000, 耗时:0.00分/1.99分 | step: 18480 | performance: 3031.4 | accuracy: 0.40 | loss: 1.31
update:775/2000, 耗时:0.00分/2.01分 | step: 18600 | performance: 4602.2 | accuracy: 0.40 | loss: 2.00
update:780/2000, 耗时:0.00分/2.02分 | step: 18720 | performance: 2928.6 | accuracy: 0.40 | loss: 4.00
update:785/2000, 耗时:0.00分/2.03分 | step: 18840 | performance: 2319.6 | accuracy: 0.39 | loss: 0.52
update:790/2000, 耗时:0.00分/2.05分 | step: 18960 | performance: 2208.2 | accuracy: 0.39 | loss: 0.44
update:795/2000, 耗时:0.00分/2.06分 | step: 19080 | performance: 1330.7 | accuracy: 0.39 | loss: 0.64
update:800/2000, 耗时:0.00分/2.07分 | step: 19200 | performance: 1620.4 | accuracy: 0.39 | loss: 1.36
update:805/2000, 耗时:0.00分/2.09分 | step: 19320 | performance: 1459.7 | accuracy: 0.39 | loss: 0.52
update:810/2000, 耗时:0.00分/2.10分 | step: 19440 | performance: 985.3 | accuracy: 0.39 | loss: 0.21
update:815/2000, 耗时:0.00分/2.11分 | step: 19560 | performance: 756.9 | accuracy: 0.39 | loss: 0.10
update:820/2000, 耗时:0.00分/2.13分 | step: 19680 | performance: 800.6 | accuracy: 0.39 | loss: 0.22
update:825/2000, 耗时:0.00分/2.14分 | step: 19800 | performance: 781.8 | accuracy: 0.38 | loss: 0.67
update:830/2000, 耗时:0.00分/2.15分 | step: 19920 | performance: 817.6 | accuracy: 0.38 | loss: 0.16
update:835/2000, 耗时:0.00分/2.17分 | step: 20040 | performance: 966.7 | accuracy: 0.38 | loss: 0.78
update:840/2000, 耗时:0.00分/2.18分 | step: 20160 | performance: 870.7 | accuracy: 0.38 | loss: 1.60
update:845/2000, 耗时:0.00分/2.19分 | step: 20280 | performance: 447.9 | accuracy: 0.38 | loss: 0.18
update:850/2000, 耗时:0.00分/2.21分 | step: 20400 | performance: 381.8 | accuracy: 0.38 | loss: 1.64
update:855/2000, 耗时:0.00分/2.22分 | step: 20520 | performance: 301.3 | accuracy: 0.38 | loss: 1.24
update:860/2000, 耗时:0.00分/2.23分 | step: 20640 | performance: 306.6 | accuracy: 0.38 | loss: 0.56
update:865/2000, 耗时:0.00分/2.24分 | step: 20760 | performance: 369.2 | accuracy: 0.38 | loss: 1.19
update:870/2000, 耗时:0.00分/2.26分 | step: 20880 | performance: 366.3 | accuracy: 0.38 | loss: 2.27
update:875/2000, 耗时:0.00分/2.27分 | step: 21000 | performance: 253.5 | accuracy: 0.38 | loss: 0.96
update:880/2000, 耗时:0.00分/2.28分 | step: 21120 | performance: 235.4 | accuracy: 0.38 | loss: 0.19
update:885/2000, 耗时:0.00分/2.30分 | step: 21240 | performance: 255.1 | accuracy: 0.38 | loss: 0.19
update:890/2000, 耗时:0.00分/2.31分 | step: 21360 | performance: 233.8 | accuracy: 0.37 | loss: 0.32
update:895/2000, 耗时:0.00分/2.32分 | step: 21480 | performance: 215.8 | accuracy: 0.37 | loss: 0.40
update:900/2000, 耗时:0.00分/2.34分 | step: 21600 | performance: 248.0 | accuracy: 0.37 | loss: 0.20
update:905/2000, 耗时:0.00分/2.35分 | step: 21720 | performance: 270.1 | accuracy: 0.37 | loss: 0.49
update:910/2000, 耗时:0.00分/2.36分 | step: 21840 | performance: 279.0 | accuracy: 0.37 | loss: 0.19
update:915/2000, 耗时:0.00分/2.38分 | step: 21960 | performance: 295.9 | accuracy: 0.37 | loss: 0.29
update:920/2000, 耗时:0.00分/2.39分 | step: 22080 | performance: 335.2 | accuracy: 0.37 | loss: 0.54
update:925/2000, 耗时:0.00分/2.40分 | step: 22200 | performance: 325.3 | accuracy: 0.37 | loss: 0.49
update:930/2000, 耗时:0.00分/2.42分 | step: 22320 | performance: 352.3 | accuracy: 0.37 | loss: 1.00
update:935/2000, 耗时:0.00分/2.43分 | step: 22440 | performance: 342.2 | accuracy: 0.36 | loss: 0.15
update:940/2000, 耗时:0.00分/2.44分 | step: 22560 | performance: 380.6 | accuracy: 0.36 | loss: 0.37
update:945/2000, 耗时:0.00分/2.46分 | step: 22680 | performance: 354.5 | accuracy: 0.36 | loss: 0.26
update:950/2000, 耗时:0.00分/2.47分 | step: 22800 | performance: 320.9 | accuracy: 0.36 | loss: 0.08
update:955/2000, 耗时:0.00分/2.48分 | step: 22920 | performance: 265.3 | accuracy: 0.36 | loss: 0.29
update:960/2000, 耗时:0.00分/2.49分 | step: 23040 | performance: 265.3 | accuracy: 0.36 | loss: 0.46
update:965/2000, 耗时:0.00分/2.51分 | step: 23160 | performance: 260.7 | accuracy: 0.35 | loss: 0.01
update:970/2000, 耗时:0.00分/2.52分 | step: 23280 | performance: 260.4 | accuracy: 0.35 | loss: 0.09
update:975/2000, 耗时:0.00分/2.53分 | step: 23400 | performance: 258.4 | accuracy: 0.35 | loss: -0.01
update:980/2000, 耗时:0.00分/2.55分 | step: 23520 | performance: 291.7 | accuracy: 0.35 | loss: 0.19
update:985/2000, 耗时:0.00分/2.56分 | step: 23640 | performance: 290.6 | accuracy: 0.35 | loss: 0.08
update:990/2000, 耗时:0.00分/2.57分 | step: 23760 | performance: 253.2 | accuracy: 0.35 | loss: 0.11
update:995/2000, 耗时:0.00分/2.59分 | step: 23880 | performance: 281.5 | accuracy: 0.35 | loss: 0.09
update:1000/2000, 耗时:0.00分/2.60分 | step: 24000 | performance: 281.5 | accuracy: 0.34 | loss: 0.09
update:1005/2000, 耗时:0.00分/2.61分 | step: 24120 | performance: 284.2 | accuracy: 0.34 | loss: 0.09
update:1010/2000, 耗时:0.00分/2.63分 | step: 24240 | performance: 305.5 | accuracy: 0.34 | loss: 0.00
update:1015/2000, 耗时:0.00分/2.64分 | step: 24360 | performance: 305.5 | accuracy: 0.34 | loss: 0.00
update:1020/2000, 耗时:0.00分/2.65分 | step: 24480 | performance: 307.8 | accuracy: 0.34 | loss: 0.03
update:1025/2000, 耗时:0.00分/2.67分 | step: 24600 | performance: 309.0 | accuracy: 0.34 | loss: 0.47
update:1030/2000, 耗时:0.00分/2.68分 | step: 24720 | performance: 344.4 | accuracy: 0.34 | loss: 0.04
update:1035/2000, 耗时:0.00分/2.69分 | step: 24840 | performance: 344.4 | accuracy: 0.34 | loss: 0.00
update:1040/2000, 耗时:0.00分/2.71分 | step: 24960 | performance: 334.9 | accuracy: 0.33 | loss: 0.02
update:1045/2000, 耗时:0.00分/2.72分 | step: 25080 | performance: 337.4 | accuracy: 0.33 | loss: 0.00
update:1050/2000, 耗时:0.00分/2.73分 | step: 25200 | performance: 337.4 | accuracy: 0.33 | loss: 0.17
update:1055/2000, 耗时:0.00分/2.74分 | step: 25320 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
Saving PPO weights in both H5 format and checkpoint @ update:1055 
step: 25433 | worker_0@n_step_2: average total_reward after train data exhaustion : 100.2 | max total_reward: 167.3
step: 25434 | worker_1@n_step_2: average total_reward after train data exhaustion : 90.2 | max total_reward: 167.3
step: 25436 | worker_3@n_step_2: average total_reward after train data exhaustion : 81.9 | max total_reward: 167.3
step: 25437 | worker_4@n_step_2: average total_reward after train data exhaustion : 74.8 | max total_reward: 167.3
step: 25438 | worker_5@n_step_2: average total_reward after train data exhaustion : 68.8 | max total_reward: 167.3
step: 25439 | worker_6@n_step_2: average total_reward after train data exhaustion : 64.0 | max total_reward: 167.3
update:1060/2000, 耗时:0.00分/2.76分 | step: 25440 | performance: 1.2 | accuracy: 0.12 | loss: 0.02
update:1065/2000, 耗时:0.00分/2.78分 | step: 25560 | performance: 0.9 | accuracy: 0.00 | loss: 0.11
step: 25603 | worker_2@n_step_2: average total_reward after train data exhaustion : 39.0 | max total_reward: 167.3
step: 25608 | worker_7@n_step_2: average total_reward after train data exhaustion : 37.3 | max total_reward: 167.3
update:1070/2000, 耗时:0.00分/2.79分 | step: 25680 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 25771 | worker_2@n_step_2: average total_reward after train data exhaustion : 28.1 | max total_reward: 167.3
update:1075/2000, 耗时:0.00分/2.80分 | step: 25800 | performance: 1.2 | accuracy: 0.14 | loss: 0.14
step: 25841 | worker_0@n_step_2: average total_reward after train data exhaustion : 27.2 | max total_reward: 167.3
step: 25842 | worker_1@n_step_2: average total_reward after train data exhaustion : 26.3 | max total_reward: 167.3
step: 25844 | worker_3@n_step_2: average total_reward after train data exhaustion : 25.5 | max total_reward: 167.3
step: 25845 | worker_4@n_step_2: average total_reward after train data exhaustion : 24.8 | max total_reward: 167.3
step: 25846 | worker_5@n_step_2: average total_reward after train data exhaustion : 24.0 | max total_reward: 167.3
step: 25847 | worker_6@n_step_2: average total_reward after train data exhaustion : 23.4 | max total_reward: 167.3
update:1080/2000, 耗时:0.00分/2.81分 | step: 25920 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 26015 | worker_6@n_step_2: average total_reward after train data exhaustion : 19.8 | max total_reward: 167.3
step: 26016 | worker_7@n_step_2: average total_reward after train data exhaustion : 19.4 | max total_reward: 167.3
update:1085/2000, 耗时:0.00分/2.83分 | step: 26040 | performance: 1.0 | accuracy: 0.00 | loss: 0.21
update:1090/2000, 耗时:0.00分/2.84分 | step: 26160 | performance: 1.0 | accuracy: 0.00 | loss: 0.29
step: 26249 | worker_0@n_step_2: average total_reward after train data exhaustion : 5.0 | max total_reward: 167.3
step: 26252 | worker_3@n_step_2: average total_reward after train data exhaustion : 2.4 | max total_reward: 167.3
step: 26254 | worker_5@n_step_2: average total_reward after train data exhaustion : -0.2 | max total_reward: 167.3
update:1095/2000, 耗时:0.00分/2.85分 | step: 26280 | performance: 1.0 | accuracy: 0.06 | loss: 0.16
step: 26347 | worker_2@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 167.3
step: 26394 | worker_1@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 167.3
step: 26397 | worker_4@n_step_2: average total_reward after train data exhaustion : -0.1 | max total_reward: 167.3
update:1100/2000, 耗时:0.00分/2.87分 | step: 26400 | performance: 1.2 | accuracy: 0.29 | loss: 0.22
update:1105/2000, 耗时:0.00分/2.88分 | step: 26520 | performance: 1.2 | accuracy: 0.17 | loss: 0.06
step: 26615 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 167.3
update:1110/2000, 耗时:0.00分/2.90分 | step: 26640 | performance: 1.2 | accuracy: 0.11 | loss: 0.23
step: 26660 | worker_3@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 167.3
step: 26662 | worker_5@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 167.3
update:1115/2000, 耗时:0.00分/2.91分 | step: 26760 | performance: 1.1 | accuracy: 0.25 | loss: 0.07
step: 26805 | worker_4@n_step_2: average total_reward after train data exhaustion : -0.0 | max total_reward: 167.3
step: 26825 | worker_0@n_step_2: average total_reward after train data exhaustion : 0.0 | max total_reward: 167.3
step: 26830 | worker_5@n_step_2: average total_reward after train data exhaustion : 0.1 | max total_reward: 167.3
update:1120/2000, 耗时:0.00分/2.92分 | step: 26880 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
update:1125/2000, 耗时:0.00分/2.94分 | step: 27000 | performance: 1.2 | accuracy: 0.12 | loss: 0.03
step: 27023 | worker_6@n_step_2: average total_reward after train data exhaustion : 0.1 | max total_reward: 167.3
step: 27068 | worker_3@n_step_2: average total_reward after train data exhaustion : 0.1 | max total_reward: 167.3
update:1130/2000, 耗时:0.00分/2.95分 | step: 27120 | performance: 1.3 | accuracy: 0.27 | loss: 0.24
update:1135/2000, 耗时:0.00分/2.96分 | step: 27240 | performance: 1.3 | accuracy: 0.19 | loss: 0.42
update:1140/2000, 耗时:0.00分/2.98分 | step: 27360 | performance: 1.2 | accuracy: 0.17 | loss: 0.32
update:1145/2000, 耗时:0.00分/2.99分 | step: 27480 | performance: 1.3 | accuracy: 0.16 | loss: 0.27
update:1150/2000, 耗时:0.00分/3.01分 | step: 27600 | performance: 1.3 | accuracy: 0.14 | loss: 0.15
update:1155/2000, 耗时:0.00分/3.02分 | step: 27720 | performance: 1.4 | accuracy: 0.13 | loss: 0.67
update:1160/2000, 耗时:0.00分/3.03分 | step: 27840 | performance: 1.4 | accuracy: 0.15 | loss: 0.38
update:1165/2000, 耗时:0.00分/3.05分 | step: 27960 | performance: 1.6 | accuracy: 0.17 | loss: 0.20
update:1170/2000, 耗时:0.00分/3.06分 | step: 28080 | performance: 1.5 | accuracy: 0.15 | loss: 0.37
update:1175/2000, 耗时:0.00分/3.07分 | step: 28200 | performance: 2.2 | accuracy: 0.16 | loss: 1.38
update:1180/2000, 耗时:0.00分/3.09分 | step: 28320 | performance: 4.4 | accuracy: 0.19 | loss: 1.54
update:1185/2000, 耗时:0.00分/3.10分 | step: 28440 | performance: 4.9 | accuracy: 0.20 | loss: 1.60
update:1190/2000, 耗时:0.00分/3.11分 | step: 28560 | performance: 12.6 | accuracy: 0.25 | loss: 2.40
update:1195/2000, 耗时:0.00分/3.13分 | step: 28680 | performance: 18.1 | accuracy: 0.28 | loss: 2.24
update:1200/2000, 耗时:0.00分/3.14分 | step: 28800 | performance: 7.5 | accuracy: 0.27 | loss: 2.21
update:1205/2000, 耗时:0.00分/3.16分 | step: 28920 | performance: 11.8 | accuracy: 0.29 | loss: 1.95
update:1210/2000, 耗时:0.00分/3.17分 | step: 29040 | performance: 9.1 | accuracy: 0.28 | loss: 1.94
update:1215/2000, 耗时:0.00分/3.18分 | step: 29160 | performance: 14.7 | accuracy: 0.30 | loss: 1.99
update:1220/2000, 耗时:0.00分/3.20分 | step: 29280 | performance: 15.0 | accuracy: 0.31 | loss: 2.00
update:1225/2000, 耗时:0.00分/3.21分 | step: 29400 | performance: 19.0 | accuracy: 0.32 | loss: 1.40
update:1230/2000, 耗时:0.00分/3.23分 | step: 29520 | performance: 19.4 | accuracy: 0.33 | loss: 1.36
update:1235/2000, 耗时:0.00分/3.24分 | step: 29640 | performance: 14.1 | accuracy: 0.33 | loss: 1.06
update:1240/2000, 耗时:0.00分/3.25分 | step: 29760 | performance: 9.6 | accuracy: 0.32 | loss: 1.88
update:1245/2000, 耗时:0.00分/3.27分 | step: 29880 | performance: 11.9 | accuracy: 0.33 | loss: 1.59
update:1250/2000, 耗时:0.00分/3.28分 | step: 30000 | performance: 10.9 | accuracy: 0.33 | loss: 1.69
update:1255/2000, 耗时:0.00分/3.29分 | step: 30120 | performance: 10.3 | accuracy: 0.33 | loss: 1.71
update:1260/2000, 耗时:0.00分/3.31分 | step: 30240 | performance: 9.9 | accuracy: 0.32 | loss: 0.82
update:1265/2000, 耗时:0.00分/3.32分 | step: 30360 | performance: 9.3 | accuracy: 0.32 | loss: 0.60
update:1270/2000, 耗时:0.00分/3.34分 | step: 30480 | performance: 4.4 | accuracy: 0.31 | loss: 1.50
update:1275/2000, 耗时:0.00分/3.35分 | step: 30600 | performance: 3.8 | accuracy: 0.30 | loss: 1.50
update:1280/2000, 耗时:0.00分/3.36分 | step: 30720 | performance: 3.8 | accuracy: 0.31 | loss: 1.58
update:1285/2000, 耗时:0.00分/3.38分 | step: 30840 | performance: 3.9 | accuracy: 0.30 | loss: 0.65
update:1290/2000, 耗时:0.00分/3.39分 | step: 30960 | performance: 3.7 | accuracy: 0.30 | loss: 1.02
update:1295/2000, 耗时:0.00分/3.40分 | step: 31080 | performance: 6.3 | accuracy: 0.31 | loss: 1.92
update:1300/2000, 耗时:0.00分/3.42分 | step: 31200 | performance: 5.3 | accuracy: 0.31 | loss: 1.96
update:1305/2000, 耗时:0.00分/3.43分 | step: 31320 | performance: 9.3 | accuracy: 0.32 | loss: 1.84
update:1310/2000, 耗时:0.00分/3.44分 | step: 31440 | performance: 5.5 | accuracy: 0.32 | loss: 1.61
update:1315/2000, 耗时:0.00分/3.45分 | step: 31560 | performance: 6.9 | accuracy: 0.33 | loss: 2.50
update:1320/2000, 耗时:0.00分/3.47分 | step: 31680 | performance: 16.6 | accuracy: 0.34 | loss: 3.66
update:1325/2000, 耗时:0.00分/3.48分 | step: 31800 | performance: 45.4 | accuracy: 0.35 | loss: 2.19
update:1330/2000, 耗时:0.00分/3.49分 | step: 31920 | performance: 31.9 | accuracy: 0.35 | loss: 3.10
update:1335/2000, 耗时:0.00分/3.51分 | step: 32040 | performance: 26.1 | accuracy: 0.35 | loss: 3.08
update:1340/2000, 耗时:0.00分/3.52分 | step: 32160 | performance: 19.1 | accuracy: 0.35 | loss: 1.69
update:1345/2000, 耗时:0.00分/3.53分 | step: 32280 | performance: 11.2 | accuracy: 0.34 | loss: 2.19
update:1350/2000, 耗时:0.00分/3.55分 | step: 32400 | performance: 32.6 | accuracy: 0.36 | loss: 2.35
update:1355/2000, 耗时:0.00分/3.56分 | step: 32520 | performance: 27.9 | accuracy: 0.36 | loss: 2.73
update:1360/2000, 耗时:0.00分/3.57分 | step: 32640 | performance: 19.7 | accuracy: 0.36 | loss: 2.56
update:1365/2000, 耗时:0.00分/3.58分 | step: 32760 | performance: 16.9 | accuracy: 0.36 | loss: 2.08
update:1370/2000, 耗时:0.00分/3.60分 | step: 32880 | performance: 27.0 | accuracy: 0.37 | loss: 1.76
update:1375/2000, 耗时:0.00分/3.61分 | step: 33000 | performance: 22.8 | accuracy: 0.36 | loss: 1.80
update:1380/2000, 耗时:0.00分/3.62分 | step: 33120 | performance: 21.7 | accuracy: 0.36 | loss: 1.21
update:1385/2000, 耗时:0.00分/3.64分 | step: 33240 | performance: 15.0 | accuracy: 0.36 | loss: 1.41
update:1390/2000, 耗时:0.00分/3.65分 | step: 33360 | performance: 14.3 | accuracy: 0.36 | loss: 1.35
update:1395/2000, 耗时:0.00分/3.66分 | step: 33480 | performance: 16.1 | accuracy: 0.36 | loss: 1.18
update:1400/2000, 耗时:0.00分/3.68分 | step: 33600 | performance: 13.5 | accuracy: 0.36 | loss: 0.92
update:1405/2000, 耗时:0.00分/3.69分 | step: 33720 | performance: 12.2 | accuracy: 0.35 | loss: 0.99
update:1410/2000, 耗时:0.00分/3.70分 | step: 33840 | performance: 10.2 | accuracy: 0.35 | loss: 1.07
update:1415/2000, 耗时:0.00分/3.71分 | step: 33960 | performance: 8.8 | accuracy: 0.35 | loss: 1.04
update:1420/2000, 耗时:0.00分/3.73分 | step: 34080 | performance: 9.0 | accuracy: 0.35 | loss: 0.91
update:1425/2000, 耗时:0.00分/3.74分 | step: 34200 | performance: 12.3 | accuracy: 0.35 | loss: 1.40
update:1430/2000, 耗时:0.00分/3.75分 | step: 34320 | performance: 10.9 | accuracy: 0.35 | loss: 1.31
update:1435/2000, 耗时:0.00分/3.77分 | step: 34440 | performance: 10.2 | accuracy: 0.35 | loss: 0.68
update:1440/2000, 耗时:0.00分/3.78分 | step: 34560 | performance: 10.9 | accuracy: 0.35 | loss: 0.87
update:1445/2000, 耗时:0.00分/3.79分 | step: 34680 | performance: 10.2 | accuracy: 0.35 | loss: 1.09
update:1450/2000, 耗时:0.00分/3.80分 | step: 34800 | performance: 10.4 | accuracy: 0.35 | loss: 1.02
update:1455/2000, 耗时:0.00分/3.82分 | step: 34920 | performance: 11.0 | accuracy: 0.34 | loss: 0.85
update:1460/2000, 耗时:0.00分/3.83分 | step: 35040 | performance: 9.4 | accuracy: 0.34 | loss: 0.62
update:1465/2000, 耗时:0.00分/3.84分 | step: 35160 | performance: 10.6 | accuracy: 0.34 | loss: 1.20
update:1470/2000, 耗时:0.00分/3.85分 | step: 35280 | performance: 11.0 | accuracy: 0.34 | loss: 0.89
update:1475/2000, 耗时:0.00分/3.87分 | step: 35400 | performance: 10.3 | accuracy: 0.34 | loss: 1.23
update:1480/2000, 耗时:0.00分/3.88分 | step: 35520 | performance: 11.6 | accuracy: 0.34 | loss: 1.14
update:1485/2000, 耗时:0.00分/3.89分 | step: 35640 | performance: 11.0 | accuracy: 0.34 | loss: 0.82
update:1490/2000, 耗时:0.00分/3.90分 | step: 35760 | performance: 14.7 | accuracy: 0.34 | loss: 1.38
update:1495/2000, 耗时:0.00分/3.92分 | step: 35880 | performance: 18.6 | accuracy: 0.34 | loss: 0.75
update:1500/2000, 耗时:0.00分/3.93分 | step: 36000 | performance: 26.3 | accuracy: 0.34 | loss: 0.68
update:1505/2000, 耗时:0.00分/3.94分 | step: 36120 | performance: 18.0 | accuracy: 0.34 | loss: 0.75
update:1510/2000, 耗时:0.00分/3.95分 | step: 36240 | performance: 20.6 | accuracy: 0.34 | loss: 0.50
update:1515/2000, 耗时:0.00分/3.97分 | step: 36360 | performance: 12.3 | accuracy: 0.34 | loss: 1.31
update:1520/2000, 耗时:0.00分/3.98分 | step: 36480 | performance: 13.4 | accuracy: 0.34 | loss: 0.40
update:1525/2000, 耗时:0.00分/3.99分 | step: 36600 | performance: 16.5 | accuracy: 0.34 | loss: 1.07
update:1530/2000, 耗时:0.00分/4.01分 | step: 36720 | performance: 25.1 | accuracy: 0.34 | loss: 0.63
update:1535/2000, 耗时:0.00分/4.02分 | step: 36840 | performance: 32.8 | accuracy: 0.34 | loss: 1.09
update:1540/2000, 耗时:0.00分/4.03分 | step: 36960 | performance: 32.5 | accuracy: 0.34 | loss: 0.69
update:1545/2000, 耗时:0.00分/4.04分 | step: 37080 | performance: 35.9 | accuracy: 0.34 | loss: 1.23
update:1550/2000, 耗时:0.00分/4.06分 | step: 37200 | performance: 35.8 | accuracy: 0.34 | loss: 1.21
update:1555/2000, 耗时:0.00分/4.07分 | step: 37320 | performance: 33.9 | accuracy: 0.34 | loss: 0.82
update:1560/2000, 耗时:0.00分/4.08分 | step: 37440 | performance: 33.9 | accuracy: 0.34 | loss: 0.72
update:1565/2000, 耗时:0.00分/4.10分 | step: 37560 | performance: 33.9 | accuracy: 0.34 | loss: 0.55
update:1570/2000, 耗时:0.00分/4.11分 | step: 37680 | performance: 33.1 | accuracy: 0.34 | loss: 0.54
update:1575/2000, 耗时:0.00分/4.12分 | step: 37800 | performance: 30.5 | accuracy: 0.34 | loss: 0.51
update:1580/2000, 耗时:0.00分/4.13分 | step: 37920 | performance: 27.9 | accuracy: 0.34 | loss: 0.37
update:1585/2000, 耗时:0.00分/4.15分 | step: 38040 | performance: 27.8 | accuracy: 0.34 | loss: 1.24
update:1590/2000, 耗时:0.00分/4.16分 | step: 38160 | performance: 49.9 | accuracy: 0.34 | loss: 0.84
update:1595/2000, 耗时:0.00分/4.17分 | step: 38280 | performance: 50.7 | accuracy: 0.34 | loss: 0.45
update:1600/2000, 耗时:0.00分/4.18分 | step: 38400 | performance: 51.9 | accuracy: 0.34 | loss: 1.18
update:1605/2000, 耗时:0.00分/4.20分 | step: 38520 | performance: 47.7 | accuracy: 0.34 | loss: 0.87
update:1610/2000, 耗时:0.00分/4.21分 | step: 38640 | performance: 41.6 | accuracy: 0.34 | loss: 1.45
update:1615/2000, 耗时:0.00分/4.22分 | step: 38760 | performance: 22.1 | accuracy: 0.34 | loss: 1.79
update:1620/2000, 耗时:0.00分/4.24分 | step: 38880 | performance: 21.6 | accuracy: 0.34 | loss: 0.65
update:1625/2000, 耗时:0.00分/4.25分 | step: 39000 | performance: 25.5 | accuracy: 0.34 | loss: 1.41
update:1630/2000, 耗时:0.00分/4.26分 | step: 39120 | performance: 24.3 | accuracy: 0.34 | loss: 1.18
update:1635/2000, 耗时:0.00分/4.27分 | step: 39240 | performance: 22.4 | accuracy: 0.34 | loss: 1.21
update:1640/2000, 耗时:0.00分/4.29分 | step: 39360 | performance: 31.7 | accuracy: 0.35 | loss: 1.77
update:1645/2000, 耗时:0.00分/4.30分 | step: 39480 | performance: 48.0 | accuracy: 0.35 | loss: 1.47
update:1650/2000, 耗时:0.00分/4.31分 | step: 39600 | performance: 79.9 | accuracy: 0.36 | loss: 0.80
update:1655/2000, 耗时:0.00分/4.32分 | step: 39720 | performance: 123.7 | accuracy: 0.36 | loss: 1.46
update:1660/2000, 耗时:0.00分/4.34分 | step: 39840 | performance: 208.3 | accuracy: 0.36 | loss: 1.55
update:1665/2000, 耗时:0.00分/4.35分 | step: 39960 | performance: 438.9 | accuracy: 0.37 | loss: 1.67
update:1670/2000, 耗时:0.00分/4.36分 | step: 40080 | performance: 312.4 | accuracy: 0.37 | loss: 2.20
update:1675/2000, 耗时:0.00分/4.37分 | step: 40200 | performance: 569.0 | accuracy: 0.37 | loss: 2.40
update:1680/2000, 耗时:0.00分/4.39分 | step: 40320 | performance: 485.1 | accuracy: 0.37 | loss: 2.74
update:1685/2000, 耗时:0.00分/4.40分 | step: 40440 | performance: 1837.7 | accuracy: 0.38 | loss: 1.92
update:1690/2000, 耗时:0.00分/4.41分 | step: 40560 | performance: 3996.5 | accuracy: 0.38 | loss: 2.43
update:1695/2000, 耗时:0.00分/4.43分 | step: 40680 | performance: 12945.0 | accuracy: 0.38 | loss: 2.69
update:1700/2000, 耗时:0.00分/4.44分 | step: 40800 | performance: 24381.0 | accuracy: 0.39 | loss: 4.67
update:1705/2000, 耗时:0.00分/4.45分 | step: 40920 | performance: 24237.6 | accuracy: 0.39 | loss: 3.03
update:1710/2000, 耗时:0.00分/4.47分 | step: 41040 | performance: 11136.9 | accuracy: 0.39 | loss: 2.21
update:1715/2000, 耗时:0.00分/4.48分 | step: 41160 | performance: 22263.1 | accuracy: 0.39 | loss: 2.71
update:1720/2000, 耗时:0.00分/4.49分 | step: 41280 | performance: 104612.4 | accuracy: 0.39 | loss: 2.30
update:1725/2000, 耗时:0.00分/4.51分 | step: 41400 | performance: 190335.7 | accuracy: 0.40 | loss: 3.85
update:1730/2000, 耗时:0.00分/4.52分 | step: 41520 | performance: 130113.2 | accuracy: 0.40 | loss: 2.76
update:1735/2000, 耗时:0.00分/4.53分 | step: 41640 | performance: 134918.0 | accuracy: 0.40 | loss: 1.88
update:1740/2000, 耗时:0.00分/4.55分 | step: 41760 | performance: 382005.4 | accuracy: 0.40 | loss: 3.07
update:1745/2000, 耗时:0.00分/4.56分 | step: 41880 | performance: 372955.3 | accuracy: 0.40 | loss: 2.19
update:1750/2000, 耗时:0.00分/4.57分 | step: 42000 | performance: 264252.6 | accuracy: 0.40 | loss: 2.71
update:1755/2000, 耗时:0.00分/4.58分 | step: 42120 | performance: 364301.0 | accuracy: 0.41 | loss: 2.13
update:1760/2000, 耗时:0.00分/4.60分 | step: 42240 | performance: 437673.2 | accuracy: 0.41 | loss: 2.57
update:1765/2000, 耗时:0.00分/4.61分 | step: 42360 | performance: 326288.4 | accuracy: 0.41 | loss: 3.06
update:1770/2000, 耗时:0.00分/4.62分 | step: 42480 | performance: 213635.7 | accuracy: 0.41 | loss: 2.18
update:1775/2000, 耗时:0.00分/4.63分 | step: 42600 | performance: 277792.9 | accuracy: 0.41 | loss: 2.34
update:1780/2000, 耗时:0.00分/4.65分 | step: 42720 | performance: 272495.0 | accuracy: 0.41 | loss: 2.38
update:1785/2000, 耗时:0.00分/4.66分 | step: 42840 | performance: 45844.6 | accuracy: 0.41 | loss: 2.96
update:1790/2000, 耗时:0.00分/4.67分 | step: 42960 | performance: 34271.1 | accuracy: 0.41 | loss: 2.18
update:1795/2000, 耗时:0.00分/4.69分 | step: 43080 | performance: 39228.0 | accuracy: 0.41 | loss: 0.87
update:1800/2000, 耗时:0.00分/4.70分 | step: 43200 | performance: 34761.6 | accuracy: 0.41 | loss: 1.47
update:1805/2000, 耗时:0.00分/4.71分 | step: 43320 | performance: 38586.6 | accuracy: 0.41 | loss: 1.03
update:1810/2000, 耗时:0.00分/4.72分 | step: 43440 | performance: 34470.6 | accuracy: 0.41 | loss: 0.77
update:1815/2000, 耗时:0.00分/4.74分 | step: 43560 | performance: 34218.8 | accuracy: 0.41 | loss: 0.58
update:1820/2000, 耗时:0.00分/4.75分 | step: 43680 | performance: 35757.9 | accuracy: 0.40 | loss: 0.62
update:1825/2000, 耗时:0.00分/4.76分 | step: 43800 | performance: 34039.3 | accuracy: 0.40 | loss: 1.58
update:1830/2000, 耗时:0.00分/4.78分 | step: 43920 | performance: 55166.4 | accuracy: 0.40 | loss: 1.03
update:1835/2000, 耗时:0.00分/4.79分 | step: 44040 | performance: 78752.7 | accuracy: 0.40 | loss: 1.76
update:1840/2000, 耗时:0.00分/4.80分 | step: 44160 | performance: 142134.6 | accuracy: 0.41 | loss: 1.00
update:1845/2000, 耗时:0.00分/4.81分 | step: 44280 | performance: 143599.0 | accuracy: 0.41 | loss: 1.28
update:1850/2000, 耗时:0.00分/4.83分 | step: 44400 | performance: 154945.2 | accuracy: 0.41 | loss: 0.79
update:1855/2000, 耗时:0.00分/4.84分 | step: 44520 | performance: 127491.0 | accuracy: 0.41 | loss: 0.72
update:1860/2000, 耗时:0.00分/4.85分 | step: 44640 | performance: 77310.1 | accuracy: 0.40 | loss: 1.63
update:1865/2000, 耗时:0.00分/4.87分 | step: 44760 | performance: 70360.1 | accuracy: 0.40 | loss: 1.79
update:1870/2000, 耗时:0.00分/4.88分 | step: 44880 | performance: 59432.4 | accuracy: 0.40 | loss: 1.10
update:1875/2000, 耗时:0.00分/4.89分 | step: 45000 | performance: 66305.5 | accuracy: 0.40 | loss: 1.31
update:1880/2000, 耗时:0.00分/4.91分 | step: 45120 | performance: 142113.2 | accuracy: 0.40 | loss: 2.15
update:1885/2000, 耗时:0.00分/4.92分 | step: 45240 | performance: 191683.7 | accuracy: 0.41 | loss: 1.34
update:1890/2000, 耗时:0.00分/4.93分 | step: 45360 | performance: 208915.0 | accuracy: 0.41 | loss: 2.63
update:1895/2000, 耗时:0.00分/4.94分 | step: 45480 | performance: 223184.6 | accuracy: 0.41 | loss: 1.68
update:1900/2000, 耗时:0.00分/4.95分 | step: 45600 | performance: 256884.1 | accuracy: 0.41 | loss: 2.38
update:1905/2000, 耗时:0.00分/4.97分 | step: 45720 | performance: 297165.5 | accuracy: 0.41 | loss: 1.09
update:1910/2000, 耗时:0.00分/4.98分 | step: 45840 | performance: 151921.7 | accuracy: 0.41 | loss: 1.45
update:1915/2000, 耗时:0.00分/4.99分 | step: 45960 | performance: 138726.6 | accuracy: 0.41 | loss: 1.33
update:1920/2000, 耗时:0.00分/5.00分 | step: 46080 | performance: 77274.7 | accuracy: 0.41 | loss: 1.17
update:1925/2000, 耗时:0.00分/5.02分 | step: 46200 | performance: 63565.5 | accuracy: 0.41 | loss: 0.52
update:1930/2000, 耗时:0.00分/5.03分 | step: 46320 | performance: 75993.7 | accuracy: 0.41 | loss: 0.95
update:1935/2000, 耗时:0.00分/5.04分 | step: 46440 | performance: 81716.9 | accuracy: 0.41 | loss: 0.60
update:1940/2000, 耗时:0.00分/5.05分 | step: 46560 | performance: 50155.7 | accuracy: 0.41 | loss: 1.45
update:1945/2000, 耗时:0.00分/5.07分 | step: 46680 | performance: 41901.0 | accuracy: 0.40 | loss: 0.81
update:1950/2000, 耗时:0.00分/5.08分 | step: 46800 | performance: 31495.4 | accuracy: 0.40 | loss: 1.31
update:1955/2000, 耗时:0.00分/5.09分 | step: 46920 | performance: 46218.3 | accuracy: 0.40 | loss: 0.88
update:1960/2000, 耗时:0.00分/5.10分 | step: 47040 | performance: 73655.0 | accuracy: 0.41 | loss: 1.95
update:1965/2000, 耗时:0.00分/5.11分 | step: 47160 | performance: 87090.6 | accuracy: 0.41 | loss: 1.17
update:1970/2000, 耗时:0.00分/5.13分 | step: 47280 | performance: 75209.6 | accuracy: 0.40 | loss: 0.80
update:1975/2000, 耗时:0.00分/5.14分 | step: 47400 | performance: 85069.0 | accuracy: 0.41 | loss: 0.75
update:1980/2000, 耗时:0.00分/5.15分 | step: 47520 | performance: 59429.4 | accuracy: 0.40 | loss: 1.60
update:1985/2000, 耗时:0.00分/5.17分 | step: 47640 | performance: 60895.4 | accuracy: 0.40 | loss: 1.08
update:1990/2000, 耗时:0.00分/5.18分 | step: 47760 | performance: 84015.3 | accuracy: 0.41 | loss: 1.17
update:1995/2000, 耗时:0.00分/5.19分 | step: 47880 | performance: 145759.1 | accuracy: 0.41 | loss: 0.80
  0%|          | 0/397 [00:00<?, ?it/s]100%|| 397/397 [00:00<00:00, 99429.07it/s]
update:2000/2000, 耗时:0.00分/5.21分 | step: 48000 | performance: 132493.5 | accuracy: 0.41 | loss: 1.62
----------------------------------------finished----------------------------------------
==================================================
2023-01-07T12:00:00 | *** START BACKTEST ***
2023-01-07T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1066.23
2023-07-24T12:00:00 | net performance [%] = 6.6228
2023-07-24T12:00:00 | number of trades [#] = 116
==================================================
Trial 46 Complete [00h 05m 39s]
net_wealth: 1066.2278042698372

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 06h 13m 22s

Search: Running Trial #47

Value             |Best Value So Far |Hyperparameter
1                 |7                 |horizon
225               |730               |lookback
True              |False             |MarketFactor
20                |14                |lags
0.5               |0.7               |gamma
16                |32                |batch_size
1                 |32                |n_step
0.96              |0.92              |gae_lambda
0.2               |0.1               |gradient_clip_norm
5                 |5                 |epochs
0.0005            |0.0001            |actor_lr
0.0001            |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4300.000000   4301.000000
mean      0.000435    20113.607657  ...   20173.020481  20169.373185
std       0.027833    16040.642334  ...   16078.674434  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7736.967529   7730.930176
50%       0.000642    11571.842969  ...   11753.029785  11751.469727
75%       0.011590    29894.706152  ...   30013.548340  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
202023-07-28223-023-070 7--228 0804:16:4 40:45:.161:455.202356-2752075:21607-2:3 24-0I825: I 7t-28 0 25e.nsor54flo 0wt/c7e0no:42:s163re-521/po017::r- If428 0l5o.la5 wtetnfor7m/s5o26co/4:r cprufe_fleowI/ /platfortcensm16oroare/ptufrelola_tg:uafo/4rcdrpmu/4.ccpuc5__:.1425ff7]52eeat8a 3utThuries2r:0 I_  Tteegeunn2asorsFlr3do.rcf_:gc:2w-l01o4uw/caoro71-22r0/263:d-wc0]78 .T h-io4rc5s.e/5 c :1745pe0T43el4/5:na2tfs8:p1l6batoorm2/c fionap]rF lou0_ few: rmrIyb i/4 ateTnshc4piui5st. :o_rfunarfy 5r7es5 e1_op6tTi:alims4 t5owg./5o8putre6i:zedu a5c or7I _er/dp.ltaeigmuincsoztacrd.eccd:e 5rflow:in1wt6h fows/oo3ri8trhm/n4c p:FeAu_2f]coolow  biP Inee14naIry TA2PI art] DTeee/ piusr  his poDpteiempeht_glTen N iNiszoeeesn TeruurausrnesoFroarafrdFll lNd oa.teltl fwocrm/cNiotwwoowrh k ewtbpL ibr co:une_wf/iAo1rePncabrikI 4oLniabrr raya yaerDy 2 rei(itsuryso]nee (/  _Tep NgeuoaDnNeND)uNoh itsrpa tipo lTmizerdodple .ucc tnNseatsitowfoeo r:Nm)i t rrtmFolkwzieothh/dw  b i eLwo f1niibnoe AraalrPurs4y2yc Ipe] i(  Dtehoen sf ooe llpuleoDTNot_wNw)t pfhh ios NeiurtniemAnioa g TeenPlnsoIrFuis  lCowze ea PUt iu thge Dbeie rnds twrNiutfCoePcntleh_ oUptnwoe  airAgNeuurrall NaPkrinsteIonos rduc.t cLii tiyoDweberpwc inogr kn:i sN a nrps 1ye 4(ro2LeCfPoUr muiranaln]o c eN-ceitewnornDpNtNsriiitm t Tkihzibcr ueirpsera clTda ry)fote (o  wiioneDtNoN)Li buranotsern sprym (t etro asheootranh  fioolnu soesi:ncnlnF ep-coriwi  etrntgh  feeeA ClPooIiAwfocDV NDN aPXUlrlmaonwi  bngAicle) VCX2i
Ton Pen Uoap ertro ya- i utenstsreusepn abi octinons:t s cAlhee  foV Xlril Aowiinngs p i oteptChtrifcrVeXNtaelP oumc tpi2o
Uiounrsie amlrin  rNeatoti mwToor ki onLnss:iitahnecbtrraen   pure -ceArnfzrriVXa AocetbiloeytViXc2al
 oo  tTpohrnmsa  nedin(cpeeer-atemo nine Don carbwal epiiNr ttheteiirfrorotNi ) nhsc,otmo nral eompse:ot hb pa eirauesue itntrniao nAVhtcslXd A io o Vtehneo:T eensrX oop-r en2 FrlaoswtAf,
 Troc VreiteicAan PebuioIl walbloopwerilling eCi o PDU dn iTntshtat htheeetnr uacpsporsomi orns:i , re eAppne obutihF tViXerNio XA Arn VleoVaXotspuX2l
ed  Tc 2r
aTolowin epe Tmop rnes reN nawialteeoiitohbrl eftreFnlo wfwa bolnr lagsskteh o,r mw e.Lretbhueimii t
ltaabncrhdh ea t he-rTiemne anp prothoe pinpr yso p(oneproDcNN)ioar ittoi turstFrree  th eichocpelea lf ooatolwl owroewpireartiat iomciomop onpienlnpsr:s,ialeerr f f lrtt i gh  CPoAaVthlUnsXea g,s .r AVX2ebbugi
nstructions in performance-critical operations:  AVX uild TensorFlow with the appropriasAVX2
To enable them in other operationse appropriate compiler ft, ree.b
uild
 c iTld TeolTmopiler f neeasonrFllonawags.
ble sorFl twhiotemgs.
w h the appropriate co with the appropriimnate compiler flags.
piler flags.
 other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 04:16:46.192373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:16:46.193036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:16:46.198262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:16:46.208569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:16:46.218502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:16:46.251679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:16:46.254512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:16:46.272685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:    40 | performance: 1.0 | accuracy: 0.60 | loss: 0.77
update: 10/2000, 耗时:0.00分/0.04分 | step:    80 | performance: 1.1 | accuracy: 0.50 | loss: 0.62
update: 15/2000, 耗时:0.00分/0.05分 | step:   120 | performance: 1.1 | accuracy: 0.47 | loss: 0.42
update: 20/2000, 耗时:0.00分/0.06分 | step:   160 | performance: 1.1 | accuracy: 0.40 | loss: 0.18
update: 25/2000, 耗时:0.00分/0.07分 | step:   200 | performance: 1.1 | accuracy: 0.44 | loss: 0.41
update: 30/2000, 耗时:0.00分/0.08分 | step:   240 | performance: 1.3 | accuracy: 0.43 | loss: 0.51
update: 35/2000, 耗时:0.00分/0.09分 | step:   280 | performance: 1.5 | accuracy: 0.49 | loss: 0.90
update: 40/2000, 耗时:0.00分/0.10分 | step:   320 | performance: 1.3 | accuracy: 0.45 | loss: 0.45
update: 45/2000, 耗时:0.00分/0.11分 | step:   360 | performance: 1.3 | accuracy: 0.42 | loss: 0.50
update: 50/2000, 耗时:0.00分/0.13分 | step:   400 | performance: 1.3 | accuracy: 0.38 | loss: 0.89
update: 55/2000, 耗时:0.00分/0.14分 | step:   440 | performance: 1.3 | accuracy: 0.36 | loss: 0.03
update: 60/2000, 耗时:0.00分/0.15分 | step:   480 | performance: 1.4 | accuracy: 0.37 | loss: 0.32
update: 65/2000, 耗时:0.00分/0.16分 | step:   520 | performance: 1.2 | accuracy: 0.35 | loss: 0.38
update: 70/2000, 耗时:0.00分/0.17分 | step:   560 | performance: 1.3 | accuracy: 0.34 | loss: 0.28
update: 75/2000, 耗时:0.00分/0.18分 | step:   600 | performance: 1.2 | accuracy: 0.33 | loss: 0.41
update: 80/2000, 耗时:0.00分/0.19分 | step:   640 | performance: 1.2 | accuracy: 0.33 | loss: 0.10
update: 85/2000, 耗时:0.00分/0.20分 | step:   680 | performance: 1.3 | accuracy: 0.34 | loss: 0.50
update: 90/2000, 耗时:0.00分/0.21分 | step:   720 | performance: 1.3 | accuracy: 0.34 | loss: 0.37
update: 95/2000, 耗时:0.00分/0.23分 | step:   760 | performance: 1.4 | accuracy: 0.37 | loss: 1.14
update:100/2000, 耗时:0.00分/0.24分 | step:   800 | performance: 1.3 | accuracy: 0.35 | loss: 0.40
update:105/2000, 耗时:0.00分/0.25分 | step:   840 | performance: 1.4 | accuracy: 0.36 | loss: 0.45
update:110/2000, 耗时:0.00分/0.26分 | step:   880 | performance: 1.4 | accuracy: 0.37 | loss: 0.40
update:115/2000, 耗时:0.00分/0.27分 | step:   920 | performance: 1.5 | accuracy: 0.38 | loss: 0.25
update:120/2000, 耗时:0.00分/0.28分 | step:   960 | performance: 1.5 | accuracy: 0.38 | loss: 0.18
update:125/2000, 耗时:0.00分/0.29分 | step:  1000 | performance: 1.5 | accuracy: 0.38 | loss: 0.23
update:130/2000, 耗时:0.00分/0.30分 | step:  1040 | performance: 1.5 | accuracy: 0.37 | loss: 0.10
update:135/2000, 耗时:0.00分/0.32分 | step:  1080 | performance: 1.6 | accuracy: 0.36 | loss: 0.17
update:140/2000, 耗时:0.00分/0.33分 | step:  1120 | performance: 1.7 | accuracy: 0.37 | loss: 0.35
update:145/2000, 耗时:0.00分/0.34分 | step:  1160 | performance: 1.7 | accuracy: 0.37 | loss: 0.36
update:150/2000, 耗时:0.00分/0.35分 | step:  1200 | performance: 1.6 | accuracy: 0.37 | loss: 0.34
update:155/2000, 耗时:0.00分/0.36分 | step:  1240 | performance: 1.5 | accuracy: 0.36 | loss: 0.22
update:160/2000, 耗时:0.00分/0.37分 | step:  1280 | performance: 1.6 | accuracy: 0.36 | loss: 0.19
update:165/2000, 耗时:0.00分/0.38分 | step:  1320 | performance: 1.6 | accuracy: 0.35 | loss: 0.21
update:170/2000, 耗时:0.00分/0.39分 | step:  1360 | performance: 1.6 | accuracy: 0.35 | loss: 0.53
update:175/2000, 耗时:0.00分/0.41分 | step:  1400 | performance: 1.7 | accuracy: 0.35 | loss: 0.11
update:180/2000, 耗时:0.00分/0.42分 | step:  1440 | performance: 1.9 | accuracy: 0.36 | loss: 0.38
update:185/2000, 耗时:0.00分/0.43分 | step:  1480 | performance: 1.9 | accuracy: 0.37 | loss: 0.22
update:190/2000, 耗时:0.00分/0.44分 | step:  1520 | performance: 1.9 | accuracy: 0.37 | loss: 0.99
update:195/2000, 耗时:0.00分/0.45分 | step:  1560 | performance: 1.8 | accuracy: 0.37 | loss: 0.07
update:200/2000, 耗时:0.00分/0.46分 | step:  1600 | performance: 2.0 | accuracy: 0.37 | loss: 0.32
update:205/2000, 耗时:0.00分/0.47分 | step:  1640 | performance: 2.1 | accuracy: 0.38 | loss: 0.09
update:210/2000, 耗时:0.00分/0.48分 | step:  1680 | performance: 2.0 | accuracy: 0.37 | loss: 0.14
update:215/2000, 耗时:0.00分/0.49分 | step:  1720 | performance: 2.1 | accuracy: 0.37 | loss: 1.06
update:220/2000, 耗时:0.00分/0.51分 | step:  1760 | performance: 2.0 | accuracy: 0.36 | loss: 0.10
update:225/2000, 耗时:0.00分/0.52分 | step:  1800 | performance: 1.9 | accuracy: 0.36 | loss: 0.09
update:230/2000, 耗时:0.00分/0.53分 | step:  1840 | performance: 2.0 | accuracy: 0.37 | loss: 0.31
update:235/2000, 耗时:0.00分/0.54分 | step:  1880 | performance: 2.0 | accuracy: 0.37 | loss: 0.24
update:240/2000, 耗时:0.00分/0.55分 | step:  1920 | performance: 2.0 | accuracy: 0.37 | loss: 0.64
update:245/2000, 耗时:0.00分/0.56分 | step:  1960 | performance: 2.0 | accuracy: 0.36 | loss: -0.03
update:250/2000, 耗时:0.00分/0.57分 | step:  2000 | performance: 2.1 | accuracy: 0.36 | loss: 0.11
update:255/2000, 耗时:0.00分/0.58分 | step:  2040 | performance: 2.1 | accuracy: 0.36 | loss: 0.21
update:260/2000, 耗时:0.00分/0.59分 | step:  2080 | performance: 2.1 | accuracy: 0.35 | loss: 0.33
update:265/2000, 耗时:0.00分/0.61分 | step:  2120 | performance: 2.1 | accuracy: 0.35 | loss: 0.03
update:270/2000, 耗时:0.00分/0.62分 | step:  2160 | performance: 2.1 | accuracy: 0.35 | loss: 0.47
update:275/2000, 耗时:0.00分/0.63分 | step:  2200 | performance: 2.2 | accuracy: 0.35 | loss: 0.36
update:280/2000, 耗时:0.00分/0.64分 | step:  2240 | performance: 2.2 | accuracy: 0.35 | loss: 0.53
update:285/2000, 耗时:0.00分/0.65分 | step:  2280 | performance: 2.3 | accuracy: 0.35 | loss: 0.20
update:290/2000, 耗时:0.00分/0.66分 | step:  2320 | performance: 2.4 | accuracy: 0.36 | loss: 0.32
update:295/2000, 耗时:0.00分/0.67分 | step:  2360 | performance: 2.3 | accuracy: 0.36 | loss: 0.17
update:300/2000, 耗时:0.00分/0.68分 | step:  2400 | performance: 2.2 | accuracy: 0.35 | loss: 0.19
update:305/2000, 耗时:0.00分/0.69分 | step:  2440 | performance: 2.3 | accuracy: 0.35 | loss: 0.14
update:310/2000, 耗时:0.00分/0.71分 | step:  2480 | performance: 2.2 | accuracy: 0.35 | loss: 0.12
update:315/2000, 耗时:0.00分/0.72分 | step:  2520 | performance: 2.2 | accuracy: 0.35 | loss: 0.26
update:320/2000, 耗时:0.00分/0.73分 | step:  2560 | performance: 2.1 | accuracy: 0.34 | loss: 0.06
update:325/2000, 耗时:0.00分/0.74分 | step:  2600 | performance: 1.9 | accuracy: 0.34 | loss: 0.33
update:330/2000, 耗时:0.00分/0.75分 | step:  2640 | performance: 1.9 | accuracy: 0.34 | loss: 0.14
update:335/2000, 耗时:0.00分/0.76分 | step:  2680 | performance: 1.9 | accuracy: 0.34 | loss: 0.22
update:340/2000, 耗时:0.00分/0.77分 | step:  2720 | performance: 2.0 | accuracy: 0.34 | loss: 0.61
update:345/2000, 耗时:0.00分/0.78分 | step:  2760 | performance: 2.1 | accuracy: 0.33 | loss: 0.35
update:350/2000, 耗时:0.00分/0.79分 | step:  2800 | performance: 2.1 | accuracy: 0.33 | loss: 0.06
update:355/2000, 耗时:0.00分/0.81分 | step:  2840 | performance: 1.9 | accuracy: 0.33 | loss: 0.33
update:360/2000, 耗时:0.00分/0.82分 | step:  2880 | performance: 1.9 | accuracy: 0.33 | loss: 0.52
update:365/2000, 耗时:0.00分/0.83分 | step:  2920 | performance: 1.9 | accuracy: 0.32 | loss: 0.06
update:370/2000, 耗时:0.00分/0.84分 | step:  2960 | performance: 1.9 | accuracy: 0.32 | loss: 0.22
update:375/2000, 耗时:0.00分/0.85分 | step:  3000 | performance: 1.9 | accuracy: 0.32 | loss: 0.20
update:380/2000, 耗时:0.00分/0.86分 | step:  3040 | performance: 1.9 | accuracy: 0.32 | loss: 0.53
update:385/2000, 耗时:0.00分/0.87分 | step:  3080 | performance: 1.9 | accuracy: 0.32 | loss: 0.03
update:390/2000, 耗时:0.00分/0.88分 | step:  3120 | performance: 1.8 | accuracy: 0.32 | loss: 0.30
update:395/2000, 耗时:0.00分/0.89分 | step:  3160 | performance: 1.9 | accuracy: 0.32 | loss: 0.49
update:400/2000, 耗时:0.00分/0.91分 | step:  3200 | performance: 1.9 | accuracy: 0.32 | loss: 0.02
update:405/2000, 耗时:0.00分/0.92分 | step:  3240 | performance: 1.8 | accuracy: 0.32 | loss: 0.12
update:410/2000, 耗时:0.00分/0.93分 | step:  3280 | performance: 2.0 | accuracy: 0.32 | loss: 2.10
update:415/2000, 耗时:0.00分/0.94分 | step:  3320 | performance: 1.9 | accuracy: 0.32 | loss: 0.34
update:420/2000, 耗时:0.00分/0.95分 | step:  3360 | performance: 1.9 | accuracy: 0.32 | loss: 0.31
update:425/2000, 耗时:0.00分/0.96分 | step:  3400 | performance: 1.9 | accuracy: 0.32 | loss: 0.19
update:430/2000, 耗时:0.00分/0.97分 | step:  3440 | performance: 1.8 | accuracy: 0.32 | loss: 0.29
update:435/2000, 耗时:0.00分/0.98分 | step:  3480 | performance: 1.7 | accuracy: 0.32 | loss: 0.46
update:440/2000, 耗时:0.00分/0.99分 | step:  3520 | performance: 1.7 | accuracy: 0.32 | loss: 1.69
update:445/2000, 耗时:0.00分/1.00分 | step:  3560 | performance: 1.6 | accuracy: 0.32 | loss: 1.25
update:450/2000, 耗时:0.00分/1.02分 | step:  3600 | performance: 1.7 | accuracy: 0.32 | loss: 0.12
update:455/2000, 耗时:0.00分/1.03分 | step:  3640 | performance: 1.7 | accuracy: 0.32 | loss: 0.03
update:460/2000, 耗时:0.00分/1.04分 | step:  3680 | performance: 1.8 | accuracy: 0.32 | loss: 0.35
update:465/2000, 耗时:0.00分/1.05分 | step:  3720 | performance: 1.7 | accuracy: 0.32 | loss: 0.99
update:470/2000, 耗时:0.00分/1.06分 | step:  3760 | performance: 1.8 | accuracy: 0.33 | loss: 0.37
update:475/2000, 耗时:0.00分/1.07分 | step:  3800 | performance: 1.7 | accuracy: 0.33 | loss: 0.04
update:480/2000, 耗时:0.00分/1.08分 | step:  3840 | performance: 1.7 | accuracy: 0.33 | loss: 0.21
update:485/2000, 耗时:0.00分/1.09分 | step:  3880 | performance: 1.8 | accuracy: 0.33 | loss: 0.29
update:490/2000, 耗时:0.00分/1.10分 | step:  3920 | performance: 1.8 | accuracy: 0.33 | loss: 0.31
update:495/2000, 耗时:0.00分/1.11分 | step:  3960 | performance: 1.8 | accuracy: 0.33 | loss: 0.05
update:500/2000, 耗时:0.00分/1.13分 | step:  4000 | performance: 1.7 | accuracy: 0.33 | loss: -0.02
update:505/2000, 耗时:0.00分/1.14分 | step:  4040 | performance: 1.6 | accuracy: 0.33 | loss: 0.25
update:510/2000, 耗时:0.00分/1.15分 | step:  4080 | performance: 1.6 | accuracy: 0.33 | loss: 0.26
update:515/2000, 耗时:0.00分/1.16分 | step:  4120 | performance: 1.7 | accuracy: 0.33 | loss: 0.43
update:520/2000, 耗时:0.00分/1.17分 | step:  4160 | performance: 1.7 | accuracy: 0.33 | loss: 0.35
update:525/2000, 耗时:0.00分/1.18分 | step:  4200 | performance: 1.6 | accuracy: 0.33 | loss: 0.16
update:530/2000, 耗时:0.00分/1.19分 | step:  4240 | performance: 1.6 | accuracy: 0.33 | loss: 0.50
update:535/2000, 耗时:0.00分/1.20分 | step:  4280 | performance: 1.6 | accuracy: 0.33 | loss: 0.29
update:540/2000, 耗时:0.00分/1.22分 | step:  4320 | performance: 1.6 | accuracy: 0.33 | loss: 0.25
update:545/2000, 耗时:0.00分/1.23分 | step:  4360 | performance: 1.6 | accuracy: 0.32 | loss: 0.13
update:550/2000, 耗时:0.00分/1.24分 | step:  4400 | performance: 1.6 | accuracy: 0.32 | loss: 0.04
update:555/2000, 耗时:0.00分/1.25分 | step:  4440 | performance: 1.6 | accuracy: 0.32 | loss: -0.01
update:560/2000, 耗时:0.00分/1.26分 | step:  4480 | performance: 1.6 | accuracy: 0.32 | loss: 0.28
update:565/2000, 耗时:0.00分/1.27分 | step:  4520 | performance: 1.5 | accuracy: 0.32 | loss: 0.08
update:570/2000, 耗时:0.00分/1.28分 | step:  4560 | performance: 1.5 | accuracy: 0.32 | loss: 0.50
update:575/2000, 耗时:0.00分/1.29分 | step:  4600 | performance: 1.5 | accuracy: 0.32 | loss: 0.05
update:580/2000, 耗时:0.00分/1.30分 | step:  4640 | performance: 1.6 | accuracy: 0.32 | loss: 0.46
update:585/2000, 耗时:0.00分/1.32分 | step:  4680 | performance: 1.6 | accuracy: 0.32 | loss: 0.05
update:590/2000, 耗时:0.00分/1.33分 | step:  4720 | performance: 1.6 | accuracy: 0.32 | loss: 1.96
update:595/2000, 耗时:0.00分/1.34分 | step:  4760 | performance: 1.6 | accuracy: 0.32 | loss: 0.00
update:600/2000, 耗时:0.00分/1.35分 | step:  4800 | performance: 1.6 | accuracy: 0.32 | loss: 0.86
update:605/2000, 耗时:0.00分/1.36分 | step:  4840 | performance: 1.6 | accuracy: 0.32 | loss: 0.10
update:610/2000, 耗时:0.00分/1.37分 | step:  4880 | performance: 1.5 | accuracy: 0.32 | loss: 0.30
update:615/2000, 耗时:0.00分/1.38分 | step:  4920 | performance: 1.6 | accuracy: 0.33 | loss: -0.01
update:620/2000, 耗时:0.00分/1.39分 | step:  4960 | performance: 1.6 | accuracy: 0.32 | loss: 0.04
update:625/2000, 耗时:0.00分/1.41分 | step:  5000 | performance: 1.6 | accuracy: 0.32 | loss: -0.00
update:630/2000, 耗时:0.00分/1.42分 | step:  5040 | performance: 1.6 | accuracy: 0.33 | loss: 0.44
update:635/2000, 耗时:0.00分/1.43分 | step:  5080 | performance: 1.8 | accuracy: 0.33 | loss: 0.50
update:640/2000, 耗时:0.00分/1.44分 | step:  5120 | performance: 1.7 | accuracy: 0.33 | loss: 0.33
update:645/2000, 耗时:0.00分/1.45分 | step:  5160 | performance: 1.6 | accuracy: 0.32 | loss: 0.02
update:650/2000, 耗时:0.00分/1.46分 | step:  5200 | performance: 1.5 | accuracy: 0.32 | loss: 0.01
update:655/2000, 耗时:0.00分/1.47分 | step:  5240 | performance: 1.3 | accuracy: 0.32 | loss: 0.41
update:660/2000, 耗时:0.00分/1.48分 | step:  5280 | performance: 1.4 | accuracy: 0.32 | loss: 1.17
update:665/2000, 耗时:0.00分/1.49分 | step:  5320 | performance: 1.5 | accuracy: 0.32 | loss: 0.72
update:670/2000, 耗时:0.00分/1.50分 | step:  5360 | performance: 1.5 | accuracy: 0.32 | loss: 1.55
update:675/2000, 耗时:0.00分/1.52分 | step:  5400 | performance: 1.6 | accuracy: 0.32 | loss: 0.48
update:680/2000, 耗时:0.00分/1.53分 | step:  5440 | performance: 1.6 | accuracy: 0.32 | loss: 0.30
update:685/2000, 耗时:0.00分/1.54分 | step:  5480 | performance: 1.7 | accuracy: 0.32 | loss: 0.04
update:690/2000, 耗时:0.00分/1.55分 | step:  5520 | performance: 1.7 | accuracy: 0.32 | loss: 0.78
update:695/2000, 耗时:0.00分/1.56分 | step:  5560 | performance: 1.7 | accuracy: 0.32 | loss: 0.13
update:700/2000, 耗时:0.00分/1.57分 | step:  5600 | performance: 1.7 | accuracy: 0.32 | loss: 0.48
update:705/2000, 耗时:0.00分/1.58分 | step:  5640 | performance: 1.8 | accuracy: 0.32 | loss: 1.02
update:710/2000, 耗时:0.00分/1.59分 | step:  5680 | performance: 1.8 | accuracy: 0.33 | loss: 0.45
update:715/2000, 耗时:0.00分/1.61分 | step:  5720 | performance: 1.8 | accuracy: 0.32 | loss: -0.01
update:720/2000, 耗时:0.00分/1.62分 | step:  5760 | performance: 1.9 | accuracy: 0.33 | loss: 0.36
update:725/2000, 耗时:0.00分/1.63分 | step:  5800 | performance: 1.8 | accuracy: 0.32 | loss: 0.37
update:730/2000, 耗时:0.00分/1.64分 | step:  5840 | performance: 1.9 | accuracy: 0.32 | loss: 0.12
update:735/2000, 耗时:0.00分/1.65分 | step:  5880 | performance: 1.9 | accuracy: 0.32 | loss: 0.13
update:740/2000, 耗时:0.00分/1.66分 | step:  5920 | performance: 1.8 | accuracy: 0.32 | loss: 0.04
update:745/2000, 耗时:0.00分/1.67分 | step:  5960 | performance: 1.8 | accuracy: 0.32 | loss: 0.37
update:750/2000, 耗时:0.00分/1.68分 | step:  6000 | performance: 1.8 | accuracy: 0.33 | loss: 0.30
update:755/2000, 耗时:0.00分/1.69分 | step:  6040 | performance: 1.8 | accuracy: 0.33 | loss: 0.26
update:760/2000, 耗时:0.00分/1.71分 | step:  6080 | performance: 1.8 | accuracy: 0.33 | loss: 0.08
update:765/2000, 耗时:0.00分/1.72分 | step:  6120 | performance: 1.8 | accuracy: 0.33 | loss: 0.52
update:770/2000, 耗时:0.00分/1.73分 | step:  6160 | performance: 1.8 | accuracy: 0.33 | loss: 0.22
update:775/2000, 耗时:0.00分/1.74分 | step:  6200 | performance: 1.8 | accuracy: 0.33 | loss: 0.28
update:780/2000, 耗时:0.00分/1.75分 | step:  6240 | performance: 1.9 | accuracy: 0.33 | loss: 0.37
update:785/2000, 耗时:0.00分/1.76分 | step:  6280 | performance: 1.8 | accuracy: 0.33 | loss: 0.30
update:790/2000, 耗时:0.00分/1.77分 | step:  6320 | performance: 1.8 | accuracy: 0.33 | loss: 0.19
update:795/2000, 耗时:0.00分/1.78分 | step:  6360 | performance: 1.8 | accuracy: 0.32 | loss: 0.21
update:800/2000, 耗时:0.00分/1.79分 | step:  6400 | performance: 1.8 | accuracy: 0.33 | loss: -0.02
update:805/2000, 耗时:0.00分/1.80分 | step:  6440 | performance: 1.9 | accuracy: 0.33 | loss: 0.09
update:810/2000, 耗时:0.00分/1.82分 | step:  6480 | performance: 1.9 | accuracy: 0.32 | loss: -0.03
update:815/2000, 耗时:0.00分/1.83分 | step:  6520 | performance: 1.9 | accuracy: 0.32 | loss: 0.22
update:820/2000, 耗时:0.00分/1.84分 | step:  6560 | performance: 1.9 | accuracy: 0.32 | loss: -0.01
update:825/2000, 耗时:0.00分/1.85分 | step:  6600 | performance: 1.9 | accuracy: 0.32 | loss: -0.01
update:830/2000, 耗时:0.00分/1.86分 | step:  6640 | performance: 1.9 | accuracy: 0.32 | loss: 0.27
update:835/2000, 耗时:0.00分/1.87分 | step:  6680 | performance: 1.7 | accuracy: 0.32 | loss: 0.80
update:840/2000, 耗时:0.00分/1.88分 | step:  6720 | performance: 1.7 | accuracy: 0.32 | loss: 0.10
update:845/2000, 耗时:0.00分/1.89分 | step:  6760 | performance: 1.7 | accuracy: 0.32 | loss: 0.01
update:850/2000, 耗时:0.00分/1.90分 | step:  6800 | performance: 1.7 | accuracy: 0.32 | loss: 0.32
update:855/2000, 耗时:0.00分/1.91分 | step:  6840 | performance: 1.8 | accuracy: 0.32 | loss: 0.01
update:860/2000, 耗时:0.00分/1.92分 | step:  6880 | performance: 1.8 | accuracy: 0.32 | loss: 0.10
update:865/2000, 耗时:0.00分/1.93分 | step:  6920 | performance: 1.8 | accuracy: 0.32 | loss: 0.05
update:870/2000, 耗时:0.00分/1.94分 | step:  6960 | performance: 1.8 | accuracy: 0.32 | loss: 0.26
update:875/2000, 耗时:0.00分/1.96分 | step:  7000 | performance: 1.8 | accuracy: 0.32 | loss: 0.18
update:880/2000, 耗时:0.00分/1.97分 | step:  7040 | performance: 1.8 | accuracy: 0.32 | loss: 0.10
update:885/2000, 耗时:0.00分/1.98分 | step:  7080 | performance: 1.8 | accuracy: 0.32 | loss: 0.01
update:890/2000, 耗时:0.00分/1.99分 | step:  7120 | performance: 1.8 | accuracy: 0.32 | loss: 0.46
update:895/2000, 耗时:0.00分/2.00分 | step:  7160 | performance: 1.7 | accuracy: 0.32 | loss: 0.01
update:900/2000, 耗时:0.00分/2.01分 | step:  7200 | performance: 1.8 | accuracy: 0.32 | loss: 0.07
update:905/2000, 耗时:0.00分/2.02分 | step:  7240 | performance: 1.7 | accuracy: 0.32 | loss: 0.27
update:910/2000, 耗时:0.00分/2.03分 | step:  7280 | performance: 1.7 | accuracy: 0.32 | loss: 0.15
update:915/2000, 耗时:0.00分/2.04分 | step:  7320 | performance: 1.7 | accuracy: 0.32 | loss: 0.17
update:920/2000, 耗时:0.00分/2.05分 | step:  7360 | performance: 1.6 | accuracy: 0.32 | loss: 1.23
update:925/2000, 耗时:0.00分/2.06分 | step:  7400 | performance: 1.7 | accuracy: 0.32 | loss: 0.33
update:930/2000, 耗时:0.00分/2.08分 | step:  7440 | performance: 1.6 | accuracy: 0.32 | loss: 0.39
update:935/2000, 耗时:0.00分/2.09分 | step:  7480 | performance: 1.6 | accuracy: 0.32 | loss: 0.63
update:940/2000, 耗时:0.00分/2.10分 | step:  7520 | performance: 1.6 | accuracy: 0.32 | loss: 0.20
update:945/2000, 耗时:0.00分/2.11分 | step:  7560 | performance: 1.6 | accuracy: 0.32 | loss: 0.54
update:950/2000, 耗时:0.00分/2.12分 | step:  7600 | performance: 1.6 | accuracy: 0.32 | loss: 0.18
update:955/2000, 耗时:0.00分/2.13分 | step:  7640 | performance: 1.6 | accuracy: 0.32 | loss: 0.22
update:960/2000, 耗时:0.00分/2.14分 | step:  7680 | performance: 1.6 | accuracy: 0.32 | loss: 0.39
update:965/2000, 耗时:0.00分/2.15分 | step:  7720 | performance: 1.7 | accuracy: 0.33 | loss: 0.34
update:970/2000, 耗时:0.00分/2.16分 | step:  7760 | performance: 1.7 | accuracy: 0.33 | loss: 0.67
update:975/2000, 耗时:0.00分/2.18分 | step:  7800 | performance: 1.7 | accuracy: 0.33 | loss: 0.19
update:980/2000, 耗时:0.00分/2.19分 | step:  7840 | performance: 1.8 | accuracy: 0.33 | loss: 0.19
update:985/2000, 耗时:0.00分/2.20分 | step:  7880 | performance: 1.8 | accuracy: 0.33 | loss: 0.08
update:990/2000, 耗时:0.00分/2.21分 | step:  7920 | performance: 1.8 | accuracy: 0.33 | loss: 0.56
update:995/2000, 耗时:0.00分/2.22分 | step:  7960 | performance: 1.7 | accuracy: 0.33 | loss: -0.01
update:1000/2000, 耗时:0.00分/2.23分 | step:  8000 | performance: 2.0 | accuracy: 0.33 | loss: 0.20
update:1005/2000, 耗时:0.00分/2.24分 | step:  8040 | performance: 1.8 | accuracy: 0.33 | loss: 0.03
update:1010/2000, 耗时:0.00分/2.25分 | step:  8080 | performance: 1.8 | accuracy: 0.33 | loss: 0.21
update:1015/2000, 耗时:0.00分/2.27分 | step:  8120 | performance: 1.8 | accuracy: 0.33 | loss: 0.60
update:1020/2000, 耗时:0.00分/2.28分 | step:  8160 | performance: 1.6 | accuracy: 0.33 | loss: 0.17
update:1025/2000, 耗时:0.00分/2.29分 | step:  8200 | performance: 1.5 | accuracy: 0.33 | loss: 0.87
update:1030/2000, 耗时:0.00分/2.30分 | step:  8240 | performance: 1.6 | accuracy: 0.33 | loss: 0.01
update:1035/2000, 耗时:0.00分/2.31分 | step:  8280 | performance: 1.7 | accuracy: 0.33 | loss: 0.54
update:1040/2000, 耗时:0.00分/2.32分 | step:  8320 | performance: 1.8 | accuracy: 0.33 | loss: 0.34
update:1045/2000, 耗时:0.00分/2.34分 | step:  8360 | performance: 1.9 | accuracy: 0.34 | loss: 0.03
update:1050/2000, 耗时:0.00分/2.35分 | step:  8400 | performance: 1.7 | accuracy: 0.33 | loss: 0.28
update:1055/2000, 耗时:0.00分/2.36分 | step:  8440 | performance: 1.6 | accuracy: 0.33 | loss: 0.45
update:1060/2000, 耗时:0.00分/2.37分 | step:  8480 | performance: 1.6 | accuracy: 0.33 | loss: 0.27
update:1065/2000, 耗时:0.00分/2.38分 | step:  8520 | performance: 1.6 | accuracy: 0.33 | loss: 0.49
update:1070/2000, 耗时:0.00分/2.39分 | step:  8560 | performance: 1.7 | accuracy: 0.33 | loss: 0.52
update:1075/2000, 耗时:0.00分/2.40分 | step:  8600 | performance: 1.7 | accuracy: 0.33 | loss: 0.06
update:1080/2000, 耗时:0.00分/2.42分 | step:  8640 | performance: 1.6 | accuracy: 0.33 | loss: 0.80
update:1085/2000, 耗时:0.00分/2.43分 | step:  8680 | performance: 1.4 | accuracy: 0.33 | loss: 0.31
update:1090/2000, 耗时:0.00分/2.44分 | step:  8720 | performance: 1.6 | accuracy: 0.34 | loss: 0.93
update:1095/2000, 耗时:0.00分/2.45分 | step:  8760 | performance: 1.8 | accuracy: 0.34 | loss: 0.64
update:1100/2000, 耗时:0.00分/2.46分 | step:  8800 | performance: 1.9 | accuracy: 0.34 | loss: 0.49
update:1105/2000, 耗时:0.00分/2.47分 | step:  8840 | performance: 1.8 | accuracy: 0.34 | loss: 0.83
update:1110/2000, 耗时:0.00分/2.48分 | step:  8880 | performance: 1.7 | accuracy: 0.34 | loss: 0.58
update:1115/2000, 耗时:0.00分/2.49分 | step:  8920 | performance: 1.5 | accuracy: 0.34 | loss: 0.12
update:1120/2000, 耗时:0.00分/2.51分 | step:  8960 | performance: 1.3 | accuracy: 0.34 | loss: 0.14
update:1125/2000, 耗时:0.00分/2.52分 | step:  9000 | performance: 1.2 | accuracy: 0.34 | loss: 0.24
update:1130/2000, 耗时:0.00分/2.53分 | step:  9040 | performance: 1.2 | accuracy: 0.33 | loss: 0.53
update:1135/2000, 耗时:0.00分/2.54分 | step:  9080 | performance: 1.2 | accuracy: 0.33 | loss: 0.53
update:1140/2000, 耗时:0.00分/2.55分 | step:  9120 | performance: 1.2 | accuracy: 0.33 | loss: 0.35
update:1145/2000, 耗时:0.00分/2.56分 | step:  9160 | performance: 1.2 | accuracy: 0.33 | loss: 0.21
update:1150/2000, 耗时:0.00分/2.57分 | step:  9200 | performance: 1.2 | accuracy: 0.33 | loss: 0.18
update:1155/2000, 耗时:0.00分/2.59分 | step:  9240 | performance: 1.2 | accuracy: 0.33 | loss: -0.00
update:1160/2000, 耗时:0.00分/2.60分 | step:  9280 | performance: 1.3 | accuracy: 0.33 | loss: 0.53
update:1165/2000, 耗时:0.00分/2.61分 | step:  9320 | performance: 1.3 | accuracy: 0.33 | loss: 0.27
update:1170/2000, 耗时:0.00分/2.62分 | step:  9360 | performance: 1.3 | accuracy: 0.34 | loss: 0.26
update:1175/2000, 耗时:0.00分/2.63分 | step:  9400 | performance: 1.3 | accuracy: 0.33 | loss: 0.30
update:1180/2000, 耗时:0.00分/2.64分 | step:  9440 | performance: 1.2 | accuracy: 0.33 | loss: 0.24
update:1185/2000, 耗时:0.00分/2.65分 | step:  9480 | performance: 1.2 | accuracy: 0.33 | loss: 0.27
update:1190/2000, 耗时:0.00分/2.67分 | step:  9520 | performance: 1.3 | accuracy: 0.33 | loss: 0.52
update:1195/2000, 耗时:0.00分/2.68分 | step:  9560 | performance: 1.3 | accuracy: 0.33 | loss: 0.11
update:1200/2000, 耗时:0.00分/2.69分 | step:  9600 | performance: 1.3 | accuracy: 0.33 | loss: 0.11
update:1205/2000, 耗时:0.00分/2.70分 | step:  9640 | performance: 1.3 | accuracy: 0.33 | loss: 0.46
update:1210/2000, 耗时:0.00分/2.71分 | step:  9680 | performance: 1.3 | accuracy: 0.33 | loss: 0.20
update:1215/2000, 耗时:0.00分/2.72分 | step:  9720 | performance: 1.3 | accuracy: 0.33 | loss: 0.10
update:1220/2000, 耗时:0.00分/2.73分 | step:  9760 | performance: 1.3 | accuracy: 0.33 | loss: -0.09
update:1225/2000, 耗时:0.00分/2.75分 | step:  9800 | performance: 1.3 | accuracy: 0.33 | loss: 0.11
update:1230/2000, 耗时:0.00分/2.76分 | step:  9840 | performance: 1.3 | accuracy: 0.33 | loss: 0.04
update:1235/2000, 耗时:0.00分/2.77分 | step:  9880 | performance: 1.3 | accuracy: 0.33 | loss: 0.02
update:1240/2000, 耗时:0.00分/2.78分 | step:  9920 | performance: 1.3 | accuracy: 0.33 | loss: 0.07
update:1245/2000, 耗时:0.00分/2.79分 | step:  9960 | performance: 1.3 | accuracy: 0.33 | loss: 0.16
update:1250/2000, 耗时:0.00分/2.80分 | step: 10000 | performance: 1.3 | accuracy: 0.33 | loss: 0.04
update:1255/2000, 耗时:0.00分/2.81分 | step: 10040 | performance: 1.3 | accuracy: 0.33 | loss: 0.08
update:1260/2000, 耗时:0.00分/2.82分 | step: 10080 | performance: 1.5 | accuracy: 0.33 | loss: 0.51
update:1265/2000, 耗时:0.00分/2.84分 | step: 10120 | performance: 1.4 | accuracy: 0.33 | loss: 0.31
update:1270/2000, 耗时:0.00分/2.85分 | step: 10160 | performance: 1.4 | accuracy: 0.33 | loss: 0.67
update:1275/2000, 耗时:0.00分/2.86分 | step: 10200 | performance: 1.4 | accuracy: 0.33 | loss: 0.13
update:1280/2000, 耗时:0.00分/2.87分 | step: 10240 | performance: 1.4 | accuracy: 0.33 | loss: 0.35
update:1285/2000, 耗时:0.00分/2.88分 | step: 10280 | performance: 1.4 | accuracy: 0.33 | loss: 0.28
update:1290/2000, 耗时:0.00分/2.89分 | step: 10320 | performance: 1.5 | accuracy: 0.33 | loss: 0.28
update:1295/2000, 耗时:0.00分/2.90分 | step: 10360 | performance: 1.6 | accuracy: 0.33 | loss: 0.18
update:1300/2000, 耗时:0.00分/2.91分 | step: 10400 | performance: 1.6 | accuracy: 0.33 | loss: 0.19
update:1305/2000, 耗时:0.00分/2.93分 | step: 10440 | performance: 1.6 | accuracy: 0.33 | loss: 0.16
update:1310/2000, 耗时:0.00分/2.94分 | step: 10480 | performance: 1.6 | accuracy: 0.33 | loss: 0.09
update:1315/2000, 耗时:0.00分/2.95分 | step: 10520 | performance: 1.5 | accuracy: 0.33 | loss: 0.29
update:1320/2000, 耗时:0.00分/2.96分 | step: 10560 | performance: 1.5 | accuracy: 0.33 | loss: 0.22
update:1325/2000, 耗时:0.00分/2.97分 | step: 10600 | performance: 1.3 | accuracy: 0.33 | loss: 0.68
update:1330/2000, 耗时:0.00分/2.98分 | step: 10640 | performance: 1.3 | accuracy: 0.33 | loss: 0.24
update:1335/2000, 耗时:0.00分/2.99分 | step: 10680 | performance: 1.3 | accuracy: 0.33 | loss: 0.05
update:1340/2000, 耗时:0.00分/3.01分 | step: 10720 | performance: 1.4 | accuracy: 0.33 | loss: 0.13
update:1345/2000, 耗时:0.00分/3.02分 | step: 10760 | performance: 1.4 | accuracy: 0.33 | loss: 0.55
update:1350/2000, 耗时:0.00分/3.03分 | step: 10800 | performance: 1.4 | accuracy: 0.33 | loss: 0.27
update:1355/2000, 耗时:0.00分/3.04分 | step: 10840 | performance: 1.4 | accuracy: 0.33 | loss: 0.15
update:1360/2000, 耗时:0.00分/3.05分 | step: 10880 | performance: 1.5 | accuracy: 0.33 | loss: 0.08
update:1365/2000, 耗时:0.00分/3.06分 | step: 10920 | performance: 1.5 | accuracy: 0.33 | loss: 0.10
update:1370/2000, 耗时:0.00分/3.07分 | step: 10960 | performance: 1.5 | accuracy: 0.33 | loss: 0.20
update:1375/2000, 耗时:0.00分/3.08分 | step: 11000 | performance: 1.4 | accuracy: 0.33 | loss: 0.44
update:1380/2000, 耗时:0.00分/3.10分 | step: 11040 | performance: 1.5 | accuracy: 0.33 | loss: 0.17
update:1385/2000, 耗时:0.00分/3.11分 | step: 11080 | performance: 1.7 | accuracy: 0.33 | loss: 0.13
update:1390/2000, 耗时:0.00分/3.12分 | step: 11120 | performance: 1.5 | accuracy: 0.33 | loss: 0.12
update:1395/2000, 耗时:0.00分/3.13分 | step: 11160 | performance: 1.5 | accuracy: 0.33 | loss: 0.21
update:1400/2000, 耗时:0.00分/3.14分 | step: 11200 | performance: 1.6 | accuracy: 0.33 | loss: 0.48
update:1405/2000, 耗时:0.00分/3.15分 | step: 11240 | performance: 1.5 | accuracy: 0.33 | loss: 0.23
update:1410/2000, 耗时:0.00分/3.16分 | step: 11280 | performance: 1.5 | accuracy: 0.33 | loss: 0.02
update:1415/2000, 耗时:0.00分/3.17分 | step: 11320 | performance: 1.5 | accuracy: 0.33 | loss: 0.26
update:1420/2000, 耗时:0.00分/3.19分 | step: 11360 | performance: 1.5 | accuracy: 0.33 | loss: 0.23
update:1425/2000, 耗时:0.00分/3.20分 | step: 11400 | performance: 1.5 | accuracy: 0.33 | loss: 0.33
update:1430/2000, 耗时:0.00分/3.21分 | step: 11440 | performance: 1.5 | accuracy: 0.33 | loss: 0.16
update:1435/2000, 耗时:0.00分/3.22分 | step: 11480 | performance: 1.5 | accuracy: 0.33 | loss: -0.01
update:1440/2000, 耗时:0.00分/3.23分 | step: 11520 | performance: 1.6 | accuracy: 0.33 | loss: 0.18
update:1445/2000, 耗时:0.00分/3.24分 | step: 11560 | performance: 1.6 | accuracy: 0.33 | loss: 0.10
update:1450/2000, 耗时:0.00分/3.26分 | step: 11600 | performance: 1.7 | accuracy: 0.33 | loss: 0.33
update:1455/2000, 耗时:0.00分/3.27分 | step: 11640 | performance: 1.7 | accuracy: 0.33 | loss: 0.01
update:1460/2000, 耗时:0.00分/3.28分 | step: 11680 | performance: 1.7 | accuracy: 0.33 | loss: 1.29
update:1465/2000, 耗时:0.00分/3.29分 | step: 11720 | performance: 1.7 | accuracy: 0.33 | loss: 0.46
update:1470/2000, 耗时:0.00分/3.30分 | step: 11760 | performance: 1.7 | accuracy: 0.33 | loss: 0.48
update:1475/2000, 耗时:0.00分/3.31分 | step: 11800 | performance: 1.8 | accuracy: 0.33 | loss: 0.44
update:1480/2000, 耗时:0.00分/3.33分 | step: 11840 | performance: 1.8 | accuracy: 0.33 | loss: 0.53
update:1485/2000, 耗时:0.00分/3.34分 | step: 11880 | performance: 1.7 | accuracy: 0.33 | loss: 0.32
update:1490/2000, 耗时:0.00分/3.35分 | step: 11920 | performance: 1.7 | accuracy: 0.33 | loss: 0.36
update:1495/2000, 耗时:0.00分/3.36分 | step: 11960 | performance: 1.6 | accuracy: 0.33 | loss: 0.20
update:1500/2000, 耗时:0.00分/3.37分 | step: 12000 | performance: 1.5 | accuracy: 0.33 | loss: 0.09
update:1505/2000, 耗时:0.00分/3.38分 | step: 12040 | performance: 1.6 | accuracy: 0.33 | loss: 0.10
update:1510/2000, 耗时:0.00分/3.40分 | step: 12080 | performance: 1.6 | accuracy: 0.33 | loss: 0.43
update:1515/2000, 耗时:0.00分/3.41分 | step: 12120 | performance: 1.6 | accuracy: 0.33 | loss: 0.11
update:1520/2000, 耗时:0.00分/3.42分 | step: 12160 | performance: 1.7 | accuracy: 0.33 | loss: 0.24
update:1525/2000, 耗时:0.00分/3.43分 | step: 12200 | performance: 1.7 | accuracy: 0.33 | loss: 0.23
update:1530/2000, 耗时:0.00分/3.44分 | step: 12240 | performance: 1.7 | accuracy: 0.33 | loss: 0.13
update:1535/2000, 耗时:0.00分/3.46分 | step: 12280 | performance: 1.7 | accuracy: 0.33 | loss: 0.30
update:1540/2000, 耗时:0.00分/3.47分 | step: 12320 | performance: 1.7 | accuracy: 0.33 | loss: 0.11
update:1545/2000, 耗时:0.00分/3.48分 | step: 12360 | performance: 1.7 | accuracy: 0.33 | loss: 0.15
update:1550/2000, 耗时:0.00分/3.49分 | step: 12400 | performance: 1.6 | accuracy: 0.33 | loss: 0.35
update:1555/2000, 耗时:0.00分/3.50分 | step: 12440 | performance: 1.7 | accuracy: 0.33 | loss: 0.33
update:1560/2000, 耗时:0.00分/3.51分 | step: 12480 | performance: 1.7 | accuracy: 0.33 | loss: 0.35
update:1565/2000, 耗时:0.00分/3.53分 | step: 12520 | performance: 1.8 | accuracy: 0.33 | loss: 0.26
update:1570/2000, 耗时:0.00分/3.54分 | step: 12560 | performance: 1.9 | accuracy: 0.33 | loss: 0.35
update:1575/2000, 耗时:0.00分/3.55分 | step: 12600 | performance: 1.9 | accuracy: 0.33 | loss: 0.23
update:1580/2000, 耗时:0.00分/3.56分 | step: 12640 | performance: 1.9 | accuracy: 0.33 | loss: 0.09
update:1585/2000, 耗时:0.00分/3.57分 | step: 12680 | performance: 1.8 | accuracy: 0.34 | loss: 0.10
update:1590/2000, 耗时:0.00分/3.59分 | step: 12720 | performance: 1.8 | accuracy: 0.34 | loss: 0.07
update:1595/2000, 耗时:0.00分/3.60分 | step: 12760 | performance: 1.6 | accuracy: 0.34 | loss: 0.24
update:1600/2000, 耗时:0.00分/3.61分 | step: 12800 | performance: 1.3 | accuracy: 0.34 | loss: 0.84
update:1605/2000, 耗时:0.00分/3.62分 | step: 12840 | performance: 1.4 | accuracy: 0.34 | loss: 0.58
update:1610/2000, 耗时:0.00分/3.63分 | step: 12880 | performance: 1.4 | accuracy: 0.34 | loss: 0.05
update:1615/2000, 耗时:0.00分/3.65分 | step: 12920 | performance: 1.4 | accuracy: 0.34 | loss: 0.06
update:1620/2000, 耗时:0.00分/3.66分 | step: 12960 | performance: 1.5 | accuracy: 0.34 | loss: 2.26
update:1625/2000, 耗时:0.00分/3.67分 | step: 13000 | performance: 1.4 | accuracy: 0.34 | loss: 0.41
update:1630/2000, 耗时:0.00分/3.68分 | step: 13040 | performance: 1.4 | accuracy: 0.34 | loss: 0.10
update:1635/2000, 耗时:0.00分/3.69分 | step: 13080 | performance: 1.3 | accuracy: 0.33 | loss: 0.20
update:1640/2000, 耗时:0.00分/3.70分 | step: 13120 | performance: 1.2 | accuracy: 0.33 | loss: 0.20
update:1645/2000, 耗时:0.00分/3.72分 | step: 13160 | performance: 1.2 | accuracy: 0.33 | loss: 0.52
update:1650/2000, 耗时:0.00分/3.73分 | step: 13200 | performance: 1.3 | accuracy: 0.34 | loss: 0.52
update:1655/2000, 耗时:0.00分/3.74分 | step: 13240 | performance: 1.3 | accuracy: 0.33 | loss: 0.27
update:1660/2000, 耗时:0.00分/3.75分 | step: 13280 | performance: 1.2 | accuracy: 0.33 | loss: 0.33
update:1665/2000, 耗时:0.00分/3.76分 | step: 13320 | performance: 1.2 | accuracy: 0.34 | loss: 0.25
update:1670/2000, 耗时:0.00分/3.77分 | step: 13360 | performance: 1.2 | accuracy: 0.34 | loss: 0.27
update:1675/2000, 耗时:0.00分/3.78分 | step: 13400 | performance: 1.2 | accuracy: 0.34 | loss: 0.08
update:1680/2000, 耗时:0.00分/3.80分 | step: 13440 | performance: 1.2 | accuracy: 0.33 | loss: 0.05
update:1685/2000, 耗时:0.00分/3.81分 | step: 13480 | performance: 1.2 | accuracy: 0.33 | loss: 0.05
update:1690/2000, 耗时:0.00分/3.82分 | step: 13520 | performance: 1.1 | accuracy: 0.33 | loss: -0.01
update:1695/2000, 耗时:0.00分/3.83分 | step: 13560 | performance: 1.1 | accuracy: 0.33 | loss: 0.44
update:1700/2000, 耗时:0.00分/3.84分 | step: 13600 | performance: 1.1 | accuracy: 0.33 | loss: 0.07
update:1705/2000, 耗时:0.00分/3.85分 | step: 13640 | performance: 1.1 | accuracy: 0.33 | loss: 0.12
update:1710/2000, 耗时:0.00分/3.86分 | step: 13680 | performance: 1.0 | accuracy: 0.33 | loss: 0.10
update:1715/2000, 耗时:0.00分/3.87分 | step: 13720 | performance: 1.0 | accuracy: 0.33 | loss: 0.34
update:1720/2000, 耗时:0.00分/3.88分 | step: 13760 | performance: 1.1 | accuracy: 0.33 | loss: 0.46
update:1725/2000, 耗时:0.00分/3.90分 | step: 13800 | performance: 1.1 | accuracy: 0.33 | loss: 0.36
update:1730/2000, 耗时:0.00分/3.91分 | step: 13840 | performance: 1.1 | accuracy: 0.33 | loss: 0.01
update:1735/2000, 耗时:0.00分/3.92分 | step: 13880 | performance: 1.2 | accuracy: 0.33 | loss: 0.05
update:1740/2000, 耗时:0.00分/3.93分 | step: 13920 | performance: 1.2 | accuracy: 0.33 | loss: 0.19
update:1745/2000, 耗时:0.00分/3.94分 | step: 13960 | performance: 1.2 | accuracy: 0.33 | loss: 0.05
update:1750/2000, 耗时:0.00分/3.95分 | step: 14000 | performance: 1.1 | accuracy: 0.33 | loss: 0.10
update:1755/2000, 耗时:0.00分/3.96分 | step: 14040 | performance: 1.1 | accuracy: 0.33 | loss: -0.00
update:1760/2000, 耗时:0.00分/3.97分 | step: 14080 | performance: 1.1 | accuracy: 0.33 | loss: 0.03
update:1765/2000, 耗时:0.00分/3.99分 | step: 14120 | performance: 1.0 | accuracy: 0.33 | loss: 0.12
update:1770/2000, 耗时:0.00分/4.00分 | step: 14160 | performance: 1.1 | accuracy: 0.33 | loss: 0.12
update:1775/2000, 耗时:0.00分/4.01分 | step: 14200 | performance: 1.0 | accuracy: 0.33 | loss: 0.19
update:1780/2000, 耗时:0.00分/4.02分 | step: 14240 | performance: 1.1 | accuracy: 0.33 | loss: 0.10
update:1785/2000, 耗时:0.00分/4.03分 | step: 14280 | performance: 1.1 | accuracy: 0.33 | loss: 0.49
update:1790/2000, 耗时:0.00分/4.04分 | step: 14320 | performance: 1.1 | accuracy: 0.33 | loss: 0.26
update:1795/2000, 耗时:0.00分/4.05分 | step: 14360 | performance: 1.1 | accuracy: 0.33 | loss: 0.18
update:1800/2000, 耗时:0.00分/4.06分 | step: 14400 | performance: 1.1 | accuracy: 0.33 | loss: 0.12
update:1805/2000, 耗时:0.00分/4.07分 | step: 14440 | performance: 1.2 | accuracy: 0.33 | loss: 0.16
update:1810/2000, 耗时:0.00分/4.09分 | step: 14480 | performance: 1.2 | accuracy: 0.33 | loss: 0.09
update:1815/2000, 耗时:0.00分/4.10分 | step: 14520 | performance: 1.2 | accuracy: 0.33 | loss: 0.18
update:1820/2000, 耗时:0.00分/4.11分 | step: 14560 | performance: 1.2 | accuracy: 0.33 | loss: 0.21
update:1825/2000, 耗时:0.00分/4.12分 | step: 14600 | performance: 1.2 | accuracy: 0.33 | loss: 0.16
update:1830/2000, 耗时:0.00分/4.13分 | step: 14640 | performance: 1.2 | accuracy: 0.33 | loss: 0.40
update:1835/2000, 耗时:0.00分/4.14分 | step: 14680 | performance: 1.2 | accuracy: 0.33 | loss: 0.37
update:1840/2000, 耗时:0.00分/4.15分 | step: 14720 | performance: 1.3 | accuracy: 0.33 | loss: 0.27
update:1845/2000, 耗时:0.00分/4.16分 | step: 14760 | performance: 1.3 | accuracy: 0.33 | loss: 0.22
update:1850/2000, 耗时:0.00分/4.17分 | step: 14800 | performance: 1.3 | accuracy: 0.33 | loss: 0.11
update:1855/2000, 耗时:0.00分/4.19分 | step: 14840 | performance: 1.3 | accuracy: 0.33 | loss: 0.27
update:1860/2000, 耗时:0.00分/4.20分 | step: 14880 | performance: 1.3 | accuracy: 0.33 | loss: 0.56
update:1865/2000, 耗时:0.00分/4.21分 | step: 14920 | performance: 1.3 | accuracy: 0.33 | loss: 0.44
update:1870/2000, 耗时:0.00分/4.22分 | step: 14960 | performance: 1.3 | accuracy: 0.33 | loss: 0.18
update:1875/2000, 耗时:0.00分/4.23分 | step: 15000 | performance: 1.4 | accuracy: 0.33 | loss: 0.23
update:1880/2000, 耗时:0.00分/4.24分 | step: 15040 | performance: 1.4 | accuracy: 0.33 | loss: -0.01
update:1885/2000, 耗时:0.00分/4.25分 | step: 15080 | performance: 1.4 | accuracy: 0.33 | loss: 0.95
update:1890/2000, 耗时:0.00分/4.26分 | step: 15120 | performance: 1.4 | accuracy: 0.33 | loss: 0.07
update:1895/2000, 耗时:0.00分/4.27分 | step: 15160 | performance: 1.4 | accuracy: 0.33 | loss: 0.15
update:1900/2000, 耗时:0.00分/4.29分 | step: 15200 | performance: 1.4 | accuracy: 0.33 | loss: 0.28
update:1905/2000, 耗时:0.00分/4.30分 | step: 15240 | performance: 1.4 | accuracy: 0.33 | loss: 0.38
update:1910/2000, 耗时:0.00分/4.31分 | step: 15280 | performance: 1.4 | accuracy: 0.33 | loss: 0.56
update:1915/2000, 耗时:0.00分/4.32分 | step: 15320 | performance: 1.4 | accuracy: 0.33 | loss: 0.56
update:1920/2000, 耗时:0.00分/4.33分 | step: 15360 | performance: 1.4 | accuracy: 0.33 | loss: 0.26
update:1925/2000, 耗时:0.00分/4.34分 | step: 15400 | performance: 1.4 | accuracy: 0.33 | loss: 0.38
update:1930/2000, 耗时:0.00分/4.35分 | step: 15440 | performance: 1.4 | accuracy: 0.33 | loss: -0.01
update:1935/2000, 耗时:0.00分/4.36分 | step: 15480 | performance: 1.4 | accuracy: 0.33 | loss: 0.16
update:1940/2000, 耗时:0.00分/4.37分 | step: 15520 | performance: 1.4 | accuracy: 0.33 | loss: 0.04
update:1945/2000, 耗时:0.00分/4.39分 | step: 15560 | performance: 1.4 | accuracy: 0.33 | loss: 0.30
update:1950/2000, 耗时:0.00分/4.40分 | step: 15600 | performance: 1.6 | accuracy: 0.33 | loss: 0.16
update:1955/2000, 耗时:0.00分/4.41分 | step: 15640 | performance: 1.6 | accuracy: 0.34 | loss: 0.73
update:1960/2000, 耗时:0.00分/4.42分 | step: 15680 | performance: 1.6 | accuracy: 0.33 | loss: 0.42
update:1965/2000, 耗时:0.00分/4.43分 | step: 15720 | performance: 1.7 | accuracy: 0.33 | loss: 0.43
update:1970/2000, 耗时:0.00分/4.44分 | step: 15760 | performance: 1.7 | accuracy: 0.34 | loss: 0.28
update:1975/2000, 耗时:0.00分/4.45分 | step: 15800 | performance: 1.7 | accuracy: 0.34 | loss: 0.19
update:1980/2000, 耗时:0.00分/4.46分 | step: 15840 | performance: 1.7 | accuracy: 0.33 | loss: 0.30
update:1985/2000, 耗时:0.00分/4.47分 | step: 15880 | performance: 1.7 | accuracy: 0.34 | loss: 0.26
update:1990/2000, 耗时:0.00分/4.48分 | step: 15920 | performance: 1.7 | accuracy: 0.33 | loss: 0.08
update:1995/2000, 耗时:0.00分/4.50分 | step: 15960 | performance: 1.7 | accuracy: 0.34 | loss: 0.03
update:2000/2000, 耗时:0.00分/4.51分 | step: 16000 | performance: 1.6 | accuracy: 0.33 | loss: 0.38
----------------------------------------finished----------------------------------------
==================================================
2023-01-10T12:00:00 | *** START BACKTEST ***
2023-01-10T12:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/391 [00:00<?, ?it/s]100%|| 391/391 [00:00<00:00, 97727.96it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 974.49
2023-07-24T12:00:00 | net performance [%] = -2.5511
2023-07-24T12:00:00 | number of trades [#] = 86
==================================================
Trial 47 Complete [00h 04m 57s]
net_wealth: 975.464366345857

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 06h 18m 19s

Search: Running Trial #48

Value             |Best Value So Far |Hyperparameter
7                 |7                 |horizon
365               |730               |lookback
True              |False             |MarketFactor
5                 |14                |lags
0.9               |0.7               |gamma
32                |32                |batch_size
32                |32                |n_step
0.85              |0.92              |gae_lambda
10                |0.1               |gradient_clip_norm
5                 |5                 |epochs
5e-05             |0.0001            |actor_lr
0.001             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4294.000000   4301.000000
mean      0.000435    20113.607657  ...   20195.171043  20169.373185
std       0.027833    16040.642334  ...   16078.971923  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7758.522461   7730.930176
50%       0.000642    11571.842969  ...   11758.879883  11751.469727
75%       0.011590    29894.706152  ...   30019.495605  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 04:21:42.890612023-07-28 04:21:42.890636: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use th2023-07-28 04:21:42.890716: I tensorflow/core/platform/cpu_feature_guard.cc28: I tensorflow/coe0r2e/pl202 follo33-win0a-gt077-f-o 228 04r:m2/c81 0pC:4:21:144Pu2_featu]2 .This8 9Tere_0g:un7sorFaU irlod79:wns 2 bI t4inarrutensoctiorflown.sy2 in . pe8ccis: orpti1mi090z7ed42260:]3   TIh-w0i7isf/ Ttcoor- 2mtern8aseh on o0e/4nnsorplaFlowrct fefbl-oiocrnwrmia//trcciycal  opoisr oueAe_fPppeat2/pluetraiIr0tion2sm iz:3ae_g-D0u  AVetede ardp NeXw f.orAmVX2cict/
:T1chuorp42 u aol eN_n2eAPI0na fee2tble taD]h7turwe- 3_-e:2eT07-8ep Ngm  euorri201:4ak4u:arn2 .dl8221oth .Neercct L9ib r8::ary10w4o 20. 4o4p(28]9 hTr:k11h9i2e2oi 1sr12nsLi br:a4tie6o2ns::T ,I  reD etensbu aryoiNNT) . Irlns8oentf te9ns(soroo1d2 TfnerD1NN0llooen) tow usorFr/csoer tlF:ow l huoe weit sfolloIwi wo/t/ewnnh s cpolraet/fFlthe pae gbinatoh CpowrlatryemPfpr ofpro /ollcpoiaioUu_rf binary e wrte cmifnilngoato misssC otPU/c ppwpu iopitnisu_tlreuctfrer fiatuelamre_ti_ogsi.z
eguard.cmdns in wg upiizarcerru/ctiecoofrd:et wohr/pm iot14alnadt.hfncee2o] rm/cpucc_f-c:ATPI 1ens iriticDna ahperfotrl 4i2s] Toeeme  oThp NeuinaeAperatsnrncsio eTensar-uFlow binary rol NertwoiFlos optimized with oneAPI Deep Neural Network Library (oneDNN) to use the followingcw bir niCtPU arinstructions in performance-critical operations:PeI Dee_g y  is ouard.cc:pAtimiz1Ved witirXk Acp4 NVeXu2r2ah o noneLib]ral a
Tos: r AVX Ty lN  enhetwork i(oneDNs TensorFlow binary  LiiospebrraaA opN) tAtionVPIimto  si:aryDuse the eep(    AbNzXfloe2Vo
elTlnour oXeal  ADN winVtXeNn)ed with oneAPIgh Neateom  itn otwb2
To enable tuher ops elhem in  ere them in o thtDeaepto Neural Networkeiheo Librarr  thens,y fr ooperations,r (Cork oLlilowinb rerPU instructions in aebuirpyg build Tens(ldo CerPUoan ent iniosTDnNN) tos, r peereDNeNtobrruncforstomFuioraFnce-cinlllosd uwr ise oTe ithnwith the appro pnpweref following CPUort)  iwirm antith the apoia nstrucuse thece -tifootnls lice n rcompilopwing CPU inieter fislorrfagoFsstrlow cwaicructioa.
ll operations:  AVX AVX2
To enable thmpnropri opsaeemr aincea in p-tthn t ehrfocrritite coicommnspal oother operatiia:olep aperatins, rebuild Tensoperoprr r AnoVXi nFatelsc:e -  Ao AVXcVXwc2o
 AVTrompiiler tficX2al  fl
aloapggeTso. 
 ens.wreaiathb ltent
he appropriate compiler flags.
i them in other oable them in otheperations, rebuild TensorFlow with the appropriate compiler flags.
ons:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
r operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 04:21:43.532977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:21:43.538403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:21:43.539701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:21:43.543007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:21:43.557554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:21:43.578290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:21:43.601078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:21:43.602230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.05分 | step:  1280 | performance: 0.6 | accuracy: 0.37 | loss: 0.94
update: 10/2000, 耗时:0.01分/0.08分 | step:  2560 | performance: 0.6 | accuracy: 0.32 | loss: 0.99
update: 15/2000, 耗时:0.01分/0.10分 | step:  3840 | performance: 0.7 | accuracy: 0.30 | loss: 0.85
update: 20/2000, 耗时:0.01分/0.13分 | step:  5120 | performance: 3.1 | accuracy: 0.30 | loss: 1.50
update: 25/2000, 耗时:0.01分/0.17分 | step:  6400 | performance: 4.6 | accuracy: 0.30 | loss: 2.66
update: 30/2000, 耗时:0.01分/0.20分 | step:  7680 | performance: 289.1 | accuracy: 0.35 | loss: 8.01
update: 35/2000, 耗时:0.01分/0.23分 | step:  8960 | performance: 100.0 | accuracy: 0.35 | loss: 1.76
update: 40/2000, 耗时:0.01分/0.27分 | step: 10240 | performance: 22.9 | accuracy: 0.35 | loss: 0.96
update: 45/2000, 耗时:0.01分/0.30分 | step: 11520 | performance: 38.9 | accuracy: 0.35 | loss: 2.97
update: 50/2000, 耗时:0.01分/0.34分 | step: 12800 | performance: 28.6 | accuracy: 0.35 | loss: 2.38
update: 55/2000, 耗时:0.01分/0.37分 | step: 14080 | performance: 85.0 | accuracy: 0.36 | loss: 4.46
update: 60/2000, 耗时:0.01分/0.40分 | step: 15360 | performance: 82.8 | accuracy: 0.37 | loss: 2.95
update: 65/2000, 耗时:0.01分/0.44分 | step: 16640 | performance: 47029.6 | accuracy: 0.40 | loss: 8.76
update: 70/2000, 耗时:0.01分/0.47分 | step: 17920 | performance: 462601.0 | accuracy: 0.41 | loss: 4.95
update: 75/2000, 耗时:0.01分/0.51分 | step: 19200 | performance: 63125.3 | accuracy: 0.41 | loss: 1.49
update: 80/2000, 耗时:0.01分/0.54分 | step: 20480 | performance: 79667.5 | accuracy: 0.40 | loss: 1.49
update: 85/2000, 耗时:0.01分/0.58分 | step: 21760 | performance: 136496.2 | accuracy: 0.41 | loss: 7.94
update: 90/2000, 耗时:0.01分/0.61分 | step: 23040 | performance: 87420.2 | accuracy: 0.40 | loss: 0.75
update: 95/2000, 耗时:0.01分/0.64分 | step: 24320 | performance: 52756.7 | accuracy: 0.39 | loss: 0.90
update:100/2000, 耗时:0.01分/0.68分 | step: 25600 | performance: 33719.0 | accuracy: 0.38 | loss: 2.94
update:105/2000, 耗时:0.01分/0.71分 | step: 26880 | performance: 81879.9 | accuracy: 0.38 | loss: 0.96
update:110/2000, 耗时:0.01分/0.75分 | step: 28160 | performance: 73047.9 | accuracy: 0.38 | loss: 0.55
Saving PPO weights in both H5 format and checkpoint @ update:111 
update:115/2000, 耗时:0.01分/0.78分 | step: 29440 | performance: 0.7 | accuracy: 0.36 | loss: 1.39
update:120/2000, 耗时:0.01分/0.82分 | step: 30720 | performance: 0.5 | accuracy: 0.30 | loss: 1.06
update:125/2000, 耗时:0.01分/0.85分 | step: 32000 | performance: 0.4 | accuracy: 0.27 | loss: 0.47
update:130/2000, 耗时:0.01分/0.88分 | step: 33280 | performance: 1.0 | accuracy: 0.26 | loss: 0.82
update:135/2000, 耗时:0.01分/0.91分 | step: 34560 | performance: 0.7 | accuracy: 0.26 | loss: 1.45
update:140/2000, 耗时:0.01分/0.95分 | step: 35840 | performance: 48.2 | accuracy: 0.32 | loss: 9.89
update:145/2000, 耗时:0.01分/0.98分 | step: 37120 | performance: 8.7 | accuracy: 0.32 | loss: 1.80
update:150/2000, 耗时:0.01分/1.01分 | step: 38400 | performance: 11.8 | accuracy: 0.32 | loss: 0.87
update:155/2000, 耗时:0.01分/1.04分 | step: 39680 | performance: 12.9 | accuracy: 0.31 | loss: 2.09
update:160/2000, 耗时:0.01分/1.08分 | step: 40960 | performance: 2.1 | accuracy: 0.31 | loss: 2.23
update:165/2000, 耗时:0.01分/1.11分 | step: 42240 | performance: 6.1 | accuracy: 0.32 | loss: 4.15
update:170/2000, 耗时:0.01分/1.14分 | step: 43520 | performance: 4.0 | accuracy: 0.33 | loss: 1.56
update:175/2000, 耗时:0.01分/1.18分 | step: 44800 | performance: 10178.2 | accuracy: 0.36 | loss: 11.46
update:180/2000, 耗时:0.01分/1.21分 | step: 46080 | performance: 61612.1 | accuracy: 0.38 | loss: 4.65
update:185/2000, 耗时:0.01分/1.24分 | step: 47360 | performance: 9804.6 | accuracy: 0.38 | loss: 1.01
update:190/2000, 耗时:0.01分/1.28分 | step: 48640 | performance: 21448.6 | accuracy: 0.37 | loss: 1.28
update:195/2000, 耗时:0.01分/1.31分 | step: 49920 | performance: 9692.1 | accuracy: 0.37 | loss: 6.81
update:200/2000, 耗时:0.01分/1.34分 | step: 51200 | performance: 4586.0 | accuracy: 0.36 | loss: 0.54
update:205/2000, 耗时:0.01分/1.37分 | step: 52480 | performance: 2786.7 | accuracy: 0.35 | loss: 0.59
update:210/2000, 耗时:0.01分/1.41分 | step: 53760 | performance: 3192.8 | accuracy: 0.34 | loss: 2.67
update:215/2000, 耗时:0.01分/1.44分 | step: 55040 | performance: 3292.6 | accuracy: 0.34 | loss: 0.96
update:220/2000, 耗时:0.01分/1.47分 | step: 56320 | performance: 2310.0 | accuracy: 0.34 | loss: 0.78
Saving PPO weights in both H5 format and checkpoint @ update:221 
update:225/2000, 耗时:0.01分/1.51分 | step: 57600 | performance: 0.7 | accuracy: 0.36 | loss: 1.37
update:230/2000, 耗时:0.01分/1.54分 | step: 58880 | performance: 1.0 | accuracy: 0.28 | loss: 1.24
update:235/2000, 耗时:0.01分/1.58分 | step: 60160 | performance: 1.7 | accuracy: 0.25 | loss: 0.48
update:240/2000, 耗时:0.01分/1.61分 | step: 61440 | performance: 7.3 | accuracy: 0.25 | loss: 0.90
update:245/2000, 耗时:0.01分/1.64分 | step: 62720 | performance: 3.1 | accuracy: 0.24 | loss: 1.35
update:250/2000, 耗时:0.01分/1.68分 | step: 64000 | performance: 197.3 | accuracy: 0.30 | loss: 10.75
update:255/2000, 耗时:0.01分/1.71分 | step: 65280 | performance: 11.5 | accuracy: 0.30 | loss: 1.71
update:260/2000, 耗时:0.01分/1.74分 | step: 66560 | performance: 9.5 | accuracy: 0.29 | loss: 1.13
update:265/2000, 耗时:0.01分/1.77分 | step: 67840 | performance: 6.9 | accuracy: 0.28 | loss: 1.96
update:270/2000, 耗时:0.01分/1.81分 | step: 69120 | performance: 7.0 | accuracy: 0.28 | loss: 2.05
update:275/2000, 耗时:0.01分/1.84分 | step: 70400 | performance: 9.0 | accuracy: 0.28 | loss: 3.21
update:280/2000, 耗时:0.01分/1.87分 | step: 71680 | performance: 9.8 | accuracy: 0.29 | loss: 0.98
update:285/2000, 耗时:0.01分/1.90分 | step: 72960 | performance: 22122.6 | accuracy: 0.33 | loss: 13.46
update:290/2000, 耗时:0.01分/1.94分 | step: 74240 | performance: 182710.0 | accuracy: 0.35 | loss: 4.99
update:295/2000, 耗时:0.01分/1.97分 | step: 75520 | performance: 29458.5 | accuracy: 0.35 | loss: 0.78
update:300/2000, 耗时:0.01分/2.00分 | step: 76800 | performance: 33157.6 | accuracy: 0.34 | loss: 1.37
update:305/2000, 耗时:0.01分/2.03分 | step: 78080 | performance: 19976.1 | accuracy: 0.34 | loss: 6.52
update:310/2000, 耗时:0.01分/2.07分 | step: 79360 | performance: 5480.4 | accuracy: 0.33 | loss: 0.49
update:315/2000, 耗时:0.01分/2.10分 | step: 80640 | performance: 2610.8 | accuracy: 0.32 | loss: 0.44
update:320/2000, 耗时:0.01分/2.13分 | step: 81920 | performance: 4441.2 | accuracy: 0.31 | loss: 1.03
update:325/2000, 耗时:0.01分/2.16分 | step: 83200 | performance: 3853.0 | accuracy: 0.30 | loss: 0.70
update:330/2000, 耗时:0.01分/2.19分 | step: 84480 | performance: 7599.3 | accuracy: 0.30 | loss: 0.48
Saving PPO weights in both H5 format and checkpoint @ update:331 
update:335/2000, 耗时:0.01分/2.23分 | step: 85760 | performance: 0.7 | accuracy: 0.31 | loss: 1.08
update:340/2000, 耗时:0.01分/2.26分 | step: 87040 | performance: 1.1 | accuracy: 0.23 | loss: 0.98
update:345/2000, 耗时:0.01分/2.30分 | step: 88320 | performance: 1.1 | accuracy: 0.20 | loss: 0.38
update:350/2000, 耗时:0.01分/2.33分 | step: 89600 | performance: 2.5 | accuracy: 0.19 | loss: 0.55
update:355/2000, 耗时:0.01分/2.36分 | step: 90880 | performance: 2.0 | accuracy: 0.19 | loss: 1.18
update:360/2000, 耗时:0.01分/2.39分 | step: 92160 | performance: 237.3 | accuracy: 0.26 | loss: 11.67
update:365/2000, 耗时:0.01分/2.43分 | step: 93440 | performance: 45.1 | accuracy: 0.27 | loss: 1.50
update:370/2000, 耗时:0.01分/2.46分 | step: 94720 | performance: 20.0 | accuracy: 0.26 | loss: 0.98
update:375/2000, 耗时:0.01分/2.49分 | step: 96000 | performance: 9.5 | accuracy: 0.25 | loss: 2.40
update:380/2000, 耗时:0.01分/2.52分 | step: 97280 | performance: 18.4 | accuracy: 0.24 | loss: 1.39
update:385/2000, 耗时:0.01分/2.56分 | step: 98560 | performance: 40.2 | accuracy: 0.25 | loss: 2.08
update:390/2000, 耗时:0.01分/2.59分 | step: 99840 | performance: 33.9 | accuracy: 0.26 | loss: 0.70
update:395/2000, 耗时:0.01分/2.62分 | step: 101120 | performance: 36174.3 | accuracy: 0.30 | loss: 11.79
update:400/2000, 耗时:0.01分/2.65分 | step: 102400 | performance: 483968.5 | accuracy: 0.32 | loss: 3.95
update:405/2000, 耗时:0.01分/2.69分 | step: 103680 | performance: 174086.4 | accuracy: 0.32 | loss: 0.61
update:410/2000, 耗时:0.01分/2.72分 | step: 104960 | performance: 407628.1 | accuracy: 0.31 | loss: 0.79
update:415/2000, 耗时:0.01分/2.75分 | step: 106240 | performance: 763810.4 | accuracy: 0.31 | loss: 5.08
update:420/2000, 耗时:0.01分/2.79分 | step: 107520 | performance: 311545.3 | accuracy: 0.30 | loss: 0.30
update:425/2000, 耗时:0.01分/2.82分 | step: 108800 | performance: 367323.7 | accuracy: 0.29 | loss: 0.37
update:430/2000, 耗时:0.01分/2.85分 | step: 110080 | performance: 328704.6 | accuracy: 0.28 | loss: 0.56
update:435/2000, 耗时:0.01分/2.89分 | step: 111360 | performance: 271440.9 | accuracy: 0.27 | loss: 0.22
update:440/2000, 耗时:0.01分/2.92分 | step: 112640 | performance: 321142.2 | accuracy: 0.27 | loss: 0.36
Saving PPO weights in both H5 format and checkpoint @ update:441 
update:445/2000, 耗时:0.01分/2.96分 | step: 113920 | performance: 2.7 | accuracy: 0.18 | loss: 0.52
update:450/2000, 耗时:0.01分/2.99分 | step: 115200 | performance: 3.1 | accuracy: 0.13 | loss: 0.52
update:455/2000, 耗时:0.01分/3.02分 | step: 116480 | performance: 3.2 | accuracy: 0.13 | loss: 0.26
update:460/2000, 耗时:0.01分/3.06分 | step: 117760 | performance: 5.2 | accuracy: 0.12 | loss: 0.36
update:465/2000, 耗时:0.01分/3.09分 | step: 119040 | performance: 2.9 | accuracy: 0.12 | loss: 0.52
update:470/2000, 耗时:0.01分/3.12分 | step: 120320 | performance: 361.1 | accuracy: 0.21 | loss: 9.62
update:475/2000, 耗时:0.01分/3.16分 | step: 121600 | performance: 62.3 | accuracy: 0.22 | loss: 1.16
update:480/2000, 耗时:0.01分/3.19分 | step: 122880 | performance: 50.6 | accuracy: 0.22 | loss: 0.70
update:485/2000, 耗时:0.01分/3.22分 | step: 124160 | performance: 45.4 | accuracy: 0.20 | loss: 1.55
update:490/2000, 耗时:0.01分/3.26分 | step: 125440 | performance: 47.3 | accuracy: 0.20 | loss: 0.61
update:495/2000, 耗时:0.01分/3.29分 | step: 126720 | performance: 41.7 | accuracy: 0.20 | loss: 0.83
update:500/2000, 耗时:0.01分/3.32分 | step: 128000 | performance: 32.2 | accuracy: 0.21 | loss: 0.54
update:505/2000, 耗时:0.01分/3.36分 | step: 129280 | performance: 33994.2 | accuracy: 0.25 | loss: 9.37
update:510/2000, 耗时:0.01分/3.39分 | step: 130560 | performance: 1137850.7 | accuracy: 0.28 | loss: 4.43
update:515/2000, 耗时:0.01分/3.43分 | step: 131840 | performance: 154177.4 | accuracy: 0.28 | loss: 0.42
update:520/2000, 耗时:0.01分/3.46分 | step: 133120 | performance: 156718.4 | accuracy: 0.26 | loss: 0.60
update:525/2000, 耗时:0.01分/3.49分 | step: 134400 | performance: 168654.8 | accuracy: 0.27 | loss: 4.79
update:530/2000, 耗时:0.01分/3.53分 | step: 135680 | performance: 78399.1 | accuracy: 0.26 | loss: 0.11
update:535/2000, 耗时:0.01分/3.56分 | step: 136960 | performance: 86886.7 | accuracy: 0.25 | loss: 0.08
update:540/2000, 耗时:0.01分/3.60分 | step: 138240 | performance: 77387.3 | accuracy: 0.23 | loss: 0.04
update:545/2000, 耗时:0.01分/3.63分 | step: 139520 | performance: 94697.1 | accuracy: 0.23 | loss: 0.12
update:550/2000, 耗时:0.01分/3.67分 | step: 140800 | performance: 76341.9 | accuracy: 0.22 | loss: 0.20
step: 141049 | worker_0@n_step_31: average total_reward after train data exhaustion : 192.2 | max total_reward: 276.7
step: 141051 | worker_2@n_step_31: average total_reward after train data exhaustion : 187.6 | max total_reward: 276.7
step: 141053 | worker_4@n_step_31: average total_reward after train data exhaustion : 183.2 | max total_reward: 276.7
step: 141056 | worker_7@n_step_31: average total_reward after train data exhaustion : 179.0 | max total_reward: 276.7
update:555/2000, 耗时:0.01分/3.70分 | step: 142080 | performance: 1.3 | accuracy: 0.12 | loss: 0.49
step: 142591 | worker_6@n_step_31: average total_reward after train data exhaustion : 90.0 | max total_reward: 276.7
update:560/2000, 耗时:0.01分/3.74分 | step: 143360 | performance: 0.7 | accuracy: 0.11 | loss: 0.46
update:565/2000, 耗时:0.01分/3.77分 | step: 144640 | performance: 2.1 | accuracy: 0.15 | loss: 0.54
update:570/2000, 耗时:0.01分/3.80分 | step: 145920 | performance: 1.9 | accuracy: 0.13 | loss: 0.37
update:575/2000, 耗时:0.01分/3.84分 | step: 147200 | performance: 1.7 | accuracy: 0.13 | loss: 0.44
update:580/2000, 耗时:0.01分/3.87分 | step: 148480 | performance: 4.0 | accuracy: 0.13 | loss: 0.57
update:585/2000, 耗时:0.01分/3.90分 | step: 149760 | performance: 2.1 | accuracy: 0.14 | loss: 1.28
update:590/2000, 耗时:0.01分/3.94分 | step: 151040 | performance: 41.0 | accuracy: 0.19 | loss: 4.35
update:595/2000, 耗时:0.01分/3.97分 | step: 152320 | performance: 16.8 | accuracy: 0.21 | loss: 2.70
update:600/2000, 耗时:0.01分/4.01分 | step: 153600 | performance: 14.4 | accuracy: 0.22 | loss: 1.90
update:605/2000, 耗时:0.01分/4.04分 | step: 154880 | performance: 5.2 | accuracy: 0.21 | loss: 1.95
update:610/2000, 耗时:0.01分/4.07分 | step: 156160 | performance: 23.9 | accuracy: 0.21 | loss: 1.12
update:615/2000, 耗时:0.01分/4.11分 | step: 157440 | performance: 21.2 | accuracy: 0.21 | loss: 1.55
update:620/2000, 耗时:0.01分/4.14分 | step: 158720 | performance: 30.6 | accuracy: 0.22 | loss: 1.73
update:625/2000, 耗时:0.01分/4.18分 | step: 160000 | performance: 12295.5 | accuracy: 0.25 | loss: 6.38
update:630/2000, 耗时:0.01分/4.21分 | step: 161280 | performance: 57053.5 | accuracy: 0.27 | loss: 4.50
update:635/2000, 耗时:0.01分/4.24分 | step: 162560 | performance: 4563.4 | accuracy: 0.27 | loss: 4.46
update:640/2000, 耗时:0.01分/4.28分 | step: 163840 | performance: 1582.0 | accuracy: 0.27 | loss: 4.51
update:645/2000, 耗时:0.01分/4.31分 | step: 165120 | performance: 1966.9 | accuracy: 0.28 | loss: 4.79
update:650/2000, 耗时:0.01分/4.35分 | step: 166400 | performance: 245.7 | accuracy: 0.29 | loss: 3.91
update:655/2000, 耗时:0.01分/4.38分 | step: 167680 | performance: 86.9 | accuracy: 0.30 | loss: 3.16
update:660/2000, 耗时:0.01分/4.42分 | step: 168960 | performance: 6.9 | accuracy: 0.30 | loss: 4.29
update:665/2000, 耗时:0.01分/4.45分 | step: 170240 | performance: 6.0 | accuracy: 0.31 | loss: 3.79
update:670/2000, 耗时:0.01分/4.49分 | step: 171520 | performance: 1.5 | accuracy: 0.31 | loss: 2.37
update:675/2000, 耗时:0.01分/4.53分 | step: 172800 | performance: 1.3 | accuracy: 0.42 | loss: 3.41
update:680/2000, 耗时:0.01分/4.56分 | step: 174080 | performance: 0.3 | accuracy: 0.41 | loss: 3.96
update:685/2000, 耗时:0.01分/4.60分 | step: 175360 | performance: 0.3 | accuracy: 0.43 | loss: 4.25
update:690/2000, 耗时:0.01分/4.64分 | step: 176640 | performance: 0.0 | accuracy: 0.43 | loss: 3.09
update:695/2000, 耗时:0.01分/4.67分 | step: 177920 | performance: 0.1 | accuracy: 0.46 | loss: 5.94
update:700/2000, 耗时:0.01分/4.71分 | step: 179200 | performance: 41.2 | accuracy: 0.51 | loss: 7.54
update:705/2000, 耗时:0.01分/4.74分 | step: 180480 | performance: 7.9 | accuracy: 0.49 | loss: 5.89
update:710/2000, 耗时:0.01分/4.77分 | step: 181760 | performance: 1.0 | accuracy: 0.47 | loss: 4.99
update:715/2000, 耗时:0.01分/4.81分 | step: 183040 | performance: 6.4 | accuracy: 0.48 | loss: 6.39
update:720/2000, 耗时:0.01分/4.84分 | step: 184320 | performance: 3.4 | accuracy: 0.49 | loss: 6.98
update:725/2000, 耗时:0.01分/4.87分 | step: 185600 | performance: 9.7 | accuracy: 0.49 | loss: 5.24
update:730/2000, 耗时:0.01分/4.90分 | step: 186880 | performance: 8.5 | accuracy: 0.49 | loss: 4.61
update:735/2000, 耗时:0.01分/4.94分 | step: 188160 | performance: 27506.1 | accuracy: 0.51 | loss: 6.75
update:740/2000, 耗时:0.01分/4.97分 | step: 189440 | performance: 374108.6 | accuracy: 0.52 | loss: 6.66
update:745/2000, 耗时:0.01分/5.00分 | step: 190720 | performance: 24358.5 | accuracy: 0.52 | loss: 7.43
update:750/2000, 耗时:0.01分/5.04分 | step: 192000 | performance: 112833.3 | accuracy: 0.52 | loss: 7.57
update:755/2000, 耗时:0.01分/5.07分 | step: 193280 | performance: 258003.7 | accuracy: 0.52 | loss: 7.10
update:760/2000, 耗时:0.01分/5.10分 | step: 194560 | performance: 48313.1 | accuracy: 0.51 | loss: 5.96
update:765/2000, 耗时:0.01分/5.13分 | step: 195840 | performance: 17073.2 | accuracy: 0.51 | loss: 5.08
update:770/2000, 耗时:0.01分/5.17分 | step: 197120 | performance: 769.4 | accuracy: 0.51 | loss: 5.62
update:775/2000, 耗时:0.01分/5.20分 | step: 198400 | performance: 236.3 | accuracy: 0.50 | loss: 4.96
update:780/2000, 耗时:0.01分/5.23分 | step: 199680 | performance: 81.6 | accuracy: 0.50 | loss: 4.05
update:785/2000, 耗时:0.01分/5.27分 | step: 200960 | performance: 0.3 | accuracy: 0.44 | loss: 4.41
update:790/2000, 耗时:0.01分/5.30分 | step: 202240 | performance: 0.0 | accuracy: 0.42 | loss: 5.63
update:795/2000, 耗时:0.01分/5.33分 | step: 203520 | performance: 0.0 | accuracy: 0.44 | loss: 4.38
update:800/2000, 耗时:0.01分/5.36分 | step: 204800 | performance: 0.0 | accuracy: 0.44 | loss: 4.69
update:805/2000, 耗时:0.01分/5.40分 | step: 206080 | performance: 0.0 | accuracy: 0.47 | loss: 5.84
update:810/2000, 耗时:0.01分/5.43分 | step: 207360 | performance: 2.1 | accuracy: 0.51 | loss: 7.29
update:815/2000, 耗时:0.01分/5.46分 | step: 208640 | performance: 0.7 | accuracy: 0.50 | loss: 6.86
update:820/2000, 耗时:0.01分/5.49分 | step: 209920 | performance: 0.1 | accuracy: 0.47 | loss: 6.32
update:825/2000, 耗时:0.01分/5.53分 | step: 211200 | performance: 0.3 | accuracy: 0.48 | loss: 5.65
update:830/2000, 耗时:0.01分/5.56分 | step: 212480 | performance: 0.1 | accuracy: 0.49 | loss: 8.06
update:835/2000, 耗时:0.01分/5.59分 | step: 213760 | performance: 0.6 | accuracy: 0.49 | loss: 5.58
update:840/2000, 耗时:0.01分/5.62分 | step: 215040 | performance: 0.5 | accuracy: 0.50 | loss: 4.63
update:845/2000, 耗时:0.01分/5.65分 | step: 216320 | performance: 879.5 | accuracy: 0.52 | loss: 6.65
update:850/2000, 耗时:0.01分/5.69分 | step: 217600 | performance: 20612.9 | accuracy: 0.53 | loss: 5.89
update:855/2000, 耗时:0.01分/5.72分 | step: 218880 | performance: 1849.9 | accuracy: 0.52 | loss: 7.72
update:860/2000, 耗时:0.01分/5.75分 | step: 220160 | performance: 7898.5 | accuracy: 0.52 | loss: 7.15
update:865/2000, 耗时:0.01分/5.79分 | step: 221440 | performance: 18930.4 | accuracy: 0.52 | loss: 8.13
update:870/2000, 耗时:0.01分/5.82分 | step: 222720 | performance: 2169.7 | accuracy: 0.52 | loss: 6.20
update:875/2000, 耗时:0.01分/5.85分 | step: 224000 | performance: 733.5 | accuracy: 0.52 | loss: 7.42
update:880/2000, 耗时:0.01分/5.88分 | step: 225280 | performance: 14.9 | accuracy: 0.51 | loss: 6.61
update:885/2000, 耗时:0.01分/5.91分 | step: 226560 | performance: 4.4 | accuracy: 0.51 | loss: 5.16
update:890/2000, 耗时:0.01分/5.95分 | step: 227840 | performance: 1.0 | accuracy: 0.50 | loss: 3.51
update:895/2000, 耗时:0.01分/5.98分 | step: 229120 | performance: 0.7 | accuracy: 0.49 | loss: 3.40
update:900/2000, 耗时:0.01分/6.01分 | step: 230400 | performance: 0.2 | accuracy: 0.46 | loss: 4.92
update:905/2000, 耗时:0.01分/6.04分 | step: 231680 | performance: 0.1 | accuracy: 0.46 | loss: 4.64
update:910/2000, 耗时:0.01分/6.07分 | step: 232960 | performance: 0.0 | accuracy: 0.45 | loss: 4.40
update:915/2000, 耗时:0.01分/6.11分 | step: 234240 | performance: 0.0 | accuracy: 0.47 | loss: 5.98
update:920/2000, 耗时:0.01分/6.14分 | step: 235520 | performance: 4.1 | accuracy: 0.52 | loss: 7.62
update:925/2000, 耗时:0.01分/6.17分 | step: 236800 | performance: 2.0 | accuracy: 0.50 | loss: 5.84
update:930/2000, 耗时:0.01分/6.20分 | step: 238080 | performance: 0.2 | accuracy: 0.48 | loss: 6.48
update:935/2000, 耗时:0.01分/6.23分 | step: 239360 | performance: 1.1 | accuracy: 0.49 | loss: 4.80
update:940/2000, 耗时:0.01分/6.27分 | step: 240640 | performance: 0.6 | accuracy: 0.50 | loss: 7.61
update:945/2000, 耗时:0.01分/6.30分 | step: 241920 | performance: 0.9 | accuracy: 0.50 | loss: 6.26
update:950/2000, 耗时:0.01分/6.33分 | step: 243200 | performance: 0.9 | accuracy: 0.50 | loss: 4.71
update:955/2000, 耗时:0.01分/6.36分 | step: 244480 | performance: 1263.3 | accuracy: 0.52 | loss: 7.16
update:960/2000, 耗时:0.01分/6.39分 | step: 245760 | performance: 40271.3 | accuracy: 0.53 | loss: 5.68
update:965/2000, 耗时:0.01分/6.43分 | step: 247040 | performance: 2851.9 | accuracy: 0.53 | loss: 7.30
update:970/2000, 耗时:0.01分/6.46分 | step: 248320 | performance: 14125.7 | accuracy: 0.52 | loss: 6.23
update:975/2000, 耗时:0.01分/6.49分 | step: 249600 | performance: 45466.1 | accuracy: 0.53 | loss: 8.38
update:980/2000, 耗时:0.01分/6.52分 | step: 250880 | performance: 5085.6 | accuracy: 0.52 | loss: 6.27
update:985/2000, 耗时:0.01分/6.55分 | step: 252160 | performance: 1936.3 | accuracy: 0.52 | loss: 7.40
update:990/2000, 耗时:0.01分/6.59分 | step: 253440 | performance: 39.5 | accuracy: 0.51 | loss: 6.80
update:995/2000, 耗时:0.01分/6.62分 | step: 254720 | performance: 14.4 | accuracy: 0.51 | loss: 5.61
update:1000/2000, 耗时:0.01分/6.65分 | step: 256000 | performance: 3.6 | accuracy: 0.51 | loss: 4.22
update:1005/2000, 耗时:0.01分/6.68分 | step: 257280 | performance: 0.3 | accuracy: 0.42 | loss: 5.01
update:1010/2000, 耗时:0.01分/6.72分 | step: 258560 | performance: 0.1 | accuracy: 0.44 | loss: 5.83
update:1015/2000, 耗时:0.01分/6.75分 | step: 259840 | performance: 0.0 | accuracy: 0.45 | loss: 5.02
update:1020/2000, 耗时:0.01分/6.78分 | step: 261120 | performance: 0.0 | accuracy: 0.44 | loss: 4.00
update:1025/2000, 耗时:0.01分/6.81分 | step: 262400 | performance: 0.0 | accuracy: 0.47 | loss: 7.81
update:1030/2000, 耗时:0.01分/6.84分 | step: 263680 | performance: 0.5 | accuracy: 0.51 | loss: 7.63
update:1035/2000, 耗时:0.01分/6.87分 | step: 264960 | performance: 0.3 | accuracy: 0.50 | loss: 6.23
update:1040/2000, 耗时:0.01分/6.91分 | step: 266240 | performance: 0.0 | accuracy: 0.48 | loss: 7.92
update:1045/2000, 耗时:0.01分/6.94分 | step: 267520 | performance: 0.2 | accuracy: 0.49 | loss: 5.74
update:1050/2000, 耗时:0.01分/6.97分 | step: 268800 | performance: 0.1 | accuracy: 0.50 | loss: 6.64
update:1055/2000, 耗时:0.01分/7.00分 | step: 270080 | performance: 0.2 | accuracy: 0.50 | loss: 6.58
update:1060/2000, 耗时:0.01分/7.03分 | step: 271360 | performance: 0.3 | accuracy: 0.50 | loss: 4.64
update:1065/2000, 耗时:0.01分/7.07分 | step: 272640 | performance: 273.0 | accuracy: 0.52 | loss: 8.22
update:1070/2000, 耗时:0.01分/7.10分 | step: 273920 | performance: 11525.1 | accuracy: 0.53 | loss: 5.88
update:1075/2000, 耗时:0.01分/7.13分 | step: 275200 | performance: 606.3 | accuracy: 0.53 | loss: 6.20
update:1080/2000, 耗时:0.01分/7.16分 | step: 276480 | performance: 3312.2 | accuracy: 0.53 | loss: 6.67
update:1085/2000, 耗时:0.01分/7.19分 | step: 277760 | performance: 11878.9 | accuracy: 0.53 | loss: 8.04
update:1090/2000, 耗时:0.01分/7.22分 | step: 279040 | performance: 1218.8 | accuracy: 0.52 | loss: 6.87
update:1095/2000, 耗时:0.01分/7.26分 | step: 280320 | performance: 602.3 | accuracy: 0.52 | loss: 7.31
update:1100/2000, 耗时:0.01分/7.29分 | step: 281600 | performance: 6.0 | accuracy: 0.51 | loss: 7.26
update:1105/2000, 耗时:0.01分/7.32分 | step: 282880 | performance: 3.4 | accuracy: 0.51 | loss: 6.37
update:1110/2000, 耗时:0.01分/7.35分 | step: 284160 | performance: 0.9 | accuracy: 0.51 | loss: 3.85
update:1115/2000, 耗时:0.01分/7.38分 | step: 285440 | performance: 0.3 | accuracy: 0.43 | loss: 4.82
update:1120/2000, 耗时:0.01分/7.41分 | step: 286720 | performance: 0.1 | accuracy: 0.45 | loss: 5.90
update:1125/2000, 耗时:0.01分/7.45分 | step: 288000 | performance: 0.0 | accuracy: 0.46 | loss: 4.96
update:1130/2000, 耗时:0.01分/7.48分 | step: 289280 | performance: 0.0 | accuracy: 0.44 | loss: 4.20
update:1135/2000, 耗时:0.01分/7.51分 | step: 290560 | performance: 0.0 | accuracy: 0.47 | loss: 7.99
update:1140/2000, 耗时:0.01分/7.54分 | step: 291840 | performance: 0.4 | accuracy: 0.51 | loss: 7.85
update:1145/2000, 耗时:0.01分/7.57分 | step: 293120 | performance: 0.5 | accuracy: 0.50 | loss: 6.27
update:1150/2000, 耗时:0.01分/7.61分 | step: 294400 | performance: 0.0 | accuracy: 0.48 | loss: 7.90
update:1155/2000, 耗时:0.01分/7.64分 | step: 295680 | performance: 0.3 | accuracy: 0.49 | loss: 5.90
update:1160/2000, 耗时:0.01分/7.67分 | step: 296960 | performance: 0.1 | accuracy: 0.50 | loss: 6.89
update:1165/2000, 耗时:0.01分/7.70分 | step: 298240 | performance: 0.2 | accuracy: 0.50 | loss: 6.61
update:1170/2000, 耗时:0.01分/7.74分 | step: 299520 | performance: 0.5 | accuracy: 0.51 | loss: 4.56
update:1175/2000, 耗时:0.01分/7.77分 | step: 300800 | performance: 309.7 | accuracy: 0.53 | loss: 8.55
update:1180/2000, 耗时:0.01分/7.80分 | step: 302080 | performance: 22990.5 | accuracy: 0.54 | loss: 5.67
update:1185/2000, 耗时:0.01分/7.83分 | step: 303360 | performance: 955.8 | accuracy: 0.53 | loss: 6.72
update:1190/2000, 耗时:0.01分/7.86分 | step: 304640 | performance: 5960.8 | accuracy: 0.53 | loss: 6.29
update:1195/2000, 耗时:0.01分/7.89分 | step: 305920 | performance: 23546.4 | accuracy: 0.53 | loss: 7.90
update:1200/2000, 耗时:0.01分/7.93分 | step: 307200 | performance: 1238.2 | accuracy: 0.52 | loss: 6.76
update:1205/2000, 耗时:0.01分/7.96分 | step: 308480 | performance: 887.7 | accuracy: 0.52 | loss: 6.52
update:1210/2000, 耗时:0.01分/7.99分 | step: 309760 | performance: 8.0 | accuracy: 0.52 | loss: 7.16
update:1215/2000, 耗时:0.01分/8.02分 | step: 311040 | performance: 4.7 | accuracy: 0.51 | loss: 6.49
update:1220/2000, 耗时:0.01分/8.05分 | step: 312320 | performance: 1.4 | accuracy: 0.51 | loss: 3.52
update:1225/2000, 耗时:0.01分/8.09分 | step: 313600 | performance: 0.3 | accuracy: 0.44 | loss: 5.07
update:1230/2000, 耗时:0.01分/8.12分 | step: 314880 | performance: 0.1 | accuracy: 0.45 | loss: 5.85
update:1235/2000, 耗时:0.01分/8.15分 | step: 316160 | performance: 0.0 | accuracy: 0.46 | loss: 4.89
update:1240/2000, 耗时:0.01分/8.18分 | step: 317440 | performance: 0.0 | accuracy: 0.44 | loss: 4.37
update:1245/2000, 耗时:0.01分/8.21分 | step: 318720 | performance: 0.0 | accuracy: 0.46 | loss: 7.75
update:1250/2000, 耗时:0.01分/8.24分 | step: 320000 | performance: 0.3 | accuracy: 0.51 | loss: 8.35
update:1255/2000, 耗时:0.01分/8.28分 | step: 321280 | performance: 0.5 | accuracy: 0.51 | loss: 6.51
update:1260/2000, 耗时:0.01分/8.31分 | step: 322560 | performance: 0.0 | accuracy: 0.48 | loss: 7.82
update:1265/2000, 耗时:0.01分/8.34分 | step: 323840 | performance: 0.3 | accuracy: 0.49 | loss: 5.64
update:1270/2000, 耗时:0.01分/8.37分 | step: 325120 | performance: 0.1 | accuracy: 0.50 | loss: 7.15
update:1275/2000, 耗时:0.01分/8.40分 | step: 326400 | performance: 0.1 | accuracy: 0.50 | loss: 6.41
update:1280/2000, 耗时:0.01分/8.44分 | step: 327680 | performance: 0.4 | accuracy: 0.51 | loss: 4.63
update:1285/2000, 耗时:0.01分/8.47分 | step: 328960 | performance: 217.3 | accuracy: 0.52 | loss: 8.53
update:1290/2000, 耗时:0.01分/8.50分 | step: 330240 | performance: 28063.5 | accuracy: 0.54 | loss: 5.54
update:1295/2000, 耗时:0.01分/8.53分 | step: 331520 | performance: 725.4 | accuracy: 0.53 | loss: 7.32
update:1300/2000, 耗时:0.01分/8.57分 | step: 332800 | performance: 5439.1 | accuracy: 0.53 | loss: 5.67
update:1305/2000, 耗时:0.01分/8.60分 | step: 334080 | performance: 30937.1 | accuracy: 0.53 | loss: 7.85
update:1310/2000, 耗时:0.01分/8.63分 | step: 335360 | performance: 854.2 | accuracy: 0.52 | loss: 6.65
update:1315/2000, 耗时:0.01分/8.66分 | step: 336640 | performance: 889.0 | accuracy: 0.52 | loss: 5.70
update:1320/2000, 耗时:0.01分/8.69分 | step: 337920 | performance: 6.3 | accuracy: 0.52 | loss: 6.65
update:1325/2000, 耗时:0.01分/8.73分 | step: 339200 | performance: 4.1 | accuracy: 0.51 | loss: 6.32
update:1330/2000, 耗时:0.01分/8.76分 | step: 340480 | performance: 1.3 | accuracy: 0.51 | loss: 3.54
update:1335/2000, 耗时:0.01分/8.79分 | step: 341760 | performance: 0.3 | accuracy: 0.45 | loss: 5.69
update:1340/2000, 耗时:0.01分/8.82分 | step: 343040 | performance: 0.1 | accuracy: 0.46 | loss: 5.88
update:1345/2000, 耗时:0.01分/8.85分 | step: 344320 | performance: 0.0 | accuracy: 0.46 | loss: 4.86
update:1350/2000, 耗时:0.01分/8.89分 | step: 345600 | performance: 0.0 | accuracy: 0.45 | loss: 4.60
update:1355/2000, 耗时:0.01分/8.92分 | step: 346880 | performance: 0.0 | accuracy: 0.46 | loss: 7.87
update:1360/2000, 耗时:0.01分/8.95分 | step: 348160 | performance: 0.2 | accuracy: 0.51 | loss: 8.79
update:1365/2000, 耗时:0.01分/8.98分 | step: 349440 | performance: 0.6 | accuracy: 0.51 | loss: 6.75
update:1370/2000, 耗时:0.01分/9.02分 | step: 350720 | performance: 0.0 | accuracy: 0.48 | loss: 7.79
update:1375/2000, 耗时:0.01分/9.05分 | step: 352000 | performance: 0.3 | accuracy: 0.50 | loss: 5.67
update:1380/2000, 耗时:0.01分/9.08分 | step: 353280 | performance: 0.1 | accuracy: 0.50 | loss: 7.02
update:1385/2000, 耗时:0.01分/9.11分 | step: 354560 | performance: 0.1 | accuracy: 0.50 | loss: 5.84
update:1390/2000, 耗时:0.01分/9.15分 | step: 355840 | performance: 0.4 | accuracy: 0.50 | loss: 4.55
update:1395/2000, 耗时:0.01分/9.18分 | step: 357120 | performance: 169.9 | accuracy: 0.52 | loss: 8.36
update:1400/2000, 耗时:0.01分/9.21分 | step: 358400 | performance: 29859.7 | accuracy: 0.54 | loss: 5.64
update:1405/2000, 耗时:0.01分/9.24分 | step: 359680 | performance: 670.9 | accuracy: 0.53 | loss: 7.32
update:1410/2000, 耗时:0.01分/9.28分 | step: 360960 | performance: 5286.1 | accuracy: 0.53 | loss: 5.34
update:1415/2000, 耗时:0.01分/9.31分 | step: 362240 | performance: 36834.8 | accuracy: 0.53 | loss: 7.73
update:1420/2000, 耗时:0.01分/9.34分 | step: 363520 | performance: 752.4 | accuracy: 0.52 | loss: 7.11
update:1425/2000, 耗时:0.01分/9.38分 | step: 364800 | performance: 915.7 | accuracy: 0.52 | loss: 4.96
update:1430/2000, 耗时:0.01分/9.41分 | step: 366080 | performance: 6.4 | accuracy: 0.52 | loss: 6.66
update:1435/2000, 耗时:0.01分/9.45分 | step: 367360 | performance: 4.3 | accuracy: 0.51 | loss: 5.76
update:1440/2000, 耗时:0.01分/9.48分 | step: 368640 | performance: 1.3 | accuracy: 0.51 | loss: 3.54
update:1445/2000, 耗时:0.01分/9.51分 | step: 369920 | performance: 0.3 | accuracy: 0.44 | loss: 5.83
update:1450/2000, 耗时:0.01分/9.55分 | step: 371200 | performance: 0.2 | accuracy: 0.46 | loss: 5.94
update:1455/2000, 耗时:0.01分/9.58分 | step: 372480 | performance: 0.0 | accuracy: 0.47 | loss: 4.79
update:1460/2000, 耗时:0.01分/9.61分 | step: 373760 | performance: 0.0 | accuracy: 0.45 | loss: 4.85
update:1465/2000, 耗时:0.01分/9.65分 | step: 375040 | performance: 0.0 | accuracy: 0.46 | loss: 7.85
update:1470/2000, 耗时:0.01分/9.68分 | step: 376320 | performance: 0.2 | accuracy: 0.51 | loss: 8.76
update:1475/2000, 耗时:0.01分/9.72分 | step: 377600 | performance: 0.6 | accuracy: 0.51 | loss: 6.73
update:1480/2000, 耗时:0.01分/9.75分 | step: 378880 | performance: 0.0 | accuracy: 0.48 | loss: 8.11
update:1485/2000, 耗时:0.01分/9.78分 | step: 380160 | performance: 0.3 | accuracy: 0.49 | loss: 5.20
update:1490/2000, 耗时:0.01分/9.82分 | step: 381440 | performance: 0.1 | accuracy: 0.50 | loss: 7.10
update:1495/2000, 耗时:0.01分/9.85分 | step: 382720 | performance: 0.1 | accuracy: 0.49 | loss: 5.56
update:1500/2000, 耗时:0.01分/9.88分 | step: 384000 | performance: 0.3 | accuracy: 0.50 | loss: 4.55
update:1505/2000, 耗时:0.01分/9.91分 | step: 385280 | performance: 140.8 | accuracy: 0.52 | loss: 8.17
update:1510/2000, 耗时:0.01分/9.95分 | step: 386560 | performance: 25949.7 | accuracy: 0.54 | loss: 5.89
update:1515/2000, 耗时:0.01分/9.98分 | step: 387840 | performance: 877.8 | accuracy: 0.53 | loss: 7.28
update:1520/2000, 耗时:0.01分/10.01分 | step: 389120 | performance: 5992.9 | accuracy: 0.53 | loss: 5.31
update:1525/2000, 耗时:0.01分/10.05分 | step: 390400 | performance: 36343.3 | accuracy: 0.53 | loss: 7.51
update:1530/2000, 耗时:0.01分/10.08分 | step: 391680 | performance: 801.7 | accuracy: 0.52 | loss: 7.03
update:1535/2000, 耗时:0.01分/10.11分 | step: 392960 | performance: 1101.2 | accuracy: 0.52 | loss: 4.61
update:1540/2000, 耗时:0.01分/10.14分 | step: 394240 | performance: 8.1 | accuracy: 0.52 | loss: 6.38
update:1545/2000, 耗时:0.01分/10.18分 | step: 395520 | performance: 4.4 | accuracy: 0.51 | loss: 5.31
update:1550/2000, 耗时:0.01分/10.21分 | step: 396800 | performance: 1.3 | accuracy: 0.51 | loss: 3.82
step: 397056 | worker_7@n_step_31: average total_reward after train data exhaustion : 137.8 | max total_reward: 276.7
update:1555/2000, 耗时:0.01分/10.24分 | step: 398080 | performance: 0.4 | accuracy: 0.45 | loss: 5.38
update:1560/2000, 耗时:0.01分/10.28分 | step: 399360 | performance: 0.2 | accuracy: 0.47 | loss: 6.31
update:1565/2000, 耗时:0.01分/10.31分 | step: 400640 | performance: 0.0 | accuracy: 0.47 | loss: 5.01
update:1570/2000, 耗时:0.01分/10.35分 | step: 401920 | performance: 0.0 | accuracy: 0.44 | loss: 5.12
update:1575/2000, 耗时:0.01分/10.38分 | step: 403200 | performance: 0.0 | accuracy: 0.46 | loss: 7.93
update:1580/2000, 耗时:0.01分/10.41分 | step: 404480 | performance: 0.2 | accuracy: 0.51 | loss: 8.27
update:1585/2000, 耗时:0.01分/10.45分 | step: 405760 | performance: 0.5 | accuracy: 0.51 | loss: 6.95
update:1590/2000, 耗时:0.01分/10.48分 | step: 407040 | performance: 0.0 | accuracy: 0.48 | loss: 7.84
update:1595/2000, 耗时:0.01分/10.52分 | step: 408320 | performance: 0.3 | accuracy: 0.49 | loss: 4.56
update:1600/2000, 耗时:0.01分/10.56分 | step: 409600 | performance: 0.1 | accuracy: 0.49 | loss: 7.09
update:1605/2000, 耗时:0.01分/10.59分 | step: 410880 | performance: 0.1 | accuracy: 0.49 | loss: 5.66
update:1610/2000, 耗时:0.01分/10.63分 | step: 412160 | performance: 0.3 | accuracy: 0.50 | loss: 4.53
update:1615/2000, 耗时:0.01分/10.66分 | step: 413440 | performance: 104.1 | accuracy: 0.52 | loss: 8.39
update:1620/2000, 耗时:0.01分/10.70分 | step: 414720 | performance: 24288.5 | accuracy: 0.54 | loss: 6.41
update:1625/2000, 耗时:0.01分/10.73分 | step: 416000 | performance: 1078.1 | accuracy: 0.53 | loss: 7.55
update:1630/2000, 耗时:0.01分/10.77分 | step: 417280 | performance: 6507.2 | accuracy: 0.53 | loss: 5.45
update:1635/2000, 耗时:0.01分/10.80分 | step: 418560 | performance: 39964.4 | accuracy: 0.53 | loss: 6.77
update:1640/2000, 耗时:0.01分/10.83分 | step: 419840 | performance: 763.3 | accuracy: 0.52 | loss: 6.87
update:1645/2000, 耗时:0.01分/10.86分 | step: 421120 | performance: 1192.1 | accuracy: 0.52 | loss: 4.83
update:1650/2000, 耗时:0.01分/10.90分 | step: 422400 | performance: 10.2 | accuracy: 0.52 | loss: 6.07
update:1655/2000, 耗时:0.01分/10.93分 | step: 423680 | performance: 4.0 | accuracy: 0.51 | loss: 4.96
update:1660/2000, 耗时:0.01分/10.97分 | step: 424960 | performance: 1.5 | accuracy: 0.51 | loss: 4.19
update:1665/2000, 耗时:0.01分/11.00分 | step: 426240 | performance: 0.5 | accuracy: 0.46 | loss: 4.93
update:1670/2000, 耗时:0.01分/11.03分 | step: 427520 | performance: 0.2 | accuracy: 0.47 | loss: 6.12
update:1675/2000, 耗时:0.01分/11.06分 | step: 428800 | performance: 0.0 | accuracy: 0.47 | loss: 4.80
update:1680/2000, 耗时:0.01分/11.10分 | step: 430080 | performance: 0.0 | accuracy: 0.44 | loss: 5.40
update:1685/2000, 耗时:0.01分/11.13分 | step: 431360 | performance: 0.0 | accuracy: 0.46 | loss: 8.04
update:1690/2000, 耗时:0.01分/11.16分 | step: 432640 | performance: 0.1 | accuracy: 0.50 | loss: 7.83
update:1695/2000, 耗时:0.01分/11.20分 | step: 433920 | performance: 0.4 | accuracy: 0.51 | loss: 7.13
update:1700/2000, 耗时:0.01分/11.23分 | step: 435200 | performance: 0.1 | accuracy: 0.49 | loss: 7.41
update:1705/2000, 耗时:0.01分/11.26分 | step: 436480 | performance: 0.2 | accuracy: 0.49 | loss: 4.51
update:1710/2000, 耗时:0.01分/11.29分 | step: 437760 | performance: 0.0 | accuracy: 0.49 | loss: 7.49
update:1715/2000, 耗时:0.01分/11.33分 | step: 439040 | performance: 0.1 | accuracy: 0.49 | loss: 5.42
update:1720/2000, 耗时:0.01分/11.36分 | step: 440320 | performance: 0.2 | accuracy: 0.50 | loss: 4.49
update:1725/2000, 耗时:0.01分/11.39分 | step: 441600 | performance: 57.6 | accuracy: 0.52 | loss: 8.24
update:1730/2000, 耗时:0.01分/11.43分 | step: 442880 | performance: 24982.3 | accuracy: 0.54 | loss: 6.28
update:1735/2000, 耗时:0.01分/11.46分 | step: 444160 | performance: 982.8 | accuracy: 0.53 | loss: 7.79
update:1740/2000, 耗时:0.01分/11.49分 | step: 445440 | performance: 5361.1 | accuracy: 0.53 | loss: 5.87
update:1745/2000, 耗时:0.01分/11.53分 | step: 446720 | performance: 38945.5 | accuracy: 0.53 | loss: 6.06
update:1750/2000, 耗时:0.01分/11.56分 | step: 448000 | performance: 597.7 | accuracy: 0.52 | loss: 6.84
update:1755/2000, 耗时:0.01分/11.59分 | step: 449280 | performance: 899.1 | accuracy: 0.52 | loss: 4.79
update:1760/2000, 耗时:0.01分/11.62分 | step: 450560 | performance: 9.1 | accuracy: 0.52 | loss: 5.63
update:1765/2000, 耗时:0.01分/11.66分 | step: 451840 | performance: 4.2 | accuracy: 0.51 | loss: 4.30
update:1770/2000, 耗时:0.01分/11.69分 | step: 453120 | performance: 2.3 | accuracy: 0.51 | loss: 3.48
update:1775/2000, 耗时:0.01分/11.72分 | step: 454400 | performance: 0.5 | accuracy: 0.47 | loss: 4.56
update:1780/2000, 耗时:0.01分/11.76分 | step: 455680 | performance: 0.2 | accuracy: 0.46 | loss: 4.53
update:1785/2000, 耗时:0.01分/11.79分 | step: 456960 | performance: 0.0 | accuracy: 0.47 | loss: 3.65
update:1790/2000, 耗时:0.01分/11.82分 | step: 458240 | performance: 0.0 | accuracy: 0.45 | loss: 1.85
update:1795/2000, 耗时:0.01分/11.85分 | step: 459520 | performance: 0.0 | accuracy: 0.47 | loss: 2.99
update:1800/2000, 耗时:0.01分/11.89分 | step: 460800 | performance: 0.2 | accuracy: 0.50 | loss: 6.45
update:1805/2000, 耗时:0.01分/11.92分 | step: 462080 | performance: 0.7 | accuracy: 0.50 | loss: 6.50
update:1810/2000, 耗时:0.01分/11.95分 | step: 463360 | performance: 0.3 | accuracy: 0.49 | loss: 5.93
update:1815/2000, 耗时:0.01分/11.98分 | step: 464640 | performance: 0.8 | accuracy: 0.50 | loss: 3.69
update:1820/2000, 耗时:0.01分/12.02分 | step: 465920 | performance: 0.1 | accuracy: 0.50 | loss: 6.81
update:1825/2000, 耗时:0.01分/12.05分 | step: 467200 | performance: 0.2 | accuracy: 0.50 | loss: 4.48
update:1830/2000, 耗时:0.01分/12.08分 | step: 468480 | performance: 0.6 | accuracy: 0.51 | loss: 4.38
update:1835/2000, 耗时:0.01分/12.12分 | step: 469760 | performance: 111.8 | accuracy: 0.52 | loss: 7.32
update:1840/2000, 耗时:0.01分/12.15分 | step: 471040 | performance: 63140.9 | accuracy: 0.54 | loss: 6.16
update:1845/2000, 耗时:0.01分/12.18分 | step: 472320 | performance: 2128.9 | accuracy: 0.53 | loss: 8.05
update:1850/2000, 耗时:0.01分/12.21分 | step: 473600 | performance: 6761.2 | accuracy: 0.53 | loss: 6.04
update:1855/2000, 耗时:0.01分/12.25分 | step: 474880 | performance: 43351.8 | accuracy: 0.53 | loss: 4.79
update:1860/2000, 耗时:0.01分/12.28分 | step: 476160 | performance: 734.6 | accuracy: 0.52 | loss: 7.18
update:1865/2000, 耗时:0.01分/12.31分 | step: 477440 | performance: 1273.2 | accuracy: 0.52 | loss: 4.53
update:1870/2000, 耗时:0.01分/12.35分 | step: 478720 | performance: 11.7 | accuracy: 0.52 | loss: 5.10
update:1875/2000, 耗时:0.01分/12.38分 | step: 480000 | performance: 6.8 | accuracy: 0.51 | loss: 4.48
update:1880/2000, 耗时:0.01分/12.41分 | step: 481280 | performance: 3.1 | accuracy: 0.51 | loss: 4.07
update:1885/2000, 耗时:0.01分/12.44分 | step: 482560 | performance: 1.5 | accuracy: 0.52 | loss: 4.57
step: 483326 | worker_5@n_step_31: average total_reward after train data exhaustion : 144.4 | max total_reward: 276.7
update:1890/2000, 耗时:0.01分/12.48分 | step: 483840 | performance: 0.3 | accuracy: 0.47 | loss: 4.90
update:1895/2000, 耗时:0.01分/12.51分 | step: 485120 | performance: 0.1 | accuracy: 0.48 | loss: 4.53
update:1900/2000, 耗时:0.01分/12.54分 | step: 486400 | performance: 0.0 | accuracy: 0.46 | loss: 4.52
update:1905/2000, 耗时:0.01分/12.57分 | step: 487680 | performance: 0.0 | accuracy: 0.47 | loss: 5.12
update:1910/2000, 耗时:0.01分/12.61分 | step: 488960 | performance: 0.4 | accuracy: 0.50 | loss: 6.50
update:1915/2000, 耗时:0.01分/12.64分 | step: 490240 | performance: 1.1 | accuracy: 0.50 | loss: 8.06
update:1920/2000, 耗时:0.01分/12.67分 | step: 491520 | performance: 0.4 | accuracy: 0.49 | loss: 6.17
update:1925/2000, 耗时:0.01分/12.71分 | step: 492800 | performance: 0.7 | accuracy: 0.49 | loss: 4.85
update:1930/2000, 耗时:0.01分/12.74分 | step: 494080 | performance: 0.1 | accuracy: 0.49 | loss: 7.57
update:1935/2000, 耗时:0.01分/12.77分 | step: 495360 | performance: 0.4 | accuracy: 0.49 | loss: 4.92
update:1940/2000, 耗时:0.01分/12.80分 | step: 496640 | performance: 0.6 | accuracy: 0.50 | loss: 4.34
update:1945/2000, 耗时:0.01分/12.84分 | step: 497920 | performance: 123.7 | accuracy: 0.52 | loss: 7.16
update:1950/2000, 耗时:0.01分/12.87分 | step: 499200 | performance: 56562.7 | accuracy: 0.54 | loss: 6.31
update:1955/2000, 耗时:0.01分/12.90分 | step: 500480 | performance: 1697.5 | accuracy: 0.53 | loss: 8.31
update:1960/2000, 耗时:0.01分/12.94分 | step: 501760 | performance: 5707.6 | accuracy: 0.53 | loss: 5.96
update:1965/2000, 耗时:0.01分/12.97分 | step: 503040 | performance: 40398.6 | accuracy: 0.53 | loss: 5.13
update:1970/2000, 耗时:0.01分/13.00分 | step: 504320 | performance: 1083.0 | accuracy: 0.52 | loss: 6.82
update:1975/2000, 耗时:0.01分/13.03分 | step: 505600 | performance: 2564.5 | accuracy: 0.52 | loss: 4.66
update:1980/2000, 耗时:0.01分/13.07分 | step: 506880 | performance: 28.9 | accuracy: 0.51 | loss: 4.27
update:1985/2000, 耗时:0.01分/13.10分 | step: 508160 | performance: 35.5 | accuracy: 0.51 | loss: 2.58
update:1990/2000, 耗时:0.01分/13.13分 | step: 509440 | performance: 39.9 | accuracy: 0.51 | loss: 2.34
step: 509690 | worker_1@n_step_31: average total_reward after train data exhaustion : 143.1 | max total_reward: 276.7
update:1995/2000, 耗时:0.01分/13.16分 | step: 510720 | performance: 3.2 | accuracy: 0.50 | loss: 2.40
  0%|          | 0/406 [00:00<?, ?it/s]100%|| 406/406 [00:00<00:00, 101440.84it/s]
update:2000/2000, 耗时:0.01分/13.19分 | step: 512000 | performance: 0.6 | accuracy: 0.46 | loss: 2.72
----------------------------------------finished----------------------------------------
==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1285.10
2023-07-24T12:00:00 | net performance [%] = 28.5096
2023-07-24T12:00:00 | number of trades [#] = 132
==================================================
Trial 48 Complete [00h 13m 38s]
net_wealth: 1286.3826416708891

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 06h 31m 58s

Search: Running Trial #49

Value             |Best Value So Far |Hyperparameter
7                 |7                 |horizon
225               |730               |lookback
False             |False             |MarketFactor
3                 |14                |lags
0.95              |0.7               |gamma
32                |32                |batch_size
64                |32                |n_step
0.8               |0.92              |gae_lambda
1                 |0.1               |gradient_clip_norm
5                 |5                 |epochs
0.0001            |0.0001            |actor_lr
0.0005            |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4308.000000   4315.000000
mean      0.000441    20062.255222  ...   20144.178930  20118.633889
std       0.027818    16039.874230  ...   16077.649782  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7710.492310   7690.540039
50%       0.000642    11554.824463  ...   11744.425293  11715.610352
75%       0.011655    29873.081836  ...   29961.684570  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 04:35:21.154496: I tensorflow/core/p22023-07-20202l32-a037-07-28 -t2form80 /044c::35:3p5u_fe:2211..1541497:5a4 5t3I1ure_: g Iuten atrd.cesnsorflocr:14fol2]202 This Teow/cnsow38 04:35:21r.Flow 154/ore/bplati4-079fo6:-rm/cpu_f2narye8 0 atu4i:rcore35s:21 eo._15pgt4uimiz6ard.cc:13ed642] This TensorFlow bi: with   II  ttoeennsnosrorflfelAPI oow//cwplao/core/platform/crDeep Npe/peu_fluralaetaf Noretm/cpu_feanutawory irs krotptiu Lemiz_reiedbgua_ wgrarittry fh oonruedA.ar(m20d2.3-07-cc:2o2P/c0p142] 8nueDThis cNNc2_0f3 -07:)4TI:35 -1e2aetns4o2 u:t218]D o.e Trheis p F0low N4:3T21b iueenary iunrsa05e tl 4N923eh-er5e:_g ufar06ol7tw22-1:.l orko wsLor2ibiI rtFlaorenwg CP8Usns ins  b0or4t :3yoinafplrucr t(ooy winmisi optim154/ized wiz9eD8ceNdN.)cc tt3:1h4 2:ood neA]  usePIT  Dee5 Itohreti:p 2his o nN1eTe .s ensw1ithof5/ iononl509trF7loewAP Ip lDeienrpelaepn :g  Io forwC tbiteNemannfosuPUsorunorrafml/ry icsec ooa-wrcppr l Ntei/micitnwuaiztoor_ffleeoawt/idlrkr eu r/wiLt cNpcalesiob rtarworkt oryh (opner oerDaltucet_iaNNtifneAPI DLo)goeeoep itrou/mnas bp l/arduse Ntetuh.eccnsf oric :: m/rarfpn Au_fe Va14cXt aope2p]ryru (folr AlolmoNe twTrVaX2winohruenncgei-ksD
 c_rTfeTNeoN )e   taneo usCePisL_n attuirgtboicarlrbhaeFU  rluloaorpera dfw.ccol:y1 42t]ielo tonew i Tnhg s:i(io_nsbnhguarsied.CneDcNtaPm Ui Nricn:s14rny 2u c)  ott]i Tsh t htAiVoXoi ers   uns oTroupee raptcst iittAoeimizen iohVndn wispornFlow bXin2
earrfes yTetTfoo elnaor  iisnbmlhancs pe, lo oopn weAterrfePoIi b-uilDienrscomrFinlg eow db manTzceieCeerid wPni- ctthhnesm trUip aNicticor oal nrop eAiiPnIsen rota trDal ucthotpyieoFeiuroanl eleeow nrpa  rtNioens:iuwNs   oeptewrraoarls opAV:k  tL ioitXNiinstehbsmi ztht,  i reAewreVX o Aan pebruyr (r2dkap ildpVro
 TL iToe enosfonwnXith oanormrFabe lnoceDlAeV -eNXN)cbrwArtiat2p
T o r wiPcriteynablahl  I o oup(iteemo nieDDseenph  NaNtte Nce roe) etohmpu attitonhsee or us raheetohiel mt :i nphleeaep    NAeVX rf oflrfaotllp atgilroolto wAVhsewrioX.2

op rorianTnostge  wopiCn k,PU  rig CnPUecs t reurcbiunsaotemLpttniaillde Tiirorbiuocn senbnfl trisaoianslrer y, (o pterfgnFe DreolohsNrnmsa nicneNbo.
-cre)uild  w  Teptwmneitiith rocalsorf  in us ormeanct toehFel heappropriate compiler flags.
other operations, rebuild TensorFlow with the appropriate compiler flags.
-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler fow with the appropriate compiler flags.
lags.
 fperations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
ollowing CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 04:35:21.778505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:35:21.796029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:35:21.799873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:35:21.808312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:35:21.809484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:35:21.814097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:35:21.817467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:35:21.830244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.06分 | step:  2560 | performance: 0.3 | accuracy: 0.40 | loss: 2.30
update: 10/2000, 耗时:0.01分/0.11分 | step:  5120 | performance: 0.2 | accuracy: 0.38 | loss: 4.21
update: 15/2000, 耗时:0.01分/0.16分 | step:  7680 | performance: 7.2 | accuracy: 0.39 | loss: 4.94
update: 20/2000, 耗时:0.01分/0.22分 | step: 10240 | performance: 407.5 | accuracy: 0.43 | loss: 1.77
update: 25/2000, 耗时:0.01分/0.27分 | step: 12800 | performance: 136.0 | accuracy: 0.42 | loss: 4.48
update: 30/2000, 耗时:0.01分/0.33分 | step: 15360 | performance: 6.2 | accuracy: 0.41 | loss: 2.41
update: 35/2000, 耗时:0.01分/0.39分 | step: 17920 | performance: 8704.4 | accuracy: 0.44 | loss: 11.39
update: 40/2000, 耗时:0.01分/0.44分 | step: 20480 | performance: 57194.3 | accuracy: 0.44 | loss: 3.17
update: 45/2000, 耗时:0.01分/0.50分 | step: 23040 | performance: 85958.0 | accuracy: 0.44 | loss: 3.27
update: 50/2000, 耗时:0.01分/0.55分 | step: 25600 | performance: 155640.4 | accuracy: 0.44 | loss: 2.21
update: 55/2000, 耗时:0.01分/0.61分 | step: 28160 | performance: 3173784.3 | accuracy: 0.44 | loss: 2.03
Saving PPO weights in both H5 format and checkpoint @ update:58 
update: 60/2000, 耗时:0.01分/0.67分 | step: 30720 | performance: 0.3 | accuracy: 0.40 | loss: 3.74
update: 65/2000, 耗时:0.01分/0.72分 | step: 33280 | performance: 2.4 | accuracy: 0.44 | loss: 3.15
update: 70/2000, 耗时:0.01分/0.78分 | step: 35840 | performance: 53.8 | accuracy: 0.43 | loss: 2.08
update: 75/2000, 耗时:0.01分/0.83分 | step: 38400 | performance: 8204.2 | accuracy: 0.47 | loss: 8.17
update: 80/2000, 耗时:0.01分/0.88分 | step: 40960 | performance: 3495.6 | accuracy: 0.46 | loss: 4.79
update: 85/2000, 耗时:0.01分/0.94分 | step: 43520 | performance: 397.0 | accuracy: 0.44 | loss: 4.36
update: 90/2000, 耗时:0.01分/0.99分 | step: 46080 | performance: 163.4 | accuracy: 0.43 | loss: 1.85
update: 95/2000, 耗时:0.01分/1.03分 | step: 48640 | performance: 2335348.7 | accuracy: 0.47 | loss: 4.34
update:100/2000, 耗时:0.01分/1.09分 | step: 51200 | performance: 558781.9 | accuracy: 0.46 | loss: 2.31
update:105/2000, 耗时:0.01分/1.14分 | step: 53760 | performance: 432953.9 | accuracy: 0.46 | loss: 4.63
update:110/2000, 耗时:0.01分/1.19分 | step: 56320 | performance: 2642364.4 | accuracy: 0.45 | loss: 4.71
update:115/2000, 耗时:0.01分/1.24分 | step: 58880 | performance: 0.6 | accuracy: 0.00 | loss: 2.16
update:120/2000, 耗时:0.01分/1.30分 | step: 61440 | performance: 0.0 | accuracy: 0.44 | loss: 3.80
update:125/2000, 耗时:0.01分/1.35分 | step: 64000 | performance: 0.0 | accuracy: 0.42 | loss: 2.89
update:130/2000, 耗时:0.01分/1.40分 | step: 66560 | performance: 0.6 | accuracy: 0.44 | loss: 3.79
update:135/2000, 耗时:0.01分/1.46分 | step: 69120 | performance: 11.9 | accuracy: 0.47 | loss: 2.41
update:140/2000, 耗时:0.01分/1.51分 | step: 71680 | performance: 9.4 | accuracy: 0.46 | loss: 4.59
update:145/2000, 耗时:0.01分/1.56分 | step: 74240 | performance: 0.7 | accuracy: 0.45 | loss: 2.75
update:150/2000, 耗时:0.01分/1.62分 | step: 76800 | performance: 326.8 | accuracy: 0.47 | loss: 11.46
update:155/2000, 耗时:0.01分/1.67分 | step: 79360 | performance: 4746.5 | accuracy: 0.48 | loss: 5.38
update:160/2000, 耗时:0.01分/1.73分 | step: 81920 | performance: 2681.6 | accuracy: 0.48 | loss: 2.89
update:165/2000, 耗时:0.01分/1.78分 | step: 84480 | performance: 1927.4 | accuracy: 0.47 | loss: 3.16
update:170/2000, 耗时:0.01分/1.84分 | step: 87040 | performance: 40632.0 | accuracy: 0.47 | loss: 2.37
update:175/2000, 耗时:0.01分/1.89分 | step: 89600 | performance: 0.0 | accuracy: 0.40 | loss: 5.61
update:180/2000, 耗时:0.01分/1.95分 | step: 92160 | performance: 0.0 | accuracy: 0.43 | loss: 2.94
update:185/2000, 耗时:0.01分/2.00分 | step: 94720 | performance: 0.4 | accuracy: 0.44 | loss: 2.38
update:190/2000, 耗时:0.01分/2.06分 | step: 97280 | performance: 135.0 | accuracy: 0.48 | loss: 7.57
update:195/2000, 耗时:0.01分/2.12分 | step: 99840 | performance: 63.9 | accuracy: 0.48 | loss: 4.86
update:200/2000, 耗时:0.01分/2.17分 | step: 102400 | performance: 0.6 | accuracy: 0.46 | loss: 3.69
update:205/2000, 耗时:0.01分/2.22分 | step: 104960 | performance: 0.2 | accuracy: 0.45 | loss: 2.40
update:210/2000, 耗时:0.01分/2.28分 | step: 107520 | performance: 3081.1 | accuracy: 0.48 | loss: 4.19
update:215/2000, 耗时:0.01分/2.33分 | step: 110080 | performance: 1085.0 | accuracy: 0.47 | loss: 2.38
update:220/2000, 耗时:0.01分/2.39分 | step: 112640 | performance: 1698.0 | accuracy: 0.47 | loss: 5.33
update:225/2000, 耗时:0.01分/2.44分 | step: 115200 | performance: 28336.9 | accuracy: 0.47 | loss: 5.17
update:230/2000, 耗时:0.01分/2.50分 | step: 117760 | performance: 0.7 | accuracy: 0.25 | loss: 2.54
update:235/2000, 耗时:0.01分/2.55分 | step: 120320 | performance: 0.5 | accuracy: 0.45 | loss: 3.61
update:240/2000, 耗时:0.01分/2.60分 | step: 122880 | performance: 1.0 | accuracy: 0.44 | loss: 3.00
update:245/2000, 耗时:0.01分/2.66分 | step: 125440 | performance: 88.2 | accuracy: 0.47 | loss: 3.25
update:250/2000, 耗时:0.01分/2.72分 | step: 128000 | performance: 1487.8 | accuracy: 0.48 | loss: 2.04
update:255/2000, 耗时:0.01分/2.77分 | step: 130560 | performance: 1749.9 | accuracy: 0.48 | loss: 3.96
update:260/2000, 耗时:0.01分/2.83分 | step: 133120 | performance: 55.3 | accuracy: 0.46 | loss: 2.20
update:265/2000, 耗时:0.01分/2.89分 | step: 135680 | performance: 40249.6 | accuracy: 0.48 | loss: 11.25
update:270/2000, 耗时:0.01分/2.94分 | step: 138240 | performance: 427874.9 | accuracy: 0.48 | loss: 4.78
update:275/2000, 耗时:0.01分/3.00分 | step: 140800 | performance: 275418.7 | accuracy: 0.49 | loss: 2.78
update:280/2000, 耗时:0.01分/3.06分 | step: 143360 | performance: 2788133.5 | accuracy: 0.48 | loss: 3.78
update:285/2000, 耗时:0.01分/3.11分 | step: 145920 | performance: 80987543.2 | accuracy: 0.48 | loss: 2.25
update:290/2000, 耗时:0.01分/3.17分 | step: 148480 | performance: 0.1 | accuracy: 0.42 | loss: 5.92
update:295/2000, 耗时:0.01分/3.22分 | step: 151040 | performance: 0.3 | accuracy: 0.44 | loss: 2.42
update:300/2000, 耗时:0.01分/3.28分 | step: 153600 | performance: 6.8 | accuracy: 0.43 | loss: 2.26
update:305/2000, 耗时:0.01分/3.33分 | step: 156160 | performance: 972.8 | accuracy: 0.47 | loss: 6.36
update:310/2000, 耗时:0.01分/3.39分 | step: 158720 | performance: 976.5 | accuracy: 0.47 | loss: 5.16
update:315/2000, 耗时:0.01分/3.44分 | step: 161280 | performance: 45.5 | accuracy: 0.45 | loss: 3.66
update:320/2000, 耗时:0.01分/3.50分 | step: 163840 | performance: 22.9 | accuracy: 0.44 | loss: 1.81
update:325/2000, 耗时:0.01分/3.55分 | step: 166400 | performance: 55274.7 | accuracy: 0.47 | loss: 3.10
update:330/2000, 耗时:0.01分/3.61分 | step: 168960 | performance: 5116.6 | accuracy: 0.46 | loss: 1.99
update:335/2000, 耗时:0.01分/3.66分 | step: 171520 | performance: 22209.6 | accuracy: 0.46 | loss: 3.95
update:340/2000, 耗时:0.01分/3.71分 | step: 174080 | performance: 66832.6 | accuracy: 0.45 | loss: 4.33
update:345/2000, 耗时:0.01分/3.77分 | step: 176640 | performance: 0.2 | accuracy: 0.00 | loss: 3.08
update:350/2000, 耗时:0.01分/3.82分 | step: 179200 | performance: 0.2 | accuracy: 0.45 | loss: 3.88
update:355/2000, 耗时:0.01分/3.88分 | step: 181760 | performance: 0.3 | accuracy: 0.45 | loss: 2.77
update:360/2000, 耗时:0.01分/3.93分 | step: 184320 | performance: 26.2 | accuracy: 0.46 | loss: 2.94
update:365/2000, 耗时:0.01分/3.99分 | step: 186880 | performance: 103.2 | accuracy: 0.48 | loss: 2.60
update:370/2000, 耗时:0.01分/4.04分 | step: 189440 | performance: 171.4 | accuracy: 0.47 | loss: 3.15
update:375/2000, 耗时:0.01分/4.09分 | step: 192000 | performance: 23.8 | accuracy: 0.46 | loss: 2.48
update:380/2000, 耗时:0.01分/4.15分 | step: 194560 | performance: 3049.1 | accuracy: 0.47 | loss: 10.02
update:385/2000, 耗时:0.01分/4.20分 | step: 197120 | performance: 447974.0 | accuracy: 0.48 | loss: 4.22
update:390/2000, 耗时:0.01分/4.25分 | step: 199680 | performance: 81458.5 | accuracy: 0.48 | loss: 2.42
update:395/2000, 耗时:0.01分/4.31分 | step: 202240 | performance: 153082.0 | accuracy: 0.47 | loss: 3.50
update:400/2000, 耗时:0.01分/4.36分 | step: 204800 | performance: 1487898.2 | accuracy: 0.47 | loss: 2.03
update:405/2000, 耗时:0.01分/4.41分 | step: 207360 | performance: 0.1 | accuracy: 0.40 | loss: 4.13
update:410/2000, 耗时:0.01分/4.47分 | step: 209920 | performance: 0.1 | accuracy: 0.41 | loss: 2.58
update:415/2000, 耗时:0.01分/4.52分 | step: 212480 | performance: 2.5 | accuracy: 0.42 | loss: 2.05
update:420/2000, 耗时:0.01分/4.58分 | step: 215040 | performance: 149.0 | accuracy: 0.46 | loss: 5.77
update:425/2000, 耗时:0.01分/4.63分 | step: 217600 | performance: 546.8 | accuracy: 0.46 | loss: 5.15
update:430/2000, 耗时:0.01分/4.68分 | step: 220160 | performance: 48.8 | accuracy: 0.44 | loss: 3.40
update:435/2000, 耗时:0.01分/4.74分 | step: 222720 | performance: 27.6 | accuracy: 0.44 | loss: 2.24
update:440/2000, 耗时:0.01分/4.79分 | step: 225280 | performance: 132569.9 | accuracy: 0.47 | loss: 2.87
update:445/2000, 耗时:0.01分/4.85分 | step: 227840 | performance: 82673.9 | accuracy: 0.46 | loss: 2.20
update:450/2000, 耗时:0.01分/4.90分 | step: 230400 | performance: 256261.7 | accuracy: 0.46 | loss: 3.74
update:455/2000, 耗时:0.01分/4.95分 | step: 232960 | performance: 1126038.8 | accuracy: 0.46 | loss: 4.24
update:460/2000, 耗时:0.01分/5.01分 | step: 235520 | performance: 0.2 | accuracy: 0.00 | loss: 3.69
update:465/2000, 耗时:0.01分/5.06分 | step: 238080 | performance: 0.2 | accuracy: 0.44 | loss: 2.89
update:470/2000, 耗时:0.01分/5.12分 | step: 240640 | performance: 0.2 | accuracy: 0.42 | loss: 2.29
update:475/2000, 耗时:0.01分/5.17分 | step: 243200 | performance: 13.7 | accuracy: 0.44 | loss: 3.79
update:480/2000, 耗时:0.01分/5.22分 | step: 245760 | performance: 410.3 | accuracy: 0.47 | loss: 1.89
update:485/2000, 耗时:0.01分/5.28分 | step: 248320 | performance: 85.1 | accuracy: 0.46 | loss: 3.49
update:490/2000, 耗时:0.01分/5.33分 | step: 250880 | performance: 4.3 | accuracy: 0.45 | loss: 1.83
update:495/2000, 耗时:0.01分/5.39分 | step: 253440 | performance: 1221.6 | accuracy: 0.47 | loss: 10.08
update:500/2000, 耗时:0.01分/5.44分 | step: 256000 | performance: 149446.3 | accuracy: 0.47 | loss: 3.68
update:505/2000, 耗时:0.01分/5.50分 | step: 258560 | performance: 19839.8 | accuracy: 0.47 | loss: 2.57
update:510/2000, 耗时:0.01分/5.55分 | step: 261120 | performance: 70646.5 | accuracy: 0.46 | loss: 3.54
update:515/2000, 耗时:0.01分/5.61分 | step: 263680 | performance: 1674317.6 | accuracy: 0.45 | loss: 1.64
update:520/2000, 耗时:0.01分/5.66分 | step: 266240 | performance: 0.6 | accuracy: 0.44 | loss: 4.13
update:525/2000, 耗时:0.01分/5.71分 | step: 268800 | performance: 1.3 | accuracy: 0.42 | loss: 2.32
update:530/2000, 耗时:0.01分/5.77分 | step: 271360 | performance: 13.4 | accuracy: 0.41 | loss: 2.00
update:535/2000, 耗时:0.01分/5.82分 | step: 273920 | performance: 736.3 | accuracy: 0.44 | loss: 6.05
update:540/2000, 耗时:0.01分/5.88分 | step: 276480 | performance: 323.0 | accuracy: 0.44 | loss: 4.12
update:545/2000, 耗时:0.01分/5.93分 | step: 279040 | performance: 44.1 | accuracy: 0.43 | loss: 2.80
update:550/2000, 耗时:0.01分/5.98分 | step: 281600 | performance: 139.6 | accuracy: 0.44 | loss: 1.96
update:555/2000, 耗时:0.01分/6.04分 | step: 284160 | performance: 359643.4 | accuracy: 0.46 | loss: 3.29
update:560/2000, 耗时:0.01分/6.10分 | step: 286720 | performance: 107165.3 | accuracy: 0.46 | loss: 2.28
update:565/2000, 耗时:0.01分/6.15分 | step: 289280 | performance: 343190.2 | accuracy: 0.45 | loss: 3.28
update:570/2000, 耗时:0.01分/6.21分 | step: 291840 | performance: 612938.5 | accuracy: 0.44 | loss: 3.16
update:575/2000, 耗时:0.01分/6.26分 | step: 294400 | performance: 0.2 | accuracy: 0.20 | loss: 3.07
update:580/2000, 耗时:0.01分/6.32分 | step: 296960 | performance: 0.1 | accuracy: 0.40 | loss: 2.44
update:585/2000, 耗时:0.01分/6.37分 | step: 299520 | performance: 0.1 | accuracy: 0.36 | loss: 1.42
update:590/2000, 耗时:0.01分/6.42分 | step: 302080 | performance: 6.5 | accuracy: 0.38 | loss: 3.72
update:595/2000, 耗时:0.01分/6.48分 | step: 304640 | performance: 270.5 | accuracy: 0.41 | loss: 1.88
update:600/2000, 耗时:0.01分/6.53分 | step: 307200 | performance: 120.2 | accuracy: 0.40 | loss: 2.79
update:605/2000, 耗时:0.01分/6.59分 | step: 309760 | performance: 212.3 | accuracy: 0.40 | loss: 1.71
update:610/2000, 耗时:0.01分/6.64分 | step: 312320 | performance: 211952.3 | accuracy: 0.43 | loss: 9.14
update:615/2000, 耗时:0.01分/6.69分 | step: 314880 | performance: 4092428.0 | accuracy: 0.44 | loss: 2.52
update:620/2000, 耗时:0.01分/6.75分 | step: 317440 | performance: 2956040.6 | accuracy: 0.44 | loss: 2.67
update:625/2000, 耗时:0.01分/6.80分 | step: 320000 | performance: 24465775.8 | accuracy: 0.43 | loss: 2.62
update:630/2000, 耗时:0.01分/6.85分 | step: 322560 | performance: 424108852.3 | accuracy: 0.43 | loss: 1.48
update:635/2000, 耗时:0.01分/6.91分 | step: 325120 | performance: 0.4 | accuracy: 0.43 | loss: 3.56
update:640/2000, 耗时:0.01分/6.96分 | step: 327680 | performance: 0.4 | accuracy: 0.39 | loss: 1.78
update:645/2000, 耗时:0.01分/7.02分 | step: 330240 | performance: 20.6 | accuracy: 0.40 | loss: 1.88
update:650/2000, 耗时:0.01分/7.07分 | step: 332800 | performance: 1569.4 | accuracy: 0.43 | loss: 6.37
update:655/2000, 耗时:0.01分/7.12分 | step: 335360 | performance: 3739.5 | accuracy: 0.43 | loss: 3.00
update:660/2000, 耗时:0.01分/7.18分 | step: 337920 | performance: 484.0 | accuracy: 0.42 | loss: 2.75
update:665/2000, 耗时:0.01分/7.23分 | step: 340480 | performance: 119.0 | accuracy: 0.42 | loss: 2.24
update:670/2000, 耗时:0.01分/7.28分 | step: 343040 | performance: 90044.7 | accuracy: 0.44 | loss: 3.09
update:675/2000, 耗时:0.01分/7.34分 | step: 345600 | performance: 63453.2 | accuracy: 0.43 | loss: 2.40
update:680/2000, 耗时:0.01分/7.39分 | step: 348160 | performance: 260043.0 | accuracy: 0.43 | loss: 2.59
update:685/2000, 耗时:0.01分/7.45分 | step: 350720 | performance: 920724.6 | accuracy: 0.43 | loss: 2.65
update:690/2000, 耗时:0.01分/7.50分 | step: 353280 | performance: 0.3 | accuracy: 0.33 | loss: 3.15
update:695/2000, 耗时:0.01分/7.55分 | step: 355840 | performance: 0.2 | accuracy: 0.39 | loss: 2.46
update:700/2000, 耗时:0.01分/7.61分 | step: 358400 | performance: 0.1 | accuracy: 0.37 | loss: 1.58
update:705/2000, 耗时:0.01分/7.66分 | step: 360960 | performance: 0.8 | accuracy: 0.39 | loss: 3.84
update:710/2000, 耗时:0.01分/7.71分 | step: 363520 | performance: 39.1 | accuracy: 0.42 | loss: 2.13
update:715/2000, 耗时:0.01分/7.77分 | step: 366080 | performance: 28.7 | accuracy: 0.42 | loss: 3.05
update:720/2000, 耗时:0.01分/7.82分 | step: 368640 | performance: 51.9 | accuracy: 0.41 | loss: 1.81
update:725/2000, 耗时:0.01分/7.88分 | step: 371200 | performance: 16483.0 | accuracy: 0.44 | loss: 8.96
update:730/2000, 耗时:0.01分/7.94分 | step: 373760 | performance: 749358.2 | accuracy: 0.45 | loss: 2.85
update:735/2000, 耗时:0.01分/7.99分 | step: 376320 | performance: 170285.3 | accuracy: 0.45 | loss: 2.35
update:740/2000, 耗时:0.01分/8.04分 | step: 378880 | performance: 333452.0 | accuracy: 0.44 | loss: 2.34
update:745/2000, 耗时:0.01分/8.10分 | step: 381440 | performance: 1777483.3 | accuracy: 0.43 | loss: 1.53
update:750/2000, 耗时:0.01分/8.15分 | step: 384000 | performance: 0.1 | accuracy: 0.39 | loss: 3.74
update:755/2000, 耗时:0.01分/8.21分 | step: 386560 | performance: 0.2 | accuracy: 0.40 | loss: 2.68
update:760/2000, 耗时:0.01分/8.26分 | step: 389120 | performance: 2.2 | accuracy: 0.40 | loss: 1.95
update:765/2000, 耗时:0.01分/8.31分 | step: 391680 | performance: 115.5 | accuracy: 0.43 | loss: 5.87
update:770/2000, 耗时:0.01分/8.37分 | step: 394240 | performance: 77.9 | accuracy: 0.43 | loss: 3.46
update:775/2000, 耗时:0.01分/8.42分 | step: 396800 | performance: 44.8 | accuracy: 0.42 | loss: 2.21
update:780/2000, 耗时:0.01分/8.48分 | step: 399360 | performance: 51.1 | accuracy: 0.42 | loss: 2.31
update:785/2000, 耗时:0.01分/8.53分 | step: 401920 | performance: 107745.6 | accuracy: 0.45 | loss: 2.38
update:790/2000, 耗时:0.01分/8.58分 | step: 404480 | performance: 162673.1 | accuracy: 0.45 | loss: 2.53
update:795/2000, 耗时:0.01分/8.64分 | step: 407040 | performance: 409392.1 | accuracy: 0.44 | loss: 2.75
update:800/2000, 耗时:0.01分/8.69分 | step: 409600 | performance: 7003713.7 | accuracy: 0.44 | loss: 3.12
update:805/2000, 耗时:0.01分/8.75分 | step: 412160 | performance: 0.4 | accuracy: 0.36 | loss: 3.51
update:810/2000, 耗时:0.01分/8.81分 | step: 414720 | performance: 0.4 | accuracy: 0.42 | loss: 2.42
update:815/2000, 耗时:0.01分/8.86分 | step: 417280 | performance: 1.3 | accuracy: 0.43 | loss: 2.02
update:820/2000, 耗时:0.01分/8.92分 | step: 419840 | performance: 53.2 | accuracy: 0.44 | loss: 3.79
update:825/2000, 耗时:0.01分/8.98分 | step: 422400 | performance: 564.8 | accuracy: 0.46 | loss: 2.67
update:830/2000, 耗时:0.01分/9.03分 | step: 424960 | performance: 174.2 | accuracy: 0.44 | loss: 2.51
update:835/2000, 耗时:0.01分/9.09分 | step: 427520 | performance: 9.7 | accuracy: 0.43 | loss: 1.95
update:840/2000, 耗时:0.01分/9.15分 | step: 430080 | performance: 572.0 | accuracy: 0.45 | loss: 9.31
update:845/2000, 耗时:0.01分/9.20分 | step: 432640 | performance: 8461.4 | accuracy: 0.45 | loss: 3.36
update:850/2000, 耗时:0.01分/9.25分 | step: 435200 | performance: 9378.2 | accuracy: 0.45 | loss: 2.03
update:855/2000, 耗时:0.01分/9.31分 | step: 437760 | performance: 94679.6 | accuracy: 0.45 | loss: 2.78
update:860/2000, 耗时:0.01分/9.36分 | step: 440320 | performance: 505766.5 | accuracy: 0.44 | loss: 1.66
update:865/2000, 耗时:0.01分/9.41分 | step: 442880 | performance: 1.4 | accuracy: 0.42 | loss: 3.50
update:870/2000, 耗时:0.01分/9.47分 | step: 445440 | performance: 0.9 | accuracy: 0.40 | loss: 2.42
update:875/2000, 耗时:0.01分/9.52分 | step: 448000 | performance: 22.1 | accuracy: 0.40 | loss: 1.82
update:880/2000, 耗时:0.01分/9.58分 | step: 450560 | performance: 472.3 | accuracy: 0.43 | loss: 4.95
update:885/2000, 耗时:0.01分/9.63分 | step: 453120 | performance: 287.9 | accuracy: 0.43 | loss: 3.37
update:890/2000, 耗时:0.01分/9.68分 | step: 455680 | performance: 4.0 | accuracy: 0.41 | loss: 2.52
update:895/2000, 耗时:0.01分/9.74分 | step: 458240 | performance: 5.1 | accuracy: 0.41 | loss: 2.07
update:900/2000, 耗时:0.01分/9.79分 | step: 460800 | performance: 52444.9 | accuracy: 0.44 | loss: 2.42
update:905/2000, 耗时:0.01分/9.85分 | step: 463360 | performance: 65845.6 | accuracy: 0.44 | loss: 2.35
update:910/2000, 耗时:0.01分/9.90分 | step: 465920 | performance: 3187678.3 | accuracy: 0.44 | loss: 2.94
update:915/2000, 耗时:0.01分/9.95分 | step: 468480 | performance: 23949892.9 | accuracy: 0.44 | loss: 2.96
update:920/2000, 耗时:0.01分/10.01分 | step: 471040 | performance: 0.2 | accuracy: 0.44 | loss: 3.29
update:925/2000, 耗时:0.01分/10.06分 | step: 473600 | performance: 0.3 | accuracy: 0.41 | loss: 2.04
update:930/2000, 耗时:0.01分/10.11分 | step: 476160 | performance: 0.4 | accuracy: 0.38 | loss: 1.87
update:935/2000, 耗时:0.01分/10.17分 | step: 478720 | performance: 16.1 | accuracy: 0.40 | loss: 3.73
update:940/2000, 耗时:0.01分/10.22分 | step: 481280 | performance: 181.5 | accuracy: 0.43 | loss: 2.61
update:945/2000, 耗时:0.01分/10.28分 | step: 483840 | performance: 187.3 | accuracy: 0.43 | loss: 2.70
update:950/2000, 耗时:0.01分/10.33分 | step: 486400 | performance: 66.5 | accuracy: 0.42 | loss: 1.51
update:955/2000, 耗时:0.01分/10.39分 | step: 488960 | performance: 10187.9 | accuracy: 0.44 | loss: 9.28
update:960/2000, 耗时:0.01分/10.44分 | step: 491520 | performance: 25116.6 | accuracy: 0.44 | loss: 3.25
update:965/2000, 耗时:0.01分/10.49分 | step: 494080 | performance: 5777.6 | accuracy: 0.44 | loss: 2.40
update:970/2000, 耗时:0.01分/10.55分 | step: 496640 | performance: 25355.0 | accuracy: 0.44 | loss: 2.53
update:975/2000, 耗时:0.01分/10.60分 | step: 499200 | performance: 59392.1 | accuracy: 0.43 | loss: 1.55
update:980/2000, 耗时:0.01分/10.66分 | step: 501760 | performance: 0.2 | accuracy: 0.42 | loss: 3.29
update:985/2000, 耗时:0.01分/10.71分 | step: 504320 | performance: 0.1 | accuracy: 0.40 | loss: 2.49
update:990/2000, 耗时:0.01分/10.77分 | step: 506880 | performance: 2.7 | accuracy: 0.41 | loss: 1.94
update:995/2000, 耗时:0.01分/10.82分 | step: 509440 | performance: 20.3 | accuracy: 0.45 | loss: 6.02
update:1000/2000, 耗时:0.01分/10.88分 | step: 512000 | performance: 20.1 | accuracy: 0.45 | loss: 3.62
update:1005/2000, 耗时:0.01分/10.93分 | step: 514560 | performance: 4.7 | accuracy: 0.43 | loss: 2.25
update:1010/2000, 耗时:0.01分/10.99分 | step: 517120 | performance: 2.3 | accuracy: 0.43 | loss: 1.68
update:1015/2000, 耗时:0.01分/11.04分 | step: 519680 | performance: 1234.9 | accuracy: 0.45 | loss: 2.51
update:1020/2000, 耗时:0.01分/11.10分 | step: 522240 | performance: 1445.6 | accuracy: 0.45 | loss: 2.28
update:1025/2000, 耗时:0.01分/11.15分 | step: 524800 | performance: 3881.9 | accuracy: 0.45 | loss: 2.74
update:1030/2000, 耗时:0.01分/11.21分 | step: 527360 | performance: 19167.5 | accuracy: 0.44 | loss: 2.78
update:1035/2000, 耗时:0.01分/11.26分 | step: 529920 | performance: 0.2 | accuracy: 0.39 | loss: 3.44
update:1040/2000, 耗时:0.01分/11.32分 | step: 532480 | performance: 0.1 | accuracy: 0.42 | loss: 2.28
update:1045/2000, 耗时:0.01分/11.37分 | step: 535040 | performance: 1.0 | accuracy: 0.42 | loss: 1.81
update:1050/2000, 耗时:0.01分/11.43分 | step: 537600 | performance: 30.9 | accuracy: 0.44 | loss: 3.87
update:1055/2000, 耗时:0.01分/11.48分 | step: 540160 | performance: 635.4 | accuracy: 0.46 | loss: 1.99
update:1060/2000, 耗时:0.01分/11.53分 | step: 542720 | performance: 667.0 | accuracy: 0.45 | loss: 2.42
update:1065/2000, 耗时:0.01分/11.59分 | step: 545280 | performance: 318.6 | accuracy: 0.45 | loss: 1.53
update:1070/2000, 耗时:0.01分/11.64分 | step: 547840 | performance: 31080.0 | accuracy: 0.46 | loss: 9.61
update:1075/2000, 耗时:0.01分/11.70分 | step: 550400 | performance: 718731.4 | accuracy: 0.47 | loss: 3.20
update:1080/2000, 耗时:0.01分/11.75分 | step: 552960 | performance: 112333.3 | accuracy: 0.46 | loss: 2.41
update:1085/2000, 耗时:0.01分/11.80分 | step: 555520 | performance: 307967.7 | accuracy: 0.45 | loss: 2.40
update:1090/2000, 耗时:0.01分/11.86分 | step: 558080 | performance: 447284.5 | accuracy: 0.45 | loss: 1.82
update:1095/2000, 耗时:0.01分/11.91分 | step: 560640 | performance: 0.7 | accuracy: 0.42 | loss: 2.73
update:1100/2000, 耗时:0.01分/11.97分 | step: 563200 | performance: 4.4 | accuracy: 0.41 | loss: 2.32
update:1105/2000, 耗时:0.01分/12.02分 | step: 565760 | performance: 70.1 | accuracy: 0.41 | loss: 1.70
update:1110/2000, 耗时:0.01分/12.07分 | step: 568320 | performance: 8294.1 | accuracy: 0.45 | loss: 5.91
update:1115/2000, 耗时:0.01分/12.13分 | step: 570880 | performance: 2706.3 | accuracy: 0.44 | loss: 2.78
update:1120/2000, 耗时:0.01分/12.18分 | step: 573440 | performance: 41.2 | accuracy: 0.42 | loss: 2.03
update:1125/2000, 耗时:0.01分/12.24分 | step: 576000 | performance: 4.9 | accuracy: 0.42 | loss: 2.05
update:1130/2000, 耗时:0.01分/12.29分 | step: 578560 | performance: 2378.6 | accuracy: 0.44 | loss: 2.55
update:1135/2000, 耗时:0.01分/12.34分 | step: 581120 | performance: 5476.2 | accuracy: 0.43 | loss: 2.23
update:1140/2000, 耗时:0.01分/12.40分 | step: 583680 | performance: 25481.5 | accuracy: 0.43 | loss: 2.53
update:1145/2000, 耗时:0.01分/12.45分 | step: 586240 | performance: 254397.3 | accuracy: 0.43 | loss: 2.49
update:1150/2000, 耗时:0.01分/12.51分 | step: 588800 | performance: 0.2 | accuracy: 0.40 | loss: 3.37
update:1155/2000, 耗时:0.01分/12.56分 | step: 591360 | performance: 0.3 | accuracy: 0.40 | loss: 1.85
update:1160/2000, 耗时:0.01分/12.62分 | step: 593920 | performance: 0.6 | accuracy: 0.38 | loss: 1.74
update:1165/2000, 耗时:0.01分/12.67分 | step: 596480 | performance: 33.4 | accuracy: 0.41 | loss: 4.08
update:1170/2000, 耗时:0.01分/12.73分 | step: 599040 | performance: 1349.1 | accuracy: 0.42 | loss: 1.59
update:1175/2000, 耗时:0.01分/12.78分 | step: 601600 | performance: 550.3 | accuracy: 0.42 | loss: 2.91
update:1180/2000, 耗时:0.01分/12.84分 | step: 604160 | performance: 226.6 | accuracy: 0.41 | loss: 1.53
update:1185/2000, 耗时:0.01分/12.89分 | step: 606720 | performance: 8459.5 | accuracy: 0.43 | loss: 8.64
update:1190/2000, 耗时:0.01分/12.95分 | step: 609280 | performance: 119470.7 | accuracy: 0.43 | loss: 2.68
update:1195/2000, 耗时:0.01分/13.00分 | step: 611840 | performance: 127573.0 | accuracy: 0.43 | loss: 2.15
update:1200/2000, 耗时:0.01分/13.06分 | step: 614400 | performance: 544252.2 | accuracy: 0.42 | loss: 1.78
update:1205/2000, 耗时:0.01分/13.11分 | step: 616960 | performance: 1771047.3 | accuracy: 0.42 | loss: 1.34
update:1210/2000, 耗时:0.01分/13.16分 | step: 619520 | performance: 0.1 | accuracy: 0.34 | loss: 2.51
update:1215/2000, 耗时:0.01分/13.22分 | step: 622080 | performance: 0.1 | accuracy: 0.37 | loss: 1.60
update:1220/2000, 耗时:0.01分/13.27分 | step: 624640 | performance: 1.2 | accuracy: 0.38 | loss: 1.53
update:1225/2000, 耗时:0.01分/13.33分 | step: 627200 | performance: 30.4 | accuracy: 0.42 | loss: 5.88
update:1230/2000, 耗时:0.01分/13.38分 | step: 629760 | performance: 38.9 | accuracy: 0.41 | loss: 2.97
update:1235/2000, 耗时:0.01分/13.43分 | step: 632320 | performance: 0.2 | accuracy: 0.39 | loss: 1.62
update:1240/2000, 耗时:0.01分/13.49分 | step: 634880 | performance: 0.1 | accuracy: 0.39 | loss: 2.64
update:1245/2000, 耗时:0.01分/13.54分 | step: 637440 | performance: 43.1 | accuracy: 0.42 | loss: 2.04
update:1250/2000, 耗时:0.01分/13.60分 | step: 640000 | performance: 8.6 | accuracy: 0.41 | loss: 2.18
update:1255/2000, 耗时:0.01分/13.65分 | step: 642560 | performance: 9.6 | accuracy: 0.41 | loss: 2.82
update:1260/2000, 耗时:0.01分/13.70分 | step: 645120 | performance: 99.2 | accuracy: 0.41 | loss: 2.27
update:1265/2000, 耗时:0.01分/13.75分 | step: 647680 | performance: 0.1 | accuracy: 0.36 | loss: 3.41
update:1270/2000, 耗时:0.01分/13.81分 | step: 650240 | performance: 1.5 | accuracy: 0.40 | loss: 1.84
update:1275/2000, 耗时:0.01分/13.86分 | step: 652800 | performance: 2.9 | accuracy: 0.39 | loss: 1.40
update:1280/2000, 耗时:0.01分/13.92分 | step: 655360 | performance: 13.8 | accuracy: 0.40 | loss: 3.54
update:1285/2000, 耗时:0.01分/13.97分 | step: 657920 | performance: 79.5 | accuracy: 0.42 | loss: 1.62
update:1290/2000, 耗时:0.01分/14.03分 | step: 660480 | performance: 16.9 | accuracy: 0.41 | loss: 2.61
update:1295/2000, 耗时:0.01分/14.08分 | step: 663040 | performance: 6.3 | accuracy: 0.40 | loss: 1.76
update:1300/2000, 耗时:0.01分/14.14分 | step: 665600 | performance: 176.8 | accuracy: 0.42 | loss: 8.52
update:1305/2000, 耗时:0.01分/14.19分 | step: 668160 | performance: 1172.0 | accuracy: 0.42 | loss: 2.86
update:1310/2000, 耗时:0.01分/14.25分 | step: 670720 | performance: 1510.5 | accuracy: 0.42 | loss: 1.89
update:1315/2000, 耗时:0.01分/14.30分 | step: 673280 | performance: 2120.6 | accuracy: 0.42 | loss: 1.77
update:1320/2000, 耗时:0.01分/14.36分 | step: 675840 | performance: 3265.1 | accuracy: 0.41 | loss: 1.92
update:1325/2000, 耗时:0.01分/14.41分 | step: 678400 | performance: 0.0 | accuracy: 0.35 | loss: 2.19
update:1330/2000, 耗时:0.01分/14.47分 | step: 680960 | performance: 0.0 | accuracy: 0.36 | loss: 1.99
update:1335/2000, 耗时:0.01分/14.52分 | step: 683520 | performance: 0.8 | accuracy: 0.36 | loss: 1.44
update:1340/2000, 耗时:0.01分/14.58分 | step: 686080 | performance: 39.6 | accuracy: 0.41 | loss: 4.77
update:1345/2000, 耗时:0.01分/14.63分 | step: 688640 | performance: 14.5 | accuracy: 0.41 | loss: 2.89
update:1350/2000, 耗时:0.01分/14.69分 | step: 691200 | performance: 1.0 | accuracy: 0.41 | loss: 1.81
update:1355/2000, 耗时:0.01分/14.75分 | step: 693760 | performance: 4.0 | accuracy: 0.42 | loss: 2.35
update:1360/2000, 耗时:0.01分/14.80分 | step: 696320 | performance: 148.3 | accuracy: 0.43 | loss: 2.39
update:1365/2000, 耗时:0.01分/14.86分 | step: 698880 | performance: 188.5 | accuracy: 0.43 | loss: 1.96
update:1370/2000, 耗时:0.01分/14.92分 | step: 701440 | performance: 358.3 | accuracy: 0.43 | loss: 2.66
update:1375/2000, 耗时:0.01分/14.97分 | step: 704000 | performance: 2329.8 | accuracy: 0.42 | loss: 1.91
update:1380/2000, 耗时:0.01分/15.03分 | step: 706560 | performance: 0.1 | accuracy: 0.29 | loss: 3.35
update:1385/2000, 耗时:0.01分/15.09分 | step: 709120 | performance: 0.0 | accuracy: 0.39 | loss: 2.01
update:1390/2000, 耗时:0.01分/15.14分 | step: 711680 | performance: 0.2 | accuracy: 0.39 | loss: 1.46
update:1395/2000, 耗时:0.01分/15.20分 | step: 714240 | performance: 4.2 | accuracy: 0.40 | loss: 3.85
update:1400/2000, 耗时:0.01分/15.25分 | step: 716800 | performance: 143.0 | accuracy: 0.42 | loss: 1.64
update:1405/2000, 耗时:0.01分/15.31分 | step: 719360 | performance: 45.2 | accuracy: 0.41 | loss: 2.62
update:1410/2000, 耗时:0.01分/15.36分 | step: 721920 | performance: 1.1 | accuracy: 0.40 | loss: 1.57
update:1415/2000, 耗时:0.01分/15.41分 | step: 724480 | performance: 29.7 | accuracy: 0.41 | loss: 8.39
update:1420/2000, 耗时:0.01分/15.47分 | step: 727040 | performance: 357.5 | accuracy: 0.42 | loss: 2.58
update:1425/2000, 耗时:0.01分/15.52分 | step: 729600 | performance: 237.7 | accuracy: 0.42 | loss: 2.33
update:1430/2000, 耗时:0.01分/15.58分 | step: 732160 | performance: 1016.3 | accuracy: 0.41 | loss: 2.57
update:1435/2000, 耗时:0.01分/15.63分 | step: 734720 | performance: 5410.2 | accuracy: 0.41 | loss: 2.05
update:1440/2000, 耗时:0.01分/15.68分 | step: 737280 | performance: 0.0 | accuracy: 0.38 | loss: 2.17
update:1445/2000, 耗时:0.01分/15.74分 | step: 739840 | performance: 0.0 | accuracy: 0.38 | loss: 2.09
update:1450/2000, 耗时:0.01分/15.79分 | step: 742400 | performance: 0.5 | accuracy: 0.40 | loss: 1.74
update:1455/2000, 耗时:0.01分/15.85分 | step: 744960 | performance: 37.6 | accuracy: 0.44 | loss: 6.08
update:1460/2000, 耗时:0.01分/15.90分 | step: 747520 | performance: 55.8 | accuracy: 0.43 | loss: 2.40
update:1465/2000, 耗时:0.01分/15.95分 | step: 750080 | performance: 2.2 | accuracy: 0.42 | loss: 1.62
update:1470/2000, 耗时:0.01分/16.01分 | step: 752640 | performance: 13.9 | accuracy: 0.43 | loss: 3.01
update:1475/2000, 耗时:0.01分/16.06分 | step: 755200 | performance: 887.2 | accuracy: 0.44 | loss: 2.13
update:1480/2000, 耗时:0.01分/16.11分 | step: 757760 | performance: 133.2 | accuracy: 0.43 | loss: 2.83
update:1485/2000, 耗时:0.01分/16.17分 | step: 760320 | performance: 443.8 | accuracy: 0.43 | loss: 2.42
update:1490/2000, 耗时:0.01分/16.22分 | step: 762880 | performance: 692.0 | accuracy: 0.42 | loss: 2.00
update:1495/2000, 耗时:0.01分/16.27分 | step: 765440 | performance: 0.2 | accuracy: 0.38 | loss: 3.43
update:1500/2000, 耗时:0.01分/16.33分 | step: 768000 | performance: 0.1 | accuracy: 0.37 | loss: 1.92
update:1505/2000, 耗时:0.01分/16.38分 | step: 770560 | performance: 0.1 | accuracy: 0.36 | loss: 1.50
update:1510/2000, 耗时:0.01分/16.44分 | step: 773120 | performance: 0.7 | accuracy: 0.37 | loss: 3.87
update:1515/2000, 耗时:0.01分/16.49分 | step: 775680 | performance: 2.4 | accuracy: 0.39 | loss: 1.39
update:1520/2000, 耗时:0.01分/16.54分 | step: 778240 | performance: 2.6 | accuracy: 0.39 | loss: 2.68
update:1525/2000, 耗时:0.01分/16.60分 | step: 780800 | performance: 0.2 | accuracy: 0.38 | loss: 1.66
update:1530/2000, 耗时:0.01分/16.65分 | step: 783360 | performance: 31.7 | accuracy: 0.41 | loss: 8.18
update:1535/2000, 耗时:0.01分/16.71分 | step: 785920 | performance: 716.7 | accuracy: 0.41 | loss: 2.31
update:1540/2000, 耗时:0.01分/16.76分 | step: 788480 | performance: 202.7 | accuracy: 0.41 | loss: 2.13
update:1545/2000, 耗时:0.01分/16.82分 | step: 791040 | performance: 425.2 | accuracy: 0.40 | loss: 1.80
update:1550/2000, 耗时:0.01分/16.87分 | step: 793600 | performance: 813.9 | accuracy: 0.40 | loss: 1.31
update:1555/2000, 耗时:0.01分/16.92分 | step: 796160 | performance: 0.0 | accuracy: 0.31 | loss: 2.14
update:1560/2000, 耗时:0.01分/16.98分 | step: 798720 | performance: 0.0 | accuracy: 0.34 | loss: 1.38
update:1565/2000, 耗时:0.01分/17.03分 | step: 801280 | performance: 0.3 | accuracy: 0.33 | loss: 1.05
update:1570/2000, 耗时:0.01分/17.09分 | step: 803840 | performance: 4.7 | accuracy: 0.37 | loss: 6.34
update:1575/2000, 耗时:0.01分/17.14分 | step: 806400 | performance: 2.6 | accuracy: 0.36 | loss: 1.52
update:1580/2000, 耗时:0.01分/17.19分 | step: 808960 | performance: 4.7 | accuracy: 0.36 | loss: 1.43
update:1585/2000, 耗时:0.01分/17.25分 | step: 811520 | performance: 11.3 | accuracy: 0.36 | loss: 2.99
update:1590/2000, 耗时:0.01分/17.30分 | step: 814080 | performance: 2260.6 | accuracy: 0.39 | loss: 2.10
update:1595/2000, 耗时:0.01分/17.35分 | step: 816640 | performance: 5751.4 | accuracy: 0.39 | loss: 2.15
update:1600/2000, 耗时:0.01分/17.41分 | step: 819200 | performance: 5564.3 | accuracy: 0.39 | loss: 2.13
update:1605/2000, 耗时:0.01分/17.46分 | step: 821760 | performance: 8231.2 | accuracy: 0.38 | loss: 1.36
update:1610/2000, 耗时:0.01分/17.52分 | step: 824320 | performance: 0.4 | accuracy: 0.46 | loss: 3.30
update:1615/2000, 耗时:0.01分/17.57分 | step: 826880 | performance: 0.1 | accuracy: 0.33 | loss: 1.79
update:1620/2000, 耗时:0.01分/17.62分 | step: 829440 | performance: 0.1 | accuracy: 0.29 | loss: 1.29
update:1625/2000, 耗时:0.01分/17.68分 | step: 832000 | performance: 1.7 | accuracy: 0.33 | loss: 3.97
update:1630/2000, 耗时:0.01分/17.73分 | step: 834560 | performance: 15.3 | accuracy: 0.36 | loss: 1.37
update:1635/2000, 耗时:0.01分/17.78分 | step: 837120 | performance: 13.0 | accuracy: 0.36 | loss: 2.83
update:1640/2000, 耗时:0.01分/17.83分 | step: 839680 | performance: 5.9 | accuracy: 0.36 | loss: 1.65
update:1645/2000, 耗时:0.01分/17.89分 | step: 842240 | performance: 311.9 | accuracy: 0.38 | loss: 7.96
update:1650/2000, 耗时:0.01分/17.94分 | step: 844800 | performance: 1061.1 | accuracy: 0.38 | loss: 1.74
update:1655/2000, 耗时:0.01分/17.99分 | step: 847360 | performance: 249.8 | accuracy: 0.39 | loss: 1.84
update:1660/2000, 耗时:0.01分/18.05分 | step: 849920 | performance: 792.2 | accuracy: 0.38 | loss: 1.41
update:1665/2000, 耗时:0.01分/18.10分 | step: 852480 | performance: 4925.3 | accuracy: 0.38 | loss: 1.36
update:1670/2000, 耗时:0.01分/18.15分 | step: 855040 | performance: 2.2 | accuracy: 0.42 | loss: 2.59
update:1675/2000, 耗时:0.01分/18.21分 | step: 857600 | performance: 0.8 | accuracy: 0.33 | loss: 1.98
update:1680/2000, 耗时:0.01分/18.26分 | step: 860160 | performance: 19.2 | accuracy: 0.35 | loss: 1.25
update:1685/2000, 耗时:0.01分/18.31分 | step: 862720 | performance: 402.0 | accuracy: 0.39 | loss: 5.68
update:1690/2000, 耗时:0.01分/18.36分 | step: 865280 | performance: 1238.2 | accuracy: 0.39 | loss: 1.71
update:1695/2000, 耗时:0.01分/18.42分 | step: 867840 | performance: 153.5 | accuracy: 0.38 | loss: 1.67
update:1700/2000, 耗时:0.01分/18.47分 | step: 870400 | performance: 543.4 | accuracy: 0.39 | loss: 2.36
update:1705/2000, 耗时:0.01分/18.52分 | step: 872960 | performance: 93509.4 | accuracy: 0.42 | loss: 2.17
update:1710/2000, 耗时:0.01分/18.58分 | step: 875520 | performance: 35595.4 | accuracy: 0.41 | loss: 1.72
update:1715/2000, 耗时:0.01分/18.63分 | step: 878080 | performance: 328886.7 | accuracy: 0.41 | loss: 1.97
update:1720/2000, 耗时:0.01分/18.69分 | step: 880640 | performance: 396907.5 | accuracy: 0.40 | loss: 1.67
update:1725/2000, 耗时:0.01分/18.74分 | step: 883200 | performance: 0.7 | accuracy: 0.50 | loss: 2.79
update:1730/2000, 耗时:0.01分/18.79分 | step: 885760 | performance: 0.4 | accuracy: 0.37 | loss: 1.97
update:1735/2000, 耗时:0.01分/18.85分 | step: 888320 | performance: 0.1 | accuracy: 0.33 | loss: 1.62
update:1740/2000, 耗时:0.01分/18.90分 | step: 890880 | performance: 0.6 | accuracy: 0.35 | loss: 4.34
update:1745/2000, 耗时:0.01分/18.95分 | step: 893440 | performance: 10.5 | accuracy: 0.38 | loss: 1.56
update:1750/2000, 耗时:0.01分/19.01分 | step: 896000 | performance: 4.9 | accuracy: 0.38 | loss: 2.87
update:1755/2000, 耗时:0.01分/19.06分 | step: 898560 | performance: 1.1 | accuracy: 0.37 | loss: 1.41
update:1760/2000, 耗时:0.01分/19.11分 | step: 901120 | performance: 62.5 | accuracy: 0.38 | loss: 6.21
update:1765/2000, 耗时:0.01分/19.17分 | step: 903680 | performance: 386.4 | accuracy: 0.38 | loss: 2.20
update:1770/2000, 耗时:0.01分/19.22分 | step: 906240 | performance: 359.8 | accuracy: 0.39 | loss: 1.55
update:1775/2000, 耗时:0.01分/19.27分 | step: 908800 | performance: 1113.1 | accuracy: 0.38 | loss: 1.64
update:1780/2000, 耗时:0.01分/19.33分 | step: 911360 | performance: 2874.9 | accuracy: 0.38 | loss: 1.52
update:1785/2000, 耗时:0.01分/19.38分 | step: 913920 | performance: 0.5 | accuracy: 0.39 | loss: 2.02
update:1790/2000, 耗时:0.01分/19.43分 | step: 916480 | performance: 0.8 | accuracy: 0.36 | loss: 1.67
update:1795/2000, 耗时:0.01分/19.49分 | step: 919040 | performance: 3.4 | accuracy: 0.36 | loss: 1.30
update:1800/2000, 耗时:0.01分/19.54分 | step: 921600 | performance: 101.4 | accuracy: 0.39 | loss: 4.54
update:1805/2000, 耗时:0.01分/19.59分 | step: 924160 | performance: 136.5 | accuracy: 0.39 | loss: 1.83
update:1810/2000, 耗时:0.01分/19.65分 | step: 926720 | performance: 24.1 | accuracy: 0.38 | loss: 1.20
update:1815/2000, 耗时:0.01分/19.71分 | step: 929280 | performance: 45.1 | accuracy: 0.38 | loss: 2.17
update:1820/2000, 耗时:0.01分/19.76分 | step: 931840 | performance: 37335.9 | accuracy: 0.40 | loss: 2.06
update:1825/2000, 耗时:0.01分/19.82分 | step: 934400 | performance: 77429.2 | accuracy: 0.40 | loss: 1.83
update:1830/2000, 耗时:0.01分/19.87分 | step: 936960 | performance: 162952.6 | accuracy: 0.39 | loss: 1.73
update:1835/2000, 耗时:0.01分/19.93分 | step: 939520 | performance: 905383.5 | accuracy: 0.39 | loss: 1.40
update:1840/2000, 耗时:0.01分/19.99分 | step: 942080 | performance: 0.2 | accuracy: 0.34 | loss: 3.09
update:1845/2000, 耗时:0.01分/20.04分 | step: 944640 | performance: 1.7 | accuracy: 0.39 | loss: 1.55
update:1850/2000, 耗时:0.01分/20.10分 | step: 947200 | performance: 8.3 | accuracy: 0.35 | loss: 1.87
update:1855/2000, 耗时:0.01分/20.15分 | step: 949760 | performance: 83.9 | accuracy: 0.36 | loss: 3.49
update:1860/2000, 耗时:0.01分/20.21分 | step: 952320 | performance: 1131.9 | accuracy: 0.38 | loss: 1.27
update:1865/2000, 耗时:0.01分/20.26分 | step: 954880 | performance: 253.9 | accuracy: 0.36 | loss: 3.65
update:1870/2000, 耗时:0.01分/20.31分 | step: 957440 | performance: 77.9 | accuracy: 0.36 | loss: 1.52
update:1875/2000, 耗时:0.01分/20.37分 | step: 960000 | performance: 2086.7 | accuracy: 0.38 | loss: 6.45
update:1880/2000, 耗时:0.01分/20.42分 | step: 962560 | performance: 18483.9 | accuracy: 0.39 | loss: 1.79
update:1885/2000, 耗时:0.01分/20.48分 | step: 965120 | performance: 8658.0 | accuracy: 0.38 | loss: 1.76
update:1890/2000, 耗时:0.01分/20.53分 | step: 967680 | performance: 7686.3 | accuracy: 0.38 | loss: 1.42
update:1895/2000, 耗时:0.01分/20.58分 | step: 970240 | performance: 21730.3 | accuracy: 0.38 | loss: 1.21
update:1900/2000, 耗时:0.01分/20.64分 | step: 972800 | performance: 0.3 | accuracy: 0.34 | loss: 1.85
update:1905/2000, 耗时:0.01分/20.69分 | step: 975360 | performance: 0.4 | accuracy: 0.34 | loss: 1.58
update:1910/2000, 耗时:0.01分/20.75分 | step: 977920 | performance: 3.0 | accuracy: 0.36 | loss: 1.47
update:1915/2000, 耗时:0.01分/20.81分 | step: 980480 | performance: 68.0 | accuracy: 0.39 | loss: 5.02
update:1920/2000, 耗时:0.01分/20.86分 | step: 983040 | performance: 53.3 | accuracy: 0.38 | loss: 1.77
update:1925/2000, 耗时:0.01分/20.92分 | step: 985600 | performance: 26.7 | accuracy: 0.37 | loss: 1.51
update:1930/2000, 耗时:0.01分/20.97分 | step: 988160 | performance: 59.3 | accuracy: 0.37 | loss: 2.46
update:1935/2000, 耗时:0.01分/21.03分 | step: 990720 | performance: 14553.1 | accuracy: 0.39 | loss: 2.07
update:1940/2000, 耗时:0.01分/21.09分 | step: 993280 | performance: 6453.5 | accuracy: 0.38 | loss: 1.63
update:1945/2000, 耗时:0.01分/21.15分 | step: 995840 | performance: 10472.0 | accuracy: 0.38 | loss: 1.60
update:1950/2000, 耗时:0.01分/21.20分 | step: 998400 | performance: 38275.4 | accuracy: 0.37 | loss: 1.72
update:1955/2000, 耗时:0.01分/21.25分 | step: 1000960 | performance: 0.6 | accuracy: 0.50 | loss: 3.22
update:1960/2000, 耗时:0.01分/21.31分 | step: 1003520 | performance: 0.1 | accuracy: 0.33 | loss: 1.56
update:1965/2000, 耗时:0.01分/21.36分 | step: 1006080 | performance: 0.0 | accuracy: 0.30 | loss: 1.86
update:1970/2000, 耗时:0.01分/21.41分 | step: 1008640 | performance: 0.2 | accuracy: 0.33 | loss: 3.14
update:1975/2000, 耗时:0.01分/21.47分 | step: 1011200 | performance: 1.7 | accuracy: 0.35 | loss: 1.14
update:1980/2000, 耗时:0.01分/21.52分 | step: 1013760 | performance: 1.0 | accuracy: 0.35 | loss: 2.45
update:1985/2000, 耗时:0.01分/21.57分 | step: 1016320 | performance: 0.6 | accuracy: 0.34 | loss: 1.54
update:1990/2000, 耗时:0.01分/21.63分 | step: 1018880 | performance: 80.8 | accuracy: 0.37 | loss: 6.35
update:1995/2000, 耗时:0.01分/21.68分 | step: 1021440 | performance: 129.7 | accuracy: 0.37 | loss: 1.67
  0%|          | 0/408 [00:00<?, ?it/s]100%|| 408/408 [00:00<00:00, 101855.61it/s]
update:2000/2000, 耗时:0.01分/21.73分 | step: 1024000 | performance: 49.2 | accuracy: 0.37 | loss: 1.76
----------------------------------------finished----------------------------------------
==================================================
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1084.85
2023-07-24T12:00:00 | net performance [%] = 8.4850
2023-07-24T12:00:00 | number of trades [#] = 104
==================================================
Trial 49 Complete [00h 22m 10s]
net_wealth: 1084.8503406449195

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 06h 54m 08s

Search: Running Trial #50

Value             |Best Value So Far |Hyperparameter
5                 |7                 |horizon
730               |730               |lookback
False             |False             |MarketFactor
5                 |14                |lags
0.8               |0.7               |gamma
16                |32                |batch_size
32                |32                |n_step
0.96              |0.92              |gae_lambda
0.5               |0.1               |gradient_clip_norm
3                 |5                 |epochs
0.0005            |0.0001            |actor_lr
1e-05             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4310.000000   4315.000000
mean      0.000441    20062.255222  ...   20136.939364  20118.633889
std       0.027818    16039.874230  ...   16077.430342  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7696.969971   7690.540039
50%       0.000642    11554.824463  ...   11742.710449  11715.610352
75%       0.011655    29873.081836  ...   29945.211914  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 04:57:31.901567: 2023-07-28 04:57:31.2023-07-28 04:57:31.901600: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in I901586: other opert I taensteioonrfs,2023-07-low/c2n0sorflow/core/platform/2 3-207-8 reb228 04:570c:pu_feature_guardu31.ild ccTo2r3-07-ee04/p:latf218 04::54527]7:31: T3.h9011is T.801: I tenso9.rflo9ensorFl0w1/nsorFlocorewo0177/1orm/c :wp iItu ht t_ehfneea staouprflrp742: I tensorflow/core/platform/cpu_featuwow/corprop labree_/gpreiuinataratl_atefo2r0mryf2 co gi/ucmopaiplerr2us_f02e rd. ofdccplags.m:/cti1.4c
c:21apt4m2i]]uzed w  Tu_featuhre_Triet_hgugi3hisar 3-s T-07u- 2T8a ens0r4d:.ocrFlowcd.cc::1421e ]4nb 2]siT onhTraihFrsily so Tensi wosTe r nosptimbFlow binar5inary7oo ne:riAsPI Deep Neural  o0Flow binary73-1Ne.ptimized ized with oneAPI Deep Neural Network Librtwork Library (902029: oneDNN) toary (oneDNN use the follow)2 t8 0o  isu4sy Iis ope :57i n:gthet etioptim iCznm isPoezrfld with oneAo31w/ecfUdoo withl.low instructions in perfo 9oire/pnr0neAPI D2manceg C1P0Uw iin1:ee-critical oth slatpPtofoIr Deep Nem/  NepceratIural rnuctioneAPIp sN u _iteeDtwofeatuirnksooerep  flnre_n sp:er guLibr Nuofwaarry e/core/plar(oantformeDNAdVuXr.cN)l a Net AtVo c:luwork o1X Ne4trmanw2o2/Lccpsrek ]
 This TeLibra To enst-ecrou_hnaer ifberFyl olf(ew oblinaatuone lorwtrey_hgi ieunsgm   aiobraCrptriinymd  (otonPDUiNNe)D hzNeeNi)r dt tti.co o uca nu sle owpitesstre the  h oneAPI Deep Neurufaoctionls in perfotrhllo peratiNoeteo follrmwaowianicnec:tgi Co-PU instructionng nCs, rebuild TensorFlwPU instructions in performance-critical operations:  AVo1ws nswX AVi4cXth2]  Tthhi2:s  e AVT
To e ensaXpoprrFnl oow abAVinbarlpe X2
Totrhie atmy ie  compsiile noptien aoblmizertehd with  iork  flags.
them eorneAPI Deen pe opp riin er Ltioarcatl otpioifborrheenmsa,ratior  onpnce-criticasera: arltio ro AVy npesbNeXue,r(ar arl otnue iAoeiNlDdNVXneb Tes:uNntsworFori)2 
Tk lo etdo AVX AVXn us 2
To enaL ibrary (oneDNN) to use the following CPlabble thelTensorFlow with the appropriate compiler flagsUow with the app m in instructions in perforroe t.tm
opriateaheher compmn operae the following CPU instructions ince-cr in ottionihets, rri ceobuilda l ip oTppelraereer frfoalramtioenannces-gs.
:c  AVXtritical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
 AVX2
To enable them in other operations, sorFlow with the appropriate compiirebuild Tonsler flags.
ensorFlow with the appropriate compiler flags.
, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 04:57:32.438593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:57:32.504292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:57:32.521116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:57:32.524520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:57:32.527032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:57:32.529172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:57:32.539608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 04:57:32.547097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.04分 | step:  1280 | performance: 1.8 | accuracy: 0.33 | loss: 2.46
update: 10/2000, 耗时:0.00分/0.07分 | step:  2560 | performance: 6.7 | accuracy: 0.36 | loss: 1.89
update: 15/2000, 耗时:0.00分/0.09分 | step:  3840 | performance: 2.8 | accuracy: 0.34 | loss: 1.14
update: 20/2000, 耗时:0.00分/0.11分 | step:  5120 | performance: 14.7 | accuracy: 0.37 | loss: 8.06
update: 25/2000, 耗时:0.01分/0.14分 | step:  6400 | performance: 3.8 | accuracy: 0.37 | loss: 6.41
update: 30/2000, 耗时:0.01分/0.17分 | step:  7680 | performance: 3.3 | accuracy: 0.37 | loss: 1.14
update: 35/2000, 耗时:0.01分/0.20分 | step:  8960 | performance: 1.7 | accuracy: 0.37 | loss: 2.45
update: 40/2000, 耗时:0.01分/0.23分 | step: 10240 | performance: 1.3 | accuracy: 0.36 | loss: 1.72
update: 45/2000, 耗时:0.01分/0.26分 | step: 11520 | performance: 1.9 | accuracy: 0.35 | loss: 1.01
update: 50/2000, 耗时:0.01分/0.28分 | step: 12800 | performance: 3.1 | accuracy: 0.36 | loss: 1.44
update: 55/2000, 耗时:0.01分/0.31分 | step: 14080 | performance: 83.3 | accuracy: 0.38 | loss: 8.74
update: 60/2000, 耗时:0.01分/0.34分 | step: 15360 | performance: 2026.5 | accuracy: 0.40 | loss: 2.88
update: 65/2000, 耗时:0.01分/0.37分 | step: 16640 | performance: 81.4 | accuracy: 0.40 | loss: 2.80
update: 70/2000, 耗时:0.01分/0.40分 | step: 17920 | performance: 179.8 | accuracy: 0.40 | loss: 3.69
update: 75/2000, 耗时:0.01分/0.43分 | step: 19200 | performance: 258.2 | accuracy: 0.41 | loss: 3.22
update: 80/2000, 耗时:0.01分/0.46分 | step: 20480 | performance: 362.9 | accuracy: 0.40 | loss: 2.28
update: 85/2000, 耗时:0.01分/0.49分 | step: 21760 | performance: 208.6 | accuracy: 0.39 | loss: 1.43
update: 90/2000, 耗时:0.01分/0.52分 | step: 23040 | performance: 204.0 | accuracy: 0.37 | loss: 0.49
update: 95/2000, 耗时:0.01分/0.55分 | step: 24320 | performance: 259.7 | accuracy: 0.37 | loss: 0.44
update:100/2000, 耗时:0.01分/0.58分 | step: 25600 | performance: 0.8 | accuracy: 0.14 | loss: 0.80
Saving PPO weights in both H5 format and checkpoint @ update:100 
update:105/2000, 耗时:0.01分/0.61分 | step: 26880 | performance: 1.3 | accuracy: 0.21 | loss: 2.48
update:110/2000, 耗时:0.01分/0.63分 | step: 28160 | performance: 1.4 | accuracy: 0.22 | loss: 0.90
update:115/2000, 耗时:0.01分/0.66分 | step: 29440 | performance: 2.1 | accuracy: 0.20 | loss: 0.84
update:120/2000, 耗时:0.01分/0.69分 | step: 30720 | performance: 4.2 | accuracy: 0.27 | loss: 5.98
update:125/2000, 耗时:0.01分/0.72分 | step: 32000 | performance: 1.8 | accuracy: 0.29 | loss: 2.57
update:130/2000, 耗时:0.01分/0.75分 | step: 33280 | performance: 0.5 | accuracy: 0.28 | loss: 0.68
update:135/2000, 耗时:0.01分/0.77分 | step: 34560 | performance: 0.2 | accuracy: 0.27 | loss: 2.94
update:140/2000, 耗时:0.01分/0.80分 | step: 35840 | performance: 0.2 | accuracy: 0.26 | loss: 0.89
update:145/2000, 耗时:0.01分/0.83分 | step: 37120 | performance: 0.2 | accuracy: 0.26 | loss: 2.34
update:150/2000, 耗时:0.01分/0.86分 | step: 38400 | performance: 0.6 | accuracy: 0.27 | loss: 2.10
update:155/2000, 耗时:0.01分/0.89分 | step: 39680 | performance: 41.0 | accuracy: 0.30 | loss: 6.63
update:160/2000, 耗时:0.01分/0.92分 | step: 40960 | performance: 76.1 | accuracy: 0.32 | loss: 6.43
update:165/2000, 耗时:0.01分/0.95分 | step: 42240 | performance: 6.5 | accuracy: 0.32 | loss: 1.63
update:170/2000, 耗时:0.01分/0.97分 | step: 43520 | performance: 16.5 | accuracy: 0.32 | loss: 2.88
update:175/2000, 耗时:0.01分/1.00分 | step: 44800 | performance: 8.5 | accuracy: 0.32 | loss: 1.66
update:180/2000, 耗时:0.01分/1.03分 | step: 46080 | performance: 3.9 | accuracy: 0.31 | loss: 1.01
update:185/2000, 耗时:0.01分/1.06分 | step: 47360 | performance: 2.4 | accuracy: 0.30 | loss: 0.51
update:190/2000, 耗时:0.01分/1.09分 | step: 48640 | performance: 2.5 | accuracy: 0.28 | loss: 0.17
update:195/2000, 耗时:0.01分/1.12分 | step: 49920 | performance: 2.7 | accuracy: 0.27 | loss: 0.10
update:200/2000, 耗时:0.01分/1.14分 | step: 51200 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:205/2000, 耗时:0.01分/1.17分 | step: 52480 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 53498 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 53499 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 53502 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 53504 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
update:210/2000, 耗时:0.01分/1.20分 | step: 53760 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 54009 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 54012 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 54013 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 54015 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
update:215/2000, 耗时:0.01分/1.23分 | step: 55040 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:220/2000, 耗时:0.01分/1.26分 | step: 56320 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:225/2000, 耗时:0.01分/1.29分 | step: 57600 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 57850 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 57851 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 57852 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 57854 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 57856 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 58361 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 58365 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 58367 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
update:230/2000, 耗时:0.01分/1.31分 | step: 58880 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:235/2000, 耗时:0.01分/1.34分 | step: 60160 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:240/2000, 耗时:0.01分/1.37分 | step: 61440 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 62202 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 62203 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 62204 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 62206 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 62208 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 62713 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 62717 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 62719 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
update:245/2000, 耗时:0.01分/1.40分 | step: 62720 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:250/2000, 耗时:0.01分/1.43分 | step: 64000 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:255/2000, 耗时:0.01分/1.46分 | step: 65280 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 66554 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 66555 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 66556 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 66558 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 66560 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
update:260/2000, 耗时:0.01分/1.49分 | step: 66560 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 67065 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 67069 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 67071 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 154.4
update:265/2000, 耗时:0.01分/1.51分 | step: 67840 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
update:270/2000, 耗时:0.01分/1.54分 | step: 69120 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:275/2000, 耗时:0.01分/1.57分 | step: 70400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 70906 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 70907 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 70908 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 70910 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 70912 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 71417 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 71421 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 71423 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
update:280/2000, 耗时:0.01分/1.60分 | step: 71680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:285/2000, 耗时:0.01分/1.63分 | step: 72960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:290/2000, 耗时:0.01分/1.66分 | step: 74240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 75258 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 75259 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 75260 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 75262 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 75264 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
update:295/2000, 耗时:0.01分/1.69分 | step: 75520 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 75769 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 75773 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 75775 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
update:300/2000, 耗时:0.01分/1.72分 | step: 76800 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:305/2000, 耗时:0.01分/1.74分 | step: 78080 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:310/2000, 耗时:0.01分/1.77分 | step: 79360 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 79610 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 79611 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 79612 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 79614 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 79616 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 80121 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 80125 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 80127 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
update:315/2000, 耗时:0.01分/1.80分 | step: 80640 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:320/2000, 耗时:0.01分/1.83分 | step: 81920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:325/2000, 耗时:0.01分/1.86分 | step: 83200 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 83962 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 83963 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 83964 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 83966 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 83968 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 84473 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 84477 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 84479 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
update:330/2000, 耗时:0.01分/1.89分 | step: 84480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:335/2000, 耗时:0.01分/1.92分 | step: 85760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:340/2000, 耗时:0.01分/1.94分 | step: 87040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 88314 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 88315 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 88316 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 88318 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
step: 88320 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 154.4
update:345/2000, 耗时:0.01分/1.97分 | step: 88320 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 88825 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 88829 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 88831 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
update:350/2000, 耗时:0.01分/2.00分 | step: 89600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:355/2000, 耗时:0.01分/2.03分 | step: 90880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:360/2000, 耗时:0.01分/2.06分 | step: 92160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 92666 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 92667 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 92668 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 92670 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 92672 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 93177 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 93181 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 93183 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
update:365/2000, 耗时:0.01分/2.09分 | step: 93440 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
update:370/2000, 耗时:0.01分/2.11分 | step: 94720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:375/2000, 耗时:0.01分/2.14分 | step: 96000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 97018 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 97019 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 97020 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 97022 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
step: 97024 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
update:380/2000, 耗时:0.01分/2.17分 | step: 97280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 97529 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 97533 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 97535 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
update:385/2000, 耗时:0.01分/2.20分 | step: 98560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:390/2000, 耗时:0.01分/2.23分 | step: 99840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:395/2000, 耗时:0.01分/2.26分 | step: 101120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 101370 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 101371 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 101372 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 101374 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 101376 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 101881 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 154.4
step: 101885 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 101887 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
update:400/2000, 耗时:0.01分/2.29分 | step: 102400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:405/2000, 耗时:0.01分/2.31分 | step: 103680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:410/2000, 耗时:0.01分/2.34分 | step: 104960 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 105722 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 154.4
step: 105723 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 154.4
step: 105724 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 154.4
step: 105726 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 154.4
step: 105728 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 106237 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 154.4
step: 106239 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 154.4
update:415/2000, 耗时:0.01分/2.37分 | step: 106240 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
update:420/2000, 耗时:0.01分/2.40分 | step: 107520 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
step: 108283 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 154.4
step: 108285 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 154.4
update:425/2000, 耗时:0.01分/2.43分 | step: 108800 | performance: 1.3 | accuracy: 0.12 | loss: 0.28
step: 109562 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 154.4
step: 109563 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 154.4
update:430/2000, 耗时:0.01分/2.46分 | step: 110080 | performance: 1.0 | accuracy: 0.07 | loss: 0.35
step: 110330 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 154.4
update:435/2000, 耗时:0.01分/2.49分 | step: 111360 | performance: 1.4 | accuracy: 0.22 | loss: 0.87
update:440/2000, 耗时:0.01分/2.52分 | step: 112640 | performance: 5.2 | accuracy: 0.28 | loss: 1.12
update:445/2000, 耗时:0.01分/2.54分 | step: 113920 | performance: 5.4 | accuracy: 0.28 | loss: 1.44
update:450/2000, 耗时:0.01分/2.57分 | step: 115200 | performance: 5.4 | accuracy: 0.22 | loss: 1.29
update:455/2000, 耗时:0.01分/2.60分 | step: 116480 | performance: 6.5 | accuracy: 0.24 | loss: 0.85
update:460/2000, 耗时:0.01分/2.63分 | step: 117760 | performance: 6.2 | accuracy: 0.24 | loss: 0.60
update:465/2000, 耗时:0.01分/2.66分 | step: 119040 | performance: 8.6 | accuracy: 0.23 | loss: 0.91
update:470/2000, 耗时:0.01分/2.69分 | step: 120320 | performance: 4.4 | accuracy: 0.22 | loss: 0.65
update:475/2000, 耗时:0.01分/2.72分 | step: 121600 | performance: 4.7 | accuracy: 0.21 | loss: 0.74
update:480/2000, 耗时:0.01分/2.74分 | step: 122880 | performance: 8.1 | accuracy: 0.22 | loss: 0.68
update:485/2000, 耗时:0.01分/2.77分 | step: 124160 | performance: 35.3 | accuracy: 0.24 | loss: 3.94
update:490/2000, 耗时:0.01分/2.80分 | step: 125440 | performance: 3595.9 | accuracy: 0.27 | loss: 4.77
update:495/2000, 耗时:0.01分/2.83分 | step: 126720 | performance: 904.4 | accuracy: 0.28 | loss: 3.20
update:500/2000, 耗时:0.01分/2.86分 | step: 128000 | performance: 634.0 | accuracy: 0.27 | loss: 1.29
update:505/2000, 耗时:0.01分/2.89分 | step: 129280 | performance: 505.3 | accuracy: 0.27 | loss: 1.84
update:510/2000, 耗时:0.01分/2.91分 | step: 130560 | performance: 242.4 | accuracy: 0.27 | loss: 1.24
update:515/2000, 耗时:0.01分/2.94分 | step: 131840 | performance: 211.9 | accuracy: 0.26 | loss: 0.76
update:520/2000, 耗时:0.01分/2.97分 | step: 133120 | performance: 491.6 | accuracy: 0.26 | loss: 1.48
update:525/2000, 耗时:0.01分/3.00分 | step: 134400 | performance: 1048.5 | accuracy: 0.26 | loss: 0.76
step: 135164 | worker_3@n_step_31: average total_reward after train data exhaustion : 3.1 | max total_reward: 154.4
update:530/2000, 耗时:0.01分/3.03分 | step: 135680 | performance: 870.3 | accuracy: 0.27 | loss: 1.05
update:535/2000, 耗时:0.01分/3.06分 | step: 136960 | performance: 1.7 | accuracy: 0.19 | loss: 0.93
update:540/2000, 耗时:0.01分/3.09分 | step: 138240 | performance: 13.4 | accuracy: 0.35 | loss: 1.64
update:545/2000, 耗时:0.01分/3.12分 | step: 139520 | performance: 17.2 | accuracy: 0.35 | loss: 1.47
update:550/2000, 耗时:0.01分/3.14分 | step: 140800 | performance: 21.8 | accuracy: 0.30 | loss: 1.54
update:555/2000, 耗时:0.01分/3.17分 | step: 142080 | performance: 19.2 | accuracy: 0.29 | loss: 0.79
update:560/2000, 耗时:0.01分/3.20分 | step: 143360 | performance: 15.7 | accuracy: 0.27 | loss: 0.41
update:565/2000, 耗时:0.01分/3.23分 | step: 144640 | performance: 11.4 | accuracy: 0.25 | loss: 0.35
update:570/2000, 耗时:0.01分/3.26分 | step: 145920 | performance: 8.3 | accuracy: 0.22 | loss: 0.43
update:575/2000, 耗时:0.01分/3.29分 | step: 147200 | performance: 8.2 | accuracy: 0.21 | loss: 0.38
update:580/2000, 耗时:0.01分/3.31分 | step: 148480 | performance: 7.9 | accuracy: 0.20 | loss: 0.18
update:585/2000, 耗时:0.01分/3.34分 | step: 149760 | performance: 10.0 | accuracy: 0.19 | loss: 0.50
update:590/2000, 耗时:0.01分/3.37分 | step: 151040 | performance: 26.3 | accuracy: 0.19 | loss: 0.68
update:595/2000, 耗时:0.01分/3.40分 | step: 152320 | performance: 22.9 | accuracy: 0.18 | loss: 0.39
update:600/2000, 耗时:0.01分/3.43分 | step: 153600 | performance: 16.7 | accuracy: 0.17 | loss: 0.35
update:605/2000, 耗时:0.01分/3.46分 | step: 154880 | performance: 18.1 | accuracy: 0.17 | loss: 0.20
update:610/2000, 耗时:0.01分/3.49分 | step: 156160 | performance: 14.2 | accuracy: 0.16 | loss: 0.14
update:615/2000, 耗时:0.01分/3.52分 | step: 157440 | performance: 16.1 | accuracy: 0.16 | loss: 0.45
update:620/2000, 耗时:0.01分/3.54分 | step: 158720 | performance: 26.0 | accuracy: 0.16 | loss: 0.59
update:625/2000, 耗时:0.01分/3.57分 | step: 160000 | performance: 29.1 | accuracy: 0.15 | loss: 0.49
update:630/2000, 耗时:0.01分/3.60分 | step: 161280 | performance: 28.3 | accuracy: 0.16 | loss: 0.57
step: 161536 | worker_7@n_step_31: average total_reward after train data exhaustion : 33.5 | max total_reward: 197.6
update:635/2000, 耗时:0.01分/3.63分 | step: 162560 | performance: 0.9 | accuracy: 0.16 | loss: 1.12
update:640/2000, 耗时:0.01分/3.66分 | step: 163840 | performance: 3.7 | accuracy: 0.25 | loss: 1.51
update:645/2000, 耗时:0.01分/3.69分 | step: 165120 | performance: 3.4 | accuracy: 0.27 | loss: 0.88
update:650/2000, 耗时:0.01分/3.72分 | step: 166400 | performance: 8.8 | accuracy: 0.25 | loss: 0.87
update:655/2000, 耗时:0.01分/3.75分 | step: 167680 | performance: 7.6 | accuracy: 0.24 | loss: 0.59
update:660/2000, 耗时:0.01分/3.78分 | step: 168960 | performance: 15.2 | accuracy: 0.24 | loss: 0.94
update:665/2000, 耗时:0.01分/3.81分 | step: 170240 | performance: 23.2 | accuracy: 0.25 | loss: 1.08
update:670/2000, 耗时:0.01分/3.84分 | step: 171520 | performance: 29.4 | accuracy: 0.24 | loss: 0.63
update:675/2000, 耗时:0.01分/3.87分 | step: 172800 | performance: 30.3 | accuracy: 0.25 | loss: 1.02
update:680/2000, 耗时:0.01分/3.90分 | step: 174080 | performance: 22.8 | accuracy: 0.26 | loss: 1.19
update:685/2000, 耗时:0.01分/3.93分 | step: 175360 | performance: 397.9 | accuracy: 0.29 | loss: 5.31
update:690/2000, 耗时:0.01分/3.96分 | step: 176640 | performance: 7533.3 | accuracy: 0.31 | loss: 7.01
update:695/2000, 耗时:0.01分/3.98分 | step: 177920 | performance: 1017.5 | accuracy: 0.32 | loss: 3.23
update:700/2000, 耗时:0.01分/4.01分 | step: 179200 | performance: 2740.2 | accuracy: 0.34 | loss: 3.75
update:705/2000, 耗时:0.01分/4.04分 | step: 180480 | performance: 5623.2 | accuracy: 0.35 | loss: 3.91
update:710/2000, 耗时:0.01分/4.07分 | step: 181760 | performance: 606.2 | accuracy: 0.35 | loss: 4.02
update:715/2000, 耗时:0.01分/4.10分 | step: 183040 | performance: 523.5 | accuracy: 0.36 | loss: 3.32
update:720/2000, 耗时:0.01分/4.12分 | step: 184320 | performance: 21.2 | accuracy: 0.36 | loss: 2.12
update:725/2000, 耗时:0.01分/4.15分 | step: 185600 | performance: 15.5 | accuracy: 0.36 | loss: 1.67
update:730/2000, 耗时:0.01分/4.18分 | step: 186880 | performance: 10.7 | accuracy: 0.36 | loss: 1.30
update:735/2000, 耗时:0.01分/4.21分 | step: 188160 | performance: 0.8 | accuracy: 0.38 | loss: 1.08
update:740/2000, 耗时:0.01分/4.24分 | step: 189440 | performance: 0.5 | accuracy: 0.36 | loss: 1.56
update:745/2000, 耗时:0.01分/4.27分 | step: 190720 | performance: 1.1 | accuracy: 0.33 | loss: 2.00
update:750/2000, 耗时:0.01分/4.29分 | step: 192000 | performance: 9.1 | accuracy: 0.37 | loss: 4.29
update:755/2000, 耗时:0.01分/4.32分 | step: 193280 | performance: 6.1 | accuracy: 0.38 | loss: 2.81
update:760/2000, 耗时:0.01分/4.35分 | step: 194560 | performance: 5.5 | accuracy: 0.39 | loss: 1.19
update:765/2000, 耗时:0.01分/4.38分 | step: 195840 | performance: 6.7 | accuracy: 0.39 | loss: 2.32
update:770/2000, 耗时:0.01分/4.41分 | step: 197120 | performance: 20.1 | accuracy: 0.41 | loss: 2.03
update:775/2000, 耗时:0.01分/4.43分 | step: 198400 | performance: 32.2 | accuracy: 0.42 | loss: 1.44
update:780/2000, 耗时:0.01分/4.46分 | step: 199680 | performance: 54.1 | accuracy: 0.42 | loss: 3.51
update:785/2000, 耗时:0.01分/4.49分 | step: 200960 | performance: 3985.3 | accuracy: 0.44 | loss: 5.83
update:790/2000, 耗时:0.01分/4.52分 | step: 202240 | performance: 27685.7 | accuracy: 0.45 | loss: 3.96
update:795/2000, 耗时:0.01分/4.55分 | step: 203520 | performance: 1870.9 | accuracy: 0.45 | loss: 5.26
update:800/2000, 耗时:0.01分/4.58分 | step: 204800 | performance: 4693.4 | accuracy: 0.45 | loss: 4.46
update:805/2000, 耗时:0.01分/4.61分 | step: 206080 | performance: 6552.7 | accuracy: 0.45 | loss: 2.79
update:810/2000, 耗时:0.01分/4.64分 | step: 207360 | performance: 1647.7 | accuracy: 0.45 | loss: 3.55
update:815/2000, 耗时:0.01分/4.67分 | step: 208640 | performance: 949.8 | accuracy: 0.44 | loss: 2.08
update:820/2000, 耗时:0.01分/4.70分 | step: 209920 | performance: 903.4 | accuracy: 0.43 | loss: 0.76
update:825/2000, 耗时:0.01分/4.73分 | step: 211200 | performance: 1021.8 | accuracy: 0.42 | loss: 0.97
update:830/2000, 耗时:0.01分/4.76分 | step: 212480 | performance: 1.0 | accuracy: 0.29 | loss: 0.62
update:835/2000, 耗时:0.01分/4.79分 | step: 213760 | performance: 1.0 | accuracy: 0.21 | loss: 0.73
update:840/2000, 耗时:0.01分/4.81分 | step: 215040 | performance: 0.7 | accuracy: 0.21 | loss: 0.89
update:845/2000, 耗时:0.01分/4.84分 | step: 216320 | performance: 0.5 | accuracy: 0.18 | loss: 1.00
update:850/2000, 耗时:0.01分/4.88分 | step: 217600 | performance: 0.4 | accuracy: 0.17 | loss: 0.78
update:855/2000, 耗时:0.01分/4.91分 | step: 218880 | performance: 0.5 | accuracy: 0.17 | loss: 0.39
update:860/2000, 耗时:0.01分/4.94分 | step: 220160 | performance: 0.4 | accuracy: 0.15 | loss: 0.28
update:865/2000, 耗时:0.01分/4.96分 | step: 221440 | performance: 0.3 | accuracy: 0.14 | loss: 0.34
update:870/2000, 耗时:0.01分/4.99分 | step: 222720 | performance: 0.4 | accuracy: 0.14 | loss: 0.28
update:875/2000, 耗时:0.01分/5.02分 | step: 224000 | performance: 0.5 | accuracy: 0.13 | loss: 0.23
update:880/2000, 耗时:0.01分/5.05分 | step: 225280 | performance: 0.4 | accuracy: 0.13 | loss: 0.65
update:885/2000, 耗时:0.01分/5.08分 | step: 226560 | performance: 7.4 | accuracy: 0.15 | loss: 3.31
update:890/2000, 耗时:0.01分/5.11分 | step: 227840 | performance: 41.7 | accuracy: 0.18 | loss: 4.58
update:895/2000, 耗时:0.01分/5.13分 | step: 229120 | performance: 2.4 | accuracy: 0.19 | loss: 2.33
update:900/2000, 耗时:0.01分/5.16分 | step: 230400 | performance: 1.8 | accuracy: 0.20 | loss: 1.83
update:905/2000, 耗时:0.01分/5.19分 | step: 231680 | performance: 5.3 | accuracy: 0.21 | loss: 1.79
update:910/2000, 耗时:0.01分/5.22分 | step: 232960 | performance: 3.4 | accuracy: 0.21 | loss: 0.71
update:915/2000, 耗时:0.01分/5.25分 | step: 234240 | performance: 3.3 | accuracy: 0.21 | loss: 0.25
update:920/2000, 耗时:0.01分/5.27分 | step: 235520 | performance: 3.9 | accuracy: 0.20 | loss: 0.21
update:925/2000, 耗时:0.01分/5.30分 | step: 236800 | performance: 3.2 | accuracy: 0.19 | loss: 0.22
update:930/2000, 耗时:0.01分/5.33分 | step: 238080 | performance: 1.0 | accuracy: 0.07 | loss: 0.14
step: 238330 | worker_1@n_step_31: average total_reward after train data exhaustion : 10.0 | max total_reward: 259.6
step: 238844 | worker_3@n_step_31: average total_reward after train data exhaustion : 2.8 | max total_reward: 259.6
update:935/2000, 耗时:0.01分/5.36分 | step: 239360 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 239609 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.3 | max total_reward: 259.6
step: 240126 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
step: 240381 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
step: 240639 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
update:940/2000, 耗时:0.01分/5.39分 | step: 240640 | performance: 1.2 | accuracy: 0.10 | loss: 0.15
update:945/2000, 耗时:0.01分/5.42分 | step: 241920 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 242688 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 243196 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
update:950/2000, 耗时:0.01分/5.44分 | step: 243200 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 243449 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
step: 243963 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
step: 244221 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
step: 244478 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
update:955/2000, 耗时:0.01分/5.47分 | step: 244480 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 244991 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 245754 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:960/2000, 耗时:0.01分/5.50分 | step: 245760 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 246524 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 259.6
step: 247040 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
update:965/2000, 耗时:0.01分/5.53分 | step: 247040 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 247803 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
update:970/2000, 耗时:0.01分/5.56分 | step: 248320 | performance: 1.0 | accuracy: 0.33 | loss: 0.25
update:975/2000, 耗时:0.01分/5.59分 | step: 249600 | performance: 1.2 | accuracy: 0.14 | loss: 0.79
update:980/2000, 耗时:0.01分/5.61分 | step: 250880 | performance: 2.5 | accuracy: 0.16 | loss: 1.45
update:985/2000, 耗时:0.01分/5.64分 | step: 252160 | performance: 1.4 | accuracy: 0.19 | loss: 0.51
update:990/2000, 耗时:0.01分/5.67分 | step: 253440 | performance: 1.2 | accuracy: 0.14 | loss: 0.14
update:995/2000, 耗时:0.01分/5.70分 | step: 254720 | performance: 1.1 | accuracy: 0.12 | loss: 0.08
update:1000/2000, 耗时:0.01分/5.73分 | step: 256000 | performance: 1.0 | accuracy: 0.11 | loss: 0.05
update:1005/2000, 耗时:0.01分/5.75分 | step: 257280 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
update:1010/2000, 耗时:0.01分/5.78分 | step: 258560 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 258813 | worker_4@n_step_31: average total_reward after train data exhaustion : 2.9 | max total_reward: 259.6
update:1015/2000, 耗时:0.01分/5.81分 | step: 259840 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 260096 | worker_7@n_step_31: average total_reward after train data exhaustion : 2.8 | max total_reward: 259.6
step: 260345 | worker_0@n_step_31: average total_reward after train data exhaustion : 2.3 | max total_reward: 259.6
step: 260350 | worker_5@n_step_31: average total_reward after train data exhaustion : 2.3 | max total_reward: 259.6
step: 260603 | worker_2@n_step_31: average total_reward after train data exhaustion : 2.3 | max total_reward: 259.6
step: 260860 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 261114 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1020/2000, 耗时:0.01分/5.84分 | step: 261120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 261887 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1025/2000, 耗时:0.01分/5.87分 | step: 262400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 263165 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1030/2000, 耗时:0.01分/5.90分 | step: 263680 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 264448 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 264697 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 264702 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 264955 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1035/2000, 耗时:0.01分/5.92分 | step: 264960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 265212 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 265466 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 266239 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1040/2000, 耗时:0.01分/5.95分 | step: 266240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 267517 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1045/2000, 耗时:0.01分/5.98分 | step: 267520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 268800 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
update:1050/2000, 耗时:0.01分/6.01分 | step: 268800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 269049 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 269054 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 269307 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 269564 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 269818 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1055/2000, 耗时:0.01分/6.04分 | step: 270080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 270591 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1060/2000, 耗时:0.01分/6.07分 | step: 271360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 271869 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1065/2000, 耗时:0.01分/6.09分 | step: 272640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 273152 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 273401 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 273406 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 273659 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 273916 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1070/2000, 耗时:0.01分/6.12分 | step: 273920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 274170 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 274943 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
update:1075/2000, 耗时:0.01分/6.15分 | step: 275200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 276221 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1080/2000, 耗时:0.01分/6.18分 | step: 276480 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 277504 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 277753 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 277758 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1085/2000, 耗时:0.01分/6.21分 | step: 277760 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 278011 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 278268 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
step: 278522 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
update:1090/2000, 耗时:0.01分/6.24分 | step: 279040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 279295 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1095/2000, 耗时:0.01分/6.26分 | step: 280320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 280573 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1100/2000, 耗时:0.01分/6.29分 | step: 281600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 281856 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 282105 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 282110 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 282363 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 282620 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 282874 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1105/2000, 耗时:0.01分/6.32分 | step: 282880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 283647 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1110/2000, 耗时:0.01分/6.35分 | step: 284160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 284925 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1115/2000, 耗时:0.01分/6.38分 | step: 285440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 286208 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 286457 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 286462 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 286715 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1120/2000, 耗时:0.01分/6.40分 | step: 286720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 286972 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 287226 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 287999 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1125/2000, 耗时:0.01分/6.43分 | step: 288000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 289277 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1130/2000, 耗时:0.01分/6.46分 | step: 289280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 290560 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1135/2000, 耗时:0.01分/6.49分 | step: 290560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 290809 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 290814 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 291067 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 291324 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 291578 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1140/2000, 耗时:0.01分/6.52分 | step: 291840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 292351 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1145/2000, 耗时:0.01分/6.54分 | step: 293120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 293629 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1150/2000, 耗时:0.01分/6.57分 | step: 294400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 294912 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 295161 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 295166 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 295419 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 295676 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1155/2000, 耗时:0.01分/6.60分 | step: 295680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 295930 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 296703 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1160/2000, 耗时:0.01分/6.63分 | step: 296960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 297981 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1165/2000, 耗时:0.01分/6.66分 | step: 298240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 299264 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 299513 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 299518 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1170/2000, 耗时:0.01分/6.69分 | step: 299520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 299771 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 300028 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 300282 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1175/2000, 耗时:0.01分/6.72分 | step: 300800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 301055 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1180/2000, 耗时:0.01分/6.74分 | step: 302080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 302333 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1185/2000, 耗时:0.01分/6.77分 | step: 303360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 303616 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 303865 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 303870 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 304123 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 304380 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 304634 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1190/2000, 耗时:0.01分/6.80分 | step: 304640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 305407 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1195/2000, 耗时:0.01分/6.83分 | step: 305920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 306685 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1200/2000, 耗时:0.01分/6.86分 | step: 307200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 307968 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 308217 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 308222 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 308475 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1205/2000, 耗时:0.01分/6.89分 | step: 308480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 308732 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 308986 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 309759 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1210/2000, 耗时:0.01分/6.91分 | step: 309760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 311037 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1215/2000, 耗时:0.01分/6.94分 | step: 311040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 312320 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1220/2000, 耗时:0.01分/6.97分 | step: 312320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 312569 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 312574 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 312827 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 313084 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 313338 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1225/2000, 耗时:0.01分/7.00分 | step: 313600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 314111 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1230/2000, 耗时:0.01分/7.03分 | step: 314880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 315389 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1235/2000, 耗时:0.01分/7.05分 | step: 316160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 316672 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 316921 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 316926 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 317179 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 317436 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1240/2000, 耗时:0.01分/7.08分 | step: 317440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 317690 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 318463 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1245/2000, 耗时:0.01分/7.11分 | step: 318720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 319741 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1250/2000, 耗时:0.01分/7.14分 | step: 320000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 321024 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 321273 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 321278 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1255/2000, 耗时:0.01分/7.17分 | step: 321280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 321531 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 321788 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 322042 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1260/2000, 耗时:0.01分/7.20分 | step: 322560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 322815 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1265/2000, 耗时:0.01分/7.23分 | step: 323840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 324093 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1270/2000, 耗时:0.01分/7.25分 | step: 325120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 325376 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 325625 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 325630 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 325883 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 326140 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 326394 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1275/2000, 耗时:0.01分/7.28分 | step: 326400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 327167 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1280/2000, 耗时:0.01分/7.31分 | step: 327680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 328445 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1285/2000, 耗时:0.01分/7.34分 | step: 328960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 329728 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 329977 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 329982 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 330235 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1290/2000, 耗时:0.01分/7.37分 | step: 330240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 330492 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 330746 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 331519 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1295/2000, 耗时:0.01分/7.40分 | step: 331520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 332797 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1300/2000, 耗时:0.01分/7.42分 | step: 332800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 334080 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1305/2000, 耗时:0.01分/7.45分 | step: 334080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 334329 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 334334 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 334587 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 334844 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 335098 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1310/2000, 耗时:0.01分/7.48分 | step: 335360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 335871 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1315/2000, 耗时:0.01分/7.51分 | step: 336640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 337149 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1320/2000, 耗时:0.01分/7.54分 | step: 337920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 338432 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 338681 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 338686 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 338939 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 339196 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1325/2000, 耗时:0.01分/7.56分 | step: 339200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 339450 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 340223 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1330/2000, 耗时:0.01分/7.59分 | step: 340480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 341501 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1335/2000, 耗时:0.01分/7.62分 | step: 341760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 342784 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 343033 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 343038 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1340/2000, 耗时:0.01分/7.65分 | step: 343040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 343291 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 343548 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 343802 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1345/2000, 耗时:0.01分/7.68分 | step: 344320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 344575 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1350/2000, 耗时:0.01分/7.71分 | step: 345600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 345853 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1355/2000, 耗时:0.01分/7.74分 | step: 346880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 347136 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 347385 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 347390 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 347643 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 347900 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 348154 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1360/2000, 耗时:0.01分/7.77分 | step: 348160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 348927 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1365/2000, 耗时:0.01分/7.79分 | step: 349440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 350205 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1370/2000, 耗时:0.01分/7.82分 | step: 350720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 351488 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 351737 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 351742 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 351995 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1375/2000, 耗时:0.01分/7.85分 | step: 352000 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 352252 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 352506 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
step: 353279 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
update:1380/2000, 耗时:0.01分/7.88分 | step: 353280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 354302 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
update:1385/2000, 耗时:0.01分/7.91分 | step: 354560 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
step: 355065 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
step: 355328 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
update:1390/2000, 耗时:0.01分/7.94分 | step: 355840 | performance: 1.0 | accuracy: 0.00 | loss: 0.25
step: 357114 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1395/2000, 耗时:0.01分/7.96分 | step: 357120 | performance: 1.3 | accuracy: 0.14 | loss: 0.57
update:1400/2000, 耗时:0.01分/7.99分 | step: 358400 | performance: 3.5 | accuracy: 0.22 | loss: 1.19
update:1405/2000, 耗时:0.01分/8.02分 | step: 359680 | performance: 3.5 | accuracy: 0.21 | loss: 0.58
update:1410/2000, 耗时:0.01分/8.05分 | step: 360960 | performance: 2.9 | accuracy: 0.17 | loss: 0.17
update:1415/2000, 耗时:0.01分/8.07分 | step: 362240 | performance: 3.1 | accuracy: 0.15 | loss: 0.21
update:1420/2000, 耗时:0.01分/8.10分 | step: 363520 | performance: 4.5 | accuracy: 0.14 | loss: 0.39
update:1425/2000, 耗时:0.01分/8.13分 | step: 364800 | performance: 4.5 | accuracy: 0.13 | loss: 0.17
update:1430/2000, 耗时:0.01分/8.16分 | step: 366080 | performance: 3.9 | accuracy: 0.12 | loss: 0.09
update:1435/2000, 耗时:0.01分/8.19分 | step: 367360 | performance: 4.2 | accuracy: 0.12 | loss: 0.14
step: 368126 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
update:1440/2000, 耗时:0.01分/8.21分 | step: 368640 | performance: 4.6 | accuracy: 0.11 | loss: 0.08
step: 369151 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.0 | max total_reward: 259.6
update:1445/2000, 耗时:0.01分/8.24分 | step: 369920 | performance: 4.2 | accuracy: 0.10 | loss: 0.09
step: 370169 | worker_0@n_step_31: average total_reward after train data exhaustion : 3.4 | max total_reward: 259.6
step: 370173 | worker_4@n_step_31: average total_reward after train data exhaustion : 3.4 | max total_reward: 259.6
step: 371194 | worker_1@n_step_31: average total_reward after train data exhaustion : 6.4 | max total_reward: 259.6
update:1450/2000, 耗时:0.01分/8.27分 | step: 371200 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 372224 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 259.6
step: 372478 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
update:1455/2000, 耗时:0.01分/8.30分 | step: 372480 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 372991 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1460/2000, 耗时:0.01分/8.33分 | step: 373760 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 374013 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 374521 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 374523 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 374524 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1465/2000, 耗时:0.01分/8.36分 | step: 375040 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 375546 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
step: 376318 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 259.6
update:1470/2000, 耗时:0.01分/8.38分 | step: 376320 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 376576 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
step: 376831 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
step: 377081 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 259.6
step: 377084 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 259.6
update:1475/2000, 耗时:0.01分/8.41分 | step: 377600 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
update:1480/2000, 耗时:0.01分/8.44分 | step: 378880 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 379646 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 379898 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
step: 379900 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
update:1485/2000, 耗时:0.01分/8.47分 | step: 380160 | performance: 1.3 | accuracy: 0.16 | loss: 0.21
step: 380409 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 259.6
update:1490/2000, 耗时:0.01分/8.50分 | step: 381440 | performance: 1.0 | accuracy: 0.00 | loss: 0.46
update:1495/2000, 耗时:0.01分/8.53分 | step: 382720 | performance: 1.4 | accuracy: 0.19 | loss: 1.40
update:1500/2000, 耗时:0.01分/8.55分 | step: 384000 | performance: 2.7 | accuracy: 0.23 | loss: 0.86
update:1505/2000, 耗时:0.01分/8.58分 | step: 385280 | performance: 2.3 | accuracy: 0.21 | loss: 0.60
update:1510/2000, 耗时:0.01分/8.61分 | step: 386560 | performance: 2.4 | accuracy: 0.17 | loss: 0.14
update:1515/2000, 耗时:0.01分/8.64分 | step: 387840 | performance: 3.5 | accuracy: 0.16 | loss: 0.30
update:1520/2000, 耗时:0.01分/8.67分 | step: 389120 | performance: 3.2 | accuracy: 0.16 | loss: 0.36
update:1525/2000, 耗时:0.01分/8.70分 | step: 390400 | performance: 3.3 | accuracy: 0.15 | loss: 0.52
update:1530/2000, 耗时:0.01分/8.73分 | step: 391680 | performance: 9.4 | accuracy: 0.15 | loss: 0.23
update:1535/2000, 耗时:0.01分/8.75分 | step: 392960 | performance: 10.8 | accuracy: 0.15 | loss: 0.34
update:1540/2000, 耗时:0.01分/8.78分 | step: 394240 | performance: 9.7 | accuracy: 0.15 | loss: 0.72
update:1545/2000, 耗时:0.01分/8.81分 | step: 395520 | performance: 46.3 | accuracy: 0.16 | loss: 1.81
update:1550/2000, 耗时:0.00分/8.83分 | step: 396800 | performance: 891.6 | accuracy: 0.19 | loss: 1.81
update:1555/2000, 耗时:0.00分/8.86分 | step: 398080 | performance: 541.2 | accuracy: 0.19 | loss: 0.46
update:1560/2000, 耗时:0.01分/8.88分 | step: 399360 | performance: 648.6 | accuracy: 0.18 | loss: 0.50
update:1565/2000, 耗时:0.01分/8.91分 | step: 400640 | performance: 586.9 | accuracy: 0.18 | loss: 0.45
update:1570/2000, 耗时:0.01分/8.94分 | step: 401920 | performance: 356.0 | accuracy: 0.17 | loss: 0.37
update:1575/2000, 耗时:0.01分/8.96分 | step: 403200 | performance: 434.7 | accuracy: 0.17 | loss: 0.67
update:1580/2000, 耗时:0.01分/8.99分 | step: 404480 | performance: 1307.7 | accuracy: 0.17 | loss: 0.47
update:1585/2000, 耗时:0.01分/9.02分 | step: 405760 | performance: 1585.0 | accuracy: 0.17 | loss: 0.84
update:1590/2000, 耗时:0.01分/9.05分 | step: 407040 | performance: 1641.6 | accuracy: 0.17 | loss: 0.37
update:1595/2000, 耗时:0.01分/9.08分 | step: 408320 | performance: 1.0 | accuracy: 0.00 | loss: 0.73
update:1600/2000, 耗时:0.01分/9.10分 | step: 409600 | performance: 1.0 | accuracy: 0.15 | loss: 0.42
update:1605/2000, 耗时:0.01分/9.13分 | step: 410880 | performance: 1.4 | accuracy: 0.12 | loss: 0.52
update:1610/2000, 耗时:0.01分/9.16分 | step: 412160 | performance: 1.1 | accuracy: 0.11 | loss: 0.17
step: 412665 | worker_0@n_step_31: average total_reward after train data exhaustion : 16.4 | max total_reward: 259.6
update:1615/2000, 耗时:0.01分/9.19分 | step: 413440 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
step: 413696 | worker_7@n_step_31: average total_reward after train data exhaustion : 12.6 | max total_reward: 259.6
update:1620/2000, 耗时:0.01分/9.22分 | step: 414720 | performance: 0.9 | accuracy: 0.00 | loss: 0.08
step: 414970 | worker_1@n_step_31: average total_reward after train data exhaustion : 1.5 | max total_reward: 259.6
step: 415996 | worker_3@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 259.6
update:1625/2000, 耗时:0.01分/9.25分 | step: 416000 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 416505 | worker_0@n_step_31: average total_reward after train data exhaustion : 1.8 | max total_reward: 259.6
step: 416507 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.8 | max total_reward: 259.6
update:1630/2000, 耗时:0.01分/9.27分 | step: 417280 | performance: 1.0 | accuracy: 0.00 | loss: 0.01
step: 418046 | worker_5@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 259.6
step: 418048 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 259.6
step: 418303 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
update:1635/2000, 耗时:0.01分/9.30分 | step: 418560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 418813 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 419322 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1640/2000, 耗时:0.01分/9.33分 | step: 419840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 420348 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 420857 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 420859 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1645/2000, 耗时:0.01分/9.36分 | step: 421120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 422398 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 422400 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1650/2000, 耗时:0.01分/9.39分 | step: 422400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 422655 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 423165 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 423674 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1655/2000, 耗时:0.01分/9.42分 | step: 423680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 424700 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1660/2000, 耗时:0.01分/9.45分 | step: 424960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 425209 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 425211 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1665/2000, 耗时:0.01分/9.48分 | step: 426240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 426750 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 426752 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 427007 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 427517 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1670/2000, 耗时:0.01分/9.51分 | step: 427520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 428026 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1675/2000, 耗时:0.01分/9.54分 | step: 428800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 429052 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 429561 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 429563 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1680/2000, 耗时:0.01分/9.57分 | step: 430080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 431102 | worker_5@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 431104 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 431359 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1685/2000, 耗时:0.01分/9.60分 | step: 431360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 431869 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 432378 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1690/2000, 耗时:0.01分/9.63分 | step: 432640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 433404 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 433913 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 433915 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1695/2000, 耗时:0.01分/9.66分 | step: 433920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1700/2000, 耗时:0.01分/9.69分 | step: 435200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 435454 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 435456 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 435711 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 436221 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1705/2000, 耗时:0.01分/9.72分 | step: 436480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 436730 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 437756 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1710/2000, 耗时:0.01分/9.75分 | step: 437760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 438265 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 438267 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1715/2000, 耗时:0.01分/9.78分 | step: 439040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 439806 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 439808 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 440063 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1720/2000, 耗时:0.01分/9.81分 | step: 440320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 440573 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 441082 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1725/2000, 耗时:0.01分/9.84分 | step: 441600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 442108 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 442617 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 442619 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1730/2000, 耗时:0.01分/9.87分 | step: 442880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 444158 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 444160 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1735/2000, 耗时:0.01分/9.90分 | step: 444160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 444415 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 444925 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 445434 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1740/2000, 耗时:0.01分/9.93分 | step: 445440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 446460 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1745/2000, 耗时:0.01分/9.96分 | step: 446720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 446969 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 446971 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1750/2000, 耗时:0.01分/9.99分 | step: 448000 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 448510 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 448512 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 448767 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 449277 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1755/2000, 耗时:0.01分/10.01分 | step: 449280 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 449786 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1760/2000, 耗时:0.01分/10.04分 | step: 450560 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 450812 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 451321 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 451323 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1765/2000, 耗时:0.01分/10.07分 | step: 451840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 452862 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 452864 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 453119 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1770/2000, 耗时:0.01分/10.10分 | step: 453120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 453629 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 454138 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1775/2000, 耗时:0.01分/10.13分 | step: 454400 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 455164 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 455673 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 455675 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1780/2000, 耗时:0.01分/10.16分 | step: 455680 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1785/2000, 耗时:0.01分/10.19分 | step: 456960 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 457214 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 457216 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 457471 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 457981 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1790/2000, 耗时:0.01分/10.22分 | step: 458240 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 458490 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 459516 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1795/2000, 耗时:0.01分/10.25分 | step: 459520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 460025 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 460027 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1800/2000, 耗时:0.01分/10.28分 | step: 460800 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 461566 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 461568 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 461823 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1805/2000, 耗时:0.01分/10.31分 | step: 462080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 462333 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 462842 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1810/2000, 耗时:0.01分/10.34分 | step: 463360 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 463868 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 464377 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 464379 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1815/2000, 耗时:0.01分/10.37分 | step: 464640 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 465918 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 465920 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1820/2000, 耗时:0.01分/10.40分 | step: 465920 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 466175 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 466685 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 467194 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1825/2000, 耗时:0.01分/10.43分 | step: 467200 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 468220 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1830/2000, 耗时:0.01分/10.46分 | step: 468480 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 468729 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 468731 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1835/2000, 耗时:0.01分/10.49分 | step: 469760 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 470270 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 470272 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 470527 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 471037 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1840/2000, 耗时:0.01分/10.52分 | step: 471040 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 471546 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1845/2000, 耗时:0.01分/10.55分 | step: 472320 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 472572 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 473081 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 473083 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1850/2000, 耗时:0.01分/10.58分 | step: 473600 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 474622 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 474624 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 474879 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1855/2000, 耗时:0.01分/10.61分 | step: 474880 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 475389 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 475898 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1860/2000, 耗时:0.01分/10.64分 | step: 476160 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 476924 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 477433 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 477435 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1865/2000, 耗时:0.01分/10.67分 | step: 477440 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
update:1870/2000, 耗时:0.01分/10.70分 | step: 478720 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 478974 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 478976 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 479231 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 479741 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
update:1875/2000, 耗时:0.01分/10.73分 | step: 480000 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 480250 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 481276 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1880/2000, 耗时:0.01分/10.76分 | step: 481280 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 481785 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 481787 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1885/2000, 耗时:0.01分/10.79分 | step: 482560 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 483326 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 483328 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 483583 | worker_6@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1890/2000, 耗时:0.01分/10.82分 | step: 483840 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 484093 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 484602 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1895/2000, 耗时:0.01分/10.85分 | step: 485120 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 485628 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 486137 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
step: 486139 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
update:1900/2000, 耗时:0.01分/10.88分 | step: 486400 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 487678 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 487680 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1905/2000, 耗时:0.01分/10.92分 | step: 487680 | performance: 1.0 | accuracy: 0.00 | loss: -0.00
step: 487935 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 488445 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 488697 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
step: 488954 | worker_1@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
update:1910/2000, 耗时:0.01分/10.95分 | step: 488960 | performance: 1.0 | accuracy: 0.00 | loss: 0.06
step: 489980 | worker_3@n_step_31: average total_reward after train data exhaustion : -0.2 | max total_reward: 259.6
update:1915/2000, 耗时:0.01分/10.97分 | step: 490240 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 490491 | worker_2@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1920/2000, 耗时:0.01分/11.00分 | step: 491520 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 492030 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 492032 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 492287 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 492797 | worker_4@n_step_31: average total_reward after train data exhaustion : -0.0 | max total_reward: 259.6
update:1925/2000, 耗时:0.01分/11.03分 | step: 492800 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 493049 | worker_0@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
step: 493306 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1930/2000, 耗时:0.01分/11.06分 | step: 494080 | performance: 1.0 | accuracy: 0.00 | loss: 0.00
step: 494332 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
step: 494843 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
update:1935/2000, 耗时:0.01分/11.09分 | step: 495360 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 496384 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
step: 496639 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1940/2000, 耗时:0.01分/11.12分 | step: 496640 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 497146 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 497149 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
step: 497401 | worker_0@n_step_31: average total_reward after train data exhaustion : 0.0 | max total_reward: 259.6
update:1945/2000, 耗时:0.01分/11.15分 | step: 497920 | performance: 1.0 | accuracy: 0.00 | loss: 0.03
step: 498430 | worker_5@n_step_31: average total_reward after train data exhaustion : 0.1 | max total_reward: 259.6
step: 498684 | worker_3@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
step: 499194 | worker_1@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 259.6
step: 499195 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.6 | max total_reward: 259.6
update:1950/2000, 耗时:0.01分/11.18分 | step: 499200 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 499967 | worker_6@n_step_31: average total_reward after train data exhaustion : 0.4 | max total_reward: 259.6
step: 500224 | worker_7@n_step_31: average total_reward after train data exhaustion : 0.3 | max total_reward: 259.6
update:1955/2000, 耗时:0.01分/11.21分 | step: 500480 | performance: 1.1 | accuracy: 0.07 | loss: 0.30
update:1960/2000, 耗时:0.01分/11.24分 | step: 501760 | performance: 1.0 | accuracy: 0.00 | loss: 0.46
update:1965/2000, 耗时:0.01分/11.26分 | step: 503040 | performance: 1.1 | accuracy: 0.08 | loss: 0.22
update:1970/2000, 耗时:0.01分/11.29分 | step: 504320 | performance: 1.0 | accuracy: 0.06 | loss: 0.12
step: 504829 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 259.6
step: 505087 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 259.6
update:1975/2000, 耗时:0.01分/11.32分 | step: 505600 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 505851 | worker_2@n_step_31: average total_reward after train data exhaustion : 0.2 | max total_reward: 259.6
step: 506368 | worker_7@n_step_31: average total_reward after train data exhaustion : -0.1 | max total_reward: 259.6
update:1980/2000, 耗时:0.01分/11.35分 | step: 506880 | performance: 1.2 | accuracy: 0.11 | loss: 0.20
step: 507135 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 259.6
step: 507645 | worker_4@n_step_31: average total_reward after train data exhaustion : 1.2 | max total_reward: 259.6
update:1985/2000, 耗时:0.01分/11.38分 | step: 508160 | performance: 1.0 | accuracy: 0.06 | loss: 0.34
step: 508413 | worker_4@n_step_31: average total_reward after train data exhaustion : 0.5 | max total_reward: 259.6
step: 508671 | worker_6@n_step_31: average total_reward after train data exhaustion : 1.3 | max total_reward: 259.6
step: 509179 | worker_2@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 259.6
step: 509184 | worker_7@n_step_31: average total_reward after train data exhaustion : 1.1 | max total_reward: 259.6
update:1990/2000, 耗时:0.01分/11.41分 | step: 509440 | performance: 1.1 | accuracy: 0.07 | loss: 0.19
update:1995/2000, 耗时:0.01分/11.44分 | step: 510720 | performance: 1.3 | accuracy: 0.16 | loss: 0.25
update:2000/2000, 耗时:0.01分/11.47分 | step: 512000 | performance: 5.3 | accuracy: 0.19 | loss: 0.50
----------------------------------------finished----------------------------------------
==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/406 [00:00<?, ?it/s]100%|| 406/406 [00:00<00:00, 135257.14it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 966.03
2023-07-24T12:00:00 | net performance [%] = -3.3969
2023-07-24T12:00:00 | number of trades [#] = 4
==================================================
Trial 50 Complete [00h 11m 55s]
net_wealth: 966.030866172612

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 07h 06m 03s

Search: Running Trial #51

Value             |Best Value So Far |Hyperparameter
7                 |7                 |horizon
730               |730               |lookback
False             |False             |MarketFactor
5                 |14                |lags
0.5               |0.7               |gamma
16                |32                |batch_size
5                 |32                |n_step
0.8               |0.92              |gae_lambda
5                 |0.1               |gradient_clip_norm
3                 |5                 |epochs
1e-05             |0.0001            |actor_lr
5e-05             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4308.000000   4315.000000
mean      0.000441    20062.255222  ...   20144.178930  20118.633889
std       0.027818    16039.874230  ...   16077.649782  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7710.492310   7690.540039
50%       0.000642    11554.824463  ...   11744.425293  11715.610352
75%       0.011655    29873.081836  ...   29961.684570  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 05:09:26.900642: I tensorflow/core/platform/cpu_feature_guard.cc:142]2023-07-28 05:09:26.900682 This TensorFl021:32023 -I0 -077te--2n828 s 00o55:r20023-07-29:26f.low/c:8 900709:2606o.: I 9re/t00692: I tensorflow/core/platform/cppulensoa_fetrflfatormo/urcw/peo_wguard.cc:142] Th u_fecore/pblatformi/0c5ina:a0s rTetuny s9o:r2Filorws opt eb_guariin6adpm.cciu:z_feature142] Tdr ewhis Tensoryith _is oneAPI o pF.lo900ti7Deep Neum57:riz awI tl bi eNneedary ig withsu oneAa opti2twork L0P23I Deer-0pd.7ibr -28 05:0ccn9:2ars:N023or-07-f2eurloa21428 w6/lc o.N2re/0plat]f oe0Thitsw or2rTke5: 09:n2sorFloLy3- mi6(.one/0wDbcrapr u_9f0eabtyur i1nae(o2n_eguryNNarDdN.91mcc)  tis:051i:  oIN)o tp1 61o z7ttiemu:snes742] -e2d wT 8us  iihi0s T e 5thItho ze:t heed er0o nfenf9 :26w.it90APsloofwo/coorllehr /oIw topn1l2i8Dleant6eensgofle:A Copw  PII PtiNrFelngo e nosw fulrUoCDoewe/pcrbfia li nl onwsNaNPe/tceruyrwotrrUu citn aoere/plis rosrtilo oNptriummaek/ Ltwntspciizb oirnkrfati/  plearecortffoLdi ronms/ cipwoprum_/fcipuy_ fthurm( oobeeaaatnne_nr nptfceea-euuaetcurDrNeArPirtyic_aelrNe rI()o_f_gg to  Dunouusaer d.greamatuearrdd..ccccpencccD eheo p-:1N:N)142:c144erfaor22 tl]l]tioo o i  ThNweiuTrihsi sn utsTn]ei tcaelg als :N eCnPt o pTweenrsAo saortVUr hiXoF lAe nTinVstfoohlXosr: Filsr wk  lu AVoLboiwn abwincX iinbgrAaVr t2ryy i
CPa iiXUrsTs o 2
y  oopnTs t eon aibnle  perfeinosn(TontrarbmaeDeletuNcnsophteimm ncN ttiioeh-enr oo)tmh etri zoepcod usFierleorwm izinia titoh st nisceni boin, rebe atuiladrnl   withh eyr  ofp ipesoedrow itopltlimarho woinnpier fotiooaetTgznAeArns,eioPman  CnIcd wrPP eD-eI DUs:c rbiu iitheeipe  Ntelunrsaol norn dseep FNettrwuNic aTl coteiAeoonesplenrruaAP sionrVXt ioo FrIA nwlokw Lip ewrithb rDa fwatVeolr hietp rsyNeeh Nt: t wo(he uXoamp reka nApVroLpibrX a2pnpra lA NcVrraeXi2atee
-Toreyt w(orpkr iLac t
oo eenarblTi DcNiet bomoitnhN)r ceanacpoieeD balreytm ml (li ptihleeorenr N  o Nf) foton etDo lNNpeuru)selasheeraam  tghse.  gf t
s.i noi
the tpoo ooelnft rahloouteswlsir:i leo n o nogAwVX AVingsp CPU et inrh,Xsattriuoe c nrC2ftose
TiPlbo,oUnlsu en i o ablld Teieinstructnn wris tieobuiphnnosrFleo ldg CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the w TensorFlow wit with the appropriate compiler flags.
erformance-critical operations: mi in other operations, rebuild TensorFlow with the appropriate compiler flags.
 AVX Aahp the appropriate compiler flags.
VX2
To enable them in othepn performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
r operations, rebuild TensorFlow with the appropriate compiler flags.
ropriate compiler flags.
2023-07-28 05:09:27.512938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:09:27.529887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:09:27.530969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:09:27.534109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:09:27.541687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:09:27.542361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:09:27.586201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:09:27.606427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   200 | performance: 1.0 | accuracy: 0.40 | loss: 1.30
update: 10/2000, 耗时:0.00分/0.04分 | step:   400 | performance: 0.9 | accuracy: 0.40 | loss: 0.92
update: 15/2000, 耗时:0.00分/0.04分 | step:   600 | performance: 1.0 | accuracy: 0.41 | loss: 0.86
update: 20/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 0.7 | accuracy: 0.38 | loss: 0.94
update: 25/2000, 耗时:0.00分/0.06分 | step:  1000 | performance: 0.6 | accuracy: 0.38 | loss: 0.57
update: 30/2000, 耗时:0.00分/0.07分 | step:  1200 | performance: 0.6 | accuracy: 0.37 | loss: 0.66
update: 35/2000, 耗时:0.00分/0.08分 | step:  1400 | performance: 1.2 | accuracy: 0.39 | loss: 1.33
update: 40/2000, 耗时:0.00分/0.09分 | step:  1600 | performance: 1.0 | accuracy: 0.38 | loss: 0.97
update: 45/2000, 耗时:0.00分/0.10分 | step:  1800 | performance: 0.7 | accuracy: 0.36 | loss: 0.78
update: 50/2000, 耗时:0.00分/0.10分 | step:  2000 | performance: 1.0 | accuracy: 0.37 | loss: 0.74
update: 55/2000, 耗时:0.00分/0.11分 | step:  2200 | performance: 0.7 | accuracy: 0.36 | loss: 0.60
update: 60/2000, 耗时:0.00分/0.12分 | step:  2400 | performance: 0.7 | accuracy: 0.37 | loss: 0.82
update: 65/2000, 耗时:0.00分/0.13分 | step:  2600 | performance: 0.5 | accuracy: 0.36 | loss: 0.81
update: 70/2000, 耗时:0.00分/0.14分 | step:  2800 | performance: 0.4 | accuracy: 0.36 | loss: 0.62
update: 75/2000, 耗时:0.00分/0.15分 | step:  3000 | performance: 0.4 | accuracy: 0.35 | loss: 0.55
update: 80/2000, 耗时:0.00分/0.16分 | step:  3200 | performance: 0.4 | accuracy: 0.35 | loss: 0.37
update: 85/2000, 耗时:0.00分/0.17分 | step:  3400 | performance: 0.3 | accuracy: 0.34 | loss: 0.71
update: 90/2000, 耗时:0.00分/0.18分 | step:  3600 | performance: 0.3 | accuracy: 0.33 | loss: 1.46
update: 95/2000, 耗时:0.00分/0.19分 | step:  3800 | performance: 0.2 | accuracy: 0.33 | loss: 0.51
update:100/2000, 耗时:0.00分/0.20分 | step:  4000 | performance: 0.3 | accuracy: 0.33 | loss: 0.59
update:105/2000, 耗时:0.00分/0.21分 | step:  4200 | performance: 0.6 | accuracy: 0.34 | loss: 2.97
update:110/2000, 耗时:0.00分/0.22分 | step:  4400 | performance: 0.4 | accuracy: 0.33 | loss: 1.72
update:115/2000, 耗时:0.00分/0.23分 | step:  4600 | performance: 0.5 | accuracy: 0.33 | loss: 0.89
update:120/2000, 耗时:0.00分/0.24分 | step:  4800 | performance: 1.5 | accuracy: 0.33 | loss: 0.74
update:125/2000, 耗时:0.00分/0.25分 | step:  5000 | performance: 1.6 | accuracy: 0.33 | loss: 0.83
update:130/2000, 耗时:0.00分/0.26分 | step:  5200 | performance: 1.3 | accuracy: 0.32 | loss: 0.56
update:135/2000, 耗时:0.00分/0.27分 | step:  5400 | performance: 1.4 | accuracy: 0.32 | loss: 2.04
update:140/2000, 耗时:0.00分/0.28分 | step:  5600 | performance: 1.9 | accuracy: 0.32 | loss: 0.86
update:145/2000, 耗时:0.00分/0.29分 | step:  5800 | performance: 1.5 | accuracy: 0.32 | loss: 0.89
update:150/2000, 耗时:0.00分/0.30分 | step:  6000 | performance: 1.6 | accuracy: 0.32 | loss: 0.74
update:155/2000, 耗时:0.00分/0.31分 | step:  6200 | performance: 1.4 | accuracy: 0.32 | loss: 0.58
update:160/2000, 耗时:0.00分/0.32分 | step:  6400 | performance: 0.4 | accuracy: 0.32 | loss: 0.53
update:165/2000, 耗时:0.00分/0.33分 | step:  6600 | performance: 0.3 | accuracy: 0.32 | loss: 0.59
update:170/2000, 耗时:0.00分/0.34分 | step:  6800 | performance: 0.2 | accuracy: 0.31 | loss: 0.72
update:175/2000, 耗时:0.00分/0.35分 | step:  7000 | performance: 0.1 | accuracy: 0.31 | loss: 0.50
update:180/2000, 耗时:0.00分/0.36分 | step:  7200 | performance: 0.0 | accuracy: 0.31 | loss: 0.99
update:185/2000, 耗时:0.00分/0.37分 | step:  7400 | performance: 0.1 | accuracy: 0.31 | loss: 0.46
update:190/2000, 耗时:0.00分/0.38分 | step:  7600 | performance: 0.1 | accuracy: 0.32 | loss: 1.00
update:195/2000, 耗时:0.00分/0.39分 | step:  7800 | performance: 0.1 | accuracy: 0.32 | loss: 0.45
update:200/2000, 耗时:0.00分/0.40分 | step:  8000 | performance: 0.0 | accuracy: 0.31 | loss: 0.48
update:205/2000, 耗时:0.00分/0.41分 | step:  8200 | performance: 0.0 | accuracy: 0.32 | loss: 0.63
update:210/2000, 耗时:0.00分/0.42分 | step:  8400 | performance: 0.1 | accuracy: 0.32 | loss: 0.68
update:215/2000, 耗时:0.00分/0.43分 | step:  8600 | performance: 0.1 | accuracy: 0.32 | loss: 0.86
update:220/2000, 耗时:0.00分/0.44分 | step:  8800 | performance: 0.0 | accuracy: 0.32 | loss: 0.96
update:225/2000, 耗时:0.00分/0.45分 | step:  9000 | performance: 0.1 | accuracy: 0.32 | loss: 1.82
update:230/2000, 耗时:0.00分/0.46分 | step:  9200 | performance: 0.1 | accuracy: 0.32 | loss: 0.64
update:235/2000, 耗时:0.00分/0.47分 | step:  9400 | performance: 0.0 | accuracy: 0.31 | loss: 0.35
update:240/2000, 耗时:0.00分/0.48分 | step:  9600 | performance: 0.0 | accuracy: 0.31 | loss: 0.54
update:245/2000, 耗时:0.00分/0.49分 | step:  9800 | performance: 0.0 | accuracy: 0.31 | loss: 0.40
update:250/2000, 耗时:0.00分/0.50分 | step: 10000 | performance: 0.0 | accuracy: 0.31 | loss: 0.30
update:255/2000, 耗时:0.00分/0.51分 | step: 10200 | performance: 0.0 | accuracy: 0.31 | loss: 0.94
update:260/2000, 耗时:0.00分/0.52分 | step: 10400 | performance: 0.0 | accuracy: 0.31 | loss: 0.42
update:265/2000, 耗时:0.00分/0.53分 | step: 10600 | performance: 0.0 | accuracy: 0.31 | loss: 0.58
update:270/2000, 耗时:0.00分/0.54分 | step: 10800 | performance: 0.0 | accuracy: 0.31 | loss: 0.38
update:275/2000, 耗时:0.00分/0.55分 | step: 11000 | performance: 0.0 | accuracy: 0.32 | loss: 0.55
update:280/2000, 耗时:0.00分/0.56分 | step: 11200 | performance: 0.0 | accuracy: 0.32 | loss: 0.52
update:285/2000, 耗时:0.00分/0.57分 | step: 11400 | performance: 0.1 | accuracy: 0.32 | loss: 0.66
update:290/2000, 耗时:0.00分/0.58分 | step: 11600 | performance: 0.1 | accuracy: 0.32 | loss: 0.47
update:295/2000, 耗时:0.00分/0.59分 | step: 11800 | performance: 0.1 | accuracy: 0.32 | loss: 0.99
update:300/2000, 耗时:0.00分/0.60分 | step: 12000 | performance: 0.1 | accuracy: 0.32 | loss: 0.39
update:305/2000, 耗时:0.00分/0.61分 | step: 12200 | performance: 0.1 | accuracy: 0.32 | loss: 0.51
update:310/2000, 耗时:0.00分/0.62分 | step: 12400 | performance: 0.1 | accuracy: 0.33 | loss: 0.50
update:315/2000, 耗时:0.00分/0.63分 | step: 12600 | performance: 0.1 | accuracy: 0.33 | loss: 0.33
update:320/2000, 耗时:0.00分/0.64分 | step: 12800 | performance: 0.1 | accuracy: 0.33 | loss: 0.45
update:325/2000, 耗时:0.00分/0.66分 | step: 13000 | performance: 0.3 | accuracy: 0.34 | loss: 0.48
update:330/2000, 耗时:0.00分/0.67分 | step: 13200 | performance: 0.3 | accuracy: 0.34 | loss: 0.46
update:335/2000, 耗时:0.00分/0.68分 | step: 13400 | performance: 0.3 | accuracy: 0.34 | loss: 1.18
update:340/2000, 耗时:0.00分/0.69分 | step: 13600 | performance: 0.8 | accuracy: 0.34 | loss: 0.62
update:345/2000, 耗时:0.00分/0.70分 | step: 13800 | performance: 4.0 | accuracy: 0.34 | loss: 0.55
update:350/2000, 耗时:0.00分/0.71分 | step: 14000 | performance: 2.4 | accuracy: 0.34 | loss: 1.78
update:355/2000, 耗时:0.00分/0.72分 | step: 14200 | performance: 2.8 | accuracy: 0.35 | loss: 0.99
update:360/2000, 耗时:0.00分/0.73分 | step: 14400 | performance: 5.0 | accuracy: 0.35 | loss: 0.35
update:365/2000, 耗时:0.00分/0.74分 | step: 14600 | performance: 5.5 | accuracy: 0.35 | loss: 0.91
update:370/2000, 耗时:0.00分/0.75分 | step: 14800 | performance: 14.3 | accuracy: 0.35 | loss: 0.73
update:375/2000, 耗时:0.00分/0.76分 | step: 15000 | performance: 8.9 | accuracy: 0.35 | loss: 0.72
update:380/2000, 耗时:0.00分/0.77分 | step: 15200 | performance: 11.4 | accuracy: 0.35 | loss: 0.98
update:385/2000, 耗时:0.00分/0.78分 | step: 15400 | performance: 9.6 | accuracy: 0.35 | loss: 1.86
update:390/2000, 耗时:0.00分/0.79分 | step: 15600 | performance: 8.8 | accuracy: 0.35 | loss: 0.78
update:395/2000, 耗时:0.00分/0.80分 | step: 15800 | performance: 11.7 | accuracy: 0.35 | loss: 1.24
update:400/2000, 耗时:0.00分/0.81分 | step: 16000 | performance: 13.2 | accuracy: 0.35 | loss: 0.73
update:405/2000, 耗时:0.00分/0.82分 | step: 16200 | performance: 14.0 | accuracy: 0.35 | loss: 0.78
update:410/2000, 耗时:0.00分/0.83分 | step: 16400 | performance: 17.7 | accuracy: 0.35 | loss: 0.75
update:415/2000, 耗时:0.00分/0.84分 | step: 16600 | performance: 18.8 | accuracy: 0.35 | loss: 0.62
update:420/2000, 耗时:0.00分/0.85分 | step: 16800 | performance: 16.8 | accuracy: 0.35 | loss: 0.78
update:425/2000, 耗时:0.00分/0.86分 | step: 17000 | performance: 30.0 | accuracy: 0.35 | loss: 1.09
update:430/2000, 耗时:0.00分/0.87分 | step: 17200 | performance: 19.4 | accuracy: 0.35 | loss: 0.54
update:435/2000, 耗时:0.00分/0.88分 | step: 17400 | performance: 24.7 | accuracy: 0.35 | loss: 0.86
update:440/2000, 耗时:0.00分/0.89分 | step: 17600 | performance: 28.3 | accuracy: 0.35 | loss: 0.65
update:445/2000, 耗时:0.00分/0.90分 | step: 17800 | performance: 31.7 | accuracy: 0.35 | loss: 0.75
update:450/2000, 耗时:0.00分/0.91分 | step: 18000 | performance: 21.0 | accuracy: 0.35 | loss: 0.51
update:455/2000, 耗时:0.00分/0.92分 | step: 18200 | performance: 40.5 | accuracy: 0.36 | loss: 0.55
update:460/2000, 耗时:0.00分/0.93分 | step: 18400 | performance: 55.4 | accuracy: 0.36 | loss: 0.91
update:465/2000, 耗时:0.00分/0.94分 | step: 18600 | performance: 56.9 | accuracy: 0.36 | loss: 0.73
update:470/2000, 耗时:0.00分/0.95分 | step: 18800 | performance: 52.3 | accuracy: 0.36 | loss: 1.71
update:475/2000, 耗时:0.00分/0.96分 | step: 19000 | performance: 51.2 | accuracy: 0.36 | loss: 1.27
update:480/2000, 耗时:0.00分/0.97分 | step: 19200 | performance: 37.2 | accuracy: 0.36 | loss: 0.51
update:485/2000, 耗时:0.00分/0.98分 | step: 19400 | performance: 24.8 | accuracy: 0.36 | loss: 0.83
update:490/2000, 耗时:0.00分/0.99分 | step: 19600 | performance: 18.4 | accuracy: 0.36 | loss: 1.00
update:495/2000, 耗时:0.00分/1.00分 | step: 19800 | performance: 19.6 | accuracy: 0.36 | loss: 0.61
update:500/2000, 耗时:0.00分/1.01分 | step: 20000 | performance: 19.8 | accuracy: 0.36 | loss: 0.25
update:505/2000, 耗时:0.00分/1.02分 | step: 20200 | performance: 22.0 | accuracy: 0.36 | loss: 0.31
update:510/2000, 耗时:0.00分/1.03分 | step: 20400 | performance: 19.5 | accuracy: 0.36 | loss: 0.51
update:515/2000, 耗时:0.00分/1.04分 | step: 20600 | performance: 37.4 | accuracy: 0.36 | loss: 0.45
update:520/2000, 耗时:0.00分/1.06分 | step: 20800 | performance: 36.9 | accuracy: 0.35 | loss: 0.48
update:525/2000, 耗时:0.00分/1.06分 | step: 21000 | performance: 38.6 | accuracy: 0.35 | loss: 0.54
update:530/2000, 耗时:0.00分/1.07分 | step: 21200 | performance: 29.1 | accuracy: 0.35 | loss: 0.54
update:535/2000, 耗时:0.00分/1.09分 | step: 21400 | performance: 26.5 | accuracy: 0.35 | loss: 0.88
update:540/2000, 耗时:0.00分/1.10分 | step: 21600 | performance: 65.5 | accuracy: 0.36 | loss: 0.97
update:545/2000, 耗时:0.00分/1.11分 | step: 21800 | performance: 76.4 | accuracy: 0.36 | loss: 0.44
update:550/2000, 耗时:0.00分/1.12分 | step: 22000 | performance: 71.2 | accuracy: 0.35 | loss: 0.53
update:555/2000, 耗时:0.00分/1.13分 | step: 22200 | performance: 133.1 | accuracy: 0.36 | loss: 0.86
update:560/2000, 耗时:0.00分/1.14分 | step: 22400 | performance: 150.4 | accuracy: 0.35 | loss: 0.73
update:565/2000, 耗时:0.00分/1.15分 | step: 22600 | performance: 163.6 | accuracy: 0.35 | loss: 0.70
update:570/2000, 耗时:0.00分/1.16分 | step: 22800 | performance: 129.0 | accuracy: 0.35 | loss: 0.70
update:575/2000, 耗时:0.00分/1.17分 | step: 23000 | performance: 95.9 | accuracy: 0.35 | loss: 0.56
update:580/2000, 耗时:0.00分/1.18分 | step: 23200 | performance: 105.3 | accuracy: 0.35 | loss: 1.25
update:585/2000, 耗时:0.00分/1.19分 | step: 23400 | performance: 112.6 | accuracy: 0.35 | loss: 0.31
update:590/2000, 耗时:0.00分/1.20分 | step: 23600 | performance: 193.4 | accuracy: 0.35 | loss: 0.69
update:595/2000, 耗时:0.00分/1.21分 | step: 23800 | performance: 186.0 | accuracy: 0.35 | loss: 0.35
update:600/2000, 耗时:0.00分/1.22分 | step: 24000 | performance: 151.1 | accuracy: 0.35 | loss: 0.52
update:605/2000, 耗时:0.00分/1.23分 | step: 24200 | performance: 162.1 | accuracy: 0.35 | loss: 0.46
update:610/2000, 耗时:0.00分/1.24分 | step: 24400 | performance: 144.9 | accuracy: 0.35 | loss: 0.53
update:615/2000, 耗时:0.00分/1.25分 | step: 24600 | performance: 182.1 | accuracy: 0.35 | loss: 0.36
update:620/2000, 耗时:0.00分/1.26分 | step: 24800 | performance: 157.3 | accuracy: 0.35 | loss: 0.65
update:625/2000, 耗时:0.00分/1.27分 | step: 25000 | performance: 161.9 | accuracy: 0.35 | loss: 0.46
update:630/2000, 耗时:0.00分/1.28分 | step: 25200 | performance: 143.8 | accuracy: 0.35 | loss: 0.49
update:635/2000, 耗时:0.00分/1.29分 | step: 25400 | performance: 1.0 | accuracy: 0.33 | loss: 0.46
Saving PPO weights in both H5 format and checkpoint @ update:635 
update:640/2000, 耗时:0.00分/1.31分 | step: 25600 | performance: 1.4 | accuracy: 0.36 | loss: 0.57
update:645/2000, 耗时:0.00分/1.32分 | step: 25800 | performance: 1.5 | accuracy: 0.38 | loss: 0.44
update:650/2000, 耗时:0.00分/1.33分 | step: 26000 | performance: 1.4 | accuracy: 0.35 | loss: 0.40
update:655/2000, 耗时:0.00分/1.34分 | step: 26200 | performance: 1.8 | accuracy: 0.38 | loss: 0.32
update:660/2000, 耗时:0.00分/1.35分 | step: 26400 | performance: 1.5 | accuracy: 0.35 | loss: 0.46
update:665/2000, 耗时:0.00分/1.36分 | step: 26600 | performance: 1.5 | accuracy: 0.36 | loss: 1.15
update:670/2000, 耗时:0.00分/1.37分 | step: 26800 | performance: 1.1 | accuracy: 0.35 | loss: 0.73
update:675/2000, 耗时:0.00分/1.38分 | step: 27000 | performance: 1.1 | accuracy: 0.33 | loss: 0.43
update:680/2000, 耗时:0.00分/1.39分 | step: 27200 | performance: 1.6 | accuracy: 0.34 | loss: 0.67
update:685/2000, 耗时:0.00分/1.40分 | step: 27400 | performance: 1.8 | accuracy: 0.34 | loss: 0.43
update:690/2000, 耗时:0.00分/1.41分 | step: 27600 | performance: 2.5 | accuracy: 0.34 | loss: 0.42
update:695/2000, 耗时:0.00分/1.42分 | step: 27800 | performance: 2.2 | accuracy: 0.33 | loss: 0.72
update:700/2000, 耗时:0.00分/1.43分 | step: 28000 | performance: 1.9 | accuracy: 0.34 | loss: 0.78
update:705/2000, 耗时:0.00分/1.44分 | step: 28200 | performance: 1.9 | accuracy: 0.33 | loss: 0.65
update:710/2000, 耗时:0.00分/1.45分 | step: 28400 | performance: 2.4 | accuracy: 0.34 | loss: 0.42
update:715/2000, 耗时:0.00分/1.46分 | step: 28600 | performance: 2.6 | accuracy: 0.35 | loss: 0.47
update:720/2000, 耗时:0.00分/1.47分 | step: 28800 | performance: 2.1 | accuracy: 0.35 | loss: 1.11
update:725/2000, 耗时:0.00分/1.48分 | step: 29000 | performance: 2.0 | accuracy: 0.34 | loss: 0.46
update:730/2000, 耗时:0.00分/1.49分 | step: 29200 | performance: 1.8 | accuracy: 0.33 | loss: 0.40
update:735/2000, 耗时:0.00分/1.50分 | step: 29400 | performance: 1.8 | accuracy: 0.34 | loss: 0.84
update:740/2000, 耗时:0.00分/1.51分 | step: 29600 | performance: 3.7 | accuracy: 0.33 | loss: 0.35
update:745/2000, 耗时:0.00分/1.52分 | step: 29800 | performance: 3.2 | accuracy: 0.33 | loss: 0.32
update:750/2000, 耗时:0.00分/1.53分 | step: 30000 | performance: 4.8 | accuracy: 0.33 | loss: 1.84
update:755/2000, 耗时:0.00分/1.54分 | step: 30200 | performance: 15.3 | accuracy: 0.34 | loss: 0.52
update:760/2000, 耗时:0.00分/1.56分 | step: 30400 | performance: 11.3 | accuracy: 0.32 | loss: 0.40
update:765/2000, 耗时:0.00分/1.57分 | step: 30600 | performance: 5.3 | accuracy: 0.32 | loss: 0.73
update:770/2000, 耗时:0.00分/1.58分 | step: 30800 | performance: 13.9 | accuracy: 0.33 | loss: 1.43
update:775/2000, 耗时:0.00分/1.59分 | step: 31000 | performance: 10.6 | accuracy: 0.32 | loss: 0.56
update:780/2000, 耗时:0.00分/1.60分 | step: 31200 | performance: 9.8 | accuracy: 0.33 | loss: 0.76
update:785/2000, 耗时:0.00分/1.61分 | step: 31400 | performance: 17.5 | accuracy: 0.33 | loss: 0.45
update:790/2000, 耗时:0.00分/1.62分 | step: 31600 | performance: 12.8 | accuracy: 0.33 | loss: 1.27
update:795/2000, 耗时:0.00分/1.63分 | step: 31800 | performance: 4.5 | accuracy: 0.33 | loss: 0.43
update:800/2000, 耗时:0.00分/1.64分 | step: 32000 | performance: 4.6 | accuracy: 0.33 | loss: 0.54
update:805/2000, 耗时:0.00分/1.65分 | step: 32200 | performance: 8.5 | accuracy: 0.33 | loss: 0.48
update:810/2000, 耗时:0.00分/1.66分 | step: 32400 | performance: 8.3 | accuracy: 0.33 | loss: 0.48
update:815/2000, 耗时:0.00分/1.67分 | step: 32600 | performance: 2.6 | accuracy: 0.32 | loss: 0.70
update:820/2000, 耗时:0.00分/1.68分 | step: 32800 | performance: 3.4 | accuracy: 0.32 | loss: 0.35
update:825/2000, 耗时:0.00分/1.69分 | step: 33000 | performance: 4.2 | accuracy: 0.32 | loss: 0.97
update:830/2000, 耗时:0.00分/1.70分 | step: 33200 | performance: 4.1 | accuracy: 0.33 | loss: 0.72
update:835/2000, 耗时:0.00分/1.71分 | step: 33400 | performance: 5.0 | accuracy: 0.33 | loss: 0.69
update:840/2000, 耗时:0.00分/1.72分 | step: 33600 | performance: 5.0 | accuracy: 0.32 | loss: 0.52
update:845/2000, 耗时:0.00分/1.73分 | step: 33800 | performance: 3.9 | accuracy: 0.32 | loss: 0.49
update:850/2000, 耗时:0.00分/1.74分 | step: 34000 | performance: 3.7 | accuracy: 0.32 | loss: 0.49
update:855/2000, 耗时:0.00分/1.75分 | step: 34200 | performance: 2.6 | accuracy: 0.33 | loss: 0.78
update:860/2000, 耗时:0.00分/1.76分 | step: 34400 | performance: 1.0 | accuracy: 0.32 | loss: 0.48
update:865/2000, 耗时:0.00分/1.77分 | step: 34600 | performance: 1.2 | accuracy: 0.32 | loss: 0.36
update:870/2000, 耗时:0.00分/1.78分 | step: 34800 | performance: 0.8 | accuracy: 0.32 | loss: 0.54
update:875/2000, 耗时:0.00分/1.79分 | step: 35000 | performance: 0.6 | accuracy: 0.32 | loss: 0.67
update:880/2000, 耗时:0.00分/1.80分 | step: 35200 | performance: 0.5 | accuracy: 0.32 | loss: 0.33
update:885/2000, 耗时:0.00分/1.81分 | step: 35400 | performance: 0.3 | accuracy: 0.31 | loss: 0.41
update:890/2000, 耗时:0.00分/1.82分 | step: 35600 | performance: 0.4 | accuracy: 0.32 | loss: 0.51
update:895/2000, 耗时:0.00分/1.83分 | step: 35800 | performance: 0.4 | accuracy: 0.32 | loss: 0.53
update:900/2000, 耗时:0.00分/1.84分 | step: 36000 | performance: 0.4 | accuracy: 0.32 | loss: 0.47
update:905/2000, 耗时:0.00分/1.85分 | step: 36200 | performance: 0.4 | accuracy: 0.32 | loss: 0.79
update:910/2000, 耗时:0.00分/1.86分 | step: 36400 | performance: 0.4 | accuracy: 0.32 | loss: 0.59
update:915/2000, 耗时:0.00分/1.87分 | step: 36600 | performance: 0.6 | accuracy: 0.33 | loss: 0.71
update:920/2000, 耗时:0.00分/1.88分 | step: 36800 | performance: 0.6 | accuracy: 0.33 | loss: 0.43
update:925/2000, 耗时:0.00分/1.89分 | step: 37000 | performance: 0.5 | accuracy: 0.33 | loss: 1.44
update:930/2000, 耗时:0.00分/1.90分 | step: 37200 | performance: 0.3 | accuracy: 0.33 | loss: 0.54
update:935/2000, 耗时:0.00分/1.91分 | step: 37400 | performance: 0.3 | accuracy: 0.33 | loss: 0.49
update:940/2000, 耗时:0.00分/1.92分 | step: 37600 | performance: 0.3 | accuracy: 0.33 | loss: 0.71
update:945/2000, 耗时:0.00分/1.93分 | step: 37800 | performance: 0.3 | accuracy: 0.33 | loss: 0.61
update:950/2000, 耗时:0.00分/1.94分 | step: 38000 | performance: 0.4 | accuracy: 0.34 | loss: 0.41
update:955/2000, 耗时:0.00分/1.95分 | step: 38200 | performance: 0.7 | accuracy: 0.34 | loss: 1.11
update:960/2000, 耗时:0.00分/1.96分 | step: 38400 | performance: 1.6 | accuracy: 0.35 | loss: 0.17
update:965/2000, 耗时:0.00分/1.98分 | step: 38600 | performance: 1.8 | accuracy: 0.35 | loss: 0.85
update:970/2000, 耗时:0.00分/1.99分 | step: 38800 | performance: 3.4 | accuracy: 0.35 | loss: 1.18
update:975/2000, 耗时:0.00分/2.00分 | step: 39000 | performance: 8.4 | accuracy: 0.36 | loss: 0.34
update:980/2000, 耗时:0.00分/2.01分 | step: 39200 | performance: 36.3 | accuracy: 0.36 | loss: 3.36
update:985/2000, 耗时:0.00分/2.02分 | step: 39400 | performance: 16.9 | accuracy: 0.36 | loss: 1.93
update:990/2000, 耗时:0.00分/2.03分 | step: 39600 | performance: 32.0 | accuracy: 0.36 | loss: 0.65
update:995/2000, 耗时:0.00分/2.04分 | step: 39800 | performance: 76.5 | accuracy: 0.36 | loss: 0.49
update:1000/2000, 耗时:0.00分/2.05分 | step: 40000 | performance: 27.5 | accuracy: 0.36 | loss: 0.42
update:1005/2000, 耗时:0.00分/2.06分 | step: 40200 | performance: 30.8 | accuracy: 0.36 | loss: 1.01
update:1010/2000, 耗时:0.00分/2.07分 | step: 40400 | performance: 19.0 | accuracy: 0.36 | loss: 0.54
update:1015/2000, 耗时:0.00分/2.08分 | step: 40600 | performance: 32.3 | accuracy: 0.36 | loss: 1.08
update:1020/2000, 耗时:0.00分/2.09分 | step: 40800 | performance: 32.8 | accuracy: 0.37 | loss: 1.14
update:1025/2000, 耗时:0.00分/2.10分 | step: 41000 | performance: 28.5 | accuracy: 0.37 | loss: 0.52
update:1030/2000, 耗时:0.00分/2.11分 | step: 41200 | performance: 10.4 | accuracy: 0.36 | loss: 1.29
update:1035/2000, 耗时:0.00分/2.12分 | step: 41400 | performance: 5.5 | accuracy: 0.36 | loss: 0.39
update:1040/2000, 耗时:0.00分/2.13分 | step: 41600 | performance: 6.4 | accuracy: 0.36 | loss: 0.69
update:1045/2000, 耗时:0.00分/2.15分 | step: 41800 | performance: 8.4 | accuracy: 0.36 | loss: 0.70
update:1050/2000, 耗时:0.00分/2.16分 | step: 42000 | performance: 11.7 | accuracy: 0.36 | loss: 0.34
update:1055/2000, 耗时:0.00分/2.17分 | step: 42200 | performance: 13.6 | accuracy: 0.36 | loss: 0.66
update:1060/2000, 耗时:0.00分/2.18分 | step: 42400 | performance: 32.8 | accuracy: 0.37 | loss: 0.72
update:1065/2000, 耗时:0.00分/2.19分 | step: 42600 | performance: 23.2 | accuracy: 0.36 | loss: 0.42
update:1070/2000, 耗时:0.00分/2.20分 | step: 42800 | performance: 28.9 | accuracy: 0.36 | loss: 0.60
update:1075/2000, 耗时:0.00分/2.21分 | step: 43000 | performance: 28.4 | accuracy: 0.36 | loss: 0.58
update:1080/2000, 耗时:0.00分/2.22分 | step: 43200 | performance: 32.3 | accuracy: 0.37 | loss: 0.57
update:1085/2000, 耗时:0.00分/2.23分 | step: 43400 | performance: 24.1 | accuracy: 0.37 | loss: 0.72
update:1090/2000, 耗时:0.00分/2.24分 | step: 43600 | performance: 60.7 | accuracy: 0.37 | loss: 0.33
update:1095/2000, 耗时:0.00分/2.25分 | step: 43800 | performance: 86.6 | accuracy: 0.37 | loss: 0.42
update:1100/2000, 耗时:0.00分/2.26分 | step: 44000 | performance: 82.2 | accuracy: 0.37 | loss: 0.75
update:1105/2000, 耗时:0.00分/2.27分 | step: 44200 | performance: 68.8 | accuracy: 0.37 | loss: 1.61
update:1110/2000, 耗时:0.00分/2.28分 | step: 44400 | performance: 54.1 | accuracy: 0.37 | loss: 0.61
update:1115/2000, 耗时:0.00分/2.29分 | step: 44600 | performance: 43.3 | accuracy: 0.37 | loss: 0.40
update:1120/2000, 耗时:0.00分/2.30分 | step: 44800 | performance: 55.7 | accuracy: 0.37 | loss: 0.75
update:1125/2000, 耗时:0.00分/2.31分 | step: 45000 | performance: 30.1 | accuracy: 0.37 | loss: 1.07
update:1130/2000, 耗时:0.00分/2.32分 | step: 45200 | performance: 24.1 | accuracy: 0.37 | loss: 1.13
update:1135/2000, 耗时:0.00分/2.33分 | step: 45400 | performance: 17.2 | accuracy: 0.37 | loss: 0.34
update:1140/2000, 耗时:0.00分/2.34分 | step: 45600 | performance: 9.9 | accuracy: 0.37 | loss: 0.40
update:1145/2000, 耗时:0.00分/2.35分 | step: 45800 | performance: 9.6 | accuracy: 0.37 | loss: 0.75
update:1150/2000, 耗时:0.00分/2.36分 | step: 46000 | performance: 21.7 | accuracy: 0.37 | loss: 0.27
update:1155/2000, 耗时:0.00分/2.37分 | step: 46200 | performance: 20.0 | accuracy: 0.37 | loss: 0.59
update:1160/2000, 耗时:0.00分/2.38分 | step: 46400 | performance: 18.7 | accuracy: 0.37 | loss: 0.50
update:1165/2000, 耗时:0.00分/2.39分 | step: 46600 | performance: 14.8 | accuracy: 0.37 | loss: 0.57
update:1170/2000, 耗时:0.00分/2.40分 | step: 46800 | performance: 17.5 | accuracy: 0.37 | loss: 0.80
update:1175/2000, 耗时:0.00分/2.41分 | step: 47000 | performance: 23.1 | accuracy: 0.37 | loss: 0.63
update:1180/2000, 耗时:0.00分/2.42分 | step: 47200 | performance: 26.2 | accuracy: 0.37 | loss: 0.45
update:1185/2000, 耗时:0.00分/2.43分 | step: 47400 | performance: 21.5 | accuracy: 0.37 | loss: 0.37
update:1190/2000, 耗时:0.00分/2.44分 | step: 47600 | performance: 96.1 | accuracy: 0.37 | loss: 0.54
update:1195/2000, 耗时:0.00分/2.45分 | step: 47800 | performance: 113.5 | accuracy: 0.37 | loss: 0.70
update:1200/2000, 耗时:0.00分/2.46分 | step: 48000 | performance: 101.7 | accuracy: 0.36 | loss: 0.96
update:1205/2000, 耗时:0.00分/2.47分 | step: 48200 | performance: 100.0 | accuracy: 0.36 | loss: 0.44
update:1210/2000, 耗时:0.00分/2.48分 | step: 48400 | performance: 92.3 | accuracy: 0.36 | loss: 0.31
update:1215/2000, 耗时:0.00分/2.49分 | step: 48600 | performance: 115.9 | accuracy: 0.36 | loss: 0.78
update:1220/2000, 耗时:0.00分/2.50分 | step: 48800 | performance: 133.9 | accuracy: 0.36 | loss: 0.40
update:1225/2000, 耗时:0.00分/2.51分 | step: 49000 | performance: 90.6 | accuracy: 0.36 | loss: 0.52
update:1230/2000, 耗时:0.00分/2.52分 | step: 49200 | performance: 80.8 | accuracy: 0.36 | loss: 0.59
update:1235/2000, 耗时:0.00分/2.53分 | step: 49400 | performance: 81.8 | accuracy: 0.36 | loss: 0.58
update:1240/2000, 耗时:0.00分/2.54分 | step: 49600 | performance: 86.8 | accuracy: 0.36 | loss: 0.36
update:1245/2000, 耗时:0.00分/2.56分 | step: 49800 | performance: 85.2 | accuracy: 0.36 | loss: 0.65
update:1250/2000, 耗时:0.00分/2.57分 | step: 50000 | performance: 99.2 | accuracy: 0.36 | loss: 0.24
update:1255/2000, 耗时:0.00分/2.58分 | step: 50200 | performance: 92.5 | accuracy: 0.36 | loss: 0.49
update:1260/2000, 耗时:0.00分/2.59分 | step: 50400 | performance: 89.2 | accuracy: 0.36 | loss: 0.47
update:1265/2000, 耗时:0.00分/2.60分 | step: 50600 | performance: 70.9 | accuracy: 0.36 | loss: 0.27
Saving PPO weights in both H5 format and checkpoint @ update:1269 
update:1270/2000, 耗时:0.00分/2.61分 | step: 50800 | performance: 0.9 | accuracy: 0.17 | loss: 0.70
update:1275/2000, 耗时:0.00分/2.62分 | step: 51000 | performance: 0.9 | accuracy: 0.42 | loss: 0.54
update:1280/2000, 耗时:0.00分/2.63分 | step: 51200 | performance: 0.8 | accuracy: 0.32 | loss: 0.51
update:1285/2000, 耗时:0.00分/2.64分 | step: 51400 | performance: 0.8 | accuracy: 0.33 | loss: 0.44
update:1290/2000, 耗时:0.00分/2.65分 | step: 51600 | performance: 1.0 | accuracy: 0.37 | loss: 0.27
update:1295/2000, 耗时:0.00分/2.66分 | step: 51800 | performance: 1.1 | accuracy: 0.38 | loss: 0.55
update:1300/2000, 耗时:0.00分/2.67分 | step: 52000 | performance: 0.9 | accuracy: 0.36 | loss: 1.29
update:1305/2000, 耗时:0.00分/2.68分 | step: 52200 | performance: 2.1 | accuracy: 0.36 | loss: 0.56
update:1310/2000, 耗时:0.00分/2.69分 | step: 52400 | performance: 2.6 | accuracy: 0.34 | loss: 0.25
update:1315/2000, 耗时:0.00分/2.70分 | step: 52600 | performance: 2.4 | accuracy: 0.33 | loss: 0.31
update:1320/2000, 耗时:0.00分/2.71分 | step: 52800 | performance: 2.6 | accuracy: 0.32 | loss: 0.23
update:1325/2000, 耗时:0.00分/2.72分 | step: 53000 | performance: 3.3 | accuracy: 0.33 | loss: 0.42
update:1330/2000, 耗时:0.00分/2.73分 | step: 53200 | performance: 3.6 | accuracy: 0.34 | loss: 0.47
update:1335/2000, 耗时:0.00分/2.74分 | step: 53400 | performance: 3.2 | accuracy: 0.33 | loss: 0.48
update:1340/2000, 耗时:0.00分/2.75分 | step: 53600 | performance: 2.6 | accuracy: 0.32 | loss: 0.76
update:1345/2000, 耗时:0.00分/2.76分 | step: 53800 | performance: 2.3 | accuracy: 0.32 | loss: 0.57
update:1350/2000, 耗时:0.00分/2.77分 | step: 54000 | performance: 2.2 | accuracy: 0.32 | loss: 0.50
update:1355/2000, 耗时:0.00分/2.78分 | step: 54200 | performance: 2.0 | accuracy: 0.33 | loss: 1.15
update:1360/2000, 耗时:0.00分/2.79分 | step: 54400 | performance: 2.6 | accuracy: 0.32 | loss: 0.39
update:1365/2000, 耗时:0.00分/2.80分 | step: 54600 | performance: 2.7 | accuracy: 0.32 | loss: 0.38
update:1370/2000, 耗时:0.00分/2.81分 | step: 54800 | performance: 2.2 | accuracy: 0.32 | loss: 1.31
update:1375/2000, 耗时:0.00分/2.82分 | step: 55000 | performance: 1.7 | accuracy: 0.31 | loss: 0.31
update:1380/2000, 耗时:0.00分/2.83分 | step: 55200 | performance: 1.2 | accuracy: 0.30 | loss: 0.91
update:1385/2000, 耗时:0.00分/2.84分 | step: 55400 | performance: 1.9 | accuracy: 0.31 | loss: 1.26
update:1390/2000, 耗时:0.00分/2.85分 | step: 55600 | performance: 5.2 | accuracy: 0.32 | loss: 1.88
update:1395/2000, 耗时:0.00分/2.86分 | step: 55800 | performance: 6.0 | accuracy: 0.32 | loss: 1.60
update:1400/2000, 耗时:0.00分/2.87分 | step: 56000 | performance: 3.4 | accuracy: 0.31 | loss: 0.69
update:1405/2000, 耗时:0.00分/2.88分 | step: 56200 | performance: 8.4 | accuracy: 0.32 | loss: 1.42
update:1410/2000, 耗时:0.00分/2.89分 | step: 56400 | performance: 3.9 | accuracy: 0.32 | loss: 0.61
update:1415/2000, 耗时:0.00分/2.90分 | step: 56600 | performance: 2.9 | accuracy: 0.32 | loss: 0.73
update:1420/2000, 耗时:0.00分/2.91分 | step: 56800 | performance: 3.9 | accuracy: 0.32 | loss: 0.37
update:1425/2000, 耗时:0.00分/2.92分 | step: 57000 | performance: 2.2 | accuracy: 0.32 | loss: 2.08
update:1430/2000, 耗时:0.00分/2.93分 | step: 57200 | performance: 2.2 | accuracy: 0.32 | loss: 0.51
update:1435/2000, 耗时:0.00分/2.95分 | step: 57400 | performance: 2.4 | accuracy: 0.32 | loss: 0.50
update:1440/2000, 耗时:0.00分/2.96分 | step: 57600 | performance: 3.7 | accuracy: 0.32 | loss: 0.28
update:1445/2000, 耗时:0.00分/2.97分 | step: 57800 | performance: 2.9 | accuracy: 0.32 | loss: 0.74
update:1450/2000, 耗时:0.00分/2.98分 | step: 58000 | performance: 2.2 | accuracy: 0.32 | loss: 0.75
update:1455/2000, 耗时:0.00分/2.99分 | step: 58200 | performance: 2.4 | accuracy: 0.31 | loss: 0.37
update:1460/2000, 耗时:0.00分/3.00分 | step: 58400 | performance: 1.6 | accuracy: 0.31 | loss: 0.68
update:1465/2000, 耗时:0.00分/3.01分 | step: 58600 | performance: 1.6 | accuracy: 0.31 | loss: 0.38
update:1470/2000, 耗时:0.00分/3.02分 | step: 58800 | performance: 1.8 | accuracy: 0.31 | loss: 0.75
update:1475/2000, 耗时:0.00分/3.03分 | step: 59000 | performance: 2.8 | accuracy: 0.31 | loss: 1.30
update:1480/2000, 耗时:0.00分/3.04分 | step: 59200 | performance: 2.6 | accuracy: 0.32 | loss: 0.58
update:1485/2000, 耗时:0.00分/3.05分 | step: 59400 | performance: 2.6 | accuracy: 0.32 | loss: 0.68
update:1490/2000, 耗时:0.00分/3.06分 | step: 59600 | performance: 3.4 | accuracy: 0.32 | loss: 0.85
update:1495/2000, 耗时:0.00分/3.07分 | step: 59800 | performance: 1.3 | accuracy: 0.32 | loss: 0.13
update:1500/2000, 耗时:0.00分/3.08分 | step: 60000 | performance: 1.6 | accuracy: 0.32 | loss: 0.23
update:1505/2000, 耗时:0.00分/3.09分 | step: 60200 | performance: 1.1 | accuracy: 0.31 | loss: 0.30
update:1510/2000, 耗时:0.00分/3.10分 | step: 60400 | performance: 0.8 | accuracy: 0.31 | loss: 0.89
update:1515/2000, 耗时:0.00分/3.11分 | step: 60600 | performance: 0.4 | accuracy: 0.31 | loss: 0.54
update:1520/2000, 耗时:0.00分/3.12分 | step: 60800 | performance: 0.4 | accuracy: 0.31 | loss: 0.43
update:1525/2000, 耗时:0.00分/3.13分 | step: 61000 | performance: 0.5 | accuracy: 0.31 | loss: 0.61
update:1530/2000, 耗时:0.00分/3.14分 | step: 61200 | performance: 0.6 | accuracy: 0.31 | loss: 0.53
update:1535/2000, 耗时:0.00分/3.15分 | step: 61400 | performance: 0.5 | accuracy: 0.31 | loss: 0.60
update:1540/2000, 耗时:0.00分/3.16分 | step: 61600 | performance: 0.5 | accuracy: 0.31 | loss: 0.48
update:1545/2000, 耗时:0.00分/3.17分 | step: 61800 | performance: 0.4 | accuracy: 0.31 | loss: 0.63
update:1550/2000, 耗时:0.00分/3.18分 | step: 62000 | performance: 1.1 | accuracy: 0.32 | loss: 0.39
update:1555/2000, 耗时:0.00分/3.19分 | step: 62200 | performance: 1.3 | accuracy: 0.32 | loss: 0.62
update:1560/2000, 耗时:0.00分/3.20分 | step: 62400 | performance: 1.0 | accuracy: 0.32 | loss: 0.73
update:1565/2000, 耗时:0.00分/3.21分 | step: 62600 | performance: 0.7 | accuracy: 0.32 | loss: 0.41
update:1570/2000, 耗时:0.00分/3.22分 | step: 62800 | performance: 0.7 | accuracy: 0.32 | loss: 0.97
update:1575/2000, 耗时:0.00分/3.23分 | step: 63000 | performance: 0.7 | accuracy: 0.32 | loss: 0.58
update:1580/2000, 耗时:0.00分/3.24分 | step: 63200 | performance: 1.1 | accuracy: 0.33 | loss: 0.42
update:1585/2000, 耗时:0.00分/3.25分 | step: 63400 | performance: 2.0 | accuracy: 0.33 | loss: 0.49
update:1590/2000, 耗时:0.00分/3.26分 | step: 63600 | performance: 5.1 | accuracy: 0.34 | loss: 0.67
update:1595/2000, 耗时:0.00分/3.27分 | step: 63800 | performance: 15.1 | accuracy: 0.35 | loss: 0.22
update:1600/2000, 耗时:0.00分/3.28分 | step: 64000 | performance: 15.1 | accuracy: 0.35 | loss: 1.42
update:1605/2000, 耗时:0.00分/3.29分 | step: 64200 | performance: 39.5 | accuracy: 0.35 | loss: 1.73
update:1610/2000, 耗时:0.00分/3.30分 | step: 64400 | performance: 126.5 | accuracy: 0.35 | loss: 0.52
update:1615/2000, 耗时:0.00分/3.31分 | step: 64600 | performance: 405.8 | accuracy: 0.36 | loss: 6.78
update:1620/2000, 耗时:0.00分/3.32分 | step: 64800 | performance: 194.2 | accuracy: 0.36 | loss: 0.67
update:1625/2000, 耗时:0.00分/3.33分 | step: 65000 | performance: 435.0 | accuracy: 0.36 | loss: 0.79
update:1630/2000, 耗时:0.00分/3.34分 | step: 65200 | performance: 2913.2 | accuracy: 0.37 | loss: 0.59
update:1635/2000, 耗时:0.00分/3.35分 | step: 65400 | performance: 2084.7 | accuracy: 0.37 | loss: 0.57
update:1640/2000, 耗时:0.00分/3.36分 | step: 65600 | performance: 5371.0 | accuracy: 0.37 | loss: 3.18
update:1645/2000, 耗时:0.00分/3.37分 | step: 65800 | performance: 6248.0 | accuracy: 0.37 | loss: 0.89
update:1650/2000, 耗时:0.00分/3.38分 | step: 66000 | performance: 7305.8 | accuracy: 0.37 | loss: 0.71
update:1655/2000, 耗时:0.00分/3.39分 | step: 66200 | performance: 9000.1 | accuracy: 0.38 | loss: 1.47
update:1660/2000, 耗时:0.00分/3.40分 | step: 66400 | performance: 13173.5 | accuracy: 0.38 | loss: 0.85
update:1665/2000, 耗时:0.00分/3.41分 | step: 66600 | performance: 5389.6 | accuracy: 0.38 | loss: 1.67
update:1670/2000, 耗时:0.00分/3.42分 | step: 66800 | performance: 3261.7 | accuracy: 0.37 | loss: 0.63
update:1675/2000, 耗时:0.00分/3.42分 | step: 67000 | performance: 2628.4 | accuracy: 0.37 | loss: 0.71
update:1680/2000, 耗时:0.00分/3.43分 | step: 67200 | performance: 2312.9 | accuracy: 0.37 | loss: 0.62
update:1685/2000, 耗时:0.00分/3.44分 | step: 67400 | performance: 2601.6 | accuracy: 0.37 | loss: 0.40
update:1690/2000, 耗时:0.00分/3.45分 | step: 67600 | performance: 1804.2 | accuracy: 0.37 | loss: 0.66
update:1695/2000, 耗时:0.00分/3.46分 | step: 67800 | performance: 3828.7 | accuracy: 0.37 | loss: 0.34
update:1700/2000, 耗时:0.00分/3.47分 | step: 68000 | performance: 4099.0 | accuracy: 0.37 | loss: 0.37
update:1705/2000, 耗时:0.00分/3.48分 | step: 68200 | performance: 4495.3 | accuracy: 0.37 | loss: 0.68
update:1710/2000, 耗时:0.00分/3.49分 | step: 68400 | performance: 6137.8 | accuracy: 0.37 | loss: 0.88
update:1715/2000, 耗时:0.00分/3.50分 | step: 68600 | performance: 6542.2 | accuracy: 0.37 | loss: 0.83
update:1720/2000, 耗时:0.00分/3.51分 | step: 68800 | performance: 5606.5 | accuracy: 0.37 | loss: 0.98
update:1725/2000, 耗时:0.00分/3.53分 | step: 69000 | performance: 8015.2 | accuracy: 0.37 | loss: 0.59
update:1730/2000, 耗时:0.00分/3.54分 | step: 69200 | performance: 11854.5 | accuracy: 0.37 | loss: 0.68
update:1735/2000, 耗时:0.00分/3.55分 | step: 69400 | performance: 17707.1 | accuracy: 0.37 | loss: 1.38
update:1740/2000, 耗时:0.00分/3.56分 | step: 69600 | performance: 8827.6 | accuracy: 0.37 | loss: 0.97
update:1745/2000, 耗时:0.00分/3.57分 | step: 69800 | performance: 9050.6 | accuracy: 0.37 | loss: 1.85
update:1750/2000, 耗时:0.00分/3.58分 | step: 70000 | performance: 8314.1 | accuracy: 0.37 | loss: 0.35
update:1755/2000, 耗时:0.00分/3.59分 | step: 70200 | performance: 15120.6 | accuracy: 0.37 | loss: 0.78
update:1760/2000, 耗时:0.00分/3.60分 | step: 70400 | performance: 12946.7 | accuracy: 0.37 | loss: 0.48
update:1765/2000, 耗时:0.00分/3.61分 | step: 70600 | performance: 14642.1 | accuracy: 0.38 | loss: 1.37
update:1770/2000, 耗时:0.00分/3.62分 | step: 70800 | performance: 20226.3 | accuracy: 0.37 | loss: 0.45
update:1775/2000, 耗时:0.00分/3.63分 | step: 71000 | performance: 22857.1 | accuracy: 0.37 | loss: 0.50
update:1780/2000, 耗时:0.00分/3.64分 | step: 71200 | performance: 30825.9 | accuracy: 0.37 | loss: 0.75
update:1785/2000, 耗时:0.00分/3.65分 | step: 71400 | performance: 26951.3 | accuracy: 0.37 | loss: 0.48
update:1790/2000, 耗时:0.00分/3.66分 | step: 71600 | performance: 26027.8 | accuracy: 0.37 | loss: 0.54
update:1795/2000, 耗时:0.00分/3.67分 | step: 71800 | performance: 27502.7 | accuracy: 0.37 | loss: 0.70
update:1800/2000, 耗时:0.00分/3.69分 | step: 72000 | performance: 22107.7 | accuracy: 0.37 | loss: 0.67
update:1805/2000, 耗时:0.00分/3.70分 | step: 72200 | performance: 22272.5 | accuracy: 0.37 | loss: 0.36
update:1810/2000, 耗时:0.00分/3.71分 | step: 72400 | performance: 29353.7 | accuracy: 0.37 | loss: 0.36
update:1815/2000, 耗时:0.00分/3.72分 | step: 72600 | performance: 35477.1 | accuracy: 0.37 | loss: 0.36
update:1820/2000, 耗时:0.00分/3.73分 | step: 72800 | performance: 21032.0 | accuracy: 0.37 | loss: 0.44
update:1825/2000, 耗时:0.00分/3.74分 | step: 73000 | performance: 99172.3 | accuracy: 0.37 | loss: 0.47
update:1830/2000, 耗时:0.00分/3.75分 | step: 73200 | performance: 149288.0 | accuracy: 0.37 | loss: 0.39
update:1835/2000, 耗时:0.00分/3.76分 | step: 73400 | performance: 126761.2 | accuracy: 0.37 | loss: 0.69
update:1840/2000, 耗时:0.00分/3.77分 | step: 73600 | performance: 104522.9 | accuracy: 0.36 | loss: 0.58
update:1845/2000, 耗时:0.00分/3.78分 | step: 73800 | performance: 94577.8 | accuracy: 0.36 | loss: 0.39
update:1850/2000, 耗时:0.00分/3.79分 | step: 74000 | performance: 118245.6 | accuracy: 0.36 | loss: 0.42
update:1855/2000, 耗时:0.00分/3.81分 | step: 74200 | performance: 146537.8 | accuracy: 0.36 | loss: 0.38
update:1860/2000, 耗时:0.00分/3.82分 | step: 74400 | performance: 125388.5 | accuracy: 0.36 | loss: 0.31
update:1865/2000, 耗时:0.00分/3.83分 | step: 74600 | performance: 131749.6 | accuracy: 0.36 | loss: 0.46
update:1870/2000, 耗时:0.00分/3.84分 | step: 74800 | performance: 138439.7 | accuracy: 0.36 | loss: 0.46
update:1875/2000, 耗时:0.00分/3.85分 | step: 75000 | performance: 146170.0 | accuracy: 0.36 | loss: 0.64
update:1880/2000, 耗时:0.00分/3.86分 | step: 75200 | performance: 163388.4 | accuracy: 0.36 | loss: 0.54
update:1885/2000, 耗时:0.00分/3.87分 | step: 75400 | performance: 98037.9 | accuracy: 0.36 | loss: 0.37
update:1890/2000, 耗时:0.00分/3.88分 | step: 75600 | performance: 111138.0 | accuracy: 0.36 | loss: 0.55
update:1895/2000, 耗时:0.00分/3.89分 | step: 75800 | performance: 110527.3 | accuracy: 0.36 | loss: 0.59
update:1900/2000, 耗时:0.00分/3.90分 | step: 76000 | performance: 92537.5 | accuracy: 0.35 | loss: 0.35
Saving PPO weights in both H5 format and checkpoint @ update:1904 
update:1905/2000, 耗时:0.00分/3.92分 | step: 76200 | performance: 1.0 | accuracy: 0.33 | loss: 0.62
update:1910/2000, 耗时:0.00分/3.93分 | step: 76400 | performance: 1.2 | accuracy: 0.32 | loss: 0.48
update:1915/2000, 耗时:0.00分/3.94分 | step: 76600 | performance: 1.0 | accuracy: 0.29 | loss: 0.73
update:1920/2000, 耗时:0.00分/3.95分 | step: 76800 | performance: 0.9 | accuracy: 0.32 | loss: 0.66
update:1925/2000, 耗时:0.00分/3.96分 | step: 77000 | performance: 0.8 | accuracy: 0.30 | loss: 0.26
update:1930/2000, 耗时:0.00分/3.97分 | step: 77200 | performance: 0.8 | accuracy: 0.31 | loss: 0.60
update:1935/2000, 耗时:0.00分/3.98分 | step: 77400 | performance: 0.5 | accuracy: 0.30 | loss: 0.95
update:1940/2000, 耗时:0.00分/3.99分 | step: 77600 | performance: 0.4 | accuracy: 0.27 | loss: 0.45
update:1945/2000, 耗时:0.00分/4.00分 | step: 77800 | performance: 0.6 | accuracy: 0.28 | loss: 0.42
update:1950/2000, 耗时:0.00分/4.01分 | step: 78000 | performance: 0.9 | accuracy: 0.30 | loss: 0.35
update:1955/2000, 耗时:0.00分/4.02分 | step: 78200 | performance: 0.7 | accuracy: 0.28 | loss: 0.64
update:1960/2000, 耗时:0.00分/4.03分 | step: 78400 | performance: 0.8 | accuracy: 0.27 | loss: 0.36
update:1965/2000, 耗时:0.00分/4.04分 | step: 78600 | performance: 1.0 | accuracy: 0.29 | loss: 0.65
update:1970/2000, 耗时:0.00分/4.05分 | step: 78800 | performance: 1.1 | accuracy: 0.29 | loss: 0.35
update:1975/2000, 耗时:0.00分/4.06分 | step: 79000 | performance: 0.9 | accuracy: 0.28 | loss: 0.49
update:1980/2000, 耗时:0.00分/4.07分 | step: 79200 | performance: 0.9 | accuracy: 0.28 | loss: 0.27
update:1985/2000, 耗时:0.00分/4.09分 | step: 79400 | performance: 0.9 | accuracy: 0.29 | loss: 0.39
update:1990/2000, 耗时:0.00分/4.10分 | step: 79600 | performance: 0.8 | accuracy: 0.29 | loss: 0.96
update:1995/2000, 耗时:0.00分/4.11分 | step: 79800 | performance: 0.9 | accuracy: 0.28 | loss: 0.57
  0%|          | 0/406 [00:00<?, ?it/s]100%|| 406/406 [00:00<00:00, 101446.89it/s]
update:2000/2000, 耗时:0.00分/4.12分 | step: 80000 | performance: 0.9 | accuracy: 0.29 | loss: 0.43
----------------------------------------finished----------------------------------------
==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1524.82
2023-07-24T12:00:00 | net performance [%] = 52.4818
2023-07-24T12:00:00 | number of trades [#] = 108
==================================================
Trial 51 Complete [00h 04m 34s]
net_wealth: 1526.3444799739111

Best net_wealth So Far: 1752.3888145064732
Total elapsed time: 07h 10m 37s

Search: Running Trial #52

Value             |Best Value So Far |Hyperparameter
6                 |7                 |horizon
365               |730               |lookback
True              |False             |MarketFactor
10                |14                |lags
0.98              |0.7               |gamma
16                |32                |batch_size
7                 |32                |n_step
0.94              |0.92              |gae_lambda
0.5               |0.1               |gradient_clip_norm
3                 |5                 |epochs
0.001             |0.0001            |actor_lr
0.001             |5e-05             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4295.000000   4301.000000
mean      0.000435    20113.607657  ...   20191.527960  20169.373185
std       0.027833    16040.642334  ...   16078.872271  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7755.915039   7730.930176
50%       0.000642    11571.842969  ...   11757.219727  11751.469727
75%       0.011590    29894.706152  ...   30018.430664  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 05:14:00.934204: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized 2023-07-28 05:14:00.934262: I tensorflow/core/platform/cpu_feature22020w_i3guarth oneA-dP0.c7Ic- Deep :2142]280 Th2 3Neural is TensorN-e0F5t:l0ow binar71-y2 w8 is o04:005.ptimiz9or:ed314:024k with oneAPI Deep Neural Network3 L Library (oneDN-0.07ib934345:- I tensorflow/core/platform28 05:14:/0craryp02 99: I tensorflouN().934202: I tensorflow _featurtwo e_guard.cusc:e 14tonheeD /fcoNlore/plN22)alto 0/t]cor 2win3eTho gf/o C-027-208 0pPluisseaU2 intfrom/cp3 -r0msT7e-n2/u8_ 0s5otf:ecrpuuartFurlow_e_1 fbeincatrions in5guaa4yr ::00d.14:0.cp0ertc is  u:op149.3tthe fo947lfor0imrl3e_g42o8m0i6zew2]u ar2i3-6T0:hidd0s T.7a:nn-e nI  2witsc8gh  I0  torteFno lCowennsseAPooPrI ercflboiwn-cUf:l1o4w2/  arcore/plcry] /Deepics i5aoptimo:14:00r.e/pla9 tforThitnsi3 488tNrumfocrte/ciuoranspl mN/et wios n perfTenucsrormantipzeukod wrFloictwic eLh al op_fe -bian0careo:turye_rgua_featrtn iiticaeuArei I _olnsPI D:  iasr dt.eebepg Auonpstoi Vard.ccNmriary r(eou:X AVr1ofal Nezenctc4:21de pwl]4o2w]DNNe XTiratiw/h2i
 otnohcor soe)/p lt:o  antrTeufosrAkem PtI hh/icspuDe eeLi  AV_fs braryTX eaTTensooeAVnXr t2up   Fe
r(NofloTeenuralls_onwooeoDNN  eraFbglula rdN.beinn)a awrilc ct:eh1ttnwbegy  ol4eC2o]i mPuUs  iT s ntshthruie mcet iosp Tt htiimions n otzene foehodi nw rwitkh  epersiLniror oFpl fbber aololoowroiwn arineryma yntbnincaeAh eg r(atry r-Poi CisiIn Desc roiptP oteDNUN oiepm izeoN)di cwa ptnoeules u,s prtaieriimtra l o hizetdpeNen swrtaiohnes ,bt iitofo thr lolnowsiunoeentencgt iA:r AwuoeC ons rikPAVbnu PIi lDdee p PXI p TiN eLeUD eieruraiepl nsoAVdNforrFlnXl 2Nestwbor
 TeoTamu eenwartarruycanbll tnisc  we itNh( tohote-ectrwnhreFmitoirc ieon aol raok kln operaotwepD iL iLwipNiotnrobNb)r arpyri (atthso usth se thie fon:   eorneaApre rthVe eo pcleDforolmoprw aryN tN) taippimlao(on eiDnerognr X CPUNnNs)uoflp,  Arseec  Vtboianr theie fol-atstl uugssXielcor2u
derwiit cntgc  iiompio.lTceTnso  eCrnPotae s U heinflir Ffalbagnl
lnst oo e themw operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
s.
ructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
llowing CPU instructions in pwith the appropriate compiler flags.
 in other operations, rebuild TensorFlow with the appropriate compiler flags.
erformance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 05:14:01.526780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:14:01.537447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:14:01.540948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:14:01.564603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:14:01.569949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:14:01.579484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:14:01.590148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:14:01.611490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   280 | performance: 0.6 | accuracy: 0.43 | loss: 7.78
update: 10/2000, 耗时:0.00分/0.04分 | step:   560 | performance: 0.2 | accuracy: 0.36 | loss: 3.23
update: 15/2000, 耗时:0.00分/0.05分 | step:   840 | performance: 0.3 | accuracy: 0.35 | loss: 1.38
update: 20/2000, 耗时:0.00分/0.06分 | step:  1120 | performance: 0.2 | accuracy: 0.32 | loss: 1.46
update: 25/2000, 耗时:0.00分/0.07分 | step:  1400 | performance: 0.2 | accuracy: 0.29 | loss: 0.21
update: 30/2000, 耗时:0.00分/0.08分 | step:  1680 | performance: 0.2 | accuracy: 0.27 | loss: 1.07
update: 35/2000, 耗时:0.00分/0.10分 | step:  1960 | performance: 0.2 | accuracy: 0.26 | loss: 1.66
update: 40/2000, 耗时:0.00分/0.11分 | step:  2240 | performance: 0.1 | accuracy: 0.24 | loss: 0.55
update: 45/2000, 耗时:0.00分/0.12分 | step:  2520 | performance: 0.1 | accuracy: 0.24 | loss: 0.89
update: 50/2000, 耗时:0.00分/0.13分 | step:  2800 | performance: 0.1 | accuracy: 0.23 | loss: 0.47
update: 55/2000, 耗时:0.00分/0.14分 | step:  3080 | performance: 0.1 | accuracy: 0.24 | loss: 1.17
update: 60/2000, 耗时:0.00分/0.16分 | step:  3360 | performance: 0.1 | accuracy: 0.23 | loss: 1.22
update: 65/2000, 耗时:0.00分/0.17分 | step:  3640 | performance: 0.1 | accuracy: 0.24 | loss: 0.83
update: 70/2000, 耗时:0.00分/0.18分 | step:  3920 | performance: 0.1 | accuracy: 0.23 | loss: 3.50
update: 75/2000, 耗时:0.00分/0.20分 | step:  4200 | performance: 0.0 | accuracy: 0.22 | loss: 1.48
update: 80/2000, 耗时:0.00分/0.21分 | step:  4480 | performance: 0.0 | accuracy: 0.21 | loss: 0.01
update: 85/2000, 耗时:0.00分/0.23分 | step:  4760 | performance: 0.0 | accuracy: 0.20 | loss: 0.89
update: 90/2000, 耗时:0.00分/0.24分 | step:  5040 | performance: 0.0 | accuracy: 0.20 | loss: 0.33
update: 95/2000, 耗时:0.00分/0.25分 | step:  5320 | performance: 0.0 | accuracy: 0.20 | loss: 3.07
update:100/2000, 耗时:0.00分/0.27分 | step:  5600 | performance: 0.0 | accuracy: 0.21 | loss: 2.16
update:105/2000, 耗时:0.00分/0.28分 | step:  5880 | performance: 0.0 | accuracy: 0.22 | loss: 1.34
update:110/2000, 耗时:0.00分/0.29分 | step:  6160 | performance: 0.0 | accuracy: 0.22 | loss: 1.63
update:115/2000, 耗时:0.00分/0.31分 | step:  6440 | performance: 0.0 | accuracy: 0.22 | loss: 1.70
update:120/2000, 耗时:0.00分/0.32分 | step:  6720 | performance: 0.0 | accuracy: 0.22 | loss: 3.16
update:125/2000, 耗时:0.00分/0.33分 | step:  7000 | performance: 0.0 | accuracy: 0.22 | loss: 1.68
update:130/2000, 耗时:0.00分/0.35分 | step:  7280 | performance: 0.0 | accuracy: 0.22 | loss: 0.91
update:135/2000, 耗时:0.00分/0.36分 | step:  7560 | performance: 0.0 | accuracy: 0.22 | loss: 2.51
update:140/2000, 耗时:0.00分/0.38分 | step:  7840 | performance: 0.0 | accuracy: 0.22 | loss: 1.49
update:145/2000, 耗时:0.00分/0.39分 | step:  8120 | performance: 0.0 | accuracy: 0.23 | loss: 5.07
update:150/2000, 耗时:0.00分/0.40分 | step:  8400 | performance: 0.0 | accuracy: 0.23 | loss: 1.13
update:155/2000, 耗时:0.00分/0.42分 | step:  8680 | performance: 0.0 | accuracy: 0.24 | loss: 6.84
update:160/2000, 耗时:0.00分/0.43分 | step:  8960 | performance: 0.0 | accuracy: 0.24 | loss: 1.62
update:165/2000, 耗时:0.00分/0.45分 | step:  9240 | performance: 0.0 | accuracy: 0.25 | loss: 5.24
update:170/2000, 耗时:0.00分/0.46分 | step:  9520 | performance: 0.0 | accuracy: 0.26 | loss: 4.38
update:175/2000, 耗时:0.00分/0.47分 | step:  9800 | performance: 0.0 | accuracy: 0.26 | loss: 2.25
update:180/2000, 耗时:0.00分/0.48分 | step: 10080 | performance: 0.0 | accuracy: 0.27 | loss: 0.84
update:185/2000, 耗时:0.00分/0.50分 | step: 10360 | performance: 0.0 | accuracy: 0.27 | loss: 1.96
update:190/2000, 耗时:0.00分/0.51分 | step: 10640 | performance: 0.0 | accuracy: 0.27 | loss: 0.51
update:195/2000, 耗时:0.00分/0.52分 | step: 10920 | performance: 0.0 | accuracy: 0.27 | loss: 4.82
update:200/2000, 耗时:0.00分/0.54分 | step: 11200 | performance: 0.0 | accuracy: 0.28 | loss: 2.06
update:205/2000, 耗时:0.00分/0.55分 | step: 11480 | performance: 0.0 | accuracy: 0.28 | loss: 8.80
update:210/2000, 耗时:0.00分/0.56分 | step: 11760 | performance: 0.1 | accuracy: 0.29 | loss: 6.14
update:215/2000, 耗时:0.00分/0.57分 | step: 12040 | performance: 0.1 | accuracy: 0.29 | loss: 7.16
update:220/2000, 耗时:0.00分/0.59分 | step: 12320 | performance: 0.2 | accuracy: 0.29 | loss: 5.86
update:225/2000, 耗时:0.00分/0.60分 | step: 12600 | performance: 0.5 | accuracy: 0.30 | loss: 6.30
update:230/2000, 耗时:0.00分/0.61分 | step: 12880 | performance: 0.7 | accuracy: 0.31 | loss: 8.48
update:235/2000, 耗时:0.00分/0.62分 | step: 13160 | performance: 0.5 | accuracy: 0.31 | loss: 7.17
update:240/2000, 耗时:0.00分/0.64分 | step: 13440 | performance: 0.8 | accuracy: 0.31 | loss: 7.12
update:245/2000, 耗时:0.00分/0.65分 | step: 13720 | performance: 0.8 | accuracy: 0.32 | loss: 0.83
update:250/2000, 耗时:0.00分/0.66分 | step: 14000 | performance: 0.3 | accuracy: 0.31 | loss: 5.04
update:255/2000, 耗时:0.00分/0.67分 | step: 14280 | performance: 0.2 | accuracy: 0.31 | loss: 1.58
update:260/2000, 耗时:0.00分/0.69分 | step: 14560 | performance: 0.5 | accuracy: 0.32 | loss: 8.84
update:265/2000, 耗时:0.00分/0.70分 | step: 14840 | performance: 0.5 | accuracy: 0.32 | loss: 9.00
update:270/2000, 耗时:0.00分/0.71分 | step: 15120 | performance: 0.4 | accuracy: 0.32 | loss: 1.88
update:275/2000, 耗时:0.00分/0.72分 | step: 15400 | performance: 0.2 | accuracy: 0.32 | loss: 4.46
update:280/2000, 耗时:0.00分/0.74分 | step: 15680 | performance: 0.1 | accuracy: 0.32 | loss: 4.24
update:285/2000, 耗时:0.00分/0.75分 | step: 15960 | performance: 0.0 | accuracy: 0.31 | loss: 11.75
update:290/2000, 耗时:0.00分/0.76分 | step: 16240 | performance: 0.0 | accuracy: 0.32 | loss: 13.68
update:295/2000, 耗时:0.00分/0.78分 | step: 16520 | performance: 0.0 | accuracy: 0.31 | loss: 27.32
update:300/2000, 耗时:0.00分/0.79分 | step: 16800 | performance: 0.0 | accuracy: 0.32 | loss: 8.53
update:305/2000, 耗时:0.00分/0.80分 | step: 17080 | performance: 0.0 | accuracy: 0.32 | loss: 26.72
update:310/2000, 耗时:0.00分/0.81分 | step: 17360 | performance: 0.0 | accuracy: 0.31 | loss: 4.09
update:315/2000, 耗时:0.00分/0.83分 | step: 17640 | performance: 0.0 | accuracy: 0.31 | loss: 2.15
update:320/2000, 耗时:0.00分/0.84分 | step: 17920 | performance: 0.0 | accuracy: 0.31 | loss: 0.37
update:325/2000, 耗时:0.00分/0.85分 | step: 18200 | performance: 0.0 | accuracy: 0.30 | loss: 0.17
update:330/2000, 耗时:0.00分/0.86分 | step: 18480 | performance: 0.0 | accuracy: 0.30 | loss: 0.40
update:335/2000, 耗时:0.00分/0.88分 | step: 18760 | performance: 0.0 | accuracy: 0.30 | loss: 5.43
update:340/2000, 耗时:0.00分/0.89分 | step: 19040 | performance: 0.0 | accuracy: 0.30 | loss: 1.15
update:345/2000, 耗时:0.00分/0.90分 | step: 19320 | performance: 0.0 | accuracy: 0.30 | loss: 3.73
update:350/2000, 耗时:0.00分/0.92分 | step: 19600 | performance: 0.0 | accuracy: 0.31 | loss: 5.83
update:355/2000, 耗时:0.00分/0.93分 | step: 19880 | performance: 0.0 | accuracy: 0.31 | loss: 10.22
update:360/2000, 耗时:0.00分/0.94分 | step: 20160 | performance: 0.0 | accuracy: 0.31 | loss: 3.57
update:365/2000, 耗时:0.00分/0.95分 | step: 20440 | performance: 0.0 | accuracy: 0.31 | loss: 2.25
update:370/2000, 耗时:0.00分/0.97分 | step: 20720 | performance: 0.0 | accuracy: 0.31 | loss: 1.15
update:375/2000, 耗时:0.00分/0.98分 | step: 21000 | performance: 0.0 | accuracy: 0.31 | loss: 6.55
update:380/2000, 耗时:0.00分/0.99分 | step: 21280 | performance: 0.0 | accuracy: 0.32 | loss: 0.68
update:385/2000, 耗时:0.00分/1.00分 | step: 21560 | performance: 0.0 | accuracy: 0.31 | loss: 2.74
update:390/2000, 耗时:0.00分/1.01分 | step: 21840 | performance: 0.0 | accuracy: 0.32 | loss: 5.94
update:395/2000, 耗时:0.00分/1.03分 | step: 22120 | performance: 0.0 | accuracy: 0.32 | loss: 4.24
update:400/2000, 耗时:0.00分/1.04分 | step: 22400 | performance: 0.0 | accuracy: 0.32 | loss: 1.01
update:405/2000, 耗时:0.00分/1.05分 | step: 22680 | performance: 0.0 | accuracy: 0.31 | loss: 1.09
update:410/2000, 耗时:0.00分/1.06分 | step: 22960 | performance: 0.0 | accuracy: 0.32 | loss: 10.37
update:415/2000, 耗时:0.00分/1.08分 | step: 23240 | performance: 0.0 | accuracy: 0.32 | loss: 8.56
update:420/2000, 耗时:0.00分/1.09分 | step: 23520 | performance: 0.0 | accuracy: 0.32 | loss: 8.89
update:425/2000, 耗时:0.00分/1.10分 | step: 23800 | performance: 0.0 | accuracy: 0.33 | loss: 3.79
update:430/2000, 耗时:0.00分/1.11分 | step: 24080 | performance: 0.0 | accuracy: 0.33 | loss: 7.90
update:435/2000, 耗时:0.00分/1.13分 | step: 24360 | performance: 0.0 | accuracy: 0.33 | loss: 23.35
update:440/2000, 耗时:0.00分/1.14分 | step: 24640 | performance: 0.0 | accuracy: 0.33 | loss: 1.47
update:445/2000, 耗时:0.00分/1.15分 | step: 24920 | performance: 0.0 | accuracy: 0.33 | loss: 27.79
update:450/2000, 耗时:0.00分/1.17分 | step: 25200 | performance: 0.0 | accuracy: 0.33 | loss: 8.98
update:455/2000, 耗时:0.00分/1.18分 | step: 25480 | performance: 0.0 | accuracy: 0.34 | loss: 8.15
update:460/2000, 耗时:0.00分/1.19分 | step: 25760 | performance: 0.0 | accuracy: 0.34 | loss: 1.88
update:465/2000, 耗时:0.00分/1.20分 | step: 26040 | performance: 0.0 | accuracy: 0.34 | loss: 0.79
update:470/2000, 耗时:0.00分/1.21分 | step: 26320 | performance: 0.0 | accuracy: 0.34 | loss: 3.09
update:475/2000, 耗时:0.00分/1.23分 | step: 26600 | performance: 0.0 | accuracy: 0.34 | loss: 2.78
update:480/2000, 耗时:0.00分/1.24分 | step: 26880 | performance: 0.0 | accuracy: 0.34 | loss: 1.61
update:485/2000, 耗时:0.00分/1.25分 | step: 27160 | performance: 0.0 | accuracy: 0.34 | loss: 1.35
update:490/2000, 耗时:0.00分/1.26分 | step: 27440 | performance: 0.0 | accuracy: 0.34 | loss: 2.84
update:495/2000, 耗时:0.00分/1.28分 | step: 27720 | performance: 0.0 | accuracy: 0.34 | loss: 1.28
update:500/2000, 耗时:0.00分/1.29分 | step: 28000 | performance: 0.0 | accuracy: 0.34 | loss: 0.53
Saving PPO weights in both H5 format and checkpoint @ update:503 
update:505/2000, 耗时:0.00分/1.31分 | step: 28280 | performance: 1.4 | accuracy: 0.47 | loss: 1.54
update:510/2000, 耗时:0.00分/1.32分 | step: 28560 | performance: 3.0 | accuracy: 0.56 | loss: 6.26
update:515/2000, 耗时:0.00分/1.33分 | step: 28840 | performance: 3.2 | accuracy: 0.56 | loss: 9.44
update:520/2000, 耗时:0.00分/1.34分 | step: 29120 | performance: 4.2 | accuracy: 0.57 | loss: 4.24
update:525/2000, 耗时:0.00分/1.35分 | step: 29400 | performance: 2.5 | accuracy: 0.51 | loss: 1.15
update:530/2000, 耗时:0.00分/1.36分 | step: 29680 | performance: 1.4 | accuracy: 0.47 | loss: 2.53
update:535/2000, 耗时:0.00分/1.37分 | step: 29960 | performance: 2.0 | accuracy: 0.49 | loss: 10.69
update:540/2000, 耗时:0.00分/1.39分 | step: 30240 | performance: 4.0 | accuracy: 0.51 | loss: 16.04
update:545/2000, 耗时:0.00分/1.40分 | step: 30520 | performance: 3.4 | accuracy: 0.49 | loss: 2.98
update:550/2000, 耗时:0.00分/1.41分 | step: 30800 | performance: 6.6 | accuracy: 0.51 | loss: 1.33
update:555/2000, 耗时:0.00分/1.42分 | step: 31080 | performance: 13.7 | accuracy: 0.53 | loss: 8.74
update:560/2000, 耗时:0.00分/1.43分 | step: 31360 | performance: 12.3 | accuracy: 0.53 | loss: 1.60
update:565/2000, 耗时:0.00分/1.45分 | step: 31640 | performance: 11.6 | accuracy: 0.52 | loss: 4.66
update:570/2000, 耗时:0.00分/1.46分 | step: 31920 | performance: 8.8 | accuracy: 0.50 | loss: 1.52
update:575/2000, 耗时:0.00分/1.47分 | step: 32200 | performance: 12.2 | accuracy: 0.50 | loss: 5.91
update:580/2000, 耗时:0.00分/1.48分 | step: 32480 | performance: 1.3 | accuracy: 0.48 | loss: 16.33
update:585/2000, 耗时:0.00分/1.49分 | step: 32760 | performance: 2.0 | accuracy: 0.48 | loss: 1.51
update:590/2000, 耗时:0.00分/1.51分 | step: 33040 | performance: 1.4 | accuracy: 0.48 | loss: 7.74
update:595/2000, 耗时:0.00分/1.52分 | step: 33320 | performance: 0.9 | accuracy: 0.47 | loss: 5.11
update:600/2000, 耗时:0.00分/1.53分 | step: 33600 | performance: 0.8 | accuracy: 0.47 | loss: 0.79
update:605/2000, 耗时:0.00分/1.54分 | step: 33880 | performance: 0.9 | accuracy: 0.47 | loss: 6.79
update:610/2000, 耗时:0.00分/1.55分 | step: 34160 | performance: 1.1 | accuracy: 0.48 | loss: 1.34
update:615/2000, 耗时:0.00分/1.57分 | step: 34440 | performance: 0.9 | accuracy: 0.48 | loss: 3.78
update:620/2000, 耗时:0.00分/1.58分 | step: 34720 | performance: 0.7 | accuracy: 0.47 | loss: 0.82
update:625/2000, 耗时:0.00分/1.59分 | step: 35000 | performance: 0.7 | accuracy: 0.45 | loss: 0.00
update:630/2000, 耗时:0.00分/1.60分 | step: 35280 | performance: 0.7 | accuracy: 0.43 | loss: 0.00
update:635/2000, 耗时:0.00分/1.61分 | step: 35560 | performance: 0.7 | accuracy: 0.42 | loss: -0.00
update:640/2000, 耗时:0.00分/1.62分 | step: 35840 | performance: 0.7 | accuracy: 0.40 | loss: 0.00
update:645/2000, 耗时:0.00分/1.64分 | step: 36120 | performance: 0.7 | accuracy: 0.39 | loss: 0.00
update:650/2000, 耗时:0.00分/1.65分 | step: 36400 | performance: 0.4 | accuracy: 0.38 | loss: 0.24
update:655/2000, 耗时:0.00分/1.66分 | step: 36680 | performance: 0.5 | accuracy: 0.37 | loss: 0.30
update:660/2000, 耗时:0.00分/1.67分 | step: 36960 | performance: 0.4 | accuracy: 0.36 | loss: 0.60
update:665/2000, 耗时:0.00分/1.68分 | step: 37240 | performance: 0.8 | accuracy: 0.36 | loss: 1.71
update:670/2000, 耗时:0.00分/1.69分 | step: 37520 | performance: 0.7 | accuracy: 0.37 | loss: 2.06
update:675/2000, 耗时:0.00分/1.71分 | step: 37800 | performance: 0.5 | accuracy: 0.37 | loss: 6.04
update:680/2000, 耗时:0.00分/1.72分 | step: 38080 | performance: 0.9 | accuracy: 0.38 | loss: 12.56
update:685/2000, 耗时:0.00分/1.73分 | step: 38360 | performance: 1.4 | accuracy: 0.39 | loss: 1.81
update:690/2000, 耗时:0.00分/1.74分 | step: 38640 | performance: 1.1 | accuracy: 0.39 | loss: 2.92
update:695/2000, 耗时:0.00分/1.75分 | step: 38920 | performance: 2.3 | accuracy: 0.39 | loss: 1.32
update:700/2000, 耗时:0.00分/1.77分 | step: 39200 | performance: 1.7 | accuracy: 0.39 | loss: 4.78
update:705/2000, 耗时:0.00分/1.78分 | step: 39480 | performance: 1.7 | accuracy: 0.38 | loss: 0.00
update:710/2000, 耗时:0.00分/1.79分 | step: 39760 | performance: 1.4 | accuracy: 0.38 | loss: 8.58
update:715/2000, 耗时:0.00分/1.80分 | step: 40040 | performance: 11.1 | accuracy: 0.38 | loss: 2.75
update:720/2000, 耗时:0.00分/1.81分 | step: 40320 | performance: 25.3 | accuracy: 0.39 | loss: 2.03
update:725/2000, 耗时:0.00分/1.82分 | step: 40600 | performance: 37.9 | accuracy: 0.39 | loss: 10.07
update:730/2000, 耗时:0.00分/1.84分 | step: 40880 | performance: 87.0 | accuracy: 0.40 | loss: 5.03
update:735/2000, 耗时:0.00分/1.85分 | step: 41160 | performance: 84.4 | accuracy: 0.40 | loss: 2.91
update:740/2000, 耗时:0.00分/1.86分 | step: 41440 | performance: 92.3 | accuracy: 0.39 | loss: 0.82
update:745/2000, 耗时:0.00分/1.87分 | step: 41720 | performance: 109.9 | accuracy: 0.40 | loss: 1.52
update:750/2000, 耗时:0.00分/1.88分 | step: 42000 | performance: 92.2 | accuracy: 0.40 | loss: 8.63
update:755/2000, 耗时:0.00分/1.90分 | step: 42280 | performance: 50.9 | accuracy: 0.39 | loss: 0.15
update:760/2000, 耗时:0.00分/1.91分 | step: 42560 | performance: 50.9 | accuracy: 0.38 | loss: 0.01
update:765/2000, 耗时:0.00分/1.92分 | step: 42840 | performance: 47.3 | accuracy: 0.38 | loss: 0.67
update:770/2000, 耗时:0.00分/1.93分 | step: 43120 | performance: 44.2 | accuracy: 0.37 | loss: 0.43
update:775/2000, 耗时:0.00分/1.94分 | step: 43400 | performance: 43.2 | accuracy: 0.37 | loss: 0.20
update:780/2000, 耗时:0.00分/1.95分 | step: 43680 | performance: 43.2 | accuracy: 0.36 | loss: 0.00
update:785/2000, 耗时:0.00分/1.96分 | step: 43960 | performance: 43.2 | accuracy: 0.35 | loss: -0.00
update:790/2000, 耗时:0.00分/1.98分 | step: 44240 | performance: 43.2 | accuracy: 0.35 | loss: -0.00
update:795/2000, 耗时:0.00分/1.99分 | step: 44520 | performance: 44.2 | accuracy: 0.34 | loss: 0.00
update:800/2000, 耗时:0.00分/2.00分 | step: 44800 | performance: 44.2 | accuracy: 0.34 | loss: -0.00
update:805/2000, 耗时:0.00分/2.01分 | step: 45080 | performance: 44.2 | accuracy: 0.33 | loss: 0.00
update:810/2000, 耗时:0.00分/2.02分 | step: 45360 | performance: 30.5 | accuracy: 0.33 | loss: 0.00
update:815/2000, 耗时:0.00分/2.03分 | step: 45640 | performance: 30.5 | accuracy: 0.32 | loss: 0.27
update:820/2000, 耗时:0.00分/2.04分 | step: 45920 | performance: 30.5 | accuracy: 0.32 | loss: 0.00
update:825/2000, 耗时:0.00分/2.05分 | step: 46200 | performance: 30.5 | accuracy: 0.31 | loss: 0.00
update:830/2000, 耗时:0.00分/2.07分 | step: 46480 | performance: 30.5 | accuracy: 0.31 | loss: 0.00
update:835/2000, 耗时:0.00分/2.08分 | step: 46760 | performance: 30.5 | accuracy: 0.30 | loss: -0.00
update:840/2000, 耗时:0.00分/2.09分 | step: 47040 | performance: 36.3 | accuracy: 0.30 | loss: 4.79
update:845/2000, 耗时:0.00分/2.10分 | step: 47320 | performance: 9.0 | accuracy: 0.30 | loss: 13.85
update:850/2000, 耗时:0.00分/2.11分 | step: 47600 | performance: 6.3 | accuracy: 0.31 | loss: 4.86
update:855/2000, 耗时:0.00分/2.12分 | step: 47880 | performance: 3.1 | accuracy: 0.31 | loss: 14.95
update:860/2000, 耗时:0.00分/2.14分 | step: 48160 | performance: 4.2 | accuracy: 0.31 | loss: 1.56
update:865/2000, 耗时:0.00分/2.15分 | step: 48440 | performance: 4.5 | accuracy: 0.31 | loss: 0.38
update:870/2000, 耗时:0.00分/2.16分 | step: 48720 | performance: 4.3 | accuracy: 0.31 | loss: 0.13
update:875/2000, 耗时:0.00分/2.17分 | step: 49000 | performance: 2.1 | accuracy: 0.30 | loss: 1.78
update:880/2000, 耗时:0.00分/2.19分 | step: 49280 | performance: 4.0 | accuracy: 0.30 | loss: 0.15
update:885/2000, 耗时:0.00分/2.20分 | step: 49560 | performance: 4.0 | accuracy: 0.30 | loss: 0.00
update:890/2000, 耗时:0.00分/2.21分 | step: 49840 | performance: 4.0 | accuracy: 0.30 | loss: 0.00
update:895/2000, 耗时:0.00分/2.22分 | step: 50120 | performance: 4.0 | accuracy: 0.29 | loss: 0.15
update:900/2000, 耗时:0.00分/2.23分 | step: 50400 | performance: 2.6 | accuracy: 0.29 | loss: 3.50
update:905/2000, 耗时:0.00分/2.24分 | step: 50680 | performance: 2.6 | accuracy: 0.29 | loss: 0.99
update:910/2000, 耗时:0.00分/2.26分 | step: 50960 | performance: 5.5 | accuracy: 0.29 | loss: 1.46
update:915/2000, 耗时:0.00分/2.27分 | step: 51240 | performance: 7.1 | accuracy: 0.30 | loss: 7.31
update:920/2000, 耗时:0.00分/2.28分 | step: 51520 | performance: 5.2 | accuracy: 0.30 | loss: 5.82
update:925/2000, 耗时:0.00分/2.29分 | step: 51800 | performance: 10.0 | accuracy: 0.30 | loss: 10.53
update:930/2000, 耗时:0.00分/2.30分 | step: 52080 | performance: 6.4 | accuracy: 0.30 | loss: 0.50
update:935/2000, 耗时:0.00分/2.31分 | step: 52360 | performance: 5.2 | accuracy: 0.30 | loss: 2.66
update:940/2000, 耗时:0.00分/2.32分 | step: 52640 | performance: 4.7 | accuracy: 0.30 | loss: 0.93
update:945/2000, 耗时:0.00分/2.33分 | step: 52920 | performance: 5.1 | accuracy: 0.31 | loss: 0.42
update:950/2000, 耗时:0.00分/2.35分 | step: 53200 | performance: 0.5 | accuracy: 0.31 | loss: 1.44
update:955/2000, 耗时:0.00分/2.36分 | step: 53480 | performance: 0.5 | accuracy: 0.31 | loss: 4.33
update:960/2000, 耗时:0.00分/2.37分 | step: 53760 | performance: 0.9 | accuracy: 0.31 | loss: 8.20
update:965/2000, 耗时:0.00分/2.38分 | step: 54040 | performance: 1.2 | accuracy: 0.31 | loss: 1.38
update:970/2000, 耗时:0.00分/2.39分 | step: 54320 | performance: 0.8 | accuracy: 0.32 | loss: 1.38
update:975/2000, 耗时:0.00分/2.40分 | step: 54600 | performance: 0.4 | accuracy: 0.32 | loss: 7.91
update:980/2000, 耗时:0.00分/2.42分 | step: 54880 | performance: 0.4 | accuracy: 0.32 | loss: 5.68
update:985/2000, 耗时:0.00分/2.43分 | step: 55160 | performance: 0.4 | accuracy: 0.32 | loss: 2.16
update:990/2000, 耗时:0.00分/2.44分 | step: 55440 | performance: 0.1 | accuracy: 0.32 | loss: 15.68
update:995/2000, 耗时:0.00分/2.45分 | step: 55720 | performance: 0.1 | accuracy: 0.32 | loss: 6.71
update:1000/2000, 耗时:0.00分/2.46分 | step: 56000 | performance: 0.1 | accuracy: 0.32 | loss: 1.53
update:1005/2000, 耗时:0.00分/2.47分 | step: 56280 | performance: 0.1 | accuracy: 0.32 | loss: 1.08
Saving PPO weights in both H5 format and checkpoint @ update:1006 
Saving PPO weights in both H5 format and checkpoint @ update:1008 
step: 56553 | worker_0@n_step_6: average total_reward after train data exhaustion : -34.8 | max total_reward: 109.3
step: 56554 | worker_1@n_step_6: average total_reward after train data exhaustion : -33.4 | max total_reward: 109.3
step: 56555 | worker_2@n_step_6: average total_reward after train data exhaustion : -32.1 | max total_reward: 109.3
step: 56556 | worker_3@n_step_6: average total_reward after train data exhaustion : -31.0 | max total_reward: 109.3
step: 56558 | worker_5@n_step_6: average total_reward after train data exhaustion : -29.9 | max total_reward: 109.3
step: 56559 | worker_6@n_step_6: average total_reward after train data exhaustion : -28.8 | max total_reward: 109.3
step: 56560 | worker_7@n_step_6: average total_reward after train data exhaustion : -27.9 | max total_reward: 109.3
update:1010/2000, 耗时:0.00分/2.49分 | step: 56560 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
Saving PPO weights in both H5 format and checkpoint @ update:1010 
Saving PPO weights in both H5 format and checkpoint @ update:1011 
update:1015/2000, 耗时:0.00分/2.51分 | step: 56840 | performance: 2.3 | accuracy: 0.54 | loss: 11.54
update:1020/2000, 耗时:0.00分/2.53分 | step: 57120 | performance: 1.8 | accuracy: 0.51 | loss: 4.20
update:1025/2000, 耗时:0.00分/2.54分 | step: 57400 | performance: 3.8 | accuracy: 0.56 | loss: 1.88
update:1030/2000, 耗时:0.00分/2.55分 | step: 57680 | performance: 5.3 | accuracy: 0.56 | loss: 1.60
update:1035/2000, 耗时:0.00分/2.56分 | step: 57960 | performance: 5.6 | accuracy: 0.55 | loss: 1.62
update:1040/2000, 耗时:0.00分/2.57分 | step: 58240 | performance: 10.4 | accuracy: 0.55 | loss: 5.82
update:1045/2000, 耗时:0.00分/2.58分 | step: 58520 | performance: 8.5 | accuracy: 0.53 | loss: 5.84
update:1050/2000, 耗时:0.00分/2.59分 | step: 58800 | performance: 11.3 | accuracy: 0.54 | loss: 0.68
update:1055/2000, 耗时:0.00分/2.61分 | step: 59080 | performance: 36.8 | accuracy: 0.55 | loss: 1.74
update:1060/2000, 耗时:0.00分/2.62分 | step: 59360 | performance: 48.5 | accuracy: 0.54 | loss: 1.58
update:1065/2000, 耗时:0.00分/2.63分 | step: 59640 | performance: 35.0 | accuracy: 0.54 | loss: 3.38
update:1070/2000, 耗时:0.00分/2.64分 | step: 59920 | performance: 40.5 | accuracy: 0.54 | loss: 1.82
update:1075/2000, 耗时:0.00分/2.65分 | step: 60200 | performance: 29.2 | accuracy: 0.52 | loss: 3.73
update:1080/2000, 耗时:0.00分/2.66分 | step: 60480 | performance: 25.0 | accuracy: 0.52 | loss: 6.37
update:1085/2000, 耗时:0.00分/2.68分 | step: 60760 | performance: 1.5 | accuracy: 0.50 | loss: 4.64
update:1090/2000, 耗时:0.00分/2.69分 | step: 61040 | performance: 0.4 | accuracy: 0.48 | loss: 8.19
update:1095/2000, 耗时:0.00分/2.70分 | step: 61320 | performance: 0.9 | accuracy: 0.49 | loss: 1.65
update:1100/2000, 耗时:0.00分/2.71分 | step: 61600 | performance: 0.7 | accuracy: 0.49 | loss: 0.65
update:1105/2000, 耗时:0.00分/2.72分 | step: 61880 | performance: 0.5 | accuracy: 0.48 | loss: 5.67
update:1110/2000, 耗时:0.00分/2.73分 | step: 62160 | performance: 1.1 | accuracy: 0.49 | loss: 2.23
update:1115/2000, 耗时:0.00分/2.75分 | step: 62440 | performance: 0.9 | accuracy: 0.49 | loss: 4.81
update:1120/2000, 耗时:0.00分/2.76分 | step: 62720 | performance: 1.2 | accuracy: 0.49 | loss: 6.05
update:1125/2000, 耗时:0.00分/2.77分 | step: 63000 | performance: 3.9 | accuracy: 0.50 | loss: 0.53
update:1130/2000, 耗时:0.00分/2.78分 | step: 63280 | performance: 3.6 | accuracy: 0.48 | loss: 0.08
update:1135/2000, 耗时:0.00分/2.79分 | step: 63560 | performance: 3.6 | accuracy: 0.46 | loss: 0.00
update:1140/2000, 耗时:0.00分/2.80分 | step: 63840 | performance: 3.6 | accuracy: 0.44 | loss: 0.00
update:1145/2000, 耗时:0.00分/2.82分 | step: 64120 | performance: 3.6 | accuracy: 0.43 | loss: 0.00
update:1150/2000, 耗时:0.00分/2.83分 | step: 64400 | performance: 3.6 | accuracy: 0.41 | loss: 0.00
update:1155/2000, 耗时:0.00分/2.84分 | step: 64680 | performance: 3.6 | accuracy: 0.40 | loss: 0.17
update:1160/2000, 耗时:0.00分/2.85分 | step: 64960 | performance: 3.3 | accuracy: 0.39 | loss: -0.00
update:1165/2000, 耗时:0.00分/2.86分 | step: 65240 | performance: 3.3 | accuracy: 0.38 | loss: 0.05
update:1170/2000, 耗时:0.00分/2.87分 | step: 65520 | performance: 3.5 | accuracy: 0.37 | loss: 1.74
update:1175/2000, 耗时:0.00分/2.89分 | step: 65800 | performance: 6.2 | accuracy: 0.37 | loss: 4.13
update:1180/2000, 耗时:0.00分/2.90分 | step: 66080 | performance: 4.7 | accuracy: 0.38 | loss: 6.91
update:1185/2000, 耗时:0.00分/2.91分 | step: 66360 | performance: 3.7 | accuracy: 0.38 | loss: 3.35
update:1190/2000, 耗时:0.00分/2.92分 | step: 66640 | performance: 15.9 | accuracy: 0.39 | loss: 2.82
update:1195/2000, 耗时:0.00分/2.93分 | step: 66920 | performance: 10.5 | accuracy: 0.39 | loss: 2.45
update:1200/2000, 耗时:0.00分/2.95分 | step: 67200 | performance: 12.7 | accuracy: 0.40 | loss: 6.41
update:1205/2000, 耗时:0.00分/2.96分 | step: 67480 | performance: 32.0 | accuracy: 0.40 | loss: 8.19
update:1210/2000, 耗时:0.00分/2.97分 | step: 67760 | performance: 16.9 | accuracy: 0.40 | loss: 1.55
update:1215/2000, 耗时:0.00分/2.98分 | step: 68040 | performance: 16.9 | accuracy: 0.39 | loss: 0.16
update:1220/2000, 耗时:0.00分/2.99分 | step: 68320 | performance: 166.1 | accuracy: 0.39 | loss: 15.65
update:1225/2000, 耗时:0.00分/3.00分 | step: 68600 | performance: 475.7 | accuracy: 0.40 | loss: 7.98
update:1230/2000, 耗时:0.00分/3.02分 | step: 68880 | performance: 819.2 | accuracy: 0.40 | loss: 7.84
update:1235/2000, 耗时:0.00分/3.03分 | step: 69160 | performance: 3089.6 | accuracy: 0.41 | loss: 0.80
update:1240/2000, 耗时:0.00分/3.04分 | step: 69440 | performance: 2460.7 | accuracy: 0.40 | loss: 0.00
update:1245/2000, 耗时:0.00分/3.05分 | step: 69720 | performance: 2201.8 | accuracy: 0.39 | loss: 0.02
update:1250/2000, 耗时:0.00分/3.06分 | step: 70000 | performance: 2201.8 | accuracy: 0.39 | loss: 0.07
update:1255/2000, 耗时:0.00分/3.07分 | step: 70280 | performance: 2086.1 | accuracy: 0.38 | loss: 0.57
update:1260/2000, 耗时:0.00分/3.09分 | step: 70560 | performance: 1584.7 | accuracy: 0.38 | loss: 0.04
update:1265/2000, 耗时:0.00分/3.10分 | step: 70840 | performance: 1584.7 | accuracy: 0.37 | loss: 0.00
update:1270/2000, 耗时:0.00分/3.11分 | step: 71120 | performance: 1584.7 | accuracy: 0.37 | loss: 0.00
update:1275/2000, 耗时:0.00分/3.12分 | step: 71400 | performance: 1584.7 | accuracy: 0.36 | loss: 0.00
update:1280/2000, 耗时:0.00分/3.13分 | step: 71680 | performance: 1584.7 | accuracy: 0.36 | loss: 0.12
update:1285/2000, 耗时:0.00分/3.14分 | step: 71960 | performance: 1584.7 | accuracy: 0.35 | loss: 0.00
update:1290/2000, 耗时:0.00分/3.16分 | step: 72240 | performance: 1584.7 | accuracy: 0.34 | loss: 0.00
update:1295/2000, 耗时:0.00分/3.17分 | step: 72520 | performance: 1584.7 | accuracy: 0.34 | loss: 0.00
update:1300/2000, 耗时:0.00分/3.18分 | step: 72800 | performance: 1584.7 | accuracy: 0.33 | loss: 0.01
update:1305/2000, 耗时:0.00分/3.19分 | step: 73080 | performance: 1584.7 | accuracy: 0.33 | loss: 0.00
update:1310/2000, 耗时:0.00分/3.20分 | step: 73360 | performance: 1584.7 | accuracy: 0.32 | loss: 0.00
update:1315/2000, 耗时:0.00分/3.21分 | step: 73640 | performance: 1584.7 | accuracy: 0.32 | loss: 0.00
update:1320/2000, 耗时:0.00分/3.22分 | step: 73920 | performance: 1584.7 | accuracy: 0.31 | loss: 0.00
update:1325/2000, 耗时:0.00分/3.24分 | step: 74200 | performance: 1584.7 | accuracy: 0.31 | loss: 0.20
update:1330/2000, 耗时:0.00分/3.25分 | step: 74480 | performance: 1584.7 | accuracy: 0.30 | loss: 0.00
update:1335/2000, 耗时:0.00分/3.26分 | step: 74760 | performance: 1584.7 | accuracy: 0.30 | loss: 0.00
update:1340/2000, 耗时:0.00分/3.27分 | step: 75040 | performance: 1584.7 | accuracy: 0.29 | loss: 0.00
update:1345/2000, 耗时:0.00分/3.28分 | step: 75320 | performance: 1695.6 | accuracy: 0.29 | loss: 5.04
update:1350/2000, 耗时:0.00分/3.30分 | step: 75600 | performance: 1177.4 | accuracy: 0.29 | loss: 4.13
update:1355/2000, 耗时:0.00分/3.31分 | step: 75880 | performance: 523.4 | accuracy: 0.30 | loss: 4.37
update:1360/2000, 耗时:0.00分/3.32分 | step: 76160 | performance: 331.7 | accuracy: 0.29 | loss: 1.20
update:1365/2000, 耗时:0.00分/3.33分 | step: 76440 | performance: 197.4 | accuracy: 0.30 | loss: 9.03
update:1370/2000, 耗时:0.00分/3.34分 | step: 76720 | performance: 562.0 | accuracy: 0.30 | loss: 0.50
update:1375/2000, 耗时:0.00分/3.35分 | step: 77000 | performance: 522.6 | accuracy: 0.30 | loss: 0.25
update:1380/2000, 耗时:0.00分/3.37分 | step: 77280 | performance: 547.5 | accuracy: 0.29 | loss: 0.85
update:1385/2000, 耗时:0.00分/3.38分 | step: 77560 | performance: 651.3 | accuracy: 0.30 | loss: 3.38
update:1390/2000, 耗时:0.00分/3.39分 | step: 77840 | performance: 649.3 | accuracy: 0.29 | loss: 0.00
update:1395/2000, 耗时:0.00分/3.40分 | step: 78120 | performance: 649.3 | accuracy: 0.29 | loss: 0.00
update:1400/2000, 耗时:0.00分/3.41分 | step: 78400 | performance: 649.3 | accuracy: 0.28 | loss: 0.00
update:1405/2000, 耗时:0.00分/3.42分 | step: 78680 | performance: 664.3 | accuracy: 0.28 | loss: 0.38
update:1410/2000, 耗时:0.00分/3.44分 | step: 78960 | performance: 484.7 | accuracy: 0.28 | loss: 0.39
update:1415/2000, 耗时:0.00分/3.45分 | step: 79240 | performance: 1750.1 | accuracy: 0.28 | loss: 3.75
update:1420/2000, 耗时:0.00分/3.46分 | step: 79520 | performance: 3918.3 | accuracy: 0.29 | loss: 9.41
update:1425/2000, 耗时:0.00分/3.47分 | step: 79800 | performance: 4497.8 | accuracy: 0.29 | loss: 12.69
update:1430/2000, 耗时:0.00分/3.48分 | step: 80080 | performance: 3150.6 | accuracy: 0.29 | loss: 8.36
update:1435/2000, 耗时:0.00分/3.49分 | step: 80360 | performance: 4414.6 | accuracy: 0.30 | loss: 3.36
update:1440/2000, 耗时:0.00分/3.51分 | step: 80640 | performance: 2425.2 | accuracy: 0.30 | loss: 1.42
update:1445/2000, 耗时:0.00分/3.52分 | step: 80920 | performance: 2383.3 | accuracy: 0.30 | loss: 8.97
update:1450/2000, 耗时:0.00分/3.53分 | step: 81200 | performance: 2002.3 | accuracy: 0.30 | loss: 1.58
update:1455/2000, 耗时:0.00分/3.54分 | step: 81480 | performance: 328.6 | accuracy: 0.30 | loss: 26.17
update:1460/2000, 耗时:0.00分/3.55分 | step: 81760 | performance: 145.1 | accuracy: 0.30 | loss: 8.11
update:1465/2000, 耗时:0.00分/3.56分 | step: 82040 | performance: 399.6 | accuracy: 0.31 | loss: 11.32
update:1470/2000, 耗时:0.00分/3.58分 | step: 82320 | performance: 415.8 | accuracy: 0.31 | loss: 2.25
update:1475/2000, 耗时:0.00分/3.59分 | step: 82600 | performance: 244.5 | accuracy: 0.31 | loss: 1.21
update:1480/2000, 耗时:0.00分/3.60分 | step: 82880 | performance: 206.7 | accuracy: 0.31 | loss: 8.47
update:1485/2000, 耗时:0.00分/3.61分 | step: 83160 | performance: 111.2 | accuracy: 0.31 | loss: 2.04
update:1490/2000, 耗时:0.00分/3.62分 | step: 83440 | performance: 114.3 | accuracy: 0.31 | loss: 1.92
update:1495/2000, 耗时:0.00分/3.63分 | step: 83720 | performance: 65.5 | accuracy: 0.31 | loss: 4.06
update:1500/2000, 耗时:0.00分/3.64分 | step: 84000 | performance: 24.5 | accuracy: 0.31 | loss: 2.74
update:1505/2000, 耗时:0.00分/3.66分 | step: 84280 | performance: 25.4 | accuracy: 0.31 | loss: 1.08
update:1510/2000, 耗时:0.00分/3.67分 | step: 84560 | performance: 23.5 | accuracy: 0.32 | loss: 0.83
Saving PPO weights in both H5 format and checkpoint @ update:1513 
Saving PPO weights in both H5 format and checkpoint @ update:1514 
update:1515/2000, 耗时:0.00分/3.69分 | step: 84840 | performance: 1.3 | accuracy: 0.47 | loss: 3.07
update:1520/2000, 耗时:0.00分/3.70分 | step: 85120 | performance: 4.2 | accuracy: 0.62 | loss: 5.59
update:1525/2000, 耗时:0.00分/3.71分 | step: 85400 | performance: 9.0 | accuracy: 0.62 | loss: 10.89
update:1530/2000, 耗时:0.00分/3.72分 | step: 85680 | performance: 10.5 | accuracy: 0.59 | loss: 2.29
update:1535/2000, 耗时:0.00分/3.74分 | step: 85960 | performance: 19.1 | accuracy: 0.59 | loss: 2.17
update:1540/2000, 耗时:0.00分/3.75分 | step: 86240 | performance: 6.9 | accuracy: 0.54 | loss: 11.60
update:1545/2000, 耗时:0.00分/3.76分 | step: 86520 | performance: 6.5 | accuracy: 0.53 | loss: 9.51
update:1550/2000, 耗时:0.00分/3.77分 | step: 86800 | performance: 14.6 | accuracy: 0.55 | loss: 16.16
update:1555/2000, 耗时:0.00分/3.78分 | step: 87080 | performance: 23.2 | accuracy: 0.55 | loss: 5.74
update:1560/2000, 耗时:0.00分/3.79分 | step: 87360 | performance: 27.8 | accuracy: 0.54 | loss: 2.18
update:1565/2000, 耗时:0.00分/3.80分 | step: 87640 | performance: 21.4 | accuracy: 0.54 | loss: 7.63
update:1570/2000, 耗时:0.00分/3.82分 | step: 87920 | performance: 26.2 | accuracy: 0.54 | loss: 2.38
update:1575/2000, 耗时:0.00分/3.83分 | step: 88200 | performance: 31.9 | accuracy: 0.54 | loss: 6.66
update:1580/2000, 耗时:0.00分/3.84分 | step: 88480 | performance: 30.7 | accuracy: 0.53 | loss: 1.33
update:1585/2000, 耗时:0.00分/3.85分 | step: 88760 | performance: 9.0 | accuracy: 0.52 | loss: 9.02
update:1590/2000, 耗时:0.00分/3.86分 | step: 89040 | performance: 0.9 | accuracy: 0.50 | loss: 14.39
update:1595/2000, 耗时:0.00分/3.87分 | step: 89320 | performance: 1.5 | accuracy: 0.50 | loss: 2.63
update:1600/2000, 耗时:0.00分/3.88分 | step: 89600 | performance: 1.1 | accuracy: 0.50 | loss: 7.51
update:1605/2000, 耗时:0.00分/3.90分 | step: 89880 | performance: 0.7 | accuracy: 0.49 | loss: 4.62
update:1610/2000, 耗时:0.00分/3.91分 | step: 90160 | performance: 0.8 | accuracy: 0.49 | loss: 5.28
update:1615/2000, 耗时:0.00分/3.92分 | step: 90440 | performance: 1.0 | accuracy: 0.49 | loss: 5.91
update:1620/2000, 耗时:0.00分/3.93分 | step: 90720 | performance: 1.3 | accuracy: 0.50 | loss: 1.66
update:1625/2000, 耗时:0.00分/3.94分 | step: 91000 | performance: 2.6 | accuracy: 0.51 | loss: 6.88
update:1630/2000, 耗时:0.00分/3.95分 | step: 91280 | performance: 2.5 | accuracy: 0.50 | loss: 0.05
update:1635/2000, 耗时:0.00分/3.96分 | step: 91560 | performance: 2.5 | accuracy: 0.48 | loss: 0.00
update:1640/2000, 耗时:0.00分/3.98分 | step: 91840 | performance: 2.5 | accuracy: 0.46 | loss: 0.00
update:1645/2000, 耗时:0.00分/3.99分 | step: 92120 | performance: 2.5 | accuracy: 0.45 | loss: 0.00
update:1650/2000, 耗时:0.00分/4.00分 | step: 92400 | performance: 2.5 | accuracy: 0.43 | loss: 0.00
update:1655/2000, 耗时:0.00分/4.01分 | step: 92680 | performance: 2.5 | accuracy: 0.42 | loss: 0.00
update:1660/2000, 耗时:0.00分/4.02分 | step: 92960 | performance: 2.5 | accuracy: 0.40 | loss: 0.24
update:1665/2000, 耗时:0.00分/4.03分 | step: 93240 | performance: 2.6 | accuracy: 0.39 | loss: 0.12
update:1670/2000, 耗时:0.00分/4.04分 | step: 93520 | performance: 3.1 | accuracy: 0.39 | loss: 1.83
update:1675/2000, 耗时:0.00分/4.05分 | step: 93800 | performance: 4.6 | accuracy: 0.38 | loss: 0.54
update:1680/2000, 耗时:0.00分/4.07分 | step: 94080 | performance: 3.1 | accuracy: 0.37 | loss: 4.32
update:1685/2000, 耗时:0.00分/4.08分 | step: 94360 | performance: 8.9 | accuracy: 0.38 | loss: 7.33
update:1690/2000, 耗时:0.00分/4.09分 | step: 94640 | performance: 12.3 | accuracy: 0.39 | loss: 6.18
update:1695/2000, 耗时:0.00分/4.10分 | step: 94920 | performance: 24.4 | accuracy: 0.39 | loss: 2.68
update:1700/2000, 耗时:0.00分/4.11分 | step: 95200 | performance: 19.3 | accuracy: 0.39 | loss: 3.57
update:1705/2000, 耗时:0.00分/4.12分 | step: 95480 | performance: 35.7 | accuracy: 0.40 | loss: 1.21
update:1710/2000, 耗时:0.00分/4.13分 | step: 95760 | performance: 32.3 | accuracy: 0.40 | loss: 4.51
update:1715/2000, 耗时:0.00分/4.15分 | step: 96040 | performance: 40.0 | accuracy: 0.40 | loss: 3.85
update:1720/2000, 耗时:0.00分/4.16分 | step: 96320 | performance: 44.4 | accuracy: 0.39 | loss: 7.34
update:1725/2000, 耗时:0.00分/4.17分 | step: 96600 | performance: 344.7 | accuracy: 0.40 | loss: 4.96
update:1730/2000, 耗时:0.00分/4.18分 | step: 96880 | performance: 786.0 | accuracy: 0.40 | loss: 3.14
update:1735/2000, 耗时:0.00分/4.19分 | step: 97160 | performance: 1177.0 | accuracy: 0.41 | loss: 9.58
update:1740/2000, 耗时:0.00分/4.20分 | step: 97440 | performance: 2121.7 | accuracy: 0.41 | loss: 10.09
update:1745/2000, 耗时:0.00分/4.22分 | step: 97720 | performance: 1810.0 | accuracy: 0.41 | loss: 2.91
update:1750/2000, 耗时:0.00分/4.23分 | step: 98000 | performance: 1869.7 | accuracy: 0.40 | loss: 0.10
update:1755/2000, 耗时:0.00分/4.24分 | step: 98280 | performance: 1801.2 | accuracy: 0.40 | loss: 1.58
update:1760/2000, 耗时:0.00分/4.25分 | step: 98560 | performance: 1439.8 | accuracy: 0.39 | loss: 5.67
update:1765/2000, 耗时:0.00分/4.26分 | step: 98840 | performance: 1196.2 | accuracy: 0.39 | loss: 0.14
update:1770/2000, 耗时:0.00分/4.27分 | step: 99120 | performance: 1196.2 | accuracy: 0.38 | loss: 0.00
update:1775/2000, 耗时:0.00分/4.29分 | step: 99400 | performance: 1200.3 | accuracy: 0.38 | loss: 0.09
update:1780/2000, 耗时:0.00分/4.30分 | step: 99680 | performance: 1059.5 | accuracy: 0.37 | loss: 0.21
update:1785/2000, 耗时:0.00分/4.31分 | step: 99960 | performance: 1059.5 | accuracy: 0.36 | loss: 0.16
update:1790/2000, 耗时:0.00分/4.32分 | step: 100240 | performance: 1059.5 | accuracy: 0.36 | loss: 0.03
update:1795/2000, 耗时:0.00分/4.33分 | step: 100520 | performance: 1059.5 | accuracy: 0.35 | loss: -0.00
update:1800/2000, 耗时:0.00分/4.34分 | step: 100800 | performance: 1059.5 | accuracy: 0.35 | loss: 0.00
update:1805/2000, 耗时:0.00分/4.35分 | step: 101080 | performance: 1059.5 | accuracy: 0.34 | loss: -0.00
update:1810/2000, 耗时:0.00分/4.36分 | step: 101360 | performance: 1059.5 | accuracy: 0.34 | loss: 0.00
update:1815/2000, 耗时:0.00分/4.37分 | step: 101640 | performance: 1059.5 | accuracy: 0.33 | loss: -0.00
update:1820/2000, 耗时:0.00分/4.39分 | step: 101920 | performance: 962.6 | accuracy: 0.33 | loss: 0.00
update:1825/2000, 耗时:0.00分/4.40分 | step: 102200 | performance: 962.6 | accuracy: 0.32 | loss: 0.00
update:1830/2000, 耗时:0.00分/4.41分 | step: 102480 | performance: 962.6 | accuracy: 0.32 | loss: 0.00
update:1835/2000, 耗时:0.00分/4.42分 | step: 102760 | performance: 962.6 | accuracy: 0.31 | loss: 0.02
update:1840/2000, 耗时:0.00分/4.43分 | step: 103040 | performance: 962.6 | accuracy: 0.31 | loss: -0.00
update:1845/2000, 耗时:0.00分/4.44分 | step: 103320 | performance: 1436.1 | accuracy: 0.30 | loss: 7.28
update:1850/2000, 耗时:0.00分/4.45分 | step: 103600 | performance: 2336.5 | accuracy: 0.30 | loss: 4.46
update:1855/2000, 耗时:0.00分/4.47分 | step: 103880 | performance: 566.5 | accuracy: 0.30 | loss: 15.20
update:1860/2000, 耗时:0.00分/4.48分 | step: 104160 | performance: 390.4 | accuracy: 0.31 | loss: 8.21
update:1865/2000, 耗时:0.00分/4.49分 | step: 104440 | performance: 183.0 | accuracy: 0.30 | loss: 3.38
update:1870/2000, 耗时:0.00分/4.50分 | step: 104720 | performance: 690.4 | accuracy: 0.31 | loss: 2.11
update:1875/2000, 耗时:0.00分/4.51分 | step: 105000 | performance: 1063.4 | accuracy: 0.31 | loss: 0.32
update:1880/2000, 耗时:0.00分/4.52分 | step: 105280 | performance: 1024.6 | accuracy: 0.31 | loss: 0.15
update:1885/2000, 耗时:0.00分/4.53分 | step: 105560 | performance: 1052.3 | accuracy: 0.31 | loss: 0.35
update:1890/2000, 耗时:0.00分/4.54分 | step: 105840 | performance: 1635.5 | accuracy: 0.31 | loss: 0.12
update:1895/2000, 耗时:0.00分/4.55分 | step: 106120 | performance: 1519.1 | accuracy: 0.30 | loss: 0.00
update:1900/2000, 耗时:0.00分/4.57分 | step: 106400 | performance: 1519.1 | accuracy: 0.30 | loss: 0.00
update:1905/2000, 耗时:0.00分/4.58分 | step: 106680 | performance: 1519.1 | accuracy: 0.29 | loss: 0.13
update:1910/2000, 耗时:0.00分/4.59分 | step: 106960 | performance: 1409.7 | accuracy: 0.29 | loss: 0.23
update:1915/2000, 耗时:0.00分/4.60分 | step: 107240 | performance: 1481.4 | accuracy: 0.29 | loss: 0.69
update:1920/2000, 耗时:0.00分/4.61分 | step: 107520 | performance: 1758.1 | accuracy: 0.29 | loss: 2.13
update:1925/2000, 耗时:0.00分/4.62分 | step: 107800 | performance: 1705.3 | accuracy: 0.29 | loss: 12.13
update:1930/2000, 耗时:0.00分/4.63分 | step: 108080 | performance: 2112.7 | accuracy: 0.29 | loss: 5.54
update:1935/2000, 耗时:0.00分/4.64分 | step: 108360 | performance: 3968.7 | accuracy: 0.30 | loss: 9.87
update:1940/2000, 耗时:0.00分/4.66分 | step: 108640 | performance: 2635.0 | accuracy: 0.30 | loss: 0.22
update:1945/2000, 耗时:0.00分/4.67分 | step: 108920 | performance: 2125.3 | accuracy: 0.30 | loss: 3.14
update:1950/2000, 耗时:0.00分/4.68分 | step: 109200 | performance: 1370.4 | accuracy: 0.30 | loss: 1.15
update:1955/2000, 耗时:0.00分/4.69分 | step: 109480 | performance: 775.8 | accuracy: 0.30 | loss: 0.84
update:1960/2000, 耗时:0.00分/4.70分 | step: 109760 | performance: 120.5 | accuracy: 0.30 | loss: 2.13
update:1965/2000, 耗时:0.00分/4.71分 | step: 110040 | performance: 112.4 | accuracy: 0.30 | loss: 5.48
update:1970/2000, 耗时:0.00分/4.72分 | step: 110320 | performance: 211.8 | accuracy: 0.31 | loss: 8.19
update:1975/2000, 耗时:0.00分/4.73分 | step: 110600 | performance: 267.0 | accuracy: 0.31 | loss: 1.87
update:1980/2000, 耗时:0.00分/4.75分 | step: 110880 | performance: 130.1 | accuracy: 0.31 | loss: 1.40
update:1985/2000, 耗时:0.00分/4.76分 | step: 111160 | performance: 45.9 | accuracy: 0.31 | loss: 7.70
update:1990/2000, 耗时:0.00分/4.77分 | step: 111440 | performance: 49.9 | accuracy: 0.31 | loss: 4.87
update:1995/2000, 耗时:0.00分/4.78分 | step: 111720 | performance: 35.1 | accuracy: 0.31 | loss: 2.29
  0%|          | 0/401 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/4.79分 | step: 112000 | performance: 10.6 | accuracy: 0.31 | loss: 17.10
----------------------------------------finished----------------------------------------
100%|| 401/401 [00:00<00:00, 100251.29it/s]
==================================================
2023-01-05T12:00:00 | *** START BACKTEST ***
2023-01-05T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1824.80
2023-07-24T12:00:00 | net performance [%] = 82.4804
2023-07-24T12:00:00 | number of trades [#] = 16
==================================================
Trial 52 Complete [00h 05m 14s]
net_wealth: 1824.8039564105297

Best net_wealth So Far: 1824.8039564105297
Total elapsed time: 07h 15m 51s

Search: Running Trial #53

Value             |Best Value So Far |Hyperparameter
6                 |6                 |horizon
225               |365               |lookback
True              |True              |MarketFactor
10                |10                |lags
0.95              |0.98              |gamma
16                |16                |batch_size
10                |7                 |n_step
0.85              |0.94              |gae_lambda
0.1               |0.5               |gradient_clip_norm
5                 |3                 |epochs
5e-05             |0.001             |actor_lr
0.0005            |0.001             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4295.000000   4301.000000
mean      0.000435    20113.607657  ...   20191.527960  20169.373185
std       0.027833    16040.642334  ...   16078.872271  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7755.915039   7730.930176
50%       0.000642    11571.842969  ...   11757.219727  11751.469727
75%       0.011590    29894.706152  ...   30018.430664  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
22023-07-28 05:19:15.464582: I tensorflow/core/platform/cpu_feature_guard.cc:14220023023-07-28 052-:19:15]. Th406i74-25s8 05:19:15 .Tenso48rF36463:low 1: I  Itbinary etnso2ensorfl0 2iorfl3oww/-2307-28 05:19:15.464-02s 7-28 057:190223-01:157:. I te464-n6362sorflocw/co/corr8e e:/0o /pI lare5/:ppl1tletatanform/scpu_ffotform/9c:o15.eat4p64rflow7u_ure_guafera54trd./c: Imure_gc:14 2teo/]cpu_ cnsoropre/tfTeapihis Temized ntlwsorFlow binary is2itah one0urA P2e_3I-gt0 fufarl7oDp-ode.uo2a8rd .wcc0c:/1c42r5c]:e20m2/3cpor1e pT/plhaiut_ff:-e09to:r1m4s17- 28T25. 04] /Tcap5:t19ur6ui_mfiezae:deh 5150e_gu arw.Ne74d6iitutnh6 osnues5orra l1 4.TAPNIe9:c  tDFecIeenps or: Nteenwluo1w4Fs o2l:binarr]ral  yo ifThowrkN eItrwosi etel o wb nosopt_rLki bLriarby srgflur/i(miaar oTenirnycnosroa rz(oordweyeed / FplDnNiN/olsa coeor)e/ p.Dwc tbNptloiNftorcn a)itfamrm:iuzseew1y4d ii tto sh  on 2wirthm /ot]/choopt ipmue_ fe efuollnatAiPzeecAsuIdo PIe wther wfioTle  Dpu_ngglho_uearedp. cciiDsN:t14h eewepf2e]a iongn eCAPNUe  utuurr TCrPea_T aUlPhI iDs gel Ni Nenesenestuianrsdwpttwrourcttorrukc tLiio .Nken sL ibrcaro rTbirnFeunsoyraFr  r(lyalpoewrlf oi bionn soNa( oinnnerD cporemaDncey:N1NeNwNe4r - )bi t2c]rin)t otfoaiwst icalo rokp  L  ourrueseraTm aonpcte-tsitohnehcer  iiittheyfmolsl si:c a li ziAbVorfae XT oendr AwVllwyi Xs2o tiho(
isn oppego wo triamtiirniezDeCnoTno FelnoawdNgeb  bwiintaP rNAhPyI ilUeC t  onP)sioeAnPs nts toU iIr Dehe uDctieme ep o :  AVNonnsX  AVieuspe NX2puir atnthn lp eNur eoeetalr Net
Tfsormanitrhuerc e-mco en irzietoafwtwipceocodoblelrkarrk l l  tLo wLtihiawobproinbsr aien aeryrm iinng yCPU inpsitrherformanc otiontthe s,  or atr(eonneDribueAe-ons:  N PIN)A to  (oneDuusild TNoVDXe eApV XNe2u
rTpcritecN) toe ntions re ot huisne  aeilctheana bNepterfosor foalrmae ftiF olplerlonollowiwowloann gw iCPeU tsce-witnheiorkg, reo Cmc in sP in n:LtrbisoU ibrattir uAc ihVXtctinsrtyruhael  or  ctioAuild poeVX 2T
(oTensraneDnsopertNo inatioorFnshNn se lpoer) fo:  AVr wt wo neiintmanuse Xp Act ie VX2haonsapethble
 tre  th-he apfppr,T oerooprlilatreebcmfpriowing ouaitlo  ende  ccomprilarit in oebicotmhpeirlrTelnaCmeanslP U r flao e thcgpseratiinorF oopseml ow .winn eothersrtare
 ope-f:  AVX AultioniVcstcath ,rXg2tions its.i
nich ereb  raatapprip
leTo enable them in other operations, rebuild TensorFlow withu operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlorfild TensorFlow with the appropriate compiler flags.
ons, rebuild TensorFlow with the appropriate compiler  the appropriate compiler flags.
opriateflags.
ormance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
 compiler flags.
w with the appropriate compiler flags.
2023-07-28 05:19:16.079722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:19:16.094948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:19:16.101685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:19:16.104516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:19:16.116576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:19:16.121476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:19:16.131941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:19:16.143246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 0.9 | accuracy: 0.26 | loss: 3.73
update: 10/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 1.2 | accuracy: 0.25 | loss: 4.16
update: 15/2000, 耗时:0.00分/0.07分 | step:  1200 | performance: 0.9 | accuracy: 0.28 | loss: 2.05
update: 20/2000, 耗时:0.00分/0.08分 | step:  1600 | performance: 2.3 | accuracy: 0.34 | loss: 1.06
update: 25/2000, 耗时:0.00分/0.10分 | step:  2000 | performance: 1.3 | accuracy: 0.33 | loss: 2.14
update: 30/2000, 耗时:0.00分/0.12分 | step:  2400 | performance: 2.0 | accuracy: 0.34 | loss: 0.99
update: 35/2000, 耗时:0.00分/0.14分 | step:  2800 | performance: 1.8 | accuracy: 0.34 | loss: 1.34
update: 40/2000, 耗时:0.00分/0.15分 | step:  3200 | performance: 1.5 | accuracy: 0.34 | loss: 5.82
update: 45/2000, 耗时:0.00分/0.17分 | step:  3600 | performance: 2.0 | accuracy: 0.35 | loss: 1.65
update: 50/2000, 耗时:0.00分/0.19分 | step:  4000 | performance: 3.2 | accuracy: 0.35 | loss: 2.82
update: 55/2000, 耗时:0.00分/0.21分 | step:  4400 | performance: 2.7 | accuracy: 0.35 | loss: 0.78
update: 60/2000, 耗时:0.00分/0.23分 | step:  4800 | performance: 1.7 | accuracy: 0.34 | loss: 0.71
update: 65/2000, 耗时:0.00分/0.25分 | step:  5200 | performance: 2.0 | accuracy: 0.35 | loss: 3.28
update: 70/2000, 耗时:0.00分/0.26分 | step:  5600 | performance: 5.5 | accuracy: 0.35 | loss: 3.35
update: 75/2000, 耗时:0.00分/0.28分 | step:  6000 | performance: 2.3 | accuracy: 0.35 | loss: 1.36
update: 80/2000, 耗时:0.00分/0.30分 | step:  6400 | performance: 3.4 | accuracy: 0.35 | loss: 0.82
update: 85/2000, 耗时:0.00分/0.32分 | step:  6800 | performance: 3.3 | accuracy: 0.35 | loss: 1.18
update: 90/2000, 耗时:0.00分/0.34分 | step:  7200 | performance: 3.2 | accuracy: 0.35 | loss: 1.06
update: 95/2000, 耗时:0.00分/0.36分 | step:  7600 | performance: 2.4 | accuracy: 0.34 | loss: 0.42
update:100/2000, 耗时:0.00分/0.38分 | step:  8000 | performance: 8.7 | accuracy: 0.35 | loss: 7.87
update:105/2000, 耗时:0.00分/0.40分 | step:  8400 | performance: 6.1 | accuracy: 0.35 | loss: 2.11
update:110/2000, 耗时:0.00分/0.41分 | step:  8800 | performance: 33.4 | accuracy: 0.36 | loss: 3.75
update:115/2000, 耗时:0.00分/0.43分 | step:  9200 | performance: 14.6 | accuracy: 0.35 | loss: 2.28
update:120/2000, 耗时:0.00分/0.45分 | step:  9600 | performance: 13.7 | accuracy: 0.35 | loss: 1.87
update:125/2000, 耗时:0.00分/0.47分 | step: 10000 | performance: 11.1 | accuracy: 0.35 | loss: 1.15
update:130/2000, 耗时:0.00分/0.49分 | step: 10400 | performance: 17.1 | accuracy: 0.35 | loss: 2.79
update:135/2000, 耗时:0.00分/0.51分 | step: 10800 | performance: 12.5 | accuracy: 0.35 | loss: 2.53
update:140/2000, 耗时:0.00分/0.53分 | step: 11200 | performance: 23.8 | accuracy: 0.36 | loss: 4.04
update:145/2000, 耗时:0.00分/0.55分 | step: 11600 | performance: 26.4 | accuracy: 0.36 | loss: 2.75
update:150/2000, 耗时:0.00分/0.56分 | step: 12000 | performance: 11.9 | accuracy: 0.36 | loss: 2.03
update:155/2000, 耗时:0.00分/0.58分 | step: 12400 | performance: 15.2 | accuracy: 0.37 | loss: 1.36
update:160/2000, 耗时:0.00分/0.60分 | step: 12800 | performance: 6.9 | accuracy: 0.37 | loss: 2.02
update:165/2000, 耗时:0.00分/0.62分 | step: 13200 | performance: 8.9 | accuracy: 0.37 | loss: 7.37
update:170/2000, 耗时:0.00分/0.64分 | step: 13600 | performance: 4.8 | accuracy: 0.37 | loss: 3.53
update:175/2000, 耗时:0.00分/0.66分 | step: 14000 | performance: 3.0 | accuracy: 0.37 | loss: 1.67
update:180/2000, 耗时:0.00分/0.68分 | step: 14400 | performance: 3.5 | accuracy: 0.36 | loss: 0.83
update:185/2000, 耗时:0.00分/0.70分 | step: 14800 | performance: 3.1 | accuracy: 0.36 | loss: 0.59
update:190/2000, 耗时:0.00分/0.72分 | step: 15200 | performance: 6.0 | accuracy: 0.36 | loss: 1.22
update:195/2000, 耗时:0.00分/0.74分 | step: 15600 | performance: 7.1 | accuracy: 0.36 | loss: 1.76
update:200/2000, 耗时:0.00分/0.76分 | step: 16000 | performance: 6.1 | accuracy: 0.36 | loss: 0.73
update:205/2000, 耗时:0.00分/0.78分 | step: 16400 | performance: 5.5 | accuracy: 0.36 | loss: 0.42
update:210/2000, 耗时:0.00分/0.80分 | step: 16800 | performance: 10.5 | accuracy: 0.36 | loss: 2.35
update:215/2000, 耗时:0.00分/0.82分 | step: 17200 | performance: 20.7 | accuracy: 0.37 | loss: 3.05
update:220/2000, 耗时:0.00分/0.84分 | step: 17600 | performance: 240.0 | accuracy: 0.37 | loss: 8.48
update:225/2000, 耗时:0.00分/0.86分 | step: 18000 | performance: 289.7 | accuracy: 0.38 | loss: 1.13
update:230/2000, 耗时:0.00分/0.88分 | step: 18400 | performance: 2484.3 | accuracy: 0.38 | loss: 3.07
update:235/2000, 耗时:0.00分/0.90分 | step: 18800 | performance: 3125.6 | accuracy: 0.39 | loss: 1.62
update:240/2000, 耗时:0.00分/0.92分 | step: 19200 | performance: 3027.5 | accuracy: 0.39 | loss: 2.72
update:245/2000, 耗时:0.00分/0.94分 | step: 19600 | performance: 2123.4 | accuracy: 0.38 | loss: 0.81
update:250/2000, 耗时:0.00分/0.96分 | step: 20000 | performance: 1198.7 | accuracy: 0.38 | loss: 2.90
update:255/2000, 耗时:0.00分/0.98分 | step: 20400 | performance: 1596.5 | accuracy: 0.38 | loss: 1.25
update:260/2000, 耗时:0.00分/1.00分 | step: 20800 | performance: 2048.5 | accuracy: 0.38 | loss: 2.02
update:265/2000, 耗时:0.00分/1.02分 | step: 21200 | performance: 1126.0 | accuracy: 0.38 | loss: 1.68
update:270/2000, 耗时:0.00分/1.04分 | step: 21600 | performance: 739.3 | accuracy: 0.38 | loss: 5.20
update:275/2000, 耗时:0.00分/1.06分 | step: 22000 | performance: 1058.2 | accuracy: 0.38 | loss: 3.39
update:280/2000, 耗时:0.00分/1.08分 | step: 22400 | performance: 2202.3 | accuracy: 0.38 | loss: 1.43
update:285/2000, 耗时:0.00分/1.10分 | step: 22800 | performance: 1480.5 | accuracy: 0.38 | loss: 1.10
update:290/2000, 耗时:0.00分/1.12分 | step: 23200 | performance: 528.4 | accuracy: 0.38 | loss: 1.78
update:295/2000, 耗时:0.00分/1.14分 | step: 23600 | performance: 500.6 | accuracy: 0.38 | loss: 2.05
update:300/2000, 耗时:0.00分/1.16分 | step: 24000 | performance: 604.8 | accuracy: 0.38 | loss: 1.20
update:305/2000, 耗时:0.00分/1.18分 | step: 24400 | performance: 893.5 | accuracy: 0.38 | loss: 1.49
update:310/2000, 耗时:0.00分/1.20分 | step: 24800 | performance: 726.6 | accuracy: 0.38 | loss: 1.05
update:315/2000, 耗时:0.00分/1.22分 | step: 25200 | performance: 476.0 | accuracy: 0.38 | loss: 1.51
update:320/2000, 耗时:0.00分/1.24分 | step: 25600 | performance: 2100.1 | accuracy: 0.38 | loss: 0.72
update:325/2000, 耗时:0.00分/1.26分 | step: 26000 | performance: 4142.3 | accuracy: 0.38 | loss: 8.32
update:330/2000, 耗时:0.00分/1.28分 | step: 26400 | performance: 13912.5 | accuracy: 0.38 | loss: 7.97
update:335/2000, 耗时:0.00分/1.30分 | step: 26800 | performance: 14719.0 | accuracy: 0.38 | loss: 1.75
update:340/2000, 耗时:0.00分/1.32分 | step: 27200 | performance: 17931.3 | accuracy: 0.38 | loss: 1.14
update:345/2000, 耗时:0.00分/1.33分 | step: 27600 | performance: 22037.6 | accuracy: 0.38 | loss: 2.83
update:350/2000, 耗时:0.00分/1.35分 | step: 28000 | performance: 18944.9 | accuracy: 0.38 | loss: 0.98
update:355/2000, 耗时:0.00分/1.37分 | step: 28400 | performance: 8572.6 | accuracy: 0.38 | loss: 6.46
update:360/2000, 耗时:0.00分/1.39分 | step: 28800 | performance: 10821.5 | accuracy: 0.38 | loss: 1.52
update:365/2000, 耗时:0.00分/1.41分 | step: 29200 | performance: 11790.7 | accuracy: 0.38 | loss: 3.05
Saving PPO weights in both H5 format and checkpoint @ update:366 
update:370/2000, 耗时:0.00分/1.43分 | step: 29600 | performance: 0.9 | accuracy: 0.36 | loss: 3.74
update:375/2000, 耗时:0.00分/1.45分 | step: 30000 | performance: 1.5 | accuracy: 0.38 | loss: 3.57
update:380/2000, 耗时:0.00分/1.47分 | step: 30400 | performance: 1.4 | accuracy: 0.36 | loss: 4.81
update:385/2000, 耗时:0.00分/1.49分 | step: 30800 | performance: 6.0 | accuracy: 0.41 | loss: 2.93
update:390/2000, 耗时:0.00分/1.51分 | step: 31200 | performance: 1.4 | accuracy: 0.36 | loss: 1.01
update:395/2000, 耗时:0.00分/1.53分 | step: 31600 | performance: 2.4 | accuracy: 0.39 | loss: 6.79
update:400/2000, 耗时:0.00分/1.55分 | step: 32000 | performance: 4.8 | accuracy: 0.40 | loss: 1.77
update:405/2000, 耗时:0.00分/1.57分 | step: 32400 | performance: 5.7 | accuracy: 0.40 | loss: 3.71
update:410/2000, 耗时:0.00分/1.58分 | step: 32800 | performance: 2.9 | accuracy: 0.40 | loss: 5.88
update:415/2000, 耗时:0.00分/1.60分 | step: 33200 | performance: 1.6 | accuracy: 0.38 | loss: 1.86
update:420/2000, 耗时:0.00分/1.62分 | step: 33600 | performance: 2.8 | accuracy: 0.40 | loss: 2.33
update:425/2000, 耗时:0.00分/1.64分 | step: 34000 | performance: 3.1 | accuracy: 0.40 | loss: 1.34
update:430/2000, 耗时:0.00分/1.66分 | step: 34400 | performance: 6.7 | accuracy: 0.41 | loss: 7.22
update:435/2000, 耗时:0.00分/1.68分 | step: 34800 | performance: 99.7 | accuracy: 0.43 | loss: 1.66
update:440/2000, 耗时:0.00分/1.70分 | step: 35200 | performance: 59.6 | accuracy: 0.42 | loss: 1.09
update:445/2000, 耗时:0.00分/1.72分 | step: 35600 | performance: 112.9 | accuracy: 0.43 | loss: 4.12
update:450/2000, 耗时:0.00分/1.73分 | step: 36000 | performance: 63.3 | accuracy: 0.43 | loss: 1.31
update:455/2000, 耗时:0.00分/1.75分 | step: 36400 | performance: 55.6 | accuracy: 0.42 | loss: 1.06
update:460/2000, 耗时:0.00分/1.77分 | step: 36800 | performance: 34.2 | accuracy: 0.42 | loss: 1.29
update:465/2000, 耗时:0.00分/1.79分 | step: 37200 | performance: 98.0 | accuracy: 0.43 | loss: 5.47
update:470/2000, 耗时:0.00分/1.81分 | step: 37600 | performance: 328.1 | accuracy: 0.44 | loss: 4.33
update:475/2000, 耗时:0.00分/1.83分 | step: 38000 | performance: 2134.0 | accuracy: 0.45 | loss: 2.93
update:480/2000, 耗时:0.00分/1.85分 | step: 38400 | performance: 760.0 | accuracy: 0.44 | loss: 5.40
update:485/2000, 耗时:0.00分/1.86分 | step: 38800 | performance: 605.2 | accuracy: 0.43 | loss: 1.09
update:490/2000, 耗时:0.00分/1.88分 | step: 39200 | performance: 325.6 | accuracy: 0.43 | loss: 1.12
update:495/2000, 耗时:0.00分/1.90分 | step: 39600 | performance: 1263.0 | accuracy: 0.44 | loss: 2.01
update:500/2000, 耗时:0.00分/1.92分 | step: 40000 | performance: 709.4 | accuracy: 0.44 | loss: 2.10
update:505/2000, 耗时:0.00分/1.94分 | step: 40400 | performance: 2815.9 | accuracy: 0.45 | loss: 4.05
update:510/2000, 耗时:0.00分/1.95分 | step: 40800 | performance: 2875.8 | accuracy: 0.45 | loss: 4.35
update:515/2000, 耗时:0.00分/1.97分 | step: 41200 | performance: 1141.8 | accuracy: 0.44 | loss: 4.29
update:520/2000, 耗时:0.00分/1.99分 | step: 41600 | performance: 1498.8 | accuracy: 0.45 | loss: 2.02
update:525/2000, 耗时:0.00分/2.01分 | step: 42000 | performance: 871.7 | accuracy: 0.44 | loss: 0.90
update:530/2000, 耗时:0.00分/2.03分 | step: 42400 | performance: 1889.2 | accuracy: 0.44 | loss: 2.80
update:535/2000, 耗时:0.00分/2.04分 | step: 42800 | performance: 884.2 | accuracy: 0.44 | loss: 3.81
update:540/2000, 耗时:0.00分/2.06分 | step: 43200 | performance: 200.0 | accuracy: 0.43 | loss: 1.14
update:545/2000, 耗时:0.00分/2.08分 | step: 43600 | performance: 129.4 | accuracy: 0.43 | loss: 1.04
update:550/2000, 耗时:0.00分/2.10分 | step: 44000 | performance: 132.8 | accuracy: 0.43 | loss: 1.27
update:555/2000, 耗时:0.00分/2.12分 | step: 44400 | performance: 87.6 | accuracy: 0.42 | loss: 3.02
update:560/2000, 耗时:0.00分/2.14分 | step: 44800 | performance: 94.2 | accuracy: 0.43 | loss: 1.78
update:565/2000, 耗时:0.00分/2.15分 | step: 45200 | performance: 43.3 | accuracy: 0.43 | loss: 0.82
update:570/2000, 耗时:0.00分/2.17分 | step: 45600 | performance: 35.0 | accuracy: 0.42 | loss: 1.05
update:575/2000, 耗时:0.00分/2.19分 | step: 46000 | performance: 79.2 | accuracy: 0.43 | loss: 1.08
update:580/2000, 耗时:0.00分/2.21分 | step: 46400 | performance: 251.8 | accuracy: 0.43 | loss: 3.67
update:585/2000, 耗时:0.00分/2.23分 | step: 46800 | performance: 2512.9 | accuracy: 0.44 | loss: 9.50
update:590/2000, 耗时:0.00分/2.24分 | step: 47200 | performance: 6816.7 | accuracy: 0.44 | loss: 4.99
update:595/2000, 耗时:0.00分/2.26分 | step: 47600 | performance: 52670.5 | accuracy: 0.45 | loss: 5.93
update:600/2000, 耗时:0.00分/2.28分 | step: 48000 | performance: 76533.9 | accuracy: 0.45 | loss: 2.92
update:605/2000, 耗时:0.00分/2.29分 | step: 48400 | performance: 81567.3 | accuracy: 0.45 | loss: 1.53
update:610/2000, 耗时:0.00分/2.31分 | step: 48800 | performance: 46421.6 | accuracy: 0.45 | loss: 1.59
update:615/2000, 耗时:0.00分/2.33分 | step: 49200 | performance: 67738.2 | accuracy: 0.45 | loss: 1.92
update:620/2000, 耗时:0.00分/2.35分 | step: 49600 | performance: 84493.5 | accuracy: 0.45 | loss: 2.96
update:625/2000, 耗时:0.00分/2.36分 | step: 50000 | performance: 98341.0 | accuracy: 0.45 | loss: 3.56
update:630/2000, 耗时:0.00分/2.38分 | step: 50400 | performance: 25827.7 | accuracy: 0.45 | loss: 1.24
update:635/2000, 耗时:0.00分/2.40分 | step: 50800 | performance: 24438.1 | accuracy: 0.45 | loss: 2.60
update:640/2000, 耗时:0.00分/2.41分 | step: 51200 | performance: 17137.7 | accuracy: 0.45 | loss: 3.93
update:645/2000, 耗时:0.00分/2.43分 | step: 51600 | performance: 37396.6 | accuracy: 0.45 | loss: 3.17
update:650/2000, 耗时:0.00分/2.45分 | step: 52000 | performance: 32676.7 | accuracy: 0.45 | loss: 4.24
update:655/2000, 耗时:0.00分/2.47分 | step: 52400 | performance: 33365.2 | accuracy: 0.45 | loss: 1.20
update:660/2000, 耗时:0.00分/2.48分 | step: 52800 | performance: 64183.1 | accuracy: 0.45 | loss: 5.33
update:665/2000, 耗时:0.00分/2.50分 | step: 53200 | performance: 125146.1 | accuracy: 0.45 | loss: 1.29
update:670/2000, 耗时:0.00分/2.52分 | step: 53600 | performance: 112953.4 | accuracy: 0.45 | loss: 2.47
update:675/2000, 耗时:0.00分/2.54分 | step: 54000 | performance: 32251.5 | accuracy: 0.45 | loss: 5.76
update:680/2000, 耗时:0.00分/2.56分 | step: 54400 | performance: 38893.4 | accuracy: 0.45 | loss: 1.82
update:685/2000, 耗时:0.00分/2.57分 | step: 54800 | performance: 157319.9 | accuracy: 0.45 | loss: 4.71
update:690/2000, 耗时:0.00分/2.59分 | step: 55200 | performance: 152398.1 | accuracy: 0.45 | loss: 0.93
update:695/2000, 耗时:0.00分/2.61分 | step: 55600 | performance: 1850800.4 | accuracy: 0.45 | loss: 3.16
update:700/2000, 耗时:0.00分/2.63分 | step: 56000 | performance: 720122.6 | accuracy: 0.45 | loss: 3.22
update:705/2000, 耗时:0.00分/2.64分 | step: 56400 | performance: 1081696.7 | accuracy: 0.45 | loss: 4.39
update:710/2000, 耗时:0.00分/2.66分 | step: 56800 | performance: 1457695.4 | accuracy: 0.45 | loss: 8.06
update:715/2000, 耗时:0.00分/2.68分 | step: 57200 | performance: 1812734.9 | accuracy: 0.45 | loss: 6.40
update:720/2000, 耗时:0.00分/2.70分 | step: 57600 | performance: 1108923.5 | accuracy: 0.45 | loss: 3.29
update:725/2000, 耗时:0.00分/2.71分 | step: 58000 | performance: 4359083.7 | accuracy: 0.45 | loss: 2.33
update:730/2000, 耗时:0.00分/2.73分 | step: 58400 | performance: 4604277.3 | accuracy: 0.45 | loss: 0.62
Saving PPO weights in both H5 format and checkpoint @ update:732 
update:735/2000, 耗时:0.00分/2.75分 | step: 58800 | performance: 2.5 | accuracy: 0.62 | loss: 7.26
update:740/2000, 耗时:0.00分/2.77分 | step: 59200 | performance: 9.9 | accuracy: 0.55 | loss: 7.34
update:745/2000, 耗时:0.00分/2.79分 | step: 59600 | performance: 2.8 | accuracy: 0.44 | loss: 4.05
update:750/2000, 耗时:0.00分/2.81分 | step: 60000 | performance: 18.4 | accuracy: 0.49 | loss: 6.59
update:755/2000, 耗时:0.00分/2.82分 | step: 60400 | performance: 5.8 | accuracy: 0.46 | loss: 2.40
update:760/2000, 耗时:0.00分/2.84分 | step: 60800 | performance: 7.5 | accuracy: 0.47 | loss: 0.99
update:765/2000, 耗时:0.00分/2.86分 | step: 61200 | performance: 31.3 | accuracy: 0.49 | loss: 4.70
update:770/2000, 耗时:0.00分/2.88分 | step: 61600 | performance: 32.5 | accuracy: 0.47 | loss: 2.40
update:775/2000, 耗时:0.00分/2.89分 | step: 62000 | performance: 18.9 | accuracy: 0.47 | loss: 6.99
update:780/2000, 耗时:0.00分/2.91分 | step: 62400 | performance: 21.3 | accuracy: 0.46 | loss: 5.05
update:785/2000, 耗时:0.00分/2.93分 | step: 62800 | performance: 15.6 | accuracy: 0.45 | loss: 3.51
update:790/2000, 耗时:0.00分/2.95分 | step: 63200 | performance: 14.6 | accuracy: 0.45 | loss: 2.76
update:795/2000, 耗时:0.00分/2.96分 | step: 63600 | performance: 18.2 | accuracy: 0.46 | loss: 1.50
update:800/2000, 耗时:0.00分/2.98分 | step: 64000 | performance: 565.5 | accuracy: 0.48 | loss: 13.73
update:805/2000, 耗时:0.00分/3.00分 | step: 64400 | performance: 351.3 | accuracy: 0.47 | loss: 0.97
update:810/2000, 耗时:0.00分/3.02分 | step: 64800 | performance: 508.8 | accuracy: 0.47 | loss: 1.19
update:815/2000, 耗时:0.00分/3.03分 | step: 65200 | performance: 295.4 | accuracy: 0.46 | loss: 6.19
update:820/2000, 耗时:0.00分/3.05分 | step: 65600 | performance: 363.4 | accuracy: 0.46 | loss: 4.09
update:825/2000, 耗时:0.00分/3.07分 | step: 66000 | performance: 196.5 | accuracy: 0.46 | loss: 2.29
update:830/2000, 耗时:0.00分/3.09分 | step: 66400 | performance: 272.1 | accuracy: 0.47 | loss: 1.98
update:835/2000, 耗时:0.00分/3.10分 | step: 66800 | performance: 1513.3 | accuracy: 0.48 | loss: 2.90
update:840/2000, 耗时:0.00分/3.12分 | step: 67200 | performance: 7274.3 | accuracy: 0.48 | loss: 10.94
update:845/2000, 耗时:0.00分/3.14分 | step: 67600 | performance: 3458.7 | accuracy: 0.48 | loss: 2.02
update:850/2000, 耗时:0.00分/3.16分 | step: 68000 | performance: 2053.4 | accuracy: 0.47 | loss: 2.26
update:855/2000, 耗时:0.00分/3.18分 | step: 68400 | performance: 1888.9 | accuracy: 0.47 | loss: 1.16
update:860/2000, 耗时:0.00分/3.19分 | step: 68800 | performance: 4691.9 | accuracy: 0.47 | loss: 2.24
update:865/2000, 耗时:0.00分/3.21分 | step: 69200 | performance: 2112.8 | accuracy: 0.47 | loss: 12.78
update:870/2000, 耗时:0.00分/3.23分 | step: 69600 | performance: 8378.3 | accuracy: 0.48 | loss: 8.17
update:875/2000, 耗时:0.00分/3.25分 | step: 70000 | performance: 12763.6 | accuracy: 0.48 | loss: 4.61
update:880/2000, 耗时:0.00分/3.27分 | step: 70400 | performance: 5047.2 | accuracy: 0.47 | loss: 1.42
update:885/2000, 耗时:0.00分/3.28分 | step: 70800 | performance: 2205.8 | accuracy: 0.46 | loss: 1.19
update:890/2000, 耗时:0.00分/3.30分 | step: 71200 | performance: 835.6 | accuracy: 0.46 | loss: 2.33
update:895/2000, 耗时:0.00分/3.32分 | step: 71600 | performance: 1275.0 | accuracy: 0.45 | loss: 1.88
update:900/2000, 耗时:0.00分/3.34分 | step: 72000 | performance: 1334.0 | accuracy: 0.45 | loss: 2.30
update:905/2000, 耗时:0.00分/3.35分 | step: 72400 | performance: 290.9 | accuracy: 0.45 | loss: 1.39
update:910/2000, 耗时:0.00分/3.37分 | step: 72800 | performance: 198.3 | accuracy: 0.44 | loss: 0.78
update:915/2000, 耗时:0.00分/3.39分 | step: 73200 | performance: 159.7 | accuracy: 0.44 | loss: 1.84
update:920/2000, 耗时:0.00分/3.41分 | step: 73600 | performance: 83.0 | accuracy: 0.44 | loss: 2.51
update:925/2000, 耗时:0.00分/3.42分 | step: 74000 | performance: 110.4 | accuracy: 0.44 | loss: 2.71
update:930/2000, 耗时:0.00分/3.44分 | step: 74400 | performance: 77.1 | accuracy: 0.44 | loss: 1.32
update:935/2000, 耗时:0.00分/3.46分 | step: 74800 | performance: 65.3 | accuracy: 0.44 | loss: 1.26
update:940/2000, 耗时:0.00分/3.48分 | step: 75200 | performance: 168.0 | accuracy: 0.44 | loss: 9.81
update:945/2000, 耗时:0.00分/3.50分 | step: 75600 | performance: 613.3 | accuracy: 0.44 | loss: 6.04
update:950/2000, 耗时:0.00分/3.51分 | step: 76000 | performance: 2868.1 | accuracy: 0.45 | loss: 6.91
update:955/2000, 耗时:0.00分/3.53分 | step: 76400 | performance: 14821.3 | accuracy: 0.45 | loss: 10.14
update:960/2000, 耗时:0.00分/3.55分 | step: 76800 | performance: 88667.7 | accuracy: 0.46 | loss: 3.58
update:965/2000, 耗时:0.00分/3.57分 | step: 77200 | performance: 172110.4 | accuracy: 0.46 | loss: 6.55
update:970/2000, 耗时:0.00分/3.58分 | step: 77600 | performance: 177735.2 | accuracy: 0.46 | loss: 1.54
update:975/2000, 耗时:0.00分/3.60分 | step: 78000 | performance: 160179.4 | accuracy: 0.46 | loss: 1.30
update:980/2000, 耗时:0.00分/3.62分 | step: 78400 | performance: 45560.8 | accuracy: 0.45 | loss: 0.74
update:985/2000, 耗时:0.00分/3.64分 | step: 78800 | performance: 25734.2 | accuracy: 0.45 | loss: 2.26
update:990/2000, 耗时:0.00分/3.65分 | step: 79200 | performance: 36590.1 | accuracy: 0.45 | loss: 2.03
update:995/2000, 耗时:0.00分/3.67分 | step: 79600 | performance: 13180.7 | accuracy: 0.44 | loss: 2.54
update:1000/2000, 耗时:0.00分/3.69分 | step: 80000 | performance: 11040.6 | accuracy: 0.44 | loss: 1.66
update:1005/2000, 耗时:0.00分/3.70分 | step: 80400 | performance: 10337.7 | accuracy: 0.44 | loss: 1.70
update:1010/2000, 耗时:0.00分/3.72分 | step: 80800 | performance: 71837.9 | accuracy: 0.45 | loss: 2.72
update:1015/2000, 耗时:0.00分/3.74分 | step: 81200 | performance: 59868.6 | accuracy: 0.45 | loss: 2.57
update:1020/2000, 耗时:0.00分/3.76分 | step: 81600 | performance: 31853.6 | accuracy: 0.44 | loss: 0.62
update:1025/2000, 耗时:0.00分/3.77分 | step: 82000 | performance: 32751.7 | accuracy: 0.44 | loss: 1.69
update:1030/2000, 耗时:0.00分/3.79分 | step: 82400 | performance: 67515.0 | accuracy: 0.44 | loss: 1.57
update:1035/2000, 耗时:0.00分/3.81分 | step: 82800 | performance: 75222.0 | accuracy: 0.44 | loss: 1.38
update:1040/2000, 耗时:0.00分/3.83分 | step: 83200 | performance: 42967.0 | accuracy: 0.43 | loss: 1.45
update:1045/2000, 耗时:0.00分/3.85分 | step: 83600 | performance: 28830.7 | accuracy: 0.43 | loss: 0.99
update:1050/2000, 耗时:0.00分/3.86分 | step: 84000 | performance: 82756.8 | accuracy: 0.43 | loss: 9.92
update:1055/2000, 耗时:0.00分/3.88分 | step: 84400 | performance: 99033.8 | accuracy: 0.43 | loss: 2.06
update:1060/2000, 耗时:0.00分/3.90分 | step: 84800 | performance: 664214.1 | accuracy: 0.43 | loss: 3.61
update:1065/2000, 耗时:0.00分/3.92分 | step: 85200 | performance: 398317.6 | accuracy: 0.43 | loss: 1.27
update:1070/2000, 耗时:0.00分/3.94分 | step: 85600 | performance: 516035.3 | accuracy: 0.43 | loss: 3.72
update:1075/2000, 耗时:0.00分/3.95分 | step: 86000 | performance: 778228.4 | accuracy: 0.43 | loss: 7.06
update:1080/2000, 耗时:0.00分/3.97分 | step: 86400 | performance: 1425643.2 | accuracy: 0.44 | loss: 3.33
update:1085/2000, 耗时:0.00分/3.99分 | step: 86800 | performance: 1280193.7 | accuracy: 0.44 | loss: 1.35
update:1090/2000, 耗时:0.00分/4.01分 | step: 87200 | performance: 3139190.8 | accuracy: 0.44 | loss: 1.97
update:1095/2000, 耗时:0.00分/4.03分 | step: 87600 | performance: 3011594.6 | accuracy: 0.43 | loss: 1.74
Saving PPO weights in both H5 format and checkpoint @ update:1098 
update:1100/2000, 耗时:0.00分/4.05分 | step: 88000 | performance: 0.4 | accuracy: 0.31 | loss: 3.59
update:1105/2000, 耗时:0.00分/4.07分 | step: 88400 | performance: 6.8 | accuracy: 0.50 | loss: 11.74
update:1110/2000, 耗时:0.00分/4.08分 | step: 88800 | performance: 0.9 | accuracy: 0.37 | loss: 8.00
update:1115/2000, 耗时:0.00分/4.10分 | step: 89200 | performance: 3.7 | accuracy: 0.42 | loss: 8.51
update:1120/2000, 耗时:0.00分/4.12分 | step: 89600 | performance: 2.5 | accuracy: 0.41 | loss: 5.49
update:1125/2000, 耗时:0.00分/4.14分 | step: 90000 | performance: 2.9 | accuracy: 0.42 | loss: 2.70
update:1130/2000, 耗时:0.00分/4.15分 | step: 90400 | performance: 5.8 | accuracy: 0.43 | loss: 6.18
update:1135/2000, 耗时:0.00分/4.17分 | step: 90800 | performance: 7.8 | accuracy: 0.43 | loss: 1.67
update:1140/2000, 耗时:0.00分/4.19分 | step: 91200 | performance: 2.8 | accuracy: 0.42 | loss: 1.41
update:1145/2000, 耗时:0.00分/4.21分 | step: 91600 | performance: 7.3 | accuracy: 0.43 | loss: 2.59
update:1150/2000, 耗时:0.00分/4.23分 | step: 92000 | performance: 7.6 | accuracy: 0.42 | loss: 1.23
update:1155/2000, 耗时:0.00分/4.24分 | step: 92400 | performance: 7.6 | accuracy: 0.42 | loss: 3.08
update:1160/2000, 耗时:0.00分/4.26分 | step: 92800 | performance: 8.0 | accuracy: 0.42 | loss: 3.30
update:1165/2000, 耗时:0.00分/4.28分 | step: 93200 | performance: 90.9 | accuracy: 0.44 | loss: 2.01
update:1170/2000, 耗时:0.00分/4.30分 | step: 93600 | performance: 120.4 | accuracy: 0.44 | loss: 2.67
update:1175/2000, 耗时:0.00分/4.32分 | step: 94000 | performance: 126.2 | accuracy: 0.44 | loss: 1.46
update:1180/2000, 耗时:0.00分/4.33分 | step: 94400 | performance: 124.6 | accuracy: 0.44 | loss: 1.58
update:1185/2000, 耗时:0.00分/4.35分 | step: 94800 | performance: 72.6 | accuracy: 0.43 | loss: 1.25
update:1190/2000, 耗时:0.00分/4.37分 | step: 95200 | performance: 45.8 | accuracy: 0.43 | loss: 1.95
update:1195/2000, 耗时:0.00分/4.38分 | step: 95600 | performance: 65.3 | accuracy: 0.44 | loss: 2.25
update:1200/2000, 耗时:0.00分/4.40分 | step: 96000 | performance: 573.5 | accuracy: 0.45 | loss: 7.70
update:1205/2000, 耗时:0.00分/4.42分 | step: 96400 | performance: 511.4 | accuracy: 0.45 | loss: 4.69
update:1210/2000, 耗时:0.00分/4.44分 | step: 96800 | performance: 574.9 | accuracy: 0.45 | loss: 7.58
update:1215/2000, 耗时:0.00分/4.45分 | step: 97200 | performance: 198.7 | accuracy: 0.44 | loss: 1.45
update:1220/2000, 耗时:0.00分/4.47分 | step: 97600 | performance: 123.2 | accuracy: 0.44 | loss: 4.79
update:1225/2000, 耗时:0.00分/4.49分 | step: 98000 | performance: 523.4 | accuracy: 0.45 | loss: 4.54
update:1230/2000, 耗时:0.00分/4.51分 | step: 98400 | performance: 714.4 | accuracy: 0.45 | loss: 1.66
update:1235/2000, 耗时:0.00分/4.53分 | step: 98800 | performance: 407.2 | accuracy: 0.45 | loss: 5.44
update:1240/2000, 耗时:0.00分/4.54分 | step: 99200 | performance: 843.0 | accuracy: 0.46 | loss: 3.53
update:1245/2000, 耗时:0.00分/4.56分 | step: 99600 | performance: 497.0 | accuracy: 0.45 | loss: 7.87
update:1250/2000, 耗时:0.00分/4.58分 | step: 100000 | performance: 228.3 | accuracy: 0.45 | loss: 2.36
update:1255/2000, 耗时:0.00分/4.60分 | step: 100400 | performance: 190.4 | accuracy: 0.45 | loss: 2.14
update:1260/2000, 耗时:0.00分/4.61分 | step: 100800 | performance: 761.6 | accuracy: 0.45 | loss: 6.59
update:1265/2000, 耗时:0.00分/4.63分 | step: 101200 | performance: 483.7 | accuracy: 0.45 | loss: 1.48
update:1270/2000, 耗时:0.00分/4.65分 | step: 101600 | performance: 85.7 | accuracy: 0.44 | loss: 2.21
update:1275/2000, 耗时:0.00分/4.67分 | step: 102000 | performance: 65.3 | accuracy: 0.44 | loss: 0.79
update:1280/2000, 耗时:0.00分/4.68分 | step: 102400 | performance: 45.6 | accuracy: 0.43 | loss: 0.87
update:1285/2000, 耗时:0.00分/4.70分 | step: 102800 | performance: 41.1 | accuracy: 0.43 | loss: 2.05
update:1290/2000, 耗时:0.00分/4.72分 | step: 103200 | performance: 45.6 | accuracy: 0.44 | loss: 2.70
update:1295/2000, 耗时:0.00分/4.74分 | step: 103600 | performance: 15.9 | accuracy: 0.43 | loss: 0.99
update:1300/2000, 耗时:0.00分/4.75分 | step: 104000 | performance: 14.5 | accuracy: 0.43 | loss: 0.75
update:1305/2000, 耗时:0.00分/4.77分 | step: 104400 | performance: 34.0 | accuracy: 0.44 | loss: 1.85
update:1310/2000, 耗时:0.00分/4.79分 | step: 104800 | performance: 103.5 | accuracy: 0.44 | loss: 5.88
update:1315/2000, 耗时:0.00分/4.81分 | step: 105200 | performance: 524.1 | accuracy: 0.45 | loss: 1.41
update:1320/2000, 耗时:0.00分/4.82分 | step: 105600 | performance: 7902.3 | accuracy: 0.45 | loss: 2.76
update:1325/2000, 耗时:0.00分/4.84分 | step: 106000 | performance: 18453.5 | accuracy: 0.46 | loss: 12.16
update:1330/2000, 耗时:0.00分/4.86分 | step: 106400 | performance: 29204.3 | accuracy: 0.46 | loss: 1.25
update:1335/2000, 耗时:0.00分/4.88分 | step: 106800 | performance: 55023.5 | accuracy: 0.46 | loss: 5.69
update:1340/2000, 耗时:0.00分/4.89分 | step: 107200 | performance: 26286.8 | accuracy: 0.46 | loss: 3.25
update:1345/2000, 耗时:0.00分/4.91分 | step: 107600 | performance: 17739.2 | accuracy: 0.46 | loss: 2.15
update:1350/2000, 耗时:0.00分/4.93分 | step: 108000 | performance: 13913.3 | accuracy: 0.46 | loss: 1.79
update:1355/2000, 耗时:0.00分/4.95分 | step: 108400 | performance: 18663.5 | accuracy: 0.46 | loss: 1.56
update:1360/2000, 耗时:0.00分/4.96分 | step: 108800 | performance: 15519.6 | accuracy: 0.45 | loss: 0.89
update:1365/2000, 耗时:0.00分/4.98分 | step: 109200 | performance: 14943.5 | accuracy: 0.45 | loss: 1.01
update:1370/2000, 耗时:0.00分/5.00分 | step: 109600 | performance: 8059.4 | accuracy: 0.45 | loss: 5.89
update:1375/2000, 耗时:0.00分/5.02分 | step: 110000 | performance: 55764.0 | accuracy: 0.46 | loss: 6.86
update:1380/2000, 耗时:0.00分/5.03分 | step: 110400 | performance: 66293.5 | accuracy: 0.46 | loss: 3.86
update:1385/2000, 耗时:0.00分/5.05分 | step: 110800 | performance: 16586.5 | accuracy: 0.45 | loss: 2.63
update:1390/2000, 耗时:0.00分/5.07分 | step: 111200 | performance: 12205.1 | accuracy: 0.45 | loss: 0.78
update:1395/2000, 耗时:0.00分/5.09分 | step: 111600 | performance: 26214.3 | accuracy: 0.45 | loss: 3.07
update:1400/2000, 耗时:0.00分/5.10分 | step: 112000 | performance: 15247.8 | accuracy: 0.45 | loss: 1.75
update:1405/2000, 耗时:0.00分/5.12分 | step: 112400 | performance: 11695.6 | accuracy: 0.44 | loss: 0.67
update:1410/2000, 耗时:0.00分/5.14分 | step: 112800 | performance: 7640.7 | accuracy: 0.44 | loss: 1.44
update:1415/2000, 耗时:0.00分/5.15分 | step: 113200 | performance: 9613.1 | accuracy: 0.44 | loss: 1.69
update:1420/2000, 耗时:0.00分/5.17分 | step: 113600 | performance: 18947.0 | accuracy: 0.44 | loss: 4.99
update:1425/2000, 耗时:0.00分/5.19分 | step: 114000 | performance: 76466.2 | accuracy: 0.44 | loss: 2.89
update:1430/2000, 耗时:0.00分/5.21分 | step: 114400 | performance: 48120.5 | accuracy: 0.44 | loss: 7.25
update:1435/2000, 耗时:0.00分/5.22分 | step: 114800 | performance: 23876.2 | accuracy: 0.43 | loss: 1.52
update:1440/2000, 耗时:0.00分/5.24分 | step: 115200 | performance: 63399.9 | accuracy: 0.44 | loss: 1.64
update:1445/2000, 耗时:0.00分/5.26分 | step: 115600 | performance: 65915.6 | accuracy: 0.44 | loss: 1.05
update:1450/2000, 耗时:0.00分/5.27分 | step: 116000 | performance: 46670.1 | accuracy: 0.44 | loss: 5.45
update:1455/2000, 耗时:0.00分/5.29分 | step: 116400 | performance: 121210.8 | accuracy: 0.44 | loss: 1.03
update:1460/2000, 耗时:0.00分/5.31分 | step: 116800 | performance: 89144.0 | accuracy: 0.43 | loss: 1.39
Saving PPO weights in both H5 format and checkpoint @ update:1464 
update:1465/2000, 耗时:0.00分/5.33分 | step: 117200 | performance: 0.7 | accuracy: 0.33 | loss: 2.67
update:1470/2000, 耗时:0.00分/5.35分 | step: 117600 | performance: 1.6 | accuracy: 0.43 | loss: 3.45
update:1475/2000, 耗时:0.00分/5.37分 | step: 118000 | performance: 0.6 | accuracy: 0.36 | loss: 1.65
update:1480/2000, 耗时:0.00分/5.38分 | step: 118400 | performance: 0.7 | accuracy: 0.33 | loss: 1.77
update:1485/2000, 耗时:0.00分/5.40分 | step: 118800 | performance: 0.8 | accuracy: 0.35 | loss: 0.40
update:1490/2000, 耗时:0.00分/5.42分 | step: 119200 | performance: 0.7 | accuracy: 0.32 | loss: 1.22
update:1495/2000, 耗时:0.00分/5.43分 | step: 119600 | performance: 1.3 | accuracy: 0.36 | loss: 0.83
update:1500/2000, 耗时:0.00分/5.45分 | step: 120000 | performance: 2.2 | accuracy: 0.36 | loss: 4.52
update:1505/2000, 耗时:0.00分/5.47分 | step: 120400 | performance: 1.2 | accuracy: 0.34 | loss: 0.65
update:1510/2000, 耗时:0.00分/5.49分 | step: 120800 | performance: 2.7 | accuracy: 0.35 | loss: 0.54
update:1515/2000, 耗时:0.00分/5.50分 | step: 121200 | performance: 2.9 | accuracy: 0.34 | loss: 1.44
update:1520/2000, 耗时:0.00分/5.52分 | step: 121600 | performance: 3.1 | accuracy: 0.33 | loss: 1.76
update:1525/2000, 耗时:0.00分/5.54分 | step: 122000 | performance: 3.0 | accuracy: 0.32 | loss: 4.10
update:1530/2000, 耗时:0.00分/5.56分 | step: 122400 | performance: 11.5 | accuracy: 0.33 | loss: 0.95
update:1535/2000, 耗时:0.00分/5.58分 | step: 122800 | performance: 7.6 | accuracy: 0.33 | loss: 1.18
update:1540/2000, 耗时:0.00分/5.59分 | step: 123200 | performance: 8.4 | accuracy: 0.33 | loss: 0.50
update:1545/2000, 耗时:0.00分/5.61分 | step: 123600 | performance: 7.8 | accuracy: 0.33 | loss: 2.01
update:1550/2000, 耗时:0.00分/5.63分 | step: 124000 | performance: 7.6 | accuracy: 0.33 | loss: 2.42
update:1555/2000, 耗时:0.00分/5.65分 | step: 124400 | performance: 3.5 | accuracy: 0.32 | loss: 4.11
update:1560/2000, 耗时:0.00分/5.66分 | step: 124800 | performance: 4.6 | accuracy: 0.34 | loss: 3.35
update:1565/2000, 耗时:0.00分/5.68分 | step: 125200 | performance: 29.7 | accuracy: 0.36 | loss: 1.51
update:1570/2000, 耗时:0.00分/5.70分 | step: 125600 | performance: 51.7 | accuracy: 0.37 | loss: 5.12
update:1575/2000, 耗时:0.00分/5.72分 | step: 126000 | performance: 163.2 | accuracy: 0.38 | loss: 5.17
update:1580/2000, 耗时:0.00分/5.73分 | step: 126400 | performance: 87.0 | accuracy: 0.38 | loss: 2.03
update:1585/2000, 耗时:0.00分/5.75分 | step: 126800 | performance: 88.9 | accuracy: 0.38 | loss: 0.65
update:1590/2000, 耗时:0.00分/5.77分 | step: 127200 | performance: 191.4 | accuracy: 0.38 | loss: 5.20
update:1595/2000, 耗时:0.00分/5.79分 | step: 127600 | performance: 226.2 | accuracy: 0.38 | loss: 1.08
update:1600/2000, 耗时:0.00分/5.81分 | step: 128000 | performance: 192.8 | accuracy: 0.38 | loss: 2.14
update:1605/2000, 耗时:0.00分/5.83分 | step: 128400 | performance: 380.8 | accuracy: 0.38 | loss: 1.72
update:1610/2000, 耗时:0.00分/5.85分 | step: 128800 | performance: 463.9 | accuracy: 0.38 | loss: 1.05
update:1615/2000, 耗时:0.00分/5.87分 | step: 129200 | performance: 142.5 | accuracy: 0.37 | loss: 2.51
update:1620/2000, 耗时:0.00分/5.89分 | step: 129600 | performance: 150.8 | accuracy: 0.38 | loss: 1.38
update:1625/2000, 耗时:0.00分/5.90分 | step: 130000 | performance: 439.5 | accuracy: 0.38 | loss: 0.80
update:1630/2000, 耗时:0.00分/5.92分 | step: 130400 | performance: 284.0 | accuracy: 0.37 | loss: 2.31
update:1635/2000, 耗时:0.00分/5.94分 | step: 130800 | performance: 126.3 | accuracy: 0.36 | loss: 1.04
update:1640/2000, 耗时:0.00分/5.96分 | step: 131200 | performance: 57.9 | accuracy: 0.36 | loss: 1.18
update:1645/2000, 耗时:0.00分/5.98分 | step: 131600 | performance: 58.2 | accuracy: 0.36 | loss: 1.57
update:1650/2000, 耗时:0.00分/6.00分 | step: 132000 | performance: 50.5 | accuracy: 0.36 | loss: 0.43
update:1655/2000, 耗时:0.00分/6.02分 | step: 132400 | performance: 90.7 | accuracy: 0.36 | loss: 2.90
update:1660/2000, 耗时:0.00分/6.04分 | step: 132800 | performance: 47.6 | accuracy: 0.36 | loss: 0.96
update:1665/2000, 耗时:0.00分/6.06分 | step: 133200 | performance: 42.4 | accuracy: 0.36 | loss: 0.62
update:1670/2000, 耗时:0.00分/6.07分 | step: 133600 | performance: 64.8 | accuracy: 0.36 | loss: 1.20
update:1675/2000, 耗时:0.00分/6.09分 | step: 134000 | performance: 356.9 | accuracy: 0.37 | loss: 3.14
update:1680/2000, 耗时:0.00分/6.11分 | step: 134400 | performance: 1163.4 | accuracy: 0.37 | loss: 9.52
update:1685/2000, 耗时:0.00分/6.13分 | step: 134800 | performance: 11377.7 | accuracy: 0.38 | loss: 12.00
update:1690/2000, 耗时:0.00分/6.15分 | step: 135200 | performance: 20323.1 | accuracy: 0.39 | loss: 7.17
update:1695/2000, 耗时:0.00分/6.17分 | step: 135600 | performance: 78982.6 | accuracy: 0.39 | loss: 2.57
update:1700/2000, 耗时:0.00分/6.19分 | step: 136000 | performance: 123149.6 | accuracy: 0.40 | loss: 2.11
update:1705/2000, 耗时:0.00分/6.21分 | step: 136400 | performance: 76339.8 | accuracy: 0.40 | loss: 6.50
update:1710/2000, 耗时:0.00分/6.22分 | step: 136800 | performance: 43998.9 | accuracy: 0.39 | loss: 1.61
update:1715/2000, 耗时:0.00分/6.24分 | step: 137200 | performance: 49329.5 | accuracy: 0.39 | loss: 0.68
update:1720/2000, 耗时:0.00分/6.26分 | step: 137600 | performance: 45827.0 | accuracy: 0.38 | loss: 0.37
update:1725/2000, 耗时:0.00分/6.28分 | step: 138000 | performance: 49866.7 | accuracy: 0.38 | loss: 0.59
update:1730/2000, 耗时:0.00分/6.30分 | step: 138400 | performance: 37492.1 | accuracy: 0.37 | loss: 2.42
update:1735/2000, 耗时:0.00分/6.31分 | step: 138800 | performance: 28677.3 | accuracy: 0.38 | loss: 2.77
update:1740/2000, 耗时:0.00分/6.33分 | step: 139200 | performance: 66520.0 | accuracy: 0.38 | loss: 2.69
update:1745/2000, 耗时:0.00分/6.35分 | step: 139600 | performance: 125953.0 | accuracy: 0.38 | loss: 3.02
update:1750/2000, 耗时:0.00分/6.37分 | step: 140000 | performance: 48661.8 | accuracy: 0.38 | loss: 2.00
update:1755/2000, 耗时:0.00分/6.39分 | step: 140400 | performance: 43015.5 | accuracy: 0.37 | loss: 0.22
update:1760/2000, 耗时:0.00分/6.41分 | step: 140800 | performance: 36153.1 | accuracy: 0.37 | loss: 1.44
update:1765/2000, 耗时:0.00分/6.42分 | step: 141200 | performance: 32129.5 | accuracy: 0.36 | loss: 0.11
update:1770/2000, 耗时:0.00分/6.44分 | step: 141600 | performance: 33451.3 | accuracy: 0.36 | loss: 0.11
update:1775/2000, 耗时:0.00分/6.46分 | step: 142000 | performance: 33152.8 | accuracy: 0.35 | loss: 0.58
update:1780/2000, 耗时:0.00分/6.48分 | step: 142400 | performance: 27336.3 | accuracy: 0.35 | loss: 0.21
update:1785/2000, 耗时:0.00分/6.50分 | step: 142800 | performance: 43505.4 | accuracy: 0.35 | loss: 0.66
update:1790/2000, 耗时:0.00分/6.51分 | step: 143200 | performance: 59378.9 | accuracy: 0.34 | loss: 0.27
update:1795/2000, 耗时:0.00分/6.53分 | step: 143600 | performance: 64180.4 | accuracy: 0.34 | loss: 0.18
update:1800/2000, 耗时:0.00分/6.55分 | step: 144000 | performance: 51944.6 | accuracy: 0.34 | loss: 0.45
update:1805/2000, 耗时:0.00分/6.57分 | step: 144400 | performance: 66265.8 | accuracy: 0.34 | loss: 0.83
update:1810/2000, 耗时:0.00分/6.59分 | step: 144800 | performance: 113907.1 | accuracy: 0.34 | loss: 0.75
update:1815/2000, 耗时:0.00分/6.61分 | step: 145200 | performance: 117245.9 | accuracy: 0.34 | loss: 1.62
update:1820/2000, 耗时:0.00分/6.62分 | step: 145600 | performance: 192648.2 | accuracy: 0.33 | loss: 0.33
update:1825/2000, 耗时:0.00分/6.64分 | step: 146000 | performance: 193859.9 | accuracy: 0.33 | loss: 0.33
step: 146313 | worker_0@n_step_9: average total_reward after train data exhaustion : 227.4 | max total_reward: 366.4
step: 146314 | worker_1@n_step_9: average total_reward after train data exhaustion : 227.9 | max total_reward: 366.4
step: 146315 | worker_2@n_step_9: average total_reward after train data exhaustion : 227.4 | max total_reward: 366.4
step: 146316 | worker_3@n_step_9: average total_reward after train data exhaustion : 229.9 | max total_reward: 366.4
step: 146317 | worker_4@n_step_9: average total_reward after train data exhaustion : 230.6 | max total_reward: 366.4
step: 146318 | worker_5@n_step_9: average total_reward after train data exhaustion : 230.1 | max total_reward: 366.4
step: 146319 | worker_6@n_step_9: average total_reward after train data exhaustion : 230.5 | max total_reward: 366.4
step: 146320 | worker_7@n_step_9: average total_reward after train data exhaustion : 231.1 | max total_reward: 366.4
Saving PPO weights in both H5 format and checkpoint @ update:1829 
update:1830/2000, 耗时:0.00分/6.67分 | step: 146400 | performance: 0.7 | accuracy: 0.20 | loss: 3.26
update:1835/2000, 耗时:0.00分/6.68分 | step: 146800 | performance: 2.2 | accuracy: 0.35 | loss: 3.10
update:1840/2000, 耗时:0.00分/6.70分 | step: 147200 | performance: 3.0 | accuracy: 0.31 | loss: 1.66
update:1845/2000, 耗时:0.00分/6.72分 | step: 147600 | performance: 4.6 | accuracy: 0.31 | loss: 1.91
update:1850/2000, 耗时:0.00分/6.74分 | step: 148000 | performance: 6.4 | accuracy: 0.30 | loss: 3.65
update:1855/2000, 耗时:0.00分/6.76分 | step: 148400 | performance: 4.6 | accuracy: 0.26 | loss: 0.70
update:1860/2000, 耗时:0.00分/6.78分 | step: 148800 | performance: 6.5 | accuracy: 0.26 | loss: 0.81
update:1865/2000, 耗时:0.00分/6.80分 | step: 149200 | performance: 16.2 | accuracy: 0.29 | loss: 0.64
update:1870/2000, 耗时:0.00分/6.82分 | step: 149600 | performance: 5.8 | accuracy: 0.27 | loss: 1.06
update:1875/2000, 耗时:0.00分/6.84分 | step: 150000 | performance: 12.0 | accuracy: 0.27 | loss: 1.07
update:1880/2000, 耗时:0.00分/6.86分 | step: 150400 | performance: 12.0 | accuracy: 0.26 | loss: 1.04
update:1885/2000, 耗时:0.00分/6.88分 | step: 150800 | performance: 10.3 | accuracy: 0.26 | loss: 0.69
update:1890/2000, 耗时:0.00分/6.90分 | step: 151200 | performance: 8.2 | accuracy: 0.24 | loss: 0.35
update:1895/2000, 耗时:0.00分/6.92分 | step: 151600 | performance: 35.5 | accuracy: 0.25 | loss: 1.95
update:1900/2000, 耗时:0.00分/6.94分 | step: 152000 | performance: 49.7 | accuracy: 0.27 | loss: 8.34
update:1905/2000, 耗时:0.00分/6.96分 | step: 152400 | performance: 48.9 | accuracy: 0.26 | loss: 1.39
update:1910/2000, 耗时:0.00分/6.98分 | step: 152800 | performance: 55.2 | accuracy: 0.27 | loss: 1.37
update:1915/2000, 耗时:0.00分/7.00分 | step: 153200 | performance: 48.1 | accuracy: 0.26 | loss: 0.86
update:1920/2000, 耗时:0.00分/7.02分 | step: 153600 | performance: 38.8 | accuracy: 0.26 | loss: 2.66
update:1925/2000, 耗时:0.00分/7.04分 | step: 154000 | performance: 63.4 | accuracy: 0.28 | loss: 2.79
update:1930/2000, 耗时:0.00分/7.06分 | step: 154400 | performance: 429.8 | accuracy: 0.30 | loss: 2.36
update:1935/2000, 耗时:0.00分/7.08分 | step: 154800 | performance: 469.3 | accuracy: 0.31 | loss: 2.01
update:1940/2000, 耗时:0.00分/7.10分 | step: 155200 | performance: 2461.5 | accuracy: 0.32 | loss: 2.34
update:1945/2000, 耗时:0.00分/7.12分 | step: 155600 | performance: 558.4 | accuracy: 0.32 | loss: 1.81
update:1950/2000, 耗时:0.00分/7.14分 | step: 156000 | performance: 711.3 | accuracy: 0.32 | loss: 0.55
update:1955/2000, 耗时:0.00分/7.16分 | step: 156400 | performance: 607.3 | accuracy: 0.32 | loss: 0.88
update:1960/2000, 耗时:0.00分/7.18分 | step: 156800 | performance: 676.7 | accuracy: 0.31 | loss: 1.41
update:1965/2000, 耗时:0.00分/7.20分 | step: 157200 | performance: 511.2 | accuracy: 0.31 | loss: 1.01
update:1970/2000, 耗时:0.00分/7.22分 | step: 157600 | performance: 1042.0 | accuracy: 0.31 | loss: 1.40
update:1975/2000, 耗时:0.00分/7.24分 | step: 158000 | performance: 1231.7 | accuracy: 0.32 | loss: 1.24
update:1980/2000, 耗时:0.00分/7.26分 | step: 158400 | performance: 722.3 | accuracy: 0.32 | loss: 1.42
update:1985/2000, 耗时:0.00分/7.28分 | step: 158800 | performance: 638.1 | accuracy: 0.32 | loss: 3.40
update:1990/2000, 耗时:0.00分/7.30分 | step: 159200 | performance: 4254.9 | accuracy: 0.32 | loss: 10.18
update:1995/2000, 耗时:0.00分/7.32分 | step: 159600 | performance: 1465.3 | accuracy: 0.31 | loss: 1.85
update:2000/2000, 耗时:0.00分/7.34分 | step: 160000 | performance: 1382.3 | accuracy: 0.31 | loss: 0.57
----------------------------------------finished----------------------------------------
==================================================
2023-01-05T12:00:00 | *** START BACKTEST ***
2023-01-05T12:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/401 [00:00<?, ?it/s]100%|| 401/401 [00:00<00:00, 100436.87it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1282.50
2023-07-24T12:00:00 | net performance [%] = 28.2496
2023-07-24T12:00:00 | number of trades [#] = 54
==================================================
Trial 53 Complete [00h 07m 47s]
net_wealth: 1283.7801974975753

Best net_wealth So Far: 1824.8039564105297
Total elapsed time: 07h 23m 39s

Search: Running Trial #54

Value             |Best Value So Far |Hyperparameter
5                 |6                 |horizon
225               |365               |lookback
False             |True              |MarketFactor
5                 |10                |lags
0.9               |0.98              |gamma
32                |16                |batch_size
10                |7                 |n_step
0.9               |0.94              |gae_lambda
0.2               |0.5               |gradient_clip_norm
5                 |3                 |epochs
0.0001            |0.001             |actor_lr
1e-05             |0.001             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4310.000000   4315.000000
mean      0.000441    20062.255222  ...   20136.939364  20118.633889
std       0.027818    16039.874230  ...   16077.430342  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7696.969971   7690.540039
50%       0.000642    11554.824463  ...   11742.710449  11715.610352
75%       0.011655    29873.081836  ...   29945.211914  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 05:27:02.654577: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) 22023-07-28 05:27:02.654660: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in per202formance-crit3t-007o use-22 th38 -05e07-28 05:272:02:27:0 f2..0oll6654254752: I ten3651: I ten-ssorfl0icaol orflow/core7/-polpeawing CPUt2froorm8 05:27/w/ instructications:  AVpcuoro_feena/stX in plA peVure_Xa2tr:02.6f
guarT5o ormae481nd2.ce-criticanccl of2o0:2rm:pearab/104t2iloec2 3 npsu_tI:  t AfVe-nso0]Xr 7AV -fXT2l8 0o2hw5/:c
is 2o3re/-TTe2nso0o 7r:Fl2e702-2e8anapt.huow rlb 6055129:0523-07 ien_gaatr-Iufy 2oa rte8m/rnso rcdf0p.l5u:_f27c:0eaowc/etm:uc 1in ob42t.her6elro:re_eg5522 2 7ou]thae/3pr pemrd.Tchi:sis T   eIn7oap cl::s0orFl21iat.fo4ttiirm26/mi]oze cThdns,tpu_fi  rn otsh er opTeneonww bsionraerrey5s 5ia1bit3fions,th6 oorFluo reneAwPI/ c:laDtiuoreelodebpu N  eurIawi lTl e snsorFebl N/eptidloaton afoprmtwiTwrm/izceor pynewui sko _tfh dtrLibrise tree_gF loaautarwrhoewn a dyp si.urpwcc:1tporoer_p4ithg2t]h  T hisouna imirritzeedAP(adtIT eD ehneseoprwofFlow bl.oei nie cc:14DaNpen t2NN]prawh/ ory p)r  isTthoccooiaroneAe iP/spu Iompptilteeu is eT rm iDcern sofaeorlFal eNzleolpe tdgmswNte hwp iureabtinair tfhoawyf lo.rloliosweir
m /r okopti ngcpu_f lCPUmfiez  liagL iNbraneaterdystwst.u
rr  ork Leuwit_c(onhibrary (neAeotni oegoPDnDnsNNu iIn DNaNrd.ec eAe)p et) too pcu:s Pr1use Ifoet D 4N2eural Networrem] This Takhep Neueennc esorFlow binary is optimized with oneAPI D the following CPU instructions in performance-critical operat -critical Library (oneDNN) to use the following CPU instructions in performfions:  AVX AVX2
To enable them in otheoance-ollowing CPUr opereap Neural Network Library ( instruceratiocpoerrlinnesDt NNaions in perf)t, otiNrier mtcbauaonentswork Lo use the following CPU instru:ce-critical operations:   iAicVX A AVlVdX 2Tber
nXstl  ioonAoperations:  AVX AVX2
ToVX2To enable th enable
To enabeamlsrFlow  them r eiyn  witihin (ot ther onopn  eohte teDrNathemperformaN hnc)apper  reit-oc ous inrs, rebuiiletdicna oTpl  then oroiopesorrFatltaeop efw with trations,hiheer ollowing  orotnC PappropriatebuilUes compiler flags.
:  AdVpXe  TensorFlow with there i nasAVXaptions, rebui2 lcompilepdrt
rop rT Tenuocsr eonabifrlFtallow wioaithtnees ing  t st.
per hhfcoree ommancappe-cmi lriperiortpi rfncaiate compilerl  otlo hefparglagesr.
s.
 operations, rebuild TensorFlow with the appropriate compiler flags.
ations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 05:27:03.269214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:27:03.287356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:27:03.304031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:27:03.304439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:27:03.311033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:27:03.312602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:27:03.317959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:27:03.319707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
Saving PPO weights in both H5 format and checkpoint @ update:2 
update:  5/2000, 耗时:0.00分/0.04分 | step:   400 | performance: 1.0 | accuracy: 0.24 | loss: 1.49
update: 10/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 3.0 | accuracy: 0.31 | loss: 4.00
update: 15/2000, 耗时:0.00分/0.07分 | step:  1200 | performance: 6.9 | accuracy: 0.37 | loss: 1.08
update: 20/2000, 耗时:0.00分/0.08分 | step:  1600 | performance: 1.4 | accuracy: 0.34 | loss: 4.48
update: 25/2000, 耗时:0.00分/0.10分 | step:  2000 | performance: 1.4 | accuracy: 0.34 | loss: 2.20
update: 30/2000, 耗时:0.00分/0.11分 | step:  2400 | performance: 2.0 | accuracy: 0.36 | loss: 1.33
update: 35/2000, 耗时:0.00分/0.13分 | step:  2800 | performance: 1.7 | accuracy: 0.35 | loss: 1.63
update: 40/2000, 耗时:0.00分/0.15分 | step:  3200 | performance: 2.2 | accuracy: 0.35 | loss: 2.66
update: 45/2000, 耗时:0.00分/0.17分 | step:  3600 | performance: 2.4 | accuracy: 0.36 | loss: 1.66
update: 50/2000, 耗时:0.00分/0.18分 | step:  4000 | performance: 3.1 | accuracy: 0.37 | loss: 1.80
update: 55/2000, 耗时:0.00分/0.20分 | step:  4400 | performance: 3.6 | accuracy: 0.37 | loss: 1.31
update: 60/2000, 耗时:0.00分/0.22分 | step:  4800 | performance: 3.4 | accuracy: 0.36 | loss: 1.99
update: 65/2000, 耗时:0.00分/0.24分 | step:  5200 | performance: 3.7 | accuracy: 0.37 | loss: 0.72
update: 70/2000, 耗时:0.00分/0.25分 | step:  5600 | performance: 1.0 | accuracy: 0.35 | loss: 5.48
update: 75/2000, 耗时:0.00分/0.27分 | step:  6000 | performance: 0.9 | accuracy: 0.35 | loss: 2.20
update: 80/2000, 耗时:0.00分/0.29分 | step:  6400 | performance: 0.6 | accuracy: 0.35 | loss: 1.20
update: 85/2000, 耗时:0.00分/0.31分 | step:  6800 | performance: 0.5 | accuracy: 0.35 | loss: 1.51
update: 90/2000, 耗时:0.00分/0.33分 | step:  7200 | performance: 0.4 | accuracy: 0.35 | loss: 1.49
update: 95/2000, 耗时:0.00分/0.35分 | step:  7600 | performance: 0.1 | accuracy: 0.35 | loss: 1.09
update:100/2000, 耗时:0.00分/0.36分 | step:  8000 | performance: 0.1 | accuracy: 0.33 | loss: 1.45
update:105/2000, 耗时:0.00分/0.38分 | step:  8400 | performance: 0.1 | accuracy: 0.32 | loss: 0.57
update:110/2000, 耗时:0.00分/0.40分 | step:  8800 | performance: 0.1 | accuracy: 0.32 | loss: 0.72
update:115/2000, 耗时:0.00分/0.42分 | step:  9200 | performance: 0.1 | accuracy: 0.30 | loss: 0.53
update:120/2000, 耗时:0.00分/0.44分 | step:  9600 | performance: 0.1 | accuracy: 0.30 | loss: 0.95
update:125/2000, 耗时:0.00分/0.46分 | step: 10000 | performance: 0.0 | accuracy: 0.30 | loss: 1.89
update:130/2000, 耗时:0.00分/0.47分 | step: 10400 | performance: 0.1 | accuracy: 0.30 | loss: 2.34
update:135/2000, 耗时:0.00分/0.49分 | step: 10800 | performance: 0.2 | accuracy: 0.31 | loss: 3.86
update:140/2000, 耗时:0.00分/0.51分 | step: 11200 | performance: 0.2 | accuracy: 0.31 | loss: 1.28
update:145/2000, 耗时:0.00分/0.53分 | step: 11600 | performance: 0.3 | accuracy: 0.32 | loss: 1.53
update:150/2000, 耗时:0.00分/0.55分 | step: 12000 | performance: 0.3 | accuracy: 0.32 | loss: 1.94
update:155/2000, 耗时:0.00分/0.57分 | step: 12400 | performance: 0.3 | accuracy: 0.32 | loss: 0.86
update:160/2000, 耗时:0.00分/0.58分 | step: 12800 | performance: 0.3 | accuracy: 0.31 | loss: 0.38
update:165/2000, 耗时:0.00分/0.60分 | step: 13200 | performance: 0.9 | accuracy: 0.31 | loss: 3.17
update:170/2000, 耗时:0.00分/0.62分 | step: 13600 | performance: 0.6 | accuracy: 0.31 | loss: 2.47
update:175/2000, 耗时:0.00分/0.64分 | step: 14000 | performance: 1.0 | accuracy: 0.31 | loss: 0.61
update:180/2000, 耗时:0.00分/0.66分 | step: 14400 | performance: 1.1 | accuracy: 0.31 | loss: 0.43
update:185/2000, 耗时:0.00分/0.68分 | step: 14800 | performance: 1.3 | accuracy: 0.31 | loss: 0.60
update:190/2000, 耗时:0.00分/0.69分 | step: 15200 | performance: 1.0 | accuracy: 0.30 | loss: 1.30
update:195/2000, 耗时:0.00分/0.71分 | step: 15600 | performance: 1.1 | accuracy: 0.30 | loss: 0.10
update:200/2000, 耗时:0.00分/0.73分 | step: 16000 | performance: 1.2 | accuracy: 0.29 | loss: 0.93
update:205/2000, 耗时:0.00分/0.75分 | step: 16400 | performance: 1.4 | accuracy: 0.29 | loss: 0.58
update:210/2000, 耗时:0.00分/0.77分 | step: 16800 | performance: 1.3 | accuracy: 0.29 | loss: 0.16
update:215/2000, 耗时:0.00分/0.79分 | step: 17200 | performance: 1.2 | accuracy: 0.28 | loss: 0.19
update:220/2000, 耗时:0.00分/0.81分 | step: 17600 | performance: 1.4 | accuracy: 0.28 | loss: 0.23
update:225/2000, 耗时:0.00分/0.82分 | step: 18000 | performance: 1.8 | accuracy: 0.27 | loss: 0.41
update:230/2000, 耗时:0.00分/0.84分 | step: 18400 | performance: 2.5 | accuracy: 0.27 | loss: 0.93
update:235/2000, 耗时:0.00分/0.86分 | step: 18800 | performance: 3.2 | accuracy: 0.27 | loss: 0.90
update:240/2000, 耗时:0.00分/0.88分 | step: 19200 | performance: 3.1 | accuracy: 0.26 | loss: 0.35
update:245/2000, 耗时:0.00分/0.90分 | step: 19600 | performance: 2.5 | accuracy: 0.26 | loss: 0.49
update:250/2000, 耗时:0.00分/0.92分 | step: 20000 | performance: 3.6 | accuracy: 0.26 | loss: 1.58
update:255/2000, 耗时:0.00分/0.93分 | step: 20400 | performance: 3.9 | accuracy: 0.26 | loss: 2.54
update:260/2000, 耗时:0.00分/0.95分 | step: 20800 | performance: 1.3 | accuracy: 0.27 | loss: 1.42
update:265/2000, 耗时:0.00分/0.97分 | step: 21200 | performance: 2.7 | accuracy: 0.27 | loss: 1.98
update:270/2000, 耗时:0.00分/0.99分 | step: 21600 | performance: 2.9 | accuracy: 0.27 | loss: 0.63
update:275/2000, 耗时:0.00分/1.01分 | step: 22000 | performance: 3.3 | accuracy: 0.27 | loss: 0.70
update:280/2000, 耗时:0.00分/1.03分 | step: 22400 | performance: 5.3 | accuracy: 0.27 | loss: 0.29
update:285/2000, 耗时:0.00分/1.04分 | step: 22800 | performance: 5.0 | accuracy: 0.26 | loss: 0.18
update:290/2000, 耗时:0.00分/1.06分 | step: 23200 | performance: 2.3 | accuracy: 0.26 | loss: 2.26
update:295/2000, 耗时:0.00分/1.08分 | step: 23600 | performance: 2.0 | accuracy: 0.26 | loss: 0.68
update:300/2000, 耗时:0.00分/1.10分 | step: 24000 | performance: 5.2 | accuracy: 0.27 | loss: 1.09
update:305/2000, 耗时:0.00分/1.12分 | step: 24400 | performance: 3.2 | accuracy: 0.27 | loss: 1.24
update:310/2000, 耗时:0.00分/1.14分 | step: 24800 | performance: 1.7 | accuracy: 0.27 | loss: 2.05
update:315/2000, 耗时:0.00分/1.15分 | step: 25200 | performance: 1.8 | accuracy: 0.27 | loss: 0.62
update:320/2000, 耗时:0.00分/1.17分 | step: 25600 | performance: 0.9 | accuracy: 0.27 | loss: 2.26
update:325/2000, 耗时:0.00分/1.19分 | step: 26000 | performance: 0.6 | accuracy: 0.27 | loss: 2.24
update:330/2000, 耗时:0.00分/1.21分 | step: 26400 | performance: 1.8 | accuracy: 0.27 | loss: 1.92
update:335/2000, 耗时:0.00分/1.22分 | step: 26800 | performance: 1.6 | accuracy: 0.28 | loss: 1.36
update:340/2000, 耗时:0.00分/1.24分 | step: 27200 | performance: 1.7 | accuracy: 0.28 | loss: 1.56
update:345/2000, 耗时:0.00分/1.26分 | step: 27600 | performance: 1.3 | accuracy: 0.28 | loss: 3.00
update:350/2000, 耗时:0.00分/1.28分 | step: 28000 | performance: 1.1 | accuracy: 0.28 | loss: 1.19
update:355/2000, 耗时:0.00分/1.29分 | step: 28400 | performance: 1.2 | accuracy: 0.28 | loss: 1.25
update:360/2000, 耗时:0.00分/1.31分 | step: 28800 | performance: 1.5 | accuracy: 0.28 | loss: 2.01
update:365/2000, 耗时:0.00分/1.33分 | step: 29200 | performance: 1.5 | accuracy: 0.29 | loss: 1.79
Saving PPO weights in both H5 format and checkpoint @ update:368 
update:370/2000, 耗时:0.00分/1.35分 | step: 29600 | performance: 1.0 | accuracy: 0.00 | loss: 0.30
Saving PPO weights in both H5 format and checkpoint @ update:370 
update:375/2000, 耗时:0.00分/1.38分 | step: 30000 | performance: 1.0 | accuracy: 0.00 | loss: 0.50
step: 30394 | worker_1@n_step_9: average total_reward after train data exhaustion : 0.2 | max total_reward: 100.2
step: 30396 | worker_3@n_step_9: average total_reward after train data exhaustion : 0.8 | max total_reward: 100.2
step: 30397 | worker_4@n_step_9: average total_reward after train data exhaustion : 0.2 | max total_reward: 100.2
step: 30399 | worker_6@n_step_9: average total_reward after train data exhaustion : 1.6 | max total_reward: 100.2
update:380/2000, 耗时:0.00分/1.39分 | step: 30400 | performance: 1.0 | accuracy: 0.00 | loss: 0.57
step: 30635 | worker_2@n_step_9: average total_reward after train data exhaustion : -0.5 | max total_reward: 100.2
step: 30638 | worker_5@n_step_9: average total_reward after train data exhaustion : -0.5 | max total_reward: 100.2
update:385/2000, 耗时:0.00分/1.41分 | step: 30800 | performance: 0.8 | accuracy: 0.15 | loss: 1.01
update:390/2000, 耗时:0.00分/1.43分 | step: 31200 | performance: 0.5 | accuracy: 0.14 | loss: 1.24
step: 31594 | worker_1@n_step_9: average total_reward after train data exhaustion : -0.5 | max total_reward: 100.2
update:395/2000, 耗时:0.00分/1.45分 | step: 31600 | performance: 0.5 | accuracy: 0.15 | loss: 0.49
step: 31757 | worker_4@n_step_9: average total_reward after train data exhaustion : -0.3 | max total_reward: 100.2
update:400/2000, 耗时:0.00分/1.46分 | step: 32000 | performance: 0.9 | accuracy: 0.20 | loss: 1.78
update:405/2000, 耗时:0.00分/1.48分 | step: 32400 | performance: 0.5 | accuracy: 0.19 | loss: 3.38
update:410/2000, 耗时:0.00分/1.50分 | step: 32800 | performance: 0.4 | accuracy: 0.21 | loss: 3.90
update:415/2000, 耗时:0.00分/1.52分 | step: 33200 | performance: 1.2 | accuracy: 0.25 | loss: 2.55
update:420/2000, 耗时:0.00分/1.53分 | step: 33600 | performance: 1.1 | accuracy: 0.25 | loss: 1.87
update:425/2000, 耗时:0.00分/1.55分 | step: 34000 | performance: 0.8 | accuracy: 0.24 | loss: 0.67
update:430/2000, 耗时:0.00分/1.57分 | step: 34400 | performance: 0.9 | accuracy: 0.25 | loss: 1.23
update:435/2000, 耗时:0.00分/1.59分 | step: 34800 | performance: 1.0 | accuracy: 0.24 | loss: 1.58
update:440/2000, 耗时:0.00分/1.60分 | step: 35200 | performance: 1.2 | accuracy: 0.25 | loss: 2.17
update:445/2000, 耗时:0.00分/1.62分 | step: 35600 | performance: 1.3 | accuracy: 0.26 | loss: 1.42
update:450/2000, 耗时:0.00分/1.64分 | step: 36000 | performance: 3.9 | accuracy: 0.27 | loss: 1.56
update:455/2000, 耗时:0.00分/1.66分 | step: 36400 | performance: 3.2 | accuracy: 0.28 | loss: 2.22
update:460/2000, 耗时:0.00分/1.67分 | step: 36800 | performance: 4.8 | accuracy: 0.28 | loss: 1.08
update:465/2000, 耗时:0.00分/1.69分 | step: 37200 | performance: 3.0 | accuracy: 0.28 | loss: 1.84
update:470/2000, 耗时:0.00分/1.71分 | step: 37600 | performance: 2.4 | accuracy: 0.29 | loss: 2.70
update:475/2000, 耗时:0.00分/1.73分 | step: 38000 | performance: 1.2 | accuracy: 0.29 | loss: 1.28
update:480/2000, 耗时:0.00分/1.75分 | step: 38400 | performance: 0.7 | accuracy: 0.28 | loss: 2.04
update:485/2000, 耗时:0.00分/1.76分 | step: 38800 | performance: 0.3 | accuracy: 0.28 | loss: 1.45
update:490/2000, 耗时:0.00分/1.78分 | step: 39200 | performance: 0.3 | accuracy: 0.28 | loss: 1.07
update:495/2000, 耗时:0.00分/1.80分 | step: 39600 | performance: 0.3 | accuracy: 0.27 | loss: 1.26
update:500/2000, 耗时:0.00分/1.82分 | step: 40000 | performance: 0.2 | accuracy: 0.27 | loss: 1.09
update:505/2000, 耗时:0.00分/1.84分 | step: 40400 | performance: 0.2 | accuracy: 0.27 | loss: 1.11
update:510/2000, 耗时:0.00分/1.85分 | step: 40800 | performance: 0.1 | accuracy: 0.27 | loss: 1.24
update:515/2000, 耗时:0.00分/1.87分 | step: 41200 | performance: 0.1 | accuracy: 0.27 | loss: 1.09
update:520/2000, 耗时:0.00分/1.89分 | step: 41600 | performance: 0.2 | accuracy: 0.27 | loss: 0.60
update:525/2000, 耗时:0.00分/1.91分 | step: 42000 | performance: 0.2 | accuracy: 0.27 | loss: 0.98
update:530/2000, 耗时:0.00分/1.92分 | step: 42400 | performance: 0.1 | accuracy: 0.27 | loss: 0.49
update:535/2000, 耗时:0.00分/1.94分 | step: 42800 | performance: 0.1 | accuracy: 0.27 | loss: 0.61
update:540/2000, 耗时:0.00分/1.96分 | step: 43200 | performance: 0.1 | accuracy: 0.27 | loss: 0.59
update:545/2000, 耗时:0.00分/1.98分 | step: 43600 | performance: 0.3 | accuracy: 0.27 | loss: 1.54
update:550/2000, 耗时:0.00分/2.00分 | step: 44000 | performance: 0.2 | accuracy: 0.26 | loss: 0.55
update:555/2000, 耗时:0.00分/2.01分 | step: 44400 | performance: 0.1 | accuracy: 0.26 | loss: 0.54
update:560/2000, 耗时:0.00分/2.03分 | step: 44800 | performance: 0.1 | accuracy: 0.26 | loss: 0.95
update:565/2000, 耗时:0.00分/2.05分 | step: 45200 | performance: 0.1 | accuracy: 0.26 | loss: 0.80
update:570/2000, 耗时:0.00分/2.07分 | step: 45600 | performance: 0.1 | accuracy: 0.26 | loss: 0.77
update:575/2000, 耗时:0.00分/2.08分 | step: 46000 | performance: 0.1 | accuracy: 0.25 | loss: 0.59
update:580/2000, 耗时:0.00分/2.10分 | step: 46400 | performance: 0.1 | accuracy: 0.25 | loss: 0.42
update:585/2000, 耗时:0.00分/2.12分 | step: 46800 | performance: 0.0 | accuracy: 0.25 | loss: 0.78
update:590/2000, 耗时:0.00分/2.14分 | step: 47200 | performance: 0.1 | accuracy: 0.25 | loss: 0.44
update:595/2000, 耗时:0.00分/2.16分 | step: 47600 | performance: 0.1 | accuracy: 0.25 | loss: 0.68
update:600/2000, 耗时:0.00分/2.18分 | step: 48000 | performance: 0.1 | accuracy: 0.25 | loss: 0.46
update:605/2000, 耗时:0.00分/2.19分 | step: 48400 | performance: 0.3 | accuracy: 0.25 | loss: 1.41
update:610/2000, 耗时:0.00分/2.21分 | step: 48800 | performance: 0.8 | accuracy: 0.25 | loss: 2.07
update:615/2000, 耗时:0.00分/2.23分 | step: 49200 | performance: 1.5 | accuracy: 0.26 | loss: 1.90
update:620/2000, 耗时:0.00分/2.25分 | step: 49600 | performance: 1.1 | accuracy: 0.26 | loss: 3.29
update:625/2000, 耗时:0.00分/2.26分 | step: 50000 | performance: 0.8 | accuracy: 0.26 | loss: 4.13
update:630/2000, 耗时:0.00分/2.28分 | step: 50400 | performance: 0.1 | accuracy: 0.26 | loss: 5.55
update:635/2000, 耗时:0.00分/2.30分 | step: 50800 | performance: 0.1 | accuracy: 0.27 | loss: 4.01
update:640/2000, 耗时:0.00分/2.32分 | step: 51200 | performance: 0.0 | accuracy: 0.27 | loss: 2.61
update:645/2000, 耗时:0.00分/2.33分 | step: 51600 | performance: 0.1 | accuracy: 0.27 | loss: 2.77
update:650/2000, 耗时:0.00分/2.35分 | step: 52000 | performance: 0.1 | accuracy: 0.27 | loss: 2.37
update:655/2000, 耗时:0.00分/2.37分 | step: 52400 | performance: 0.1 | accuracy: 0.27 | loss: 2.07
update:660/2000, 耗时:0.00分/2.39分 | step: 52800 | performance: 0.1 | accuracy: 0.28 | loss: 1.71
update:665/2000, 耗时:0.00分/2.41分 | step: 53200 | performance: 0.1 | accuracy: 0.28 | loss: 1.26
update:670/2000, 耗时:0.00分/2.42分 | step: 53600 | performance: 0.0 | accuracy: 0.28 | loss: 2.73
update:675/2000, 耗时:0.00分/2.44分 | step: 54000 | performance: 0.0 | accuracy: 0.28 | loss: 3.04
update:680/2000, 耗时:0.00分/2.46分 | step: 54400 | performance: 0.0 | accuracy: 0.28 | loss: 1.15
update:685/2000, 耗时:0.00分/2.48分 | step: 54800 | performance: 0.0 | accuracy: 0.28 | loss: 1.68
update:690/2000, 耗时:0.00分/2.50分 | step: 55200 | performance: 0.0 | accuracy: 0.28 | loss: 3.06
update:695/2000, 耗时:0.00分/2.52分 | step: 55600 | performance: 0.0 | accuracy: 0.28 | loss: 0.93
update:700/2000, 耗时:0.00分/2.53分 | step: 56000 | performance: 0.0 | accuracy: 0.29 | loss: 1.02
update:705/2000, 耗时:0.00分/2.55分 | step: 56400 | performance: 0.0 | accuracy: 0.28 | loss: 2.14
update:710/2000, 耗时:0.00分/2.57分 | step: 56800 | performance: 0.0 | accuracy: 0.28 | loss: 1.46
update:715/2000, 耗时:0.00分/2.59分 | step: 57200 | performance: 0.0 | accuracy: 0.28 | loss: 1.39
update:720/2000, 耗时:0.00分/2.60分 | step: 57600 | performance: 0.0 | accuracy: 0.29 | loss: 1.12
update:725/2000, 耗时:0.00分/2.62分 | step: 58000 | performance: 0.0 | accuracy: 0.29 | loss: 1.07
update:730/2000, 耗时:0.00分/2.64分 | step: 58400 | performance: 0.0 | accuracy: 0.29 | loss: 2.69
update:735/2000, 耗时:0.00分/2.65分 | step: 58800 | performance: 0.0 | accuracy: 0.29 | loss: 0.73
update:740/2000, 耗时:0.00分/2.67分 | step: 59200 | performance: 0.0 | accuracy: 0.29 | loss: 1.36
update:745/2000, 耗时:0.00分/2.69分 | step: 59600 | performance: 0.0 | accuracy: 0.28 | loss: 1.35
update:750/2000, 耗时:0.00分/2.71分 | step: 60000 | performance: 1.7 | accuracy: 0.44 | loss: 2.02
update:755/2000, 耗时:0.00分/2.72分 | step: 60400 | performance: 3.3 | accuracy: 0.43 | loss: 1.21
update:760/2000, 耗时:0.00分/2.74分 | step: 60800 | performance: 3.4 | accuracy: 0.38 | loss: 2.77
step: 61035 | worker_2@n_step_9: average total_reward after train data exhaustion : 1.7 | max total_reward: 150.2
step: 61038 | worker_5@n_step_9: average total_reward after train data exhaustion : 5.0 | max total_reward: 165.5
update:765/2000, 耗时:0.00分/2.76分 | step: 61200 | performance: 3.9 | accuracy: 0.34 | loss: 1.41
Saving PPO weights in both H5 format and checkpoint @ update:766 
Saving PPO weights in both H5 format and checkpoint @ update:767 
update:770/2000, 耗时:0.00分/2.79分 | step: 61600 | performance: 4.4 | accuracy: 0.32 | loss: 1.36
update:775/2000, 耗时:0.00分/2.80分 | step: 62000 | performance: 3.4 | accuracy: 0.30 | loss: 3.96
update:780/2000, 耗时:0.00分/2.82分 | step: 62400 | performance: 6.0 | accuracy: 0.32 | loss: 1.58
update:785/2000, 耗时:0.00分/2.84分 | step: 62800 | performance: 12.4 | accuracy: 0.33 | loss: 1.81
update:790/2000, 耗时:0.00分/2.86分 | step: 63200 | performance: 8.1 | accuracy: 0.33 | loss: 2.38
update:795/2000, 耗时:0.00分/2.87分 | step: 63600 | performance: 12.9 | accuracy: 0.34 | loss: 1.48
update:800/2000, 耗时:0.00分/2.89分 | step: 64000 | performance: 19.1 | accuracy: 0.34 | loss: 2.83
update:805/2000, 耗时:0.00分/2.91分 | step: 64400 | performance: 18.1 | accuracy: 0.33 | loss: 3.04
update:810/2000, 耗时:0.00分/2.93分 | step: 64800 | performance: 18.0 | accuracy: 0.34 | loss: 2.38
update:815/2000, 耗时:0.00分/2.94分 | step: 65200 | performance: 71.7 | accuracy: 0.35 | loss: 2.38
update:820/2000, 耗时:0.00分/2.96分 | step: 65600 | performance: 137.3 | accuracy: 0.36 | loss: 2.75
update:825/2000, 耗时:0.00分/2.98分 | step: 66000 | performance: 170.2 | accuracy: 0.37 | loss: 2.15
update:830/2000, 耗时:0.00分/3.00分 | step: 66400 | performance: 194.3 | accuracy: 0.37 | loss: 3.55
update:835/2000, 耗时:0.00分/3.01分 | step: 66800 | performance: 128.9 | accuracy: 0.37 | loss: 3.70
update:840/2000, 耗时:0.00分/3.03分 | step: 67200 | performance: 108.8 | accuracy: 0.37 | loss: 1.85
update:845/2000, 耗时:0.00分/3.05分 | step: 67600 | performance: 40.9 | accuracy: 0.36 | loss: 2.17
update:850/2000, 耗时:0.00分/3.06分 | step: 68000 | performance: 31.6 | accuracy: 0.36 | loss: 1.87
update:855/2000, 耗时:0.00分/3.08分 | step: 68400 | performance: 23.1 | accuracy: 0.36 | loss: 2.30
update:860/2000, 耗时:0.00分/3.10分 | step: 68800 | performance: 5.3 | accuracy: 0.35 | loss: 2.58
update:865/2000, 耗时:0.00分/3.12分 | step: 69200 | performance: 7.3 | accuracy: 0.35 | loss: 1.22
update:870/2000, 耗时:0.00分/3.14分 | step: 69600 | performance: 8.3 | accuracy: 0.35 | loss: 0.98
update:875/2000, 耗时:0.00分/3.15分 | step: 70000 | performance: 7.6 | accuracy: 0.35 | loss: 1.89
update:880/2000, 耗时:0.00分/3.17分 | step: 70400 | performance: 6.8 | accuracy: 0.35 | loss: 1.19
update:885/2000, 耗时:0.00分/3.19分 | step: 70800 | performance: 7.8 | accuracy: 0.35 | loss: 0.60
update:890/2000, 耗时:0.00分/3.21分 | step: 71200 | performance: 10.8 | accuracy: 0.35 | loss: 1.34
update:895/2000, 耗时:0.00分/3.23分 | step: 71600 | performance: 8.1 | accuracy: 0.35 | loss: 1.63
update:900/2000, 耗时:0.00分/3.24分 | step: 72000 | performance: 6.0 | accuracy: 0.35 | loss: 2.71
update:905/2000, 耗时:0.00分/3.26分 | step: 72400 | performance: 3.3 | accuracy: 0.34 | loss: 1.79
update:910/2000, 耗时:0.00分/3.28分 | step: 72800 | performance: 6.4 | accuracy: 0.34 | loss: 1.17
update:915/2000, 耗时:0.00分/3.30分 | step: 73200 | performance: 3.9 | accuracy: 0.34 | loss: 1.36
update:920/2000, 耗时:0.00分/3.31分 | step: 73600 | performance: 1.6 | accuracy: 0.34 | loss: 1.10
update:925/2000, 耗时:0.00分/3.33分 | step: 74000 | performance: 1.9 | accuracy: 0.33 | loss: 0.86
update:930/2000, 耗时:0.00分/3.35分 | step: 74400 | performance: 2.4 | accuracy: 0.33 | loss: 1.26
update:935/2000, 耗时:0.00分/3.37分 | step: 74800 | performance: 2.8 | accuracy: 0.33 | loss: 0.39
update:940/2000, 耗时:0.00分/3.38分 | step: 75200 | performance: 2.8 | accuracy: 0.33 | loss: 0.60
update:945/2000, 耗时:0.00分/3.40分 | step: 75600 | performance: 1.9 | accuracy: 0.33 | loss: 0.92
update:950/2000, 耗时:0.00分/3.42分 | step: 76000 | performance: 1.8 | accuracy: 0.32 | loss: 0.49
update:955/2000, 耗时:0.00分/3.43分 | step: 76400 | performance: 2.5 | accuracy: 0.32 | loss: 0.71
update:960/2000, 耗时:0.00分/3.45分 | step: 76800 | performance: 4.0 | accuracy: 0.32 | loss: 2.38
update:965/2000, 耗时:0.00分/3.47分 | step: 77200 | performance: 5.7 | accuracy: 0.32 | loss: 1.49
update:970/2000, 耗时:0.00分/3.49分 | step: 77600 | performance: 32.8 | accuracy: 0.33 | loss: 2.80
update:975/2000, 耗时:0.00分/3.50分 | step: 78000 | performance: 30.6 | accuracy: 0.33 | loss: 3.06
update:980/2000, 耗时:0.00分/3.52分 | step: 78400 | performance: 144.0 | accuracy: 0.34 | loss: 4.13
update:985/2000, 耗时:0.00分/3.54分 | step: 78800 | performance: 275.5 | accuracy: 0.34 | loss: 8.83
update:990/2000, 耗时:0.00分/3.56分 | step: 79200 | performance: 357.5 | accuracy: 0.35 | loss: 4.40
update:995/2000, 耗时:0.00分/3.57分 | step: 79600 | performance: 178.7 | accuracy: 0.35 | loss: 5.26
update:1000/2000, 耗时:0.00分/3.59分 | step: 80000 | performance: 38.6 | accuracy: 0.35 | loss: 4.36
update:1005/2000, 耗时:0.00分/3.61分 | step: 80400 | performance: 20.0 | accuracy: 0.35 | loss: 3.68
update:1010/2000, 耗时:0.00分/3.62分 | step: 80800 | performance: 22.3 | accuracy: 0.35 | loss: 4.11
update:1015/2000, 耗时:0.00分/3.64分 | step: 81200 | performance: 56.3 | accuracy: 0.35 | loss: 5.37
update:1020/2000, 耗时:0.00分/3.66分 | step: 81600 | performance: 44.9 | accuracy: 0.35 | loss: 1.76
update:1025/2000, 耗时:0.00分/3.68分 | step: 82000 | performance: 71.8 | accuracy: 0.35 | loss: 1.99
update:1030/2000, 耗时:0.00分/3.69分 | step: 82400 | performance: 108.7 | accuracy: 0.36 | loss: 2.88
update:1035/2000, 耗时:0.00分/3.71分 | step: 82800 | performance: 50.2 | accuracy: 0.36 | loss: 2.82
update:1040/2000, 耗时:0.00分/3.73分 | step: 83200 | performance: 33.7 | accuracy: 0.36 | loss: 3.50
update:1045/2000, 耗时:0.00分/3.74分 | step: 83600 | performance: 18.2 | accuracy: 0.36 | loss: 2.21
update:1050/2000, 耗时:0.00分/3.76分 | step: 84000 | performance: 18.0 | accuracy: 0.36 | loss: 2.99
update:1055/2000, 耗时:0.00分/3.78分 | step: 84400 | performance: 10.5 | accuracy: 0.36 | loss: 3.14
update:1060/2000, 耗时:0.00分/3.80分 | step: 84800 | performance: 16.9 | accuracy: 0.36 | loss: 2.27
update:1065/2000, 耗时:0.00分/3.81分 | step: 85200 | performance: 11.2 | accuracy: 0.36 | loss: 3.20
update:1070/2000, 耗时:0.00分/3.83分 | step: 85600 | performance: 4.8 | accuracy: 0.36 | loss: 1.89
update:1075/2000, 耗时:0.00分/3.85分 | step: 86000 | performance: 1.9 | accuracy: 0.35 | loss: 2.78
update:1080/2000, 耗时:0.00分/3.87分 | step: 86400 | performance: 1.1 | accuracy: 0.35 | loss: 2.73
update:1085/2000, 耗时:0.00分/3.88分 | step: 86800 | performance: 2.0 | accuracy: 0.35 | loss: 0.53
update:1090/2000, 耗时:0.00分/3.90分 | step: 87200 | performance: 1.9 | accuracy: 0.35 | loss: 0.75
update:1095/2000, 耗时:0.00分/3.92分 | step: 87600 | performance: 1.5 | accuracy: 0.35 | loss: 0.63
update:1100/2000, 耗时:0.00分/3.93分 | step: 88000 | performance: 1.5 | accuracy: 0.35 | loss: 0.67
update:1105/2000, 耗时:0.00分/3.95分 | step: 88400 | performance: 1.0 | accuracy: 0.34 | loss: 0.70
Saving PPO weights in both H5 format and checkpoint @ update:1105 
step: 88713 | worker_0@n_step_9: average total_reward after train data exhaustion : 16.1 | max total_reward: 233.8
update:1110/2000, 耗时:0.00分/3.98分 | step: 88800 | performance: 0.9 | accuracy: 0.34 | loss: 0.75
step: 89200 | worker_7@n_step_9: average total_reward after train data exhaustion : 16.0 | max total_reward: 233.8
update:1115/2000, 耗时:0.00分/3.99分 | step: 89200 | performance: 1.0 | accuracy: 0.00 | loss: 0.58
update:1120/2000, 耗时:0.00分/4.01分 | step: 89600 | performance: 1.1 | accuracy: 0.22 | loss: 0.51
Saving PPO weights in both H5 format and checkpoint @ update:1121 
update:1125/2000, 耗时:0.00分/4.04分 | step: 90000 | performance: 5.6 | accuracy: 0.25 | loss: 1.57
update:1130/2000, 耗时:0.00分/4.06分 | step: 90400 | performance: 2.1 | accuracy: 0.22 | loss: 0.91
Saving PPO weights in both H5 format and checkpoint @ update:1131 
Saving PPO weights in both H5 format and checkpoint @ update:1133 
Saving PPO weights in both H5 format and checkpoint @ update:1134 
update:1135/2000, 耗时:0.00分/4.09分 | step: 90800 | performance: 5.6 | accuracy: 0.27 | loss: 1.97
Saving PPO weights in both H5 format and checkpoint @ update:1135 
update:1140/2000, 耗时:0.00分/4.11分 | step: 91200 | performance: 4.4 | accuracy: 0.24 | loss: 2.77
update:1145/2000, 耗时:0.00分/4.13分 | step: 91600 | performance: 7.2 | accuracy: 0.27 | loss: 2.44
update:1150/2000, 耗时:0.00分/4.15分 | step: 92000 | performance: 17.8 | accuracy: 0.29 | loss: 2.84
update:1155/2000, 耗时:0.00分/4.17分 | step: 92400 | performance: 15.6 | accuracy: 0.29 | loss: 2.75
update:1160/2000, 耗时:0.00分/4.19分 | step: 92800 | performance: 22.7 | accuracy: 0.31 | loss: 1.94
update:1165/2000, 耗时:0.00分/4.20分 | step: 93200 | performance: 37.1 | accuracy: 0.31 | loss: 1.99
update:1170/2000, 耗时:0.00分/4.22分 | step: 93600 | performance: 36.6 | accuracy: 0.31 | loss: 2.23
update:1175/2000, 耗时:0.00分/4.24分 | step: 94000 | performance: 30.7 | accuracy: 0.31 | loss: 2.34
update:1180/2000, 耗时:0.00分/4.26分 | step: 94400 | performance: 36.9 | accuracy: 0.31 | loss: 1.60
update:1185/2000, 耗时:0.00分/4.28分 | step: 94800 | performance: 177.1 | accuracy: 0.32 | loss: 2.03
update:1190/2000, 耗时:0.00分/4.30分 | step: 95200 | performance: 137.6 | accuracy: 0.33 | loss: 2.01
update:1195/2000, 耗时:0.00分/4.31分 | step: 95600 | performance: 151.0 | accuracy: 0.33 | loss: 3.01
update:1200/2000, 耗时:0.00分/4.33分 | step: 96000 | performance: 103.7 | accuracy: 0.33 | loss: 3.94
update:1205/2000, 耗时:0.00分/4.35分 | step: 96400 | performance: 91.1 | accuracy: 0.33 | loss: 2.88
update:1210/2000, 耗时:0.00分/4.37分 | step: 96800 | performance: 39.1 | accuracy: 0.32 | loss: 2.28
update:1215/2000, 耗时:0.00分/4.39分 | step: 97200 | performance: 30.3 | accuracy: 0.31 | loss: 1.72
update:1220/2000, 耗时:0.00分/4.40分 | step: 97600 | performance: 9.9 | accuracy: 0.31 | loss: 1.98
update:1225/2000, 耗时:0.00分/4.42分 | step: 98000 | performance: 9.8 | accuracy: 0.31 | loss: 2.40
update:1230/2000, 耗时:0.00分/4.44分 | step: 98400 | performance: 22.2 | accuracy: 0.31 | loss: 0.72
update:1235/2000, 耗时:0.00分/4.46分 | step: 98800 | performance: 23.2 | accuracy: 0.31 | loss: 1.48
update:1240/2000, 耗时:0.00分/4.48分 | step: 99200 | performance: 21.2 | accuracy: 0.31 | loss: 0.96
update:1245/2000, 耗时:0.00分/4.50分 | step: 99600 | performance: 25.6 | accuracy: 0.31 | loss: 0.68
update:1250/2000, 耗时:0.00分/4.51分 | step: 100000 | performance: 33.3 | accuracy: 0.31 | loss: 0.94
update:1255/2000, 耗时:0.00分/4.53分 | step: 100400 | performance: 39.2 | accuracy: 0.31 | loss: 0.89
update:1260/2000, 耗时:0.00分/4.55分 | step: 100800 | performance: 51.2 | accuracy: 0.31 | loss: 0.71
update:1265/2000, 耗时:0.00分/4.57分 | step: 101200 | performance: 29.4 | accuracy: 0.30 | loss: 1.07
update:1270/2000, 耗时:0.00分/4.59分 | step: 101600 | performance: 30.7 | accuracy: 0.31 | loss: 1.08
update:1275/2000, 耗时:0.00分/4.61分 | step: 102000 | performance: 38.6 | accuracy: 0.31 | loss: 3.24
update:1280/2000, 耗时:0.00分/4.62分 | step: 102400 | performance: 108.5 | accuracy: 0.31 | loss: 2.44
update:1285/2000, 耗时:0.00分/4.64分 | step: 102800 | performance: 80.9 | accuracy: 0.31 | loss: 2.33
update:1290/2000, 耗时:0.00分/4.66分 | step: 103200 | performance: 105.0 | accuracy: 0.31 | loss: 1.68
update:1295/2000, 耗时:0.00分/4.68分 | step: 103600 | performance: 103.8 | accuracy: 0.31 | loss: 3.07
update:1300/2000, 耗时:0.00分/4.70分 | step: 104000 | performance: 127.6 | accuracy: 0.31 | loss: 1.27
update:1305/2000, 耗时:0.00分/4.71分 | step: 104400 | performance: 118.3 | accuracy: 0.31 | loss: 0.58
update:1310/2000, 耗时:0.00分/4.73分 | step: 104800 | performance: 101.4 | accuracy: 0.31 | loss: 0.93
update:1315/2000, 耗时:0.00分/4.75分 | step: 105200 | performance: 111.0 | accuracy: 0.30 | loss: 0.63
update:1320/2000, 耗时:0.00分/4.77分 | step: 105600 | performance: 92.4 | accuracy: 0.30 | loss: 0.73
update:1325/2000, 耗时:0.00分/4.79分 | step: 106000 | performance: 79.3 | accuracy: 0.29 | loss: 0.53
update:1330/2000, 耗时:0.00分/4.80分 | step: 106400 | performance: 146.8 | accuracy: 0.30 | loss: 0.66
update:1335/2000, 耗时:0.00分/4.82分 | step: 106800 | performance: 174.9 | accuracy: 0.30 | loss: 1.65
update:1340/2000, 耗时:0.00分/4.84分 | step: 107200 | performance: 597.5 | accuracy: 0.30 | loss: 2.61
update:1345/2000, 耗时:0.00分/4.86分 | step: 107600 | performance: 1332.2 | accuracy: 0.31 | loss: 2.19
update:1350/2000, 耗时:0.00分/4.88分 | step: 108000 | performance: 2050.1 | accuracy: 0.31 | loss: 2.50
update:1355/2000, 耗时:0.00分/4.90分 | step: 108400 | performance: 2249.4 | accuracy: 0.31 | loss: 4.48
update:1360/2000, 耗时:0.00分/4.91分 | step: 108800 | performance: 1531.8 | accuracy: 0.32 | loss: 6.47
update:1365/2000, 耗时:0.00分/4.93分 | step: 109200 | performance: 346.0 | accuracy: 0.31 | loss: 4.78
update:1370/2000, 耗时:0.00分/4.95分 | step: 109600 | performance: 432.2 | accuracy: 0.32 | loss: 3.83
update:1375/2000, 耗时:0.00分/4.97分 | step: 110000 | performance: 170.6 | accuracy: 0.32 | loss: 4.54
update:1380/2000, 耗时:0.00分/4.99分 | step: 110400 | performance: 500.5 | accuracy: 0.32 | loss: 4.23
update:1385/2000, 耗时:0.00分/5.01分 | step: 110800 | performance: 763.1 | accuracy: 0.32 | loss: 4.07
update:1390/2000, 耗时:0.00分/5.03分 | step: 111200 | performance: 473.3 | accuracy: 0.33 | loss: 3.90
update:1395/2000, 耗时:0.00分/5.05分 | step: 111600 | performance: 3426.2 | accuracy: 0.34 | loss: 5.01
update:1400/2000, 耗时:0.00分/5.07分 | step: 112000 | performance: 3520.5 | accuracy: 0.34 | loss: 2.62
update:1405/2000, 耗时:0.00分/5.09分 | step: 112400 | performance: 1129.8 | accuracy: 0.34 | loss: 5.89
update:1410/2000, 耗时:0.00分/5.11分 | step: 112800 | performance: 877.1 | accuracy: 0.34 | loss: 4.15
update:1415/2000, 耗时:0.00分/5.13分 | step: 113200 | performance: 260.9 | accuracy: 0.34 | loss: 2.59
update:1420/2000, 耗时:0.00分/5.15分 | step: 113600 | performance: 278.7 | accuracy: 0.34 | loss: 4.88
update:1425/2000, 耗时:0.00分/5.17分 | step: 114000 | performance: 407.9 | accuracy: 0.34 | loss: 2.46
update:1430/2000, 耗时:0.00分/5.19分 | step: 114400 | performance: 419.6 | accuracy: 0.34 | loss: 3.95
update:1435/2000, 耗时:0.00分/5.21分 | step: 114800 | performance: 298.4 | accuracy: 0.35 | loss: 3.00
update:1440/2000, 耗时:0.00分/5.23分 | step: 115200 | performance: 187.7 | accuracy: 0.34 | loss: 1.30
update:1445/2000, 耗时:0.00分/5.25分 | step: 115600 | performance: 78.4 | accuracy: 0.34 | loss: 4.01
update:1450/2000, 耗时:0.00分/5.27分 | step: 116000 | performance: 93.8 | accuracy: 0.34 | loss: 2.23
update:1455/2000, 耗时:0.00分/5.29分 | step: 116400 | performance: 125.8 | accuracy: 0.34 | loss: 1.44
update:1460/2000, 耗时:0.00分/5.31分 | step: 116800 | performance: 136.3 | accuracy: 0.34 | loss: 0.92
update:1465/2000, 耗时:0.00分/5.33分 | step: 117200 | performance: 128.8 | accuracy: 0.34 | loss: 0.94
update:1470/2000, 耗时:0.00分/5.35分 | step: 117600 | performance: 135.9 | accuracy: 0.34 | loss: 0.52
update:1475/2000, 耗时:0.00分/5.37分 | step: 118000 | performance: 126.9 | accuracy: 0.34 | loss: 0.85
update:1480/2000, 耗时:0.00分/5.39分 | step: 118400 | performance: 128.4 | accuracy: 0.34 | loss: 0.78
Saving PPO weights in both H5 format and checkpoint @ update:1483 
update:1485/2000, 耗时:0.00分/5.42分 | step: 118800 | performance: 2.0 | accuracy: 0.43 | loss: 2.00
update:1490/2000, 耗时:0.00分/5.44分 | step: 119200 | performance: 1.7 | accuracy: 0.30 | loss: 1.83
Saving PPO weights in both H5 format and checkpoint @ update:1490 
update:1495/2000, 耗时:0.00分/5.46分 | step: 119600 | performance: 1.9 | accuracy: 0.27 | loss: 1.27
Saving PPO weights in both H5 format and checkpoint @ update:1499 
update:1500/2000, 耗时:0.00分/5.48分 | step: 120000 | performance: 2.2 | accuracy: 0.28 | loss: 2.46
Saving PPO weights in both H5 format and checkpoint @ update:1501 
Saving PPO weights in both H5 format and checkpoint @ update:1502 
update:1505/2000, 耗时:0.00分/5.51分 | step: 120400 | performance: 2.6 | accuracy: 0.29 | loss: 3.11
update:1510/2000, 耗时:0.00分/5.53分 | step: 120800 | performance: 1.7 | accuracy: 0.27 | loss: 2.98
update:1515/2000, 耗时:0.00分/5.54分 | step: 121200 | performance: 3.4 | accuracy: 0.28 | loss: 1.41
update:1520/2000, 耗时:0.00分/5.56分 | step: 121600 | performance: 5.9 | accuracy: 0.28 | loss: 1.14
update:1525/2000, 耗时:0.00分/5.58分 | step: 122000 | performance: 3.0 | accuracy: 0.28 | loss: 1.70
update:1530/2000, 耗时:0.00分/5.60分 | step: 122400 | performance: 4.6 | accuracy: 0.28 | loss: 0.78
update:1535/2000, 耗时:0.00分/5.62分 | step: 122800 | performance: 4.3 | accuracy: 0.27 | loss: 1.27
update:1540/2000, 耗时:0.00分/5.64分 | step: 123200 | performance: 4.1 | accuracy: 0.27 | loss: 1.15
update:1545/2000, 耗时:0.00分/5.65分 | step: 123600 | performance: 5.7 | accuracy: 0.27 | loss: 1.53
update:1550/2000, 耗时:0.00分/5.67分 | step: 124000 | performance: 13.0 | accuracy: 0.28 | loss: 1.00
update:1555/2000, 耗时:0.00分/5.69分 | step: 124400 | performance: 37.0 | accuracy: 0.29 | loss: 0.52
update:1560/2000, 耗时:0.00分/5.71分 | step: 124800 | performance: 33.8 | accuracy: 0.29 | loss: 1.47
update:1565/2000, 耗时:0.00分/5.73分 | step: 125200 | performance: 44.4 | accuracy: 0.29 | loss: 0.74
update:1570/2000, 耗时:0.00分/5.75分 | step: 125600 | performance: 50.9 | accuracy: 0.29 | loss: 2.26
update:1575/2000, 耗时:0.00分/5.77分 | step: 126000 | performance: 44.1 | accuracy: 0.28 | loss: 2.03
update:1580/2000, 耗时:0.00分/5.78分 | step: 126400 | performance: 21.1 | accuracy: 0.28 | loss: 1.71
update:1585/2000, 耗时:0.00分/5.80分 | step: 126800 | performance: 11.9 | accuracy: 0.28 | loss: 1.30
update:1590/2000, 耗时:0.00分/5.82分 | step: 127200 | performance: 17.2 | accuracy: 0.28 | loss: 0.89
update:1595/2000, 耗时:0.00分/5.84分 | step: 127600 | performance: 16.8 | accuracy: 0.27 | loss: 0.66
update:1600/2000, 耗时:0.00分/5.86分 | step: 128000 | performance: 17.9 | accuracy: 0.27 | loss: 0.42
update:1605/2000, 耗时:0.00分/5.88分 | step: 128400 | performance: 15.7 | accuracy: 0.26 | loss: 0.20
update:1610/2000, 耗时:0.00分/5.89分 | step: 128800 | performance: 16.2 | accuracy: 0.25 | loss: 0.25
update:1615/2000, 耗时:0.00分/5.91分 | step: 129200 | performance: 19.0 | accuracy: 0.25 | loss: 0.22
update:1620/2000, 耗时:0.00分/5.93分 | step: 129600 | performance: 21.4 | accuracy: 0.24 | loss: 0.44
update:1625/2000, 耗时:0.00分/5.95分 | step: 130000 | performance: 28.1 | accuracy: 0.24 | loss: 0.69
update:1630/2000, 耗时:0.00分/5.96分 | step: 130400 | performance: 25.6 | accuracy: 0.24 | loss: 0.36
update:1635/2000, 耗时:0.00分/5.98分 | step: 130800 | performance: 20.7 | accuracy: 0.23 | loss: 0.57
update:1640/2000, 耗时:0.00分/6.00分 | step: 131200 | performance: 18.3 | accuracy: 0.23 | loss: 0.91
update:1645/2000, 耗时:0.00分/6.02分 | step: 131600 | performance: 35.5 | accuracy: 0.23 | loss: 1.03
update:1650/2000, 耗时:0.00分/6.04分 | step: 132000 | performance: 45.4 | accuracy: 0.23 | loss: 0.76
update:1655/2000, 耗时:0.00分/6.05分 | step: 132400 | performance: 29.0 | accuracy: 0.23 | loss: 0.65
update:1660/2000, 耗时:0.00分/6.07分 | step: 132800 | performance: 32.0 | accuracy: 0.22 | loss: 0.28
update:1665/2000, 耗时:0.00分/6.09分 | step: 133200 | performance: 33.0 | accuracy: 0.22 | loss: 1.27
update:1670/2000, 耗时:0.00分/6.11分 | step: 133600 | performance: 35.3 | accuracy: 0.22 | loss: 0.38
update:1675/2000, 耗时:0.00分/6.12分 | step: 134000 | performance: 29.2 | accuracy: 0.22 | loss: 0.30
update:1680/2000, 耗时:0.00分/6.14分 | step: 134400 | performance: 29.8 | accuracy: 0.21 | loss: 0.38
update:1685/2000, 耗时:0.00分/6.16分 | step: 134800 | performance: 26.6 | accuracy: 0.21 | loss: 0.12
update:1690/2000, 耗时:0.00分/6.18分 | step: 135200 | performance: 29.4 | accuracy: 0.21 | loss: 0.31
update:1695/2000, 耗时:0.00分/6.20分 | step: 135600 | performance: 26.2 | accuracy: 0.20 | loss: 0.22
update:1700/2000, 耗时:0.00分/6.21分 | step: 136000 | performance: 27.6 | accuracy: 0.20 | loss: 0.46
update:1705/2000, 耗时:0.00分/6.23分 | step: 136400 | performance: 47.4 | accuracy: 0.20 | loss: 0.58
update:1710/2000, 耗时:0.00分/6.25分 | step: 136800 | performance: 40.1 | accuracy: 0.20 | loss: 1.31
update:1715/2000, 耗时:0.00分/6.27分 | step: 137200 | performance: 83.0 | accuracy: 0.21 | loss: 2.45
update:1720/2000, 耗时:0.00分/6.28分 | step: 137600 | performance: 204.6 | accuracy: 0.21 | loss: 4.96
update:1725/2000, 耗时:0.00分/6.30分 | step: 138000 | performance: 251.0 | accuracy: 0.22 | loss: 4.84
update:1730/2000, 耗时:0.00分/6.32分 | step: 138400 | performance: 131.3 | accuracy: 0.22 | loss: 5.11
update:1735/2000, 耗时:0.00分/6.34分 | step: 138800 | performance: 23.7 | accuracy: 0.22 | loss: 2.64
update:1740/2000, 耗时:0.00分/6.36分 | step: 139200 | performance: 18.4 | accuracy: 0.22 | loss: 4.50
update:1745/2000, 耗时:0.00分/6.37分 | step: 139600 | performance: 16.6 | accuracy: 0.23 | loss: 4.47
update:1750/2000, 耗时:0.00分/6.39分 | step: 140000 | performance: 63.1 | accuracy: 0.23 | loss: 6.00
update:1755/2000, 耗时:0.00分/6.41分 | step: 140400 | performance: 72.1 | accuracy: 0.24 | loss: 3.99
update:1760/2000, 耗时:0.00分/6.43分 | step: 140800 | performance: 133.7 | accuracy: 0.24 | loss: 2.83
update:1765/2000, 耗时:0.00分/6.45分 | step: 141200 | performance: 225.5 | accuracy: 0.25 | loss: 2.25
update:1770/2000, 耗时:0.00分/6.46分 | step: 141600 | performance: 129.6 | accuracy: 0.25 | loss: 2.42
update:1775/2000, 耗时:0.00分/6.48分 | step: 142000 | performance: 74.6 | accuracy: 0.25 | loss: 3.75
update:1780/2000, 耗时:0.00分/6.50分 | step: 142400 | performance: 39.5 | accuracy: 0.25 | loss: 2.61
update:1785/2000, 耗时:0.00分/6.52分 | step: 142800 | performance: 65.8 | accuracy: 0.26 | loss: 3.02
update:1790/2000, 耗时:0.00分/6.53分 | step: 143200 | performance: 34.0 | accuracy: 0.26 | loss: 2.74
update:1795/2000, 耗时:0.00分/6.55分 | step: 143600 | performance: 79.2 | accuracy: 0.27 | loss: 2.31
update:1800/2000, 耗时:0.00分/6.57分 | step: 144000 | performance: 38.1 | accuracy: 0.27 | loss: 4.01
update:1805/2000, 耗时:0.00分/6.59分 | step: 144400 | performance: 14.7 | accuracy: 0.27 | loss: 2.99
update:1810/2000, 耗时:0.00分/6.60分 | step: 144800 | performance: 4.4 | accuracy: 0.27 | loss: 6.02
update:1815/2000, 耗时:0.00分/6.62分 | step: 145200 | performance: 3.8 | accuracy: 0.27 | loss: 2.40
update:1820/2000, 耗时:0.00分/6.64分 | step: 145600 | performance: 4.8 | accuracy: 0.27 | loss: 1.00
update:1825/2000, 耗时:0.00分/6.66分 | step: 146000 | performance: 3.3 | accuracy: 0.27 | loss: 1.30
update:1830/2000, 耗时:0.00分/6.68分 | step: 146400 | performance: 3.3 | accuracy: 0.27 | loss: 0.75
update:1835/2000, 耗时:0.00分/6.69分 | step: 146800 | performance: 3.6 | accuracy: 0.27 | loss: 0.58
update:1840/2000, 耗时:0.00分/6.71分 | step: 147200 | performance: 3.4 | accuracy: 0.27 | loss: 0.53
update:1845/2000, 耗时:0.00分/6.73分 | step: 147600 | performance: 3.0 | accuracy: 0.27 | loss: 0.48
update:1850/2000, 耗时:0.00分/6.75分 | step: 148000 | performance: 3.3 | accuracy: 0.27 | loss: 0.29
update:1855/2000, 耗时:0.00分/6.77分 | step: 148400 | performance: 0.8 | accuracy: 0.00 | loss: 0.38
update:1860/2000, 耗时:0.00分/6.78分 | step: 148800 | performance: 0.8 | accuracy: 0.07 | loss: 0.53
step: 148960 | worker_7@n_step_9: average total_reward after train data exhaustion : 52.7 | max total_reward: 244.9
update:1865/2000, 耗时:0.00分/6.80分 | step: 149200 | performance: 1.4 | accuracy: 0.20 | loss: 0.54
Saving PPO weights in both H5 format and checkpoint @ update:1867 
Saving PPO weights in both H5 format and checkpoint @ update:1869 
update:1870/2000, 耗时:0.00分/6.83分 | step: 149600 | performance: 1.5 | accuracy: 0.15 | loss: 0.68
Saving PPO weights in both H5 format and checkpoint @ update:1870 
step: 149914 | worker_1@n_step_9: average total_reward after train data exhaustion : 65.8 | max total_reward: 244.9
Saving PPO weights in both H5 format and checkpoint @ update:1874 
step: 149996 | worker_3@n_step_9: average total_reward after train data exhaustion : 64.9 | max total_reward: 244.9
update:1875/2000, 耗时:0.00分/6.85分 | step: 150000 | performance: 2.7 | accuracy: 0.15 | loss: 0.66
update:1880/2000, 耗时:0.00分/6.87分 | step: 150400 | performance: 3.9 | accuracy: 0.17 | loss: 1.32
update:1885/2000, 耗时:0.00分/6.89分 | step: 150800 | performance: 3.5 | accuracy: 0.17 | loss: 1.62
update:1890/2000, 耗时:0.00分/6.91分 | step: 151200 | performance: 3.8 | accuracy: 0.17 | loss: 1.51
update:1895/2000, 耗时:0.00分/6.92分 | step: 151600 | performance: 7.5 | accuracy: 0.20 | loss: 1.62
update:1900/2000, 耗时:0.00分/6.94分 | step: 152000 | performance: 18.6 | accuracy: 0.23 | loss: 1.48
update:1905/2000, 耗时:0.00分/6.96分 | step: 152400 | performance: 6.9 | accuracy: 0.22 | loss: 2.40
update:1910/2000, 耗时:0.00分/6.97分 | step: 152800 | performance: 9.7 | accuracy: 0.23 | loss: 1.35
update:1915/2000, 耗时:0.00分/6.99分 | step: 153200 | performance: 10.6 | accuracy: 0.22 | loss: 1.68
update:1920/2000, 耗时:0.00分/7.01分 | step: 153600 | performance: 10.3 | accuracy: 0.23 | loss: 2.01
update:1925/2000, 耗时:0.00分/7.03分 | step: 154000 | performance: 11.7 | accuracy: 0.25 | loss: 1.68
update:1930/2000, 耗时:0.00分/7.05分 | step: 154400 | performance: 78.2 | accuracy: 0.27 | loss: 3.61
update:1935/2000, 耗时:0.00分/7.06分 | step: 154800 | performance: 79.3 | accuracy: 0.28 | loss: 4.18
update:1940/2000, 耗时:0.00分/7.08分 | step: 155200 | performance: 86.8 | accuracy: 0.29 | loss: 5.16
update:1945/2000, 耗时:0.00分/7.10分 | step: 155600 | performance: 88.2 | accuracy: 0.30 | loss: 3.08
update:1950/2000, 耗时:0.00分/7.12分 | step: 156000 | performance: 76.6 | accuracy: 0.30 | loss: 1.23
update:1955/2000, 耗时:0.00分/7.13分 | step: 156400 | performance: 59.8 | accuracy: 0.30 | loss: 3.94
update:1960/2000, 耗时:0.00分/7.15分 | step: 156800 | performance: 22.5 | accuracy: 0.29 | loss: 5.16
update:1965/2000, 耗时:0.00分/7.17分 | step: 157200 | performance: 6.3 | accuracy: 0.29 | loss: 2.51
update:1970/2000, 耗时:0.00分/7.19分 | step: 157600 | performance: 6.3 | accuracy: 0.30 | loss: 2.25
update:1975/2000, 耗时:0.00分/7.20分 | step: 158000 | performance: 2.1 | accuracy: 0.29 | loss: 3.99
update:1980/2000, 耗时:0.00分/7.22分 | step: 158400 | performance: 2.0 | accuracy: 0.30 | loss: 3.92
update:1985/2000, 耗时:0.00分/7.24分 | step: 158800 | performance: 1.9 | accuracy: 0.30 | loss: 2.46
update:1990/2000, 耗时:0.00分/7.26分 | step: 159200 | performance: 1.5 | accuracy: 0.30 | loss: 2.25
update:1995/2000, 耗时:0.00分/7.27分 | step: 159600 | performance: 2.9 | accuracy: 0.30 | loss: 2.38
update:2000/2000, 耗时:0.00分/7.29分 | step: 160000 | performance: 2.6 | accuracy: 0.30 | loss: 2.27
----------------------------------------finished----------------------------------------
  0%|          | 0/406 [00:00<?, ?it/s]==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
100%|| 406/406 [00:00<00:00, 94092.58it/s]
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 913.42
2023-07-24T12:00:00 | net performance [%] = -8.6581
2023-07-24T12:00:00 | number of trades [#] = 62
==================================================
Trial 54 Complete [00h 07m 44s]
net_wealth: 913.4189109382984

Best net_wealth So Far: 1824.8039564105297
Total elapsed time: 07h 31m 23s

Search: Running Trial #55

Value             |Best Value So Far |Hyperparameter
6                 |6                 |horizon
365               |365               |lookback
False             |True              |MarketFactor
5                 |10                |lags
0.9               |0.98              |gamma
32                |16                |batch_size
5                 |7                 |n_step
0.92              |0.94              |gae_lambda
2                 |0.5               |gradient_clip_norm
3                 |3                 |epochs
0.001             |0.001             |actor_lr
0.0005            |0.001             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4309.000000   4315.000000
mean      0.000441    20062.255222  ...   20140.547965  20118.633889
std       0.027818    16039.874230  ...   16077.550480  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7699.189941   7690.540039
50%       0.000642    11554.824463  ...   11743.940430  11715.610352
75%       0.011655    29873.081836  ...   29950.949219  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
22023-07-22023-07-28 05:34:46.7648503:  I tensor205:34:46.023-flo0w/cor270e-72026/45pla238 023-050:34:7t-284:  0456I t.enso-for023-07-28 05:34:46.764499:0 I7m/cpu_:3-28 05:34:447:46.6457176:6 4I.61r flotew9nsorff/cor:lo I etew en/atplatformu/cre_guardotensorr.cc:14ef//cp7llow/core/pp6ula4504at:f_torf sorflIform/cpum_fo2ewature_gu/2/]cao Thrrd2eei/a0p022scp33tl.at-0f our7--u28 0m5_:34:46f /ctepTe.0n77nsoru-eatf6c4u995_lcf:e1a:r I4t2u 2e8_ ]re_ g0tTghuiarduse Tn5ra.ccresoen_gso:srufaloodr.Fclcr34:r14Fw/dc2loo.:]oocw46.:7wr ebw /bi6/ p1l4ninaatr2ary] coT5f02o1h iyics:s r rm/co:e p142]t/iT ens pliatTpuhThmifsis Tizorme_fdeo r/F opast icenpTul_tfuIe ntmeeswsith oniozredowFl broes rin_ogFwnarwulaorryi owf lboted .wihbc co:14iAPin2s/ cnoa]oIrre/pnary is op e paThis TetnAlDeeatitsotform/pirucm mFireizlp_uNezo_feegwyural N id wiseatur  etuPI e_garduaoptbiDeeprd..ccinamicc: :142]d zed1 wNeural42 ]i thThirThs  yth NeTwiso Te is oontworersn oneAPIkeptAwn sPiI Lko tLhi moniezeiribd wAbraFrDei oly (oroewp NrartDee yh oneFep low binaub (oneDNANryeinnary isNePu risral  P Ioptim IaloiD) NzeNeet to uwetwork so DeeLibrareeDptimNpNr izedk wit hNepy ( ) Libdr oou tw tNeruanleaArhriteo   neaPfollowingIuhNDNN)s to ulsey  NCe one e(te  PDUt owork LibrewnoerkDNN)iteA PaIr y tp Deep NenL(hh ural se folNibrary truc tet(e floonoenDeDNNeNwNi)uNr)awlootionork Li ng llowins  to use the ftbNeg  in perfoor ary (oneDNNormanCc)ll PCPU iutouU sie s tthoe  wwofionlelnoswner-kciusstr ntgr uCcPtUitte r ihcea lf oouiLignp cillbrsartyrucotteor n (iotnsh we ing CaCofns teiPnUPiino Uion pn DpNs eirlle:s nf ortN) iruoorwstrucnmsaAncfiong CVPX itUrma eno tctions  iionn-upse r fini n perfoosnscperfoeAte-rrmance-criVrucmancXccri thrmante-crirtitictici2e foions al opertice-criilccal oloa
To enalatnpera ti al opeonpwblirserfortopeecmraana:l  opicnag e-cCr AVePtionst trhXemi:aU  ii tAiVcX2n  AVXo AVnXs2

Ttiinoni:T  so other  eons:AVX AVoX2
To e ops:nablea  AlVXenraabtlions AtV eoXe per2 r uAVna
 Tt,h erme tinacbtuthiXb AVX2
ions iTo ee motno l lihenpierodn Te  oth nrofneenrp eorateipessoroaoabr al:b  tns, rehte thle emmanceions, rere inb-tbFmA uichuliow wil dVolr eXmttii  dhT the AVX entsnaT2hic ip
eTeoaon othrlF opertahlnprsorFloeoeroto rwr ow wit ppere nhirioa tw the appoatie comnpoerpioable rlith s:  AVXthe apat themperaAe ri nf pinoost,orpVh renrsX,tei onblr oopperi2i
aaatgTsu,i rse.or eebnabuillbdr
ueil lcated  tTheemd  iT ectoeonmspim nilopnTsorFnee ioltlorr Ffllownhsoeer sawrf, g wsi.
th the appropl rebuagswri o.
oarte ciFpild TensorFlow wiotth the appropriate chlow with the a the appropriateerations, rebuild TensorFlow with the appropriate compimpiler flags.
ompiler flags.
ppropriate compiler flags.
 compiler flags.
ler flags.
2023-07-28 05:34:47.391365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:34:47.396273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:34:47.401931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:34:47.404206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:34:47.404360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForc20e RTX 3070, pci bus id: 00023-07-28 00:01:00.0, compute capabil5:34ity: 8.6
:47.404443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:34:47.442601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:34:47.443544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   200 | performance: 1.1 | accuracy: 0.36 | loss: 1.95
update: 10/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 1.2 | accuracy: 0.44 | loss: 1.86
update: 15/2000, 耗时:0.00分/0.04分 | step:   600 | performance: 2.4 | accuracy: 0.47 | loss: 1.36
update: 20/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 1.6 | accuracy: 0.41 | loss: 1.34
update: 25/2000, 耗时:0.00分/0.06分 | step:  1000 | performance: 1.7 | accuracy: 0.39 | loss: 0.79
update: 30/2000, 耗时:0.00分/0.07分 | step:  1200 | performance: 1.6 | accuracy: 0.37 | loss: 0.77
update: 35/2000, 耗时:0.00分/0.08分 | step:  1400 | performance: 3.1 | accuracy: 0.40 | loss: 1.21
update: 40/2000, 耗时:0.00分/0.08分 | step:  1600 | performance: 2.5 | accuracy: 0.36 | loss: 1.27
update: 45/2000, 耗时:0.00分/0.09分 | step:  1800 | performance: 2.1 | accuracy: 0.37 | loss: 0.97
update: 50/2000, 耗时:0.00分/0.10分 | step:  2000 | performance: 1.6 | accuracy: 0.36 | loss: 3.41
update: 55/2000, 耗时:0.00分/0.11分 | step:  2200 | performance: 1.8 | accuracy: 0.37 | loss: 3.69
update: 60/2000, 耗时:0.00分/0.12分 | step:  2400 | performance: 1.4 | accuracy: 0.36 | loss: 0.20
update: 65/2000, 耗时:0.00分/0.13分 | step:  2600 | performance: 3.0 | accuracy: 0.37 | loss: 3.69
update: 70/2000, 耗时:0.00分/0.14分 | step:  2800 | performance: 2.5 | accuracy: 0.37 | loss: 0.70
update: 75/2000, 耗时:0.00分/0.15分 | step:  3000 | performance: 2.5 | accuracy: 0.36 | loss: 0.50
update: 80/2000, 耗时:0.00分/0.16分 | step:  3200 | performance: 3.0 | accuracy: 0.36 | loss: 1.36
update: 85/2000, 耗时:0.00分/0.17分 | step:  3400 | performance: 2.4 | accuracy: 0.36 | loss: 0.57
update: 90/2000, 耗时:0.00分/0.18分 | step:  3600 | performance: 3.0 | accuracy: 0.36 | loss: 3.06
update: 95/2000, 耗时:0.00分/0.19分 | step:  3800 | performance: 2.9 | accuracy: 0.35 | loss: 0.20
update:100/2000, 耗时:0.00分/0.20分 | step:  4000 | performance: 3.4 | accuracy: 0.35 | loss: 0.96
update:105/2000, 耗时:0.00分/0.21分 | step:  4200 | performance: 5.9 | accuracy: 0.36 | loss: 0.51
update:110/2000, 耗时:0.00分/0.22分 | step:  4400 | performance: 9.3 | accuracy: 0.36 | loss: 0.49
update:115/2000, 耗时:0.00分/0.23分 | step:  4600 | performance: 25.0 | accuracy: 0.37 | loss: 3.39
update:120/2000, 耗时:0.00分/0.24分 | step:  4800 | performance: 12.2 | accuracy: 0.37 | loss: 3.91
update:125/2000, 耗时:0.00分/0.25分 | step:  5000 | performance: 9.4 | accuracy: 0.37 | loss: 4.23
update:130/2000, 耗时:0.00分/0.26分 | step:  5200 | performance: 14.0 | accuracy: 0.37 | loss: 0.75
update:135/2000, 耗时:0.00分/0.27分 | step:  5400 | performance: 17.0 | accuracy: 0.37 | loss: 3.05
update:140/2000, 耗时:0.00分/0.28分 | step:  5600 | performance: 13.5 | accuracy: 0.38 | loss: 1.70
update:145/2000, 耗时:0.00分/0.29分 | step:  5800 | performance: 9.0 | accuracy: 0.38 | loss: 1.30
update:150/2000, 耗时:0.00分/0.30分 | step:  6000 | performance: 8.1 | accuracy: 0.37 | loss: 0.61
update:155/2000, 耗时:0.00分/0.31分 | step:  6200 | performance: 7.3 | accuracy: 0.37 | loss: 0.52
update:160/2000, 耗时:0.00分/0.32分 | step:  6400 | performance: 2.1 | accuracy: 0.36 | loss: 1.84
update:165/2000, 耗时:0.00分/0.33分 | step:  6600 | performance: 2.1 | accuracy: 0.35 | loss: 0.28
update:170/2000, 耗时:0.00分/0.34分 | step:  6800 | performance: 2.0 | accuracy: 0.34 | loss: -0.00
update:175/2000, 耗时:0.00分/0.35分 | step:  7000 | performance: 2.0 | accuracy: 0.33 | loss: 0.22
update:180/2000, 耗时:0.00分/0.36分 | step:  7200 | performance: 1.9 | accuracy: 0.33 | loss: 0.87
update:185/2000, 耗时:0.00分/0.37分 | step:  7400 | performance: 1.6 | accuracy: 0.33 | loss: 0.77
update:190/2000, 耗时:0.00分/0.38分 | step:  7600 | performance: 2.0 | accuracy: 0.33 | loss: 0.69
update:195/2000, 耗时:0.00分/0.39分 | step:  7800 | performance: 3.8 | accuracy: 0.34 | loss: 9.42
update:200/2000, 耗时:0.00分/0.40分 | step:  8000 | performance: 3.5 | accuracy: 0.34 | loss: 7.55
update:205/2000, 耗时:0.00分/0.41分 | step:  8200 | performance: 1.7 | accuracy: 0.34 | loss: 3.81
update:210/2000, 耗时:0.00分/0.42分 | step:  8400 | performance: 3.1 | accuracy: 0.35 | loss: 1.36
update:215/2000, 耗时:0.00分/0.43分 | step:  8600 | performance: 1.6 | accuracy: 0.34 | loss: 0.97
update:220/2000, 耗时:0.00分/0.44分 | step:  8800 | performance: 1.3 | accuracy: 0.34 | loss: 3.37
update:225/2000, 耗时:0.00分/0.45分 | step:  9000 | performance: 1.8 | accuracy: 0.35 | loss: 0.78
update:230/2000, 耗时:0.00分/0.46分 | step:  9200 | performance: 0.9 | accuracy: 0.34 | loss: 1.95
update:235/2000, 耗时:0.00分/0.47分 | step:  9400 | performance: 0.9 | accuracy: 0.34 | loss: 1.63
update:240/2000, 耗时:0.00分/0.48分 | step:  9600 | performance: 0.9 | accuracy: 0.34 | loss: 1.29
update:245/2000, 耗时:0.00分/0.49分 | step:  9800 | performance: 0.4 | accuracy: 0.33 | loss: 0.02
update:250/2000, 耗时:0.00分/0.50分 | step: 10000 | performance: 0.5 | accuracy: 0.34 | loss: 1.10
update:255/2000, 耗时:0.00分/0.51分 | step: 10200 | performance: 0.7 | accuracy: 0.34 | loss: 6.72
update:260/2000, 耗时:0.00分/0.52分 | step: 10400 | performance: 0.8 | accuracy: 0.34 | loss: 2.24
update:265/2000, 耗时:0.00分/0.53分 | step: 10600 | performance: 0.7 | accuracy: 0.34 | loss: 4.20
update:270/2000, 耗时:0.00分/0.54分 | step: 10800 | performance: 0.7 | accuracy: 0.35 | loss: 4.46
update:275/2000, 耗时:0.00分/0.55分 | step: 11000 | performance: 0.3 | accuracy: 0.34 | loss: 0.18
update:280/2000, 耗时:0.00分/0.56分 | step: 11200 | performance: 0.2 | accuracy: 0.34 | loss: 3.61
update:285/2000, 耗时:0.00分/0.57分 | step: 11400 | performance: 0.2 | accuracy: 0.33 | loss: 0.17
update:290/2000, 耗时:0.00分/0.58分 | step: 11600 | performance: 0.2 | accuracy: 0.33 | loss: 0.18
update:295/2000, 耗时:0.00分/0.59分 | step: 11800 | performance: 0.2 | accuracy: 0.32 | loss: 0.15
update:300/2000, 耗时:0.00分/0.60分 | step: 12000 | performance: 0.1 | accuracy: 0.32 | loss: 11.10
update:305/2000, 耗时:0.00分/0.61分 | step: 12200 | performance: 0.1 | accuracy: 0.31 | loss: 0.04
update:310/2000, 耗时:0.00分/0.62分 | step: 12400 | performance: 0.1 | accuracy: 0.31 | loss: 0.00
update:315/2000, 耗时:0.00分/0.63分 | step: 12600 | performance: 0.1 | accuracy: 0.30 | loss: 0.07
update:320/2000, 耗时:0.00分/0.64分 | step: 12800 | performance: 0.1 | accuracy: 0.30 | loss: 0.00
update:325/2000, 耗时:0.00分/0.65分 | step: 13000 | performance: 0.1 | accuracy: 0.30 | loss: 0.00
update:330/2000, 耗时:0.00分/0.66分 | step: 13200 | performance: 0.1 | accuracy: 0.29 | loss: -0.00
update:335/2000, 耗时:0.00分/0.67分 | step: 13400 | performance: 0.1 | accuracy: 0.29 | loss: 0.00
update:340/2000, 耗时:0.00分/0.69分 | step: 13600 | performance: 0.1 | accuracy: 0.28 | loss: -0.00
update:345/2000, 耗时:0.00分/0.70分 | step: 13800 | performance: 0.1 | accuracy: 0.28 | loss: 0.01
update:350/2000, 耗时:0.00分/0.71分 | step: 14000 | performance: 0.1 | accuracy: 0.28 | loss: 0.00
update:355/2000, 耗时:0.00分/0.72分 | step: 14200 | performance: 0.1 | accuracy: 0.27 | loss: 0.00
update:360/2000, 耗时:0.00分/0.73分 | step: 14400 | performance: 0.1 | accuracy: 0.27 | loss: 0.00
update:365/2000, 耗时:0.00分/0.74分 | step: 14600 | performance: 0.1 | accuracy: 0.27 | loss: 0.16
update:370/2000, 耗时:0.00分/0.75分 | step: 14800 | performance: 0.1 | accuracy: 0.26 | loss: 0.00
update:375/2000, 耗时:0.00分/0.76分 | step: 15000 | performance: 0.1 | accuracy: 0.26 | loss: 0.00
update:380/2000, 耗时:0.00分/0.77分 | step: 15200 | performance: 0.1 | accuracy: 0.26 | loss: 0.23
update:385/2000, 耗时:0.00分/0.78分 | step: 15400 | performance: 0.1 | accuracy: 0.26 | loss: 0.12
update:390/2000, 耗时:0.00分/0.79分 | step: 15600 | performance: 0.1 | accuracy: 0.25 | loss: 0.00
update:395/2000, 耗时:0.00分/0.80分 | step: 15800 | performance: 0.1 | accuracy: 0.25 | loss: 0.00
update:400/2000, 耗时:0.00分/0.81分 | step: 16000 | performance: 0.1 | accuracy: 0.25 | loss: 0.00
update:405/2000, 耗时:0.00分/0.82分 | step: 16200 | performance: 0.1 | accuracy: 0.25 | loss: 0.02
update:410/2000, 耗时:0.00分/0.83分 | step: 16400 | performance: 0.1 | accuracy: 0.24 | loss: 0.02
update:415/2000, 耗时:0.00分/0.84分 | step: 16600 | performance: 0.1 | accuracy: 0.24 | loss: 0.00
update:420/2000, 耗时:0.00分/0.85分 | step: 16800 | performance: 0.1 | accuracy: 0.24 | loss: 0.06
update:425/2000, 耗时:0.00分/0.86分 | step: 17000 | performance: 0.1 | accuracy: 0.23 | loss: 0.00
update:430/2000, 耗时:0.00分/0.87分 | step: 17200 | performance: 0.1 | accuracy: 0.23 | loss: 0.00
update:435/2000, 耗时:0.00分/0.88分 | step: 17400 | performance: 0.1 | accuracy: 0.23 | loss: 0.00
update:440/2000, 耗时:0.00分/0.89分 | step: 17600 | performance: 0.1 | accuracy: 0.23 | loss: 0.00
update:445/2000, 耗时:0.00分/0.90分 | step: 17800 | performance: 0.1 | accuracy: 0.22 | loss: 0.14
update:450/2000, 耗时:0.00分/0.91分 | step: 18000 | performance: 0.1 | accuracy: 0.22 | loss: 0.00
update:455/2000, 耗时:0.00分/0.92分 | step: 18200 | performance: 0.1 | accuracy: 0.22 | loss: 0.01
update:460/2000, 耗时:0.00分/0.93分 | step: 18400 | performance: 0.1 | accuracy: 0.22 | loss: 0.00
update:465/2000, 耗时:0.00分/0.94分 | step: 18600 | performance: 0.1 | accuracy: 0.22 | loss: 0.00
update:470/2000, 耗时:0.00分/0.95分 | step: 18800 | performance: 0.1 | accuracy: 0.21 | loss: 0.00
update:475/2000, 耗时:0.00分/0.96分 | step: 19000 | performance: 0.1 | accuracy: 0.21 | loss: 0.00
update:480/2000, 耗时:0.00分/0.97分 | step: 19200 | performance: 0.1 | accuracy: 0.21 | loss: 0.00
update:485/2000, 耗时:0.00分/0.98分 | step: 19400 | performance: 0.1 | accuracy: 0.21 | loss: 0.10
update:490/2000, 耗时:0.00分/0.99分 | step: 19600 | performance: 0.1 | accuracy: 0.21 | loss: 0.02
update:495/2000, 耗时:0.00分/1.00分 | step: 19800 | performance: 0.1 | accuracy: 0.21 | loss: 1.44
update:500/2000, 耗时:0.00分/1.01分 | step: 20000 | performance: 0.0 | accuracy: 0.20 | loss: 0.00
update:505/2000, 耗时:0.00分/1.02分 | step: 20200 | performance: 0.0 | accuracy: 0.20 | loss: 0.00
update:510/2000, 耗时:0.00分/1.03分 | step: 20400 | performance: 0.0 | accuracy: 0.20 | loss: 0.00
update:515/2000, 耗时:0.00分/1.04分 | step: 20600 | performance: 0.0 | accuracy: 0.20 | loss: 0.10
update:520/2000, 耗时:0.00分/1.05分 | step: 20800 | performance: 0.0 | accuracy: 0.20 | loss: 0.05
update:525/2000, 耗时:0.00分/1.06分 | step: 21000 | performance: 0.0 | accuracy: 0.20 | loss: 0.06
update:530/2000, 耗时:0.00分/1.07分 | step: 21200 | performance: 0.0 | accuracy: 0.19 | loss: 0.14
update:535/2000, 耗时:0.00分/1.08分 | step: 21400 | performance: 0.0 | accuracy: 0.20 | loss: 1.57
update:540/2000, 耗时:0.00分/1.09分 | step: 21600 | performance: 0.0 | accuracy: 0.20 | loss: 1.72
update:545/2000, 耗时:0.00分/1.10分 | step: 21800 | performance: 0.0 | accuracy: 0.20 | loss: 1.64
update:550/2000, 耗时:0.00分/1.11分 | step: 22000 | performance: 0.0 | accuracy: 0.20 | loss: 3.01
update:555/2000, 耗时:0.00分/1.12分 | step: 22200 | performance: 0.0 | accuracy: 0.20 | loss: 0.01
update:560/2000, 耗时:0.00分/1.13分 | step: 22400 | performance: 0.0 | accuracy: 0.20 | loss: 0.05
update:565/2000, 耗时:0.00分/1.14分 | step: 22600 | performance: 0.0 | accuracy: 0.20 | loss: 1.87
update:570/2000, 耗时:0.00分/1.15分 | step: 22800 | performance: 0.0 | accuracy: 0.20 | loss: 1.87
update:575/2000, 耗时:0.00分/1.16分 | step: 23000 | performance: 0.0 | accuracy: 0.20 | loss: 0.03
update:580/2000, 耗时:0.00分/1.17分 | step: 23200 | performance: 0.0 | accuracy: 0.20 | loss: 0.49
update:585/2000, 耗时:0.00分/1.18分 | step: 23400 | performance: 0.0 | accuracy: 0.20 | loss: 0.02
update:590/2000, 耗时:0.00分/1.19分 | step: 23600 | performance: 0.0 | accuracy: 0.20 | loss: 0.05
update:595/2000, 耗时:0.00分/1.20分 | step: 23800 | performance: 0.0 | accuracy: 0.20 | loss: 0.04
update:600/2000, 耗时:0.00分/1.21分 | step: 24000 | performance: 0.0 | accuracy: 0.20 | loss: 0.44
update:605/2000, 耗时:0.00分/1.22分 | step: 24200 | performance: 0.0 | accuracy: 0.20 | loss: 0.36
update:610/2000, 耗时:0.00分/1.23分 | step: 24400 | performance: 0.0 | accuracy: 0.20 | loss: 1.70
update:615/2000, 耗时:0.00分/1.24分 | step: 24600 | performance: 0.1 | accuracy: 0.20 | loss: 0.70
update:620/2000, 耗时:0.00分/1.25分 | step: 24800 | performance: 0.1 | accuracy: 0.20 | loss: 2.59
update:625/2000, 耗时:0.00分/1.26分 | step: 25000 | performance: 0.1 | accuracy: 0.20 | loss: 1.45
update:630/2000, 耗时:0.00分/1.27分 | step: 25200 | performance: 0.7 | accuracy: 0.21 | loss: 0.64
update:635/2000, 耗时:0.00分/1.28分 | step: 25400 | performance: 1.1 | accuracy: 0.21 | loss: 8.43
update:640/2000, 耗时:0.00分/1.29分 | step: 25600 | performance: 0.7 | accuracy: 0.21 | loss: 7.70
update:645/2000, 耗时:0.00分/1.30分 | step: 25800 | performance: 0.4 | accuracy: 0.21 | loss: 2.86
update:650/2000, 耗时:0.00分/1.31分 | step: 26000 | performance: 0.4 | accuracy: 0.21 | loss: 5.33
update:655/2000, 耗时:0.00分/1.32分 | step: 26200 | performance: 0.8 | accuracy: 0.22 | loss: 0.66
update:660/2000, 耗时:0.00分/1.33分 | step: 26400 | performance: 1.5 | accuracy: 0.22 | loss: 1.09
update:665/2000, 耗时:0.00分/1.34分 | step: 26600 | performance: 1.4 | accuracy: 0.22 | loss: 0.38
update:670/2000, 耗时:0.00分/1.35分 | step: 26800 | performance: 1.5 | accuracy: 0.22 | loss: 0.49
update:675/2000, 耗时:0.00分/1.36分 | step: 27000 | performance: 1.6 | accuracy: 0.23 | loss: 1.76
update:680/2000, 耗时:0.00分/1.37分 | step: 27200 | performance: 1.2 | accuracy: 0.23 | loss: 5.79
update:685/2000, 耗时:0.00分/1.38分 | step: 27400 | performance: 1.2 | accuracy: 0.23 | loss: 2.40
update:690/2000, 耗时:0.00分/1.39分 | step: 27600 | performance: 4.1 | accuracy: 0.23 | loss: 0.78
update:695/2000, 耗时:0.00分/1.40分 | step: 27800 | performance: 3.5 | accuracy: 0.23 | loss: 2.08
update:700/2000, 耗时:0.00分/1.41分 | step: 28000 | performance: 3.0 | accuracy: 0.23 | loss: 1.85
update:705/2000, 耗时:0.00分/1.42分 | step: 28200 | performance: 4.1 | accuracy: 0.23 | loss: 1.67
Saving PPO weights in both H5 format and checkpoint @ update:708 
update:710/2000, 耗时:0.00分/1.43分 | step: 28400 | performance: 1.4 | accuracy: 0.54 | loss: 2.57
update:715/2000, 耗时:0.00分/1.44分 | step: 28600 | performance: 3.0 | accuracy: 0.58 | loss: 6.64
update:720/2000, 耗时:0.00分/1.45分 | step: 28800 | performance: 11.4 | accuracy: 0.65 | loss: 1.42
update:725/2000, 耗时:0.00分/1.46分 | step: 29000 | performance: 4.8 | accuracy: 0.58 | loss: 8.86
update:730/2000, 耗时:0.00分/1.47分 | step: 29200 | performance: 2.4 | accuracy: 0.50 | loss: 0.40
update:735/2000, 耗时:0.00分/1.48分 | step: 29400 | performance: 2.1 | accuracy: 0.50 | loss: 3.18
update:740/2000, 耗时:0.00分/1.49分 | step: 29600 | performance: 4.2 | accuracy: 0.53 | loss: 1.00
update:745/2000, 耗时:0.00分/1.50分 | step: 29800 | performance: 7.3 | accuracy: 0.53 | loss: 4.09
update:750/2000, 耗时:0.00分/1.51分 | step: 30000 | performance: 19.4 | accuracy: 0.56 | loss: 1.00
update:755/2000, 耗时:0.00分/1.52分 | step: 30200 | performance: 31.5 | accuracy: 0.56 | loss: 2.34
update:760/2000, 耗时:0.00分/1.53分 | step: 30400 | performance: 21.1 | accuracy: 0.53 | loss: 3.89
update:765/2000, 耗时:0.00分/1.54分 | step: 30600 | performance: 7.9 | accuracy: 0.51 | loss: 2.47
update:770/2000, 耗时:0.00分/1.55分 | step: 30800 | performance: 11.9 | accuracy: 0.52 | loss: 5.25
update:775/2000, 耗时:0.00分/1.56分 | step: 31000 | performance: 24.2 | accuracy: 0.53 | loss: 3.34
update:780/2000, 耗时:0.00分/1.57分 | step: 31200 | performance: 14.7 | accuracy: 0.51 | loss: 4.29
update:785/2000, 耗时:0.00分/1.58分 | step: 31400 | performance: 29.1 | accuracy: 0.52 | loss: 1.03
update:790/2000, 耗时:0.00分/1.59分 | step: 31600 | performance: 20.9 | accuracy: 0.51 | loss: 1.04
update:795/2000, 耗时:0.00分/1.59分 | step: 31800 | performance: 22.9 | accuracy: 0.51 | loss: 1.66
update:800/2000, 耗时:0.00分/1.60分 | step: 32000 | performance: 22.3 | accuracy: 0.51 | loss: 2.98
update:805/2000, 耗时:0.00分/1.61分 | step: 32200 | performance: 30.2 | accuracy: 0.53 | loss: 3.51
update:810/2000, 耗时:0.00分/1.62分 | step: 32400 | performance: 28.4 | accuracy: 0.51 | loss: 0.52
update:815/2000, 耗时:0.00分/1.63分 | step: 32600 | performance: 421.8 | accuracy: 0.54 | loss: 6.36
update:820/2000, 耗时:0.00分/1.64分 | step: 32800 | performance: 1188.0 | accuracy: 0.54 | loss: 7.04
update:825/2000, 耗时:0.00分/1.65分 | step: 33000 | performance: 667.5 | accuracy: 0.54 | loss: 11.52
update:830/2000, 耗时:0.00分/1.66分 | step: 33200 | performance: 792.8 | accuracy: 0.54 | loss: 0.69
update:835/2000, 耗时:0.00分/1.67分 | step: 33400 | performance: 1130.1 | accuracy: 0.54 | loss: 0.90
update:840/2000, 耗时:0.00分/1.68分 | step: 33600 | performance: 1162.8 | accuracy: 0.53 | loss: 0.55
update:845/2000, 耗时:0.00分/1.69分 | step: 33800 | performance: 1338.9 | accuracy: 0.53 | loss: 1.05
update:850/2000, 耗时:0.00分/1.70分 | step: 34000 | performance: 670.8 | accuracy: 0.53 | loss: 5.01
update:855/2000, 耗时:0.00分/1.71分 | step: 34200 | performance: 872.6 | accuracy: 0.53 | loss: 0.88
update:860/2000, 耗时:0.00分/1.72分 | step: 34400 | performance: 673.4 | accuracy: 0.52 | loss: 3.65
update:865/2000, 耗时:0.00分/1.73分 | step: 34600 | performance: 592.7 | accuracy: 0.51 | loss: 3.91
update:870/2000, 耗时:0.00分/1.74分 | step: 34800 | performance: 178.2 | accuracy: 0.50 | loss: 0.37
update:875/2000, 耗时:0.00分/1.75分 | step: 35000 | performance: 199.8 | accuracy: 0.49 | loss: 2.51
update:880/2000, 耗时:0.00分/1.76分 | step: 35200 | performance: 287.4 | accuracy: 0.50 | loss: 0.49
update:885/2000, 耗时:0.00分/1.77分 | step: 35400 | performance: 1466.2 | accuracy: 0.51 | loss: 1.50
update:890/2000, 耗时:0.00分/1.78分 | step: 35600 | performance: 2700.6 | accuracy: 0.51 | loss: 9.12
update:895/2000, 耗时:0.00分/1.79分 | step: 35800 | performance: 1971.4 | accuracy: 0.51 | loss: 2.37
update:900/2000, 耗时:0.00分/1.80分 | step: 36000 | performance: 18661.3 | accuracy: 0.52 | loss: 5.23
update:905/2000, 耗时:0.00分/1.81分 | step: 36200 | performance: 17380.5 | accuracy: 0.52 | loss: 1.15
update:910/2000, 耗时:0.00分/1.82分 | step: 36400 | performance: 9456.8 | accuracy: 0.52 | loss: 1.83
update:915/2000, 耗时:0.00分/1.83分 | step: 36600 | performance: 6859.5 | accuracy: 0.51 | loss: 3.68
update:920/2000, 耗时:0.00分/1.84分 | step: 36800 | performance: 7396.3 | accuracy: 0.51 | loss: 9.18
update:925/2000, 耗时:0.00分/1.85分 | step: 37000 | performance: 6054.5 | accuracy: 0.51 | loss: 0.84
update:930/2000, 耗时:0.00分/1.86分 | step: 37200 | performance: 6375.0 | accuracy: 0.51 | loss: 3.20
update:935/2000, 耗时:0.00分/1.87分 | step: 37400 | performance: 5134.6 | accuracy: 0.50 | loss: 1.57
update:940/2000, 耗时:0.00分/1.88分 | step: 37600 | performance: 6413.6 | accuracy: 0.50 | loss: 0.28
update:945/2000, 耗时:0.00分/1.89分 | step: 37800 | performance: 6145.5 | accuracy: 0.50 | loss: 3.49
update:950/2000, 耗时:0.00分/1.90分 | step: 38000 | performance: 2880.5 | accuracy: 0.50 | loss: 3.99
update:955/2000, 耗时:0.00分/1.91分 | step: 38200 | performance: 3391.8 | accuracy: 0.49 | loss: 3.83
update:960/2000, 耗时:0.00分/1.92分 | step: 38400 | performance: 9983.8 | accuracy: 0.50 | loss: 7.01
update:965/2000, 耗时:0.00分/1.93分 | step: 38600 | performance: 11026.2 | accuracy: 0.50 | loss: 0.90
update:970/2000, 耗时:0.00分/1.94分 | step: 38800 | performance: 14796.4 | accuracy: 0.51 | loss: 2.41
update:975/2000, 耗时:0.00分/1.95分 | step: 39000 | performance: 10586.2 | accuracy: 0.50 | loss: 0.24
update:980/2000, 耗时:0.00分/1.96分 | step: 39200 | performance: 5539.6 | accuracy: 0.49 | loss: 0.52
update:985/2000, 耗时:0.00分/1.97分 | step: 39400 | performance: 5351.7 | accuracy: 0.49 | loss: 0.96
update:990/2000, 耗时:0.00分/1.98分 | step: 39600 | performance: 3405.6 | accuracy: 0.48 | loss: 1.19
update:995/2000, 耗时:0.00分/1.99分 | step: 39800 | performance: 3155.7 | accuracy: 0.48 | loss: 1.36
update:1000/2000, 耗时:0.00分/2.00分 | step: 40000 | performance: 1366.0 | accuracy: 0.48 | loss: 1.77
update:1005/2000, 耗时:0.00分/2.01分 | step: 40200 | performance: 1511.3 | accuracy: 0.48 | loss: 4.09
update:1010/2000, 耗时:0.00分/2.02分 | step: 40400 | performance: 1604.8 | accuracy: 0.47 | loss: 0.11
update:1015/2000, 耗时:0.00分/2.03分 | step: 40600 | performance: 1492.5 | accuracy: 0.46 | loss: 0.08
update:1020/2000, 耗时:0.00分/2.04分 | step: 40800 | performance: 1473.9 | accuracy: 0.46 | loss: 0.89
update:1025/2000, 耗时:0.00分/2.05分 | step: 41000 | performance: 840.9 | accuracy: 0.45 | loss: 0.17
update:1030/2000, 耗时:0.00分/2.06分 | step: 41200 | performance: 1258.3 | accuracy: 0.46 | loss: 3.67
update:1035/2000, 耗时:0.00分/2.07分 | step: 41400 | performance: 1100.0 | accuracy: 0.46 | loss: 1.43
update:1040/2000, 耗时:0.00分/2.08分 | step: 41600 | performance: 1404.3 | accuracy: 0.46 | loss: 2.85
update:1045/2000, 耗时:0.00分/2.09分 | step: 41800 | performance: 1129.9 | accuracy: 0.46 | loss: 1.16
update:1050/2000, 耗时:0.00分/2.10分 | step: 42000 | performance: 849.8 | accuracy: 0.45 | loss: 2.03
update:1055/2000, 耗时:0.00分/2.11分 | step: 42200 | performance: 761.7 | accuracy: 0.45 | loss: 1.15
update:1060/2000, 耗时:0.00分/2.12分 | step: 42400 | performance: 1750.0 | accuracy: 0.46 | loss: 5.88
update:1065/2000, 耗时:0.00分/2.13分 | step: 42600 | performance: 2383.1 | accuracy: 0.46 | loss: 2.38
update:1070/2000, 耗时:0.00分/2.14分 | step: 42800 | performance: 2333.0 | accuracy: 0.46 | loss: 0.95
update:1075/2000, 耗时:0.00分/2.15分 | step: 43000 | performance: 1068.1 | accuracy: 0.46 | loss: 8.53
update:1080/2000, 耗时:0.00分/2.16分 | step: 43200 | performance: 1351.7 | accuracy: 0.46 | loss: 3.21
update:1085/2000, 耗时:0.00分/2.17分 | step: 43400 | performance: 1203.4 | accuracy: 0.46 | loss: 1.63
update:1090/2000, 耗时:0.00分/2.18分 | step: 43600 | performance: 1436.7 | accuracy: 0.46 | loss: 3.47
update:1095/2000, 耗时:0.00分/2.19分 | step: 43800 | performance: 3114.2 | accuracy: 0.47 | loss: 0.93
update:1100/2000, 耗时:0.00分/2.20分 | step: 44000 | performance: 7968.9 | accuracy: 0.47 | loss: 4.47
update:1105/2000, 耗时:0.00分/2.21分 | step: 44200 | performance: 20113.0 | accuracy: 0.47 | loss: 2.17
update:1110/2000, 耗时:0.00分/2.22分 | step: 44400 | performance: 29087.1 | accuracy: 0.48 | loss: 1.46
update:1115/2000, 耗时:0.00分/2.23分 | step: 44600 | performance: 28624.7 | accuracy: 0.48 | loss: 2.00
update:1120/2000, 耗时:0.00分/2.24分 | step: 44800 | performance: 164023.5 | accuracy: 0.48 | loss: 3.26
update:1125/2000, 耗时:0.00分/2.25分 | step: 45000 | performance: 2058697.2 | accuracy: 0.49 | loss: 4.15
update:1130/2000, 耗时:0.00分/2.26分 | step: 45200 | performance: 873349.1 | accuracy: 0.48 | loss: 17.87
update:1135/2000, 耗时:0.00分/2.27分 | step: 45400 | performance: 881677.9 | accuracy: 0.48 | loss: 0.91
update:1140/2000, 耗时:0.00分/2.28分 | step: 45600 | performance: 6148894.7 | accuracy: 0.49 | loss: 0.61
update:1145/2000, 耗时:0.00分/2.29分 | step: 45800 | performance: 4994453.9 | accuracy: 0.49 | loss: 11.09
update:1150/2000, 耗时:0.00分/2.30分 | step: 46000 | performance: 15709929.4 | accuracy: 0.49 | loss: 2.13
update:1155/2000, 耗时:0.00分/2.31分 | step: 46200 | performance: 11707380.9 | accuracy: 0.49 | loss: 7.05
update:1160/2000, 耗时:0.00分/2.32分 | step: 46400 | performance: 17950415.0 | accuracy: 0.49 | loss: 1.34
update:1165/2000, 耗时:0.00分/2.33分 | step: 46600 | performance: 17350896.3 | accuracy: 0.50 | loss: 10.54
update:1170/2000, 耗时:0.00分/2.34分 | step: 46800 | performance: 13428231.7 | accuracy: 0.49 | loss: 0.81
update:1175/2000, 耗时:0.00分/2.35分 | step: 47000 | performance: 8536618.7 | accuracy: 0.49 | loss: 10.39
update:1180/2000, 耗时:0.00分/2.37分 | step: 47200 | performance: 2283187.7 | accuracy: 0.49 | loss: 4.15
update:1185/2000, 耗时:0.00分/2.38分 | step: 47400 | performance: 3250828.5 | accuracy: 0.49 | loss: 2.49
update:1190/2000, 耗时:0.00分/2.39分 | step: 47600 | performance: 2150995.1 | accuracy: 0.49 | loss: 0.58
update:1195/2000, 耗时:0.00分/2.40分 | step: 47800 | performance: 1656579.5 | accuracy: 0.48 | loss: 3.78
update:1200/2000, 耗时:0.00分/2.41分 | step: 48000 | performance: 2145262.3 | accuracy: 0.49 | loss: 4.64
update:1205/2000, 耗时:0.00分/2.42分 | step: 48200 | performance: 794320.8 | accuracy: 0.48 | loss: 6.82
update:1210/2000, 耗时:0.00分/2.43分 | step: 48400 | performance: 452726.1 | accuracy: 0.48 | loss: 1.70
update:1215/2000, 耗时:0.00分/2.44分 | step: 48600 | performance: 261426.9 | accuracy: 0.48 | loss: 2.47
update:1220/2000, 耗时:0.00分/2.45分 | step: 48800 | performance: 234780.2 | accuracy: 0.48 | loss: 2.72
update:1225/2000, 耗时:0.00分/2.46分 | step: 49000 | performance: 140184.2 | accuracy: 0.47 | loss: 2.28
update:1230/2000, 耗时:0.00分/2.47分 | step: 49200 | performance: 121563.8 | accuracy: 0.48 | loss: 1.02
update:1235/2000, 耗时:0.00分/2.48分 | step: 49400 | performance: 94976.5 | accuracy: 0.47 | loss: 1.88
update:1240/2000, 耗时:0.00分/2.49分 | step: 49600 | performance: 196344.6 | accuracy: 0.48 | loss: 3.24
update:1245/2000, 耗时:0.00分/2.50分 | step: 49800 | performance: 189834.5 | accuracy: 0.48 | loss: 0.52
update:1250/2000, 耗时:0.00分/2.51分 | step: 50000 | performance: 178046.6 | accuracy: 0.48 | loss: 7.33
update:1255/2000, 耗时:0.00分/2.52分 | step: 50200 | performance: 100605.6 | accuracy: 0.48 | loss: 1.99
update:1260/2000, 耗时:0.00分/2.53分 | step: 50400 | performance: 43055.4 | accuracy: 0.47 | loss: 1.20
update:1265/2000, 耗时:0.00分/2.55分 | step: 50600 | performance: 59750.9 | accuracy: 0.47 | loss: 1.59
update:1270/2000, 耗时:0.00分/2.56分 | step: 50800 | performance: 40520.4 | accuracy: 0.47 | loss: 2.19
update:1275/2000, 耗时:0.00分/2.57分 | step: 51000 | performance: 57209.8 | accuracy: 0.47 | loss: 3.02
update:1280/2000, 耗时:0.00分/2.58分 | step: 51200 | performance: 79291.8 | accuracy: 0.47 | loss: 2.10
update:1285/2000, 耗时:0.00分/2.59分 | step: 51400 | performance: 65195.8 | accuracy: 0.47 | loss: 0.14
update:1290/2000, 耗时:0.00分/2.60分 | step: 51600 | performance: 103668.0 | accuracy: 0.47 | loss: 0.94
update:1295/2000, 耗时:0.00分/2.61分 | step: 51800 | performance: 54264.1 | accuracy: 0.46 | loss: -0.01
update:1300/2000, 耗时:0.00分/2.62分 | step: 52000 | performance: 51510.0 | accuracy: 0.46 | loss: 0.17
update:1305/2000, 耗时:0.00分/2.63分 | step: 52200 | performance: 49266.6 | accuracy: 0.46 | loss: 0.91
update:1310/2000, 耗时:0.00分/2.64分 | step: 52400 | performance: 56495.6 | accuracy: 0.46 | loss: 0.29
update:1315/2000, 耗时:0.00分/2.65分 | step: 52600 | performance: 52198.9 | accuracy: 0.45 | loss: 0.56
update:1320/2000, 耗时:0.00分/2.66分 | step: 52800 | performance: 74877.2 | accuracy: 0.45 | loss: 2.92
update:1325/2000, 耗时:0.00分/2.67分 | step: 53000 | performance: 89303.2 | accuracy: 0.45 | loss: 0.98
update:1330/2000, 耗时:0.00分/2.68分 | step: 53200 | performance: 75649.4 | accuracy: 0.45 | loss: 1.30
update:1335/2000, 耗时:0.00分/2.69分 | step: 53400 | performance: 325772.3 | accuracy: 0.45 | loss: 5.87
update:1340/2000, 耗时:0.00分/2.70分 | step: 53600 | performance: 472043.3 | accuracy: 0.45 | loss: 4.31
update:1345/2000, 耗时:0.00分/2.71分 | step: 53800 | performance: 491209.6 | accuracy: 0.45 | loss: 4.99
update:1350/2000, 耗时:0.00分/2.72分 | step: 54000 | performance: 246624.7 | accuracy: 0.45 | loss: 1.06
update:1355/2000, 耗时:0.00分/2.73分 | step: 54200 | performance: 208319.7 | accuracy: 0.45 | loss: 1.02
update:1360/2000, 耗时:0.00分/2.74分 | step: 54400 | performance: 239293.8 | accuracy: 0.45 | loss: 5.81
update:1365/2000, 耗时:0.00分/2.75分 | step: 54600 | performance: 488891.6 | accuracy: 0.45 | loss: 1.92
update:1370/2000, 耗时:0.00分/2.76分 | step: 54800 | performance: 313651.3 | accuracy: 0.45 | loss: 2.25
update:1375/2000, 耗时:0.00分/2.77分 | step: 55000 | performance: 610457.9 | accuracy: 0.45 | loss: 0.73
update:1380/2000, 耗时:0.00分/2.78分 | step: 55200 | performance: 493289.1 | accuracy: 0.45 | loss: 1.66
update:1385/2000, 耗时:0.00分/2.79分 | step: 55400 | performance: 592756.0 | accuracy: 0.45 | loss: 3.06
update:1390/2000, 耗时:0.00分/2.80分 | step: 55600 | performance: 406371.5 | accuracy: 0.45 | loss: 3.29
update:1395/2000, 耗时:0.00分/2.81分 | step: 55800 | performance: 1384617.5 | accuracy: 0.45 | loss: 2.99
update:1400/2000, 耗时:0.00分/2.82分 | step: 56000 | performance: 1517814.7 | accuracy: 0.45 | loss: 1.70
update:1405/2000, 耗时:0.00分/2.84分 | step: 56200 | performance: 1272751.6 | accuracy: 0.45 | loss: 2.21
update:1410/2000, 耗时:0.00分/2.85分 | step: 56400 | performance: 1415449.9 | accuracy: 0.45 | loss: 3.65
update:1415/2000, 耗时:0.00分/2.86分 | step: 56600 | performance: 1.0 | accuracy: 1.00 | loss: 1.40
Saving PPO weights in both H5 format and checkpoint @ update:1415 
update:1420/2000, 耗时:0.00分/2.87分 | step: 56800 | performance: 0.4 | accuracy: 0.38 | loss: 2.12
update:1425/2000, 耗时:0.00分/2.88分 | step: 57000 | performance: 0.3 | accuracy: 0.39 | loss: 5.39
update:1430/2000, 耗时:0.00分/2.89分 | step: 57200 | performance: 0.8 | accuracy: 0.46 | loss: 2.84
update:1435/2000, 耗时:0.00分/2.90分 | step: 57400 | performance: 0.2 | accuracy: 0.42 | loss: 6.08
update:1440/2000, 耗时:0.00分/2.91分 | step: 57600 | performance: 0.1 | accuracy: 0.39 | loss: 1.16
update:1445/2000, 耗时:0.00分/2.92分 | step: 57800 | performance: 0.3 | accuracy: 0.43 | loss: 0.95
update:1450/2000, 耗时:0.00分/2.93分 | step: 58000 | performance: 0.6 | accuracy: 0.48 | loss: 3.87
update:1455/2000, 耗时:0.00分/2.94分 | step: 58200 | performance: 0.6 | accuracy: 0.47 | loss: 3.07
update:1460/2000, 耗时:0.00分/2.95分 | step: 58400 | performance: 1.4 | accuracy: 0.49 | loss: 2.96
update:1465/2000, 耗时:0.00分/2.96分 | step: 58600 | performance: 1.3 | accuracy: 0.47 | loss: 1.66
update:1470/2000, 耗时:0.00分/2.97分 | step: 58800 | performance: 1.0 | accuracy: 0.46 | loss: 8.07
update:1475/2000, 耗时:0.00分/2.98分 | step: 59000 | performance: 0.4 | accuracy: 0.44 | loss: 0.76
update:1480/2000, 耗时:0.00分/2.99分 | step: 59200 | performance: 1.3 | accuracy: 0.47 | loss: 2.26
update:1485/2000, 耗时:0.00分/3.00分 | step: 59400 | performance: 1.1 | accuracy: 0.46 | loss: 1.44
update:1490/2000, 耗时:0.00分/3.01分 | step: 59600 | performance: 0.8 | accuracy: 0.45 | loss: 2.81
update:1495/2000, 耗时:0.00分/3.02分 | step: 59800 | performance: 1.4 | accuracy: 0.45 | loss: 1.29
update:1500/2000, 耗时:0.00分/3.03分 | step: 60000 | performance: 1.2 | accuracy: 0.46 | loss: 0.80
update:1505/2000, 耗时:0.00分/3.04分 | step: 60200 | performance: 1.6 | accuracy: 0.46 | loss: 5.96
update:1510/2000, 耗时:0.00分/3.05分 | step: 60400 | performance: 1.3 | accuracy: 0.46 | loss: 0.90
update:1515/2000, 耗时:0.00分/3.06分 | step: 60600 | performance: 1.3 | accuracy: 0.46 | loss: 3.29
update:1520/2000, 耗时:0.00分/3.07分 | step: 60800 | performance: 4.0 | accuracy: 0.48 | loss: 4.39
update:1525/2000, 耗时:0.00分/3.08分 | step: 61000 | performance: 14.9 | accuracy: 0.48 | loss: 1.04
update:1530/2000, 耗时:0.00分/3.09分 | step: 61200 | performance: 57.6 | accuracy: 0.50 | loss: 3.57
update:1535/2000, 耗时:0.00分/3.10分 | step: 61400 | performance: 27.4 | accuracy: 0.50 | loss: 5.06
update:1540/2000, 耗时:0.00分/3.11分 | step: 61600 | performance: 18.5 | accuracy: 0.49 | loss: 5.56
update:1545/2000, 耗时:0.00分/3.12分 | step: 61800 | performance: 35.2 | accuracy: 0.49 | loss: 1.53
update:1550/2000, 耗时:0.00分/3.13分 | step: 62000 | performance: 44.6 | accuracy: 0.49 | loss: 3.90
update:1555/2000, 耗时:0.00分/3.14分 | step: 62200 | performance: 36.4 | accuracy: 0.50 | loss: 1.95
update:1560/2000, 耗时:0.00分/3.15分 | step: 62400 | performance: 26.1 | accuracy: 0.49 | loss: 1.14
update:1565/2000, 耗时:0.00分/3.16分 | step: 62600 | performance: 24.1 | accuracy: 0.48 | loss: 0.67
update:1570/2000, 耗时:0.00分/3.17分 | step: 62800 | performance: 21.1 | accuracy: 0.48 | loss: 0.69
update:1575/2000, 耗时:0.00分/3.19分 | step: 63000 | performance: 6.3 | accuracy: 0.47 | loss: 1.30
update:1580/2000, 耗时:0.00分/3.20分 | step: 63200 | performance: 8.2 | accuracy: 0.48 | loss: 4.14
update:1585/2000, 耗时:0.00分/3.21分 | step: 63400 | performance: 8.8 | accuracy: 0.48 | loss: 2.25
update:1590/2000, 耗时:0.00分/3.22分 | step: 63600 | performance: 61.3 | accuracy: 0.49 | loss: 9.17
update:1595/2000, 耗时:0.00分/3.23分 | step: 63800 | performance: 104.2 | accuracy: 0.50 | loss: 2.81
update:1600/2000, 耗时:0.00分/3.24分 | step: 64000 | performance: 86.7 | accuracy: 0.50 | loss: 1.28
update:1605/2000, 耗时:0.00分/3.25分 | step: 64200 | performance: 220.2 | accuracy: 0.51 | loss: 1.21
update:1610/2000, 耗时:0.00分/3.26分 | step: 64400 | performance: 532.4 | accuracy: 0.51 | loss: 15.01
update:1615/2000, 耗时:0.00分/3.27分 | step: 64600 | performance: 526.0 | accuracy: 0.51 | loss: 11.10
update:1620/2000, 耗时:0.00分/3.28分 | step: 64800 | performance: 269.3 | accuracy: 0.50 | loss: 6.36
update:1625/2000, 耗时:0.00分/3.29分 | step: 65000 | performance: 892.3 | accuracy: 0.51 | loss: 0.71
update:1630/2000, 耗时:0.00分/3.30分 | step: 65200 | performance: 405.5 | accuracy: 0.50 | loss: 2.39
update:1635/2000, 耗时:0.00分/3.31分 | step: 65400 | performance: 319.8 | accuracy: 0.50 | loss: 4.77
update:1640/2000, 耗时:0.00分/3.32分 | step: 65600 | performance: 357.7 | accuracy: 0.50 | loss: 0.81
update:1645/2000, 耗时:0.00分/3.33分 | step: 65800 | performance: 136.6 | accuracy: 0.49 | loss: 1.44
update:1650/2000, 耗时:0.00分/3.34分 | step: 66000 | performance: 122.4 | accuracy: 0.49 | loss: 4.59
update:1655/2000, 耗时:0.00分/3.35分 | step: 66200 | performance: 158.1 | accuracy: 0.49 | loss: 1.34
update:1660/2000, 耗时:0.00分/3.36分 | step: 66400 | performance: 62.0 | accuracy: 0.49 | loss: 2.24
update:1665/2000, 耗时:0.00分/3.37分 | step: 66600 | performance: 85.8 | accuracy: 0.49 | loss: 3.70
update:1670/2000, 耗时:0.00分/3.38分 | step: 66800 | performance: 181.0 | accuracy: 0.50 | loss: 5.89
update:1675/2000, 耗时:0.00分/3.39分 | step: 67000 | performance: 240.6 | accuracy: 0.50 | loss: 3.73
update:1680/2000, 耗时:0.00分/3.40分 | step: 67200 | performance: 220.5 | accuracy: 0.50 | loss: 4.82
update:1685/2000, 耗时:0.00分/3.41分 | step: 67400 | performance: 209.6 | accuracy: 0.50 | loss: 4.89
update:1690/2000, 耗时:0.00分/3.42分 | step: 67600 | performance: 93.9 | accuracy: 0.49 | loss: 0.73
update:1695/2000, 耗时:0.00分/3.43分 | step: 67800 | performance: 86.5 | accuracy: 0.49 | loss: 1.82
update:1700/2000, 耗时:0.00分/3.45分 | step: 68000 | performance: 135.4 | accuracy: 0.50 | loss: 2.60
update:1705/2000, 耗时:0.00分/3.46分 | step: 68200 | performance: 102.3 | accuracy: 0.50 | loss: 0.69
update:1710/2000, 耗时:0.00分/3.47分 | step: 68400 | performance: 46.0 | accuracy: 0.49 | loss: 2.76
update:1715/2000, 耗时:0.00分/3.48分 | step: 68600 | performance: 196.5 | accuracy: 0.49 | loss: 11.07
update:1720/2000, 耗时:0.00分/3.49分 | step: 68800 | performance: 127.9 | accuracy: 0.49 | loss: 6.39
update:1725/2000, 耗时:0.00分/3.50分 | step: 69000 | performance: 114.8 | accuracy: 0.49 | loss: 3.70
update:1730/2000, 耗时:0.00分/3.51分 | step: 69200 | performance: 55.7 | accuracy: 0.49 | loss: 3.99
update:1735/2000, 耗时:0.00分/3.52分 | step: 69400 | performance: 33.0 | accuracy: 0.49 | loss: 1.38
update:1740/2000, 耗时:0.00分/3.53分 | step: 69600 | performance: 29.6 | accuracy: 0.49 | loss: 6.16
update:1745/2000, 耗时:0.00分/3.55分 | step: 69800 | performance: 39.0 | accuracy: 0.49 | loss: 0.57
update:1750/2000, 耗时:0.00分/3.56分 | step: 70000 | performance: 31.1 | accuracy: 0.49 | loss: 1.08
update:1755/2000, 耗时:0.00分/3.57分 | step: 70200 | performance: 25.0 | accuracy: 0.49 | loss: 1.73
update:1760/2000, 耗时:0.00分/3.58分 | step: 70400 | performance: 26.4 | accuracy: 0.49 | loss: 1.87
update:1765/2000, 耗时:0.00分/3.59分 | step: 70600 | performance: 31.6 | accuracy: 0.49 | loss: 3.57
update:1770/2000, 耗时:0.00分/3.60分 | step: 70800 | performance: 83.4 | accuracy: 0.49 | loss: 1.47
update:1775/2000, 耗时:0.00分/3.61分 | step: 71000 | performance: 110.4 | accuracy: 0.50 | loss: 2.90
update:1780/2000, 耗时:0.00分/3.62分 | step: 71200 | performance: 86.9 | accuracy: 0.49 | loss: 2.18
update:1785/2000, 耗时:0.00分/3.63分 | step: 71400 | performance: 43.1 | accuracy: 0.49 | loss: 2.46
update:1790/2000, 耗时:0.00分/3.64分 | step: 71600 | performance: 46.2 | accuracy: 0.49 | loss: 1.11
update:1795/2000, 耗时:0.00分/3.65分 | step: 71800 | performance: 49.5 | accuracy: 0.50 | loss: 0.95
update:1800/2000, 耗时:0.00分/3.66分 | step: 72000 | performance: 77.6 | accuracy: 0.50 | loss: 2.19
update:1805/2000, 耗时:0.00分/3.68分 | step: 72200 | performance: 209.6 | accuracy: 0.50 | loss: 1.97
update:1810/2000, 耗时:0.00分/3.69分 | step: 72400 | performance: 529.9 | accuracy: 0.51 | loss: 1.01
update:1815/2000, 耗时:0.00分/3.70分 | step: 72600 | performance: 1177.4 | accuracy: 0.51 | loss: 2.69
update:1820/2000, 耗时:0.00分/3.71分 | step: 72800 | performance: 1320.7 | accuracy: 0.51 | loss: 3.26
update:1825/2000, 耗时:0.00分/3.72分 | step: 73000 | performance: 4494.5 | accuracy: 0.51 | loss: 1.85
update:1830/2000, 耗时:0.00分/3.73分 | step: 73200 | performance: 23213.8 | accuracy: 0.51 | loss: 2.82
update:1835/2000, 耗时:0.00分/3.74分 | step: 73400 | performance: 74735.3 | accuracy: 0.52 | loss: 1.17
update:1840/2000, 耗时:0.00分/3.75分 | step: 73600 | performance: 26242.3 | accuracy: 0.51 | loss: 4.16
update:1845/2000, 耗时:0.00分/3.76分 | step: 73800 | performance: 156961.7 | accuracy: 0.52 | loss: 5.47
update:1850/2000, 耗时:0.00分/3.77分 | step: 74000 | performance: 811214.5 | accuracy: 0.52 | loss: 2.78
update:1855/2000, 耗时:0.00分/3.78分 | step: 74200 | performance: 325816.2 | accuracy: 0.52 | loss: 6.46
update:1860/2000, 耗时:0.00分/3.79分 | step: 74400 | performance: 887072.2 | accuracy: 0.52 | loss: 0.69
update:1865/2000, 耗时:0.00分/3.80分 | step: 74600 | performance: 943400.6 | accuracy: 0.52 | loss: 1.29
update:1870/2000, 耗时:0.00分/3.81分 | step: 74800 | performance: 1131272.7 | accuracy: 0.53 | loss: 0.71
update:1875/2000, 耗时:0.00分/3.82分 | step: 75000 | performance: 346498.9 | accuracy: 0.52 | loss: 12.36
update:1880/2000, 耗时:0.00分/3.83分 | step: 75200 | performance: 787534.1 | accuracy: 0.52 | loss: 0.92
update:1885/2000, 耗时:0.00分/3.84分 | step: 75400 | performance: 97388.8 | accuracy: 0.52 | loss: 10.57
update:1890/2000, 耗时:0.00分/3.85分 | step: 75600 | performance: 133494.8 | accuracy: 0.52 | loss: 4.22
update:1895/2000, 耗时:0.00分/3.86分 | step: 75800 | performance: 119477.6 | accuracy: 0.52 | loss: 1.87
update:1900/2000, 耗时:0.00分/3.87分 | step: 76000 | performance: 237817.9 | accuracy: 0.52 | loss: 3.48
update:1905/2000, 耗时:0.00分/3.88分 | step: 76200 | performance: 213097.8 | accuracy: 0.52 | loss: 3.52
update:1910/2000, 耗时:0.00分/3.89分 | step: 76400 | performance: 348041.2 | accuracy: 0.52 | loss: 0.96
update:1915/2000, 耗时:0.00分/3.90分 | step: 76600 | performance: 85006.8 | accuracy: 0.52 | loss: 2.09
update:1920/2000, 耗时:0.00分/3.91分 | step: 76800 | performance: 32575.8 | accuracy: 0.52 | loss: 3.72
update:1925/2000, 耗时:0.00分/3.92分 | step: 77000 | performance: 34396.4 | accuracy: 0.51 | loss: 1.23
update:1930/2000, 耗时:0.00分/3.93分 | step: 77200 | performance: 23871.7 | accuracy: 0.51 | loss: 8.14
update:1935/2000, 耗时:0.00分/3.94分 | step: 77400 | performance: 13880.2 | accuracy: 0.51 | loss: 6.39
update:1940/2000, 耗时:0.00分/3.95分 | step: 77600 | performance: 6826.1 | accuracy: 0.51 | loss: 2.00
update:1945/2000, 耗时:0.00分/3.96分 | step: 77800 | performance: 23422.1 | accuracy: 0.51 | loss: 4.88
update:1950/2000, 耗时:0.00分/3.97分 | step: 78000 | performance: 22306.5 | accuracy: 0.51 | loss: 1.43
update:1955/2000, 耗时:0.00分/3.98分 | step: 78200 | performance: 35662.8 | accuracy: 0.52 | loss: 1.05
update:1960/2000, 耗时:0.00分/3.99分 | step: 78400 | performance: 14510.7 | accuracy: 0.51 | loss: 4.00
update:1965/2000, 耗时:0.00分/4.00分 | step: 78600 | performance: 5583.3 | accuracy: 0.51 | loss: 9.57
update:1970/2000, 耗时:0.00分/4.01分 | step: 78800 | performance: 5333.1 | accuracy: 0.51 | loss: 0.79
update:1975/2000, 耗时:0.00分/4.02分 | step: 79000 | performance: 3478.4 | accuracy: 0.51 | loss: 1.42
update:1980/2000, 耗时:0.00分/4.03分 | step: 79200 | performance: 6399.2 | accuracy: 0.51 | loss: 3.08
update:1985/2000, 耗时:0.00分/4.04分 | step: 79400 | performance: 18763.0 | accuracy: 0.51 | loss: 1.62
update:1990/2000, 耗时:0.00分/4.05分 | step: 79600 | performance: 7712.0 | accuracy: 0.51 | loss: 7.22
update:1995/2000, 耗时:0.00分/4.06分 | step: 79800 | performance: 9448.7 | accuracy: 0.51 | loss: 7.12
  0%|          | 0/406 [00:00<?, ?it/s]100%|| 406/406 [00:00<00:00, 135332.39it/s]
update:2000/2000, 耗时:0.00分/4.08分 | step: 80000 | performance: 6583.6 | accuracy: 0.51 | loss: 1.65
----------------------------------------finished----------------------------------------
==================================================
2023-01-03T00:00:00 | *** START BACKTEST ***
2023-01-03T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1335.57
2023-07-24T12:00:00 | net performance [%] = 33.5566
2023-07-24T12:00:00 | number of trades [#] = 8
==================================================
Trial 55 Complete [00h 04m 31s]
net_wealth: 1336.903073337453

Best net_wealth So Far: 1824.8039564105297
Total elapsed time: 07h 35m 54s

Search: Running Trial #56

Value             |Best Value So Far |Hyperparameter
6                 |6                 |horizon
225               |365               |lookback
True              |True              |MarketFactor
3                 |10                |lags
0.92              |0.98              |gamma
16                |16                |batch_size
10                |7                 |n_step
0.92              |0.94              |gae_lambda
1                 |0.5               |gradient_clip_norm
5                 |3                 |epochs
1e-05             |0.001             |actor_lr
0.001             |0.001             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4295.000000   4301.000000
mean      0.000435    20113.607657  ...   20191.527960  20169.373185
std       0.027833    16040.642334  ...   16078.872271  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7755.915039   7730.930176
50%       0.000642    11571.842969  ...   11757.219727  11751.469727
75%       0.011590    29894.706152  ...   30018.430664  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 05:39:18.400401: I tensorflow/core/platform2023-07-28 05:3/cpu_feature_guard.cc:142] 9:18.4004T33his TensorFlow binary is optimized with oneAPI Deep Neur:a I tensorflowl/2023-07-28 05:39:18.core/platf o400524: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Libra2r023-0rm7y /(cponu_feature_g-e2DNN2208u 05:0ard.cc:142eN3-0t)329w7o :]rk Libr 1t8This ary.- (oo2480 0n eDT05:3eNN) t92:1u83on644.: I tensorfl4sorF-0sl0ow bie6 na0ry78 i-2t84 s optimihe20 z:e 200d23f olI5:-lo w20t7e3n-0s-2iorngfo7w-/2c8 39:18 .o4rusee/ tl0o0phC 6l8aew/t ffooP0l5:93U 9::18i.co4nlroes0 08I/ 4ttwe5ns: ipolIawng CPUt r intiurcfsetnht ltrsioouocnonreffso tAPrrmw/cimino npsuper/8c/cpu_fooIr i n ferD e_afmea0pltureoewr/fpl/5cnore/:cee-op Neceraplarti_ticmtafgfanl coe-urarcoperlmo/c pNuertuat_feriwaraitimd/.ccpcca3u_felotou9a n:s:  1:reA8V.opr4a0tu01t8_kuX4 2L]i bAgVuXr5a1:ree_gr _gTu rId.a2hird
 s TenTecte.surnsoations:rcfalr oarFlr dcyoAoc.:1o VwXcc 4(2o]ne DNen abTb:Nhinawry i:/c142l)i s  ]AsVo1T4e ree /tptlop 2onXh2e
mT oi nenaa]tb fus  TTehtiost itmhs hhiorTeoei zfeerd mnr Fo/sopersa tlorlFTiolne elnostohw swl,ow irbienbnocwigutahrrp uC_PU infesat btyu riiilFer_ud lonnac soguraTewn sr tiy idsbooproeFAlPiten.sc  mo w owpittihniani itmr co:hmyn  piee tihzeiI rDformdaencz ewerp oea1 4e2-] cdipNpertr iuroaplr iph NetaTthitowwoirtssi  Teeekho pt  raniecAoPmoctaImio DLeiilzn eoApnbed iwrnsps,PIoaer rebruFilliry  detDhl(oore wn ebD ep NefeuraliNnNa ryl )Noat pT eneeitws to ioroNnsauneAkgs.s eooPrI
 D ethesFurlp fo:w   alt iNeLtwoArk iLbiV omlwiXz bilowitArVaXnghrye 2
T epCPth Neuo enarUdbe   (wralrey oai intnsatprpucr (eoDprloNnh ioatNn)eAeth tPDINtemi o inoDeN  cousmnp o)e the follsi owinNetwo  toler fgrk Library (oneDNN) to use the following CPU instructions in perf lags.u o
se the efollowing CPU instructions in performance-critical rep Neural NetwomainrCtnchPU  epik- cLer ibenrfostooperaructions in perftrmancerperations:itical operations:  AVX A ormance-critical opei-criticaVo AVrary (oneDX AVX2
To enable them iratioNl opennN) stn: o  Aso,X user trVaXt AeiVXb uthe ild Tenher operations, rebuild TensorFlow w2
isorFlth the approp2o
Tonrs:i Toenabf ol ee twh with the appropriate compiler flags.
ate cooem m piniAlVnX AVX2
lable them lT ieoorothwni oth erer ope n onefapergl ragas.btli
CaeoPt them nUiions, rebusn i iother operati,nstrucld Te ornsebt, reinusorFlooinld sbw with the appropriate compiler flags.
TensorFlow with the appropriate compiler flags.
 in performanuild TensorFlow with the appropriate compiler flags.
ce-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 05:39:19.030214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:39:19.039664: I tensorflow/core/common_runt2ime/gpu/gpu2_device.cc:01023-523-07-21008] Cr7-28 eated de vice00 /job:loc5:39:19.5a042614lhos: t:/r3e9pli:19.I 040331: I tca:0/etenstasorflonsw/ok:rflocwo/0/dre/cecoviommon_runtime/gpu/gpu_device.cre/common_runct:ime/gpu1510] /gpu_dce:GPUeCr:0 with 5evice454 .cc:1MB510a memory:te]  ->  ddevi Creatcede: 0,vice /joed  nadme: Nevice /joVIb:loDb:IcaAloca lGlhosehot/st/replicForrepa:0c/taskli:0/ed RTevX 3070, pccai:i 0ce/buts aids: k:0/devi:GPUce:GPU:000 wi00:01:00.0,th compute capab 5454ility: 8.6 MB:
0 with 5454 MB memory:  -> d meevicemory::  - >0 dev, name: NVIDIiceA: 0, na GeForce RTX 30me: NVIDI70, pci A GeForce bus id: 0000:01:00.0, comRTX 3070, pute cpci bus apabiliid:t y: 80000:01:00.6
.0, compute capability: 8.6
2023-07-28 05:39:19.052751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:39:19.055169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:39:19.065013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:39:19.070569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.03分 | step:   400 | performance: 2.7 | accuracy: 0.50 | loss: 5.58
update: 10/2000, 耗时:0.00分/0.05分 | step:   800 | performance: 11.5 | accuracy: 0.45 | loss: 3.26
update: 15/2000, 耗时:0.00分/0.06分 | step:  1200 | performance: 8.7 | accuracy: 0.39 | loss: 0.81
update: 20/2000, 耗时:0.00分/0.08分 | step:  1600 | performance: 11.9 | accuracy: 0.35 | loss: 0.81
update: 25/2000, 耗时:0.00分/0.10分 | step:  2000 | performance: 18.4 | accuracy: 0.33 | loss: 0.95
update: 30/2000, 耗时:0.00分/0.11分 | step:  2400 | performance: 12.1 | accuracy: 0.32 | loss: 2.14
update: 35/2000, 耗时:0.00分/0.13分 | step:  2800 | performance: 12.9 | accuracy: 0.32 | loss: 2.38
update: 40/2000, 耗时:0.00分/0.15分 | step:  3200 | performance: 16.8 | accuracy: 0.32 | loss: 0.68
update: 45/2000, 耗时:0.00分/0.16分 | step:  3600 | performance: 96.8 | accuracy: 0.34 | loss: 4.63
update: 50/2000, 耗时:0.00分/0.18分 | step:  4000 | performance: 122.6 | accuracy: 0.33 | loss: 0.67
update: 55/2000, 耗时:0.00分/0.20分 | step:  4400 | performance: 109.0 | accuracy: 0.31 | loss: 0.61
update: 60/2000, 耗时:0.00分/0.22分 | step:  4800 | performance: 127.3 | accuracy: 0.32 | loss: 2.09
update: 65/2000, 耗时:0.00分/0.24分 | step:  5200 | performance: 84.5 | accuracy: 0.31 | loss: 1.23
update: 70/2000, 耗时:0.00分/0.26分 | step:  5600 | performance: 22.5 | accuracy: 0.30 | loss: 1.08
update: 75/2000, 耗时:0.00分/0.27分 | step:  6000 | performance: 37.4 | accuracy: 0.30 | loss: 1.17
update: 80/2000, 耗时:0.00分/0.29分 | step:  6400 | performance: 27.3 | accuracy: 0.29 | loss: 0.98
update: 85/2000, 耗时:0.00分/0.31分 | step:  6800 | performance: 39.3 | accuracy: 0.29 | loss: 1.02
update: 90/2000, 耗时:0.00分/0.33分 | step:  7200 | performance: 48.1 | accuracy: 0.30 | loss: 1.12
update: 95/2000, 耗时:0.00分/0.35分 | step:  7600 | performance: 20.5 | accuracy: 0.30 | loss: 1.67
update:100/2000, 耗时:0.00分/0.36分 | step:  8000 | performance: 7.1 | accuracy: 0.30 | loss: 6.19
update:105/2000, 耗时:0.00分/0.38分 | step:  8400 | performance: 2.9 | accuracy: 0.30 | loss: 7.59
update:110/2000, 耗时:0.00分/0.40分 | step:  8800 | performance: 0.6 | accuracy: 0.29 | loss: 1.71
update:115/2000, 耗时:0.00分/0.42分 | step:  9200 | performance: 1.1 | accuracy: 0.31 | loss: 9.07
update:120/2000, 耗时:0.00分/0.44分 | step:  9600 | performance: 1.4 | accuracy: 0.31 | loss: 2.48
update:125/2000, 耗时:0.00分/0.46分 | step: 10000 | performance: 2.0 | accuracy: 0.32 | loss: 0.73
update:130/2000, 耗时:0.00分/0.48分 | step: 10400 | performance: 1.8 | accuracy: 0.32 | loss: 1.31
update:135/2000, 耗时:0.00分/0.49分 | step: 10800 | performance: 2.2 | accuracy: 0.32 | loss: 0.40
update:140/2000, 耗时:0.00分/0.51分 | step: 11200 | performance: 2.8 | accuracy: 0.32 | loss: 0.97
update:145/2000, 耗时:0.00分/0.53分 | step: 11600 | performance: 2.8 | accuracy: 0.31 | loss: 0.78
update:150/2000, 耗时:0.00分/0.55分 | step: 12000 | performance: 3.5 | accuracy: 0.31 | loss: 1.88
update:155/2000, 耗时:0.00分/0.57分 | step: 12400 | performance: 2.3 | accuracy: 0.31 | loss: 2.94
update:160/2000, 耗时:0.00分/0.59分 | step: 12800 | performance: 2.9 | accuracy: 0.32 | loss: 5.82
update:165/2000, 耗时:0.00分/0.61分 | step: 13200 | performance: 6.8 | accuracy: 0.32 | loss: 0.62
update:170/2000, 耗时:0.00分/0.62分 | step: 13600 | performance: 12.2 | accuracy: 0.32 | loss: 1.19
update:175/2000, 耗时:0.00分/0.64分 | step: 14000 | performance: 9.5 | accuracy: 0.32 | loss: 0.85
update:180/2000, 耗时:0.00分/0.66分 | step: 14400 | performance: 8.7 | accuracy: 0.32 | loss: 1.78
update:185/2000, 耗时:0.00分/0.68分 | step: 14800 | performance: 8.5 | accuracy: 0.32 | loss: 1.47
update:190/2000, 耗时:0.00分/0.70分 | step: 15200 | performance: 5.6 | accuracy: 0.32 | loss: 1.69
update:195/2000, 耗时:0.00分/0.71分 | step: 15600 | performance: 6.4 | accuracy: 0.33 | loss: 2.01
update:200/2000, 耗时:0.00分/0.73分 | step: 16000 | performance: 9.6 | accuracy: 0.33 | loss: 0.68
update:205/2000, 耗时:0.00分/0.75分 | step: 16400 | performance: 10.6 | accuracy: 0.33 | loss: 0.90
update:210/2000, 耗时:0.00分/0.77分 | step: 16800 | performance: 6.3 | accuracy: 0.33 | loss: 0.75
update:215/2000, 耗时:0.00分/0.79分 | step: 17200 | performance: 2.5 | accuracy: 0.33 | loss: 4.70
update:220/2000, 耗时:0.00分/0.80分 | step: 17600 | performance: 0.7 | accuracy: 0.33 | loss: 2.77
update:225/2000, 耗时:0.00分/0.82分 | step: 18000 | performance: 0.5 | accuracy: 0.33 | loss: 3.56
update:230/2000, 耗时:0.00分/0.84分 | step: 18400 | performance: 0.1 | accuracy: 0.33 | loss: 1.40
update:235/2000, 耗时:0.00分/0.86分 | step: 18800 | performance: 0.2 | accuracy: 0.33 | loss: 3.74
update:240/2000, 耗时:0.00分/0.88分 | step: 19200 | performance: 0.2 | accuracy: 0.34 | loss: 1.49
update:245/2000, 耗时:0.00分/0.90分 | step: 19600 | performance: 0.3 | accuracy: 0.34 | loss: 1.73
update:250/2000, 耗时:0.00分/0.91分 | step: 20000 | performance: 0.9 | accuracy: 0.34 | loss: 5.36
update:255/2000, 耗时:0.00分/0.93分 | step: 20400 | performance: 0.7 | accuracy: 0.34 | loss: 0.66
update:260/2000, 耗时:0.00分/0.95分 | step: 20800 | performance: 0.4 | accuracy: 0.33 | loss: 0.66
update:265/2000, 耗时:0.00分/0.97分 | step: 21200 | performance: 0.7 | accuracy: 0.34 | loss: 1.65
update:270/2000, 耗时:0.00分/0.99分 | step: 21600 | performance: 0.8 | accuracy: 0.34 | loss: 2.09
update:275/2000, 耗时:0.00分/1.01分 | step: 22000 | performance: 1.4 | accuracy: 0.34 | loss: 2.57
update:280/2000, 耗时:0.00分/1.03分 | step: 22400 | performance: 1.3 | accuracy: 0.34 | loss: 2.18
update:285/2000, 耗时:0.00分/1.04分 | step: 22800 | performance: 1.1 | accuracy: 0.34 | loss: 2.86
update:290/2000, 耗时:0.00分/1.06分 | step: 23200 | performance: 1.2 | accuracy: 0.34 | loss: 1.21
update:295/2000, 耗时:0.00分/1.08分 | step: 23600 | performance: 1.3 | accuracy: 0.34 | loss: 1.16
update:300/2000, 耗时:0.00分/1.10分 | step: 24000 | performance: 1.1 | accuracy: 0.34 | loss: 1.02
update:305/2000, 耗时:0.00分/1.12分 | step: 24400 | performance: 2.8 | accuracy: 0.34 | loss: 2.04
update:310/2000, 耗时:0.00分/1.14分 | step: 24800 | performance: 2.3 | accuracy: 0.34 | loss: 0.73
update:315/2000, 耗时:0.00分/1.16分 | step: 25200 | performance: 4.3 | accuracy: 0.34 | loss: 1.95
update:320/2000, 耗时:0.00分/1.18分 | step: 25600 | performance: 5.1 | accuracy: 0.34 | loss: 0.98
update:325/2000, 耗时:0.00分/1.20分 | step: 26000 | performance: 3.9 | accuracy: 0.34 | loss: 0.92
update:330/2000, 耗时:0.00分/1.21分 | step: 26400 | performance: 4.2 | accuracy: 0.33 | loss: 0.26
update:335/2000, 耗时:0.00分/1.23分 | step: 26800 | performance: 5.3 | accuracy: 0.33 | loss: 0.89
update:340/2000, 耗时:0.00分/1.25分 | step: 27200 | performance: 6.4 | accuracy: 0.33 | loss: 0.85
update:345/2000, 耗时:0.00分/1.27分 | step: 27600 | performance: 7.4 | accuracy: 0.33 | loss: 0.80
update:350/2000, 耗时:0.00分/1.29分 | step: 28000 | performance: 8.9 | accuracy: 0.33 | loss: 0.33
update:355/2000, 耗时:0.00分/1.31分 | step: 28400 | performance: 9.9 | accuracy: 0.33 | loss: 0.50
update:360/2000, 耗时:0.00分/1.32分 | step: 28800 | performance: 15.5 | accuracy: 0.33 | loss: 0.89
update:365/2000, 耗时:0.00分/1.34分 | step: 29200 | performance: 15.3 | accuracy: 0.33 | loss: 0.75
Saving PPO weights in both H5 format and checkpoint @ update:367 
update:370/2000, 耗时:0.00分/1.37分 | step: 29600 | performance: 1.6 | accuracy: 0.57 | loss: 6.74
update:375/2000, 耗时:0.00分/1.38分 | step: 30000 | performance: 21.5 | accuracy: 0.58 | loss: 5.17
update:380/2000, 耗时:0.00分/1.40分 | step: 30400 | performance: 5.6 | accuracy: 0.39 | loss: 1.28
update:385/2000, 耗时:0.00分/1.42分 | step: 30800 | performance: 12.7 | accuracy: 0.36 | loss: 0.51
update:390/2000, 耗时:0.00分/1.44分 | step: 31200 | performance: 12.2 | accuracy: 0.33 | loss: 3.25
update:395/2000, 耗时:0.00分/1.45分 | step: 31600 | performance: 9.6 | accuracy: 0.31 | loss: 1.16
update:400/2000, 耗时:0.00分/1.47分 | step: 32000 | performance: 7.2 | accuracy: 0.29 | loss: 1.10
update:405/2000, 耗时:0.00分/1.49分 | step: 32400 | performance: 7.4 | accuracy: 0.30 | loss: 0.79
update:410/2000, 耗时:0.00分/1.51分 | step: 32800 | performance: 6.9 | accuracy: 0.29 | loss: 1.89
update:415/2000, 耗时:0.00分/1.52分 | step: 33200 | performance: 9.7 | accuracy: 0.28 | loss: 0.92
update:420/2000, 耗时:0.00分/1.54分 | step: 33600 | performance: 9.8 | accuracy: 0.28 | loss: 0.91
update:425/2000, 耗时:0.00分/1.56分 | step: 34000 | performance: 12.2 | accuracy: 0.28 | loss: 1.58
update:430/2000, 耗时:0.00分/1.58分 | step: 34400 | performance: 11.2 | accuracy: 0.27 | loss: 1.21
update:435/2000, 耗时:0.00分/1.60分 | step: 34800 | performance: 4.3 | accuracy: 0.27 | loss: 1.42
update:440/2000, 耗时:0.00分/1.61分 | step: 35200 | performance: 2.5 | accuracy: 0.26 | loss: 1.26
update:445/2000, 耗时:0.00分/1.63分 | step: 35600 | performance: 1.6 | accuracy: 0.26 | loss: 0.64
update:450/2000, 耗时:0.00分/1.65分 | step: 36000 | performance: 1.3 | accuracy: 0.26 | loss: 1.46
update:455/2000, 耗时:0.00分/1.67分 | step: 36400 | performance: 1.3 | accuracy: 0.26 | loss: 0.92
update:460/2000, 耗时:0.00分/1.69分 | step: 36800 | performance: 0.7 | accuracy: 0.25 | loss: 5.16
update:465/2000, 耗时:0.00分/1.70分 | step: 37200 | performance: 0.4 | accuracy: 0.26 | loss: 6.78
update:470/2000, 耗时:0.00分/1.72分 | step: 37600 | performance: 0.1 | accuracy: 0.25 | loss: 6.07
update:475/2000, 耗时:0.00分/1.74分 | step: 38000 | performance: 0.1 | accuracy: 0.26 | loss: 2.37
update:480/2000, 耗时:0.00分/1.76分 | step: 38400 | performance: 0.1 | accuracy: 0.27 | loss: 15.27
update:485/2000, 耗时:0.00分/1.78分 | step: 38800 | performance: 0.1 | accuracy: 0.27 | loss: 1.38
update:490/2000, 耗时:0.00分/1.79分 | step: 39200 | performance: 0.1 | accuracy: 0.28 | loss: 1.41
update:495/2000, 耗时:0.00分/1.81分 | step: 39600 | performance: 0.1 | accuracy: 0.28 | loss: 1.05
update:500/2000, 耗时:0.00分/1.83分 | step: 40000 | performance: 0.0 | accuracy: 0.27 | loss: 0.66
update:505/2000, 耗时:0.00分/1.85分 | step: 40400 | performance: 0.1 | accuracy: 0.27 | loss: 1.05
update:510/2000, 耗时:0.00分/1.86分 | step: 40800 | performance: 0.1 | accuracy: 0.27 | loss: 0.30
update:515/2000, 耗时:0.00分/1.88分 | step: 41200 | performance: 0.0 | accuracy: 0.27 | loss: 1.60
update:520/2000, 耗时:0.00分/1.90分 | step: 41600 | performance: 0.1 | accuracy: 0.27 | loss: 1.70
update:525/2000, 耗时:0.00分/1.92分 | step: 42000 | performance: 0.1 | accuracy: 0.28 | loss: 5.80
update:530/2000, 耗时:0.00分/1.93分 | step: 42400 | performance: 0.8 | accuracy: 0.29 | loss: 3.77
update:535/2000, 耗时:0.00分/1.95分 | step: 42800 | performance: 0.9 | accuracy: 0.28 | loss: 0.70
update:540/2000, 耗时:0.00分/1.97分 | step: 43200 | performance: 1.0 | accuracy: 0.28 | loss: 1.52
update:545/2000, 耗时:0.00分/1.99分 | step: 43600 | performance: 0.4 | accuracy: 0.28 | loss: 0.90
update:550/2000, 耗时:0.00分/2.01分 | step: 44000 | performance: 0.4 | accuracy: 0.28 | loss: 1.26
update:555/2000, 耗时:0.00分/2.02分 | step: 44400 | performance: 0.3 | accuracy: 0.29 | loss: 2.84
update:560/2000, 耗时:0.00分/2.04分 | step: 44800 | performance: 0.2 | accuracy: 0.29 | loss: 2.21
update:565/2000, 耗时:0.00分/2.06分 | step: 45200 | performance: 0.3 | accuracy: 0.29 | loss: 5.69
update:570/2000, 耗时:0.00分/2.08分 | step: 45600 | performance: 0.2 | accuracy: 0.29 | loss: 0.98
update:575/2000, 耗时:0.00分/2.09分 | step: 46000 | performance: 0.2 | accuracy: 0.29 | loss: 1.81
update:580/2000, 耗时:0.00分/2.11分 | step: 46400 | performance: 0.0 | accuracy: 0.29 | loss: 4.20
update:585/2000, 耗时:0.00分/2.13分 | step: 46800 | performance: 0.0 | accuracy: 0.29 | loss: 1.46
update:590/2000, 耗时:0.00分/2.15分 | step: 47200 | performance: 0.0 | accuracy: 0.29 | loss: 2.79
update:595/2000, 耗时:0.00分/2.17分 | step: 47600 | performance: 0.0 | accuracy: 0.30 | loss: 2.79
update:600/2000, 耗时:0.00分/2.18分 | step: 48000 | performance: 0.0 | accuracy: 0.30 | loss: 3.60
update:605/2000, 耗时:0.00分/2.20分 | step: 48400 | performance: 0.0 | accuracy: 0.30 | loss: 1.88
update:610/2000, 耗时:0.00分/2.22分 | step: 48800 | performance: 0.0 | accuracy: 0.30 | loss: 4.75
update:615/2000, 耗时:0.00分/2.24分 | step: 49200 | performance: 0.0 | accuracy: 0.31 | loss: 11.99
update:620/2000, 耗时:0.00分/2.25分 | step: 49600 | performance: 0.0 | accuracy: 0.30 | loss: 0.38
update:625/2000, 耗时:0.00分/2.27分 | step: 50000 | performance: 0.0 | accuracy: 0.30 | loss: 0.50
update:630/2000, 耗时:0.00分/2.29分 | step: 50400 | performance: 0.0 | accuracy: 0.30 | loss: 2.91
update:635/2000, 耗时:0.00分/2.31分 | step: 50800 | performance: 0.0 | accuracy: 0.30 | loss: 1.10
update:640/2000, 耗时:0.00分/2.33分 | step: 51200 | performance: 0.0 | accuracy: 0.30 | loss: 1.54
update:645/2000, 耗时:0.00分/2.35分 | step: 51600 | performance: 0.0 | accuracy: 0.30 | loss: 2.01
update:650/2000, 耗时:0.00分/2.36分 | step: 52000 | performance: 0.0 | accuracy: 0.31 | loss: 2.51
update:655/2000, 耗时:0.00分/2.38分 | step: 52400 | performance: 0.0 | accuracy: 0.31 | loss: 1.91
update:660/2000, 耗时:0.00分/2.40分 | step: 52800 | performance: 0.0 | accuracy: 0.31 | loss: 0.49
update:665/2000, 耗时:0.00分/2.42分 | step: 53200 | performance: 0.0 | accuracy: 0.31 | loss: 0.82
update:670/2000, 耗时:0.00分/2.44分 | step: 53600 | performance: 0.0 | accuracy: 0.31 | loss: 1.00
update:675/2000, 耗时:0.00分/2.45分 | step: 54000 | performance: 0.0 | accuracy: 0.31 | loss: 2.00
update:680/2000, 耗时:0.00分/2.47分 | step: 54400 | performance: 0.0 | accuracy: 0.31 | loss: 7.01
update:685/2000, 耗时:0.00分/2.49分 | step: 54800 | performance: 0.0 | accuracy: 0.31 | loss: 0.95
update:690/2000, 耗时:0.00分/2.51分 | step: 55200 | performance: 0.0 | accuracy: 0.31 | loss: 0.36
update:695/2000, 耗时:0.00分/2.52分 | step: 55600 | performance: 0.0 | accuracy: 0.31 | loss: 0.85
update:700/2000, 耗时:0.00分/2.54分 | step: 56000 | performance: 0.0 | accuracy: 0.30 | loss: 0.23
update:705/2000, 耗时:0.00分/2.56分 | step: 56400 | performance: 0.0 | accuracy: 0.30 | loss: 0.39
update:710/2000, 耗时:0.00分/2.58分 | step: 56800 | performance: 0.0 | accuracy: 0.30 | loss: 0.77
update:715/2000, 耗时:0.00分/2.60分 | step: 57200 | performance: 0.0 | accuracy: 0.30 | loss: 1.41
update:720/2000, 耗时:0.00分/2.61分 | step: 57600 | performance: 0.0 | accuracy: 0.30 | loss: 0.36
update:725/2000, 耗时:0.00分/2.63分 | step: 58000 | performance: 0.0 | accuracy: 0.29 | loss: 1.52
update:730/2000, 耗时:0.00分/2.65分 | step: 58400 | performance: 0.0 | accuracy: 0.29 | loss: 0.66
step: 58633 | worker_0@n_step_9: average total_reward after train data exhaustion : -63.1 | max total_reward: 0.4
step: 58634 | worker_1@n_step_9: average total_reward after train data exhaustion : -61.5 | max total_reward: 0.4
step: 58635 | worker_2@n_step_9: average total_reward after train data exhaustion : -60.2 | max total_reward: 0.4
step: 58636 | worker_3@n_step_9: average total_reward after train data exhaustion : -58.3 | max total_reward: 0.4
step: 58637 | worker_4@n_step_9: average total_reward after train data exhaustion : -55.2 | max total_reward: 0.4
step: 58638 | worker_5@n_step_9: average total_reward after train data exhaustion : -54.2 | max total_reward: 0.4
step: 58639 | worker_6@n_step_9: average total_reward after train data exhaustion : -53.1 | max total_reward: 0.4
step: 58640 | worker_7@n_step_9: average total_reward after train data exhaustion : -59.9 | max total_reward: 0.4
Saving PPO weights in both H5 format and checkpoint @ update:733 
update:735/2000, 耗时:0.00分/2.67分 | step: 58800 | performance: 0.6 | accuracy: 0.45 | loss: 14.83
update:740/2000, 耗时:0.00分/2.69分 | step: 59200 | performance: 5.8 | accuracy: 0.53 | loss: 3.94
update:745/2000, 耗时:0.00分/2.71分 | step: 59600 | performance: 8.7 | accuracy: 0.45 | loss: 0.69
update:750/2000, 耗时:0.00分/2.73分 | step: 60000 | performance: 7.1 | accuracy: 0.37 | loss: 2.16
update:755/2000, 耗时:0.00分/2.74分 | step: 60400 | performance: 10.3 | accuracy: 0.32 | loss: 0.83
update:760/2000, 耗时:0.00分/2.76分 | step: 60800 | performance: 9.7 | accuracy: 0.31 | loss: 0.91
update:765/2000, 耗时:0.00分/2.78分 | step: 61200 | performance: 16.1 | accuracy: 0.32 | loss: 0.61
update:770/2000, 耗时:0.00分/2.80分 | step: 61600 | performance: 15.4 | accuracy: 0.30 | loss: 1.23
update:775/2000, 耗时:0.00分/2.81分 | step: 62000 | performance: 36.0 | accuracy: 0.30 | loss: 1.34
update:780/2000, 耗时:0.00分/2.83分 | step: 62400 | performance: 61.9 | accuracy: 0.31 | loss: 1.74
update:785/2000, 耗时:0.00分/2.85分 | step: 62800 | performance: 58.7 | accuracy: 0.30 | loss: 1.15
update:790/2000, 耗时:0.00分/2.87分 | step: 63200 | performance: 59.5 | accuracy: 0.29 | loss: 0.32
update:795/2000, 耗时:0.00分/2.88分 | step: 63600 | performance: 56.4 | accuracy: 0.29 | loss: 0.53
update:800/2000, 耗时:0.00分/2.90分 | step: 64000 | performance: 94.5 | accuracy: 0.29 | loss: 3.34
update:805/2000, 耗时:0.00分/2.92分 | step: 64400 | performance: 74.4 | accuracy: 0.28 | loss: 2.27
update:810/2000, 耗时:0.00分/2.94分 | step: 64800 | performance: 64.1 | accuracy: 0.28 | loss: 0.60
update:815/2000, 耗时:0.00分/2.96分 | step: 65200 | performance: 65.8 | accuracy: 0.27 | loss: 0.45
update:820/2000, 耗时:0.00分/2.97分 | step: 65600 | performance: 58.0 | accuracy: 0.27 | loss: 1.17
update:825/2000, 耗时:0.00分/2.99分 | step: 66000 | performance: 56.5 | accuracy: 0.27 | loss: 3.15
update:830/2000, 耗时:0.00分/3.01分 | step: 66400 | performance: 17.6 | accuracy: 0.27 | loss: 2.06
update:835/2000, 耗时:0.00分/3.03分 | step: 66800 | performance: 13.5 | accuracy: 0.27 | loss: 3.67
update:840/2000, 耗时:0.00分/3.04分 | step: 67200 | performance: 5.1 | accuracy: 0.27 | loss: 6.58
update:845/2000, 耗时:0.00分/3.06分 | step: 67600 | performance: 1.5 | accuracy: 0.27 | loss: 4.80
update:850/2000, 耗时:0.00分/3.08分 | step: 68000 | performance: 4.1 | accuracy: 0.28 | loss: 6.60
update:855/2000, 耗时:0.00分/3.10分 | step: 68400 | performance: 6.5 | accuracy: 0.28 | loss: 1.21
update:860/2000, 耗时:0.00分/3.11分 | step: 68800 | performance: 6.0 | accuracy: 0.28 | loss: 1.10
update:865/2000, 耗时:0.00分/3.13分 | step: 69200 | performance: 8.4 | accuracy: 0.28 | loss: 0.79
update:870/2000, 耗时:0.00分/3.15分 | step: 69600 | performance: 10.7 | accuracy: 0.28 | loss: 0.51
update:875/2000, 耗时:0.00分/3.17分 | step: 70000 | performance: 12.6 | accuracy: 0.28 | loss: 0.38
update:880/2000, 耗时:0.00分/3.18分 | step: 70400 | performance: 9.8 | accuracy: 0.28 | loss: 1.02
update:885/2000, 耗时:0.00分/3.20分 | step: 70800 | performance: 12.1 | accuracy: 0.28 | loss: 1.18
update:890/2000, 耗时:0.00分/3.22分 | step: 71200 | performance: 9.8 | accuracy: 0.28 | loss: 1.69
update:895/2000, 耗时:0.00分/3.24分 | step: 71600 | performance: 237.0 | accuracy: 0.29 | loss: 17.06
update:900/2000, 耗时:0.00分/3.26分 | step: 72000 | performance: 79.7 | accuracy: 0.28 | loss: 1.14
update:905/2000, 耗时:0.00分/3.27分 | step: 72400 | performance: 128.8 | accuracy: 0.28 | loss: 1.19
update:910/2000, 耗时:0.00分/3.29分 | step: 72800 | performance: 55.5 | accuracy: 0.28 | loss: 2.88
update:915/2000, 耗时:0.00分/3.31分 | step: 73200 | performance: 45.9 | accuracy: 0.28 | loss: 1.20
update:920/2000, 耗时:0.00分/3.32分 | step: 73600 | performance: 40.6 | accuracy: 0.28 | loss: 1.67
update:925/2000, 耗时:0.00分/3.34分 | step: 74000 | performance: 24.3 | accuracy: 0.28 | loss: 2.24
update:930/2000, 耗时:0.00分/3.36分 | step: 74400 | performance: 42.0 | accuracy: 0.29 | loss: 6.05
update:935/2000, 耗时:0.00分/3.38分 | step: 74800 | performance: 41.2 | accuracy: 0.29 | loss: 1.32
update:940/2000, 耗时:0.00分/3.40分 | step: 75200 | performance: 35.4 | accuracy: 0.29 | loss: 1.41
update:945/2000, 耗时:0.00分/3.41分 | step: 75600 | performance: 8.3 | accuracy: 0.29 | loss: 7.35
update:950/2000, 耗时:0.00分/3.43分 | step: 76000 | performance: 4.0 | accuracy: 0.29 | loss: 7.70
update:955/2000, 耗时:0.00分/3.45分 | step: 76400 | performance: 0.9 | accuracy: 0.29 | loss: 4.06
update:960/2000, 耗时:0.00分/3.46分 | step: 76800 | performance: 0.8 | accuracy: 0.30 | loss: 3.22
update:965/2000, 耗时:0.00分/3.48分 | step: 77200 | performance: 2.3 | accuracy: 0.30 | loss: 3.63
update:970/2000, 耗时:0.00分/3.50分 | step: 77600 | performance: 1.0 | accuracy: 0.31 | loss: 5.08
update:975/2000, 耗时:0.00分/3.52分 | step: 78000 | performance: 0.7 | accuracy: 0.31 | loss: 6.74
update:980/2000, 耗时:0.00分/3.53分 | step: 78400 | performance: 1.8 | accuracy: 0.31 | loss: 6.38
update:985/2000, 耗时:0.00分/3.55分 | step: 78800 | performance: 4.3 | accuracy: 0.31 | loss: 1.07
update:990/2000, 耗时:0.00分/3.57分 | step: 79200 | performance: 2.7 | accuracy: 0.31 | loss: 1.14
update:995/2000, 耗时:0.00分/3.59分 | step: 79600 | performance: 4.4 | accuracy: 0.31 | loss: 3.16
update:1000/2000, 耗时:0.00分/3.60分 | step: 80000 | performance: 5.4 | accuracy: 0.31 | loss: 2.73
update:1005/2000, 耗时:0.00分/3.62分 | step: 80400 | performance: 3.8 | accuracy: 0.31 | loss: 6.30
update:1010/2000, 耗时:0.00分/3.64分 | step: 80800 | performance: 2.4 | accuracy: 0.31 | loss: 1.06
update:1015/2000, 耗时:0.00分/3.66分 | step: 81200 | performance: 1.7 | accuracy: 0.31 | loss: 1.40
update:1020/2000, 耗时:0.00分/3.68分 | step: 81600 | performance: 3.6 | accuracy: 0.32 | loss: 2.10
update:1025/2000, 耗时:0.00分/3.70分 | step: 82000 | performance: 5.1 | accuracy: 0.32 | loss: 0.62
update:1030/2000, 耗时:0.00分/3.71分 | step: 82400 | performance: 6.7 | accuracy: 0.31 | loss: 0.27
update:1035/2000, 耗时:0.00分/3.73分 | step: 82800 | performance: 7.9 | accuracy: 0.31 | loss: 1.21
update:1040/2000, 耗时:0.00分/3.75分 | step: 83200 | performance: 3.8 | accuracy: 0.31 | loss: 1.54
update:1045/2000, 耗时:0.00分/3.77分 | step: 83600 | performance: 4.1 | accuracy: 0.31 | loss: 1.27
update:1050/2000, 耗时:0.00分/3.79分 | step: 84000 | performance: 7.6 | accuracy: 0.31 | loss: 0.80
update:1055/2000, 耗时:0.00分/3.81分 | step: 84400 | performance: 13.9 | accuracy: 0.31 | loss: 0.95
update:1060/2000, 耗时:0.00分/3.83分 | step: 84800 | performance: 10.9 | accuracy: 0.31 | loss: 2.03
update:1065/2000, 耗时:0.00分/3.84分 | step: 85200 | performance: 10.9 | accuracy: 0.31 | loss: 0.26
update:1070/2000, 耗时:0.00分/3.86分 | step: 85600 | performance: 12.2 | accuracy: 0.31 | loss: 0.28
update:1075/2000, 耗时:0.00分/3.88分 | step: 86000 | performance: 16.8 | accuracy: 0.30 | loss: 0.22
update:1080/2000, 耗时:0.00分/3.90分 | step: 86400 | performance: 16.1 | accuracy: 0.30 | loss: 0.57
update:1085/2000, 耗时:0.00分/3.92分 | step: 86800 | performance: 16.1 | accuracy: 0.30 | loss: 0.27
update:1090/2000, 耗时:0.00分/3.94分 | step: 87200 | performance: 24.2 | accuracy: 0.30 | loss: 1.05
update:1095/2000, 耗时:0.00分/3.96分 | step: 87600 | performance: 21.9 | accuracy: 0.30 | loss: 0.28
update:1100/2000, 耗时:0.00分/3.98分 | step: 88000 | performance: 1.3 | accuracy: 0.80 | loss: 2.27
Saving PPO weights in both H5 format and checkpoint @ update:1100 
update:1105/2000, 耗时:0.00分/4.00分 | step: 88400 | performance: 7.3 | accuracy: 0.62 | loss: 5.48
update:1110/2000, 耗时:0.00分/4.02分 | step: 88800 | performance: 18.2 | accuracy: 0.51 | loss: 1.99
update:1115/2000, 耗时:0.00分/4.04分 | step: 89200 | performance: 23.2 | accuracy: 0.43 | loss: 1.56
update:1120/2000, 耗时:0.00分/4.06分 | step: 89600 | performance: 22.9 | accuracy: 0.36 | loss: 0.42
update:1125/2000, 耗时:0.00分/4.08分 | step: 90000 | performance: 28.9 | accuracy: 0.35 | loss: 1.11
update:1130/2000, 耗时:0.00分/4.10分 | step: 90400 | performance: 39.5 | accuracy: 0.33 | loss: 0.44
update:1135/2000, 耗时:0.00分/4.11分 | step: 90800 | performance: 34.1 | accuracy: 0.31 | loss: 0.75
update:1140/2000, 耗时:0.00分/4.13分 | step: 91200 | performance: 45.5 | accuracy: 0.30 | loss: 1.18
update:1145/2000, 耗时:0.00分/4.15分 | step: 91600 | performance: 147.2 | accuracy: 0.32 | loss: 5.13
update:1150/2000, 耗时:0.00分/4.17分 | step: 92000 | performance: 133.1 | accuracy: 0.30 | loss: 0.20
update:1155/2000, 耗时:0.00分/4.19分 | step: 92400 | performance: 128.7 | accuracy: 0.29 | loss: 0.47
update:1160/2000, 耗时:0.00分/4.21分 | step: 92800 | performance: 159.8 | accuracy: 0.29 | loss: 1.55
update:1165/2000, 耗时:0.00分/4.23分 | step: 93200 | performance: 230.9 | accuracy: 0.28 | loss: 3.72
update:1170/2000, 耗时:0.00分/4.24分 | step: 93600 | performance: 304.7 | accuracy: 0.28 | loss: 0.30
update:1175/2000, 耗时:0.00分/4.26分 | step: 94000 | performance: 436.4 | accuracy: 0.28 | loss: 1.46
update:1180/2000, 耗时:0.00分/4.28分 | step: 94400 | performance: 411.0 | accuracy: 0.27 | loss: 0.53
update:1185/2000, 耗时:0.00分/4.30分 | step: 94800 | performance: 426.9 | accuracy: 0.27 | loss: 1.51
update:1190/2000, 耗时:0.00分/4.32分 | step: 95200 | performance: 374.2 | accuracy: 0.27 | loss: 1.00
update:1195/2000, 耗时:0.00分/4.34分 | step: 95600 | performance: 181.2 | accuracy: 0.26 | loss: 4.68
update:1200/2000, 耗时:0.00分/4.35分 | step: 96000 | performance: 169.3 | accuracy: 0.27 | loss: 4.37
update:1205/2000, 耗时:0.00分/4.37分 | step: 96400 | performance: 127.2 | accuracy: 0.27 | loss: 3.92
update:1210/2000, 耗时:0.00分/4.39分 | step: 96800 | performance: 18.0 | accuracy: 0.27 | loss: 4.78
update:1215/2000, 耗时:0.00分/4.41分 | step: 97200 | performance: 21.6 | accuracy: 0.28 | loss: 6.72
update:1220/2000, 耗时:0.00分/4.43分 | step: 97600 | performance: 12.3 | accuracy: 0.28 | loss: 2.06
update:1225/2000, 耗时:0.00分/4.45分 | step: 98000 | performance: 11.5 | accuracy: 0.29 | loss: 0.82
update:1230/2000, 耗时:0.00分/4.47分 | step: 98400 | performance: 16.4 | accuracy: 0.28 | loss: 0.40
update:1235/2000, 耗时:0.00分/4.49分 | step: 98800 | performance: 19.4 | accuracy: 0.28 | loss: 1.92
update:1240/2000, 耗时:0.00分/4.51分 | step: 99200 | performance: 28.2 | accuracy: 0.28 | loss: 0.92
update:1245/2000, 耗时:0.00分/4.52分 | step: 99600 | performance: 21.6 | accuracy: 0.27 | loss: 0.99
update:1250/2000, 耗时:0.00分/4.54分 | step: 100000 | performance: 25.1 | accuracy: 0.27 | loss: 1.15
update:1255/2000, 耗时:0.00分/4.56分 | step: 100400 | performance: 19.9 | accuracy: 0.27 | loss: 2.44
update:1260/2000, 耗时:0.00分/4.58分 | step: 100800 | performance: 24.1 | accuracy: 0.28 | loss: 2.81
update:1265/2000, 耗时:0.00分/4.60分 | step: 101200 | performance: 249.2 | accuracy: 0.28 | loss: 0.57
update:1270/2000, 耗时:0.00分/4.62分 | step: 101600 | performance: 283.4 | accuracy: 0.28 | loss: 1.42
update:1275/2000, 耗时:0.00分/4.63分 | step: 102000 | performance: 325.3 | accuracy: 0.28 | loss: 1.50
update:1280/2000, 耗时:0.00分/4.65分 | step: 102400 | performance: 339.2 | accuracy: 0.29 | loss: 1.15
update:1285/2000, 耗时:0.00分/4.67分 | step: 102800 | performance: 354.8 | accuracy: 0.29 | loss: 1.19
update:1290/2000, 耗时:0.00分/4.69分 | step: 103200 | performance: 237.4 | accuracy: 0.29 | loss: 1.49
update:1295/2000, 耗时:0.00分/4.71分 | step: 103600 | performance: 302.7 | accuracy: 0.30 | loss: 3.04
update:1300/2000, 耗时:0.00分/4.73分 | step: 104000 | performance: 516.7 | accuracy: 0.30 | loss: 1.16
update:1305/2000, 耗时:0.00分/4.75分 | step: 104400 | performance: 436.0 | accuracy: 0.30 | loss: 0.71
update:1310/2000, 耗时:0.00分/4.77分 | step: 104800 | performance: 196.7 | accuracy: 0.30 | loss: 2.79
update:1315/2000, 耗时:0.00分/4.79分 | step: 105200 | performance: 66.2 | accuracy: 0.30 | loss: 2.73
update:1320/2000, 耗时:0.00分/4.82分 | step: 105600 | performance: 19.3 | accuracy: 0.30 | loss: 2.13
update:1325/2000, 耗时:0.00分/4.84分 | step: 106000 | performance: 37.8 | accuracy: 0.30 | loss: 1.17
update:1330/2000, 耗时:0.00分/4.86分 | step: 106400 | performance: 7.8 | accuracy: 0.30 | loss: 2.30
update:1335/2000, 耗时:0.00分/4.88分 | step: 106800 | performance: 4.0 | accuracy: 0.30 | loss: 1.15
update:1340/2000, 耗时:0.00分/4.90分 | step: 107200 | performance: 3.3 | accuracy: 0.31 | loss: 4.64
update:1345/2000, 耗时:0.00分/4.92分 | step: 107600 | performance: 4.9 | accuracy: 0.31 | loss: 1.29
update:1350/2000, 耗时:0.00分/4.94分 | step: 108000 | performance: 8.9 | accuracy: 0.31 | loss: 1.47
update:1355/2000, 耗时:0.00分/4.96分 | step: 108400 | performance: 5.1 | accuracy: 0.31 | loss: 0.64
update:1360/2000, 耗时:0.00分/4.98分 | step: 108800 | performance: 3.9 | accuracy: 0.30 | loss: 0.26
update:1365/2000, 耗时:0.00分/5.00分 | step: 109200 | performance: 6.9 | accuracy: 0.30 | loss: 1.01
update:1370/2000, 耗时:0.00分/5.02分 | step: 109600 | performance: 7.0 | accuracy: 0.30 | loss: 4.20
update:1375/2000, 耗时:0.00分/5.04分 | step: 110000 | performance: 5.9 | accuracy: 0.31 | loss: 3.44
update:1380/2000, 耗时:0.00分/5.06分 | step: 110400 | performance: 7.9 | accuracy: 0.31 | loss: 2.08
update:1385/2000, 耗时:0.00分/5.08分 | step: 110800 | performance: 9.2 | accuracy: 0.31 | loss: 2.43
update:1390/2000, 耗时:0.00分/5.10分 | step: 111200 | performance: 8.5 | accuracy: 0.32 | loss: 1.37
update:1395/2000, 耗时:0.00分/5.12分 | step: 111600 | performance: 9.4 | accuracy: 0.31 | loss: 0.92
update:1400/2000, 耗时:0.00分/5.14分 | step: 112000 | performance: 7.9 | accuracy: 0.31 | loss: 2.08
update:1405/2000, 耗时:0.00分/5.16分 | step: 112400 | performance: 10.6 | accuracy: 0.31 | loss: 1.60
update:1410/2000, 耗时:0.00分/5.18分 | step: 112800 | performance: 8.7 | accuracy: 0.31 | loss: 0.54
update:1415/2000, 耗时:0.00分/5.20分 | step: 113200 | performance: 10.8 | accuracy: 0.31 | loss: 1.16
update:1420/2000, 耗时:0.00分/5.22分 | step: 113600 | performance: 9.9 | accuracy: 0.31 | loss: 1.40
update:1425/2000, 耗时:0.00分/5.24分 | step: 114000 | performance: 8.3 | accuracy: 0.30 | loss: 0.96
update:1430/2000, 耗时:0.00分/5.26分 | step: 114400 | performance: 14.8 | accuracy: 0.30 | loss: 0.64
update:1435/2000, 耗时:0.00分/5.28分 | step: 114800 | performance: 22.4 | accuracy: 0.30 | loss: 0.55
update:1440/2000, 耗时:0.00分/5.30分 | step: 115200 | performance: 26.1 | accuracy: 0.30 | loss: 0.30
update:1445/2000, 耗时:0.00分/5.31分 | step: 115600 | performance: 27.9 | accuracy: 0.30 | loss: 1.47
update:1450/2000, 耗时:0.00分/5.33分 | step: 116000 | performance: 28.9 | accuracy: 0.30 | loss: 0.15
update:1455/2000, 耗时:0.00分/5.35分 | step: 116400 | performance: 33.6 | accuracy: 0.29 | loss: 0.93
update:1460/2000, 耗时:0.00分/5.37分 | step: 116800 | performance: 64.8 | accuracy: 0.29 | loss: 0.10
update:1465/2000, 耗时:0.00分/5.39分 | step: 117200 | performance: 61.8 | accuracy: 0.29 | loss: 0.62
step: 117273 | worker_0@n_step_9: average total_reward after train data exhaustion : -39.6 | max total_reward: 39.9
step: 117274 | worker_1@n_step_9: average total_reward after train data exhaustion : -37.9 | max total_reward: 39.9
step: 117275 | worker_2@n_step_9: average total_reward after train data exhaustion : -37.1 | max total_reward: 39.9
step: 117276 | worker_3@n_step_9: average total_reward after train data exhaustion : -35.2 | max total_reward: 39.9
step: 117277 | worker_4@n_step_9: average total_reward after train data exhaustion : -35.4 | max total_reward: 39.9
step: 117278 | worker_5@n_step_9: average total_reward after train data exhaustion : -36.0 | max total_reward: 39.9
step: 117279 | worker_6@n_step_9: average total_reward after train data exhaustion : -32.3 | max total_reward: 78.8
step: 117280 | worker_7@n_step_9: average total_reward after train data exhaustion : -28.1 | max total_reward: 103.5
Saving PPO weights in both H5 format and checkpoint @ update:1466 
update:1470/2000, 耗时:0.00分/5.41分 | step: 117600 | performance: 3.3 | accuracy: 0.65 | loss: 4.28
update:1475/2000, 耗时:0.00分/5.43分 | step: 118000 | performance: 9.9 | accuracy: 0.52 | loss: 6.89
update:1480/2000, 耗时:0.00分/5.45分 | step: 118400 | performance: 5.4 | accuracy: 0.39 | loss: 0.79
update:1485/2000, 耗时:0.00分/5.47分 | step: 118800 | performance: 5.3 | accuracy: 0.34 | loss: 0.45
update:1490/2000, 耗时:0.00分/5.49分 | step: 119200 | performance: 6.1 | accuracy: 0.30 | loss: 0.31
update:1495/2000, 耗时:0.00分/5.51分 | step: 119600 | performance: 7.7 | accuracy: 0.29 | loss: 0.79
update:1500/2000, 耗时:0.00分/5.52分 | step: 120000 | performance: 7.5 | accuracy: 0.26 | loss: 0.56
update:1505/2000, 耗时:0.00分/5.54分 | step: 120400 | performance: 7.8 | accuracy: 0.25 | loss: 0.42
update:1510/2000, 耗时:0.00分/5.56分 | step: 120800 | performance: 9.4 | accuracy: 0.25 | loss: 1.27
update:1515/2000, 耗时:0.00分/5.58分 | step: 121200 | performance: 17.0 | accuracy: 0.25 | loss: 0.62
update:1520/2000, 耗时:0.00分/5.60分 | step: 121600 | performance: 19.9 | accuracy: 0.25 | loss: 0.24
update:1525/2000, 耗时:0.00分/5.62分 | step: 122000 | performance: 21.1 | accuracy: 0.24 | loss: 2.20
update:1530/2000, 耗时:0.00分/5.63分 | step: 122400 | performance: 20.4 | accuracy: 0.23 | loss: 0.46
update:1535/2000, 耗时:0.00分/5.65分 | step: 122800 | performance: 39.4 | accuracy: 0.24 | loss: 1.17
update:1540/2000, 耗时:0.00分/5.67分 | step: 123200 | performance: 30.5 | accuracy: 0.23 | loss: 0.72
update:1545/2000, 耗时:0.00分/5.69分 | step: 123600 | performance: 30.7 | accuracy: 0.23 | loss: 0.19
update:1550/2000, 耗时:0.00分/5.71分 | step: 124000 | performance: 37.7 | accuracy: 0.23 | loss: 1.05
update:1555/2000, 耗时:0.00分/5.72分 | step: 124400 | performance: 31.9 | accuracy: 0.23 | loss: 0.58
update:1560/2000, 耗时:0.00分/5.74分 | step: 124800 | performance: 20.5 | accuracy: 0.23 | loss: 1.48
update:1565/2000, 耗时:0.00分/5.76分 | step: 125200 | performance: 14.8 | accuracy: 0.23 | loss: 3.00
update:1570/2000, 耗时:0.00分/5.78分 | step: 125600 | performance: 8.7 | accuracy: 0.24 | loss: 2.14
update:1575/2000, 耗时:0.00分/5.79分 | step: 126000 | performance: 3.7 | accuracy: 0.24 | loss: 3.10
update:1580/2000, 耗时:0.00分/5.81分 | step: 126400 | performance: 4.0 | accuracy: 0.25 | loss: 3.52
update:1585/2000, 耗时:0.00分/5.83分 | step: 126800 | performance: 3.7 | accuracy: 0.26 | loss: 1.64
update:1590/2000, 耗时:0.00分/5.85分 | step: 127200 | performance: 3.2 | accuracy: 0.26 | loss: 1.14
update:1595/2000, 耗时:0.00分/5.87分 | step: 127600 | performance: 4.3 | accuracy: 0.26 | loss: 1.50
update:1600/2000, 耗时:0.00分/5.88分 | step: 128000 | performance: 3.9 | accuracy: 0.26 | loss: 0.64
update:1605/2000, 耗时:0.00分/5.90分 | step: 128400 | performance: 4.4 | accuracy: 0.26 | loss: 0.39
update:1610/2000, 耗时:0.00分/5.92分 | step: 128800 | performance: 3.3 | accuracy: 0.25 | loss: 0.43
update:1615/2000, 耗时:0.00分/5.94分 | step: 129200 | performance: 3.5 | accuracy: 0.25 | loss: 0.33
update:1620/2000, 耗时:0.00分/5.95分 | step: 129600 | performance: 3.8 | accuracy: 0.25 | loss: 0.91
update:1625/2000, 耗时:0.00分/5.97分 | step: 130000 | performance: 8.9 | accuracy: 0.26 | loss: 5.95
update:1630/2000, 耗时:0.00分/5.99分 | step: 130400 | performance: 84.9 | accuracy: 0.26 | loss: 1.48
update:1635/2000, 耗时:0.00分/6.01分 | step: 130800 | performance: 85.9 | accuracy: 0.26 | loss: 0.41
update:1640/2000, 耗时:0.00分/6.03分 | step: 131200 | performance: 133.7 | accuracy: 0.26 | loss: 3.17
update:1645/2000, 耗时:0.00分/6.04分 | step: 131600 | performance: 136.7 | accuracy: 0.26 | loss: 0.89
update:1650/2000, 耗时:0.00分/6.06分 | step: 132000 | performance: 149.4 | accuracy: 0.27 | loss: 1.39
update:1655/2000, 耗时:0.00分/6.08分 | step: 132400 | performance: 159.6 | accuracy: 0.27 | loss: 1.90
update:1660/2000, 耗时:0.00分/6.10分 | step: 132800 | performance: 213.6 | accuracy: 0.28 | loss: 4.12
update:1665/2000, 耗时:0.00分/6.11分 | step: 133200 | performance: 308.1 | accuracy: 0.28 | loss: 2.22
update:1670/2000, 耗时:0.00分/6.13分 | step: 133600 | performance: 193.8 | accuracy: 0.28 | loss: 1.57
update:1675/2000, 耗时:0.00分/6.15分 | step: 134000 | performance: 117.7 | accuracy: 0.28 | loss: 6.05
update:1680/2000, 耗时:0.00分/6.17分 | step: 134400 | performance: 39.3 | accuracy: 0.28 | loss: 6.20
update:1685/2000, 耗时:0.00分/6.19分 | step: 134800 | performance: 14.9 | accuracy: 0.28 | loss: 2.17
update:1690/2000, 耗时:0.00分/6.20分 | step: 135200 | performance: 40.9 | accuracy: 0.29 | loss: 4.54
update:1695/2000, 耗时:0.00分/6.22分 | step: 135600 | performance: 61.0 | accuracy: 0.29 | loss: 3.16
update:1700/2000, 耗时:0.00分/6.24分 | step: 136000 | performance: 26.7 | accuracy: 0.29 | loss: 4.35
update:1705/2000, 耗时:0.00分/6.26分 | step: 136400 | performance: 30.0 | accuracy: 0.29 | loss: 1.01
update:1710/2000, 耗时:0.00分/6.28分 | step: 136800 | performance: 30.8 | accuracy: 0.30 | loss: 4.28
update:1715/2000, 耗时:0.00分/6.29分 | step: 137200 | performance: 196.2 | accuracy: 0.30 | loss: 2.81
update:1720/2000, 耗时:0.00分/6.31分 | step: 137600 | performance: 112.6 | accuracy: 0.30 | loss: 1.17
update:1725/2000, 耗时:0.00分/6.33分 | step: 138000 | performance: 101.3 | accuracy: 0.29 | loss: 0.33
update:1730/2000, 耗时:0.00分/6.35分 | step: 138400 | performance: 56.4 | accuracy: 0.29 | loss: 2.25
update:1735/2000, 耗时:0.00分/6.37分 | step: 138800 | performance: 75.2 | accuracy: 0.29 | loss: 1.10
update:1740/2000, 耗时:0.00分/6.38分 | step: 139200 | performance: 124.7 | accuracy: 0.30 | loss: 1.26
update:1745/2000, 耗时:0.00分/6.40分 | step: 139600 | performance: 146.7 | accuracy: 0.30 | loss: 1.91
update:1750/2000, 耗时:0.00分/6.42分 | step: 140000 | performance: 128.3 | accuracy: 0.30 | loss: 2.43
update:1755/2000, 耗时:0.00分/6.44分 | step: 140400 | performance: 220.0 | accuracy: 0.31 | loss: 1.36
update:1760/2000, 耗时:0.00分/6.46分 | step: 140800 | performance: 210.9 | accuracy: 0.30 | loss: 0.62
update:1765/2000, 耗时:0.00分/6.47分 | step: 141200 | performance: 240.4 | accuracy: 0.30 | loss: 1.25
update:1770/2000, 耗时:0.00分/6.49分 | step: 141600 | performance: 224.8 | accuracy: 0.30 | loss: 1.01
update:1775/2000, 耗时:0.00分/6.51分 | step: 142000 | performance: 190.2 | accuracy: 0.30 | loss: 0.79
update:1780/2000, 耗时:0.00分/6.53分 | step: 142400 | performance: 319.4 | accuracy: 0.30 | loss: 1.66
update:1785/2000, 耗时:0.00分/6.55分 | step: 142800 | performance: 623.9 | accuracy: 0.30 | loss: 2.22
update:1790/2000, 耗时:0.00分/6.57分 | step: 143200 | performance: 530.5 | accuracy: 0.30 | loss: 0.35
update:1795/2000, 耗时:0.00分/6.58分 | step: 143600 | performance: 548.0 | accuracy: 0.30 | loss: 0.83
update:1800/2000, 耗时:0.00分/6.60分 | step: 144000 | performance: 659.7 | accuracy: 0.30 | loss: 0.67
update:1805/2000, 耗时:0.00分/6.62分 | step: 144400 | performance: 618.8 | accuracy: 0.29 | loss: 0.93
update:1810/2000, 耗时:0.00分/6.64分 | step: 144800 | performance: 1059.5 | accuracy: 0.29 | loss: 0.69
update:1815/2000, 耗时:0.00分/6.66分 | step: 145200 | performance: 894.6 | accuracy: 0.29 | loss: 0.27
update:1820/2000, 耗时:0.00分/6.68分 | step: 145600 | performance: 836.4 | accuracy: 0.29 | loss: 0.47
update:1825/2000, 耗时:0.00分/6.69分 | step: 146000 | performance: 776.4 | accuracy: 0.29 | loss: 0.24
update:1830/2000, 耗时:0.00分/6.71分 | step: 146400 | performance: 867.9 | accuracy: 0.29 | loss: 0.45
Saving PPO weights in both H5 format and checkpoint @ update:1833 
update:1835/2000, 耗时:0.00分/6.73分 | step: 146800 | performance: 0.7 | accuracy: 0.48 | loss: 5.51
update:1840/2000, 耗时:0.00分/6.75分 | step: 147200 | performance: 3.5 | accuracy: 0.45 | loss: 4.66
update:1845/2000, 耗时:0.00分/6.77分 | step: 147600 | performance: 2.2 | accuracy: 0.35 | loss: 0.53
update:1850/2000, 耗时:0.00分/6.79分 | step: 148000 | performance: 1.0 | accuracy: 0.30 | loss: 0.82
update:1855/2000, 耗时:0.00分/6.81分 | step: 148400 | performance: 0.9 | accuracy: 0.25 | loss: 0.57
update:1860/2000, 耗时:0.00分/6.82分 | step: 148800 | performance: 1.8 | accuracy: 0.25 | loss: 1.14
update:1865/2000, 耗时:0.00分/6.84分 | step: 149200 | performance: 1.7 | accuracy: 0.22 | loss: 0.42
update:1870/2000, 耗时:0.00分/6.86分 | step: 149600 | performance: 1.9 | accuracy: 0.22 | loss: 0.90
update:1875/2000, 耗时:0.00分/6.88分 | step: 150000 | performance: 2.7 | accuracy: 0.22 | loss: 1.11
update:1880/2000, 耗时:0.00分/6.90分 | step: 150400 | performance: 5.2 | accuracy: 0.24 | loss: 0.75
update:1885/2000, 耗时:0.00分/6.91分 | step: 150800 | performance: 8.0 | accuracy: 0.24 | loss: 2.14
update:1890/2000, 耗时:0.00分/6.93分 | step: 151200 | performance: 8.0 | accuracy: 0.23 | loss: 0.50
update:1895/2000, 耗时:0.00分/6.95分 | step: 151600 | performance: 6.5 | accuracy: 0.23 | loss: 0.29
update:1900/2000, 耗时:0.00分/6.97分 | step: 152000 | performance: 11.2 | accuracy: 0.23 | loss: 2.84
update:1905/2000, 耗时:0.00分/6.99分 | step: 152400 | performance: 6.4 | accuracy: 0.22 | loss: 0.38
update:1910/2000, 耗时:0.00分/7.01分 | step: 152800 | performance: 7.6 | accuracy: 0.22 | loss: 1.00
update:1915/2000, 耗时:0.00分/7.03分 | step: 153200 | performance: 7.1 | accuracy: 0.22 | loss: 0.74
update:1920/2000, 耗时:0.00分/7.05分 | step: 153600 | performance: 8.3 | accuracy: 0.22 | loss: 0.82
update:1925/2000, 耗时:0.00分/7.06分 | step: 154000 | performance: 4.3 | accuracy: 0.22 | loss: 4.03
update:1930/2000, 耗时:0.00分/7.08分 | step: 154400 | performance: 3.8 | accuracy: 0.23 | loss: 2.83
update:1935/2000, 耗时:0.00分/7.10分 | step: 154800 | performance: 4.2 | accuracy: 0.24 | loss: 1.66
update:1940/2000, 耗时:0.00分/7.12分 | step: 155200 | performance: 1.9 | accuracy: 0.24 | loss: 6.97
update:1945/2000, 耗时:0.00分/7.14分 | step: 155600 | performance: 1.2 | accuracy: 0.25 | loss: 2.42
update:1950/2000, 耗时:0.00分/7.15分 | step: 156000 | performance: 1.6 | accuracy: 0.26 | loss: 2.81
update:1955/2000, 耗时:0.00分/7.17分 | step: 156400 | performance: 1.6 | accuracy: 0.26 | loss: 1.51
update:1960/2000, 耗时:0.00分/7.19分 | step: 156800 | performance: 1.8 | accuracy: 0.26 | loss: 1.75
update:1965/2000, 耗时:0.00分/7.21分 | step: 157200 | performance: 1.9 | accuracy: 0.25 | loss: 0.24
update:1970/2000, 耗时:0.00分/7.23分 | step: 157600 | performance: 1.7 | accuracy: 0.25 | loss: 0.45
update:1975/2000, 耗时:0.00分/7.24分 | step: 158000 | performance: 1.9 | accuracy: 0.25 | loss: 0.24
update:1980/2000, 耗时:0.00分/7.26分 | step: 158400 | performance: 1.6 | accuracy: 0.25 | loss: 0.53
update:1985/2000, 耗时:0.00分/7.28分 | step: 158800 | performance: 1.0 | accuracy: 0.24 | loss: 4.62
update:1990/2000, 耗时:0.00分/7.30分 | step: 159200 | performance: 1.1 | accuracy: 0.25 | loss: 1.73
update:1995/2000, 耗时:0.00分/7.32分 | step: 159600 | performance: 14.1 | accuracy: 0.26 | loss: 3.14
update:2000/2000, 耗时:0.00分/7.33分 | step: 160000 | performance: 21.0 | accuracy: 0.26 | loss: 0.98
----------------------------------------finished----------------------------------------
  0%|          | 0/408 [00:00<?, ?it/s]100%|| 408/408 [00:00<00:00, 89142.89it/s]
==================================================
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1475.82
2023-07-24T12:00:00 | net performance [%] = 47.5820
2023-07-24T12:00:00 | number of trades [#] = 92
==================================================
Trial 56 Complete [00h 07m 47s]
net_wealth: 1477.2977188757022

Best net_wealth So Far: 1824.8039564105297
Total elapsed time: 07h 43m 41s

Search: Running Trial #57

Value             |Best Value So Far |Hyperparameter
3                 |6                 |horizon
225               |365               |lookback
False             |True              |MarketFactor
20                |10                |lags
0.98              |0.98              |gamma
32                |16                |batch_size
7                 |7                 |n_step
0.85              |0.94              |gae_lambda
10                |0.5               |gradient_clip_norm
5                 |3                 |epochs
5e-05             |0.001             |actor_lr
0.001             |0.001             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4312.000000   4315.000000
mean      0.000441    20062.255222  ...   20129.629835  20118.633889
std       0.027818    16039.874230  ...   16077.282571  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7694.525024   7690.540039
50%       0.000642    11554.824463  ...   11737.255371  11715.610352
75%       0.011655    29873.081836  ...   29933.737305  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 05:47:05.230448: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the follow2023-07-28 05:47:05.230528: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized 2023-07-28 05:47:05.230588: I tensorflow2ing CPU instr0with 20223-07-28 05:/437c:-0or507-28 05:47:05.230610: I t.e2e/3n0p6l2a6sorflot:wfor/core/platform/cpu_feature_gua m/cpuIr _td.ccfenso:r1of42] This Telow/cuocrnnetsie/oplatforrAPI Deep Neural NetwormFlow /kc Libpbui_rfneaartauyr is er_ogyuptimia r(onedz.ed Dcc:o142] ThiNN) to use the followingeats Tensu Cnws in peitohrrFl ooe_gwne uabAPirdnI Da.ccreey:14 p i2] sNePUuralThi  sop itTeinnmisszedot wrriu2tcFlho0 o2t3inw binary ioe-s opr0API27n0tf-orm ance-2i3 Dse inN p2et-8m ierf205:40ep707-oz eNdew2u23rr owmaia-8rlk   N05Letwornkce-c ricriticaliticbr o:pe0a7rtaa0-htlio2 roy5 (.onns:en2  AePI3 10 op1DADeNre9e:pat I NiV:euLralibr 4 N)NaetX7r8w : yt o oA (uo0Vonnes:srek D5t Xetns N:47o2rhfe :
lAow/fVNX) co ot0o5 u Tl.seoL2i3bAraV11 erXy2 ( tlown0a25b.heil
2 Tof re631 t:hen0g 6I1 eteensno /m:r I apblifnl C Potoelwat he/nscotUerfrhtoflree oorwmo oper/anteioD/ccoorNeN/lplp)u_mn si/ , lonirnpawife easntgr btouottCPU i unstrlsauucthecttfofitldi ruo rotmirTe_eme/r/ gopnhounasr desroatens .ciccppuu_rc_fiin peof:e14rf2oaFtelnn foarouwr m epsl_logaweiwing ,n ceuCaPUr-rdtu] tTh  .ercbruiihtihsrtlid cTc:ci neenfsos1 4aaplTorrFlo eonpseorraFmwtpianlo ns2r]o :e_gutwo pcawbrriTihth uctie a teAridi-.cctcs:Vrh 1X Ain cToenet iacppalrsaoomn opoe42]rrpaypriVlXr iFilso  otpitoaTewt br2 ehiinmi c
azfloiresags. mipT
d withilenn oys si n:r so  e   ApTeernfsonfolVeAPapoaX rAVX2
TmIao  rebgsDnFabncelloet.e-ep
 imcwrltih  Nbee m eizieitutinda rn hwcraoteiatlyh il Nes mo i h ro onpnpeeA toimeropePIaition Deets,r arebuild TensorFlow with the appropriate compiler flags.
ther operations, rebuild TensorFlow with the appropriate compiler flags.
work Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operationstions:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropria, rebuild TensorFlow with the appropriate compiler flags.
zed with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
te compiler flags.
p Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 05:47:05.826898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:47:05.835114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:47:05.835589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:47:05.864829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:47:05.865061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:47:05.873682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:47:05.885632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:47:05.886781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
step: 166 | worker_5@n_step_6: average total_reward after train data exhaustion : -7.1 | max total_reward: -5.0
Saving PPO weights in both H5 format and checkpoint @ update:3 
update:  5/2000, 耗时:0.00分/0.04分 | step:   280 | performance: 0.9 | accuracy: 0.26 | loss: 1.38
update: 10/2000, 耗时:0.00分/0.05分 | step:   560 | performance: 1.0 | accuracy: 0.26 | loss: 1.04
update: 15/2000, 耗时:0.00分/0.06分 | step:   840 | performance: 0.6 | accuracy: 0.20 | loss: 0.97
update: 20/2000, 耗时:0.00分/0.08分 | step:  1120 | performance: 0.6 | accuracy: 0.25 | loss: 1.58
update: 25/2000, 耗时:0.00分/0.09分 | step:  1400 | performance: 0.5 | accuracy: 0.23 | loss: 1.25
update: 30/2000, 耗时:0.00分/0.10分 | step:  1680 | performance: 0.6 | accuracy: 0.23 | loss: 0.54
update: 35/2000, 耗时:0.00分/0.12分 | step:  1960 | performance: 0.4 | accuracy: 0.22 | loss: 1.15
update: 40/2000, 耗时:0.00分/0.13分 | step:  2240 | performance: 0.3 | accuracy: 0.24 | loss: 0.65
update: 45/2000, 耗时:0.00分/0.15分 | step:  2520 | performance: 0.3 | accuracy: 0.23 | loss: 1.04
update: 50/2000, 耗时:0.00分/0.16分 | step:  2800 | performance: 0.2 | accuracy: 0.21 | loss: 0.64
update: 55/2000, 耗时:0.00分/0.18分 | step:  3080 | performance: 0.3 | accuracy: 0.21 | loss: 0.22
update: 60/2000, 耗时:0.00分/0.19分 | step:  3360 | performance: 0.2 | accuracy: 0.21 | loss: 1.28
update: 65/2000, 耗时:0.00分/0.21分 | step:  3640 | performance: 0.2 | accuracy: 0.22 | loss: 1.09
update: 70/2000, 耗时:0.00分/0.23分 | step:  3920 | performance: 0.2 | accuracy: 0.21 | loss: 1.09
update: 75/2000, 耗时:0.00分/0.24分 | step:  4200 | performance: 0.3 | accuracy: 0.22 | loss: 0.54
update: 80/2000, 耗时:0.00分/0.26分 | step:  4480 | performance: 0.3 | accuracy: 0.21 | loss: 0.59
update: 85/2000, 耗时:0.00分/0.27分 | step:  4760 | performance: 0.2 | accuracy: 0.22 | loss: 1.02
update: 90/2000, 耗时:0.00分/0.29分 | step:  5040 | performance: 0.2 | accuracy: 0.22 | loss: 0.50
update: 95/2000, 耗时:0.00分/0.31分 | step:  5320 | performance: 0.3 | accuracy: 0.22 | loss: 1.02
update:100/2000, 耗时:0.00分/0.32分 | step:  5600 | performance: 0.3 | accuracy: 0.21 | loss: 0.73
update:105/2000, 耗时:0.00分/0.34分 | step:  5880 | performance: 0.2 | accuracy: 0.21 | loss: 0.66
update:110/2000, 耗时:0.00分/0.35分 | step:  6160 | performance: 0.2 | accuracy: 0.21 | loss: 0.31
update:115/2000, 耗时:0.00分/0.37分 | step:  6440 | performance: 0.2 | accuracy: 0.21 | loss: 0.35
update:120/2000, 耗时:0.00分/0.39分 | step:  6720 | performance: 0.2 | accuracy: 0.20 | loss: 0.68
update:125/2000, 耗时:0.00分/0.40分 | step:  7000 | performance: 0.2 | accuracy: 0.21 | loss: 0.57
update:130/2000, 耗时:0.00分/0.42分 | step:  7280 | performance: 0.2 | accuracy: 0.21 | loss: 0.88
update:135/2000, 耗时:0.00分/0.43分 | step:  7560 | performance: 0.3 | accuracy: 0.23 | loss: 0.80
update:140/2000, 耗时:0.00分/0.45分 | step:  7840 | performance: 0.4 | accuracy: 0.24 | loss: 1.85
update:145/2000, 耗时:0.00分/0.47分 | step:  8120 | performance: 1.1 | accuracy: 0.26 | loss: 2.28
update:150/2000, 耗时:0.00分/0.48分 | step:  8400 | performance: 1.2 | accuracy: 0.26 | loss: 2.83
update:155/2000, 耗时:0.00分/0.50分 | step:  8680 | performance: 2.3 | accuracy: 0.28 | loss: 5.13
update:160/2000, 耗时:0.00分/0.51分 | step:  8960 | performance: 3.3 | accuracy: 0.29 | loss: 2.96
update:165/2000, 耗时:0.00分/0.53分 | step:  9240 | performance: 1.0 | accuracy: 0.29 | loss: 2.61
update:170/2000, 耗时:0.00分/0.54分 | step:  9520 | performance: 0.8 | accuracy: 0.29 | loss: 4.58
update:175/2000, 耗时:0.00分/0.56分 | step:  9800 | performance: 0.7 | accuracy: 0.30 | loss: 0.65
update:180/2000, 耗时:0.00分/0.58分 | step: 10080 | performance: 0.7 | accuracy: 0.30 | loss: 0.89
update:185/2000, 耗时:0.00分/0.59分 | step: 10360 | performance: 0.6 | accuracy: 0.29 | loss: 0.59
update:190/2000, 耗时:0.00分/0.61分 | step: 10640 | performance: 0.6 | accuracy: 0.29 | loss: 0.58
update:195/2000, 耗时:0.00分/0.62分 | step: 10920 | performance: 0.4 | accuracy: 0.29 | loss: 0.95
update:200/2000, 耗时:0.00分/0.64分 | step: 11200 | performance: 0.5 | accuracy: 0.29 | loss: 0.98
update:205/2000, 耗时:0.00分/0.65分 | step: 11480 | performance: 0.6 | accuracy: 0.28 | loss: 0.29
update:210/2000, 耗时:0.00分/0.67分 | step: 11760 | performance: 0.6 | accuracy: 0.29 | loss: 1.02
update:215/2000, 耗时:0.00分/0.69分 | step: 12040 | performance: 0.5 | accuracy: 0.28 | loss: 0.78
update:220/2000, 耗时:0.00分/0.70分 | step: 12320 | performance: 0.5 | accuracy: 0.29 | loss: 1.52
update:225/2000, 耗时:0.00分/0.72分 | step: 12600 | performance: 0.5 | accuracy: 0.29 | loss: 1.31
update:230/2000, 耗时:0.00分/0.73分 | step: 12880 | performance: 0.2 | accuracy: 0.29 | loss: 2.40
update:235/2000, 耗时:0.00分/0.75分 | step: 13160 | performance: 0.1 | accuracy: 0.29 | loss: 1.41
update:240/2000, 耗时:0.00分/0.77分 | step: 13440 | performance: 0.1 | accuracy: 0.29 | loss: 0.43
update:245/2000, 耗时:0.00分/0.78分 | step: 13720 | performance: 0.1 | accuracy: 0.29 | loss: 0.46
update:250/2000, 耗时:0.00分/0.80分 | step: 14000 | performance: 0.2 | accuracy: 0.29 | loss: 1.56
update:255/2000, 耗时:0.00分/0.81分 | step: 14280 | performance: 0.1 | accuracy: 0.29 | loss: 0.64
update:260/2000, 耗时:0.00分/0.83分 | step: 14560 | performance: 0.1 | accuracy: 0.30 | loss: 1.69
update:265/2000, 耗时:0.00分/0.85分 | step: 14840 | performance: 0.1 | accuracy: 0.30 | loss: 0.70
update:270/2000, 耗时:0.00分/0.86分 | step: 15120 | performance: 0.1 | accuracy: 0.30 | loss: 1.86
update:275/2000, 耗时:0.00分/0.88分 | step: 15400 | performance: 0.2 | accuracy: 0.30 | loss: 2.26
update:280/2000, 耗时:0.00分/0.90分 | step: 15680 | performance: 0.1 | accuracy: 0.31 | loss: 1.37
update:285/2000, 耗时:0.00分/0.91分 | step: 15960 | performance: 0.1 | accuracy: 0.30 | loss: 0.89
update:290/2000, 耗时:0.00分/0.93分 | step: 16240 | performance: 0.1 | accuracy: 0.30 | loss: 0.63
update:295/2000, 耗时:0.00分/0.94分 | step: 16520 | performance: 0.1 | accuracy: 0.31 | loss: 1.73
update:300/2000, 耗时:0.00分/0.96分 | step: 16800 | performance: 0.2 | accuracy: 0.31 | loss: 1.29
update:305/2000, 耗时:0.00分/0.98分 | step: 17080 | performance: 0.4 | accuracy: 0.32 | loss: 2.51
update:310/2000, 耗时:0.00分/0.99分 | step: 17360 | performance: 0.7 | accuracy: 0.32 | loss: 3.36
update:315/2000, 耗时:0.00分/1.01分 | step: 17640 | performance: 2.5 | accuracy: 0.33 | loss: 5.86
update:320/2000, 耗时:0.00分/1.03分 | step: 17920 | performance: 2.6 | accuracy: 0.33 | loss: 3.24
update:325/2000, 耗时:0.00分/1.04分 | step: 18200 | performance: 3.2 | accuracy: 0.33 | loss: 3.60
update:330/2000, 耗时:0.00分/1.06分 | step: 18480 | performance: 3.9 | accuracy: 0.34 | loss: 3.44
update:335/2000, 耗时:0.00分/1.08分 | step: 18760 | performance: 6.4 | accuracy: 0.34 | loss: 2.34
update:340/2000, 耗时:0.00分/1.09分 | step: 19040 | performance: 5.7 | accuracy: 0.35 | loss: 1.61
update:345/2000, 耗时:0.00分/1.11分 | step: 19320 | performance: 4.3 | accuracy: 0.35 | loss: 6.82
update:350/2000, 耗时:0.00分/1.13分 | step: 19600 | performance: 3.0 | accuracy: 0.35 | loss: 2.00
update:355/2000, 耗时:0.00分/1.14分 | step: 19880 | performance: 1.7 | accuracy: 0.35 | loss: 1.59
update:360/2000, 耗时:0.00分/1.16分 | step: 20160 | performance: 1.9 | accuracy: 0.35 | loss: 1.25
update:365/2000, 耗时:0.00分/1.17分 | step: 20440 | performance: 2.2 | accuracy: 0.34 | loss: 1.23
update:370/2000, 耗时:0.00分/1.19分 | step: 20720 | performance: 2.4 | accuracy: 0.34 | loss: 1.48
update:375/2000, 耗时:0.00分/1.20分 | step: 21000 | performance: 2.2 | accuracy: 0.34 | loss: 0.76
update:380/2000, 耗时:0.00分/1.22分 | step: 21280 | performance: 2.3 | accuracy: 0.34 | loss: 1.99
update:385/2000, 耗时:0.00分/1.24分 | step: 21560 | performance: 2.6 | accuracy: 0.34 | loss: 0.53
update:390/2000, 耗时:0.00分/1.25分 | step: 21840 | performance: 1.8 | accuracy: 0.34 | loss: 1.64
update:395/2000, 耗时:0.00分/1.27分 | step: 22120 | performance: 2.6 | accuracy: 0.35 | loss: 0.76
update:400/2000, 耗时:0.00分/1.29分 | step: 22400 | performance: 2.9 | accuracy: 0.35 | loss: 0.94
update:405/2000, 耗时:0.00分/1.30分 | step: 22680 | performance: 3.4 | accuracy: 0.35 | loss: 1.35
update:410/2000, 耗时:0.00分/1.32分 | step: 22960 | performance: 2.3 | accuracy: 0.35 | loss: 1.28
update:415/2000, 耗时:0.00分/1.34分 | step: 23240 | performance: 1.7 | accuracy: 0.35 | loss: 0.75
update:420/2000, 耗时:0.00分/1.35分 | step: 23520 | performance: 1.6 | accuracy: 0.35 | loss: 0.59
update:425/2000, 耗时:0.00分/1.37分 | step: 23800 | performance: 2.5 | accuracy: 0.35 | loss: 2.23
update:430/2000, 耗时:0.00分/1.38分 | step: 24080 | performance: 1.5 | accuracy: 0.35 | loss: 1.21
update:435/2000, 耗时:0.00分/1.40分 | step: 24360 | performance: 2.1 | accuracy: 0.35 | loss: 1.35
update:440/2000, 耗时:0.00分/1.42分 | step: 24640 | performance: 2.2 | accuracy: 0.35 | loss: 3.38
update:445/2000, 耗时:0.00分/1.43分 | step: 24920 | performance: 1.7 | accuracy: 0.35 | loss: 1.22
update:450/2000, 耗时:0.00分/1.45分 | step: 25200 | performance: 1.7 | accuracy: 0.35 | loss: 1.16
update:455/2000, 耗时:0.00分/1.47分 | step: 25480 | performance: 2.4 | accuracy: 0.35 | loss: 2.12
update:460/2000, 耗时:0.00分/1.48分 | step: 25760 | performance: 3.8 | accuracy: 0.35 | loss: 0.78
update:465/2000, 耗时:0.00分/1.50分 | step: 26040 | performance: 4.4 | accuracy: 0.35 | loss: 3.08
update:470/2000, 耗时:0.00分/1.51分 | step: 26320 | performance: 10.9 | accuracy: 0.36 | loss: 3.15
update:475/2000, 耗时:0.00分/1.53分 | step: 26600 | performance: 9.7 | accuracy: 0.36 | loss: 4.19
update:480/2000, 耗时:0.00分/1.55分 | step: 26880 | performance: 8.5 | accuracy: 0.36 | loss: 1.32
update:485/2000, 耗时:0.00分/1.56分 | step: 27160 | performance: 6.9 | accuracy: 0.36 | loss: 1.26
update:490/2000, 耗时:0.00分/1.58分 | step: 27440 | performance: 8.8 | accuracy: 0.36 | loss: 1.74
update:495/2000, 耗时:0.00分/1.59分 | step: 27720 | performance: 11.0 | accuracy: 0.36 | loss: 1.35
update:500/2000, 耗时:0.00分/1.61分 | step: 28000 | performance: 12.7 | accuracy: 0.36 | loss: 1.42
update:505/2000, 耗时:0.00分/1.62分 | step: 28280 | performance: 10.2 | accuracy: 0.36 | loss: 1.07
update:510/2000, 耗时:0.00分/1.64分 | step: 28560 | performance: 16.7 | accuracy: 0.36 | loss: 0.65
update:515/2000, 耗时:0.00分/1.65分 | step: 28840 | performance: 17.1 | accuracy: 0.37 | loss: 1.17
update:520/2000, 耗时:0.00分/1.67分 | step: 29120 | performance: 18.3 | accuracy: 0.37 | loss: 0.98
Saving PPO weights in both H5 format and checkpoint @ update:524 
update:525/2000, 耗时:0.00分/1.69分 | step: 29400 | performance: 0.7 | accuracy: 0.31 | loss: 1.71
Saving PPO weights in both H5 format and checkpoint @ update:527 
update:530/2000, 耗时:0.00分/1.71分 | step: 29680 | performance: 0.7 | accuracy: 0.35 | loss: 3.81
Saving PPO weights in both H5 format and checkpoint @ update:531 
update:535/2000, 耗时:0.00分/1.73分 | step: 29960 | performance: 0.7 | accuracy: 0.35 | loss: 2.99
update:540/2000, 耗时:0.00分/1.75分 | step: 30240 | performance: 0.6 | accuracy: 0.37 | loss: 5.42
update:545/2000, 耗时:0.00分/1.76分 | step: 30520 | performance: 0.7 | accuracy: 0.37 | loss: 1.89
update:550/2000, 耗时:0.00分/1.78分 | step: 30800 | performance: 1.4 | accuracy: 0.41 | loss: 5.95
update:555/2000, 耗时:0.00分/1.79分 | step: 31080 | performance: 0.9 | accuracy: 0.40 | loss: 0.87
update:560/2000, 耗时:0.00分/1.81分 | step: 31360 | performance: 0.6 | accuracy: 0.38 | loss: 1.59
update:565/2000, 耗时:0.00分/1.82分 | step: 31640 | performance: 0.8 | accuracy: 0.39 | loss: 1.41
update:570/2000, 耗时:0.00分/1.84分 | step: 31920 | performance: 0.9 | accuracy: 0.40 | loss: 1.64
update:575/2000, 耗时:0.00分/1.85分 | step: 32200 | performance: 1.6 | accuracy: 0.41 | loss: 1.10
update:580/2000, 耗时:0.00分/1.87分 | step: 32480 | performance: 1.6 | accuracy: 0.42 | loss: 1.06
update:585/2000, 耗时:0.00分/1.89分 | step: 32760 | performance: 0.8 | accuracy: 0.40 | loss: 1.16
update:590/2000, 耗时:0.00分/1.90分 | step: 33040 | performance: 1.3 | accuracy: 0.41 | loss: 2.01
update:595/2000, 耗时:0.00分/1.92分 | step: 33320 | performance: 1.0 | accuracy: 0.41 | loss: 1.97
update:600/2000, 耗时:0.00分/1.93分 | step: 33600 | performance: 0.9 | accuracy: 0.41 | loss: 1.38
update:605/2000, 耗时:0.00分/1.95分 | step: 33880 | performance: 1.0 | accuracy: 0.41 | loss: 1.21
update:610/2000, 耗时:0.00分/1.97分 | step: 34160 | performance: 0.9 | accuracy: 0.40 | loss: 1.23
update:615/2000, 耗时:0.00分/1.98分 | step: 34440 | performance: 0.9 | accuracy: 0.41 | loss: 0.76
update:620/2000, 耗时:0.00分/2.00分 | step: 34720 | performance: 2.9 | accuracy: 0.42 | loss: 1.75
update:625/2000, 耗时:0.00分/2.02分 | step: 35000 | performance: 4.7 | accuracy: 0.42 | loss: 6.75
update:630/2000, 耗时:0.00分/2.03分 | step: 35280 | performance: 4.6 | accuracy: 0.43 | loss: 1.27
update:635/2000, 耗时:0.00分/2.05分 | step: 35560 | performance: 6.0 | accuracy: 0.43 | loss: 1.82
update:640/2000, 耗时:0.00分/2.06分 | step: 35840 | performance: 5.7 | accuracy: 0.43 | loss: 1.95
update:645/2000, 耗时:0.00分/2.08分 | step: 36120 | performance: 5.8 | accuracy: 0.42 | loss: 1.06
update:650/2000, 耗时:0.00分/2.10分 | step: 36400 | performance: 5.8 | accuracy: 0.42 | loss: 2.17
update:655/2000, 耗时:0.00分/2.11分 | step: 36680 | performance: 10.4 | accuracy: 0.42 | loss: 2.32
update:660/2000, 耗时:0.00分/2.13分 | step: 36960 | performance: 11.9 | accuracy: 0.43 | loss: 2.39
update:665/2000, 耗时:0.00分/2.15分 | step: 37240 | performance: 16.4 | accuracy: 0.43 | loss: 1.35
update:670/2000, 耗时:0.00分/2.16分 | step: 37520 | performance: 38.9 | accuracy: 0.44 | loss: 2.01
update:675/2000, 耗时:0.00分/2.18分 | step: 37800 | performance: 37.7 | accuracy: 0.44 | loss: 1.23
update:680/2000, 耗时:0.00分/2.19分 | step: 38080 | performance: 113.3 | accuracy: 0.45 | loss: 1.56
update:685/2000, 耗时:0.00分/2.21分 | step: 38360 | performance: 52.3 | accuracy: 0.45 | loss: 4.00
update:690/2000, 耗时:0.00分/2.23分 | step: 38640 | performance: 64.0 | accuracy: 0.45 | loss: 3.21
update:695/2000, 耗时:0.00分/2.24分 | step: 38920 | performance: 61.4 | accuracy: 0.46 | loss: 1.69
update:700/2000, 耗时:0.00分/2.26分 | step: 39200 | performance: 56.6 | accuracy: 0.46 | loss: 1.20
update:705/2000, 耗时:0.00分/2.28分 | step: 39480 | performance: 57.9 | accuracy: 0.45 | loss: 0.69
update:710/2000, 耗时:0.00分/2.29分 | step: 39760 | performance: 62.3 | accuracy: 0.45 | loss: 1.74
update:715/2000, 耗时:0.00分/2.31分 | step: 40040 | performance: 46.9 | accuracy: 0.45 | loss: 1.57
update:720/2000, 耗时:0.00分/2.32分 | step: 40320 | performance: 56.1 | accuracy: 0.45 | loss: 2.07
update:725/2000, 耗时:0.00分/2.34分 | step: 40600 | performance: 74.6 | accuracy: 0.45 | loss: 2.61
update:730/2000, 耗时:0.00分/2.36分 | step: 40880 | performance: 76.4 | accuracy: 0.46 | loss: 1.35
update:735/2000, 耗时:0.00分/2.37分 | step: 41160 | performance: 54.6 | accuracy: 0.45 | loss: 4.97
update:740/2000, 耗时:0.00分/2.39分 | step: 41440 | performance: 43.9 | accuracy: 0.45 | loss: 1.40
update:745/2000, 耗时:0.00分/2.41分 | step: 41720 | performance: 70.8 | accuracy: 0.45 | loss: 1.73
update:750/2000, 耗时:0.00分/2.42分 | step: 42000 | performance: 38.0 | accuracy: 0.45 | loss: 2.79
update:755/2000, 耗时:0.00分/2.44分 | step: 42280 | performance: 16.2 | accuracy: 0.45 | loss: 1.79
update:760/2000, 耗时:0.00分/2.45分 | step: 42560 | performance: 7.7 | accuracy: 0.45 | loss: 1.74
update:765/2000, 耗时:0.00分/2.47分 | step: 42840 | performance: 6.6 | accuracy: 0.45 | loss: 1.82
update:770/2000, 耗时:0.00分/2.49分 | step: 43120 | performance: 2.8 | accuracy: 0.44 | loss: 1.84
update:775/2000, 耗时:0.00分/2.50分 | step: 43400 | performance: 3.0 | accuracy: 0.44 | loss: 1.52
update:780/2000, 耗时:0.00分/2.52分 | step: 43680 | performance: 3.7 | accuracy: 0.44 | loss: 0.92
update:785/2000, 耗时:0.00分/2.54分 | step: 43960 | performance: 3.7 | accuracy: 0.44 | loss: 0.90
update:790/2000, 耗时:0.00分/2.55分 | step: 44240 | performance: 3.8 | accuracy: 0.44 | loss: 1.07
update:795/2000, 耗时:0.00分/2.57分 | step: 44520 | performance: 3.1 | accuracy: 0.44 | loss: 1.67
update:800/2000, 耗时:0.00分/2.59分 | step: 44800 | performance: 3.1 | accuracy: 0.44 | loss: 2.27
update:805/2000, 耗时:0.00分/2.60分 | step: 45080 | performance: 1.9 | accuracy: 0.44 | loss: 1.18
update:810/2000, 耗时:0.00分/2.62分 | step: 45360 | performance: 2.1 | accuracy: 0.44 | loss: 2.65
update:815/2000, 耗时:0.00分/2.63分 | step: 45640 | performance: 1.8 | accuracy: 0.43 | loss: 1.13
update:820/2000, 耗时:0.00分/2.65分 | step: 45920 | performance: 2.8 | accuracy: 0.44 | loss: 3.93
update:825/2000, 耗时:0.00分/2.67分 | step: 46200 | performance: 6.0 | accuracy: 0.44 | loss: 5.58
update:830/2000, 耗时:0.00分/2.68分 | step: 46480 | performance: 7.0 | accuracy: 0.44 | loss: 1.46
update:835/2000, 耗时:0.00分/2.70分 | step: 46760 | performance: 13.3 | accuracy: 0.45 | loss: 1.40
update:840/2000, 耗时:0.00分/2.72分 | step: 47040 | performance: 64.0 | accuracy: 0.45 | loss: 2.55
update:845/2000, 耗时:0.00分/2.73分 | step: 47320 | performance: 29.3 | accuracy: 0.45 | loss: 4.49
update:850/2000, 耗时:0.00分/2.75分 | step: 47600 | performance: 100.5 | accuracy: 0.45 | loss: 0.94
update:855/2000, 耗时:0.00分/2.76分 | step: 47880 | performance: 104.4 | accuracy: 0.46 | loss: 4.38
update:860/2000, 耗时:0.00分/2.78分 | step: 48160 | performance: 168.2 | accuracy: 0.46 | loss: 2.58
update:865/2000, 耗时:0.00分/2.80分 | step: 48440 | performance: 143.4 | accuracy: 0.46 | loss: 1.58
update:870/2000, 耗时:0.00分/2.81分 | step: 48720 | performance: 109.8 | accuracy: 0.46 | loss: 5.10
update:875/2000, 耗时:0.00分/2.83分 | step: 49000 | performance: 149.2 | accuracy: 0.46 | loss: 2.31
update:880/2000, 耗时:0.00分/2.84分 | step: 49280 | performance: 121.5 | accuracy: 0.46 | loss: 2.01
update:885/2000, 耗时:0.00分/2.86分 | step: 49560 | performance: 89.2 | accuracy: 0.46 | loss: 2.18
update:890/2000, 耗时:0.00分/2.88分 | step: 49840 | performance: 130.0 | accuracy: 0.46 | loss: 2.21
update:895/2000, 耗时:0.00分/2.89分 | step: 50120 | performance: 187.7 | accuracy: 0.46 | loss: 1.22
update:900/2000, 耗时:0.00分/2.91分 | step: 50400 | performance: 70.2 | accuracy: 0.46 | loss: 5.77
update:905/2000, 耗时:0.00分/2.93分 | step: 50680 | performance: 89.1 | accuracy: 0.46 | loss: 0.87
update:910/2000, 耗时:0.00分/2.95分 | step: 50960 | performance: 80.9 | accuracy: 0.46 | loss: 0.79
update:915/2000, 耗时:0.00分/2.96分 | step: 51240 | performance: 59.2 | accuracy: 0.46 | loss: 1.15
update:920/2000, 耗时:0.00分/2.98分 | step: 51520 | performance: 93.8 | accuracy: 0.46 | loss: 2.10
update:925/2000, 耗时:0.00分/3.00分 | step: 51800 | performance: 99.7 | accuracy: 0.46 | loss: 2.29
update:930/2000, 耗时:0.00分/3.01分 | step: 52080 | performance: 76.6 | accuracy: 0.46 | loss: 1.32
update:935/2000, 耗时:0.00分/3.03分 | step: 52360 | performance: 45.6 | accuracy: 0.46 | loss: 1.62
update:940/2000, 耗时:0.00分/3.05分 | step: 52640 | performance: 31.7 | accuracy: 0.45 | loss: 1.50
update:945/2000, 耗时:0.00分/3.06分 | step: 52920 | performance: 49.6 | accuracy: 0.46 | loss: 1.62
update:950/2000, 耗时:0.00分/3.08分 | step: 53200 | performance: 76.2 | accuracy: 0.46 | loss: 2.25
update:955/2000, 耗时:0.00分/3.10分 | step: 53480 | performance: 48.9 | accuracy: 0.46 | loss: 2.71
update:960/2000, 耗时:0.00分/3.12分 | step: 53760 | performance: 73.3 | accuracy: 0.46 | loss: 4.67
update:965/2000, 耗时:0.00分/3.13分 | step: 54040 | performance: 52.5 | accuracy: 0.46 | loss: 1.26
update:970/2000, 耗时:0.00分/3.15分 | step: 54320 | performance: 45.2 | accuracy: 0.46 | loss: 1.18
update:975/2000, 耗时:0.00分/3.17分 | step: 54600 | performance: 54.5 | accuracy: 0.46 | loss: 1.27
update:980/2000, 耗时:0.00分/3.19分 | step: 54880 | performance: 113.1 | accuracy: 0.46 | loss: 1.16
update:985/2000, 耗时:0.00分/3.20分 | step: 55160 | performance: 105.6 | accuracy: 0.46 | loss: 2.43
update:990/2000, 耗时:0.00分/3.22分 | step: 55440 | performance: 403.3 | accuracy: 0.46 | loss: 4.97
update:995/2000, 耗时:0.00分/3.24分 | step: 55720 | performance: 378.8 | accuracy: 0.46 | loss: 3.36
update:1000/2000, 耗时:0.00分/3.26分 | step: 56000 | performance: 274.6 | accuracy: 0.46 | loss: 1.26
update:1005/2000, 耗时:0.00分/3.27分 | step: 56280 | performance: 228.5 | accuracy: 0.46 | loss: 1.76
update:1010/2000, 耗时:0.00分/3.29分 | step: 56560 | performance: 361.4 | accuracy: 0.46 | loss: 2.46
update:1015/2000, 耗时:0.00分/3.31分 | step: 56840 | performance: 396.0 | accuracy: 0.46 | loss: 2.40
update:1020/2000, 耗时:0.00分/3.33分 | step: 57120 | performance: 429.9 | accuracy: 0.46 | loss: 1.46
update:1025/2000, 耗时:0.00分/3.34分 | step: 57400 | performance: 450.9 | accuracy: 0.46 | loss: 1.77
update:1030/2000, 耗时:0.00分/3.36分 | step: 57680 | performance: 332.9 | accuracy: 0.46 | loss: 3.96
update:1035/2000, 耗时:0.00分/3.38分 | step: 57960 | performance: 748.4 | accuracy: 0.46 | loss: 1.42
update:1040/2000, 耗时:0.00分/3.39分 | step: 58240 | performance: 686.0 | accuracy: 0.47 | loss: 0.91
update:1045/2000, 耗时:0.00分/3.41分 | step: 58520 | performance: 777.9 | accuracy: 0.47 | loss: 1.22
Saving PPO weights in both H5 format and checkpoint @ update:1047 
update:1050/2000, 耗时:0.00分/3.43分 | step: 58800 | performance: 1.0 | accuracy: 0.50 | loss: 5.01
Saving PPO weights in both H5 format and checkpoint @ update:1050 
Saving PPO weights in both H5 format and checkpoint @ update:1054 
update:1055/2000, 耗时:0.00分/3.46分 | step: 59080 | performance: 0.6 | accuracy: 0.49 | loss: 1.52
update:1060/2000, 耗时:0.00分/3.47分 | step: 59360 | performance: 1.4 | accuracy: 0.51 | loss: 1.36
update:1065/2000, 耗时:0.00分/3.49分 | step: 59640 | performance: 0.8 | accuracy: 0.47 | loss: 4.35
update:1070/2000, 耗时:0.00分/3.51分 | step: 59920 | performance: 0.9 | accuracy: 0.46 | loss: 4.34
update:1075/2000, 耗时:0.00分/3.52分 | step: 60200 | performance: 1.8 | accuracy: 0.49 | loss: 2.31
update:1080/2000, 耗时:0.00分/3.54分 | step: 60480 | performance: 0.8 | accuracy: 0.44 | loss: 4.52
update:1085/2000, 耗时:0.00分/3.56分 | step: 60760 | performance: 1.0 | accuracy: 0.45 | loss: 1.50
update:1090/2000, 耗时:0.00分/3.57分 | step: 61040 | performance: 1.3 | accuracy: 0.45 | loss: 1.29
update:1095/2000, 耗时:0.00分/3.59分 | step: 61320 | performance: 2.1 | accuracy: 0.46 | loss: 0.88
update:1100/2000, 耗时:0.00分/3.61分 | step: 61600 | performance: 2.1 | accuracy: 0.46 | loss: 1.39
update:1105/2000, 耗时:0.00分/3.62分 | step: 61880 | performance: 1.5 | accuracy: 0.45 | loss: 1.86
update:1110/2000, 耗时:0.00分/3.64分 | step: 62160 | performance: 1.8 | accuracy: 0.46 | loss: 1.51
update:1115/2000, 耗时:0.00分/3.65分 | step: 62440 | performance: 2.0 | accuracy: 0.46 | loss: 1.59
update:1120/2000, 耗时:0.00分/3.67分 | step: 62720 | performance: 2.6 | accuracy: 0.47 | loss: 1.09
update:1125/2000, 耗时:0.00分/3.69分 | step: 63000 | performance: 2.3 | accuracy: 0.46 | loss: 2.19
update:1130/2000, 耗时:0.00分/3.70分 | step: 63280 | performance: 2.2 | accuracy: 0.46 | loss: 2.18
update:1135/2000, 耗时:0.00分/3.72分 | step: 63560 | performance: 2.7 | accuracy: 0.47 | loss: 1.43
update:1140/2000, 耗时:0.00分/3.74分 | step: 63840 | performance: 6.6 | accuracy: 0.47 | loss: 5.71
update:1145/2000, 耗时:0.00分/3.75分 | step: 64120 | performance: 16.5 | accuracy: 0.48 | loss: 3.48
update:1150/2000, 耗时:0.00分/3.77分 | step: 64400 | performance: 13.1 | accuracy: 0.48 | loss: 1.91
update:1155/2000, 耗时:0.00分/3.78分 | step: 64680 | performance: 14.8 | accuracy: 0.48 | loss: 4.46
update:1160/2000, 耗时:0.00分/3.80分 | step: 64960 | performance: 17.0 | accuracy: 0.48 | loss: 3.64
update:1165/2000, 耗时:0.00分/3.81分 | step: 65240 | performance: 14.7 | accuracy: 0.47 | loss: 1.23
update:1170/2000, 耗时:0.00分/3.83分 | step: 65520 | performance: 12.9 | accuracy: 0.47 | loss: 1.11
update:1175/2000, 耗时:0.00分/3.85分 | step: 65800 | performance: 12.1 | accuracy: 0.46 | loss: 0.67
update:1180/2000, 耗时:0.00分/3.86分 | step: 66080 | performance: 18.4 | accuracy: 0.46 | loss: 0.66
update:1185/2000, 耗时:0.00分/3.88分 | step: 66360 | performance: 18.9 | accuracy: 0.47 | loss: 2.48
update:1190/2000, 耗时:0.00分/3.90分 | step: 66640 | performance: 60.6 | accuracy: 0.48 | loss: 6.34
update:1195/2000, 耗时:0.00分/3.91分 | step: 66920 | performance: 72.0 | accuracy: 0.48 | loss: 1.31
update:1200/2000, 耗时:0.00分/3.93分 | step: 67200 | performance: 73.0 | accuracy: 0.48 | loss: 1.67
update:1205/2000, 耗时:0.00分/3.94分 | step: 67480 | performance: 109.0 | accuracy: 0.48 | loss: 1.72
update:1210/2000, 耗时:0.00分/3.96分 | step: 67760 | performance: 81.6 | accuracy: 0.48 | loss: 3.39
update:1215/2000, 耗时:0.00分/3.97分 | step: 68040 | performance: 99.1 | accuracy: 0.48 | loss: 1.21
update:1220/2000, 耗时:0.00分/3.99分 | step: 68320 | performance: 80.6 | accuracy: 0.48 | loss: 0.91
update:1225/2000, 耗时:0.00分/4.00分 | step: 68600 | performance: 84.6 | accuracy: 0.48 | loss: 0.97
update:1230/2000, 耗时:0.00分/4.02分 | step: 68880 | performance: 126.5 | accuracy: 0.48 | loss: 1.15
update:1235/2000, 耗时:0.00分/4.04分 | step: 69160 | performance: 149.5 | accuracy: 0.48 | loss: 1.12
update:1240/2000, 耗时:0.00分/4.05分 | step: 69440 | performance: 95.9 | accuracy: 0.48 | loss: 1.43
update:1245/2000, 耗时:0.00分/4.07分 | step: 69720 | performance: 183.2 | accuracy: 0.48 | loss: 2.32
update:1250/2000, 耗时:0.00分/4.08分 | step: 70000 | performance: 192.3 | accuracy: 0.48 | loss: 3.40
update:1255/2000, 耗时:0.00分/4.10分 | step: 70280 | performance: 196.8 | accuracy: 0.49 | loss: 1.81
update:1260/2000, 耗时:0.00分/4.11分 | step: 70560 | performance: 120.5 | accuracy: 0.48 | loss: 3.70
update:1265/2000, 耗时:0.00分/4.13分 | step: 70840 | performance: 131.0 | accuracy: 0.48 | loss: 1.77
update:1270/2000, 耗时:0.00分/4.15分 | step: 71120 | performance: 168.3 | accuracy: 0.48 | loss: 2.41
update:1275/2000, 耗时:0.00分/4.16分 | step: 71400 | performance: 119.1 | accuracy: 0.48 | loss: 1.54
update:1280/2000, 耗时:0.00分/4.18分 | step: 71680 | performance: 22.8 | accuracy: 0.48 | loss: 4.96
update:1285/2000, 耗时:0.00分/4.19分 | step: 71960 | performance: 21.5 | accuracy: 0.48 | loss: 4.47
update:1290/2000, 耗时:0.00分/4.21分 | step: 72240 | performance: 17.3 | accuracy: 0.48 | loss: 4.55
update:1295/2000, 耗时:0.00分/4.22分 | step: 72520 | performance: 7.8 | accuracy: 0.47 | loss: 1.91
update:1300/2000, 耗时:0.00分/4.24分 | step: 72800 | performance: 8.1 | accuracy: 0.47 | loss: 1.55
update:1305/2000, 耗时:0.00分/4.25分 | step: 73080 | performance: 6.9 | accuracy: 0.47 | loss: 2.35
update:1310/2000, 耗时:0.00分/4.27分 | step: 73360 | performance: 6.6 | accuracy: 0.47 | loss: 1.31
update:1315/2000, 耗时:0.00分/4.28分 | step: 73640 | performance: 6.3 | accuracy: 0.47 | loss: 0.86
update:1320/2000, 耗时:0.00分/4.29分 | step: 73920 | performance: 9.8 | accuracy: 0.47 | loss: 0.76
update:1325/2000, 耗时:0.00分/4.31分 | step: 74200 | performance: 9.3 | accuracy: 0.47 | loss: 0.75
update:1330/2000, 耗时:0.00分/4.32分 | step: 74480 | performance: 6.0 | accuracy: 0.47 | loss: 0.97
update:1335/2000, 耗时:0.00分/4.34分 | step: 74760 | performance: 7.1 | accuracy: 0.47 | loss: 0.88
update:1340/2000, 耗时:0.00分/4.35分 | step: 75040 | performance: 6.4 | accuracy: 0.47 | loss: 1.51
update:1345/2000, 耗时:0.00分/4.37分 | step: 75320 | performance: 10.8 | accuracy: 0.47 | loss: 3.29
update:1350/2000, 耗时:0.00分/4.38分 | step: 75600 | performance: 20.4 | accuracy: 0.48 | loss: 1.69
update:1355/2000, 耗时:0.00分/4.40分 | step: 75880 | performance: 17.6 | accuracy: 0.48 | loss: 1.69
update:1360/2000, 耗时:0.00分/4.42分 | step: 76160 | performance: 55.5 | accuracy: 0.48 | loss: 2.59
update:1365/2000, 耗时:0.00分/4.43分 | step: 76440 | performance: 130.4 | accuracy: 0.48 | loss: 1.95
update:1370/2000, 耗时:0.00分/4.45分 | step: 76720 | performance: 121.0 | accuracy: 0.48 | loss: 2.61
update:1375/2000, 耗时:0.00分/4.46分 | step: 77000 | performance: 464.9 | accuracy: 0.49 | loss: 4.96
update:1380/2000, 耗时:0.00分/4.48分 | step: 77280 | performance: 416.5 | accuracy: 0.49 | loss: 4.50
update:1385/2000, 耗时:0.00分/4.49分 | step: 77560 | performance: 411.9 | accuracy: 0.49 | loss: 2.04
update:1390/2000, 耗时:0.00分/4.51分 | step: 77840 | performance: 612.4 | accuracy: 0.49 | loss: 2.38
update:1395/2000, 耗时:0.00分/4.52分 | step: 78120 | performance: 488.5 | accuracy: 0.49 | loss: 2.10
update:1400/2000, 耗时:0.00分/4.54分 | step: 78400 | performance: 380.3 | accuracy: 0.49 | loss: 3.81
update:1405/2000, 耗时:0.00分/4.55分 | step: 78680 | performance: 299.6 | accuracy: 0.49 | loss: 2.51
update:1410/2000, 耗时:0.00分/4.57分 | step: 78960 | performance: 422.8 | accuracy: 0.49 | loss: 2.41
update:1415/2000, 耗时:0.00分/4.59分 | step: 79240 | performance: 404.5 | accuracy: 0.49 | loss: 2.53
update:1420/2000, 耗时:0.00分/4.60分 | step: 79520 | performance: 248.2 | accuracy: 0.49 | loss: 7.67
update:1425/2000, 耗时:0.00分/4.62分 | step: 79800 | performance: 161.4 | accuracy: 0.49 | loss: 2.08
update:1430/2000, 耗时:0.00分/4.63分 | step: 80080 | performance: 193.6 | accuracy: 0.48 | loss: 1.52
update:1435/2000, 耗时:0.00分/4.65分 | step: 80360 | performance: 191.6 | accuracy: 0.49 | loss: 1.20
update:1440/2000, 耗时:0.00分/4.66分 | step: 80640 | performance: 215.0 | accuracy: 0.49 | loss: 1.70
update:1445/2000, 耗时:0.00分/4.68分 | step: 80920 | performance: 361.0 | accuracy: 0.49 | loss: 3.21
update:1450/2000, 耗时:0.00分/4.69分 | step: 81200 | performance: 458.7 | accuracy: 0.49 | loss: 3.18
update:1455/2000, 耗时:0.00分/4.71分 | step: 81480 | performance: 236.0 | accuracy: 0.49 | loss: 1.46
update:1460/2000, 耗时:0.00分/4.72分 | step: 81760 | performance: 186.1 | accuracy: 0.49 | loss: 2.79
update:1465/2000, 耗时:0.00分/4.74分 | step: 82040 | performance: 181.8 | accuracy: 0.49 | loss: 1.50
update:1470/2000, 耗时:0.00分/4.75分 | step: 82320 | performance: 236.9 | accuracy: 0.49 | loss: 2.32
update:1475/2000, 耗时:0.00分/4.77分 | step: 82600 | performance: 256.5 | accuracy: 0.49 | loss: 3.43
update:1480/2000, 耗时:0.00分/4.78分 | step: 82880 | performance: 348.2 | accuracy: 0.49 | loss: 1.65
update:1485/2000, 耗时:0.00分/4.80分 | step: 83160 | performance: 345.2 | accuracy: 0.49 | loss: 1.83
update:1490/2000, 耗时:0.00分/4.82分 | step: 83440 | performance: 215.3 | accuracy: 0.49 | loss: 3.98
update:1495/2000, 耗时:0.00分/4.83分 | step: 83720 | performance: 250.8 | accuracy: 0.49 | loss: 0.72
update:1500/2000, 耗时:0.00分/4.85分 | step: 84000 | performance: 302.5 | accuracy: 0.49 | loss: 0.97
update:1505/2000, 耗时:0.00分/4.86分 | step: 84280 | performance: 636.4 | accuracy: 0.49 | loss: 1.44
update:1510/2000, 耗时:0.00分/4.88分 | step: 84560 | performance: 593.9 | accuracy: 0.49 | loss: 1.23
update:1515/2000, 耗时:0.00分/4.89分 | step: 84840 | performance: 1694.4 | accuracy: 0.49 | loss: 5.06
update:1520/2000, 耗时:0.00分/4.91分 | step: 85120 | performance: 2254.1 | accuracy: 0.49 | loss: 4.63
update:1525/2000, 耗时:0.00分/4.92分 | step: 85400 | performance: 1465.7 | accuracy: 0.49 | loss: 5.39
update:1530/2000, 耗时:0.00分/4.94分 | step: 85680 | performance: 1445.6 | accuracy: 0.49 | loss: 2.32
update:1535/2000, 耗时:0.00分/4.95分 | step: 85960 | performance: 2516.3 | accuracy: 0.49 | loss: 1.23
update:1540/2000, 耗时:0.00分/4.97分 | step: 86240 | performance: 2951.6 | accuracy: 0.49 | loss: 2.28
update:1545/2000, 耗时:0.00分/4.98分 | step: 86520 | performance: 2868.7 | accuracy: 0.49 | loss: 3.60
update:1550/2000, 耗时:0.00分/5.00分 | step: 86800 | performance: 2755.3 | accuracy: 0.50 | loss: 1.96
update:1555/2000, 耗时:0.00分/5.01分 | step: 87080 | performance: 4711.2 | accuracy: 0.50 | loss: 1.77
update:1560/2000, 耗时:0.00分/5.03分 | step: 87360 | performance: 5158.4 | accuracy: 0.50 | loss: 1.10
update:1565/2000, 耗时:0.00分/5.04分 | step: 87640 | performance: 5246.7 | accuracy: 0.50 | loss: 3.59
update:1570/2000, 耗时:0.00分/5.06分 | step: 87920 | performance: 0.8 | accuracy: 0.25 | loss: 5.57
Saving PPO weights in both H5 format and checkpoint @ update:1570 
Saving PPO weights in both H5 format and checkpoint @ update:1573 
update:1575/2000, 耗时:0.00分/5.08分 | step: 88200 | performance: 0.6 | accuracy: 0.44 | loss: 2.49
Saving PPO weights in both H5 format and checkpoint @ update:1577 
update:1580/2000, 耗时:0.00分/5.11分 | step: 88480 | performance: 0.3 | accuracy: 0.45 | loss: 5.15
update:1585/2000, 耗时:0.00分/5.12分 | step: 88760 | performance: 0.1 | accuracy: 0.40 | loss: 3.36
update:1590/2000, 耗时:0.00分/5.14分 | step: 89040 | performance: 0.2 | accuracy: 0.42 | loss: 3.72
update:1595/2000, 耗时:0.00分/5.15分 | step: 89320 | performance: 0.3 | accuracy: 0.45 | loss: 4.40
update:1600/2000, 耗时:0.00分/5.17分 | step: 89600 | performance: 0.3 | accuracy: 0.46 | loss: 7.66
update:1605/2000, 耗时:0.00分/5.19分 | step: 89880 | performance: 0.2 | accuracy: 0.44 | loss: 2.67
update:1610/2000, 耗时:0.00分/5.20分 | step: 90160 | performance: 0.3 | accuracy: 0.45 | loss: 2.78
update:1615/2000, 耗时:0.00分/5.22分 | step: 90440 | performance: 0.4 | accuracy: 0.46 | loss: 1.03
update:1620/2000, 耗时:0.00分/5.23分 | step: 90720 | performance: 0.8 | accuracy: 0.47 | loss: 2.36
update:1625/2000, 耗时:0.00分/5.25分 | step: 91000 | performance: 0.7 | accuracy: 0.47 | loss: 1.69
update:1630/2000, 耗时:0.00分/5.27分 | step: 91280 | performance: 0.4 | accuracy: 0.46 | loss: 2.34
update:1635/2000, 耗时:0.00分/5.28分 | step: 91560 | performance: 0.9 | accuracy: 0.48 | loss: 2.44
update:1640/2000, 耗时:0.00分/5.30分 | step: 91840 | performance: 0.6 | accuracy: 0.47 | loss: 1.32
update:1645/2000, 耗时:0.00分/5.31分 | step: 92120 | performance: 0.9 | accuracy: 0.48 | loss: 2.80
update:1650/2000, 耗时:0.00分/5.33分 | step: 92400 | performance: 0.8 | accuracy: 0.48 | loss: 1.59
update:1655/2000, 耗时:0.00分/5.34分 | step: 92680 | performance: 0.8 | accuracy: 0.48 | loss: 1.62
update:1660/2000, 耗时:0.00分/5.36分 | step: 92960 | performance: 0.9 | accuracy: 0.48 | loss: 2.61
update:1665/2000, 耗时:0.00分/5.38分 | step: 93240 | performance: 4.2 | accuracy: 0.49 | loss: 3.02
update:1670/2000, 耗时:0.00分/5.39分 | step: 93520 | performance: 7.3 | accuracy: 0.50 | loss: 1.88
update:1675/2000, 耗时:0.00分/5.41分 | step: 93800 | performance: 4.9 | accuracy: 0.49 | loss: 1.13
update:1680/2000, 耗时:0.00分/5.42分 | step: 94080 | performance: 5.5 | accuracy: 0.49 | loss: 3.23
update:1685/2000, 耗时:0.00分/5.44分 | step: 94360 | performance: 6.6 | accuracy: 0.49 | loss: 0.99
update:1690/2000, 耗时:0.00分/5.46分 | step: 94640 | performance: 4.6 | accuracy: 0.48 | loss: 1.13
update:1695/2000, 耗时:0.00分/5.47分 | step: 94920 | performance: 5.1 | accuracy: 0.48 | loss: 0.57
update:1700/2000, 耗时:0.00分/5.49分 | step: 95200 | performance: 4.8 | accuracy: 0.47 | loss: 1.79
update:1705/2000, 耗时:0.00分/5.50分 | step: 95480 | performance: 6.2 | accuracy: 0.48 | loss: 0.87
update:1710/2000, 耗时:0.00分/5.52分 | step: 95760 | performance: 8.8 | accuracy: 0.48 | loss: 4.36
update:1715/2000, 耗时:0.00分/5.54分 | step: 96040 | performance: 21.9 | accuracy: 0.49 | loss: 2.03
update:1720/2000, 耗时:0.00分/5.55分 | step: 96320 | performance: 20.6 | accuracy: 0.49 | loss: 2.03
update:1725/2000, 耗时:0.00分/5.57分 | step: 96600 | performance: 59.0 | accuracy: 0.50 | loss: 4.49
update:1730/2000, 耗时:0.00分/5.58分 | step: 96880 | performance: 61.2 | accuracy: 0.50 | loss: 3.77
update:1735/2000, 耗时:0.00分/5.60分 | step: 97160 | performance: 28.9 | accuracy: 0.50 | loss: 1.40
update:1740/2000, 耗时:0.00分/5.62分 | step: 97440 | performance: 23.7 | accuracy: 0.50 | loss: 1.93
update:1745/2000, 耗时:0.00分/5.63分 | step: 97720 | performance: 24.2 | accuracy: 0.49 | loss: 1.37
update:1750/2000, 耗时:0.00分/5.65分 | step: 98000 | performance: 23.8 | accuracy: 0.49 | loss: 1.44
update:1755/2000, 耗时:0.00分/5.66分 | step: 98280 | performance: 42.5 | accuracy: 0.49 | loss: 1.48
update:1760/2000, 耗时:0.00分/5.68分 | step: 98560 | performance: 35.9 | accuracy: 0.49 | loss: 2.40
update:1765/2000, 耗时:0.00分/5.70分 | step: 98840 | performance: 33.4 | accuracy: 0.49 | loss: 0.70
update:1770/2000, 耗时:0.00分/5.71分 | step: 99120 | performance: 51.4 | accuracy: 0.50 | loss: 4.33
update:1775/2000, 耗时:0.00分/5.73分 | step: 99400 | performance: 74.9 | accuracy: 0.50 | loss: 2.57
update:1780/2000, 耗时:0.00分/5.74分 | step: 99680 | performance: 62.1 | accuracy: 0.50 | loss: 1.37
update:1785/2000, 耗时:0.00分/5.76分 | step: 99960 | performance: 38.0 | accuracy: 0.50 | loss: 1.70
update:1790/2000, 耗时:0.00分/5.78分 | step: 100240 | performance: 35.1 | accuracy: 0.49 | loss: 3.13
update:1795/2000, 耗时:0.00分/5.79分 | step: 100520 | performance: 32.3 | accuracy: 0.49 | loss: 1.10
update:1800/2000, 耗时:0.00分/5.81分 | step: 100800 | performance: 31.8 | accuracy: 0.49 | loss: 5.27
update:1805/2000, 耗时:0.00分/5.82分 | step: 101080 | performance: 20.7 | accuracy: 0.49 | loss: 3.24
update:1810/2000, 耗时:0.00分/5.84分 | step: 101360 | performance: 15.9 | accuracy: 0.49 | loss: 2.06
update:1815/2000, 耗时:0.00分/5.86分 | step: 101640 | performance: 8.2 | accuracy: 0.49 | loss: 1.70
update:1820/2000, 耗时:0.00分/5.87分 | step: 101920 | performance: 8.1 | accuracy: 0.49 | loss: 2.17
update:1825/2000, 耗时:0.00分/5.89分 | step: 102200 | performance: 8.1 | accuracy: 0.48 | loss: 1.08
update:1830/2000, 耗时:0.00分/5.90分 | step: 102480 | performance: 6.9 | accuracy: 0.48 | loss: 0.73
update:1835/2000, 耗时:0.00分/5.92分 | step: 102760 | performance: 7.0 | accuracy: 0.48 | loss: 0.75
update:1840/2000, 耗时:0.00分/5.94分 | step: 103040 | performance: 4.7 | accuracy: 0.48 | loss: 1.24
update:1845/2000, 耗时:0.00分/5.95分 | step: 103320 | performance: 5.1 | accuracy: 0.48 | loss: 2.83
update:1850/2000, 耗时:0.00分/5.97分 | step: 103600 | performance: 3.2 | accuracy: 0.47 | loss: 4.07
update:1855/2000, 耗时:0.00分/5.99分 | step: 103880 | performance: 2.9 | accuracy: 0.47 | loss: 1.76
update:1860/2000, 耗时:0.00分/6.00分 | step: 104160 | performance: 3.1 | accuracy: 0.47 | loss: 1.59
update:1865/2000, 耗时:0.00分/6.02分 | step: 104440 | performance: 3.9 | accuracy: 0.48 | loss: 3.23
update:1870/2000, 耗时:0.00分/6.03分 | step: 104720 | performance: 5.6 | accuracy: 0.48 | loss: 2.23
update:1875/2000, 耗时:0.00分/6.05分 | step: 105000 | performance: 9.3 | accuracy: 0.48 | loss: 5.12
update:1880/2000, 耗时:0.00分/6.07分 | step: 105280 | performance: 14.8 | accuracy: 0.48 | loss: 5.52
update:1885/2000, 耗时:0.00分/6.08分 | step: 105560 | performance: 40.9 | accuracy: 0.49 | loss: 2.07
update:1890/2000, 耗时:0.00分/6.10分 | step: 105840 | performance: 37.8 | accuracy: 0.49 | loss: 4.91
update:1895/2000, 耗时:0.00分/6.11分 | step: 106120 | performance: 89.7 | accuracy: 0.49 | loss: 4.05
update:1900/2000, 耗时:0.00分/6.13分 | step: 106400 | performance: 84.7 | accuracy: 0.49 | loss: 1.88
update:1905/2000, 耗时:0.00分/6.14分 | step: 106680 | performance: 141.2 | accuracy: 0.49 | loss: 2.71
update:1910/2000, 耗时:0.00分/6.16分 | step: 106960 | performance: 152.3 | accuracy: 0.49 | loss: 1.99
update:1915/2000, 耗时:0.00分/6.18分 | step: 107240 | performance: 123.2 | accuracy: 0.49 | loss: 2.54
update:1920/2000, 耗时:0.00分/6.19分 | step: 107520 | performance: 154.3 | accuracy: 0.49 | loss: 1.15
update:1925/2000, 耗时:0.00分/6.21分 | step: 107800 | performance: 128.5 | accuracy: 0.49 | loss: 2.58
update:1930/2000, 耗时:0.00分/6.22分 | step: 108080 | performance: 145.6 | accuracy: 0.49 | loss: 2.77
update:1935/2000, 耗时:0.00分/6.24分 | step: 108360 | performance: 170.1 | accuracy: 0.49 | loss: 6.30
update:1940/2000, 耗时:0.00分/6.26分 | step: 108640 | performance: 253.4 | accuracy: 0.49 | loss: 4.00
update:1945/2000, 耗时:0.00分/6.27分 | step: 108920 | performance: 135.2 | accuracy: 0.49 | loss: 4.34
update:1950/2000, 耗时:0.00分/6.29分 | step: 109200 | performance: 111.2 | accuracy: 0.49 | loss: 3.19
update:1955/2000, 耗时:0.00分/6.30分 | step: 109480 | performance: 77.7 | accuracy: 0.49 | loss: 2.63
update:1960/2000, 耗时:0.00分/6.32分 | step: 109760 | performance: 45.0 | accuracy: 0.48 | loss: 1.16
update:1965/2000, 耗时:0.00分/6.34分 | step: 110040 | performance: 60.4 | accuracy: 0.48 | loss: 1.05
update:1970/2000, 耗时:0.00分/6.35分 | step: 110320 | performance: 74.0 | accuracy: 0.49 | loss: 2.01
update:1975/2000, 耗时:0.00分/6.37分 | step: 110600 | performance: 70.8 | accuracy: 0.49 | loss: 2.17
update:1980/2000, 耗时:0.00分/6.38分 | step: 110880 | performance: 53.1 | accuracy: 0.49 | loss: 3.18
update:1985/2000, 耗时:0.00分/6.40分 | step: 111160 | performance: 44.4 | accuracy: 0.48 | loss: 1.03
update:1990/2000, 耗时:0.00分/6.42分 | step: 111440 | performance: 68.7 | accuracy: 0.49 | loss: 4.23
update:1995/2000, 耗时:0.00分/6.43分 | step: 111720 | performance: 106.3 | accuracy: 0.49 | loss: 1.96
  0%|          | 0/391 [00:00<?, ?it/s]100%|| 391/391 [00:00<00:00, 97698.85it/s]
update:2000/2000, 耗时:0.00分/6.45分 | step: 112000 | performance: 77.6 | accuracy: 0.49 | loss: 1.83
----------------------------------------finished----------------------------------------
==================================================
2023-01-10T12:00:00 | *** START BACKTEST ***
2023-01-10T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1108.51
2023-07-24T12:00:00 | net performance [%] = 10.8511
2023-07-24T12:00:00 | number of trades [#] = 60
==================================================
Trial 57 Complete [00h 06m 53s]
net_wealth: 1109.620199747796

Best net_wealth So Far: 1824.8039564105297
Total elapsed time: 07h 50m 35s

Search: Running Trial #58

Value             |Best Value So Far |Hyperparameter
3                 |6                 |horizon
365               |365               |lookback
False             |True              |MarketFactor
8                 |10                |lags
0.8               |0.98              |gamma
16                |16                |batch_size
1                 |7                 |n_step
0.98              |0.94              |gae_lambda
0.2               |0.5               |gradient_clip_norm
3                 |3                 |epochs
0.0001            |0.001             |actor_lr
0.0001            |0.001             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4312.000000   4315.000000
mean      0.000441    20062.255222  ...   20129.629835  20118.633889
std       0.027818    16039.874230  ...   16077.282571  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7694.525024   7690.540039
50%       0.000642    11554.824463  ...   11737.255371  11715.610352
75%       0.011655    29873.081836  ...   29933.737305  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 05:53:58.999160: I tensorflow/core/platform/cpu_feature_guard220023-07-28 05:53:58.999198: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow bi2.cc023-072:-128 05:53:58.999251: I tensorflow/core/platform/cpu20_f23-4e207-2] Tatnaryure8_2 003-0723-07-28 05: is53:58. op999349: h-iI2s8   tT0ensorflow5e/:nc5so3or:rFle585/p:o5w gl3:58a.tbu.ar9f9timidze.cd with oneAPI Deep9 9or19ina6Neural:r y is opt i9290301:2mmNei3-07-28 0z25e:5/3:58ctcI: t 1I. 4t92ens0]wodrk9 o 9Lib6Thpu_r4ri ary s(wienso rflooth owf/TennlocfeeAaows/orreco23t/Fplrl0a:e-07t InufoPeDrNrI- 2DeNee_m) g/pc8tuoa p 0 5:u53sNeu:/5p8l.aet 9t9hur_al Nefre dtfw966 eoa6.tfrooe:tclk oIw  lowibLuinbc:s142]o rflrteor nThmairnya /wr/y( oisiscoprsn u_ffloeaw/ceD copotiToNrtenere_rNn)/upglu mtoi zged waiea/urttfse hr oor Cdnmt/he.PUcp ucce f_ofll:e_eo142] wTiniahgupture_ianlsgAsPIagttsr r du.u foDocCaTrensdo.cPcrrcct:rFUioFl in1lno:s4t2w1 biruocw] 4tion2snbse ea riyn i spi n] p oem/p Nee rcfppTutTorrium_izahl fmancNeeahies tTeniure-si_sncetgwuor raarkd d ioTrwy.rLenisboirFtFr aciiscalr ylotcr: ofp1e4ro(w oat rneDobpi2niNtairmyaN)mon] ins tTohi:s zece -  i sA Vod wiuptitXTlenhmsho ow i zoe bseo thriFnaAnneeAPVdA wPIXclrIer2i
tTo  oyi  DfD eise niaweep cbaooetph lepN lo ne  NlopeAtthlreautraeobwiemuirzmiPniang alrIy D is eCeloepPU  i nN Nteipeitwnosrtkm  r LiibtrNoathizdu ocnwerrtye d so:p iwe(iotihtnue  eDor hA VorNXaonnNtns w)e Ato uoPeI asr kAl in AVPeX N eitI 2DpoDnese,p  rNeLi
wtheerTboeb efourrkfueaproroill a rLyi b(rNeaurrmdloanle y  e TNenNsnalbeDNoarFtlwowonleNo wcete-) wwit  tthoemocrritik r u(ih tk  icLaiboln ensLehrDaonp egorN Nter)yiht her   otpeb  Caf(oaPtprpaeUroaner riionnDoNtliopNo)lsnts, su:sre orwuc   yA i(ttion aohtee  fotVXc  ungi roAloseCePmVX2UeDbNN  lthep)uionwstirnucinstig 
  ftolTino ood lilpoe  elnea bCnwrifnog CPrmUrsP Tenl f Usuea inl ainningsssc osrFlotep.e
ttw w-erhem inrircr tuchetfiti ourcticfaoll lhomoti naontpe rhcoen-wcriticoetisa si naaptpl  iir oopneorhpgnfeep no rpieartfermrsanCro:r aPt icoonmcpma so: e-peratcrU ncei-ci lit iAonisc, alrAVnrX iAVe eXt2i
operVbuild TeXcTa alAVX2
To enable them in other operations, rebuild Tenss operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
ro nsorFlowflao enabltrFlow with the appropriaie g with ttstrt.hoeens:  A c
uompilVX AVche aerXtpm2
  pions iropTioria tee compilenabln performen thaeflags.
mr ncoth in ote-critical operations:  AVX AVX2
To enable them in other opher operations,er operations, rebuild TensorFlow with the appropriate compiler flags.
 flags.
 rebuild TensorFlow with the appropriate compiler flags.
erations, rebuild TensorFlow with the appropriate compiler flags.
2023-07-28 05:53:59.601744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:53:59.607361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:53:59.621190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:53:59.624318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:53:59.640175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:53:59.643317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:53:59.649159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:53:59.659731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.02分 | step:    40 | performance: 1.1 | accuracy: 0.60 | loss: 0.55
update: 10/2000, 耗时:0.00分/0.03分 | step:    80 | performance: 1.0 | accuracy: 0.30 | loss: 0.97
update: 15/2000, 耗时:0.00分/0.04分 | step:   120 | performance: 0.7 | accuracy: 0.20 | loss: 0.98
update: 20/2000, 耗时:0.00分/0.04分 | step:   160 | performance: 0.7 | accuracy: 0.25 | loss: 0.58
update: 25/2000, 耗时:0.00分/0.05分 | step:   200 | performance: 0.7 | accuracy: 0.24 | loss: 0.46
update: 30/2000, 耗时:0.00分/0.06分 | step:   240 | performance: 0.6 | accuracy: 0.23 | loss: 0.42
update: 35/2000, 耗时:0.00分/0.06分 | step:   280 | performance: 0.6 | accuracy: 0.23 | loss: 0.91
update: 40/2000, 耗时:0.00分/0.07分 | step:   320 | performance: 0.6 | accuracy: 0.23 | loss: 0.16
update: 45/2000, 耗时:0.00分/0.08分 | step:   360 | performance: 0.6 | accuracy: 0.22 | loss: 0.44
update: 50/2000, 耗时:0.00分/0.08分 | step:   400 | performance: 0.6 | accuracy: 0.24 | loss: 1.43
update: 55/2000, 耗时:0.00分/0.09分 | step:   440 | performance: 0.6 | accuracy: 0.24 | loss: 0.81
update: 60/2000, 耗时:0.00分/0.09分 | step:   480 | performance: 0.7 | accuracy: 0.27 | loss: 0.61
update: 65/2000, 耗时:0.00分/0.10分 | step:   520 | performance: 0.7 | accuracy: 0.28 | loss: 1.09
update: 70/2000, 耗时:0.00分/0.11分 | step:   560 | performance: 0.8 | accuracy: 0.29 | loss: 0.46
update: 75/2000, 耗时:0.00分/0.11分 | step:   600 | performance: 0.8 | accuracy: 0.28 | loss: 0.32
update: 80/2000, 耗时:0.00分/0.12分 | step:   640 | performance: 0.8 | accuracy: 0.30 | loss: 0.31
update: 85/2000, 耗时:0.00分/0.13分 | step:   680 | performance: 0.8 | accuracy: 0.28 | loss: 0.24
update: 90/2000, 耗时:0.00分/0.13分 | step:   720 | performance: 0.8 | accuracy: 0.28 | loss: 0.12
update: 95/2000, 耗时:0.00分/0.14分 | step:   760 | performance: 0.8 | accuracy: 0.26 | loss: 0.32
update:100/2000, 耗时:0.00分/0.15分 | step:   800 | performance: 0.8 | accuracy: 0.25 | loss: 0.38
update:105/2000, 耗时:0.00分/0.15分 | step:   840 | performance: 0.8 | accuracy: 0.25 | loss: 0.32
update:110/2000, 耗时:0.00分/0.16分 | step:   880 | performance: 0.8 | accuracy: 0.24 | loss: 0.17
update:115/2000, 耗时:0.00分/0.17分 | step:   920 | performance: 0.8 | accuracy: 0.23 | loss: 0.39
update:120/2000, 耗时:0.00分/0.18分 | step:   960 | performance: 0.8 | accuracy: 0.23 | loss: 0.60
update:125/2000, 耗时:0.00分/0.18分 | step:  1000 | performance: 0.8 | accuracy: 0.23 | loss: 0.62
update:130/2000, 耗时:0.00分/0.19分 | step:  1040 | performance: 0.8 | accuracy: 0.24 | loss: 0.22
update:135/2000, 耗时:0.00分/0.20分 | step:  1080 | performance: 0.8 | accuracy: 0.24 | loss: 0.51
update:140/2000, 耗时:0.00分/0.20分 | step:  1120 | performance: 0.8 | accuracy: 0.25 | loss: 0.84
update:145/2000, 耗时:0.00分/0.21分 | step:  1160 | performance: 0.7 | accuracy: 0.26 | loss: 0.38
update:150/2000, 耗时:0.00分/0.22分 | step:  1200 | performance: 0.7 | accuracy: 0.25 | loss: 0.51
update:155/2000, 耗时:0.00分/0.22分 | step:  1240 | performance: 0.7 | accuracy: 0.24 | loss: 0.13
update:160/2000, 耗时:0.00分/0.23分 | step:  1280 | performance: 0.7 | accuracy: 0.24 | loss: 0.31
update:165/2000, 耗时:0.00分/0.24分 | step:  1320 | performance: 0.6 | accuracy: 0.24 | loss: 0.90
update:170/2000, 耗时:0.00分/0.25分 | step:  1360 | performance: 0.6 | accuracy: 0.24 | loss: 0.27
update:175/2000, 耗时:0.00分/0.25分 | step:  1400 | performance: 0.6 | accuracy: 0.24 | loss: 0.16
update:180/2000, 耗时:0.00分/0.26分 | step:  1440 | performance: 0.6 | accuracy: 0.24 | loss: 0.26
update:185/2000, 耗时:0.00分/0.27分 | step:  1480 | performance: 0.6 | accuracy: 0.25 | loss: 0.53
update:190/2000, 耗时:0.00分/0.28分 | step:  1520 | performance: 0.5 | accuracy: 0.25 | loss: 0.24
update:195/2000, 耗时:0.00分/0.28分 | step:  1560 | performance: 0.5 | accuracy: 0.24 | loss: 0.12
update:200/2000, 耗时:0.00分/0.29分 | step:  1600 | performance: 0.5 | accuracy: 0.23 | loss: 0.60
update:205/2000, 耗时:0.00分/0.30分 | step:  1640 | performance: 0.6 | accuracy: 0.24 | loss: 0.30
update:210/2000, 耗时:0.00分/0.30分 | step:  1680 | performance: 0.6 | accuracy: 0.24 | loss: 0.33
update:215/2000, 耗时:0.00分/0.31分 | step:  1720 | performance: 0.6 | accuracy: 0.24 | loss: 0.09
update:220/2000, 耗时:0.00分/0.32分 | step:  1760 | performance: 0.5 | accuracy: 0.24 | loss: 0.17
update:225/2000, 耗时:0.00分/0.33分 | step:  1800 | performance: 0.6 | accuracy: 0.24 | loss: 0.13
update:230/2000, 耗时:0.00分/0.33分 | step:  1840 | performance: 0.6 | accuracy: 0.24 | loss: 0.45
update:235/2000, 耗时:0.00分/0.34分 | step:  1880 | performance: 0.6 | accuracy: 0.24 | loss: 0.24
update:240/2000, 耗时:0.00分/0.35分 | step:  1920 | performance: 0.6 | accuracy: 0.24 | loss: 0.25
update:245/2000, 耗时:0.00分/0.36分 | step:  1960 | performance: 0.5 | accuracy: 0.24 | loss: 0.28
update:250/2000, 耗时:0.00分/0.36分 | step:  2000 | performance: 0.5 | accuracy: 0.24 | loss: 0.12
update:255/2000, 耗时:0.00分/0.37分 | step:  2040 | performance: 0.5 | accuracy: 0.24 | loss: 0.34
update:260/2000, 耗时:0.00分/0.38分 | step:  2080 | performance: 0.5 | accuracy: 0.24 | loss: 0.29
update:265/2000, 耗时:0.00分/0.38分 | step:  2120 | performance: 0.5 | accuracy: 0.24 | loss: 0.20
update:270/2000, 耗时:0.00分/0.39分 | step:  2160 | performance: 0.5 | accuracy: 0.24 | loss: -0.01
update:275/2000, 耗时:0.00分/0.40分 | step:  2200 | performance: 0.5 | accuracy: 0.24 | loss: 0.00
update:280/2000, 耗时:0.00分/0.41分 | step:  2240 | performance: 0.5 | accuracy: 0.24 | loss: 0.16
update:285/2000, 耗时:0.00分/0.41分 | step:  2280 | performance: 0.5 | accuracy: 0.24 | loss: 0.22
update:290/2000, 耗时:0.00分/0.42分 | step:  2320 | performance: 0.5 | accuracy: 0.24 | loss: 0.33
update:295/2000, 耗时:0.00分/0.43分 | step:  2360 | performance: 0.5 | accuracy: 0.23 | loss: 0.50
update:300/2000, 耗时:0.00分/0.44分 | step:  2400 | performance: 0.5 | accuracy: 0.24 | loss: 0.17
update:305/2000, 耗时:0.00分/0.44分 | step:  2440 | performance: 0.5 | accuracy: 0.24 | loss: 0.60
update:310/2000, 耗时:0.00分/0.45分 | step:  2480 | performance: 0.5 | accuracy: 0.24 | loss: 0.44
update:315/2000, 耗时:0.00分/0.46分 | step:  2520 | performance: 0.5 | accuracy: 0.24 | loss: 0.34
update:320/2000, 耗时:0.00分/0.46分 | step:  2560 | performance: 0.6 | accuracy: 0.24 | loss: 0.42
update:325/2000, 耗时:0.00分/0.47分 | step:  2600 | performance: 0.7 | accuracy: 0.25 | loss: 0.24
update:330/2000, 耗时:0.00分/0.48分 | step:  2640 | performance: 0.7 | accuracy: 0.25 | loss: 0.28
update:335/2000, 耗时:0.00分/0.49分 | step:  2680 | performance: 0.7 | accuracy: 0.25 | loss: 0.23
update:340/2000, 耗时:0.00分/0.49分 | step:  2720 | performance: 0.7 | accuracy: 0.24 | loss: 0.53
update:345/2000, 耗时:0.00分/0.50分 | step:  2760 | performance: 0.7 | accuracy: 0.24 | loss: -0.01
update:350/2000, 耗时:0.00分/0.51分 | step:  2800 | performance: 0.7 | accuracy: 0.24 | loss: 0.34
update:355/2000, 耗时:0.00分/0.51分 | step:  2840 | performance: 0.6 | accuracy: 0.24 | loss: 0.11
update:360/2000, 耗时:0.00分/0.52分 | step:  2880 | performance: 0.6 | accuracy: 0.24 | loss: 0.40
update:365/2000, 耗时:0.00分/0.53分 | step:  2920 | performance: 0.6 | accuracy: 0.24 | loss: 0.11
update:370/2000, 耗时:0.00分/0.53分 | step:  2960 | performance: 0.6 | accuracy: 0.24 | loss: -0.01
update:375/2000, 耗时:0.00分/0.54分 | step:  3000 | performance: 0.6 | accuracy: 0.24 | loss: 0.81
update:380/2000, 耗时:0.00分/0.55分 | step:  3040 | performance: 0.6 | accuracy: 0.23 | loss: 0.42
update:385/2000, 耗时:0.00分/0.56分 | step:  3080 | performance: 0.6 | accuracy: 0.24 | loss: 0.33
update:390/2000, 耗时:0.00分/0.56分 | step:  3120 | performance: 0.6 | accuracy: 0.24 | loss: -0.01
update:395/2000, 耗时:0.00分/0.57分 | step:  3160 | performance: 0.6 | accuracy: 0.24 | loss: 0.22
update:400/2000, 耗时:0.00分/0.58分 | step:  3200 | performance: 0.6 | accuracy: 0.23 | loss: 0.25
update:405/2000, 耗时:0.00分/0.58分 | step:  3240 | performance: 0.6 | accuracy: 0.23 | loss: 0.08
update:410/2000, 耗时:0.00分/0.59分 | step:  3280 | performance: 0.6 | accuracy: 0.23 | loss: 0.32
update:415/2000, 耗时:0.00分/0.60分 | step:  3320 | performance: 0.6 | accuracy: 0.23 | loss: 0.26
update:420/2000, 耗时:0.00分/0.61分 | step:  3360 | performance: 0.6 | accuracy: 0.23 | loss: 0.55
update:425/2000, 耗时:0.00分/0.61分 | step:  3400 | performance: 0.6 | accuracy: 0.24 | loss: 0.50
update:430/2000, 耗时:0.00分/0.62分 | step:  3440 | performance: 0.6 | accuracy: 0.23 | loss: 0.30
update:435/2000, 耗时:0.00分/0.63分 | step:  3480 | performance: 0.6 | accuracy: 0.23 | loss: 0.18
update:440/2000, 耗时:0.00分/0.63分 | step:  3520 | performance: 0.6 | accuracy: 0.23 | loss: 0.13
update:445/2000, 耗时:0.00分/0.64分 | step:  3560 | performance: 0.6 | accuracy: 0.23 | loss: 0.10
update:450/2000, 耗时:0.00分/0.65分 | step:  3600 | performance: 0.6 | accuracy: 0.23 | loss: 0.55
update:455/2000, 耗时:0.00分/0.66分 | step:  3640 | performance: 0.6 | accuracy: 0.23 | loss: 0.09
update:460/2000, 耗时:0.00分/0.66分 | step:  3680 | performance: 0.6 | accuracy: 0.23 | loss: 0.55
update:465/2000, 耗时:0.00分/0.67分 | step:  3720 | performance: 0.6 | accuracy: 0.23 | loss: 0.25
update:470/2000, 耗时:0.00分/0.68分 | step:  3760 | performance: 0.6 | accuracy: 0.23 | loss: 0.12
update:475/2000, 耗时:0.00分/0.68分 | step:  3800 | performance: 0.6 | accuracy: 0.23 | loss: 0.32
update:480/2000, 耗时:0.00分/0.69分 | step:  3840 | performance: 0.6 | accuracy: 0.22 | loss: 0.06
update:485/2000, 耗时:0.00分/0.70分 | step:  3880 | performance: 0.6 | accuracy: 0.22 | loss: 0.35
update:490/2000, 耗时:0.00分/0.71分 | step:  3920 | performance: 0.6 | accuracy: 0.22 | loss: 0.32
update:495/2000, 耗时:0.00分/0.71分 | step:  3960 | performance: 0.6 | accuracy: 0.22 | loss: 0.29
update:500/2000, 耗时:0.00分/0.72分 | step:  4000 | performance: 0.6 | accuracy: 0.22 | loss: 0.13
update:505/2000, 耗时:0.00分/0.73分 | step:  4040 | performance: 0.6 | accuracy: 0.22 | loss: 0.27
update:510/2000, 耗时:0.00分/0.73分 | step:  4080 | performance: 0.6 | accuracy: 0.22 | loss: 0.14
update:515/2000, 耗时:0.00分/0.74分 | step:  4120 | performance: 0.6 | accuracy: 0.22 | loss: 0.49
update:520/2000, 耗时:0.00分/0.75分 | step:  4160 | performance: 0.6 | accuracy: 0.23 | loss: 0.54
update:525/2000, 耗时:0.00分/0.76分 | step:  4200 | performance: 0.6 | accuracy: 0.23 | loss: 0.46
update:530/2000, 耗时:0.00分/0.76分 | step:  4240 | performance: 0.4 | accuracy: 0.23 | loss: 0.11
update:535/2000, 耗时:0.00分/0.77分 | step:  4280 | performance: 0.5 | accuracy: 0.23 | loss: 0.21
update:540/2000, 耗时:0.00分/0.78分 | step:  4320 | performance: 0.5 | accuracy: 0.23 | loss: 0.21
update:545/2000, 耗时:0.00分/0.78分 | step:  4360 | performance: 0.6 | accuracy: 0.23 | loss: 0.62
update:550/2000, 耗时:0.00分/0.79分 | step:  4400 | performance: 0.6 | accuracy: 0.23 | loss: 0.25
update:555/2000, 耗时:0.00分/0.80分 | step:  4440 | performance: 0.7 | accuracy: 0.24 | loss: 0.15
update:560/2000, 耗时:0.00分/0.80分 | step:  4480 | performance: 0.7 | accuracy: 0.24 | loss: 0.38
update:565/2000, 耗时:0.00分/0.81分 | step:  4520 | performance: 0.6 | accuracy: 0.24 | loss: 0.40
update:570/2000, 耗时:0.00分/0.82分 | step:  4560 | performance: 0.6 | accuracy: 0.24 | loss: 0.18
update:575/2000, 耗时:0.00分/0.83分 | step:  4600 | performance: 0.6 | accuracy: 0.23 | loss: 0.19
update:580/2000, 耗时:0.00分/0.83分 | step:  4640 | performance: 0.6 | accuracy: 0.23 | loss: 0.54
update:585/2000, 耗时:0.00分/0.84分 | step:  4680 | performance: 0.6 | accuracy: 0.23 | loss: 0.25
update:590/2000, 耗时:0.00分/0.85分 | step:  4720 | performance: 0.6 | accuracy: 0.23 | loss: 0.13
update:595/2000, 耗时:0.00分/0.85分 | step:  4760 | performance: 0.6 | accuracy: 0.23 | loss: 0.15
update:600/2000, 耗时:0.00分/0.86分 | step:  4800 | performance: 0.6 | accuracy: 0.23 | loss: 0.46
update:605/2000, 耗时:0.00分/0.87分 | step:  4840 | performance: 0.7 | accuracy: 0.24 | loss: 0.28
update:610/2000, 耗时:0.00分/0.88分 | step:  4880 | performance: 0.7 | accuracy: 0.24 | loss: 0.08
update:615/2000, 耗时:0.00分/0.88分 | step:  4920 | performance: 0.6 | accuracy: 0.24 | loss: 0.13
update:620/2000, 耗时:0.00分/0.89分 | step:  4960 | performance: 0.6 | accuracy: 0.24 | loss: 0.15
update:625/2000, 耗时:0.00分/0.90分 | step:  5000 | performance: 0.7 | accuracy: 0.24 | loss: 0.18
update:630/2000, 耗时:0.00分/0.90分 | step:  5040 | performance: 0.7 | accuracy: 0.24 | loss: 0.36
update:635/2000, 耗时:0.00分/0.91分 | step:  5080 | performance: 0.8 | accuracy: 0.24 | loss: 0.38
update:640/2000, 耗时:0.00分/0.92分 | step:  5120 | performance: 0.8 | accuracy: 0.24 | loss: 0.25
update:645/2000, 耗时:0.00分/0.93分 | step:  5160 | performance: 0.8 | accuracy: 0.24 | loss: 0.19
update:650/2000, 耗时:0.00分/0.93分 | step:  5200 | performance: 0.8 | accuracy: 0.24 | loss: 0.23
update:655/2000, 耗时:0.00分/0.94分 | step:  5240 | performance: 0.8 | accuracy: 0.24 | loss: 0.41
update:660/2000, 耗时:0.00分/0.95分 | step:  5280 | performance: 0.8 | accuracy: 0.24 | loss: 0.27
update:665/2000, 耗时:0.00分/0.95分 | step:  5320 | performance: 0.9 | accuracy: 0.25 | loss: 0.37
update:670/2000, 耗时:0.00分/0.96分 | step:  5360 | performance: 0.8 | accuracy: 0.24 | loss: 0.15
update:675/2000, 耗时:0.00分/0.97分 | step:  5400 | performance: 0.8 | accuracy: 0.24 | loss: 0.26
update:680/2000, 耗时:0.00分/0.98分 | step:  5440 | performance: 0.8 | accuracy: 0.24 | loss: 0.32
update:685/2000, 耗时:0.00分/0.98分 | step:  5480 | performance: 0.8 | accuracy: 0.24 | loss: 0.19
update:690/2000, 耗时:0.00分/0.99分 | step:  5520 | performance: 0.8 | accuracy: 0.24 | loss: 0.23
update:695/2000, 耗时:0.00分/1.00分 | step:  5560 | performance: 0.8 | accuracy: 0.24 | loss: 0.18
update:700/2000, 耗时:0.00分/1.01分 | step:  5600 | performance: 0.8 | accuracy: 0.24 | loss: 0.22
update:705/2000, 耗时:0.00分/1.01分 | step:  5640 | performance: 0.8 | accuracy: 0.24 | loss: 0.54
update:710/2000, 耗时:0.00分/1.02分 | step:  5680 | performance: 0.7 | accuracy: 0.24 | loss: 0.20
update:715/2000, 耗时:0.00分/1.03分 | step:  5720 | performance: 0.7 | accuracy: 0.24 | loss: -0.01
update:720/2000, 耗时:0.00分/1.04分 | step:  5760 | performance: 0.7 | accuracy: 0.24 | loss: 0.35
update:725/2000, 耗时:0.00分/1.04分 | step:  5800 | performance: 0.8 | accuracy: 0.24 | loss: 0.11
update:730/2000, 耗时:0.00分/1.05分 | step:  5840 | performance: 0.8 | accuracy: 0.24 | loss: 0.10
update:735/2000, 耗时:0.00分/1.06分 | step:  5880 | performance: 0.8 | accuracy: 0.24 | loss: 0.48
update:740/2000, 耗时:0.00分/1.07分 | step:  5920 | performance: 0.8 | accuracy: 0.24 | loss: 0.19
update:745/2000, 耗时:0.00分/1.08分 | step:  5960 | performance: 0.8 | accuracy: 0.24 | loss: 0.05
update:750/2000, 耗时:0.00分/1.08分 | step:  6000 | performance: 0.8 | accuracy: 0.24 | loss: 0.26
update:755/2000, 耗时:0.00分/1.09分 | step:  6040 | performance: 0.8 | accuracy: 0.24 | loss: 0.33
update:760/2000, 耗时:0.00分/1.10分 | step:  6080 | performance: 0.8 | accuracy: 0.24 | loss: 0.15
update:765/2000, 耗时:0.00分/1.11分 | step:  6120 | performance: 0.8 | accuracy: 0.24 | loss: 0.32
update:770/2000, 耗时:0.00分/1.11分 | step:  6160 | performance: 0.7 | accuracy: 0.24 | loss: 0.34
update:775/2000, 耗时:0.00分/1.12分 | step:  6200 | performance: 0.7 | accuracy: 0.24 | loss: 0.25
update:780/2000, 耗时:0.00分/1.13分 | step:  6240 | performance: 0.7 | accuracy: 0.24 | loss: 0.29
update:785/2000, 耗时:0.00分/1.14分 | step:  6280 | performance: 0.7 | accuracy: 0.24 | loss: 0.42
update:790/2000, 耗时:0.00分/1.14分 | step:  6320 | performance: 0.7 | accuracy: 0.24 | loss: 0.35
update:795/2000, 耗时:0.00分/1.15分 | step:  6360 | performance: 0.7 | accuracy: 0.24 | loss: 0.67
update:800/2000, 耗时:0.00分/1.16分 | step:  6400 | performance: 0.7 | accuracy: 0.24 | loss: 0.13
update:805/2000, 耗时:0.00分/1.17分 | step:  6440 | performance: 0.7 | accuracy: 0.24 | loss: 0.23
update:810/2000, 耗时:0.00分/1.17分 | step:  6480 | performance: 0.7 | accuracy: 0.24 | loss: 0.34
update:815/2000, 耗时:0.00分/1.18分 | step:  6520 | performance: 0.8 | accuracy: 0.24 | loss: 0.05
update:820/2000, 耗时:0.00分/1.19分 | step:  6560 | performance: 0.7 | accuracy: 0.24 | loss: 0.11
update:825/2000, 耗时:0.00分/1.20分 | step:  6600 | performance: 0.7 | accuracy: 0.24 | loss: 0.19
update:830/2000, 耗时:0.00分/1.21分 | step:  6640 | performance: 0.7 | accuracy: 0.24 | loss: 0.42
update:835/2000, 耗时:0.00分/1.21分 | step:  6680 | performance: 0.7 | accuracy: 0.24 | loss: 0.48
update:840/2000, 耗时:0.00分/1.22分 | step:  6720 | performance: 0.7 | accuracy: 0.24 | loss: 0.39
update:845/2000, 耗时:0.00分/1.23分 | step:  6760 | performance: 0.7 | accuracy: 0.24 | loss: 0.25
update:850/2000, 耗时:0.00分/1.24分 | step:  6800 | performance: 0.7 | accuracy: 0.24 | loss: 0.31
update:855/2000, 耗时:0.00分/1.24分 | step:  6840 | performance: 0.7 | accuracy: 0.24 | loss: 0.68
update:860/2000, 耗时:0.00分/1.25分 | step:  6880 | performance: 0.7 | accuracy: 0.24 | loss: 0.58
update:865/2000, 耗时:0.00分/1.26分 | step:  6920 | performance: 0.6 | accuracy: 0.24 | loss: 0.29
update:870/2000, 耗时:0.00分/1.27分 | step:  6960 | performance: 0.8 | accuracy: 0.24 | loss: 0.48
update:875/2000, 耗时:0.00分/1.27分 | step:  7000 | performance: 1.0 | accuracy: 0.24 | loss: 0.26
update:880/2000, 耗时:0.00分/1.28分 | step:  7040 | performance: 0.9 | accuracy: 0.24 | loss: 0.99
update:885/2000, 耗时:0.00分/1.29分 | step:  7080 | performance: 0.7 | accuracy: 0.24 | loss: 0.54
update:890/2000, 耗时:0.00分/1.30分 | step:  7120 | performance: 0.7 | accuracy: 0.24 | loss: 0.83
update:895/2000, 耗时:0.00分/1.30分 | step:  7160 | performance: 0.7 | accuracy: 0.24 | loss: 0.52
update:900/2000, 耗时:0.00分/1.31分 | step:  7200 | performance: 0.7 | accuracy: 0.24 | loss: 0.40
update:905/2000, 耗时:0.00分/1.32分 | step:  7240 | performance: 0.8 | accuracy: 0.25 | loss: 0.32
update:910/2000, 耗时:0.00分/1.33分 | step:  7280 | performance: 0.7 | accuracy: 0.25 | loss: 0.80
update:915/2000, 耗时:0.00分/1.33分 | step:  7320 | performance: 0.7 | accuracy: 0.25 | loss: 0.08
update:920/2000, 耗时:0.00分/1.34分 | step:  7360 | performance: 0.6 | accuracy: 0.25 | loss: 0.30
update:925/2000, 耗时:0.00分/1.35分 | step:  7400 | performance: 0.6 | accuracy: 0.25 | loss: 0.37
update:930/2000, 耗时:0.00分/1.36分 | step:  7440 | performance: 0.6 | accuracy: 0.25 | loss: 0.31
update:935/2000, 耗时:0.00分/1.36分 | step:  7480 | performance: 0.6 | accuracy: 0.25 | loss: 0.54
update:940/2000, 耗时:0.00分/1.37分 | step:  7520 | performance: 0.7 | accuracy: 0.25 | loss: 0.68
update:945/2000, 耗时:0.00分/1.38分 | step:  7560 | performance: 0.8 | accuracy: 0.26 | loss: 0.45
update:950/2000, 耗时:0.00分/1.39分 | step:  7600 | performance: 0.8 | accuracy: 0.26 | loss: 0.28
update:955/2000, 耗时:0.00分/1.39分 | step:  7640 | performance: 1.0 | accuracy: 0.26 | loss: 0.46
update:960/2000, 耗时:0.00分/1.40分 | step:  7680 | performance: 1.1 | accuracy: 0.26 | loss: 0.33
update:965/2000, 耗时:0.00分/1.41分 | step:  7720 | performance: 1.0 | accuracy: 0.26 | loss: 0.97
update:970/2000, 耗时:0.00分/1.42分 | step:  7760 | performance: 0.9 | accuracy: 0.26 | loss: 1.31
update:975/2000, 耗时:0.00分/1.42分 | step:  7800 | performance: 0.8 | accuracy: 0.26 | loss: 0.60
update:980/2000, 耗时:0.00分/1.43分 | step:  7840 | performance: 0.6 | accuracy: 0.26 | loss: 0.08
update:985/2000, 耗时:0.00分/1.44分 | step:  7880 | performance: 0.7 | accuracy: 0.26 | loss: 0.19
update:990/2000, 耗时:0.00分/1.45分 | step:  7920 | performance: 0.6 | accuracy: 0.26 | loss: 0.51
update:995/2000, 耗时:0.00分/1.45分 | step:  7960 | performance: 0.5 | accuracy: 0.26 | loss: 0.69
update:1000/2000, 耗时:0.00分/1.46分 | step:  8000 | performance: 0.6 | accuracy: 0.26 | loss: 0.79
update:1005/2000, 耗时:0.00分/1.47分 | step:  8040 | performance: 0.6 | accuracy: 0.26 | loss: 0.17
update:1010/2000, 耗时:0.00分/1.48分 | step:  8080 | performance: 0.6 | accuracy: 0.26 | loss: 0.46
update:1015/2000, 耗时:0.00分/1.48分 | step:  8120 | performance: 0.6 | accuracy: 0.26 | loss: 0.15
update:1020/2000, 耗时:0.00分/1.49分 | step:  8160 | performance: 0.6 | accuracy: 0.26 | loss: 0.54
update:1025/2000, 耗时:0.00分/1.50分 | step:  8200 | performance: 0.6 | accuracy: 0.27 | loss: 0.65
update:1030/2000, 耗时:0.00分/1.50分 | step:  8240 | performance: 0.6 | accuracy: 0.26 | loss: 0.26
update:1035/2000, 耗时:0.00分/1.51分 | step:  8280 | performance: 0.6 | accuracy: 0.26 | loss: 0.84
update:1040/2000, 耗时:0.00分/1.52分 | step:  8320 | performance: 0.6 | accuracy: 0.27 | loss: 0.48
update:1045/2000, 耗时:0.00分/1.53分 | step:  8360 | performance: 0.8 | accuracy: 0.27 | loss: 0.70
update:1050/2000, 耗时:0.00分/1.53分 | step:  8400 | performance: 0.9 | accuracy: 0.27 | loss: 0.42
update:1055/2000, 耗时:0.00分/1.54分 | step:  8440 | performance: 0.8 | accuracy: 0.27 | loss: 0.27
update:1060/2000, 耗时:0.00分/1.55分 | step:  8480 | performance: 0.7 | accuracy: 0.27 | loss: 0.79
update:1065/2000, 耗时:0.00分/1.56分 | step:  8520 | performance: 0.7 | accuracy: 0.27 | loss: 0.32
update:1070/2000, 耗时:0.00分/1.56分 | step:  8560 | performance: 0.7 | accuracy: 0.27 | loss: 0.26
update:1075/2000, 耗时:0.00分/1.57分 | step:  8600 | performance: 0.7 | accuracy: 0.27 | loss: 0.67
update:1080/2000, 耗时:0.00分/1.58分 | step:  8640 | performance: 0.8 | accuracy: 0.27 | loss: 0.40
update:1085/2000, 耗时:0.00分/1.59分 | step:  8680 | performance: 0.8 | accuracy: 0.27 | loss: 0.37
update:1090/2000, 耗时:0.00分/1.59分 | step:  8720 | performance: 0.9 | accuracy: 0.28 | loss: 0.80
update:1095/2000, 耗时:0.00分/1.60分 | step:  8760 | performance: 1.0 | accuracy: 0.28 | loss: 0.27
update:1100/2000, 耗时:0.00分/1.61分 | step:  8800 | performance: 1.2 | accuracy: 0.28 | loss: 0.71
update:1105/2000, 耗时:0.00分/1.62分 | step:  8840 | performance: 1.1 | accuracy: 0.28 | loss: 0.37
update:1110/2000, 耗时:0.00分/1.62分 | step:  8880 | performance: 1.1 | accuracy: 0.28 | loss: 0.52
update:1115/2000, 耗时:0.00分/1.63分 | step:  8920 | performance: 1.1 | accuracy: 0.28 | loss: 0.70
update:1120/2000, 耗时:0.00分/1.64分 | step:  8960 | performance: 1.2 | accuracy: 0.28 | loss: 0.47
update:1125/2000, 耗时:0.00分/1.65分 | step:  9000 | performance: 1.2 | accuracy: 0.28 | loss: 0.03
update:1130/2000, 耗时:0.00分/1.65分 | step:  9040 | performance: 1.1 | accuracy: 0.28 | loss: 0.49
update:1135/2000, 耗时:0.00分/1.66分 | step:  9080 | performance: 1.0 | accuracy: 0.28 | loss: 0.62
update:1140/2000, 耗时:0.00分/1.67分 | step:  9120 | performance: 1.1 | accuracy: 0.28 | loss: 0.38
update:1145/2000, 耗时:0.00分/1.68分 | step:  9160 | performance: 1.4 | accuracy: 0.28 | loss: 0.72
update:1150/2000, 耗时:0.00分/1.68分 | step:  9200 | performance: 1.6 | accuracy: 0.29 | loss: 0.36
update:1155/2000, 耗时:0.00分/1.69分 | step:  9240 | performance: 1.6 | accuracy: 0.29 | loss: 0.45
update:1160/2000, 耗时:0.00分/1.70分 | step:  9280 | performance: 1.6 | accuracy: 0.29 | loss: 0.39
update:1165/2000, 耗时:0.00分/1.71分 | step:  9320 | performance: 1.6 | accuracy: 0.29 | loss: 0.34
update:1170/2000, 耗时:0.00分/1.71分 | step:  9360 | performance: 1.5 | accuracy: 0.29 | loss: 0.52
update:1175/2000, 耗时:0.00分/1.72分 | step:  9400 | performance: 1.4 | accuracy: 0.29 | loss: 0.51
update:1180/2000, 耗时:0.00分/1.73分 | step:  9440 | performance: 1.4 | accuracy: 0.28 | loss: 0.32
update:1185/2000, 耗时:0.00分/1.74分 | step:  9480 | performance: 1.4 | accuracy: 0.29 | loss: 0.35
update:1190/2000, 耗时:0.00分/1.74分 | step:  9520 | performance: 1.3 | accuracy: 0.29 | loss: 0.45
update:1195/2000, 耗时:0.00分/1.75分 | step:  9560 | performance: 1.3 | accuracy: 0.29 | loss: 0.50
update:1200/2000, 耗时:0.00分/1.76分 | step:  9600 | performance: 1.3 | accuracy: 0.29 | loss: 0.21
update:1205/2000, 耗时:0.00分/1.77分 | step:  9640 | performance: 1.6 | accuracy: 0.29 | loss: 0.73
update:1210/2000, 耗时:0.00分/1.77分 | step:  9680 | performance: 1.9 | accuracy: 0.29 | loss: 0.12
update:1215/2000, 耗时:0.00分/1.78分 | step:  9720 | performance: 1.8 | accuracy: 0.29 | loss: 0.64
update:1220/2000, 耗时:0.00分/1.79分 | step:  9760 | performance: 1.8 | accuracy: 0.29 | loss: 0.12
update:1225/2000, 耗时:0.00分/1.80分 | step:  9800 | performance: 1.8 | accuracy: 0.29 | loss: 0.40
update:1230/2000, 耗时:0.00分/1.80分 | step:  9840 | performance: 1.7 | accuracy: 0.29 | loss: 0.18
update:1235/2000, 耗时:0.00分/1.81分 | step:  9880 | performance: 1.7 | accuracy: 0.28 | loss: 0.29
update:1240/2000, 耗时:0.00分/1.82分 | step:  9920 | performance: 1.8 | accuracy: 0.28 | loss: 0.24
update:1245/2000, 耗时:0.00分/1.83分 | step:  9960 | performance: 1.9 | accuracy: 0.29 | loss: 0.41
update:1250/2000, 耗时:0.00分/1.83分 | step: 10000 | performance: 1.8 | accuracy: 0.29 | loss: 0.30
update:1255/2000, 耗时:0.00分/1.84分 | step: 10040 | performance: 1.8 | accuracy: 0.29 | loss: 0.47
update:1260/2000, 耗时:0.00分/1.85分 | step: 10080 | performance: 2.2 | accuracy: 0.29 | loss: 1.33
update:1265/2000, 耗时:0.00分/1.86分 | step: 10120 | performance: 2.3 | accuracy: 0.29 | loss: 0.42
update:1270/2000, 耗时:0.00分/1.86分 | step: 10160 | performance: 2.3 | accuracy: 0.29 | loss: 0.50
update:1275/2000, 耗时:0.00分/1.87分 | step: 10200 | performance: 2.2 | accuracy: 0.29 | loss: 0.25
update:1280/2000, 耗时:0.00分/1.88分 | step: 10240 | performance: 2.2 | accuracy: 0.29 | loss: 0.47
update:1285/2000, 耗时:0.00分/1.89分 | step: 10280 | performance: 2.2 | accuracy: 0.29 | loss: 0.18
update:1290/2000, 耗时:0.00分/1.89分 | step: 10320 | performance: 2.2 | accuracy: 0.29 | loss: 0.34
update:1295/2000, 耗时:0.00分/1.90分 | step: 10360 | performance: 2.2 | accuracy: 0.29 | loss: 0.21
update:1300/2000, 耗时:0.00分/1.91分 | step: 10400 | performance: 2.2 | accuracy: 0.29 | loss: 0.05
update:1305/2000, 耗时:0.00分/1.92分 | step: 10440 | performance: 2.2 | accuracy: 0.29 | loss: 0.44
update:1310/2000, 耗时:0.00分/1.92分 | step: 10480 | performance: 2.4 | accuracy: 0.29 | loss: 0.38
update:1315/2000, 耗时:0.00分/1.93分 | step: 10520 | performance: 2.5 | accuracy: 0.29 | loss: 0.56
update:1320/2000, 耗时:0.00分/1.94分 | step: 10560 | performance: 2.5 | accuracy: 0.29 | loss: 0.04
update:1325/2000, 耗时:0.00分/1.95分 | step: 10600 | performance: 2.5 | accuracy: 0.29 | loss: 0.16
update:1330/2000, 耗时:0.00分/1.95分 | step: 10640 | performance: 2.6 | accuracy: 0.29 | loss: 0.34
update:1335/2000, 耗时:0.00分/1.96分 | step: 10680 | performance: 2.6 | accuracy: 0.29 | loss: 0.23
update:1340/2000, 耗时:0.00分/1.97分 | step: 10720 | performance: 2.6 | accuracy: 0.29 | loss: 0.33
update:1345/2000, 耗时:0.00分/1.98分 | step: 10760 | performance: 2.6 | accuracy: 0.29 | loss: 0.29
update:1350/2000, 耗时:0.00分/1.98分 | step: 10800 | performance: 2.5 | accuracy: 0.29 | loss: 0.53
update:1355/2000, 耗时:0.00分/1.99分 | step: 10840 | performance: 2.5 | accuracy: 0.28 | loss: 0.34
update:1360/2000, 耗时:0.00分/2.00分 | step: 10880 | performance: 2.2 | accuracy: 0.28 | loss: 0.45
update:1365/2000, 耗时:0.00分/2.01分 | step: 10920 | performance: 2.1 | accuracy: 0.28 | loss: 0.20
update:1370/2000, 耗时:0.00分/2.01分 | step: 10960 | performance: 2.4 | accuracy: 0.28 | loss: 0.06
update:1375/2000, 耗时:0.00分/2.02分 | step: 11000 | performance: 2.4 | accuracy: 0.28 | loss: 0.43
update:1380/2000, 耗时:0.00分/2.03分 | step: 11040 | performance: 2.3 | accuracy: 0.28 | loss: 0.17
update:1385/2000, 耗时:0.00分/2.04分 | step: 11080 | performance: 2.3 | accuracy: 0.28 | loss: 0.45
update:1390/2000, 耗时:0.00分/2.04分 | step: 11120 | performance: 2.2 | accuracy: 0.28 | loss: 0.27
update:1395/2000, 耗时:0.00分/2.05分 | step: 11160 | performance: 1.9 | accuracy: 0.28 | loss: 0.42
update:1400/2000, 耗时:0.00分/2.06分 | step: 11200 | performance: 1.9 | accuracy: 0.28 | loss: 0.32
update:1405/2000, 耗时:0.00分/2.07分 | step: 11240 | performance: 1.9 | accuracy: 0.28 | loss: 0.45
update:1410/2000, 耗时:0.00分/2.08分 | step: 11280 | performance: 2.0 | accuracy: 0.28 | loss: 0.25
update:1415/2000, 耗时:0.00分/2.08分 | step: 11320 | performance: 1.8 | accuracy: 0.28 | loss: 0.23
update:1420/2000, 耗时:0.00分/2.09分 | step: 11360 | performance: 1.8 | accuracy: 0.28 | loss: 0.13
update:1425/2000, 耗时:0.00分/2.10分 | step: 11400 | performance: 1.8 | accuracy: 0.28 | loss: 0.38
update:1430/2000, 耗时:0.00分/2.11分 | step: 11440 | performance: 1.9 | accuracy: 0.28 | loss: 0.08
update:1435/2000, 耗时:0.00分/2.11分 | step: 11480 | performance: 1.7 | accuracy: 0.28 | loss: 0.52
update:1440/2000, 耗时:0.00分/2.12分 | step: 11520 | performance: 1.5 | accuracy: 0.28 | loss: 0.37
update:1445/2000, 耗时:0.00分/2.13分 | step: 11560 | performance: 1.6 | accuracy: 0.28 | loss: 0.19
update:1450/2000, 耗时:0.00分/2.14分 | step: 11600 | performance: 1.5 | accuracy: 0.28 | loss: 0.41
update:1455/2000, 耗时:0.00分/2.14分 | step: 11640 | performance: 1.6 | accuracy: 0.28 | loss: 0.45
update:1460/2000, 耗时:0.00分/2.15分 | step: 11680 | performance: 1.6 | accuracy: 0.28 | loss: 0.25
update:1465/2000, 耗时:0.00分/2.16分 | step: 11720 | performance: 1.6 | accuracy: 0.28 | loss: 0.26
update:1470/2000, 耗时:0.00分/2.17分 | step: 11760 | performance: 1.5 | accuracy: 0.28 | loss: 0.56
update:1475/2000, 耗时:0.00分/2.18分 | step: 11800 | performance: 1.2 | accuracy: 0.28 | loss: 0.90
update:1480/2000, 耗时:0.00分/2.18分 | step: 11840 | performance: 1.2 | accuracy: 0.28 | loss: 0.38
update:1485/2000, 耗时:0.00分/2.19分 | step: 11880 | performance: 4.3 | accuracy: 0.28 | loss: 0.38
update:1490/2000, 耗时:0.00分/2.20分 | step: 11920 | performance: 4.6 | accuracy: 0.28 | loss: 0.64
update:1495/2000, 耗时:0.00分/2.21分 | step: 11960 | performance: 5.0 | accuracy: 0.28 | loss: 1.51
update:1500/2000, 耗时:0.00分/2.21分 | step: 12000 | performance: 4.9 | accuracy: 0.28 | loss: 0.03
update:1505/2000, 耗时:0.00分/2.22分 | step: 12040 | performance: 4.6 | accuracy: 0.28 | loss: 0.09
update:1510/2000, 耗时:0.00分/2.23分 | step: 12080 | performance: 4.0 | accuracy: 0.28 | loss: 0.09
update:1515/2000, 耗时:0.00分/2.24分 | step: 12120 | performance: 4.0 | accuracy: 0.28 | loss: 0.22
update:1520/2000, 耗时:0.00分/2.24分 | step: 12160 | performance: 4.3 | accuracy: 0.28 | loss: 0.39
update:1525/2000, 耗时:0.00分/2.25分 | step: 12200 | performance: 4.8 | accuracy: 0.28 | loss: 0.46
update:1530/2000, 耗时:0.00分/2.26分 | step: 12240 | performance: 4.3 | accuracy: 0.28 | loss: 0.29
update:1535/2000, 耗时:0.00分/2.27分 | step: 12280 | performance: 4.0 | accuracy: 0.28 | loss: 0.32
update:1540/2000, 耗时:0.00分/2.27分 | step: 12320 | performance: 3.7 | accuracy: 0.28 | loss: 0.30
update:1545/2000, 耗时:0.00分/2.28分 | step: 12360 | performance: 3.3 | accuracy: 0.28 | loss: 0.31
update:1550/2000, 耗时:0.00分/2.29分 | step: 12400 | performance: 3.3 | accuracy: 0.28 | loss: 0.13
update:1555/2000, 耗时:0.00分/2.30分 | step: 12440 | performance: 3.4 | accuracy: 0.28 | loss: 0.26
update:1560/2000, 耗时:0.00分/2.31分 | step: 12480 | performance: 3.7 | accuracy: 0.28 | loss: 0.15
update:1565/2000, 耗时:0.00分/2.31分 | step: 12520 | performance: 3.4 | accuracy: 0.28 | loss: 0.34
update:1570/2000, 耗时:0.00分/2.32分 | step: 12560 | performance: 3.5 | accuracy: 0.28 | loss: 0.13
update:1575/2000, 耗时:0.00分/2.33分 | step: 12600 | performance: 3.4 | accuracy: 0.28 | loss: 0.29
update:1580/2000, 耗时:0.00分/2.34分 | step: 12640 | performance: 3.0 | accuracy: 0.28 | loss: 0.84
update:1585/2000, 耗时:0.00分/2.34分 | step: 12680 | performance: 2.9 | accuracy: 0.28 | loss: 0.50
update:1590/2000, 耗时:0.00分/2.35分 | step: 12720 | performance: 3.0 | accuracy: 0.28 | loss: 0.28
update:1595/2000, 耗时:0.00分/2.36分 | step: 12760 | performance: 2.9 | accuracy: 0.28 | loss: 0.66
update:1600/2000, 耗时:0.00分/2.37分 | step: 12800 | performance: 3.6 | accuracy: 0.28 | loss: 0.44
update:1605/2000, 耗时:0.00分/2.37分 | step: 12840 | performance: 3.8 | accuracy: 0.28 | loss: 0.37
update:1610/2000, 耗时:0.00分/2.38分 | step: 12880 | performance: 3.6 | accuracy: 0.28 | loss: 0.64
update:1615/2000, 耗时:0.00分/2.39分 | step: 12920 | performance: 3.8 | accuracy: 0.28 | loss: 0.57
update:1620/2000, 耗时:0.00分/2.40分 | step: 12960 | performance: 3.6 | accuracy: 0.28 | loss: 0.12
update:1625/2000, 耗时:0.00分/2.41分 | step: 13000 | performance: 4.3 | accuracy: 0.28 | loss: 0.53
update:1630/2000, 耗时:0.00分/2.41分 | step: 13040 | performance: 4.8 | accuracy: 0.28 | loss: 0.39
update:1635/2000, 耗时:0.00分/2.42分 | step: 13080 | performance: 4.5 | accuracy: 0.28 | loss: 0.35
update:1640/2000, 耗时:0.00分/2.43分 | step: 13120 | performance: 4.0 | accuracy: 0.28 | loss: 0.52
update:1645/2000, 耗时:0.00分/2.44分 | step: 13160 | performance: 3.8 | accuracy: 0.28 | loss: 0.54
update:1650/2000, 耗时:0.00分/2.45分 | step: 13200 | performance: 4.3 | accuracy: 0.28 | loss: 0.19
update:1655/2000, 耗时:0.00分/2.45分 | step: 13240 | performance: 4.4 | accuracy: 0.28 | loss: 0.25
update:1660/2000, 耗时:0.00分/2.46分 | step: 13280 | performance: 4.5 | accuracy: 0.28 | loss: 0.30
update:1665/2000, 耗时:0.00分/2.47分 | step: 13320 | performance: 4.5 | accuracy: 0.28 | loss: 0.54
update:1670/2000, 耗时:0.00分/2.48分 | step: 13360 | performance: 4.4 | accuracy: 0.28 | loss: 0.28
update:1675/2000, 耗时:0.00分/2.48分 | step: 13400 | performance: 4.2 | accuracy: 0.28 | loss: 0.72
update:1680/2000, 耗时:0.00分/2.49分 | step: 13440 | performance: 4.4 | accuracy: 0.28 | loss: 0.27
update:1685/2000, 耗时:0.00分/2.50分 | step: 13480 | performance: 4.4 | accuracy: 0.28 | loss: 0.39
update:1690/2000, 耗时:0.00分/2.51分 | step: 13520 | performance: 4.0 | accuracy: 0.28 | loss: 0.52
update:1695/2000, 耗时:0.00分/2.51分 | step: 13560 | performance: 3.8 | accuracy: 0.28 | loss: 0.38
update:1700/2000, 耗时:0.00分/2.52分 | step: 13600 | performance: 3.8 | accuracy: 0.28 | loss: 0.40
update:1705/2000, 耗时:0.00分/2.53分 | step: 13640 | performance: 3.8 | accuracy: 0.28 | loss: 0.32
update:1710/2000, 耗时:0.00分/2.54分 | step: 13680 | performance: 3.9 | accuracy: 0.28 | loss: 0.23
update:1715/2000, 耗时:0.00分/2.54分 | step: 13720 | performance: 3.9 | accuracy: 0.28 | loss: 0.31
update:1720/2000, 耗时:0.00分/2.55分 | step: 13760 | performance: 3.8 | accuracy: 0.28 | loss: 0.19
update:1725/2000, 耗时:0.00分/2.56分 | step: 13800 | performance: 4.0 | accuracy: 0.28 | loss: 0.40
update:1730/2000, 耗时:0.00分/2.57分 | step: 13840 | performance: 4.0 | accuracy: 0.28 | loss: 0.19
update:1735/2000, 耗时:0.00分/2.57分 | step: 13880 | performance: 4.1 | accuracy: 0.29 | loss: 0.45
update:1740/2000, 耗时:0.00分/2.58分 | step: 13920 | performance: 4.0 | accuracy: 0.29 | loss: 0.18
update:1745/2000, 耗时:0.00分/2.59分 | step: 13960 | performance: 4.0 | accuracy: 0.29 | loss: 0.37
update:1750/2000, 耗时:0.00分/2.60分 | step: 14000 | performance: 3.9 | accuracy: 0.29 | loss: 0.36
update:1755/2000, 耗时:0.00分/2.60分 | step: 14040 | performance: 3.9 | accuracy: 0.28 | loss: 0.33
update:1760/2000, 耗时:0.00分/2.61分 | step: 14080 | performance: 3.7 | accuracy: 0.28 | loss: 0.30
update:1765/2000, 耗时:0.00分/2.62分 | step: 14120 | performance: 3.8 | accuracy: 0.28 | loss: 0.19
update:1770/2000, 耗时:0.00分/2.63分 | step: 14160 | performance: 4.1 | accuracy: 0.28 | loss: 0.39
update:1775/2000, 耗时:0.00分/2.63分 | step: 14200 | performance: 4.2 | accuracy: 0.29 | loss: 0.77
update:1780/2000, 耗时:0.00分/2.64分 | step: 14240 | performance: 4.3 | accuracy: 0.29 | loss: 0.49
update:1785/2000, 耗时:0.00分/2.65分 | step: 14280 | performance: 4.3 | accuracy: 0.29 | loss: 0.21
update:1790/2000, 耗时:0.00分/2.66分 | step: 14320 | performance: 4.2 | accuracy: 0.29 | loss: 0.34
update:1795/2000, 耗时:0.00分/2.66分 | step: 14360 | performance: 4.1 | accuracy: 0.29 | loss: 0.21
update:1800/2000, 耗时:0.00分/2.67分 | step: 14400 | performance: 4.2 | accuracy: 0.29 | loss: 0.35
update:1805/2000, 耗时:0.00分/2.68分 | step: 14440 | performance: 4.1 | accuracy: 0.29 | loss: -0.06
update:1810/2000, 耗时:0.00分/2.69分 | step: 14480 | performance: 4.2 | accuracy: 0.29 | loss: 0.10
update:1815/2000, 耗时:0.00分/2.69分 | step: 14520 | performance: 4.2 | accuracy: 0.29 | loss: 0.17
update:1820/2000, 耗时:0.00分/2.70分 | step: 14560 | performance: 4.3 | accuracy: 0.29 | loss: 0.19
update:1825/2000, 耗时:0.00分/2.71分 | step: 14600 | performance: 4.1 | accuracy: 0.29 | loss: 0.33
update:1830/2000, 耗时:0.00分/2.72分 | step: 14640 | performance: 4.0 | accuracy: 0.29 | loss: 0.15
update:1835/2000, 耗时:0.00分/2.73分 | step: 14680 | performance: 3.9 | accuracy: 0.29 | loss: 0.63
update:1840/2000, 耗时:0.00分/2.73分 | step: 14720 | performance: 3.8 | accuracy: 0.29 | loss: 0.36
update:1845/2000, 耗时:0.00分/2.74分 | step: 14760 | performance: 3.9 | accuracy: 0.29 | loss: 0.36
update:1850/2000, 耗时:0.00分/2.75分 | step: 14800 | performance: 3.9 | accuracy: 0.29 | loss: 0.27
update:1855/2000, 耗时:0.00分/2.76分 | step: 14840 | performance: 3.8 | accuracy: 0.29 | loss: 0.31
update:1860/2000, 耗时:0.00分/2.76分 | step: 14880 | performance: 3.5 | accuracy: 0.28 | loss: 0.11
update:1865/2000, 耗时:0.00分/2.77分 | step: 14920 | performance: 3.6 | accuracy: 0.29 | loss: 0.30
update:1870/2000, 耗时:0.00分/2.78分 | step: 14960 | performance: 3.3 | accuracy: 0.29 | loss: 0.61
update:1875/2000, 耗时:0.00分/2.79分 | step: 15000 | performance: 3.3 | accuracy: 0.29 | loss: 0.40
update:1880/2000, 耗时:0.00分/2.79分 | step: 15040 | performance: 3.3 | accuracy: 0.29 | loss: 0.36
update:1885/2000, 耗时:0.00分/2.80分 | step: 15080 | performance: 3.3 | accuracy: 0.29 | loss: 0.10
update:1890/2000, 耗时:0.00分/2.81分 | step: 15120 | performance: 3.3 | accuracy: 0.29 | loss: 0.47
update:1895/2000, 耗时:0.00分/2.82分 | step: 15160 | performance: 3.2 | accuracy: 0.29 | loss: 0.32
update:1900/2000, 耗时:0.00分/2.82分 | step: 15200 | performance: 3.2 | accuracy: 0.29 | loss: 0.42
update:1905/2000, 耗时:0.00分/2.83分 | step: 15240 | performance: 3.2 | accuracy: 0.29 | loss: 0.26
update:1910/2000, 耗时:0.00分/2.84分 | step: 15280 | performance: 3.3 | accuracy: 0.29 | loss: 0.46
update:1915/2000, 耗时:0.00分/2.85分 | step: 15320 | performance: 3.2 | accuracy: 0.29 | loss: 0.28
update:1920/2000, 耗时:0.00分/2.85分 | step: 15360 | performance: 3.2 | accuracy: 0.29 | loss: 0.33
update:1925/2000, 耗时:0.00分/2.86分 | step: 15400 | performance: 3.1 | accuracy: 0.29 | loss: 0.23
update:1930/2000, 耗时:0.00分/2.87分 | step: 15440 | performance: 3.0 | accuracy: 0.29 | loss: 0.37
update:1935/2000, 耗时:0.00分/2.88分 | step: 15480 | performance: 3.3 | accuracy: 0.29 | loss: 0.14
update:1940/2000, 耗时:0.00分/2.88分 | step: 15520 | performance: 3.3 | accuracy: 0.29 | loss: 0.48
update:1945/2000, 耗时:0.00分/2.89分 | step: 15560 | performance: 3.2 | accuracy: 0.29 | loss: 0.37
update:1950/2000, 耗时:0.00分/2.90分 | step: 15600 | performance: 3.4 | accuracy: 0.29 | loss: 0.24
update:1955/2000, 耗时:0.00分/2.91分 | step: 15640 | performance: 3.4 | accuracy: 0.29 | loss: 0.39
update:1960/2000, 耗时:0.00分/2.91分 | step: 15680 | performance: 3.6 | accuracy: 0.29 | loss: 0.77
update:1965/2000, 耗时:0.00分/2.92分 | step: 15720 | performance: 3.5 | accuracy: 0.29 | loss: 0.36
update:1970/2000, 耗时:0.00分/2.93分 | step: 15760 | performance: 3.7 | accuracy: 0.29 | loss: 0.22
update:1975/2000, 耗时:0.00分/2.94分 | step: 15800 | performance: 4.0 | accuracy: 0.29 | loss: 0.34
update:1980/2000, 耗时:0.00分/2.94分 | step: 15840 | performance: 3.8 | accuracy: 0.29 | loss: 0.33
update:1985/2000, 耗时:0.00分/2.95分 | step: 15880 | performance: 3.8 | accuracy: 0.29 | loss: 0.08
update:1990/2000, 耗时:0.00分/2.96分 | step: 15920 | performance: 4.2 | accuracy: 0.29 | loss: 0.25
update:1995/2000, 耗时:0.00分/2.96分 | step: 15960 | performance: 4.3 | accuracy: 0.29 | loss: 0.33
  0%|          | 0/403 [00:00<?, ?it/s]update:2000/2000, 耗时:0.00分/2.97分 | step: 16000 | performance: 4.0 | accuracy: 0.29 | loss: 1.37
----------------------------------------finished----------------------------------------
100%|| 403/403 [00:00<00:00, 100715.28it/s]
==================================================
2023-01-04T12:00:00 | *** START BACKTEST ***
2023-01-04T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1569.30
2023-07-24T12:00:00 | net performance [%] = 56.9300
2023-07-24T12:00:00 | number of trades [#] = 58
==================================================
Trial 58 Complete [00h 03m 25s]
net_wealth: 1570.8709138375038

Best net_wealth So Far: 1824.8039564105297
Total elapsed time: 07h 54m 00s

Search: Running Trial #59

Value             |Best Value So Far |Hyperparameter
5                 |6                 |horizon
730               |365               |lookback
False             |True              |MarketFactor
3                 |10                |lags
0.85              |0.98              |gamma
32                |16                |batch_size
64                |7                 |n_step
0.8               |0.94              |gae_lambda
10                |0.5               |gradient_clip_norm
3                 |3                 |epochs
0.0005            |0.001             |actor_lr
0.001             |0.001             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4315.000000     4315.000000  ...    4310.000000   4315.000000
mean      0.000441    20062.255222  ...   20136.939364  20118.633889
std       0.027818    16039.874230  ...   16077.430342  16077.098476
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009736     7609.090466  ...    7696.969971   7690.540039
50%       0.000642    11554.824463  ...   11742.710449  11715.610352
75%       0.011655    29873.081836  ...   29945.211914  29923.605469
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 8 columns]
                           log_return  ...        close
2017-08-27 08:00:00+08:00   -0.003249  ...  4323.370117
2017-08-27 20:00:00+08:00   -0.003095  ...  4310.009766

[2 rows x 8 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 8 columns]
2023-07-28 05:57:24.243788: I tensorflow/co2023-07-28 052:023-07r57:-2e/p428.latfor2 405:53m872:3/:2 cI4 .tensorf2437plowu8/2_fea09: It2cor e/pl3tuaensorrf-tform0e_gu7alow/core-rd.2208/platf c0o5rm/cpc:u23-07-28 /c0p5u5::_57f7_f:ee:224aa41t4ure_gut.ure_gua2438912rd.cc:142.:24 I]3 ]7 tenso 92:rf IlTohia tensorflow/cowrsTreh/pl/ids .Tencoarcetsor/Fp low blform/catfpu_featurTioeenr_gumnaard.sr/coy ccris:p14Flo2u_featwc 0u:1 23-ro2bi4e2]_gunaar]  TThh0prtyi7ids mi. cc:-sT eopntsoi1rFs i42zeldowi miz]2Tbenie8 0 nTary is ohd2spois 0w25 i3-:2Trthtiemns00o2rFlioz3 o5-enw70d 7 -ewAPI Deep Nebi2u8n a05 wiit:r5ray7Fl ih:lowt bins2h4 aon eAP  rNeyt is.wI2o noo 7-44r3k8ep ti28 moLii:05:bp9t:r a5izIe 27t:ensor24DAd .eefwitPI24r.y  2h4p4 N(meiu4lo3zed r7422:5 6Iowwneiatlh  Ne: DNN )I ttto  te/ouewncnsorkoeAe  tren/spLshDel aton ofroollfrfloweofibrawepePAPI ir/IcoDrney  eNego rmuel o(D/rawCoe/elp/corp Np PUeclpnNeeD/ e tNNNiuuweour)nsatrak_ rtpl fLeaiarflttbuocormr/ tautarel_ ryi fguu(oosaer dthne onNfso liln eeDNNt)p o. cNerrcpeu_twtmcf/efawoo utwuoro:rk1c4se tep rh_eguL2]k  T_ fiofueahlarbirsa rd.lTetcureLrmoawi_ngnncseyc :(1i4og uCPUb2ra-rda]rrc . cyc :(1iTo4nriti2cheiDFNlNow)o]anl n nTih ibegDsotps iCrPeNnaUry i NT nu)c raienststsr uoctoi utsoorpnte ionst:  imFlsAsiVzXedo  oth i n ewT bA VpXe2r
fToorw  iufnae sie ttroytnsoieonhrmFlahlalown bieowi nsc ei-c  nonen rfos AoPIi tDielplltoibmeppegr ew iin thNenfargy eimz eidno uiC  CPrUasr moal PwUi Nicptiatlhn cooe noeeA-ttpPn stiwehrmaiorcructnzI Distrerkt iLoinreoeucdt iwionns s iin sten:brh i tpiep   N ceauoonprelfroAeVraarypAeal (onXr fto Nret ormiaApVeXDonnecre-PsIw, cr Deor2riatioek
 TetNN)binspL tooc: N e uri b meAuraaal VoXrnuiald yAse p  TenVtearnaXth(es cilo nfb2lo
TeNoeteoonls:   reFDle NlNwtAV-oc)oowhiw  wtiot Xureimt sr nniaknb lohteig Ahe cLal  opi btrtehreth eCPhaer ye atVimX(2oU  f
nT oiioao ppre DNennraonpbori snp:N l aeorlslteru otwi)t tnhtAegVeX c tcioomhAoVe Xamp2C
PTUoinrst  iln ioons,  ei nin  rontsu peahepetrr ufctiborsbeeearnlsa t i oirofognns, puptehres. 
lmeae rfthrarte oirmencelanibf-m in ouilocoldcritical operations Tneetd: n-hlecr TseonroFwsrsolr,iotion gpic w  AwVXeitra arl  toipoeFAnVse,lho wt Xb uhw2r
aTtoiCoPU inisltdr u eTnesinrac:th enes  tbtabpop AiVrXhuerFoinosp in lpeer  appropriAlVXformance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriat 2
To enadetble theh eTm come piilnn othersorFlow with the appropriate compiler flags.
er flags.
riate co operations, rebuild TensorFlow witmate low with the appropriate commc iopmppiihiller  er the appropriate compiler leflags.
flrag sfla.
fn other logasgperations, rebuild TensorFlow with the appropriate compiler flags.
s.
.
2023-07-28 05:57:24.836735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:57:24.847114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:57:24.859428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:57:24.864713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:57:24.876346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:57:24.883132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:57:24.901477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 05:57:24.915926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.01分/0.06分 | step:  2560 | performance: 0.2 | accuracy: 0.35 | loss: 1.51
update: 10/2000, 耗时:0.01分/0.10分 | step:  5120 | performance: 0.4 | accuracy: 0.36 | loss: 3.17
update: 15/2000, 耗时:0.01分/0.15分 | step:  7680 | performance: 0.6 | accuracy: 0.36 | loss: 1.27
update: 20/2000, 耗时:0.01分/0.20分 | step: 10240 | performance: 1.6 | accuracy: 0.35 | loss: 1.48
update: 25/2000, 耗时:0.01分/0.25分 | step: 12800 | performance: 0.4 | accuracy: 0.34 | loss: 1.31
update: 30/2000, 耗时:0.01分/0.31分 | step: 15360 | performance: 0.0 | accuracy: 0.32 | loss: 0.68
update: 35/2000, 耗时:0.01分/0.36分 | step: 17920 | performance: 0.0 | accuracy: 0.32 | loss: 0.71
update: 40/2000, 耗时:0.01分/0.42分 | step: 20480 | performance: 0.0 | accuracy: 0.31 | loss: 1.22
update: 45/2000, 耗时:0.01分/0.47分 | step: 23040 | performance: 0.0 | accuracy: 0.31 | loss: 1.37
update: 50/2000, 耗时:0.01分/0.52分 | step: 25600 | performance: 1.1 | accuracy: 0.31 | loss: 0.69
Saving PPO weights in both H5 format and checkpoint @ update:50 
update: 55/2000, 耗时:0.01分/0.58分 | step: 28160 | performance: 3.5 | accuracy: 0.34 | loss: 0.61
update: 60/2000, 耗时:0.01分/0.63分 | step: 30720 | performance: 5.4 | accuracy: 0.27 | loss: 0.51
update: 65/2000, 耗时:0.01分/0.68分 | step: 33280 | performance: 10.9 | accuracy: 0.25 | loss: 0.44
update: 70/2000, 耗时:0.01分/0.73分 | step: 35840 | performance: 31.5 | accuracy: 0.24 | loss: 0.39
update: 75/2000, 耗时:0.01分/0.78分 | step: 38400 | performance: 26.6 | accuracy: 0.22 | loss: 0.28
update: 80/2000, 耗时:0.01分/0.83分 | step: 40960 | performance: 30.7 | accuracy: 0.19 | loss: 0.18
update: 85/2000, 耗时:0.01分/0.88分 | step: 43520 | performance: 58.2 | accuracy: 0.18 | loss: 0.30
update: 90/2000, 耗时:0.01分/0.94分 | step: 46080 | performance: 72.8 | accuracy: 0.17 | loss: 0.32
update: 95/2000, 耗时:0.01分/0.99分 | step: 48640 | performance: 70.9 | accuracy: 0.17 | loss: 0.26
update:100/2000, 耗时:0.01分/1.04分 | step: 51200 | performance: 1.0 | accuracy: 0.00 | loss: 0.31
Saving PPO weights in both H5 format and checkpoint @ update:100 
step: 51709 | worker_4@n_step_63: average total_reward after train data exhaustion : -1.5 | max total_reward: 138.0
Saving PPO weights in both H5 format and checkpoint @ update:101 
update:105/2000, 耗时:0.01分/1.10分 | step: 53760 | performance: 2.5 | accuracy: 0.20 | loss: 0.53
update:110/2000, 耗时:0.01分/1.15分 | step: 56320 | performance: 1.2 | accuracy: 0.16 | loss: 0.18
update:115/2000, 耗时:0.01分/1.20分 | step: 58880 | performance: 1.6 | accuracy: 0.14 | loss: 0.17
update:120/2000, 耗时:0.01分/1.25分 | step: 61440 | performance: 0.6 | accuracy: 0.11 | loss: 0.21
Saving PPO weights in both H5 format and checkpoint @ update:124 
update:125/2000, 耗时:0.01分/1.30分 | step: 64000 | performance: 0.7 | accuracy: 0.10 | loss: 0.18
Saving PPO weights in both H5 format and checkpoint @ update:125 
Saving PPO weights in both H5 format and checkpoint @ update:126 
Saving PPO weights in both H5 format and checkpoint @ update:127 
Saving PPO weights in both H5 format and checkpoint @ update:128 
update:130/2000, 耗时:0.01分/1.37分 | step: 66560 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
update:135/2000, 耗时:0.01分/1.42分 | step: 69120 | performance: 1.0 | accuracy: 0.17 | loss: 0.15
step: 70143 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 138.0
step: 71163 | worker_2@n_step_63: average total_reward after train data exhaustion : 2.2 | max total_reward: 138.0
step: 71164 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.2 | max total_reward: 138.0
update:140/2000, 耗时:0.01分/1.48分 | step: 71680 | performance: 1.1 | accuracy: 0.38 | loss: 0.15
step: 73215 | worker_6@n_step_63: average total_reward after train data exhaustion : 2.0 | max total_reward: 138.0
step: 73725 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 138.0
update:145/2000, 耗时:0.01分/1.53分 | step: 74240 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:150/2000, 耗时:0.01分/1.58分 | step: 76800 | performance: 1.4 | accuracy: 0.15 | loss: 0.32
update:155/2000, 耗时:0.01分/1.63分 | step: 79360 | performance: 0.9 | accuracy: 0.14 | loss: 0.36
update:160/2000, 耗时:0.01分/1.68分 | step: 81920 | performance: 0.5 | accuracy: 0.12 | loss: 0.24
update:165/2000, 耗时:0.01分/1.73分 | step: 84480 | performance: 0.3 | accuracy: 0.11 | loss: 0.30
update:170/2000, 耗时:0.01分/1.78分 | step: 87040 | performance: 0.2 | accuracy: 0.11 | loss: 0.17
update:175/2000, 耗时:0.01分/1.83分 | step: 89600 | performance: 0.1 | accuracy: 0.10 | loss: 0.22
update:180/2000, 耗时:0.01分/1.88分 | step: 92160 | performance: 0.1 | accuracy: 0.11 | loss: 0.45
update:185/2000, 耗时:0.01分/1.93分 | step: 94720 | performance: 0.1 | accuracy: 0.11 | loss: 0.30
update:190/2000, 耗时:0.01分/1.98分 | step: 97280 | performance: 0.0 | accuracy: 0.11 | loss: 0.16
update:195/2000, 耗时:0.01分/2.03分 | step: 99840 | performance: 0.0 | accuracy: 0.10 | loss: 0.13
step: 101882 | worker_1@n_step_63: average total_reward after train data exhaustion : 9.2 | max total_reward: 155.7
Saving PPO weights in both H5 format and checkpoint @ update:199 
step: 102397 | worker_4@n_step_63: average total_reward after train data exhaustion : 12.8 | max total_reward: 155.7
update:200/2000, 耗时:0.01分/2.09分 | step: 102400 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
Saving PPO weights in both H5 format and checkpoint @ update:200 
step: 103424 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.8 | max total_reward: 155.7
step: 104444 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
step: 104959 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 155.7
update:205/2000, 耗时:0.01分/2.14分 | step: 104960 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 107001 | worker_0@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 155.7
update:210/2000, 耗时:0.01分/2.19分 | step: 107520 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 109053 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 155.7
step: 110075 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:215/2000, 耗时:0.01分/2.25分 | step: 110080 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
update:220/2000, 耗时:0.01分/2.30分 | step: 112640 | performance: 0.9 | accuracy: 0.15 | loss: 0.24
step: 114686 | worker_5@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 155.7
update:225/2000, 耗时:0.01分/2.35分 | step: 115200 | performance: 1.1 | accuracy: 0.16 | loss: 0.34
update:230/2000, 耗时:0.01分/2.40分 | step: 117760 | performance: 1.3 | accuracy: 0.13 | loss: 0.28
update:235/2000, 耗时:0.01分/2.45分 | step: 120320 | performance: 1.7 | accuracy: 0.13 | loss: 0.28
update:240/2000, 耗时:0.01分/2.50分 | step: 122880 | performance: 1.7 | accuracy: 0.12 | loss: 0.24
update:245/2000, 耗时:0.01分/2.55分 | step: 125440 | performance: 2.7 | accuracy: 0.13 | loss: 0.25
step: 126459 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:250/2000, 耗时:0.01分/2.60分 | step: 128000 | performance: 4.2 | accuracy: 0.12 | loss: 0.40
update:255/2000, 耗时:0.01分/2.65分 | step: 130560 | performance: 8.6 | accuracy: 0.12 | loss: 0.26
update:260/2000, 耗时:0.01分/2.70分 | step: 133120 | performance: 4.4 | accuracy: 0.11 | loss: 0.14
update:265/2000, 耗时:0.01分/2.75分 | step: 135680 | performance: 6.0 | accuracy: 0.11 | loss: 0.13
update:270/2000, 耗时:0.01分/2.80分 | step: 138240 | performance: 1.0 | accuracy: 0.10 | loss: 0.22
update:275/2000, 耗时:0.01分/2.86分 | step: 140800 | performance: 1.2 | accuracy: 0.11 | loss: 0.13
update:280/2000, 耗时:0.01分/2.91分 | step: 143360 | performance: 1.2 | accuracy: 0.14 | loss: 0.23
step: 144895 | worker_6@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 155.7
update:285/2000, 耗时:0.01分/2.96分 | step: 145920 | performance: 1.4 | accuracy: 0.11 | loss: 0.32
update:290/2000, 耗时:0.01分/3.01分 | step: 148480 | performance: 0.9 | accuracy: 0.11 | loss: 0.20
step: 150013 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 155.7
update:295/2000, 耗时:0.01分/3.06分 | step: 151040 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
update:300/2000, 耗时:0.01分/3.11分 | step: 153600 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
update:305/2000, 耗时:0.01分/3.16分 | step: 156160 | performance: 1.3 | accuracy: 0.12 | loss: 0.25
step: 156665 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 155.7
update:310/2000, 耗时:0.01分/3.21分 | step: 158720 | performance: 1.1 | accuracy: 0.12 | loss: 0.30
update:315/2000, 耗时:0.01分/3.27分 | step: 161280 | performance: 1.7 | accuracy: 0.12 | loss: 0.21
update:320/2000, 耗时:0.01分/3.32分 | step: 163840 | performance: 1.1 | accuracy: 0.11 | loss: 0.20
update:325/2000, 耗时:0.01分/3.37分 | step: 166400 | performance: 0.6 | accuracy: 0.11 | loss: 0.17
update:330/2000, 耗时:0.01分/3.42分 | step: 168960 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 169978 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 155.7
step: 169981 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 155.7
update:335/2000, 耗时:0.01分/3.47分 | step: 171520 | performance: 1.0 | accuracy: 0.20 | loss: 0.16
update:340/2000, 耗时:0.01分/3.53分 | step: 174080 | performance: 1.0 | accuracy: 0.20 | loss: 0.15
step: 175612 | worker_3@n_step_63: average total_reward after train data exhaustion : -0.3 | max total_reward: 155.7
step: 176122 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
update:345/2000, 耗时:0.01分/3.58分 | step: 176640 | performance: 1.0 | accuracy: 0.08 | loss: 0.11
step: 177145 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
step: 177151 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
step: 177660 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:350/2000, 耗时:0.01分/3.63分 | step: 179200 | performance: 1.0 | accuracy: 0.08 | loss: 0.42
update:355/2000, 耗时:0.01分/3.68分 | step: 181760 | performance: 1.6 | accuracy: 0.17 | loss: 0.40
update:360/2000, 耗时:0.01分/3.74分 | step: 184320 | performance: 0.7 | accuracy: 0.12 | loss: 0.17
update:365/2000, 耗时:0.01分/3.79分 | step: 186880 | performance: 0.8 | accuracy: 0.10 | loss: 0.14
update:370/2000, 耗时:0.01分/3.84分 | step: 189440 | performance: 1.0 | accuracy: 0.00 | loss: 0.13
step: 190975 | worker_6@n_step_63: average total_reward after train data exhaustion : 2.9 | max total_reward: 155.7
update:375/2000, 耗时:0.01分/3.89分 | step: 192000 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
step: 193535 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.8 | max total_reward: 155.7
update:380/2000, 耗时:0.01分/3.94分 | step: 194560 | performance: 1.5 | accuracy: 0.12 | loss: 0.21
update:385/2000, 耗时:0.01分/3.99分 | step: 197120 | performance: 1.4 | accuracy: 0.11 | loss: 0.47
update:390/2000, 耗时:0.01分/4.05分 | step: 199680 | performance: 1.0 | accuracy: 0.00 | loss: 0.26
update:395/2000, 耗时:0.01分/4.10分 | step: 202240 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
step: 204282 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 155.7
update:400/2000, 耗时:0.01分/4.15分 | step: 204800 | performance: 1.0 | accuracy: 0.25 | loss: 0.13
step: 205817 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.3 | max total_reward: 155.7
update:405/2000, 耗时:0.01分/4.20分 | step: 207360 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 208383 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
update:410/2000, 耗时:0.01分/4.25分 | step: 209920 | performance: 1.3 | accuracy: 0.15 | loss: 0.29
update:415/2000, 耗时:0.01分/4.30分 | step: 212480 | performance: 1.8 | accuracy: 0.13 | loss: 0.60
update:420/2000, 耗时:0.01分/4.36分 | step: 215040 | performance: 0.9 | accuracy: 0.12 | loss: 0.31
update:425/2000, 耗时:0.01分/4.41分 | step: 217600 | performance: 0.6 | accuracy: 0.11 | loss: 0.15
update:430/2000, 耗时:0.01分/4.46分 | step: 220160 | performance: 1.0 | accuracy: 0.08 | loss: 0.12
step: 221696 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 155.7
update:435/2000, 耗时:0.01分/4.51分 | step: 222720 | performance: 1.0 | accuracy: 0.11 | loss: 0.12
step: 224766 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 155.7
update:440/2000, 耗时:0.01分/4.56分 | step: 225280 | performance: 1.0 | accuracy: 0.07 | loss: 0.10
step: 226809 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 155.7
step: 227324 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 155.7
update:445/2000, 耗时:0.01分/4.62分 | step: 227840 | performance: 1.0 | accuracy: 0.12 | loss: 0.15
update:450/2000, 耗时:0.01分/4.67分 | step: 230400 | performance: 1.3 | accuracy: 0.18 | loss: 0.53
update:455/2000, 耗时:0.01分/4.73分 | step: 232960 | performance: 1.4 | accuracy: 0.16 | loss: 0.26
update:460/2000, 耗时:0.01分/4.78分 | step: 235520 | performance: 1.4 | accuracy: 0.13 | loss: 0.22
update:465/2000, 耗时:0.01分/4.83分 | step: 238080 | performance: 1.3 | accuracy: 0.12 | loss: 0.21
update:470/2000, 耗时:0.01分/4.88分 | step: 240640 | performance: 1.0 | accuracy: 0.12 | loss: 0.18
update:475/2000, 耗时:0.01分/4.94分 | step: 243200 | performance: 1.8 | accuracy: 0.11 | loss: 0.14
step: 245244 | worker_3@n_step_63: average total_reward after train data exhaustion : 3.2 | max total_reward: 155.7
update:480/2000, 耗时:0.01分/4.99分 | step: 245760 | performance: 1.0 | accuracy: 0.07 | loss: 0.20
update:485/2000, 耗时:0.01分/5.05分 | step: 248320 | performance: 1.0 | accuracy: 0.10 | loss: 0.17
step: 248825 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 155.7
step: 248831 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 155.7
update:490/2000, 耗时:0.01分/5.10分 | step: 250880 | performance: 1.3 | accuracy: 0.11 | loss: 0.29
update:495/2000, 耗时:0.01分/5.15分 | step: 253440 | performance: 1.6 | accuracy: 0.14 | loss: 0.55
update:500/2000, 耗时:0.01分/5.20分 | step: 256000 | performance: 1.0 | accuracy: 0.12 | loss: 0.25
update:505/2000, 耗时:0.01分/5.25分 | step: 258560 | performance: 1.0 | accuracy: 0.11 | loss: 0.14
update:510/2000, 耗时:0.01分/5.31分 | step: 261120 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
update:515/2000, 耗时:0.01分/5.36分 | step: 263680 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
step: 264704 | worker_7@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 155.7
step: 265726 | worker_5@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 155.7
step: 266234 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
step: 266237 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:520/2000, 耗时:0.01分/5.41分 | step: 266240 | performance: 1.0 | accuracy: 0.20 | loss: 0.05
step: 267260 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
step: 267264 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
step: 268285 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 155.7
update:525/2000, 耗时:0.01分/5.46分 | step: 268800 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
update:530/2000, 耗时:0.01分/5.51分 | step: 271360 | performance: 5.1 | accuracy: 0.15 | loss: 0.37
update:535/2000, 耗时:0.01分/5.56分 | step: 273920 | performance: 2.2 | accuracy: 0.13 | loss: 0.19
update:540/2000, 耗时:0.01分/5.62分 | step: 276480 | performance: 1.9 | accuracy: 0.11 | loss: 0.18
step: 276988 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.4 | max total_reward: 155.7
step: 278521 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.9 | max total_reward: 155.7
update:545/2000, 耗时:0.01分/5.67分 | step: 279040 | performance: 3.5 | accuracy: 0.12 | loss: 0.23
update:550/2000, 耗时:0.01分/5.72分 | step: 281600 | performance: 3.8 | accuracy: 0.12 | loss: 0.27
update:555/2000, 耗时:0.01分/5.77分 | step: 284160 | performance: 3.4 | accuracy: 0.11 | loss: 0.22
update:560/2000, 耗时:0.01分/5.82分 | step: 286720 | performance: 2.9 | accuracy: 0.11 | loss: 0.20
update:565/2000, 耗时:0.01分/5.87分 | step: 289280 | performance: 6.9 | accuracy: 0.11 | loss: 0.32
update:570/2000, 耗时:0.01分/5.92分 | step: 291840 | performance: 8.4 | accuracy: 0.11 | loss: 0.25
update:575/2000, 耗时:0.01分/5.98分 | step: 294400 | performance: 9.0 | accuracy: 0.10 | loss: 0.14
step: 295418 | worker_1@n_step_63: average total_reward after train data exhaustion : 9.6 | max total_reward: 155.7
update:580/2000, 耗时:0.01分/6.03分 | step: 296960 | performance: 1.5 | accuracy: 0.12 | loss: 0.23
step: 298494 | worker_5@n_step_63: average total_reward after train data exhaustion : -0.3 | max total_reward: 155.7
update:585/2000, 耗时:0.01分/6.08分 | step: 299520 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
step: 300031 | worker_6@n_step_63: average total_reward after train data exhaustion : -0.2 | max total_reward: 155.7
update:590/2000, 耗时:0.01分/6.13分 | step: 302080 | performance: 1.0 | accuracy: 0.07 | loss: 0.29
update:595/2000, 耗时:0.01分/6.19分 | step: 304640 | performance: 1.3 | accuracy: 0.18 | loss: 0.40
update:600/2000, 耗时:0.01分/6.24分 | step: 307200 | performance: 2.0 | accuracy: 0.13 | loss: 0.33
step: 309244 | worker_3@n_step_63: average total_reward after train data exhaustion : 3.8 | max total_reward: 155.7
update:605/2000, 耗时:0.01分/6.29分 | step: 309760 | performance: 1.4 | accuracy: 0.11 | loss: 0.17
step: 311803 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 155.7
update:610/2000, 耗时:0.01分/6.34分 | step: 312320 | performance: 2.5 | accuracy: 0.11 | loss: 0.21
update:615/2000, 耗时:0.01分/6.39分 | step: 314880 | performance: 1.7 | accuracy: 0.10 | loss: 0.24
step: 315391 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 155.7
step: 315901 | worker_4@n_step_63: average total_reward after train data exhaustion : 2.6 | max total_reward: 155.7
update:620/2000, 耗时:0.01分/6.44分 | step: 317440 | performance: 1.3 | accuracy: 0.16 | loss: 0.26
update:625/2000, 耗时:0.01分/6.49分 | step: 320000 | performance: 1.6 | accuracy: 0.15 | loss: 0.53
update:630/2000, 耗时:0.01分/6.54分 | step: 322560 | performance: 1.0 | accuracy: 0.14 | loss: 0.30
update:635/2000, 耗时:0.01分/6.59分 | step: 325120 | performance: 0.7 | accuracy: 0.11 | loss: 0.21
update:640/2000, 耗时:0.01分/6.65分 | step: 327680 | performance: 0.6 | accuracy: 0.11 | loss: 0.27
update:645/2000, 耗时:0.01分/6.70分 | step: 330240 | performance: 0.7 | accuracy: 0.10 | loss: 0.13
step: 332797 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 155.7
update:650/2000, 耗时:0.01分/6.75分 | step: 332800 | performance: 1.0 | accuracy: 0.00 | loss: 0.12
update:655/2000, 耗时:0.01分/6.80分 | step: 335360 | performance: 1.8 | accuracy: 0.12 | loss: 0.19
update:660/2000, 耗时:0.01分/6.85分 | step: 337920 | performance: 1.1 | accuracy: 0.12 | loss: 0.38
update:665/2000, 耗时:0.01分/6.91分 | step: 340480 | performance: 1.2 | accuracy: 0.11 | loss: 0.24
update:670/2000, 耗时:0.01分/6.96分 | step: 343040 | performance: 1.2 | accuracy: 0.11 | loss: 0.23
update:675/2000, 耗时:0.01分/7.01分 | step: 345600 | performance: 1.4 | accuracy: 0.11 | loss: 0.27
update:680/2000, 耗时:0.01分/7.06分 | step: 348160 | performance: 0.6 | accuracy: 0.10 | loss: 0.14
step: 349696 | worker_7@n_step_63: average total_reward after train data exhaustion : 4.1 | max total_reward: 155.7
step: 350207 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.5 | max total_reward: 155.7
update:685/2000, 耗时:0.01分/7.11分 | step: 350720 | performance: 1.3 | accuracy: 0.12 | loss: 0.15
update:690/2000, 耗时:0.01分/7.16分 | step: 353280 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:695/2000, 耗时:0.01分/7.22分 | step: 355840 | performance: 1.4 | accuracy: 0.17 | loss: 0.37
update:700/2000, 耗时:0.01分/7.27分 | step: 358400 | performance: 0.8 | accuracy: 0.14 | loss: 0.33
update:705/2000, 耗时:0.01分/7.32分 | step: 360960 | performance: 0.9 | accuracy: 0.12 | loss: 0.21
update:710/2000, 耗时:0.01分/7.37分 | step: 363520 | performance: 0.9 | accuracy: 0.12 | loss: 0.37
update:715/2000, 耗时:0.01分/7.42分 | step: 366080 | performance: 0.8 | accuracy: 0.11 | loss: 0.27
step: 368121 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 155.7
update:720/2000, 耗时:0.01分/7.47分 | step: 368640 | performance: 0.5 | accuracy: 0.10 | loss: 0.09
step: 369149 | worker_4@n_step_63: average total_reward after train data exhaustion : 4.9 | max total_reward: 155.7
update:725/2000, 耗时:0.01分/7.52分 | step: 371200 | performance: 1.0 | accuracy: 0.07 | loss: 0.07
step: 372729 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
step: 373757 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
update:730/2000, 耗时:0.01分/7.57分 | step: 373760 | performance: 2.1 | accuracy: 0.14 | loss: 0.21
step: 375802 | worker_1@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 155.7
update:735/2000, 耗时:0.01分/7.62分 | step: 376320 | performance: 2.3 | accuracy: 0.12 | loss: 0.26
step: 376825 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
update:740/2000, 耗时:0.01分/7.68分 | step: 378880 | performance: 1.6 | accuracy: 0.16 | loss: 0.21
step: 379903 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.5 | max total_reward: 155.7
update:745/2000, 耗时:0.01分/7.73分 | step: 381440 | performance: 2.0 | accuracy: 0.15 | loss: 0.31
update:750/2000, 耗时:0.01分/7.78分 | step: 384000 | performance: 1.6 | accuracy: 0.12 | loss: 0.21
update:755/2000, 耗时:0.01分/7.83分 | step: 386560 | performance: 1.2 | accuracy: 0.10 | loss: 0.21
update:760/2000, 耗时:0.01分/7.88分 | step: 389120 | performance: 3.2 | accuracy: 0.10 | loss: 0.20
update:765/2000, 耗时:0.01分/7.93分 | step: 391680 | performance: 1.2 | accuracy: 0.14 | loss: 0.19
update:770/2000, 耗时:0.01分/7.98分 | step: 394240 | performance: 1.0 | accuracy: 0.08 | loss: 0.12
update:775/2000, 耗时:0.01分/8.03分 | step: 396800 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 397822 | worker_5@n_step_63: average total_reward after train data exhaustion : -0.2 | max total_reward: 155.7
step: 399353 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:780/2000, 耗时:0.01分/8.08分 | step: 399360 | performance: 1.3 | accuracy: 0.15 | loss: 0.30
update:785/2000, 耗时:0.01分/8.13分 | step: 401920 | performance: 1.8 | accuracy: 0.16 | loss: 0.47
update:790/2000, 耗时:0.01分/8.18分 | step: 404480 | performance: 1.2 | accuracy: 0.13 | loss: 0.25
step: 407037 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 155.7
update:795/2000, 耗时:0.01分/8.23分 | step: 407040 | performance: 0.9 | accuracy: 0.12 | loss: 0.19
step: 408573 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 155.7
update:800/2000, 耗时:0.01分/8.28分 | step: 409600 | performance: 0.5 | accuracy: 0.10 | loss: 0.18
update:805/2000, 耗时:0.01分/8.33分 | step: 412160 | performance: 1.0 | accuracy: 0.50 | loss: 0.23
step: 413178 | worker_1@n_step_63: average total_reward after train data exhaustion : 3.6 | max total_reward: 155.7
step: 413689 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.7 | max total_reward: 155.7
step: 414207 | worker_6@n_step_63: average total_reward after train data exhaustion : 2.0 | max total_reward: 155.7
step: 414715 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 155.7
update:810/2000, 耗时:0.01分/8.39分 | step: 414720 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 415225 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 155.7
step: 415229 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
update:815/2000, 耗时:0.01分/8.44分 | step: 417280 | performance: 1.1 | accuracy: 0.12 | loss: 0.15
step: 418812 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
update:820/2000, 耗时:0.01分/8.48分 | step: 419840 | performance: 1.3 | accuracy: 0.19 | loss: 0.38
update:825/2000, 耗时:0.01分/8.53分 | step: 422400 | performance: 2.0 | accuracy: 0.15 | loss: 0.34
update:830/2000, 耗时:0.01分/8.59分 | step: 424960 | performance: 0.9 | accuracy: 0.12 | loss: 0.15
update:835/2000, 耗时:0.01分/8.63分 | step: 427520 | performance: 0.9 | accuracy: 0.11 | loss: 0.17
update:840/2000, 耗时:0.01分/8.68分 | step: 430080 | performance: 2.4 | accuracy: 0.10 | loss: 0.20
update:845/2000, 耗时:0.01分/8.74分 | step: 432640 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
step: 434176 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
step: 435193 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:850/2000, 耗时:0.01分/8.79分 | step: 435200 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 435708 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 155.7
update:855/2000, 耗时:0.01分/8.84分 | step: 437760 | performance: 2.3 | accuracy: 0.15 | loss: 0.31
update:860/2000, 耗时:0.01分/8.89分 | step: 440320 | performance: 1.4 | accuracy: 0.12 | loss: 0.21
step: 442876 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 155.7
update:865/2000, 耗时:0.01分/8.94分 | step: 442880 | performance: 1.3 | accuracy: 0.11 | loss: 0.17
step: 443385 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.4 | max total_reward: 155.7
step: 445434 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 155.7
update:870/2000, 耗时:0.01分/8.98分 | step: 445440 | performance: 1.2 | accuracy: 0.14 | loss: 0.23
step: 445952 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 155.7
update:875/2000, 耗时:0.01分/9.02分 | step: 448000 | performance: 0.9 | accuracy: 0.12 | loss: 0.25
update:880/2000, 耗时:0.01分/9.07分 | step: 450560 | performance: 1.5 | accuracy: 0.12 | loss: 0.23
step: 453113 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 155.7
update:885/2000, 耗时:0.01分/9.12分 | step: 453120 | performance: 1.0 | accuracy: 0.09 | loss: 0.14
step: 455679 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
update:890/2000, 耗时:0.01分/9.17分 | step: 455680 | performance: 1.0 | accuracy: 0.00 | loss: 0.25
update:895/2000, 耗时:0.01分/9.23分 | step: 458240 | performance: 4.0 | accuracy: 0.20 | loss: 0.42
update:900/2000, 耗时:0.01分/9.28分 | step: 460800 | performance: 2.8 | accuracy: 0.15 | loss: 0.27
update:905/2000, 耗时:0.01分/9.33分 | step: 463360 | performance: 5.6 | accuracy: 0.14 | loss: 0.17
step: 464379 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
update:910/2000, 耗时:0.01分/9.38分 | step: 465920 | performance: 13.4 | accuracy: 0.13 | loss: 0.19
update:915/2000, 耗时:0.01分/9.43分 | step: 468480 | performance: 8.8 | accuracy: 0.12 | loss: 0.20
step: 468986 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 155.7
step: 468991 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 155.7
update:920/2000, 耗时:0.01分/9.48分 | step: 471040 | performance: 3.0 | accuracy: 0.12 | loss: 0.23
step: 471545 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 155.7
update:925/2000, 耗时:0.01分/9.53分 | step: 473600 | performance: 2.0 | accuracy: 0.11 | loss: 0.23
step: 474108 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.5 | max total_reward: 155.7
update:930/2000, 耗时:0.01分/9.59分 | step: 476160 | performance: 2.2 | accuracy: 0.10 | loss: 0.14
step: 477179 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:935/2000, 耗时:0.01分/9.64分 | step: 478720 | performance: 3.5 | accuracy: 0.10 | loss: 0.15
update:940/2000, 耗时:0.01分/9.69分 | step: 481280 | performance: 6.1 | accuracy: 0.11 | loss: 0.43
step: 481792 | worker_7@n_step_63: average total_reward after train data exhaustion : 3.1 | max total_reward: 155.7
update:945/2000, 耗时:0.01分/9.74分 | step: 483840 | performance: 1.7 | accuracy: 0.12 | loss: 0.30
update:950/2000, 耗时:0.01分/9.79分 | step: 486400 | performance: 0.7 | accuracy: 0.11 | loss: 0.19
update:955/2000, 耗时:0.01分/9.84分 | step: 488960 | performance: 0.7 | accuracy: 0.10 | loss: 0.21
update:960/2000, 耗时:0.01分/9.89分 | step: 491520 | performance: 1.0 | accuracy: 0.00 | loss: 0.19
step: 493567 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 155.7
step: 494073 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 155.7
update:965/2000, 耗时:0.01分/9.95分 | step: 494080 | performance: 1.0 | accuracy: 0.14 | loss: 0.14
update:970/2000, 耗时:0.01分/10.00分 | step: 496640 | performance: 1.3 | accuracy: 0.11 | loss: 0.22
update:975/2000, 耗时:0.01分/10.05分 | step: 499200 | performance: 1.4 | accuracy: 0.14 | loss: 0.32
update:980/2000, 耗时:0.01分/10.10分 | step: 501760 | performance: 0.7 | accuracy: 0.12 | loss: 0.42
update:985/2000, 耗时:0.01分/10.15分 | step: 504320 | performance: 1.0 | accuracy: 0.12 | loss: 0.23
update:990/2000, 耗时:0.01分/10.20分 | step: 506880 | performance: 1.3 | accuracy: 0.12 | loss: 0.32
update:995/2000, 耗时:0.01分/10.25分 | step: 509440 | performance: 0.7 | accuracy: 0.11 | loss: 0.24
update:1000/2000, 耗时:0.01分/10.30分 | step: 512000 | performance: 0.7 | accuracy: 0.10 | loss: 0.10
update:1005/2000, 耗时:0.01分/10.35分 | step: 514560 | performance: 1.0 | accuracy: 0.07 | loss: 0.12
step: 515067 | worker_2@n_step_63: average total_reward after train data exhaustion : 2.8 | max total_reward: 155.7
step: 515068 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.7 | max total_reward: 155.7
step: 515069 | worker_4@n_step_63: average total_reward after train data exhaustion : 2.8 | max total_reward: 155.7
step: 515583 | worker_6@n_step_63: average total_reward after train data exhaustion : 2.8 | max total_reward: 155.7
step: 516601 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
update:1010/2000, 耗时:0.01分/10.40分 | step: 517120 | performance: 1.0 | accuracy: 0.20 | loss: 0.12
step: 517628 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:1015/2000, 耗时:0.01分/10.45分 | step: 519680 | performance: 1.0 | accuracy: 0.07 | loss: 0.27
update:1020/2000, 耗时:0.01分/10.50分 | step: 522240 | performance: 2.8 | accuracy: 0.19 | loss: 0.28
update:1025/2000, 耗时:0.01分/10.55分 | step: 524800 | performance: 1.4 | accuracy: 0.14 | loss: 0.20
update:1030/2000, 耗时:0.01分/10.61分 | step: 527360 | performance: 1.2 | accuracy: 0.11 | loss: 0.24
update:1035/2000, 耗时:0.01分/10.66分 | step: 529920 | performance: 1.4 | accuracy: 0.10 | loss: 0.19
step: 530431 | worker_6@n_step_63: average total_reward after train data exhaustion : 3.3 | max total_reward: 155.7
step: 530940 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.5 | max total_reward: 155.7
step: 532480 | worker_7@n_step_63: average total_reward after train data exhaustion : 2.6 | max total_reward: 155.7
update:1040/2000, 耗时:0.01分/10.71分 | step: 532480 | performance: 1.0 | accuracy: 0.00 | loss: 0.15
update:1045/2000, 耗时:0.01分/10.76分 | step: 535040 | performance: 1.1 | accuracy: 0.14 | loss: 0.19
update:1050/2000, 耗时:0.01分/10.81分 | step: 537600 | performance: 0.8 | accuracy: 0.12 | loss: 0.36
update:1055/2000, 耗时:0.01分/10.86分 | step: 540160 | performance: 0.4 | accuracy: 0.11 | loss: 0.24
update:1060/2000, 耗时:0.01分/10.91分 | step: 542720 | performance: 1.0 | accuracy: 0.00 | loss: 0.23
update:1065/2000, 耗时:0.01分/10.97分 | step: 545280 | performance: 1.9 | accuracy: 0.13 | loss: 0.24
step: 547328 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.8 | max total_reward: 155.7
update:1070/2000, 耗时:0.01分/11.02分 | step: 547840 | performance: 1.1 | accuracy: 0.16 | loss: 0.20
update:1075/2000, 耗时:0.01分/11.07分 | step: 550400 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 550909 | worker_4@n_step_63: average total_reward after train data exhaustion : 2.1 | max total_reward: 155.7
step: 551929 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
update:1080/2000, 耗时:0.01分/11.12分 | step: 552960 | performance: 1.1 | accuracy: 0.14 | loss: 0.24
step: 554496 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
update:1085/2000, 耗时:0.01分/11.17分 | step: 555520 | performance: 1.0 | accuracy: 0.10 | loss: 0.22
step: 556025 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.8 | max total_reward: 155.7
update:1090/2000, 耗时:0.01分/11.22分 | step: 558080 | performance: 1.3 | accuracy: 0.11 | loss: 0.26
update:1095/2000, 耗时:0.01分/11.27分 | step: 560640 | performance: 1.3 | accuracy: 0.13 | loss: 0.25
step: 563198 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 155.7
update:1100/2000, 耗时:0.01分/11.32分 | step: 563200 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
step: 564732 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
update:1105/2000, 耗时:0.01分/11.37分 | step: 565760 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 566271 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
step: 568315 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 155.7
update:1110/2000, 耗时:0.01分/11.43分 | step: 568320 | performance: 1.0 | accuracy: 0.25 | loss: 0.17
step: 569342 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 155.7
step: 570368 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
update:1115/2000, 耗时:0.01分/11.48分 | step: 570880 | performance: 1.0 | accuracy: 0.08 | loss: 0.20
step: 571389 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 155.7
step: 571391 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:1120/2000, 耗时:0.01分/11.53分 | step: 573440 | performance: 2.4 | accuracy: 0.13 | loss: 0.36
update:1125/2000, 耗时:0.01分/11.58分 | step: 576000 | performance: 0.7 | accuracy: 0.11 | loss: 0.18
update:1130/2000, 耗时:0.01分/11.63分 | step: 578560 | performance: 0.8 | accuracy: 0.11 | loss: 0.15
step: 580093 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 155.7
update:1135/2000, 耗时:0.01分/11.68分 | step: 581120 | performance: 1.0 | accuracy: 0.10 | loss: 0.22
step: 583168 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 155.7
update:1140/2000, 耗时:0.01分/11.73分 | step: 583680 | performance: 1.2 | accuracy: 0.17 | loss: 0.39
update:1145/2000, 耗时:0.01分/11.78分 | step: 586240 | performance: 1.7 | accuracy: 0.14 | loss: 0.30
update:1150/2000, 耗时:0.01分/11.84分 | step: 588800 | performance: 0.6 | accuracy: 0.11 | loss: 0.22
update:1155/2000, 耗时:0.01分/11.89分 | step: 591360 | performance: 0.6 | accuracy: 0.12 | loss: 0.31
update:1160/2000, 耗时:0.01分/11.94分 | step: 593920 | performance: 0.3 | accuracy: 0.11 | loss: 0.22
update:1165/2000, 耗时:0.01分/11.99分 | step: 596480 | performance: 0.3 | accuracy: 0.11 | loss: 0.18
update:1170/2000, 耗时:0.01分/12.04分 | step: 599040 | performance: 0.2 | accuracy: 0.10 | loss: 0.17
step: 599552 | worker_7@n_step_63: average total_reward after train data exhaustion : 2.8 | max total_reward: 155.7
update:1175/2000, 耗时:0.01分/12.09分 | step: 601600 | performance: 1.1 | accuracy: 0.14 | loss: 0.18
step: 603642 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 155.7
step: 603647 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 155.7
step: 604157 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
update:1180/2000, 耗时:0.01分/12.14分 | step: 604160 | performance: 1.0 | accuracy: 0.12 | loss: 0.12
update:1185/2000, 耗时:0.01分/12.19分 | step: 606720 | performance: 1.4 | accuracy: 0.17 | loss: 0.27
update:1190/2000, 耗时:0.01分/12.24分 | step: 609280 | performance: 1.0 | accuracy: 0.12 | loss: 0.38
update:1195/2000, 耗时:0.01分/12.29分 | step: 611840 | performance: 0.4 | accuracy: 0.11 | loss: 0.31
update:1200/2000, 耗时:0.01分/12.34分 | step: 614400 | performance: 0.4 | accuracy: 0.11 | loss: 0.20
update:1205/2000, 耗时:0.01分/12.39分 | step: 616960 | performance: 0.2 | accuracy: 0.10 | loss: 0.12
step: 619002 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 155.7
step: 619003 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.7 | max total_reward: 155.7
update:1210/2000, 耗时:0.01分/12.45分 | step: 619520 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 621561 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.6 | max total_reward: 155.7
step: 621565 | worker_4@n_step_63: average total_reward after train data exhaustion : 2.7 | max total_reward: 155.7
update:1215/2000, 耗时:0.01分/12.50分 | step: 622080 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
update:1220/2000, 耗时:0.01分/12.55分 | step: 624640 | performance: 0.9 | accuracy: 0.17 | loss: 0.27
update:1225/2000, 耗时:0.01分/12.60分 | step: 627200 | performance: 1.0 | accuracy: 0.12 | loss: 0.22
step: 629243 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.0 | max total_reward: 155.7
update:1230/2000, 耗时:0.01分/12.65分 | step: 629760 | performance: 0.8 | accuracy: 0.11 | loss: 0.21
step: 630780 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 155.7
step: 631291 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 155.7
step: 631806 | worker_5@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 155.7
update:1235/2000, 耗时:0.01分/12.70分 | step: 632320 | performance: 0.9 | accuracy: 0.11 | loss: 0.22
update:1240/2000, 耗时:0.01分/12.75分 | step: 634880 | performance: 1.3 | accuracy: 0.11 | loss: 0.21
step: 636923 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 155.7
step: 637437 | worker_4@n_step_63: average total_reward after train data exhaustion : 3.4 | max total_reward: 155.7
update:1245/2000, 耗时:0.01分/12.80分 | step: 637440 | performance: 0.8 | accuracy: 0.10 | loss: 0.14
step: 637951 | worker_6@n_step_63: average total_reward after train data exhaustion : 3.5 | max total_reward: 155.7
update:1250/2000, 耗时:0.01分/12.85分 | step: 640000 | performance: 1.0 | accuracy: 0.12 | loss: 0.13
step: 640512 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 155.7
update:1255/2000, 耗时:0.01分/12.90分 | step: 642560 | performance: 1.2 | accuracy: 0.19 | loss: 0.40
update:1260/2000, 耗时:0.01分/12.95分 | step: 645120 | performance: 4.5 | accuracy: 0.18 | loss: 0.42
update:1265/2000, 耗时:0.01分/13.00分 | step: 647680 | performance: 2.2 | accuracy: 0.14 | loss: 0.26
update:1270/2000, 耗时:0.01分/13.05分 | step: 650240 | performance: 1.7 | accuracy: 0.12 | loss: 0.26
update:1275/2000, 耗时:0.01分/13.10分 | step: 652800 | performance: 1.3 | accuracy: 0.12 | loss: 0.18
step: 654842 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 155.7
update:1280/2000, 耗时:0.01分/13.15分 | step: 655360 | performance: 1.1 | accuracy: 0.11 | loss: 0.10
step: 657919 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 155.7
update:1285/2000, 耗时:0.01分/13.20分 | step: 657920 | performance: 1.0 | accuracy: 0.08 | loss: 0.07
step: 658427 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
step: 659456 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
step: 660475 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 155.7
update:1290/2000, 耗时:0.01分/13.25分 | step: 660480 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 660985 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 155.7
update:1295/2000, 耗时:0.01分/13.30分 | step: 663040 | performance: 0.9 | accuracy: 0.11 | loss: 0.43
update:1300/2000, 耗时:0.01分/13.35分 | step: 665600 | performance: 0.7 | accuracy: 0.14 | loss: 0.20
update:1305/2000, 耗时:0.01分/13.40分 | step: 668160 | performance: 0.8 | accuracy: 0.12 | loss: 0.22
update:1310/2000, 耗时:0.01分/13.45分 | step: 670720 | performance: 1.1 | accuracy: 0.12 | loss: 0.36
update:1315/2000, 耗时:0.01分/13.50分 | step: 673280 | performance: 1.5 | accuracy: 0.12 | loss: 0.24
step: 675839 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
update:1320/2000, 耗时:0.01分/13.55分 | step: 675840 | performance: 0.6 | accuracy: 0.11 | loss: 0.20
step: 676859 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 155.7
update:1325/2000, 耗时:0.01分/13.60分 | step: 678400 | performance: 0.3 | accuracy: 0.10 | loss: 0.17
step: 679419 | worker_2@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 155.7
update:1330/2000, 耗时:0.01分/13.65分 | step: 680960 | performance: 1.4 | accuracy: 0.15 | loss: 0.27
update:1335/2000, 耗时:0.01分/13.70分 | step: 683520 | performance: 2.2 | accuracy: 0.14 | loss: 0.38
update:1340/2000, 耗时:0.01分/13.75分 | step: 686080 | performance: 1.4 | accuracy: 0.10 | loss: 0.16
update:1345/2000, 耗时:0.01分/13.80分 | step: 688640 | performance: 0.9 | accuracy: 0.13 | loss: 0.26
update:1350/2000, 耗时:0.01分/13.85分 | step: 691200 | performance: 1.0 | accuracy: 0.20 | loss: 0.25
update:1355/2000, 耗时:0.01分/13.90分 | step: 693760 | performance: 1.0 | accuracy: 0.14 | loss: 0.30
step: 695807 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.9 | max total_reward: 155.7
update:1360/2000, 耗时:0.01分/13.95分 | step: 696320 | performance: 1.0 | accuracy: 0.11 | loss: 0.21
step: 697856 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 155.7
update:1365/2000, 耗时:0.01分/14.00分 | step: 698880 | performance: 1.3 | accuracy: 0.16 | loss: 0.22
update:1370/2000, 耗时:0.01分/14.05分 | step: 701440 | performance: 0.8 | accuracy: 0.13 | loss: 0.47
update:1375/2000, 耗时:0.01分/14.10分 | step: 704000 | performance: 0.2 | accuracy: 0.11 | loss: 0.27
update:1380/2000, 耗时:0.01分/14.15分 | step: 706560 | performance: 0.3 | accuracy: 0.11 | loss: 0.23
update:1385/2000, 耗时:0.01分/14.20分 | step: 709120 | performance: 0.3 | accuracy: 0.11 | loss: 0.20
update:1390/2000, 耗时:0.01分/14.25分 | step: 711680 | performance: 0.1 | accuracy: 0.10 | loss: 0.15
update:1395/2000, 耗时:0.01分/14.30分 | step: 714240 | performance: 3.6 | accuracy: 0.14 | loss: 0.22
update:1400/2000, 耗时:0.01分/14.35分 | step: 716800 | performance: 2.3 | accuracy: 0.12 | loss: 0.22
update:1405/2000, 耗时:0.01分/14.40分 | step: 719360 | performance: 1.5 | accuracy: 0.11 | loss: 0.19
update:1410/2000, 耗时:0.01分/14.45分 | step: 721920 | performance: 1.2 | accuracy: 0.11 | loss: 0.27
update:1415/2000, 耗时:0.01分/14.50分 | step: 724480 | performance: 1.1 | accuracy: 0.10 | loss: 0.23
update:1420/2000, 耗时:0.01分/14.55分 | step: 727040 | performance: 1.3 | accuracy: 0.10 | loss: 0.31
update:1425/2000, 耗时:0.01分/14.60分 | step: 729600 | performance: 1.3 | accuracy: 0.24 | loss: 0.28
update:1430/2000, 耗时:0.01分/14.65分 | step: 732160 | performance: 2.2 | accuracy: 0.14 | loss: 0.25
update:1435/2000, 耗时:0.01分/14.70分 | step: 734720 | performance: 1.0 | accuracy: 0.11 | loss: 0.18
step: 735228 | worker_3@n_step_63: average total_reward after train data exhaustion : 3.9 | max total_reward: 155.7
update:1440/2000, 耗时:0.01分/14.75分 | step: 737280 | performance: 1.0 | accuracy: 0.10 | loss: 0.18
update:1445/2000, 耗时:0.01分/14.80分 | step: 739840 | performance: 1.2 | accuracy: 0.11 | loss: 0.22
step: 741371 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
update:1450/2000, 耗时:0.01分/14.85分 | step: 742400 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 742911 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
step: 743929 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
step: 744447 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
update:1455/2000, 耗时:0.01分/14.90分 | step: 744960 | performance: 0.9 | accuracy: 0.12 | loss: 0.25
update:1460/2000, 耗时:0.01分/14.95分 | step: 747520 | performance: 0.4 | accuracy: 0.11 | loss: 0.37
update:1465/2000, 耗时:0.01分/15.00分 | step: 750080 | performance: 0.9 | accuracy: 0.12 | loss: 0.29
update:1470/2000, 耗时:0.01分/15.05分 | step: 752640 | performance: 0.9 | accuracy: 0.11 | loss: 0.20
update:1475/2000, 耗时:0.01分/15.10分 | step: 755200 | performance: 0.9 | accuracy: 0.11 | loss: 0.27
update:1480/2000, 耗时:0.01分/15.15分 | step: 757760 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 760319 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 155.7
update:1485/2000, 耗时:0.01分/15.20分 | step: 760320 | performance: 1.8 | accuracy: 0.12 | loss: 0.20
step: 761337 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.4 | max total_reward: 155.7
update:1490/2000, 耗时:0.01分/15.25分 | step: 762880 | performance: 1.6 | accuracy: 0.20 | loss: 0.39
update:1495/2000, 耗时:0.01分/15.30分 | step: 765440 | performance: 2.4 | accuracy: 0.17 | loss: 0.33
update:1500/2000, 耗时:0.01分/15.35分 | step: 768000 | performance: 0.4 | accuracy: 0.13 | loss: 0.31
update:1505/2000, 耗时:0.01分/15.40分 | step: 770560 | performance: 0.7 | accuracy: 0.13 | loss: 0.39
update:1510/2000, 耗时:0.01分/15.45分 | step: 773120 | performance: 0.5 | accuracy: 0.11 | loss: 0.11
step: 775166 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:1515/2000, 耗时:0.01分/15.50分 | step: 775680 | performance: 0.5 | accuracy: 0.11 | loss: 0.07
step: 776700 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
step: 778240 | worker_7@n_step_63: average total_reward after train data exhaustion : -0.4 | max total_reward: 155.7
update:1520/2000, 耗时:0.01分/15.55分 | step: 778240 | performance: 1.0 | accuracy: 0.00 | loss: 0.05
step: 779259 | worker_2@n_step_63: average total_reward after train data exhaustion : 2.6 | max total_reward: 155.7
update:1525/2000, 耗时:0.01分/15.60分 | step: 780800 | performance: 1.0 | accuracy: 0.00 | loss: 0.02
step: 781818 | worker_1@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
step: 781821 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
step: 782841 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
step: 782847 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
update:1530/2000, 耗时:0.01分/15.65分 | step: 783360 | performance: 1.0 | accuracy: 0.00 | loss: 0.04
step: 784892 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
update:1535/2000, 耗时:0.01分/15.71分 | step: 785920 | performance: 1.0 | accuracy: 0.00 | loss: 0.10
step: 786432 | worker_7@n_step_63: average total_reward after train data exhaustion : -0.1 | max total_reward: 155.7
step: 786939 | worker_2@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
step: 787964 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:1540/2000, 耗时:0.01分/15.76分 | step: 788480 | performance: 0.8 | accuracy: 0.00 | loss: 0.13
step: 788990 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
step: 788992 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
step: 791036 | worker_3@n_step_63: average total_reward after train data exhaustion : 0.0 | max total_reward: 155.7
step: 791040 | worker_7@n_step_63: average total_reward after train data exhaustion : -0.0 | max total_reward: 155.7
update:1545/2000, 耗时:0.01分/15.81分 | step: 791040 | performance: 1.0 | accuracy: 0.00 | loss: 0.20
update:1550/2000, 耗时:0.01分/15.86分 | step: 793600 | performance: 2.4 | accuracy: 0.15 | loss: 0.40
update:1555/2000, 耗时:0.01分/15.91分 | step: 796160 | performance: 0.9 | accuracy: 0.13 | loss: 0.30
update:1560/2000, 耗时:0.01分/15.96分 | step: 798720 | performance: 0.8 | accuracy: 0.11 | loss: 0.11
step: 800250 | worker_1@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 155.7
step: 800255 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.9 | max total_reward: 155.7
step: 800761 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.0 | max total_reward: 155.7
update:1565/2000, 耗时:0.01分/16.02分 | step: 801280 | performance: 1.0 | accuracy: 0.00 | loss: 0.07
step: 803325 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
update:1570/2000, 耗时:0.01分/16.07分 | step: 803840 | performance: 1.0 | accuracy: 0.00 | loss: 0.09
update:1575/2000, 耗时:0.01分/16.12分 | step: 806400 | performance: 1.0 | accuracy: 0.09 | loss: 0.25
update:1580/2000, 耗时:0.01分/16.17分 | step: 808960 | performance: 1.5 | accuracy: 0.11 | loss: 0.40
update:1585/2000, 耗时:0.01分/16.22分 | step: 811520 | performance: 0.5 | accuracy: 0.10 | loss: 0.29
update:1590/2000, 耗时:0.01分/16.27分 | step: 814080 | performance: 1.0 | accuracy: 0.11 | loss: 0.14
update:1595/2000, 耗时:0.01分/16.32分 | step: 816640 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
step: 817149 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 155.7
update:1600/2000, 耗时:0.01分/16.37分 | step: 819200 | performance: 1.0 | accuracy: 0.00 | loss: 0.22
update:1605/2000, 耗时:0.01分/16.42分 | step: 821760 | performance: 2.9 | accuracy: 0.16 | loss: 0.35
update:1610/2000, 耗时:0.01分/16.47分 | step: 824320 | performance: 1.7 | accuracy: 0.12 | loss: 0.36
update:1615/2000, 耗时:0.01分/16.52分 | step: 826880 | performance: 1.5 | accuracy: 0.12 | loss: 0.40
update:1620/2000, 耗时:0.01分/16.57分 | step: 829440 | performance: 1.5 | accuracy: 0.11 | loss: 0.40
update:1625/2000, 耗时:0.01分/16.62分 | step: 832000 | performance: 1.1 | accuracy: 0.11 | loss: 0.22
update:1630/2000, 耗时:0.01分/16.67分 | step: 834560 | performance: 1.0 | accuracy: 0.10 | loss: 0.12
update:1635/2000, 耗时:0.01分/16.73分 | step: 837120 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
update:1640/2000, 耗时:0.01分/16.78分 | step: 839680 | performance: 1.3 | accuracy: 0.14 | loss: 0.23
update:1645/2000, 耗时:0.01分/16.83分 | step: 842240 | performance: 2.1 | accuracy: 0.12 | loss: 0.24
update:1650/2000, 耗时:0.01分/16.88分 | step: 844800 | performance: 1.1 | accuracy: 0.11 | loss: 0.35
step: 845306 | worker_1@n_step_63: average total_reward after train data exhaustion : 4.4 | max total_reward: 155.7
update:1655/2000, 耗时:0.01分/16.93分 | step: 847360 | performance: 1.1 | accuracy: 0.12 | loss: 0.39
update:1660/2000, 耗时:0.01分/16.99分 | step: 849920 | performance: 0.8 | accuracy: 0.12 | loss: 0.32
update:1665/2000, 耗时:0.01分/17.04分 | step: 852480 | performance: 0.6 | accuracy: 0.12 | loss: 0.28
update:1670/2000, 耗时:0.01分/17.09分 | step: 855040 | performance: 0.4 | accuracy: 0.11 | loss: 0.20
update:1675/2000, 耗时:0.01分/17.14分 | step: 857600 | performance: 0.5 | accuracy: 0.11 | loss: 0.25
update:1680/2000, 耗时:0.01分/17.19分 | step: 860160 | performance: 1.2 | accuracy: 0.11 | loss: 0.21
update:1685/2000, 耗时:0.01分/17.24分 | step: 862720 | performance: 0.7 | accuracy: 0.10 | loss: 0.26
update:1690/2000, 耗时:0.01分/17.29分 | step: 865280 | performance: 1.6 | accuracy: 0.16 | loss: 0.26
step: 866299 | worker_2@n_step_63: average total_reward after train data exhaustion : 13.1 | max total_reward: 155.7
Saving PPO weights in both H5 format and checkpoint @ update:1692 
update:1695/2000, 耗时:0.01分/17.34分 | step: 867840 | performance: 1.9 | accuracy: 0.15 | loss: 0.33
Saving PPO weights in both H5 format and checkpoint @ update:1698 
Saving PPO weights in both H5 format and checkpoint @ update:1699 
update:1700/2000, 耗时:0.01分/17.40分 | step: 870400 | performance: 0.9 | accuracy: 0.14 | loss: 0.25
update:1705/2000, 耗时:0.01分/17.45分 | step: 872960 | performance: 1.0 | accuracy: 0.13 | loss: 0.23
update:1710/2000, 耗时:0.01分/17.50分 | step: 875520 | performance: 1.1 | accuracy: 0.12 | loss: 0.35
update:1715/2000, 耗时:0.01分/17.55分 | step: 878080 | performance: 0.8 | accuracy: 0.11 | loss: 0.25
update:1720/2000, 耗时:0.01分/17.60分 | step: 880640 | performance: 1.5 | accuracy: 0.10 | loss: 0.20
update:1725/2000, 耗时:0.01分/17.65分 | step: 883200 | performance: 1.1 | accuracy: 0.12 | loss: 0.12
update:1730/2000, 耗时:0.01分/17.70分 | step: 885760 | performance: 1.0 | accuracy: 0.00 | loss: 0.14
step: 886272 | worker_7@n_step_63: average total_reward after train data exhaustion : 1.3 | max total_reward: 155.7
step: 887806 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 155.7
update:1735/2000, 耗时:0.01分/17.75分 | step: 888320 | performance: 1.2 | accuracy: 0.19 | loss: 0.31
step: 890365 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:1740/2000, 耗时:0.01分/17.80分 | step: 890880 | performance: 1.8 | accuracy: 0.13 | loss: 0.25
update:1745/2000, 耗时:0.01分/17.85分 | step: 893440 | performance: 1.4 | accuracy: 0.11 | loss: 0.29
update:1750/2000, 耗时:0.01分/17.90分 | step: 896000 | performance: 1.9 | accuracy: 0.12 | loss: 0.23
step: 898045 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.4 | max total_reward: 155.7
update:1755/2000, 耗时:0.01分/17.95分 | step: 898560 | performance: 1.5 | accuracy: 0.11 | loss: 0.15
step: 899071 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 155.7
update:1760/2000, 耗时:0.01分/18.00分 | step: 901120 | performance: 1.5 | accuracy: 0.10 | loss: 0.11
step: 903167 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.1 | max total_reward: 155.7
update:1765/2000, 耗时:0.01分/18.06分 | step: 903680 | performance: 1.0 | accuracy: 0.00 | loss: 0.18
step: 904701 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
step: 904704 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
update:1770/2000, 耗时:0.01分/18.11分 | step: 906240 | performance: 2.1 | accuracy: 0.16 | loss: 0.31
update:1775/2000, 耗时:0.01分/18.16分 | step: 908800 | performance: 1.6 | accuracy: 0.13 | loss: 0.33
update:1780/2000, 耗时:0.01分/18.21分 | step: 911360 | performance: 1.1 | accuracy: 0.11 | loss: 0.24
update:1785/2000, 耗时:0.01分/18.26分 | step: 913920 | performance: 1.0 | accuracy: 0.33 | loss: 0.10
update:1790/2000, 耗时:0.01分/18.31分 | step: 916480 | performance: 1.0 | accuracy: 0.33 | loss: 0.22
step: 919038 | worker_5@n_step_63: average total_reward after train data exhaustion : 2.0 | max total_reward: 155.7
update:1795/2000, 耗时:0.01分/18.36分 | step: 919040 | performance: 2.3 | accuracy: 0.15 | loss: 0.31
update:1800/2000, 耗时:0.01分/18.41分 | step: 921600 | performance: 2.3 | accuracy: 0.12 | loss: 0.25
update:1805/2000, 耗时:0.01分/18.46分 | step: 924160 | performance: 4.3 | accuracy: 0.12 | loss: 0.29
update:1810/2000, 耗时:0.01分/18.51分 | step: 926720 | performance: 7.1 | accuracy: 0.12 | loss: 0.24
update:1815/2000, 耗时:0.01分/18.56分 | step: 929280 | performance: 7.9 | accuracy: 0.12 | loss: 0.21
update:1820/2000, 耗时:0.01分/18.61分 | step: 931840 | performance: 6.9 | accuracy: 0.11 | loss: 0.23
step: 933881 | worker_0@n_step_63: average total_reward after train data exhaustion : 2.7 | max total_reward: 155.7
update:1825/2000, 耗时:0.01分/18.66分 | step: 934400 | performance: 4.3 | accuracy: 0.11 | loss: 0.16
update:1830/2000, 耗时:0.01分/18.71分 | step: 936960 | performance: 3.6 | accuracy: 0.11 | loss: 0.16
update:1835/2000, 耗时:0.01分/18.76分 | step: 939520 | performance: 6.1 | accuracy: 0.11 | loss: 0.32
step: 940543 | worker_6@n_step_63: average total_reward after train data exhaustion : 5.8 | max total_reward: 155.7
update:1840/2000, 耗时:0.01分/18.81分 | step: 942080 | performance: 0.9 | accuracy: 0.08 | loss: 0.40
update:1845/2000, 耗时:0.01分/18.86分 | step: 944640 | performance: 1.0 | accuracy: 0.00 | loss: 0.16
update:1850/2000, 耗时:0.01分/18.91分 | step: 947200 | performance: 1.1 | accuracy: 0.13 | loss: 0.24
update:1855/2000, 耗时:0.01分/18.96分 | step: 949760 | performance: 1.2 | accuracy: 0.22 | loss: 0.14
step: 950779 | worker_2@n_step_63: average total_reward after train data exhaustion : 2.3 | max total_reward: 155.7
step: 950783 | worker_6@n_step_63: average total_reward after train data exhaustion : 2.3 | max total_reward: 155.7
update:1860/2000, 耗时:0.01分/19.01分 | step: 952320 | performance: 2.7 | accuracy: 0.14 | loss: 0.24
update:1865/2000, 耗时:0.01分/19.06分 | step: 954880 | performance: 0.9 | accuracy: 0.12 | loss: 0.26
update:1870/2000, 耗时:0.01分/19.11分 | step: 957440 | performance: 1.3 | accuracy: 0.11 | loss: 0.29
update:1875/2000, 耗时:0.01分/19.16分 | step: 960000 | performance: 1.4 | accuracy: 0.11 | loss: 0.20
update:1880/2000, 耗时:0.01分/19.21分 | step: 962560 | performance: 1.7 | accuracy: 0.11 | loss: 0.13
update:1885/2000, 耗时:0.01分/19.26分 | step: 965120 | performance: 1.1 | accuracy: 0.12 | loss: 0.20
step: 965631 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.6 | max total_reward: 155.7
step: 967679 | worker_6@n_step_63: average total_reward after train data exhaustion : 2.2 | max total_reward: 155.7
update:1890/2000, 耗时:0.01分/19.31分 | step: 967680 | performance: 1.0 | accuracy: 0.00 | loss: 0.11
step: 969726 | worker_5@n_step_63: average total_reward after train data exhaustion : 0.5 | max total_reward: 155.7
update:1895/2000, 耗时:0.01分/19.36分 | step: 970240 | performance: 1.0 | accuracy: 0.00 | loss: 0.17
step: 970745 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.6 | max total_reward: 155.7
step: 971769 | worker_0@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
step: 972288 | worker_7@n_step_63: average total_reward after train data exhaustion : 0.2 | max total_reward: 155.7
update:1900/2000, 耗时:0.01分/19.41分 | step: 972800 | performance: 1.2 | accuracy: 0.17 | loss: 0.33
update:1905/2000, 耗时:0.01分/19.46分 | step: 975360 | performance: 1.7 | accuracy: 0.12 | loss: 0.39
update:1910/2000, 耗时:0.01分/19.51分 | step: 977920 | performance: 1.2 | accuracy: 0.11 | loss: 0.29
update:1915/2000, 耗时:0.01分/19.56分 | step: 980480 | performance: 1.8 | accuracy: 0.11 | loss: 0.20
update:1920/2000, 耗时:0.01分/19.61分 | step: 983040 | performance: 2.1 | accuracy: 0.10 | loss: 0.15
update:1925/2000, 耗时:0.01分/19.66分 | step: 985600 | performance: 1.8 | accuracy: 0.14 | loss: 0.14
step: 987647 | worker_6@n_step_63: average total_reward after train data exhaustion : 0.7 | max total_reward: 155.7
update:1930/2000, 耗时:0.01分/19.71分 | step: 988160 | performance: 1.0 | accuracy: 0.33 | loss: 0.27
step: 990205 | worker_4@n_step_63: average total_reward after train data exhaustion : 0.3 | max total_reward: 155.7
update:1935/2000, 耗时:0.01分/19.76分 | step: 990720 | performance: 1.3 | accuracy: 0.14 | loss: 0.31
update:1940/2000, 耗时:0.01分/19.81分 | step: 993280 | performance: 2.3 | accuracy: 0.14 | loss: 0.22
update:1945/2000, 耗时:0.01分/19.86分 | step: 995840 | performance: 1.5 | accuracy: 0.11 | loss: 0.13
step: 997887 | worker_6@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 155.7
step: 998393 | worker_0@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 155.7
update:1950/2000, 耗时:0.01分/19.91分 | step: 998400 | performance: 2.2 | accuracy: 0.11 | loss: 0.16
update:1955/2000, 耗时:0.01分/19.96分 | step: 1000960 | performance: 2.0 | accuracy: 0.11 | loss: 0.23
step: 1001468 | worker_3@n_step_63: average total_reward after train data exhaustion : 1.2 | max total_reward: 155.7
update:1960/2000, 耗时:0.01分/20.01分 | step: 1003520 | performance: 1.1 | accuracy: 0.10 | loss: 0.25
step: 1006078 | worker_5@n_step_63: average total_reward after train data exhaustion : 3.8 | max total_reward: 155.7
update:1965/2000, 耗时:0.01分/20.06分 | step: 1006080 | performance: 1.1 | accuracy: 0.11 | loss: 0.21
step: 1007104 | worker_7@n_step_63: average total_reward after train data exhaustion : 3.6 | max total_reward: 155.7
update:1970/2000, 耗时:0.01分/20.11分 | step: 1008640 | performance: 2.8 | accuracy: 0.16 | loss: 0.32
update:1975/2000, 耗时:0.01分/20.16分 | step: 1011200 | performance: 1.4 | accuracy: 0.12 | loss: 0.43
update:1980/2000, 耗时:0.01分/20.21分 | step: 1013760 | performance: 2.2 | accuracy: 0.11 | loss: 0.22
update:1985/2000, 耗时:0.01分/20.26分 | step: 1016320 | performance: 4.5 | accuracy: 0.11 | loss: 0.23
step: 1016829 | worker_4@n_step_63: average total_reward after train data exhaustion : 1.1 | max total_reward: 155.7
update:1990/2000, 耗时:0.01分/20.31分 | step: 1018880 | performance: 3.1 | accuracy: 0.11 | loss: 0.16
update:1995/2000, 耗时:0.01分/20.36分 | step: 1021440 | performance: 2.6 | accuracy: 0.10 | loss: 0.13
step: 1022460 | worker_3@n_step_63: average total_reward after train data exhaustion : 2.2 | max total_reward: 155.7
step: 1023487 | worker_6@n_step_63: average total_reward after train data exhaustion : 4.1 | max total_reward: 155.7
update:2000/2000, 耗时:0.01分/20.41分 | step: 1024000 | performance: 1.0 | accuracy: 0.00 | loss: 0.08
----------------------------------------finished----------------------------------------
==================================================
2023-01-02T00:00:00 | *** START BACKTEST ***
2023-01-02T00:00:00 | current balance = 1000.00
==================================================
  0%|          | 0/408 [00:00<?, ?it/s]100%|| 408/408 [00:00<00:00, 101952.70it/s]
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 984.67
2023-07-24T12:00:00 | net performance [%] = -1.5330
2023-07-24T12:00:00 | number of trades [#] = 10
==================================================
Trial 59 Complete [00h 20m 52s]
net_wealth: 984.6704388847485

Best net_wealth So Far: 1824.8039564105297
Total elapsed time: 08h 14m 52s

Search: Running Trial #60

Value             |Best Value So Far |Hyperparameter
3                 |6                 |horizon
365               |365               |lookback
True              |True              |MarketFactor
10                |10                |lags
0.92              |0.98              |gamma
32                |16                |batch_size
1                 |7                 |n_step
0.94              |0.94              |gae_lambda
2                 |0.5               |gradient_clip_norm
3                 |3                 |epochs
0.0005            |0.001             |actor_lr
0.001             |0.001             |critic_lr

<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 4335 entries, 2017-08-17 00:00:00+00:00 to 2023-07-24 12:00:00+00:00
Data columns (total 9 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   open        4335 non-null   float64
 1   high        4335 non-null   float64
 2   low         4335 non-null   float64
 3   close       4335 non-null   float64
 4   volume      4335 non-null   float64
 5   amount      4335 non-null   float64
 6   num_trades  4335 non-null   int64  
 7   bid_volume  4335 non-null   float64
 8   bid_amount  4335 non-null   float64
dtypes: float64(8), int64(1)
memory usage: 338.7 KB
从json中读出Data.info:None
        log_return  Roll_price_sma  ...  horizon_price         close
count  4301.000000     4301.000000  ...    4298.000000   4301.000000
mean      0.000435    20113.607657  ...   20180.392273  20169.373185
std       0.027833    16040.642334  ...   16078.781641  16078.584047
min      -0.268357     3359.310486  ...    2919.000000   2919.000000
25%      -0.009750     7678.996509  ...    7741.750122   7730.930176
50%       0.000642    11571.842969  ...   11754.949707  11751.469727
75%       0.011590    29894.706152  ...   30015.383301  30012.630859
max       0.237092    64595.437500  ...   67594.976562  67594.976562

[8 rows x 18 columns]
                           log_return  ...        close
2017-09-03 08:00:00+08:00    0.003094  ...  4486.000000
2017-09-03 20:00:00+08:00    0.005132  ...  4509.080078

[2 rows x 18 columns]
                           log_return  ...         close
2023-07-24 08:00:00+08:00   -0.027422  ...  29269.990234
2023-07-24 20:00:00+08:00   -0.005706  ...  29103.449219

[2 rows x 18 columns]
2023-07-28 06:18:16.207170: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFl2023-07-28 06:18:16.207220: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library 22(oneD0023-2NN3o-w) bi07-28 06:182 t023:16-07-28 06.207294: I tensorflow/core/platform/cpu_feature_guard.cc:142] This Tensor2o023-07-28 06n:18:16F.ary isl 207351: I toens07w bina-28oo 06:18:16.p207291: ry use tis oprthie ftmoiilmzlieozdw:i2 wie18:16.207325: I t2flow/core/pl0ng CPU i2atfo3th oneAP-n07Ids-28  wtr  I06:18:16Dui et.teep Neh2nue onn02sorf3esA-0olowrPI 0rram7/cDefe7c-2t8io/ln sN cpp Nou_rloew/coreueifeane/p/tplatflo79 au rpte06:r3tre1_work: I  amrfguaLfororrml /m/cpu_fedtanNetcp.ensowaci8c:16.tubror20urk Laci7702brry : I te_a:(orneeDr_yfeguard.cc (14ae:N1N) 2] -Th42ifonsnscturritieel oTw/ccaolr eeoDNn]orfl p/pla_oTeratgwhiNstfuard.c)c:1so  rt/tTm/o core/platform/cpu4eocouse2i]rp_ ons fTeaturFlotue_:nsorFlow bwh_fg  h usuii nbeeAasrd.cae fol Vture_clX Aary o VX2
the TinaTiseg:ry is  nuardosorFwoinp1l4o2fo]t iw oThis gb inm.ptimillowing zTC aizedcensCPUenorry isabl instr FoloPU inecp:tustruce c wtions iw1imizdi twi4ted wtihi  th on2obtoneA] This Tenihns nsnahP in perfpeAPI DI eee onorForrmancemDe loy-rpeA Pin  cIe iDfotNepormritischance aNleer oewureupe pbi opna tral Net-icmali rwoopNrrz edeik LNeyutical   riertwieal Networaowithbrapork oneAPIerats optimionsktionrati: Liized   Aor wsL:i  AVX inth ones, VX braryDAVX2
 y (oneDNN)AVX2
Tb AT(oo neenoato u PIrebe  Deeneapb lrbsepe utNeuraahem in other operild Tensorl NetwDoeFl oNeurNwrk a tle rLyh N)( too ne th follusoewieDwtmi oinal Netth tibwing CPU instrnro ehe NaNo uctirt)t harhsopnpsr ointyokp use there , e follo rebuil diate comwpinr folLibra g CPU (Tlperformaneoirylocnwiineso ng CDeNr r(e-crPFnofi U insnloloNtructpe)eDagsw wiNions.raNs in pt)iotr totnictahl   uo s,cpterause
ittieornst thohe app:fo ens in puseo rer  t fropebuild Tof rriatllowmancAiheee coVng nsorFloe-critical opXC PU inAVsmpileerations: Xtructori2w  o
rmance-with the appropriate compiler flags.
AVX AVX2
To enable them T flags.
in other operations, rebuild TensorFlow with the appropriate  following CPU instructions in performance-critical operations:  AVX AVX2
To enable tcocromp enhns in performance-critical operations:  iabltem in other operations,ical operationAsV ieler:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appro flags.
X AVX2
Torebuild TensorFlow with the appropriate compiler flags.
 them in other operations, rebuild TensorFlow with the appropriate compiler flags.
 enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
priate compiler flags.
2023-07-28 06:18:16.826447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 06:18:16.840753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 06:18:16.851507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 06:18:16.860184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 06:18:16.869499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 06:18:16.886541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 06:18:16.887687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
2023-07-28 06:18:16.888318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5454 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6
update:  5/2000, 耗时:0.00分/0.02分 | step:    40 | performance: 0.9 | accuracy: 0.00 | loss: 0.37
update: 10/2000, 耗时:0.00分/0.03分 | step:    80 | performance: 1.2 | accuracy: 0.30 | loss: 0.89
update: 15/2000, 耗时:0.00分/0.04分 | step:   120 | performance: 1.3 | accuracy: 0.27 | loss: 0.56
update: 20/2000, 耗时:0.00分/0.04分 | step:   160 | performance: 1.1 | accuracy: 0.25 | loss: 0.41
update: 25/2000, 耗时:0.00分/0.05分 | step:   200 | performance: 1.2 | accuracy: 0.32 | loss: 1.43
update: 30/2000, 耗时:0.00分/0.06分 | step:   240 | performance: 1.2 | accuracy: 0.30 | loss: 0.44
update: 35/2000, 耗时:0.00分/0.06分 | step:   280 | performance: 1.0 | accuracy: 0.26 | loss: 0.13
update: 40/2000, 耗时:0.00分/0.07分 | step:   320 | performance: 1.0 | accuracy: 0.23 | loss: 0.41
update: 45/2000, 耗时:0.00分/0.07分 | step:   360 | performance: 0.9 | accuracy: 0.22 | loss: 0.94
update: 50/2000, 耗时:0.00分/0.08分 | step:   400 | performance: 0.8 | accuracy: 0.22 | loss: 0.32
update: 55/2000, 耗时:0.00分/0.09分 | step:   440 | performance: 0.9 | accuracy: 0.27 | loss: 0.07
update: 60/2000, 耗时:0.00分/0.09分 | step:   480 | performance: 0.9 | accuracy: 0.25 | loss: 0.05
update: 65/2000, 耗时:0.00分/0.10分 | step:   520 | performance: 0.9 | accuracy: 0.23 | loss: 0.32
update: 70/2000, 耗时:0.00分/0.10分 | step:   560 | performance: 0.9 | accuracy: 0.21 | loss: -0.01
update: 75/2000, 耗时:0.00分/0.11分 | step:   600 | performance: 0.9 | accuracy: 0.23 | loss: 0.35
update: 80/2000, 耗时:0.00分/0.12分 | step:   640 | performance: 0.9 | accuracy: 0.23 | loss: 0.73
update: 85/2000, 耗时:0.00分/0.12分 | step:   680 | performance: 1.0 | accuracy: 0.25 | loss: 0.08
update: 90/2000, 耗时:0.00分/0.13分 | step:   720 | performance: 1.1 | accuracy: 0.28 | loss: 0.51
update: 95/2000, 耗时:0.00分/0.14分 | step:   760 | performance: 1.1 | accuracy: 0.29 | loss: 0.67
update:100/2000, 耗时:0.00分/0.14分 | step:   800 | performance: 1.2 | accuracy: 0.32 | loss: 0.31
update:105/2000, 耗时:0.00分/0.15分 | step:   840 | performance: 1.1 | accuracy: 0.32 | loss: 0.46
update:110/2000, 耗时:0.00分/0.16分 | step:   880 | performance: 1.2 | accuracy: 0.34 | loss: 0.71
update:115/2000, 耗时:0.00分/0.16分 | step:   920 | performance: 1.3 | accuracy: 0.36 | loss: 0.47
update:120/2000, 耗时:0.00分/0.17分 | step:   960 | performance: 1.1 | accuracy: 0.34 | loss: 0.55
update:125/2000, 耗时:0.00分/0.18分 | step:  1000 | performance: 1.0 | accuracy: 0.34 | loss: 0.09
update:130/2000, 耗时:0.00分/0.18分 | step:  1040 | performance: 1.0 | accuracy: 0.32 | loss: -0.06
update:135/2000, 耗时:0.00分/0.19分 | step:  1080 | performance: 1.0 | accuracy: 0.31 | loss: 0.70
update:140/2000, 耗时:0.00分/0.20分 | step:  1120 | performance: 1.0 | accuracy: 0.31 | loss: 0.22
update:145/2000, 耗时:0.00分/0.21分 | step:  1160 | performance: 1.0 | accuracy: 0.31 | loss: 0.35
update:150/2000, 耗时:0.00分/0.21分 | step:  1200 | performance: 1.0 | accuracy: 0.31 | loss: 0.29
update:155/2000, 耗时:0.00分/0.22分 | step:  1240 | performance: 1.0 | accuracy: 0.30 | loss: 0.03
update:160/2000, 耗时:0.00分/0.23分 | step:  1280 | performance: 1.0 | accuracy: 0.29 | loss: 0.26
update:165/2000, 耗时:0.00分/0.23分 | step:  1320 | performance: 1.0 | accuracy: 0.28 | loss: 0.18
update:170/2000, 耗时:0.00分/0.24分 | step:  1360 | performance: 0.9 | accuracy: 0.28 | loss: 0.04
update:175/2000, 耗时:0.00分/0.25分 | step:  1400 | performance: 0.9 | accuracy: 0.27 | loss: 0.01
update:180/2000, 耗时:0.00分/0.26分 | step:  1440 | performance: 0.9 | accuracy: 0.26 | loss: 0.03
update:185/2000, 耗时:0.00分/0.26分 | step:  1480 | performance: 0.9 | accuracy: 0.26 | loss: 0.15
update:190/2000, 耗时:0.00分/0.27分 | step:  1520 | performance: 1.0 | accuracy: 0.26 | loss: 1.06
update:195/2000, 耗时:0.00分/0.28分 | step:  1560 | performance: 1.1 | accuracy: 0.27 | loss: 0.22
update:200/2000, 耗时:0.00分/0.29分 | step:  1600 | performance: 1.1 | accuracy: 0.28 | loss: 0.00
update:205/2000, 耗时:0.00分/0.29分 | step:  1640 | performance: 1.0 | accuracy: 0.27 | loss: 0.10
update:210/2000, 耗时:0.00分/0.30分 | step:  1680 | performance: 1.0 | accuracy: 0.27 | loss: 0.05
update:215/2000, 耗时:0.00分/0.31分 | step:  1720 | performance: 1.0 | accuracy: 0.27 | loss: 0.00
update:220/2000, 耗时:0.00分/0.31分 | step:  1760 | performance: 1.0 | accuracy: 0.27 | loss: 0.67
update:225/2000, 耗时:0.00分/0.32分 | step:  1800 | performance: 1.0 | accuracy: 0.27 | loss: 0.08
update:230/2000, 耗时:0.00分/0.33分 | step:  1840 | performance: 1.0 | accuracy: 0.26 | loss: 0.02
update:235/2000, 耗时:0.00分/0.34分 | step:  1880 | performance: 1.0 | accuracy: 0.26 | loss: 0.32
update:240/2000, 耗时:0.00分/0.34分 | step:  1920 | performance: 1.0 | accuracy: 0.26 | loss: 0.03
update:245/2000, 耗时:0.00分/0.35分 | step:  1960 | performance: 0.9 | accuracy: 0.25 | loss: 0.06
update:250/2000, 耗时:0.00分/0.36分 | step:  2000 | performance: 0.9 | accuracy: 0.25 | loss: -0.00
update:255/2000, 耗时:0.00分/0.37分 | step:  2040 | performance: 0.9 | accuracy: 0.25 | loss: 0.01
update:260/2000, 耗时:0.00分/0.37分 | step:  2080 | performance: 0.9 | accuracy: 0.24 | loss: -0.00
update:265/2000, 耗时:0.00分/0.38分 | step:  2120 | performance: 0.9 | accuracy: 0.24 | loss: 0.16
update:270/2000, 耗时:0.00分/0.39分 | step:  2160 | performance: 0.9 | accuracy: 0.24 | loss: -0.00
update:275/2000, 耗时:0.00分/0.39分 | step:  2200 | performance: 1.0 | accuracy: 0.24 | loss: -0.01
update:280/2000, 耗时:0.00分/0.40分 | step:  2240 | performance: 1.0 | accuracy: 0.25 | loss: 0.39
update:285/2000, 耗时:0.00分/0.41分 | step:  2280 | performance: 1.0 | accuracy: 0.26 | loss: -0.02
update:290/2000, 耗时:0.00分/0.42分 | step:  2320 | performance: 0.9 | accuracy: 0.25 | loss: 0.57
update:295/2000, 耗时:0.00分/0.42分 | step:  2360 | performance: 0.9 | accuracy: 0.25 | loss: 0.17
update:300/2000, 耗时:0.00分/0.43分 | step:  2400 | performance: 0.9 | accuracy: 0.24 | loss: 0.00
update:305/2000, 耗时:0.00分/0.44分 | step:  2440 | performance: 0.9 | accuracy: 0.24 | loss: 0.01
update:310/2000, 耗时:0.00分/0.45分 | step:  2480 | performance: 0.9 | accuracy: 0.24 | loss: 0.04
update:315/2000, 耗时:0.00分/0.45分 | step:  2520 | performance: 0.9 | accuracy: 0.23 | loss: 0.00
update:320/2000, 耗时:0.00分/0.46分 | step:  2560 | performance: 0.9 | accuracy: 0.23 | loss: 0.07
update:325/2000, 耗时:0.00分/0.47分 | step:  2600 | performance: 1.0 | accuracy: 0.23 | loss: 0.01
update:330/2000, 耗时:0.00分/0.47分 | step:  2640 | performance: 1.0 | accuracy: 0.23 | loss: -0.00
update:335/2000, 耗时:0.00分/0.48分 | step:  2680 | performance: 0.9 | accuracy: 0.22 | loss: 0.96
update:340/2000, 耗时:0.00分/0.49分 | step:  2720 | performance: 0.9 | accuracy: 0.22 | loss: 0.01
update:345/2000, 耗时:0.00分/0.49分 | step:  2760 | performance: 0.9 | accuracy: 0.22 | loss: 0.67
update:350/2000, 耗时:0.00分/0.50分 | step:  2800 | performance: 0.9 | accuracy: 0.22 | loss: 0.03
update:355/2000, 耗时:0.00分/0.51分 | step:  2840 | performance: 1.0 | accuracy: 0.23 | loss: 0.10
update:360/2000, 耗时:0.00分/0.52分 | step:  2880 | performance: 0.9 | accuracy: 0.22 | loss: -0.00
update:365/2000, 耗时:0.00分/0.52分 | step:  2920 | performance: 1.0 | accuracy: 0.23 | loss: 0.05
update:370/2000, 耗时:0.00分/0.53分 | step:  2960 | performance: 1.0 | accuracy: 0.23 | loss: 0.00
update:375/2000, 耗时:0.00分/0.54分 | step:  3000 | performance: 1.0 | accuracy: 0.22 | loss: 0.00
update:380/2000, 耗时:0.00分/0.54分 | step:  3040 | performance: 1.0 | accuracy: 0.22 | loss: 0.06
update:385/2000, 耗时:0.00分/0.55分 | step:  3080 | performance: 1.0 | accuracy: 0.22 | loss: 0.00
update:390/2000, 耗时:0.00分/0.56分 | step:  3120 | performance: 1.0 | accuracy: 0.22 | loss: 0.01
update:395/2000, 耗时:0.00分/0.57分 | step:  3160 | performance: 1.1 | accuracy: 0.22 | loss: 0.19
update:400/2000, 耗时:0.00分/0.57分 | step:  3200 | performance: 1.1 | accuracy: 0.22 | loss: 0.04
update:405/2000, 耗时:0.00分/0.58分 | step:  3240 | performance: 1.1 | accuracy: 0.22 | loss: -0.00
update:410/2000, 耗时:0.00分/0.59分 | step:  3280 | performance: 1.1 | accuracy: 0.22 | loss: 0.26
update:415/2000, 耗时:0.00分/0.59分 | step:  3320 | performance: 1.1 | accuracy: 0.21 | loss: 0.00
update:420/2000, 耗时:0.00分/0.60分 | step:  3360 | performance: 1.1 | accuracy: 0.21 | loss: 0.03
update:425/2000, 耗时:0.00分/0.61分 | step:  3400 | performance: 1.1 | accuracy: 0.21 | loss: 0.00
update:430/2000, 耗时:0.00分/0.62分 | step:  3440 | performance: 1.0 | accuracy: 0.21 | loss: 0.24
update:435/2000, 耗时:0.00分/0.62分 | step:  3480 | performance: 1.0 | accuracy: 0.21 | loss: 0.43
update:440/2000, 耗时:0.00分/0.63分 | step:  3520 | performance: 0.9 | accuracy: 0.21 | loss: 0.01
update:445/2000, 耗时:0.00分/0.64分 | step:  3560 | performance: 1.0 | accuracy: 0.21 | loss: 0.06
update:450/2000, 耗时:0.00分/0.64分 | step:  3600 | performance: 0.9 | accuracy: 0.21 | loss: 0.37
update:455/2000, 耗时:0.00分/0.65分 | step:  3640 | performance: 0.9 | accuracy: 0.21 | loss: 0.00
update:460/2000, 耗时:0.00分/0.66分 | step:  3680 | performance: 0.9 | accuracy: 0.21 | loss: -0.00
update:465/2000, 耗时:0.00分/0.67分 | step:  3720 | performance: 0.9 | accuracy: 0.21 | loss: -0.00
update:470/2000, 耗时:0.00分/0.67分 | step:  3760 | performance: 0.9 | accuracy: 0.20 | loss: 0.01
update:475/2000, 耗时:0.00分/0.68分 | step:  3800 | performance: 1.0 | accuracy: 0.21 | loss: 0.32
update:480/2000, 耗时:0.00分/0.69分 | step:  3840 | performance: 1.0 | accuracy: 0.20 | loss: 0.01
update:485/2000, 耗时:0.00分/0.70分 | step:  3880 | performance: 1.0 | accuracy: 0.21 | loss: 0.27
update:490/2000, 耗时:0.00分/0.70分 | step:  3920 | performance: 0.9 | accuracy: 0.21 | loss: 0.32
update:495/2000, 耗时:0.00分/0.71分 | step:  3960 | performance: 0.9 | accuracy: 0.21 | loss: 0.18
update:500/2000, 耗时:0.00分/0.72分 | step:  4000 | performance: 0.9 | accuracy: 0.21 | loss: 0.46
update:505/2000, 耗时:0.00分/0.73分 | step:  4040 | performance: 1.0 | accuracy: 0.21 | loss: 0.34
update:510/2000, 耗时:0.00分/0.73分 | step:  4080 | performance: 1.0 | accuracy: 0.21 | loss: 0.09
update:515/2000, 耗时:0.00分/0.74分 | step:  4120 | performance: 1.0 | accuracy: 0.21 | loss: 0.25
update:520/2000, 耗时:0.00分/0.75分 | step:  4160 | performance: 1.0 | accuracy: 0.21 | loss: 0.00
update:525/2000, 耗时:0.00分/0.76分 | step:  4200 | performance: 1.1 | accuracy: 0.21 | loss: 0.37
update:530/2000, 耗时:0.00分/0.76分 | step:  4240 | performance: 1.1 | accuracy: 0.21 | loss: 0.00
update:535/2000, 耗时:0.00分/0.77分 | step:  4280 | performance: 1.0 | accuracy: 0.20 | loss: 0.00
update:540/2000, 耗时:0.00分/0.78分 | step:  4320 | performance: 1.0 | accuracy: 0.20 | loss: 0.00
update:545/2000, 耗时:0.00分/0.79分 | step:  4360 | performance: 1.0 | accuracy: 0.20 | loss: 0.83
update:550/2000, 耗时:0.00分/0.80分 | step:  4400 | performance: 1.0 | accuracy: 0.20 | loss: 0.49
update:555/2000, 耗时:0.00分/0.80分 | step:  4440 | performance: 1.0 | accuracy: 0.20 | loss: -0.00
update:560/2000, 耗时:0.00分/0.81分 | step:  4480 | performance: 0.9 | accuracy: 0.20 | loss: 0.00
update:565/2000, 耗时:0.00分/0.82分 | step:  4520 | performance: 0.9 | accuracy: 0.20 | loss: -0.00
update:570/2000, 耗时:0.00分/0.83分 | step:  4560 | performance: 0.9 | accuracy: 0.20 | loss: 0.67
update:575/2000, 耗时:0.00分/0.83分 | step:  4600 | performance: 0.8 | accuracy: 0.20 | loss: 0.70
update:580/2000, 耗时:0.00分/0.84分 | step:  4640 | performance: 0.8 | accuracy: 0.20 | loss: 0.00
update:585/2000, 耗时:0.00分/0.85分 | step:  4680 | performance: 0.8 | accuracy: 0.20 | loss: 0.46
update:590/2000, 耗时:0.00分/0.86分 | step:  4720 | performance: 0.9 | accuracy: 0.20 | loss: 0.45
update:595/2000, 耗时:0.00分/0.87分 | step:  4760 | performance: 0.9 | accuracy: 0.20 | loss: 0.18
update:600/2000, 耗时:0.00分/0.87分 | step:  4800 | performance: 0.9 | accuracy: 0.20 | loss: 0.04
update:605/2000, 耗时:0.00分/0.88分 | step:  4840 | performance: 0.9 | accuracy: 0.20 | loss: 0.58
update:610/2000, 耗时:0.00分/0.89分 | step:  4880 | performance: 0.9 | accuracy: 0.20 | loss: 0.01
update:615/2000, 耗时:0.00分/0.90分 | step:  4920 | performance: 0.8 | accuracy: 0.20 | loss: 0.19
update:620/2000, 耗时:0.00分/0.90分 | step:  4960 | performance: 0.9 | accuracy: 0.20 | loss: 0.00
update:625/2000, 耗时:0.00分/0.91分 | step:  5000 | performance: 0.9 | accuracy: 0.20 | loss: 0.10
update:630/2000, 耗时:0.00分/0.92分 | step:  5040 | performance: 0.9 | accuracy: 0.21 | loss: 0.01
update:635/2000, 耗时:0.00分/0.93分 | step:  5080 | performance: 0.9 | accuracy: 0.21 | loss: -0.00
update:640/2000, 耗时:0.00分/0.94分 | step:  5120 | performance: 0.8 | accuracy: 0.21 | loss: 0.39
update:645/2000, 耗时:0.00分/0.94分 | step:  5160 | performance: 0.9 | accuracy: 0.21 | loss: 0.29
update:650/2000, 耗时:0.00分/0.95分 | step:  5200 | performance: 0.8 | accuracy: 0.20 | loss: 0.02
update:655/2000, 耗时:0.00分/0.96分 | step:  5240 | performance: 0.8 | accuracy: 0.21 | loss: 0.35
update:660/2000, 耗时:0.00分/0.97分 | step:  5280 | performance: 0.8 | accuracy: 0.21 | loss: 0.38
update:665/2000, 耗时:0.00分/0.97分 | step:  5320 | performance: 0.8 | accuracy: 0.21 | loss: 0.00
update:670/2000, 耗时:0.00分/0.98分 | step:  5360 | performance: 0.8 | accuracy: 0.20 | loss: 0.53
update:675/2000, 耗时:0.00分/0.99分 | step:  5400 | performance: 0.7 | accuracy: 0.20 | loss: 0.39
update:680/2000, 耗时:0.00分/1.00分 | step:  5440 | performance: 0.7 | accuracy: 0.20 | loss: 0.01
update:685/2000, 耗时:0.00分/1.01分 | step:  5480 | performance: 0.7 | accuracy: 0.20 | loss: 0.32
update:690/2000, 耗时:0.00分/1.01分 | step:  5520 | performance: 0.7 | accuracy: 0.20 | loss: 0.26
update:695/2000, 耗时:0.00分/1.02分 | step:  5560 | performance: 0.8 | accuracy: 0.20 | loss: 0.54
update:700/2000, 耗时:0.00分/1.03分 | step:  5600 | performance: 0.8 | accuracy: 0.21 | loss: 0.31
update:705/2000, 耗时:0.00分/1.04分 | step:  5640 | performance: 0.7 | accuracy: 0.20 | loss: 0.70
update:710/2000, 耗时:0.00分/1.04分 | step:  5680 | performance: 0.7 | accuracy: 0.20 | loss: 0.00
update:715/2000, 耗时:0.00分/1.05分 | step:  5720 | performance: 0.7 | accuracy: 0.20 | loss: 0.09
update:720/2000, 耗时:0.00分/1.06分 | step:  5760 | performance: 0.6 | accuracy: 0.20 | loss: 0.00
update:725/2000, 耗时:0.00分/1.07分 | step:  5800 | performance: 0.7 | accuracy: 0.20 | loss: 0.01
update:730/2000, 耗时:0.00分/1.08分 | step:  5840 | performance: 0.7 | accuracy: 0.20 | loss: 0.03
update:735/2000, 耗时:0.00分/1.08分 | step:  5880 | performance: 0.6 | accuracy: 0.20 | loss: 0.02
update:740/2000, 耗时:0.00分/1.09分 | step:  5920 | performance: 0.6 | accuracy: 0.20 | loss: 0.01
update:745/2000, 耗时:0.00分/1.10分 | step:  5960 | performance: 0.6 | accuracy: 0.20 | loss: 0.04
update:750/2000, 耗时:0.00分/1.11分 | step:  6000 | performance: 0.6 | accuracy: 0.20 | loss: 0.44
update:755/2000, 耗时:0.00分/1.12分 | step:  6040 | performance: 0.6 | accuracy: 0.20 | loss: 0.55
update:760/2000, 耗时:0.00分/1.12分 | step:  6080 | performance: 0.6 | accuracy: 0.21 | loss: 0.00
update:765/2000, 耗时:0.00分/1.13分 | step:  6120 | performance: 0.6 | accuracy: 0.20 | loss: 0.48
update:770/2000, 耗时:0.00分/1.14分 | step:  6160 | performance: 0.6 | accuracy: 0.21 | loss: 0.01
update:775/2000, 耗时:0.00分/1.15分 | step:  6200 | performance: 0.6 | accuracy: 0.21 | loss: -0.00
update:780/2000, 耗时:0.00分/1.16分 | step:  6240 | performance: 1.0 | accuracy: 0.21 | loss: 1.06
update:785/2000, 耗时:0.00分/1.16分 | step:  6280 | performance: 1.1 | accuracy: 0.21 | loss: 0.01
update:790/2000, 耗时:0.00分/1.17分 | step:  6320 | performance: 1.1 | accuracy: 0.22 | loss: 0.00
update:795/2000, 耗时:0.00分/1.18分 | step:  6360 | performance: 1.1 | accuracy: 0.22 | loss: 0.38
update:800/2000, 耗时:0.00分/1.19分 | step:  6400 | performance: 1.1 | accuracy: 0.22 | loss: 0.09
update:805/2000, 耗时:0.00分/1.19分 | step:  6440 | performance: 1.1 | accuracy: 0.22 | loss: 0.60
update:810/2000, 耗时:0.00分/1.20分 | step:  6480 | performance: 1.1 | accuracy: 0.22 | loss: -0.00
update:815/2000, 耗时:0.00分/1.21分 | step:  6520 | performance: 1.1 | accuracy: 0.22 | loss: 0.21
update:820/2000, 耗时:0.00分/1.22分 | step:  6560 | performance: 1.1 | accuracy: 0.22 | loss: 0.00
update:825/2000, 耗时:0.00分/1.23分 | step:  6600 | performance: 1.1 | accuracy: 0.22 | loss: 0.02
update:830/2000, 耗时:0.00分/1.23分 | step:  6640 | performance: 1.0 | accuracy: 0.22 | loss: 0.22
update:835/2000, 耗时:0.00分/1.24分 | step:  6680 | performance: 1.0 | accuracy: 0.22 | loss: 0.05
update:840/2000, 耗时:0.00分/1.25分 | step:  6720 | performance: 1.0 | accuracy: 0.22 | loss: 0.00
update:845/2000, 耗时:0.00分/1.26分 | step:  6760 | performance: 1.0 | accuracy: 0.22 | loss: 0.02
update:850/2000, 耗时:0.00分/1.26分 | step:  6800 | performance: 1.1 | accuracy: 0.22 | loss: 0.04
update:855/2000, 耗时:0.00分/1.27分 | step:  6840 | performance: 1.5 | accuracy: 0.22 | loss: 0.91
update:860/2000, 耗时:0.00分/1.28分 | step:  6880 | performance: 1.5 | accuracy: 0.22 | loss: 1.04
update:865/2000, 耗时:0.00分/1.29分 | step:  6920 | performance: 1.7 | accuracy: 0.22 | loss: 0.60
update:870/2000, 耗时:0.00分/1.29分 | step:  6960 | performance: 1.3 | accuracy: 0.22 | loss: 1.19
update:875/2000, 耗时:0.00分/1.30分 | step:  7000 | performance: 1.3 | accuracy: 0.22 | loss: 0.31
update:880/2000, 耗时:0.00分/1.31分 | step:  7040 | performance: 1.3 | accuracy: 0.22 | loss: 0.03
update:885/2000, 耗时:0.00分/1.32分 | step:  7080 | performance: 1.5 | accuracy: 0.22 | loss: 0.68
update:890/2000, 耗时:0.00分/1.32分 | step:  7120 | performance: 1.7 | accuracy: 0.23 | loss: 0.42
update:895/2000, 耗时:0.00分/1.33分 | step:  7160 | performance: 1.5 | accuracy: 0.23 | loss: 1.01
update:900/2000, 耗时:0.00分/1.34分 | step:  7200 | performance: 1.6 | accuracy: 0.23 | loss: 0.00
update:905/2000, 耗时:0.00分/1.35分 | step:  7240 | performance: 1.3 | accuracy: 0.23 | loss: 0.00
update:910/2000, 耗时:0.00分/1.35分 | step:  7280 | performance: 1.3 | accuracy: 0.23 | loss: 0.00
update:915/2000, 耗时:0.00分/1.36分 | step:  7320 | performance: 1.2 | accuracy: 0.23 | loss: 0.51
update:920/2000, 耗时:0.00分/1.37分 | step:  7360 | performance: 1.2 | accuracy: 0.22 | loss: 0.00
update:925/2000, 耗时:0.00分/1.38分 | step:  7400 | performance: 1.3 | accuracy: 0.23 | loss: 0.38
update:930/2000, 耗时:0.00分/1.38分 | step:  7440 | performance: 1.5 | accuracy: 0.23 | loss: 0.11
update:935/2000, 耗时:0.00分/1.39分 | step:  7480 | performance: 1.5 | accuracy: 0.23 | loss: 0.51
update:940/2000, 耗时:0.00分/1.40分 | step:  7520 | performance: 2.3 | accuracy: 0.23 | loss: 0.29
update:945/2000, 耗时:0.00分/1.41分 | step:  7560 | performance: 2.8 | accuracy: 0.24 | loss: 0.03
update:950/2000, 耗时:0.00分/1.41分 | step:  7600 | performance: 3.1 | accuracy: 0.24 | loss: 4.43
update:955/2000, 耗时:0.00分/1.42分 | step:  7640 | performance: 2.8 | accuracy: 0.24 | loss: 0.30
update:960/2000, 耗时:0.00分/1.43分 | step:  7680 | performance: 2.4 | accuracy: 0.24 | loss: 1.61
update:965/2000, 耗时:0.00分/1.44分 | step:  7720 | performance: 1.9 | accuracy: 0.24 | loss: 1.02
update:970/2000, 耗时:0.00分/1.45分 | step:  7760 | performance: 2.0 | accuracy: 0.24 | loss: 0.65
update:975/2000, 耗时:0.00分/1.45分 | step:  7800 | performance: 2.0 | accuracy: 0.24 | loss: 0.48
update:980/2000, 耗时:0.00分/1.46分 | step:  7840 | performance: 1.5 | accuracy: 0.24 | loss: 0.23
update:985/2000, 耗时:0.00分/1.47分 | step:  7880 | performance: 1.1 | accuracy: 0.24 | loss: 0.07
update:990/2000, 耗时:0.00分/1.48分 | step:  7920 | performance: 1.0 | accuracy: 0.24 | loss: 0.00
update:995/2000, 耗时:0.00分/1.48分 | step:  7960 | performance: 1.2 | accuracy: 0.24 | loss: 1.56
update:1000/2000, 耗时:0.00分/1.49分 | step:  8000 | performance: 1.1 | accuracy: 0.24 | loss: 0.63
update:1005/2000, 耗时:0.00分/1.50分 | step:  8040 | performance: 0.9 | accuracy: 0.24 | loss: 0.41
update:1010/2000, 耗时:0.00分/1.51分 | step:  8080 | performance: 0.9 | accuracy: 0.24 | loss: 0.05
update:1015/2000, 耗时:0.00分/1.51分 | step:  8120 | performance: 0.9 | accuracy: 0.24 | loss: 0.28
update:1020/2000, 耗时:0.00分/1.52分 | step:  8160 | performance: 1.0 | accuracy: 0.25 | loss: 0.38
update:1025/2000, 耗时:0.00分/1.53分 | step:  8200 | performance: 1.1 | accuracy: 0.25 | loss: 0.33
update:1030/2000, 耗时:0.00分/1.54分 | step:  8240 | performance: 1.4 | accuracy: 0.25 | loss: 1.28
update:1035/2000, 耗时:0.00分/1.54分 | step:  8280 | performance: 1.5 | accuracy: 0.25 | loss: 0.19
update:1040/2000, 耗时:0.00分/1.55分 | step:  8320 | performance: 1.3 | accuracy: 0.25 | loss: 0.14
update:1045/2000, 耗时:0.00分/1.56分 | step:  8360 | performance: 1.1 | accuracy: 0.25 | loss: 0.77
update:1050/2000, 耗时:0.00分/1.57分 | step:  8400 | performance: 1.1 | accuracy: 0.25 | loss: -0.00
update:1055/2000, 耗时:0.00分/1.57分 | step:  8440 | performance: 1.2 | accuracy: 0.25 | loss: 0.47
update:1060/2000, 耗时:0.00分/1.58分 | step:  8480 | performance: 1.0 | accuracy: 0.26 | loss: 1.11
update:1065/2000, 耗时:0.00分/1.59分 | step:  8520 | performance: 1.0 | accuracy: 0.26 | loss: 0.28
update:1070/2000, 耗时:0.00分/1.60分 | step:  8560 | performance: 1.1 | accuracy: 0.26 | loss: 0.46
update:1075/2000, 耗时:0.00分/1.60分 | step:  8600 | performance: 0.9 | accuracy: 0.26 | loss: 0.74
update:1080/2000, 耗时:0.00分/1.61分 | step:  8640 | performance: 0.9 | accuracy: 0.26 | loss: 0.45
update:1085/2000, 耗时:0.00分/1.62分 | step:  8680 | performance: 1.1 | accuracy: 0.26 | loss: 0.36
update:1090/2000, 耗时:0.00分/1.63分 | step:  8720 | performance: 1.2 | accuracy: 0.26 | loss: 0.03
update:1095/2000, 耗时:0.00分/1.63分 | step:  8760 | performance: 1.1 | accuracy: 0.26 | loss: 0.00
update:1100/2000, 耗时:0.00分/1.64分 | step:  8800 | performance: 1.0 | accuracy: 0.26 | loss: 0.92
update:1105/2000, 耗时:0.00分/1.65分 | step:  8840 | performance: 1.0 | accuracy: 0.26 | loss: 0.25
update:1110/2000, 耗时:0.00分/1.66分 | step:  8880 | performance: 1.0 | accuracy: 0.26 | loss: 0.10
update:1115/2000, 耗时:0.00分/1.67分 | step:  8920 | performance: 1.0 | accuracy: 0.26 | loss: 0.01
update:1120/2000, 耗时:0.00分/1.67分 | step:  8960 | performance: 1.0 | accuracy: 0.26 | loss: 0.04
update:1125/2000, 耗时:0.00分/1.68分 | step:  9000 | performance: 1.0 | accuracy: 0.26 | loss: 0.03
update:1130/2000, 耗时:0.00分/1.69分 | step:  9040 | performance: 1.0 | accuracy: 0.26 | loss: 0.04
update:1135/2000, 耗时:0.00分/1.70分 | step:  9080 | performance: 0.9 | accuracy: 0.26 | loss: 0.79
update:1140/2000, 耗时:0.00分/1.70分 | step:  9120 | performance: 1.0 | accuracy: 0.26 | loss: 0.80
update:1145/2000, 耗时:0.00分/1.71分 | step:  9160 | performance: 1.0 | accuracy: 0.26 | loss: 0.44
update:1150/2000, 耗时:0.00分/1.72分 | step:  9200 | performance: 1.0 | accuracy: 0.26 | loss: 0.25
update:1155/2000, 耗时:0.00分/1.73分 | step:  9240 | performance: 1.0 | accuracy: 0.26 | loss: 0.00
update:1160/2000, 耗时:0.00分/1.73分 | step:  9280 | performance: 1.0 | accuracy: 0.26 | loss: 0.00
update:1165/2000, 耗时:0.00分/1.74分 | step:  9320 | performance: 1.0 | accuracy: 0.26 | loss: 0.03
update:1170/2000, 耗时:0.00分/1.75分 | step:  9360 | performance: 1.0 | accuracy: 0.26 | loss: -0.00
update:1175/2000, 耗时:0.00分/1.76分 | step:  9400 | performance: 1.0 | accuracy: 0.26 | loss: 0.00
update:1180/2000, 耗时:0.00分/1.77分 | step:  9440 | performance: 1.0 | accuracy: 0.26 | loss: 0.06
update:1185/2000, 耗时:0.00分/1.77分 | step:  9480 | performance: 1.2 | accuracy: 0.26 | loss: 0.67
update:1190/2000, 耗时:0.00分/1.78分 | step:  9520 | performance: 1.1 | accuracy: 0.26 | loss: 1.16
update:1195/2000, 耗时:0.00分/1.79分 | step:  9560 | performance: 0.9 | accuracy: 0.26 | loss: 0.47
update:1200/2000, 耗时:0.00分/1.80分 | step:  9600 | performance: 1.0 | accuracy: 0.26 | loss: 0.23
update:1205/2000, 耗时:0.00分/1.80分 | step:  9640 | performance: 1.0 | accuracy: 0.27 | loss: 0.28
update:1210/2000, 耗时:0.00分/1.81分 | step:  9680 | performance: 1.0 | accuracy: 0.27 | loss: 0.30
update:1215/2000, 耗时:0.00分/1.82分 | step:  9720 | performance: 1.0 | accuracy: 0.27 | loss: 0.04
update:1220/2000, 耗时:0.00分/1.83分 | step:  9760 | performance: 1.0 | accuracy: 0.27 | loss: 0.35
update:1225/2000, 耗时:0.00分/1.84分 | step:  9800 | performance: 0.9 | accuracy: 0.27 | loss: 0.03
update:1230/2000, 耗时:0.00分/1.85分 | step:  9840 | performance: 1.0 | accuracy: 0.27 | loss: 0.39
update:1235/2000, 耗时:0.00分/1.85分 | step:  9880 | performance: 1.0 | accuracy: 0.27 | loss: 0.33
update:1240/2000, 耗时:0.00分/1.86分 | step:  9920 | performance: 1.2 | accuracy: 0.27 | loss: 0.13
update:1245/2000, 耗时:0.00分/1.87分 | step:  9960 | performance: 1.6 | accuracy: 0.27 | loss: 0.16
update:1250/2000, 耗时:0.00分/1.88分 | step: 10000 | performance: 1.7 | accuracy: 0.27 | loss: 0.46
update:1255/2000, 耗时:0.00分/1.89分 | step: 10040 | performance: 1.6 | accuracy: 0.27 | loss: 0.60
update:1260/2000, 耗时:0.00分/1.89分 | step: 10080 | performance: 1.4 | accuracy: 0.27 | loss: 0.33
update:1265/2000, 耗时:0.00分/1.90分 | step: 10120 | performance: 1.3 | accuracy: 0.27 | loss: 0.39
update:1270/2000, 耗时:0.00分/1.91分 | step: 10160 | performance: 1.3 | accuracy: 0.27 | loss: 1.00
update:1275/2000, 耗时:0.00分/1.92分 | step: 10200 | performance: 1.4 | accuracy: 0.27 | loss: 1.26
update:1280/2000, 耗时:0.00分/1.92分 | step: 10240 | performance: 1.4 | accuracy: 0.28 | loss: 0.24
update:1285/2000, 耗时:0.00分/1.93分 | step: 10280 | performance: 1.5 | accuracy: 0.28 | loss: 0.14
update:1290/2000, 耗时:0.00分/1.94分 | step: 10320 | performance: 1.5 | accuracy: 0.28 | loss: 0.01
update:1295/2000, 耗时:0.00分/1.95分 | step: 10360 | performance: 1.8 | accuracy: 0.28 | loss: 0.01
update:1300/2000, 耗时:0.00分/1.96分 | step: 10400 | performance: 1.5 | accuracy: 0.28 | loss: 0.27
update:1305/2000, 耗时:0.00分/1.96分 | step: 10440 | performance: 1.6 | accuracy: 0.28 | loss: 5.53
update:1310/2000, 耗时:0.00分/1.97分 | step: 10480 | performance: 1.6 | accuracy: 0.28 | loss: 0.43
update:1315/2000, 耗时:0.00分/1.98分 | step: 10520 | performance: 1.7 | accuracy: 0.29 | loss: 1.18
update:1320/2000, 耗时:0.00分/1.99分 | step: 10560 | performance: 1.6 | accuracy: 0.28 | loss: 0.02
update:1325/2000, 耗时:0.00分/1.99分 | step: 10600 | performance: 1.7 | accuracy: 0.29 | loss: 0.22
update:1330/2000, 耗时:0.00分/2.00分 | step: 10640 | performance: 1.6 | accuracy: 0.29 | loss: 3.65
update:1335/2000, 耗时:0.00分/2.01分 | step: 10680 | performance: 1.5 | accuracy: 0.29 | loss: 0.34
update:1340/2000, 耗时:0.00分/2.02分 | step: 10720 | performance: 1.4 | accuracy: 0.29 | loss: 0.03
update:1345/2000, 耗时:0.00分/2.03分 | step: 10760 | performance: 1.4 | accuracy: 0.29 | loss: 0.04
update:1350/2000, 耗时:0.00分/2.03分 | step: 10800 | performance: 1.4 | accuracy: 0.29 | loss: -0.00
update:1355/2000, 耗时:0.00分/2.04分 | step: 10840 | performance: 1.3 | accuracy: 0.29 | loss: 0.34
update:1360/2000, 耗时:0.00分/2.05分 | step: 10880 | performance: 1.4 | accuracy: 0.29 | loss: 0.15
update:1365/2000, 耗时:0.00分/2.06分 | step: 10920 | performance: 1.4 | accuracy: 0.29 | loss: 0.65
update:1370/2000, 耗时:0.00分/2.07分 | step: 10960 | performance: 1.3 | accuracy: 0.29 | loss: 0.04
update:1375/2000, 耗时:0.00分/2.07分 | step: 11000 | performance: 1.3 | accuracy: 0.29 | loss: -0.00
update:1380/2000, 耗时:0.00分/2.08分 | step: 11040 | performance: 1.3 | accuracy: 0.29 | loss: 0.37
update:1385/2000, 耗时:0.00分/2.09分 | step: 11080 | performance: 1.3 | accuracy: 0.29 | loss: 0.20
update:1390/2000, 耗时:0.00分/2.10分 | step: 11120 | performance: 1.3 | accuracy: 0.29 | loss: 0.18
update:1395/2000, 耗时:0.00分/2.11分 | step: 11160 | performance: 1.3 | accuracy: 0.29 | loss: 0.00
update:1400/2000, 耗时:0.00分/2.11分 | step: 11200 | performance: 1.3 | accuracy: 0.29 | loss: 0.62
update:1405/2000, 耗时:0.00分/2.12分 | step: 11240 | performance: 1.3 | accuracy: 0.29 | loss: 0.77
update:1410/2000, 耗时:0.00分/2.13分 | step: 11280 | performance: 1.3 | accuracy: 0.29 | loss: 0.00
update:1415/2000, 耗时:0.00分/2.14分 | step: 11320 | performance: 1.3 | accuracy: 0.29 | loss: 1.24
update:1420/2000, 耗时:0.00分/2.15分 | step: 11360 | performance: 1.1 | accuracy: 0.29 | loss: -0.00
update:1425/2000, 耗时:0.00分/2.15分 | step: 11400 | performance: 1.2 | accuracy: 0.29 | loss: 0.63
update:1430/2000, 耗时:0.00分/2.16分 | step: 11440 | performance: 1.2 | accuracy: 0.29 | loss: 0.35
update:1435/2000, 耗时:0.00分/2.17分 | step: 11480 | performance: 1.0 | accuracy: 0.29 | loss: 0.17
update:1440/2000, 耗时:0.00分/2.18分 | step: 11520 | performance: 0.8 | accuracy: 0.29 | loss: -0.00
update:1445/2000, 耗时:0.00分/2.18分 | step: 11560 | performance: 0.8 | accuracy: 0.29 | loss: 0.00
update:1450/2000, 耗时:0.00分/2.19分 | step: 11600 | performance: 0.7 | accuracy: 0.29 | loss: 0.17
update:1455/2000, 耗时:0.00分/2.20分 | step: 11640 | performance: 0.7 | accuracy: 0.29 | loss: 0.01
update:1460/2000, 耗时:0.00分/2.21分 | step: 11680 | performance: 0.6 | accuracy: 0.29 | loss: 0.78
update:1465/2000, 耗时:0.00分/2.22分 | step: 11720 | performance: 0.6 | accuracy: 0.29 | loss: 1.08
update:1470/2000, 耗时:0.00分/2.22分 | step: 11760 | performance: 0.2 | accuracy: 0.29 | loss: 2.50
update:1475/2000, 耗时:0.00分/2.23分 | step: 11800 | performance: 0.2 | accuracy: 0.29 | loss: 0.27
update:1480/2000, 耗时:0.00分/2.24分 | step: 11840 | performance: 0.2 | accuracy: 0.29 | loss: 0.18
update:1485/2000, 耗时:0.00分/2.25分 | step: 11880 | performance: 0.2 | accuracy: 0.29 | loss: 0.87
update:1490/2000, 耗时:0.00分/2.25分 | step: 11920 | performance: 0.2 | accuracy: 0.29 | loss: 0.99
update:1495/2000, 耗时:0.00分/2.26分 | step: 11960 | performance: 0.2 | accuracy: 0.29 | loss: 0.86
update:1500/2000, 耗时:0.00分/2.27分 | step: 12000 | performance: 0.2 | accuracy: 0.29 | loss: 1.26
update:1505/2000, 耗时:0.00分/2.28分 | step: 12040 | performance: 0.2 | accuracy: 0.29 | loss: 0.00
update:1510/2000, 耗时:0.00分/2.28分 | step: 12080 | performance: 0.2 | accuracy: 0.29 | loss: -0.00
update:1515/2000, 耗时:0.00分/2.29分 | step: 12120 | performance: 0.1 | accuracy: 0.29 | loss: 0.19
update:1520/2000, 耗时:0.00分/2.30分 | step: 12160 | performance: 0.2 | accuracy: 0.29 | loss: 0.46
update:1525/2000, 耗时:0.00分/2.31分 | step: 12200 | performance: 0.2 | accuracy: 0.29 | loss: 0.48
update:1530/2000, 耗时:0.00分/2.32分 | step: 12240 | performance: 0.1 | accuracy: 0.29 | loss: 0.04
update:1535/2000, 耗时:0.00分/2.32分 | step: 12280 | performance: 0.1 | accuracy: 0.29 | loss: 0.48
update:1540/2000, 耗时:0.00分/2.33分 | step: 12320 | performance: 0.2 | accuracy: 0.29 | loss: 0.03
update:1545/2000, 耗时:0.00分/2.34分 | step: 12360 | performance: 0.2 | accuracy: 0.29 | loss: 0.50
update:1550/2000, 耗时:0.00分/2.35分 | step: 12400 | performance: 0.2 | accuracy: 0.29 | loss: -0.00
update:1555/2000, 耗时:0.00分/2.35分 | step: 12440 | performance: 0.2 | accuracy: 0.29 | loss: 0.23
update:1560/2000, 耗时:0.00分/2.36分 | step: 12480 | performance: 0.2 | accuracy: 0.29 | loss: 0.50
update:1565/2000, 耗时:0.00分/2.37分 | step: 12520 | performance: 0.2 | accuracy: 0.29 | loss: 0.05
update:1570/2000, 耗时:0.00分/2.38分 | step: 12560 | performance: 0.2 | accuracy: 0.29 | loss: 0.07
update:1575/2000, 耗时:0.00分/2.38分 | step: 12600 | performance: 0.2 | accuracy: 0.29 | loss: 1.09
update:1580/2000, 耗时:0.00分/2.39分 | step: 12640 | performance: 0.2 | accuracy: 0.29 | loss: 0.58
update:1585/2000, 耗时:0.00分/2.40分 | step: 12680 | performance: 0.1 | accuracy: 0.29 | loss: 1.24
update:1590/2000, 耗时:0.00分/2.41分 | step: 12720 | performance: 0.1 | accuracy: 0.29 | loss: 1.55
update:1595/2000, 耗时:0.00分/2.41分 | step: 12760 | performance: 0.2 | accuracy: 0.29 | loss: 1.23
update:1600/2000, 耗时:0.00分/2.42分 | step: 12800 | performance: 0.2 | accuracy: 0.29 | loss: 0.68
update:1605/2000, 耗时:0.00分/2.43分 | step: 12840 | performance: 0.2 | accuracy: 0.29 | loss: 0.06
update:1610/2000, 耗时:0.00分/2.44分 | step: 12880 | performance: 0.1 | accuracy: 0.29 | loss: 0.11
update:1615/2000, 耗时:0.00分/2.45分 | step: 12920 | performance: 0.1 | accuracy: 0.29 | loss: 0.07
update:1620/2000, 耗时:0.00分/2.45分 | step: 12960 | performance: 0.1 | accuracy: 0.29 | loss: 0.00
update:1625/2000, 耗时:0.00分/2.46分 | step: 13000 | performance: 0.1 | accuracy: 0.29 | loss: 0.39
update:1630/2000, 耗时:0.00分/2.47分 | step: 13040 | performance: 0.2 | accuracy: 0.29 | loss: 0.07
update:1635/2000, 耗时:0.00分/2.48分 | step: 13080 | performance: 0.2 | accuracy: 0.29 | loss: 0.25
update:1640/2000, 耗时:0.00分/2.48分 | step: 13120 | performance: 0.2 | accuracy: 0.29 | loss: 0.47
update:1645/2000, 耗时:0.00分/2.49分 | step: 13160 | performance: 0.2 | accuracy: 0.29 | loss: 0.03
update:1650/2000, 耗时:0.00分/2.50分 | step: 13200 | performance: 0.2 | accuracy: 0.29 | loss: 0.00
update:1655/2000, 耗时:0.00分/2.51分 | step: 13240 | performance: 0.2 | accuracy: 0.29 | loss: 0.00
update:1660/2000, 耗时:0.00分/2.51分 | step: 13280 | performance: 0.2 | accuracy: 0.29 | loss: 0.00
update:1665/2000, 耗时:0.00分/2.52分 | step: 13320 | performance: 0.1 | accuracy: 0.29 | loss: 0.03
update:1670/2000, 耗时:0.00分/2.53分 | step: 13360 | performance: 0.1 | accuracy: 0.29 | loss: 0.00
update:1675/2000, 耗时:0.00分/2.54分 | step: 13400 | performance: 0.1 | accuracy: 0.28 | loss: 0.06
update:1680/2000, 耗时:0.00分/2.54分 | step: 13440 | performance: 0.1 | accuracy: 0.28 | loss: -0.00
update:1685/2000, 耗时:0.00分/2.55分 | step: 13480 | performance: 0.1 | accuracy: 0.28 | loss: 0.00
update:1690/2000, 耗时:0.00分/2.56分 | step: 13520 | performance: 0.1 | accuracy: 0.28 | loss: -0.00
update:1695/2000, 耗时:0.00分/2.57分 | step: 13560 | performance: 0.1 | accuracy: 0.28 | loss: -0.00
update:1700/2000, 耗时:0.00分/2.57分 | step: 13600 | performance: 0.1 | accuracy: 0.28 | loss: -0.00
update:1705/2000, 耗时:0.00分/2.58分 | step: 13640 | performance: 0.1 | accuracy: 0.28 | loss: 0.00
update:1710/2000, 耗时:0.00分/2.59分 | step: 13680 | performance: 0.1 | accuracy: 0.28 | loss: 0.00
update:1715/2000, 耗时:0.00分/2.60分 | step: 13720 | performance: 0.1 | accuracy: 0.28 | loss: -0.00
update:1720/2000, 耗时:0.00分/2.60分 | step: 13760 | performance: 0.1 | accuracy: 0.28 | loss: 0.00
update:1725/2000, 耗时:0.00分/2.61分 | step: 13800 | performance: 0.1 | accuracy: 0.28 | loss: -0.00
update:1730/2000, 耗时:0.00分/2.62分 | step: 13840 | performance: 0.1 | accuracy: 0.28 | loss: -0.00
update:1735/2000, 耗时:0.00分/2.62分 | step: 13880 | performance: 0.1 | accuracy: 0.28 | loss: -0.00
update:1740/2000, 耗时:0.00分/2.63分 | step: 13920 | performance: 0.1 | accuracy: 0.28 | loss: 0.00
update:1745/2000, 耗时:0.00分/2.64分 | step: 13960 | performance: 0.1 | accuracy: 0.28 | loss: 0.38
update:1750/2000, 耗时:0.00分/2.65分 | step: 14000 | performance: 0.2 | accuracy: 0.28 | loss: 0.26
update:1755/2000, 耗时:0.00分/2.65分 | step: 14040 | performance: 0.2 | accuracy: 0.28 | loss: 0.00
update:1760/2000, 耗时:0.00分/2.66分 | step: 14080 | performance: 0.2 | accuracy: 0.28 | loss: 0.42
update:1765/2000, 耗时:0.00分/2.67分 | step: 14120 | performance: 0.2 | accuracy: 0.28 | loss: 0.43
update:1770/2000, 耗时:0.00分/2.68分 | step: 14160 | performance: 0.2 | accuracy: 0.27 | loss: 0.00
update:1775/2000, 耗时:0.00分/2.68分 | step: 14200 | performance: 0.2 | accuracy: 0.27 | loss: -0.00
update:1780/2000, 耗时:0.00分/2.69分 | step: 14240 | performance: 0.2 | accuracy: 0.27 | loss: 0.24
update:1785/2000, 耗时:0.00分/2.70分 | step: 14280 | performance: 0.2 | accuracy: 0.27 | loss: 0.00
update:1790/2000, 耗时:0.00分/2.71分 | step: 14320 | performance: 0.2 | accuracy: 0.27 | loss: 0.00
update:1795/2000, 耗时:0.00分/2.71分 | step: 14360 | performance: 0.2 | accuracy: 0.27 | loss: 0.00
update:1800/2000, 耗时:0.00分/2.72分 | step: 14400 | performance: 0.2 | accuracy: 0.27 | loss: -0.00
update:1805/2000, 耗时:0.00分/2.73分 | step: 14440 | performance: 0.2 | accuracy: 0.27 | loss: 0.01
update:1810/2000, 耗时:0.00分/2.74分 | step: 14480 | performance: 0.2 | accuracy: 0.27 | loss: 0.00
update:1815/2000, 耗时:0.00分/2.74分 | step: 14520 | performance: 0.2 | accuracy: 0.27 | loss: -0.00
update:1820/2000, 耗时:0.00分/2.75分 | step: 14560 | performance: 0.2 | accuracy: 0.27 | loss: -0.00
update:1825/2000, 耗时:0.00分/2.76分 | step: 14600 | performance: 0.2 | accuracy: 0.27 | loss: 0.31
update:1830/2000, 耗时:0.00分/2.77分 | step: 14640 | performance: 0.2 | accuracy: 0.27 | loss: 0.11
update:1835/2000, 耗时:0.00分/2.77分 | step: 14680 | performance: 0.2 | accuracy: 0.27 | loss: 0.15
update:1840/2000, 耗时:0.00分/2.78分 | step: 14720 | performance: 0.2 | accuracy: 0.27 | loss: 0.04
update:1845/2000, 耗时:0.00分/2.79分 | step: 14760 | performance: 0.2 | accuracy: 0.27 | loss: 0.08
update:1850/2000, 耗时:0.00分/2.80分 | step: 14800 | performance: 0.2 | accuracy: 0.27 | loss: 0.21
update:1855/2000, 耗时:0.00分/2.80分 | step: 14840 | performance: 0.2 | accuracy: 0.27 | loss: 0.00
update:1860/2000, 耗时:0.00分/2.81分 | step: 14880 | performance: 0.2 | accuracy: 0.27 | loss: 0.00
update:1865/2000, 耗时:0.00分/2.82分 | step: 14920 | performance: 0.2 | accuracy: 0.27 | loss: 0.24
update:1870/2000, 耗时:0.00分/2.83分 | step: 14960 | performance: 0.2 | accuracy: 0.27 | loss: 0.62
update:1875/2000, 耗时:0.00分/2.83分 | step: 15000 | performance: 0.2 | accuracy: 0.27 | loss: 0.68
update:1880/2000, 耗时:0.00分/2.84分 | step: 15040 | performance: 0.2 | accuracy: 0.27 | loss: 0.00
update:1885/2000, 耗时:0.00分/2.85分 | step: 15080 | performance: 0.2 | accuracy: 0.27 | loss: 0.38
update:1890/2000, 耗时:0.00分/2.86分 | step: 15120 | performance: 0.2 | accuracy: 0.27 | loss: 0.07
update:1895/2000, 耗时:0.00分/2.86分 | step: 15160 | performance: 0.2 | accuracy: 0.27 | loss: 0.19
update:1900/2000, 耗时:0.00分/2.87分 | step: 15200 | performance: 0.2 | accuracy: 0.27 | loss: 0.22
update:1905/2000, 耗时:0.00分/2.88分 | step: 15240 | performance: 0.2 | accuracy: 0.27 | loss: 0.19
update:1910/2000, 耗时:0.00分/2.89分 | step: 15280 | performance: 0.2 | accuracy: 0.27 | loss: 0.26
update:1915/2000, 耗时:0.00分/2.89分 | step: 15320 | performance: 0.3 | accuracy: 0.28 | loss: 0.00
update:1920/2000, 耗时:0.00分/2.90分 | step: 15360 | performance: 0.3 | accuracy: 0.28 | loss: 0.03
update:1925/2000, 耗时:0.00分/2.91分 | step: 15400 | performance: 0.3 | accuracy: 0.28 | loss: 3.07
update:1930/2000, 耗时:0.00分/2.92分 | step: 15440 | performance: 0.3 | accuracy: 0.28 | loss: 0.23
update:1935/2000, 耗时:0.00分/2.92分 | step: 15480 | performance: 0.3 | accuracy: 0.28 | loss: 0.01
update:1940/2000, 耗时:0.00分/2.93分 | step: 15520 | performance: 0.3 | accuracy: 0.28 | loss: 0.05
update:1945/2000, 耗时:0.00分/2.94分 | step: 15560 | performance: 0.5 | accuracy: 0.28 | loss: 0.03
update:1950/2000, 耗时:0.00分/2.95分 | step: 15600 | performance: 0.4 | accuracy: 0.28 | loss: 0.14
update:1955/2000, 耗时:0.00分/2.95分 | step: 15640 | performance: 0.4 | accuracy: 0.28 | loss: 0.75
update:1960/2000, 耗时:0.00分/2.96分 | step: 15680 | performance: 0.5 | accuracy: 0.29 | loss: 1.50
update:1965/2000, 耗时:0.00分/2.97分 | step: 15720 | performance: 0.5 | accuracy: 0.29 | loss: 0.12
update:1970/2000, 耗时:0.00分/2.98分 | step: 15760 | performance: 0.7 | accuracy: 0.29 | loss: 0.00
update:1975/2000, 耗时:0.00分/2.99分 | step: 15800 | performance: 0.8 | accuracy: 0.29 | loss: 0.00
update:1980/2000, 耗时:0.00分/2.99分 | step: 15840 | performance: 0.8 | accuracy: 0.29 | loss: 0.72
update:1985/2000, 耗时:0.00分/3.00分 | step: 15880 | performance: 0.6 | accuracy: 0.29 | loss: 1.21
update:1990/2000, 耗时:0.00分/3.01分 | step: 15920 | performance: 0.6 | accuracy: 0.29 | loss: 1.45
update:1995/2000, 耗时:0.00分/3.02分 | step: 15960 | performance: 0.8 | accuracy: 0.29 | loss: 0.26
  0%|          | 0/401 [00:00<?, ?it/s]100%|| 401/401 [00:00<00:00, 133400.69it/s]
update:2000/2000, 耗时:0.00分/3.02分 | step: 16000 | performance: 0.8 | accuracy: 0.29 | loss: 1.90
----------------------------------------finished----------------------------------------
==================================================
2023-01-05T12:00:00 | *** START BACKTEST ***
2023-01-05T12:00:00 | current balance = 1000.00
==================================================
==================================================
2023-07-24T12:00:00 | *** CLOSING OUT ***
2023-07-24T12:00:00 | current balance = 1725.61
2023-07-24T12:00:00 | net performance [%] = 72.5615
2023-07-24T12:00:00 | number of trades [#] = 2
==================================================
Trial 60 Complete [00h 03m 28s]
net_wealth: 1727.3420349333471

Best net_wealth So Far: 1824.8039564105297
Total elapsed time: 08h 18m 21s
Results summary
Results in saved_model\keras_tuner
Showing 10 best trials
Objective(name="net_wealth", direction="max")

Trial 51 summary
Hyperparameters:
horizon: 6
lookback: 365
MarketFactor: True
lags: 10
gamma: 0.98
batch_size: 16
n_step: 7
gae_lambda: 0.94
gradient_clip_norm: 0.5
epochs: 3
actor_lr: 0.001
critic_lr: 0.001
Score: 1824.8039564105297

Trial 33 summary
Hyperparameters:
horizon: 7
lookback: 730
MarketFactor: False
lags: 14
gamma: 0.7
batch_size: 32
n_step: 32
gae_lambda: 0.92
gradient_clip_norm: 0.1
epochs: 5
actor_lr: 0.0001
critic_lr: 5e-05
Score: 1752.3888145064732

Trial 13 summary
Hyperparameters:
horizon: 1
lookback: 730
MarketFactor: False
lags: 3
gamma: 0.92
batch_size: 32
n_step: 1
gae_lambda: 0.94
gradient_clip_norm: 5.0
epochs: 5
actor_lr: 0.0001
critic_lr: 0.0005
Score: 1739.2646221209268

Trial 38 summary
Hyperparameters:
horizon: 1
lookback: 730
MarketFactor: True
lags: 10
gamma: 0.9
batch_size: 16
n_step: 7
gae_lambda: 0.98
gradient_clip_norm: 5.0
epochs: 5
actor_lr: 0.001
critic_lr: 0.0001
Score: 1727.3420349333471

Trial 59 summary
Hyperparameters:
horizon: 3
lookback: 365
MarketFactor: True
lags: 10
gamma: 0.92
batch_size: 32
n_step: 1
gae_lambda: 0.94
gradient_clip_norm: 2.0
epochs: 3
actor_lr: 0.0005
critic_lr: 0.001
Score: 1727.3420349333471

Trial 43 summary
Hyperparameters:
horizon: 5
lookback: 730
MarketFactor: False
lags: 7
gamma: 0.6
batch_size: 32
n_step: 7
gae_lambda: 0.92
gradient_clip_norm: 2.0
epochs: 3
actor_lr: 0.001
critic_lr: 0.0001
Score: 1726.9829154412218

Trial 21 summary
Hyperparameters:
horizon: 4
lookback: 225
MarketFactor: True
lags: 14
gamma: 0.98
batch_size: 16
n_step: 64
gae_lambda: 0.99
gradient_clip_norm: 1.0
epochs: 3
actor_lr: 0.0001
critic_lr: 0.001
Score: 1719.2504621082335

Trial 15 summary
Hyperparameters:
horizon: 2
lookback: 365
MarketFactor: True
lags: 5
gamma: 0.7
batch_size: 32
n_step: 1
gae_lambda: 0.96
gradient_clip_norm: 2.0
epochs: 5
actor_lr: 0.0001
critic_lr: 0.0005
Score: 1715.952446010363

Trial 07 summary
Hyperparameters:
horizon: 6
lookback: 225
MarketFactor: True
lags: 14
gamma: 0.85
batch_size: 32
n_step: 64
gae_lambda: 0.8
gradient_clip_norm: 2.0
epochs: 3
actor_lr: 0.001
critic_lr: 1e-05
Score: 1714.485333603393

Trial 25 summary
Hyperparameters:
horizon: 1
lookback: 225
MarketFactor: True
lags: 10
gamma: 0.8
batch_size: 16
n_step: 32
gae_lambda: 0.99
gradient_clip_norm: 0.1
epochs: 5
actor_lr: 5e-05
critic_lr: 0.0001
Score: 1679.7001409568088
None
   horizon  lookback  MarketFactor  ...  actor_lr  critic_lr        score
0        6       365          True  ...   0.00100    0.00100  1824.803956
1        7       730         False  ...   0.00010    0.00005  1752.388815
2        1       730         False  ...   0.00010    0.00050  1739.264622
3        1       730          True  ...   0.00100    0.00010  1727.342035
4        3       365          True  ...   0.00050    0.00100  1727.342035
5        5       730         False  ...   0.00100    0.00010  1726.982915
6        4       225          True  ...   0.00010    0.00100  1719.250462
7        2       365          True  ...   0.00010    0.00050  1715.952446
8        6       225          True  ...   0.00100    0.00001  1714.485334
9        1       225          True  ...   0.00005    0.00010  1679.700141

[10 rows x 13 columns]
horizon=6
lookback=365
MarketFactor=True
lags=10
gamma=0.98
batch_size=16
n_step=7
gae_lambda=0.94
gradient_clip_norm=0.5
epochs=3
actor_lr=0.001
critic_lr=0.001
